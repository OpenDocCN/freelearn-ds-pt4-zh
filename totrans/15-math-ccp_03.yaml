- en: <st c="0">2</st>
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="0">2</st>
- en: <st c="2">Random Variables and Probability Distributions</st>
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="2">随机变量与概率分布</st>
- en: <st c="48">In this chapter, we are going to learn about randomness in data and
    how we can use probability distributions to describe and handle this randomness.</st>
    <st c="198">Because of the importance of this chapter, we will deliberately spend
    a lot of time emphasizing in words the math concepts we are introducing.</st>
    <st c="341">This makes this chapter a long one.</st> <st c="377">Take your time
    and digest its contents fully.</st> <st c="423">Doing so will pay dividends because
    so many of the other math concepts we introduce in this book are underpinned by
    what we introduce in this chapter.</st> <st c="574">We will do this in five separate
    topics, each building upon the previous topic.</st> <st c="654">Those topics are</st>
    <st c="671">the following:</st>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48">在这一章中，我们将学习数据中的随机性，以及如何使用概率分布来描述和处理这些随机性。</st> <st c="198">由于这一章的重要性，我们会特意花费大量时间通过文字强调我们所引入的数学概念。</st>
    <st c="341">这使得这一章内容较长。</st> <st c="377">请慢慢阅读，充分消化其内容。</st> <st c="423">这样做会带来回报，因为本书中我们所介绍的许多其他数学概念都建立在这一章所介绍的基础上。</st>
    <st c="574">我们将通过五个独立的主题来进行，每个主题都建立在前一个主题的基础上。</st> <st c="654">这些主题包括</st> <st
    c="671">以下内容：</st>
- en: '*<st c="685">All data is random</st>*<st c="704">: In this section, we learn
    how randomness in data arises and why it is important to</st> <st c="790">understand
    it</st>'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="685">所有数据都是随机的</st>*<st c="704">：在这一节中，我们将学习数据中的随机性是如何产生的，以及为什么理解它如此重要。</st>
    <st c="790">理解这一点</st>。'
- en: '*<st c="803">Random variables and probability distributions</st>*<st c="850">:
    In this section, we learn the basics of random variables and probability distributions,
    why they are useful for describing randomness in data, how to summarize their
    characteristics, how to transform them, as well as the details of some commonly
    occurring distributions you will encounter as a</st> <st c="1147">data scientist</st>'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="803">随机变量与概率分布</st>*<st c="850">：在这一节中，我们将学习随机变量和概率分布的基础知识，了解它们为何在描述数据中的随机性时非常有用，如何总结它们的特性，如何对它们进行转换，以及一些常见分布的详细内容，这些分布你会在作为</st>
    <st c="1147">数据科学家</st> 时遇到。'
- en: '*<st c="1161">Sampling from distributions</st>*<st c="1189">: In this section,
    we learn how datasets are created or sampled from probability distributions, and
    how to generate our</st> <st c="1310">own samples</st>'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="1161">从分布中抽样</st>*<st c="1189">：在这一节中，我们将学习数据集是如何从概率分布中创建或抽样的，以及如何生成我们自己的</st>
    <st c="1310">样本</st>。'
- en: '*<st c="1321">Understanding statistical estimators</st>*<st c="1358">: In this
    section, we learn how samples of data differ from the distribution from which
    the data was generated, and how to use our new knowledge of probability distributions
    to make accurate inferences from samples</st> <st c="1574">of data</st>'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="1321">理解统计估计量</st>*<st c="1358">：在这一节中，我们将学习数据样本如何与生成数据的分布不同，以及如何利用我们对概率分布的新理解，从样本中做出准确的推断。</st>
    <st c="1574">数据样本</st>'
- en: '*<st c="1581">The Central Limit Theorem</st>* <st c="1607">(</st>*<st c="1609">CLT</st>*<st
    c="1612">): In this section, we learn why and how the normal distribution is one
    of the most common distributions we will encounter as a</st> <st c="1741">data
    scientist</st>'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="1581">中心极限定理</st>* <st c="1607">（</st>*<st c="1609">CLT</st>*<st c="1612">）：在这一节中，我们将学习为何以及如何正态分布成为我们作为</st>
    <st c="1741">数据科学家</st> 时最常遇到的分布之一。'
- en: <st c="1755">Technical requirements</st>
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="1755">技术要求</st>
- en: <st c="1778">All code examples given in this chapter (and additional examples)
    can be found at the GitHub repository,</st> [<st c="1884">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter02</st>](https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter02)<st
    c="1988">. To run the Jupyter notebooks, you will need a full Python installation,
    including the</st> <st c="2076">following packages:</st>
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="1778">本章中给出的所有代码示例（以及其他额外的示例）可以在 GitHub 仓库中找到，</st> [<st c="1884">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter02</st>](https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter02)<st
    c="1988">。要运行 Jupyter notebooks，你需要安装完整的 Python 环境，包括以下包：</st>
- en: '`<st c="2095">numpy</st>` <st c="2101">(>=1.24.3)</st>'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2095">numpy</st>` <st c="2101">(>=1.24.3)</st>'
- en: '`<st c="2112">scipy</st>` <st c="2118">(>=1.11.1)</st>'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2112">scipy</st>` <st c="2118">(>=1.11.1)</st>'
- en: '`<st c="2129">scikit-learn</st>` <st c="2142">(>=1.3.0)</st>'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2129">scikit-learn</st>` <st c="2142">(>=1.3.0)</st>'
- en: '`<st c="2152">matplotlib</st>` <st c="2163">(>=3.7.2)</st>'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2152">matplotlib</st>` <st c="2163">(>=3.7.2)</st>'
- en: <st c="2173">All data is random</st>
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="2173">所有数据都是随机的</st>
- en: <st c="2192">If you</st> <st c="2200">read only one chapter in this book, read
    this one.</st> <st c="2251">Why?</st> <st c="2256">Well, because it explains the
    most important math concept in data science – all data is random.</st> <st c="2352">Or,
    more precisely, all data contains a</st> <st c="2392">random component.</st>
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2192">如果你</st> <st c="2200">只读这本书中的一章，那就读这一章。</st> <st c="2251">为什么？</st>
    <st c="2256">因为它解释了数据科学中最重要的数学概念——所有数据都是随机的。</st> <st c="2352">或者，更准确地说，所有数据都包含一个</st>
    <st c="2392">随机成分。</st>
- en: <st c="2409">Is this really the case?</st> <st c="2435">Let’s explain.</st>
    <st c="2450">To start, we must explain what we mean by random.</st> <st c="2500">I’m
    not going to give some dry technical definition here, expressed in mathematical
    symbols.</st> <st c="2593">I’m going to give a technical, but intuitive definition:</st>
    *<st c="2650">random</st>* *<st c="2657">means non-predictable</st>*<st c="2678">.</st>
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2409">这真的是这样吗？</st> <st c="2435">让我们来解释一下。</st> <st c="2450">首先，我们必须解释一下我们所说的“随机”是什么意思。</st>
    <st c="2500">我不会在这里给出一些枯燥的技术定义，用数学符号表示。</st> <st c="2593">我将给出一个技术性但直观的定义：</st>
    *<st c="2650">随机</st>* *<st c="2657">意味着不可预测</st>*<st c="2678">。</st>
- en: <st c="2679">What do we mean by that?</st> <st c="2705">Precisely what it says.</st>
    <st c="2729">If something is random, it can’t be computed or calculated</st> <st
    c="2788">in advance.</st>
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2679">我们这是什么意思？</st> <st c="2705">正是它所说的意思。</st> <st c="2729">如果某件事是随机的，它是无法提前计算或推算的。</st>
    <st c="2788">提前计算是不可能的。</st>
- en: <st c="2799">A little example</st>
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="2799">一个小例子</st>
- en: <st c="2816">I have an</st> <st c="2826">old ship’s barometer that belonged
    to my father (he was a ship’s captain).</st> <st c="2902">The barometer is damaged
    and a bit temperamental, so the measurement is imprecise.</st> <st c="2985">This
    means the measured atmospheric pressure is not the same as the actual atmospheric
    pressure but deviates from it, possibly by as much as +/- 40 mbar.</st> <st c="3139">We
    can capture the idea of that deviation in the following</st> <st c="3198">schematic
    equation:</st>
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2816">我有一只</st> <st c="2826">属于我父亲的旧船用气压计（他是船长）。</st> <st c="2902">这个气压计坏了，有点不稳定，因此测量不准确。</st>
    <st c="2985">这意味着测得的大气压力与实际大气压力不相同，而是偏离它，偏差可能达到+/- 40 毫巴。</st> <st c="3139">我们可以用以下示意方程来表示这个偏差：</st>
    <st c="3198">示意方程：</st>
- en: <st c="3217">Measured atmospheric pressure = True atmospheric pressure + Measurement
    ‘Noise</st><st c="3296">’</st>
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3217">测量的大气压力 = 真实的大气压力 + 测量“噪声”</st><st c="3296">’</st>
- en: <st c="3298">Eq.</st> <st c="3302">1</st>
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3298">公式</st> <st c="3302">1</st>
- en: <st c="3303">I have referred</st> <st c="3319">to this as a schematic equation
    because it expresses a key concept.</st> <st c="3387">The data we have, the measured
    pressure, deviates from what we’d like to know – the true pressure – due to the
    addition of the random measurement noise.</st> <st c="3540">So, the data (the
    observation) contains a</st> <st c="3582">random component.</st>
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3303">我将此称为示意方程，因为它表达了一个关键概念。</st> <st c="3319">我们拥有的数据，即测量的压力，偏离了我们想要知道的——真实压力——这是由于随机测量噪声的添加。</st>
    <st c="3387">因此，数据（观察值）包含一个</st> <st c="3540">随机成分。</st>
- en: <st c="3599">Sometimes, we also refer to measurement noise as measurement error
    or just error.</st> <st c="3682">In fact,</st> *<st c="3691">error</st>* <st c="3696">is
    a word used a lot to describe the random component in data.</st> <st c="3760">Sometimes
    we will also use the word</st> *<st c="3796">stochastic</st>* <st c="3806">instead
    of random, so you may see the terms</st> *<st c="3851">random error</st>*<st c="3863">,</st>
    *<st c="3865">random component</st>*<st c="3881">,</st> *<st c="3883">stochastic
    error</st>*<st c="3899">, and</st> *<st c="3905">stochastic component</st>* <st
    c="3925">used interchangeably.</st>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3582">有时，我们也称测量噪声为测量误差或仅仅是误差。</st> <st c="3599">实际上，</st> *<st c="3691">误差</st>*
    <st c="3696">是一个常用来描述数据中随机成分的词。</st> <st c="3760">有时我们还会用</st> *<st c="3796">随机过程</st>*
    <st c="3806">来代替随机一词，所以你可能会看到</st> *<st c="3851">随机误差</st>*<st c="3863">、</st>
    *<st c="3865">随机成分</st>*<st c="3881">、</st> *<st c="3883">随机误差</st>*<st c="3899">和</st>
    *<st c="3905">随机成分</st>* <st c="3925">这些词汇互换使用。</st>
- en: <st c="3947">You may say, “</st>*<st c="3962">But that measurement error is
    just because you’re using an old barometer.</st> <st c="4037">If you were just
    using a modern digital barometer, the error in the pressure measurement would
    be inconsequential</st>*<st c="4150">.” True, but measurement error would still
    be there because we have to use some proxy physical process by which the force
    of the atmosphere is transferred to some other object whose change we can measure.</st>
    <st c="4355">Philosophically, what matters is that the error is there.</st> <st
    c="4413">One of our jobs as data scientists is to assess/quantify the scale of
    the error and determine how consequential</st> <st c="4525">it is.</st>
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3947">你可能会说：“</st>*<st c="3962">但那个测量误差只是因为你使用的是旧气压计。</st> <st c="4037">如果你使用现代数字气压计，压力测量中的误差就微不足道了</st>*<st
    c="4150">。”没错，但测量误差仍然存在，因为我们必须通过某种代理物理过程来测量大气压力的作用力，并将其传递到另一个我们能测量变化的物体上。</st>
    <st c="4355">从哲学的角度来看，重要的是误差是存在的。</st> <st c="4413">作为数据科学家的工作之一就是评估/量化误差的大小，并确定其影响的程度。</st>
    <st c="4525">它的重要性。</st>
- en: <st c="4531">One thing we should emphasize is that the use of the word</st>
    *<st c="4590">error</st>* <st c="4595">does not imply a mistake has been made.</st>
    <st c="4636">It simply implies that there is a difference between the measurement
    and the true value.</st> <st c="4725">In our preceding example, the use of the
    word</st> *<st c="4771">error</st>* <st c="4776">means there is a difference between
    the measured pressure and the true (and unobserved) pressure.</st> <st c="4875">That
    difference is natural, and we understand why it comes about.</st> <st c="4941">No
    mistake has been made.</st> <st c="4967">Measurement error is a natural consequence
    of the fact that we measure things via proxy physical processes; for example,
    the atmosphere exerting pressure indirectly on a</st> <st c="5137">metal spring.</st>
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4531">我们需要强调的一点是，使用“</st>*<st c="4590">误差</st>* <st c="4595">”这个词并不意味着发生了错误。</st>
    <st c="4636">它只是意味着测量值与真实值之间存在差异。</st> <st c="4725">在我们之前的例子中，使用“</st>*<st c="4771">误差</st>*
    <st c="4776">”这个词表示测量的压力与真实（且未观测到的）压力之间存在差异。</st> <st c="4875">这种差异是自然的，我们理解它为什么会发生。</st>
    <st c="4941">并没有发生错误。</st> <st c="4967">测量误差是我们通过代理物理过程来进行测量的自然结果；例如，大气压力通过金属弹簧间接传递。</st>
- en: <st c="5150">Pro tip</st>
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="5150">专业提示</st>
- en: <st c="5158">On this point about what we mean, as data scientists, when we use
    the word</st> *<st c="5234">error</st>*<st c="5239">, be careful.</st> <st c="5253">Don’t
    use the word</st> *<st c="5272">error</st>* <st c="5277">when talking to non-data
    science stakeholders, or be very careful using it.</st> <st c="5354">A non-data
    scientist may hear</st> *<st c="5384">mistake</st>* <st c="5391">when you use
    the word</st> *<st c="5414">error</st>*<st c="5419">. So, instead, I tend to explain
    using words such as</st> *<st c="5472">deviation</st>* <st c="5481">or</st> *<st
    c="5485">difference</st>*<st c="5495">.</st>
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="5158">作为数据科学家，在使用“</st>*<st c="5234">误差</st>*<st c="5239">”这个词时，我们要注意。</st>
    <st c="5253">不要在与非数据科学相关者交谈时使用“</st>*<st c="5272">误差</st>* <st c="5277">”这个词，或者使用时要非常小心。</st>
    <st c="5354">非数据科学家听到</st> *<st c="5384">错误</st>* <st c="5391">时可能会理解为</st> *<st
    c="5414">失误</st>*<st c="5419">。因此，我倾向于使用</st> *<st c="5472">偏差</st>* <st c="5481">或</st>
    *<st c="5485">差异</st>*<st c="5495">等词汇来解释。</st>
- en: <st c="5496">Systematic variation can be learned – random variation can’t</st>
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="5496">系统性变化可以被学习——随机变化则不行</st>
- en: <st c="5557">Sometimes I’m</st> <st c="5571">interested in just how inaccurate
    the old ship’s barometer is, so I also take a measurement using a small digital
    barometer I have.</st> <st c="5704">The measurement from the digital barometer
    I consider to be accurate – the measurement error is much smaller – and so the
    reading from the digital barometer I interpret as being the true atmospheric pressure.</st>
    <st c="5913">The following scatterplot shows how the two measurements relate to</st>
    <st c="5980">each other:</st>
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="5557">有时我对旧船气压计的准确性感兴趣，因此我还会用我手头的小型数字气压计进行测量。</st> <st c="5704">我认为数字气压计的测量是准确的——其测量误差更小——因此我将数字气压计的读数视为真正的大气压。</st>
    <st c="5913">下面的散点图显示了这两个测量值之间的关系：</st> <st c="5980">彼此之间：</st>
- en: '![Figure 2.1: Scatterplot showing the accuracy of my old ship’s barometer](img/B19496_02_01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1：显示我旧船气压计准确性的散点图](img/B19496_02_01.jpg)'
- en: '<st c="6128">Figure 2.1: Scatterplot showing the accuracy of my old ship’s
    barometer</st>'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6128">图2.1：显示我旧船气压计准确性的散点图</st>
- en: <st c="6199">The solid red line is the 1:1 line and so shows that on average
    the ship’s barometer reading gives the correct atmospheric pressure, but the vertical
    scatter about that line clearly highlights the random nature of the measurement
    from the ship’s barometer.</st> <st c="6457">What it also highlights is that if
    I wanted to predict what the ship’s barometer measurement would be, I wouldn’t
    be able to do so, even if I knew what the true pressure was.</st> <st c="6632">How
    far above or below the line any particular individual ship’s barometer measurement
    is is determined by the random measurement error.</st> <st c="6769">We can’t predict
    this in advance because, by definition, it is random.</st> <st c="6840">No amount
    of clever mathematics will change this.</st> <st c="6890">No</st> **<st c="6893">machine
    learning</st>** <st c="6909">(</st>**<st c="6911">ML</st>**<st c="6913">) algorithm
    will be able to predict what the next measurement from my ship’s barometer will
    be, no matter how much training data is given to</st> <st c="7055">that algorithm.</st>
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6199">实心红线是1:1线，显示了船只气压计读数平均能够提供正确的大气压力，但该线周围的垂直散布清楚地突显了船只气压计测量的随机性。</st>
    <st c="6457">它还突显了，如果我想预测船只气压计的读数，即使我知道真实压力，也无法做到这一点。</st> <st c="6632">任何特定船只的气压计读数离该线的远近是由随机测量误差决定的。</st>
    <st c="6769">我们无法提前预测这一点，因为根据定义，它是随机的。</st> <st c="6840">再聪明的数学也无法改变这一点。</st>
    <st c="6890">没有</st> **<st c="6893">机器学习</st>** <st c="6909">(</st>**<st c="6911">ML</st>**<st
    c="6913">) 算法能够预测我的船只气压计下一个测量值会是多少，无论给该算法多少训练数据。</st> <st c="7055">这些训练数据。</st>
- en: <st c="7070">What the solid line</st> <st c="7090">on the scatterplot does show,
    though, is that there is something about the ship’s barometer measurement that
    can be predicted – its average behavior.</st> <st c="7241">The average ship’s
    barometer measurement is the same as the true pressure, and so it varies systematically
    with the true pressure.</st> <st c="7372">It is this average or systematic behavior
    that an ML algorithm could learn and would learn with increasing accuracy as we
    used an increasing amount of training data.</st> <st c="7538">An alternative schematic
    way of writing</st> *<st c="7578">Eq.</st> <st c="7582">1</st>* <st c="7583">would
    be</st> <st c="7593">the following:</st>
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7070">然而，散点图上实线所展示的内容是，船只气压计的测量值中有一些是可以预测的——它的平均行为。</st> <st c="7090">船只气压计的平均测量值等于真实压力，因此它会随真实压力的变化而系统性地变化。</st>
    <st c="7241">正是这种平均或系统性行为是机器学习算法可以学习的，并且随着我们使用越来越多的训练数据，算法的准确度会逐步提高。</st> <st
    c="7372">这种平均或系统性行为是机器学习算法能够学习的内容，并且随着我们使用更多的训练数据，它会逐渐提高准确性。</st> <st c="7538">另一种示意性写法</st>
    *<st c="7578">公式</st> <st c="7582">1</st>* <st c="7583">可以是以下形式：</st>
- en: <st c="7607">Observed Data = Systematic component + Random compon</st><st c="7660">ent</st>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7607">观测数据 = 系统性成分 + 随机成分</st><st c="7660">成分</st>
- en: <st c="7664">Eq.</st> <st c="7669">2</st>
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7664">公式</st> <st c="7669">2</st>
- en: <st c="7670">It is the systematic component that data science algorithms can
    learn and not the random component.</st> <st c="7770">In this simple example,
    the random component is additive, and without loss of generality, we can assume
    its average is zero.</st> <st c="7895">Consequently, the systematic component
    here is equal to the average value of the observed data, or more correctly, the
    average value of the observed data is equal to the systematic contribution to
    the data.</st> <st c="8102">This is not always the case, as we</st> <st c="8137">explain
    next.</st>
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7670">数据科学算法可以学习的，正是系统性成分，而非随机成分。</st> <st c="7770">在这个简单的例子中，随机成分是加性的，且我们可以假设其平均值为零，而不失一般性。</st>
    <st c="7895">因此，系统性成分等于观测数据的平均值，或者更准确地说，观测数据的平均值等于数据的系统性贡献。</st> <st c="8102">但这并非总是如此，正如我们</st>
    <st c="8137">接下来将解释的那样。</st>
- en: <st c="8150">Random variation is not just measurement error</st>
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="8150">随机变化不仅仅是测量误差</st>
- en: <st c="8197">“But,” I can</st> <st c="8210">hear you say, “what about something
    where there is no measurement error, where it is highly unlikely that we measured
    something incorrectly?” Consider something such as what kind of drink I’m drinking
    now, as I write this at 11:15 a.m.</st> <st c="8447">on a Saturday morning.</st>
    <st c="8470">Surely, I can’t be mistaken about what kind of drink, tea or coffee,
    that I have in my cup?</st> <st c="8562">No, but what type of drink I choose to
    put in the cup can still have a large random component to it.</st> <st c="8663">Let</st>
    <st c="8667">me illustrate.</st>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="8197">“但是，”我听到你说，“如果没有测量误差，且我们测量的东西极不可能出错呢？”</st> <st c="8210">考虑一下我现在在11:15上午写作时喝的是什么饮品，假设是一个星期六的早晨。</st>
    <st c="8447">我确定我杯子里的是茶还是咖啡，不会错吧？</st> <st c="8470">我没有错误，但我选择放入杯中的饮品类型仍然可能有很大的随机成分。</st>
    <st c="8562">让我举个例子。</st>
- en: <st c="8681">In the morning when I’m writing, I like to have a hot drink around
    11:00 a.m.</st> <st c="8760">Overall, I choose tea 40% of the time and coffee
    60% of the time.</st> <st c="8826">There is some good logic as to which drink
    I will choose.</st> <st c="8884">Largely, which type of drink depends on whether
    I’m already getting tired by 11:00 a.m., and that depends on how well I’ve slept.</st>
    <st c="9014">How well I’ve slept depends on whether I’ve had my cat trying to
    sit on my head during the night while I’ve been trying to sleep.</st> <st c="9144">Whether
    the cat tries to sit on my head depends on whether the cat wants to be inside
    the house or outside hunting.</st> <st c="9260">This chain of connections is summarized
    in the</st> <st c="9307">following diagram:</st>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="8681">早晨我在写作时，我喜欢在上午11:00左右喝一杯热饮。</st> <st c="8760">总体来说，我40%的时间选择茶，60%的时间选择咖啡。</st>
    <st c="8826">我选择饮品的理由有一定的逻辑。</st> <st c="8884">主要是，选择哪种饮料取决于我在上午11:00时是否已经感到疲倦，而这取决于我睡得好不好。</st>
    <st c="9014">我睡得好不好取决于晚上睡觉时猫咪是否试图坐在我的头上。</st> <st c="9144">猫咪是否试图坐在我的头上取决于它是否想待在屋里还是去外面打猎。</st>
    <st c="9260">这种关联链条总结在下面的</st> <st c="9307">图表中：</st>
- en: '![Figure 2.2: How my cat’s random behavior makes my choice of morning drink
    effectively random](img/B19496_02_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2：我的猫咪的随机行为如何使我选择早晨饮品变得完全随机](img/B19496_02_02.jpg)'
- en: '<st c="9350">Figure 2.2: How my cat’s random behavior makes my choice of morning
    drink effectively random</st>'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9350">图2.2：我的猫咪的随机行为如何使我选择早晨饮品变得完全随机</st>
- en: <st c="9442">Despite there</st> <st c="9456">being a strong deterministic element
    to how I make my choice of drink in the morning, there is a large random variability
    in the outcome because my choice is now largely determined by the whim of my cat’s
    behavior the</st> <st c="9675">night before.</st>
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9442">尽管我选择早晨饮品的方式有很强的决定性因素，但结果中仍然存在较大的随机变化，因为我的选择在很大程度上取决于猫咪前一晚的行为。</st>
    <st c="9675">夜晚的行为是完全随机的。</st>
- en: <st c="9688">This example highlights three</st> <st c="9719">important things:</st>
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9688">这个例子突出了三件</st> <st c="9719">重要的事情：</st>
- en: <st c="9736">The random component within data is not necessarily additive.</st>
    <st c="9799">Random variation does not always present itself in the form of</st>
    *<st c="9862">Eq.</st> <st c="9866">2</st>*<st c="9867">. Instead, random variation
    can be variation in the chosen outcome.</st> <st c="9935">The potential outcomes
    may have well-defined long-run frequencies of occurrence, but any single instance
    of an outcome is unpredictable – that is, random – because in this example, on
    any particular night, I don’t know what my cat is going</st> <st c="10175">to
    do.</st>
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="9736">数据中的随机成分不一定是可加的。</st> <st c="9799">随机变化并不总是以</st> *<st c="9862">公式</st>
    <st c="9866">2</st>*<st c="9867">的形式出现。</st> <st c="9935">相反，随机变化可以表现为所选择结果的变化。</st>
    <st c="10175">这些潜在的结果可能具有明确定义的长期出现频率，但任何单一的结果实例都是不可预测的——也就是说，是随机的——因为在这个例子中，在任何特定的夜晚，我都无法知道猫咪将</st>
    <st c="10175">做什么。</st>
- en: <st c="10181">What we consider to be random can be a matter of modeling choice.</st>
    <st c="10248">I’ve said my morning drink is essentially determined by what my
    cat did the night before.</st> <st c="10338">Now, you may think that my cat’s
    behavior could potentially be predicted.</st> <st c="10412">Personally, I doubt
    it, but let’s say that in theory, it could.</st> <st c="10476">However, whatever
    equations are determining my cat’s behavior, they must be so complex as to give
    the appearance of something almost random because I have yet to work my cat out.</st>
    <st c="10655">What this illustrates is that sometimes we have variation in data
    that is systematic – meaning it is deterministic in nature and could in principle
    be predicted in advance – but that systematic variation is so complex, or its
    deterministic causes hidden from us, that we choose to view that variation as
    effectively being random and we model it</st> <st c="11000">as such.</st>
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="10181">我们认为是随机的，可能是建模选择的问题。</st> <st c="10248">我曾说过，我早晨喝的饮料本质上是由我的猫昨晚的行为决定的。</st>
    <st c="10338">现在，你可能认为，我猫的行为或许是可以预测的。</st> <st c="10412">就我个人而言，我对此表示怀疑，但假设从理论上讲，它是可以预测的。</st>
    <st c="10476">然而，无论是什么方程决定了我猫的行为，它们一定是如此复杂，以至于表现出几乎是随机的现象，因为我至今还没搞懂我的猫。</st> <st
    c="10655">这表明，有时候我们数据中的变异是有规律的——意味着它本质上是决定性的，原则上可以预先预测——但这种规律性的变异如此复杂，或者它的决定性原因我们无法知晓，以至于我们选择将其视为随机的，并且将其建模为</st>
    <st c="11000">随机的。</st>
- en: <st c="11008">Wherever</st> <st c="11018">human decisions are involved, we have
    random variability in outcomes, and that variability can be marked.</st> <st c="11124">When
    modeling datasets of human decisions, understanding this</st> <st c="11186">is
    important.</st>
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="11008">无论何时</st> <st c="11018">只要涉及到人类决策，我们的结果就会有随机变异，这种变异是可以标记的。</st>
    <st c="11124">在对人类决策数据集建模时，理解这一点</st> <st c="11186">非常重要。</st>
- en: <st c="11199">What are the consequences of data being random?</st>
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="11199">数据是随机的，会带来什么后果呢？</st>
- en: <st c="11247">Okay – so I may</st> <st c="11263">have convinced you that all
    data contains some random component.</st> <st c="11329">So what?</st> <st c="11338">Why
    is this important for data science?</st> <st c="11378">Unfortunately, if our starting
    data has some random variation within it, then so does everything we derive from
    that data.</st> <st c="11501">This means every downstream quantity we calculate.</st>
    <st c="11552">And I mean everything – every average value calculated from a dataset,
    every loss-function value we calculate from a dataset when training an ML algorithm,
    every parameter value of a</st> **<st c="11735">deep learning</st>** <st c="11748">(</st>**<st
    c="11750">DL</st>**<st c="11752">)</st> **<st c="11755">neural network</st>**
    <st c="11769">(</st>**<st c="11771">NN</st>**<st c="11773">) trained using a dataset,
    every single ML metric</st> <st c="11824">we calculate.</st>
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="11247">好的——所以我可能</st> <st c="11263">已经让你相信所有数据都包含某种随机成分。</st> <st c="11329">那又怎样呢？</st>
    <st c="11338">为什么这对数据科学如此重要？</st> <st c="11378">不幸的是，如果我们起始的数据中包含随机变异，那么我们从这些数据中推导出的所有内容也会包含随机成分。</st>
    <st c="11501">这意味着我们计算的每一个下游量都会有随机性。</st> <st c="11552">我的意思是每一件事——从数据集计算的每一个平均值，从数据集计算出的每个损失函数值，在训练机器学习算法时，从数据集得出的每个参数值，每一个深度学习**（DL）**神经网络**（NN）**的参数值，所有计算出的机器学习指标</st>
    <st c="11824">都会包含随机成分。</st>
- en: <st c="11837">If the random variation within data affects every single calculation
    we do in data science, we’d better learn how to handle this random variation.</st>
    <st c="11985">The rest of this chapter is devoted to giving you the mathematical
    tools and language to do just that.</st> <st c="12088">But it will first require
    learning some new concepts, so this is a good place to finish this section and
    recap what we</st> <st c="12207">have learned.</st>
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="11837">如果数据中的随机变异影响了我们在数据科学中进行的每一次计算，我们最好学会如何处理这种随机变异。</st> <st c="11985">本章的其余部分将致力于为你提供实现这一目标的数学工具和语言。</st>
    <st c="12088">但首先，我们需要学习一些新的概念，因此在此结束本节并回顾一下我们</st> <st c="12207">所学的内容是个不错的选择。</st>
- en: <st c="12220">What we learned</st>
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="12220">我们所学到的内容</st>
- en: <st c="12236">In this section, we have learned</st> <st c="12270">the following:</st>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="12236">在本节中，我们学到了</st> <st c="12270">以下内容：</st>
- en: <st c="12284">All data we will work with as data scientists has a random component</st>
    <st c="12354">to it</st>
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="12284">作为数据科学家，我们将处理的所有数据都有一个随机成分</st> <st c="12354">在其中。</st>
- en: <st c="12359">Because of this randomness in data, all quantities derived from
    data also contain a</st> <st c="12444">random component</st>
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="12359">由于数据中的这种随机性，所有从数据中派生的量也都包含一个</st> <st c="12444">随机成分</st>
- en: <st c="12460">Only the non-random or systematic variation in a dataset is learnable
    by a data</st> <st c="12541">science algorithm</st>
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="12460">只有数据集中的非随机或系统性变化才是数据</st> <st c="12541">科学算法可以学习的。</st>
- en: <st c="12558">Sometimes, parts of the systematic variation in a dataset will
    be hidden from us – we will be unaware that the variation is systematic, and so
    because of our ignorance we will treat it</st> <st c="12744">as random</st>
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="12558">有时，数据集中的系统性变化的部分会对我们隐藏——我们不知道这些变化是系统性的，因此由于我们的无知，我们会把它</st> <st
    c="12744">当作随机的</st>
- en: <st c="12753">Sometimes, parts of the systematic variation in a dataset will
    be so complex that we deliberately choose to treat it as</st> <st c="12874">effectively
    random</st>
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="12753">有时，数据集中的部分系统性变化会复杂到我们故意选择将其视为</st> <st c="12874">有效的随机</st>
- en: <st c="12892">Having learned how randomness appears in all datasets we work
    with as data scientists, in the next section, we move on to how we describe and
    quantify</st> <st c="13044">that randomness.</st>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="12892">在学习了随机性如何出现在我们作为数据科学家所处理的所有数据集之后，在下一节中，我们将讨论如何描述和量化</st> <st c="13044">这种随机性。</st>
- en: <st c="13060">Random variables and probability distributions</st>
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="13060">随机变量和概率分布</st>
- en: <st c="13107">We start this section by introducing a new concept that is necessary
    to describe the randomness we find</st> <st c="13212">in data.</st>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13107">我们通过引入一个新概念来开始这一节内容，这个概念对于描述数据中的随机性是必需的。</st> <st c="13212">在数据中。</st>
- en: <st c="13220">A new concept – random variables</st>
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="13220">一个新概念——随机变量</st>
- en: <st c="13253">In</st> <st c="13257">computer code, when we want to use a variable,
    we type something such as</st> `<st c="13330">x=5</st>`<st c="13333">. In many
    programming languages, we may change the value of the variable</st> `<st c="13406">x</st>`<st
    c="13407">. We even use the word</st> *<st c="13430">variable</st>* <st c="13438">to
    indicate that its value may change.</st> <st c="13478">However, those changes
    are caused by us or by code we have written, and so typically they happen in a
    deterministic way; that is, we compute when the changes should happen, and we
    can compute the new value of</st> <st c="13687">the variable.</st>
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13253">在</st> <st c="13257">计算机代码中，当我们想要使用一个变量时，我们会输入类似</st> `<st c="13330">x=5</st>`<st
    c="13333">的内容。在许多编程语言中，我们可以改变变量</st> `<st c="13406">x</st>`<st c="13407">的值。我们甚至使用*<st
    c="13430">变量</st>*一词来表示它的值可能会改变。</st> <st c="13478">然而，这些变化是由我们或者我们编写的代码引起的，因此它们通常是以确定性的方式发生的；也就是说，我们计算出变化应该发生的时刻，并且可以计算出</st>
    <st c="13687">变量的新值。</st>
- en: <st c="13700">For data that contains a random component, we need a new concept.</st>
    <st c="13767">Remember – random means non-predictable.</st> <st c="13808">When
    we record, observe, or capture the value of that variable, its value is not pre-determined.</st>
    <st c="13905">Instead, it could take on a number of values.</st> <st c="13951">The
    new concept we need is that of a</st> **<st c="13988">random variable</st>**<st
    c="14003">. A random variable is a variable, but its value when measured can be
    one of many different potential outcomes, each occurring with different probabilities.</st>
    <st c="14160">For example, the hot drink I will choose tomorrow morning is a random
    variable with two possible outcomes (tea or coffee) with probabilities of 0.4
    and</st> <st c="14312">0.6, respectively.</st>
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13700">对于包含随机成分的数据，我们需要一个新概念。</st> <st c="13767">记住——随机意味着不可预测。</st>
    <st c="13808">当我们记录、观察或捕捉到该变量的值时，它的值是无法预定的。</st> <st c="13905">相反，它可能会取多个值。</st>
    <st c="13951">我们需要的新概念是</st> **<st c="13988">随机变量</st>**<st c="14003">。随机变量是一个变量，但它在测量时的值可能是许多不同潜在结果之一，每个结果的发生概率不同。</st>
    <st c="14160">例如，我明天早晨选择的热饮是一个随机变量，有两个可能的结果（茶或咖啡），它们的概率分别为0.4和</st> <st c="14312">0.6。</st>
- en: <st c="14330">Listing the possible outcomes of a random variable and their associated
    probabilities gives us all the information we need to work with that random variable.</st>
    <st c="14489">We call this set of probabilities a</st> **<st c="14525">probability
    distribution</st>**<st c="14549">. Graphically, we can display this as a simple
    chart.</st> <st c="14603">For</st> <st c="14607">example, the bar chart in</st>
    *<st c="14633">Figure 2</st>**<st c="14641">.3</st>* <st c="14643">shows the two
    possible outcomes for the tea/coffee example and their</st> <st c="14713">associated
    probabili</st><st c="14733">ties:</st>
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="14330">列出随机变量的所有可能结果及其关联的概率，给了我们处理该随机变量所需的所有信息。</st> <st c="14489">我们称这个概率集合为</st>
    **<st c="14525">概率分布</st>**<st c="14549">。图形化显示时，我们可以将其表示为一个简单的图表。</st> <st c="14603">例如，</st>
    *<st c="14633">图 2</st>**<st c="14641">.3</st>* <st c="14643">中的条形图展示了茶/咖啡示例的两个可能结果及其</st>
    <st c="14713">关联概率</st><st c="14733">：</st>
- en: '![Figure 2.3: The probability distribution for my morning drink choice](img/B19496_02_03.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3：我的早晨饮品选择的概率分布](img/B19496_02_03.jpg)'
- en: '<st c="14841">Figure 2.3: The probability distribution for my morning drink
    choice</st>'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="14841">图 2.3：我的早晨饮品选择的概率分布</st>
- en: <st c="14909">We could equally have listed the probability distribution as a
    table, such as we have in</st> *<st c="14999">Table</st> <st c="15005">2.1</st>*<st
    c="15008">:</st>
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="14909">我们也可以将概率分布列为表格，如</st> *<st c="14999">表</st> <st c="15005">2.1</st>*<st
    c="15008">所示：</st>
- en: '![Table 2.1: My morning drink probability distribution displayed in table form](img/B19496_02_04.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![表 2.1：我的早晨饮品概率分布表格形式展示](img/B19496_02_04.jpg)'
- en: '<st c="15045">Table 2.1: My morning drink probability distribution displayed
    in table form</st>'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15045">表 2.1：我的早晨饮品概率分布表格形式展示</st>
- en: <st c="15121">Where we have many outcomes, the graphical visualization is more
    intuitive.</st> <st c="15198">We can quickly pick out which outcomes have the
    highest probability, and we can see where the probability becomes very small,
    so outcomes occur very infrequently.</st> <st c="15361">In many situations, the
    possible outcomes of a random variable will have a natural ordering; for example,
    if I was considering the number of items bought from an e-commerce website in
    a day.</st> <st c="15552">Ten items bought in a day is clearly larger than five
    items bought.</st> <st c="15620">The number of items bought in a day probably
    has an upper limit, but some random variables can have an infinite number of</st>
    <st c="15742">potential outcomes.</st>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15121">当结果很多时，图形化可视化更为直观。</st> <st c="15198">我们可以快速识别出概率最高的结果，并且可以看到概率变得非常小的地方，这意味着这些结果发生的频率非常低。</st>
    <st c="15361">在许多情况下，随机变量的可能结果会有自然的顺序；例如，如果我考虑的是在一天内从电商网站购买的商品数量。</st> <st c="15552">一天购买十件商品显然比五件更多。</st>
    <st c="15620">一天购买的商品数量可能有一个上限，但一些随机变量的潜在结果可以是无限的。</st>
- en: <st c="15761">One of the most obvious</st> <st c="15786">characteristics of
    the probability distribution shown in</st> *<st c="15843">Figure 2</st>**<st c="15851">.3</st>*
    <st c="15853">or</st> *<st c="15857">Table 2.1</st>* <st c="15866">is that the
    probabilities for the two possible outcomes add up to 1\.</st> <st c="15936">This
    is true for any probability distribution.</st> <st c="15983">The probabilities
    across all the possible outcomes always sum to 1\.</st> <st c="16051">This is
    because the sum of the probabilities represents the probability of getting any
    outcome, and we have absolute certainty that we will get some outcome.</st> <st
    c="16209">If a probability distribution has outcomes</st> <st c="16252">x</st>
    <st c="16253">and associated probabilities</st> <st c="16283">p</st><st c="16284">(</st><st
    c="16285">x</st><st c="16286">)</st><st c="16287">, we write this condition</st>
    <st c="16313">as follows:</st>
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15761">概率分布的一个最明显的</st> <st c="15786">特征，如</st> *<st c="15843">图 2</st>**<st
    c="15851">.3</st>* <st c="15853">或</st> *<st c="15857">表 2.1</st>* <st c="15866">所示，两个可能结果的概率之和等于
    1\。</st> <st c="15936">这一点适用于任何概率分布。</st> <st c="15983">所有可能结果的概率总和始终为 1\。</st>
    <st c="16051">这是因为概率之和表示得到任何结果的概率，而我们完全确定会得到某个结果。</st> <st c="16209">如果一个概率分布有结果</st>
    <st c="16252">x</st> <st c="16253">及其关联的概率</st> <st c="16283">p</st><st c="16284">(</st><st
    c="16285">x</st><st c="16286">)</st><st c="16287">，我们可以将此条件表示为：</st>
- en: <st c="16324">∑</st><st c="16326">x</st><st c="16327">p</st><st c="16328">(</st><st
    c="16329">x</st><st c="16330">)</st> <st c="16331">=</st> <st c="16332">1</st>
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16324">∑</st><st c="16326">x</st><st c="16327">p</st><st c="16328">(</st><st
    c="16329">x</st><st c="16330">)</st> <st c="16331">=</st> <st c="16332">1</st>
- en: <st c="16333">Eq.</st> <st c="16337">3</st>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16333">公式</st> <st c="16337">3</st>
- en: <st c="16338">Some types of probability distributions are so commonly used that
    we i) give them a name so that we can conveniently refer to them using shorthand
    rather than having to list all the outcomes and probabilities and ii) because
    we want to study them in depth and share our findings with other scientists who
    may also be working with the same distribution.</st> <st c="16691">Giving something
    a name facilitates easier communication about</st> <st c="16754">that thing.</st>
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16338">某些类型的概率分布使用得非常普遍，以至于我们 i) 给它们起一个名字，以便我们可以方便地使用简写来引用它们，而不必列出所有的结果和概率，并且
    ii) 我们希望深入研究它们并与其他可能也在研究相同分布的科学家分享我们的发现。</st> <st c="16691">给某物命名有助于更方便地沟通</st>
    <st c="16754">关于该事物的讨论。</st>
- en: <st c="16765">The probability distribution</st> <st c="16795">where we have
    just two possible outcomes is called the</st> **<st c="16850">Bernoulli distribution</st>**
    <st c="16872">(named after Jacob Bernoulli from the famous Bernoulli dynasty of
    Swiss mathematicians).</st> <st c="16962">Without loss of generality, we call
    those outcomes 1 and 0 because the choice of what labels we map or associate to
    the 1 and 0 outcomes is a matter of individual choice, and so doesn’t affect the
    mathematical properties of the Bernoulli distribution.</st> <st c="17214">The
    two outcomes are also sometimes called “success” and “failure,” reflecting the
    fact that one of the outcomes may be more beneficial or preferrable.</st> <st
    c="17366">For the Bernoulli distribution, we also only need to know the probability
    associated with the 1 (or success) outcome.</st> <st c="17484">Let’s denote that
    probability by</st> <st c="17517">p</st><st c="17518">. The fact that the probabilities
    of all possible outcomes must sum to 1 means that the probability of the 0 (or
    failure) outcome is</st> <st c="17651">1</st> <st c="17652">−</st> <st c="17653">p</st><st
    c="17654">. For the tea/coffee example, because the probability of me choosing
    a tea drink was 0.4, then the probability of me choosing coffee was automatically
    0.6\.</st> <st c="17810">So, a Bernoulli distribution is entirely specified once
    we know the value of</st> <st c="17887">p</st><st c="17888">, and so we write
    a Bernoulli distribution using a shorthand notation as</st> <st c="17961">Bernoulli</st><st
    c="17970">(</st><st c="17972">p</st><st c="17973">)</st><st c="17974">. If I see
    the notation</st> <st c="17998">Bernoulli</st><st c="18007">(</st><st c="18009">p</st><st
    c="18010">)</st><st c="18011">, I know we are talking about a probability distribution
    with two possible outcomes, 1 and 0, with the probability of 1 being</st> <st
    c="18137">p</st> <st c="18138">and the probability of 0 being</st> <st c="18170">1</st>
    <st c="18171">−</st> <st c="18172">p</st><st c="18173">.</st>
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16765">概率分布</st> <st c="16795">当我们只有两个可能的结果时，这种分布叫做</st> **<st c="16850">伯努利分布</st>**
    <st c="16872">(以瑞士数学家伯努利家族的雅各布·伯努利命名)。</st> <st c="16962">不失一般性，我们将这些结果称为 1 和
    0，因为我们对 1 和 0 结果所映射或关联的标签选择是个人的选择，因此不会影响伯努利分布的数学属性。</st> <st c="17214">这两个结果有时也称为“成功”和“失败”，反映了其中一个结果可能更有利或更可取。</st>
    <st c="17366">对于伯努利分布，我们只需要知道与 1（或成功）结果相关的概率。</st> <st c="17484">我们用</st> <st
    c="17517">p</st><st c="17518">表示这个概率。由于所有可能结果的概率之和必须为 1，这意味着 0（或失败）结果的概率为</st>
    <st c="17651">1</st> <st c="17652">−</st> <st c="17653">p</st><st c="17654">。以茶/咖啡为例，由于我选择茶的概率是
    0.4，那么选择咖啡的概率自然是 0.6。</st> <st c="17810">因此，一旦知道</st> <st c="17887">p</st><st
    c="17888">的值，伯努利分布就完全确定了，所以我们用简写表示伯努利分布为</st> <st c="17961">Bernoulli</st><st
    c="17970">(</st><st c="17972">p</st><st c="17973">)</st><st c="17974">。如果我看到符号</st>
    <st c="17998">Bernoulli</st><st c="18007">(</st><st c="18009">p</st><st c="18010">)</st><st
    c="18011">，我知道我们在讨论一个有两个可能结果（1 和 0）的概率分布，其中 1 的概率是</st> <st c="18137">p</st> <st
    c="18138">，0 的概率是</st> <st c="18170">1</st> <st c="18171">−</st> <st c="18172">p</st><st
    c="18173">。</st>
- en: <st c="18174">Now, when we have a random variable</st> <st c="18211">X</st>
    <st c="18212">that follows a</st> <st c="18227">Bernoulli distribution, we write</st>
    <st c="18261">the following:</st>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18174">现在，当我们有一个遵循</st> <st c="18211">伯努利分布</st>的随机变量</st> <st c="18212">X</st>
    <st c="18227">时，我们写出如下公式：</st>
- en: <st c="18275">X</st> <st c="18277">∼</st> <st c="18278">Bernoulli</st><st c="18287">(</st><st
    c="18289">p</st><st c="18290">)</st>
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18275">X</st> <st c="18277">∼</st> <st c="18278">伯努利</st><st c="18287">(</st><st
    c="18289">p</st><st c="18290">)</st>
- en: <st c="18291">Eq.</st> <st c="18295">4</st>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18291">公式</st> <st c="18295">4</st>
- en: <st c="18296">Let’s unpack</st> <st c="18309">that notation.</st> <st c="18324">Firstly,
    the use of</st> <st c="18344">~</st> <st c="18345">(the tilde symbol) and the
    presence of a named distribution on the right-hand side of</st> *<st c="18432">Eq.</st>
    <st c="18436">4</st>* <st c="18437">tells us that</st> <st c="18452">X</st> <st
    c="18453">is a random variable.</st> <st c="18476">We have used a capital letter
    for the random variable.</st> <st c="18531">This is common practice, to distinguish
    it from an ordinary variable that we would more commonly represent by a symbol
    such as</st> <st c="18658">x</st><st c="18659">. However, it is not unusual to
    see lowercase symbols used to represent random variables as well, and so the main
    giveaway that something is a random variable is the presence of the tilde symbol
    (</st><st c="18855">~</st><st c="18857">).</st> <st c="18860">The use of</st>
    <st c="18871">~</st> <st c="18872">means that the random variable on the left-hand
    side of</st> *<st c="18929">Eq.</st> <st c="18933">4</st>* <st c="18934">follows
    the probability distribution on the right-hand side.</st> <st c="18996">Overall,
    we read</st> *<st c="19013">Eq.</st> <st c="19017">4</st>* <st c="19018">as meaning</st>
    <st c="19030">X</st> <st c="19031">is distributed as</st> <st c="19050">Bernoulli</st><st
    c="19059">(</st><st c="19061">p</st><st c="19062">)</st><st c="19063">. This immediately
    tells us that</st> <st c="19096">X</st> <st c="19097">has two possible outcomes,
    1 and 0, with associated probabilities of</st> <st c="19167">p</st><st c="19168">,</st>
    <st c="19169">1</st> <st c="19170">−</st> <st c="19171">p</st><st c="19172">.
    What the outcomes 1 and 0 map to in terms of more useful human interpretable labels
    is usually explained elsewhere in the documentation that had the equation</st>
    <st c="19332">in it.</st>
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18296">让我们来解析</st> <st c="18309">这个符号。</st> <st c="18324">首先，符号</st>
    <st c="18344">~</st>（即波浪线符号）和右侧出现的命名分布表示</st> *<st c="18432">公式</st> <st c="18436">4</st>*
    <st c="18437">告诉我们</st> <st c="18452">X</st> <st c="18453">是一个随机变量。</st> <st c="18476">我们使用了大写字母来表示随机变量。</st>
    <st c="18531">这是常见做法，用以与我们通常用符号如</st> <st c="18658">x</st><st c="18659">表示的普通变量区分开来。</st>
    然而，也不罕见看到小写符号用于表示随机变量，因此，区分一个是随机变量的主要标志就是波浪线符号（</st><st c="18855">~</st><st c="18857">）。</st>
    <st c="18860">使用</st> <st c="18871">~</st> <st c="18872">意味着左侧的随机变量</st> *<st
    c="18929">公式</st> <st c="18933">4</st>* <st c="18934">遵循右侧的概率分布。</st> <st c="18996">总体上，我们可以理解</st>
    *<st c="19013">公式</st> <st c="19017">4</st>* <st c="19018">的含义是</st> <st c="19030">X</st>
    <st c="19031">服从</st> <st c="19050">伯努利</st><st c="19059">(</st><st c="19061">p</st><st
    c="19062">)</st><st c="19063">分布。</st> <st c="19096">这立即告诉我们，</st> <st c="19097">X</st>
    <st c="19097">有两个可能的结果，1 和 0，且对应的概率分别是</st> <st c="19167">p</st><st c="19168">和</st>
    <st c="19169">1</st> <st c="19170">−</st> <st c="19171">p</st><st c="19172">。</st>
    结果 1 和 0 在更具可解释性的人类标签上通常会在包含该方程的文档中做进一步说明。</st>
- en: <st c="19338">For my morning drink example, and using the encoding 1=Coffee,
    0=Tea, I can write</st> <st c="19421">the following,</st>
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="19338">以我早晨饮品的例子，采用编码 1=咖啡，0=茶，我可以写出</st> <st c="19421">如下内容，</st>
- en: <st c="19435">Drink</st> <st c="19441">~</st> <st c="19443">Bernoulli</st><st
    c="19452">(</st><st c="19454">0.6</st><st c="19457">)</st>
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="19443">饮品</st> ~ <st c="19443">伯努利</st><st c="19452">(</st><st c="19454">0.6</st><st
    c="19457">)</st>
- en: <st c="19459">Eq.</st> <st c="19463">5</st>
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="19459">公式</st> <st c="19463">5</st>
- en: <st c="19464">Having learned about how random variables and their associated
    probability distributions are natural math concepts to describe the randomness
    we find in data, we are now going to learn how to quantify and summarize probability
    distributions in a more</st> <st c="19715">intuitive way.</st>
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="19464">在了解了随机变量及其相关概率分布是描述数据中随机性的自然数学概念后，我们现在将学习如何以更</st> <st c="19715">直观的方式</st>
    <st c="19435">总结</st> <st c="19441">概率分布</st>。
- en: <st c="19729">Summarizing probability distributions</st>
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="19729">总结概率分布</st>
- en: <st c="19767">The probability distribution</st> <st c="19797">associated with
    a random variable tells us everything we need to know about that random variable.</st>
    <st c="19895">It tells us what the probability of any particular outcome is.</st>
    <st c="19958">Imagine we wanted to communicate information about the random variable
    to a colleague.</st> <st c="20045">Obviously, the most complete way would be to
    communicate all the individual probabilities for all the individual outcomes.</st>
    <st c="20168">If we have a large or infinite number of outcomes, that is a lot
    of probabilities we must communicate to our colleague.</st> <st c="20288">We could
    send our colleague the bar chart showing the probability distribution.</st> <st
    c="20368">However, while that bar chart is a great visual way of communicating</st>
    <st c="20436">the distribution, it doesn’t easily communicate all the numerical
    values of the probabilities to our colleague.</st> <st c="20549">But what if our
    colleague doesn’t want all the probabilities?</st> <st c="20611">What if they
    just want to get a quantitative feel for what the distribution is about?</st>
    <st c="20697">Is there a single number or a couple of numbers that conveniently
    summarize most of the information contained in the probability distribution?</st>
    <st c="20840">The answer is yes, and we will now introduce the most</st> <st c="20894">important
    ones.</st>
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="19767">与随机变量相关的</st> <st c="19797">概率分布告诉我们所有关于该随机变量的信息。</st> <st c="19895">它告诉我们每个特定结果的概率。</st>
    <st c="19958">假设我们想要向同事传达关于这个随机变量的信息。</st> <st c="20045">显然，最完整的方式是传达所有单个结果的每个个体概率。</st>
    <st c="20168">如果我们有大量或无限个结果，那么我们必须传递给同事的就是大量的概率。</st> <st c="20288">我们可以把显示概率分布的条形图发给同事。</st>
    <st c="20368">然而，虽然这个条形图是传达分布的很好的视觉方式，</st> <st c="20436">但它并不能轻松地将所有概率的数值传达给我们的同事。</st>
    <st c="20549">但是，如果我们的同事不需要所有的概率呢？</st> <st c="20611">如果他们只想获得关于分布的定量了解呢？</st>
    <st c="20697">有没有一个或几个数字可以方便地总结概率分布中大部分的信息呢？</st> <st c="20840">答案是有的，现在我们将介绍最重要的那些。</st>
- en: <st c="20909">The mean of a distribution</st>
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="20909">分布的均值</st>
- en: <st c="20936">The</st> **<st c="20941">mean</st>** <st c="20945">of a</st> <st
    c="20950">distribution is a single number that we calculate from the full probability
    distribution.</st> <st c="21041">The mean is used to give us an idea about the
    average value of the distribution; that is, the typical value we would expect
    to see if we drew lots of values from the same distribution.</st> <st c="21226">However,
    be aware that the mean does not always do a good job of this.</st> <st c="21297">We
    will see why later.</st> <st c="21320">For now, let’s see how the mean</st> <st
    c="21352">is calculated.</st>
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="20936">一个</st> **<st c="20941">均值</st>** <st c="20945">是从完整的概率分布中计算得到的一个数字。</st>
    <st c="21041">均值用于给我们提供一个关于分布的平均值的概念；也就是说，如果我们从同一分布中抽取大量值，通常我们会期待看到的值。</st> <st
    c="21226">然而，请注意，均值并不总是很好地完成这个任务。</st> <st c="21297">我们稍后会看到原因。</st> <st c="21320">现在，先来看一下如何计算均值。</st>
- en: <st c="21366">The mean of a probability distribution that has outcomes</st>
    <st c="21424">x</st> <st c="21425">and associated probabilities</st> <st c="21455">p</st><st
    c="21456">(</st><st c="21457">x</st><st c="21458">)</st> <st c="21459">is defined</st>
    <st c="21471">as follows:</st>
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21366">一个具有结果</st> <st c="21424">x</st> <st c="21425">和相关概率</st> <st
    c="21455">p</st><st c="21456">(</st><st c="21457">x</st><st c="21458">)</st> <st
    c="21459">的概率分布的均值</st> <st c="21471">定义如下：</st>
- en: <st c="21482">Mean</st> <st c="21487">=</st> <st c="21489">∑</st><st c="21490">x</st><st
    c="21491">x</st><st c="21492">p</st><st c="21493">(</st><st c="21494">x</st><st
    c="21495">)</st>
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21482">均值</st> <st c="21487">=</st> <st c="21489">∑</st><st c="21490">x</st><st
    c="21491">x</st><st c="21492">p</st><st c="21493">(</st><st c="21494">x</st><st
    c="21495">)</st>
- en: <st c="21496">Eq.</st> <st c="21500">6</st>
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21496">公式</st> <st c="21500">6</st>
- en: <st c="21501">Here, the summation is over all the possible outcomes.</st> <st
    c="21556">Let’s make that a bit more concrete.</st> <st c="21593">Imagine I have
    the probability distribution shown in</st> *<st c="21646">F</st><st c="21647">igure
    2</st>**<st c="21654">.4</st>*<st c="21656">:</st>
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21501">在这里，求和是对所有可能的结果进行的。</st> <st c="21556">让我们更具体一些。</st> <st c="21593">假设我有下面所示的概率分布</st>
    *<st c="21646">图</st><st c="21647">2</st>**<st c="21654">.4</st>*<st c="21656">：</st>
- en: '![Figure 2.4: Example probability distribution](img/B19496_02_05.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 2.4: Example probability distribution](img/B19496_02_05.jpg)'
- en: '<st c="21693">Figure 2.4: Example probability distribution</st>'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21694">图 2.4：示例概率分布</st>
- en: <st c="21737">The</st> <st c="21742">outcomes are the integer values 1, 2, …,
    10 (perhaps resulting from throwing a strangely shaped 10-sided die).</st> <st
    c="21853">The mean is then the sum of each of those integer values multiplied
    by the corresponding probability shown in</st> *<st c="21963">Figure 2</st>**<st
    c="21971">.4</st>*<st c="21973">. The mean value turns out to be 5.5 and is shown
    by the vertical dashed line in</st> *<st c="22054">Figure 2</st>**<st c="22062">.4</st>*<st
    c="22064">. Is the mean value useful to us?</st> <st c="22098">Yes – in this case,
    it is very useful.</st> <st c="22137">You can see from the shape of the probability
    distribution in</st> *<st c="22199">Figure 2</st>**<st c="22207">.4</st>* <st
    c="22209">that the most probable outcomes are 5 and 6, with other outcomes having
    a lower probability and hence occurring less frequently.</st> <st c="22339">When
    drawing a single value from this distribution, we would expect to get 5 or 6 a
    lot of the time.</st> <st c="22440">For this reason, the mean is what’s called
    an</st> **<st c="22486">expectation value</st>** <st c="22503">or</st> **<st c="22507">expected
    value</st>**<st c="22521">. The mean of the random variable</st> <st c="22555">X</st>
    <st c="22556">is called the</st> <st c="22571">expectation value of</st> <st c="22592">X</st>
    <st c="22593">or the expected value of</st> <st c="22619">X</st><st c="22620">.
    We have a special symbol for an expectation value.</st> <st c="22673">We use the
    symbol</st> <st c="22691">𝔼</st><st c="22693">(</st><st c="22695">X</st><st c="22696">)</st>
    <st c="22697">for the expectation value of</st> <st c="22727">X</st><st c="22728">.
    So,</st> <st c="22734">𝔼</st><st c="22736">(</st><st c="22738">X</st><st c="22739">)</st>
    <st c="22740">means the same as calculate the mean of</st> <st c="22781">X</st><st
    c="22782">. That is shown in the</st> <st c="22805">following formula:</st>
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21738">结果是整数值 1, 2, …, 10（可能是由一个奇形怪状的十面体骰子投掷而来）。</st> <st c="21854">均值是这些整数值乘以相应概率的总和，如</st>
    *<st c="21964">图 2</st>**<st c="21972">.4</st>*<st c="21974">。均值为 5.5，由</st> *<st
    c="22055">图 2</st>**<st c="22063">.4</st>*<st c="22065">上的垂直虚线表示。</st> <st c="22099">均值对我们有用吗？</st>
    <st c="22138">是的，在这种情况下非常有用。</st> <st c="22187">从</st> *<st c="22200">图 2</st>**<st
    c="22208">.4</st>* <st c="22210">中概率分布的形状可以看出，5 和 6 是最可能的结果，而其他结果的概率较低，因此出现频率较低。</st>
    <st c="22338">从这个分布中抽取单个值时，我们预期大多数情况下会得到 5 或 6。</st> <st c="22441">因此，均值被称为</st>
    **<st c="22487">期望值</st>** <st c="22504">或</st> **<st c="22508">期望值</st>**<st
    c="22522">。随机变量</st> <st c="22556">X</st> <st c="22557">的均值称为</st> <st c="22572">X</st>
    <st c="22573">的期望值或</st> <st c="22600">X</st><st c="22601">的期望值。</st> <st c="22645">我们有一个特殊的符号表示期望值。</st>
    <st c="22674">我们使用符号</st> <st c="22692">𝔼</st><st c="22694">(</st><st c="22696">X</st><st
    c="22697">)</st> <st c="22698">表示</st> <st c="22728">X</st><st c="22729">的期望值。</st>
    <st c="22735">因此，</st> <st c="22782">𝔼</st><st c="22784">(</st><st c="22786">X</st><st
    c="22787">)</st> <st c="22788">意味着计算</st> <st c="22806">X</st><st c="22807">的均值。这如下公式所示：</st>
- en: <st c="22823">𝔼</st><st c="22826">(</st><st c="22828">X</st><st c="22829">)</st>
    <st c="22830">=</st> <st c="22831">∑</st><st c="22832">x</st><st c="22833">x</st>
    <st c="22834">p</st><st c="22835">(</st><st c="22836">x</st><st c="22837">)</st>
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="22824">𝔼</st><st c="22827">(</st><st c="22829">X</st><st c="22830">)</st>
    <st c="22831">=</st> <st c="22832">∑</st><st c="22833">x</st><st c="22834">x</st>
    <st c="22835">p</st><st c="22836">(</st><st c="22837">x</st><st c="22838">)</st>
- en: <st c="22838">Eq.</st> <st c="22842">7</st>
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="22838">方程</st> <st c="22843">7</st>
- en: <st c="22843">From the notation</st> <st c="22861">𝔼</st><st c="22863">(</st><st
    c="22865">X</st><st c="22866">)</st><st c="22867">, you’ll see that we sort of
    consider</st> <st c="22905">𝔼</st> <st c="22907">to be like a function, in that
    it is applied to the thing inside the brackets.</st> <st c="22987">It is actually
    an operator, but we won’t go into that distinction here.</st> <st c="23059">You
    can think of</st> <st c="23076">𝔼</st> <st c="23078">as a function that gets applied
    to random variables.</st> <st c="23132">That means we can also apply</st> <st
    c="23161">𝔼</st> <st c="23163">in a composite way.</st> <st c="23184">Say we wanted
    to calculate the mean value of taking the exponential of any outcome</st> <st
    c="23267">x</st> <st c="23268">of the random variable</st> <st c="23292">X</st><st
    c="23293">. Taking the exponential of a random variable is just another random
    variable – remember what we said about anything derived or computed from something
    random being also</st> <st c="23463">random.</st> <st c="23471">We’ll denote this
    newly derived random variable as</st> <st c="23522">e</st><st c="23523">X</st>
    <st c="23524">to signify that it is a random variable obtained from taking the
    exponential of the original random variable</st> <st c="23634">X</st><st c="23635">.
    The expectation value of this newly derived random variable</st> <st c="23697">e</st><st
    c="23698">X</st> <st c="23699">is calculated</st> <st c="23714">as follows:</st>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="22843">从符号</st> <st c="22861">𝔼</st><st c="22863">(</st><st c="22865">X</st><st
    c="22866">)</st><st c="22867">中，你会看到我们将</st> <st c="22905">𝔼</st> <st c="22907">看作一个类似于函数的东西，因为它应用于括号内的内容。</st>
    <st c="22987">它实际上是一个运算符，但我们在这里不讨论这个区别。</st> <st c="23059">你可以把</st> <st c="23076">𝔼</st>
    <st c="23078">看作是一个作用于随机变量的函数。</st> <st c="23132">这意味着我们也可以以复合的方式应用</st> <st c="23161">𝔼</st>
    <st c="23163">。</st> <st c="23184">假设我们想计算对任何随机变量</st> <st c="23267">x</st> <st
    c="23268">的指数进行运算后的均值</st> <st c="23292">X</st><st c="23293">。对随机变量取指数值只是得到另一个随机变量——记住我们所说的，从随机中导出或计算的任何内容也都是</st>
    <st c="23463">随机的。</st> <st c="23471">我们将这个新推导的随机变量表示为</st> <st c="23522">e</st><st
    c="23523">X</st> <st c="23524">，表示它是通过对原始随机变量</st> <st c="23634">X</st><st c="23635">取指数得到的一个随机变量。</st>
    <st c="23634">这个新推导的随机变量</st> <st c="23697">e</st><st c="23698">X</st> <st c="23699">的期望值</st>
    <st c="23714">计算如下：</st>
- en: <st c="23725">𝔼</st><st c="23728">(</st><st c="23730">e</st><st c="23731">X</st><st
    c="23732">)</st> <st c="23733">=</st> <st c="23734">∑</st><st c="23735">x</st><st
    c="23736">e</st><st c="23737">x</st> <st c="23738">p</st><st c="23739">(</st><st
    c="23740">x</st><st c="23741">)</st>
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="23725">𝔼</st><st c="23728">(</st><st c="23730">e</st><st c="23731">X</st><st
    c="23732">)</st> <st c="23733">=</st> <st c="23734">∑</st><st c="23735">x</st><st
    c="23736">e</st><st c="23737">x</st> <st c="23738">p</st><st c="23739">(</st><st
    c="23740">x</st><st c="23741">)</st>
- en: <st c="23742">Eq.</st> <st c="23746">8</st>
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="23742">方程</st> <st c="23746">8</st>
- en: <st c="23747">To calculate the expectation value of this newly derived random
    variable, we have simply applied the same function (the exponential function)
    to the outcome values</st> <st c="23911">x</st><st c="23912">. As you might guess,
    for a general function</st> <st c="23957">f</st> <st c="23958">we calculate the
    expectation value of</st> <st c="23997">f</st><st c="23998">(</st><st c="23999">X</st><st
    c="24000">)</st> <st c="24001">by calculating</st> <st c="24017">the following:</st>
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="23747">为了计算这个新推导的随机变量的期望值，我们仅仅对结果值</st> <st c="23911">x</st><st c="23912">应用了相同的函数（指数函数）</st>。如你所猜测，对于一般的函数</st>
    <st c="23957">f</st> <st c="23958">我们通过计算</st> <st c="23997">f</st><st c="23998">(</st><st
    c="23999">X</st><st c="24000">)</st> <st c="24001">的期望值来进行计算</st> <st c="24017">，如下所示：</st>
- en: <st c="24031">𝔼</st><st c="24034">(</st><st c="24036">f</st><st c="24037">(</st><st
    c="24038">X</st><st c="24039">)</st><st c="24040">)</st> <st c="24041">=</st>
    <st c="24042">∑</st><st c="24043">x</st><st c="24044">f</st><st c="24045">(</st><st
    c="24046">x</st><st c="24047">)</st><st c="24048">p</st><st c="24049">(</st><st
    c="24050">x</st><st c="24051">)</st>
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24031">𝔼</st><st c="24034">(</st><st c="24036">f</st><st c="24037">(</st><st
    c="24038">X</st><st c="24039">)</st><st c="24040">)</st> <st c="24041">=</st>
    <st c="24042">∑</st><st c="24043">x</st><st c="24044">f</st><st c="24045">(</st><st
    c="24046">x</st><st c="24047">)</st><st c="24048">p</st><st c="24049">(</st><st
    c="24050">x</st><st c="24051">)</st>
- en: <st c="24052">Eq.</st> <st c="24056">9</st>
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24052">方程</st> <st c="24056">9</st>
- en: <st c="24057">The variance of a distribution</st>
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="24057">分布的方差</st>
- en: <st c="24087">Looking</st> <st c="24096">at</st> *<st c="24099">Figure 2</st>**<st
    c="24107">.4</st>*<st c="24109">, we would think from the shape of the distribution
    that it was obvious that the mean of</st> <st c="24198">X</st> <st c="24199">was
    representative of the typical value we would get when we draw a value from the
    distribution, because of how tightly concentrated the distribution is around its
    highest probability outcomes at</st> <st c="24396">x</st> <st c="24397">=</st>
    <st c="24398">5</st> <st c="24399">and</st> <st c="24404">x</st> <st c="24405">=</st>
    <st c="24406">6</st><st c="24407">. What would happen if we had a distribution
    that was more widely spread?</st> <st c="24481">Take a look at</st> *<st c="24495">Figure
    2</st>**<st c="24504">.5</st>*<st c="24506">:</st>
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24087">观察</st> <st c="24096">*图 2*</st>**<st c="24107">.4</st>**<st c="24109">，从分布的形状来看，我们会认为均值</st>
    <st c="24198">X</st> <st c="24199">代表了从该分布中抽取一个值时的典型值，因为分布在其最高概率结果周围非常集中，特别是在</st>
    <st c="24396">x</st> <st c="24397">=</st> <st c="24398">5</st> <st c="24399">和</st>
    <st c="24404">x</st> <st c="24405">=</st> <st c="24406">6</st><st c="24407">。如果我们有一个分布更加广泛扩展的情况，会怎样呢？</st>
    <st c="24481">请看</st> *<st c="24495">图 2</st>**<st c="24504">.5</st>*<st c="24506">：</st>
- en: '![Figure 2.5: Another example probability distribution](img/B19496_02_06.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5：另一个概率分布示例](img/B19496_02_06.jpg)'
- en: '<st c="24544">Figure 2.5: Another example probability distribution</st>'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24544">图 2.5：另一个概率分布示例</st>
- en: <st c="24596">The mean</st> <st c="24606">of this distribution is also 5.5,
    but clearly, values that are very different from 5.5 are now more likely compared
    to when we were drawing values from the distribution in</st> *<st c="24778">Figure
    2</st>**<st c="24786">.4</st>*<st c="24788">. So, for</st> *<st c="24798">Figure
    2</st>**<st c="24806">.5</st>*<st c="24808">, the mean of</st> <st c="24822">X</st>
    <st c="24823">is the average value we would get when we draw lots of values from
    the distribution in</st> *<st c="24911">Figure 2</st>**<st c="24919">.5</st>*<st
    c="24921">, but as a single number, the mean value of 5.5 is not typical as there
    is a lot spread of values around 5.5\.</st> <st c="25031">Clearly, knowing</st>
    **<st c="25048">only</st>** <st c="25052">the mean isn’t a good way of summarizing
    the distribution in</st> *<st c="25114">Figure 2</st>**<st c="25122">.5</st>*<st
    c="25124">. Whether that spread is small or large is important to know.</st> <st
    c="25186">How can we quantify</st> <st c="25206">that spread?</st>
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24596">这个分布的均值</st> <st c="24606">也是 5.5，但显然，和 5.5 相差较远的值现在比我们从</st>
    *<st c="24778">图 2</st>**<st c="24786">.4</st>*<st c="24788">中抽取值时更有可能出现。因此，对于</st>
    *<st c="24798">图 2</st>**<st c="24806">.5</st>*<st c="24808">，均值</st> <st c="24822">X</st>
    <st c="24823">是我们从</st> *<st c="24911">图 2</st>**<st c="24919">.5</st>*<st c="24921">中抽取大量值时得到的平均值，但作为一个单一的数值，5.5
    的均值并不典型，因为在 5.5 周围有很多分布。</st> <st c="25031">显然，单知道均值并不是总结</st> *<st c="25114">图
    2</st>**<st c="25122">.5</st>*<st c="25124">分布的好方法。了解这个分布的扩展程度——无论是小还是大，都是非常重要的。</st>
    <st c="25186">我们如何量化</st> <st c="25206">这种扩展呢？</st>
- en: <st c="25218">Just as the mean quantifies the average value drawn from the distribution,
    we can also calculate the average difference from that mean value.</st> <st c="25361">If
    the mean of a distribution is</st> <st c="25394">μ</st> <st c="25395">and we look
    at a specific outcome value</st> <st c="25436">x</st><st c="25437">, then the
    deviation of the outcome from the mean is</st> <st c="25490">x</st> <st c="25491">−</st>
    <st c="25492">μ</st><st c="25493">. We could then just take the average of this
    deviation over all possible outcomes.</st> <st c="25577">This would give us</st>
    <st c="25596">the following:</st>
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25218">就像均值量化从分布中抽取的平均值一样，我们还可以计算与该均值的平均差异。</st> <st c="25361">如果一个分布的均值是</st>
    <st c="25394">μ</st> <st c="25395">，我们查看某个具体的结果值</st> <st c="25436">x</st><st
    c="25437">，那么该结果与均值的偏差为</st> <st c="25490">x</st> <st c="25491">−</st> <st c="25492">μ</st><st
    c="25493">。然后，我们可以将所有可能结果的偏差取平均。</st> <st c="25577">这将给我们</st> <st c="25596">以下结果：</st>
- en: <st c="25610">∑</st><st c="25612">x</st><st c="25613">(</st><st c="25614">x</st>
    <st c="25615">−</st> <st c="25616">μ</st><st c="25617">)</st><st c="25618">p</st><st
    c="25619">(</st><st c="25620">x</st><st c="25621">)</st>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25610">∑</st><st c="25612">x</st><st c="25613">(</st><st c="25614">x</st>
    <st c="25615">−</st> <st c="25616">μ</st><st c="25617">)</st><st c="25618">p</st><st
    c="25619">(</st><st c="25620">x</st><st c="25621">)</st>
- en: <st c="25622">Eq.</st> <st c="25626">10</st>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25622">公式</st> <st c="25626">10</st>
- en: <st c="25628">A quick bit of algebra will tell you that this is always zero,
    so it isn’t a very good way of measuring the spread of a distribution.</st> <st
    c="25763">The reason for this is that for small values of</st> <st c="25811">x</st><st
    c="25812">, the deviation</st> <st c="25828">x</st> <st c="25829">−</st> <st c="25830">μ</st>
    <st c="25831">is negative, while for large values of</st> <st c="25871">x</st>
    <st c="25872">the deviation is positive, and overall, the positive and negative
    values exactly cancel each other out.</st> <st c="25977">We can stop this cancellation
    by using the squared deviation</st> <st c="26038">(</st><st c="26039">x</st><st
    c="26040">−</st> <st c="26041">μ</st><st c="26042">)</st><st c="26043">2</st>
    <st c="26044">instead and calculate the average of this squared deviation because
    the squared deviation is always positive or zero.</st> <st c="26163">This is calculated
    using the</st> <st c="26192">following formula:</st>
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25628">一些简单的代数可以告诉你，这总是零，因此它不是一种很好的测量分布扩展的方法。</st> <st c="25763">原因在于，对于小的</st>
    <st c="25811">x</st><st c="25812">，偏差</st> <st c="25828">x</st> <st c="25829">−</st>
    <st c="25830">μ</st> <st c="25831">是负数，而对于大的</st> <st c="25871">x</st> <st c="25872">偏差是正数，整体上，正值和负值恰好相互抵消。</st>
    <st c="25977">我们可以通过使用平方偏差来停止这种抵消</st> <st c="26038">(</st><st c="26039">x</st><st
    c="26040">−</st> <st c="26041">μ</st><st c="26042">)</st><st c="26043">2</st>
    <st c="26044">代替，并计算这个平方偏差的平均值，因为平方偏差始终是正数或零。</st> <st c="26163">这是通过以下公式计算的：</st>
- en: <st c="26210">Variance</st> <st c="26219">=</st> <st c="26221">∑</st><st c="26222">x</st><st
    c="26223">(</st><st c="26224">x</st><st c="26225">−</st> <st c="26226">μ</st><st
    c="26227">)</st><st c="26228">2</st> <st c="26229">p</st><st c="26230">(</st><st
    c="26231">x</st><st c="26232">)</st>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26210">方差</st> <st c="26219">=</st> <st c="26221">∑</st><st c="26222">x</st><st
    c="26223">(</st><st c="26224">x</st><st c="26225">−</st> <st c="26226">μ</st><st
    c="26227">)</st><st c="26228">2</st> <st c="26229">p</st><st c="26230">(</st><st
    c="26231">x</st><st c="26232">)</st>
- en: <st c="26233">Eq.</st> <st c="26237">11</st>
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26233">公式</st> <st c="26237">11</st>
- en: <st c="26239">We</st> <st c="26243">call this average squared deviation the</st>
    **<st c="26283">variance</st>** <st c="26291">of the distribution.</st> <st c="26313">Now,
    you’re probably asking how this gives us a measure of the spread of a distribution
    if we have calculated the average squared deviation.</st> <st c="26454">The answer
    is it doesn’t.</st> <st c="26480">To get a measure of spread, we take the inverse
    operation at the end; that is, we take the square root of the variance.</st> <st
    c="26600">The square root of the variance is called</st> <st c="26641">the</st>
    **<st c="26646">standard deviation</st>**<st c="26664">. So, putting that together,
    we have</st> <st c="26701">the following:</st>
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26239">我们</st> <st c="26243">将这个平均平方偏差称为</st> **<st c="26283">方差</st>**
    <st c="26291">分布的方差。</st> <st c="26313">现在，你可能在问，如果我们已经计算了平均平方偏差，这如何给我们提供分布扩展的度量。</st>
    <st c="26454">答案是，它并没有。</st> <st c="26480">为了得到扩展度量，我们在最后进行逆操作；也就是说，我们取方差的平方根。</st>
    <st c="26600">方差的平方根称为</st> <st c="26641">标准差</st> **<st c="26646">标准差</st>**<st
    c="26664">。所以，将这些结合起来，我们得到</st> <st c="26701">以下内容：</st>
- en: <st c="26715">Standard Deviation =</st> <st c="26737">√</st><st c="26738">_</st><st
    c="26739">Variance</st> <st c="26747">=</st> <st c="26749">[</st><st c="26750">∑</st><st
    c="26751">x</st><st c="26752">(</st><st c="26753">x</st><st c="26754">−</st> <st
    c="26755">μ</st><st c="26756">)</st><st c="26757">2</st> <st c="26758">p</st><st
    c="26759">(</st><st c="26760">x</st><st c="26761">)</st><st c="26762">]</st><st
    c="26763">1</st><st c="26764">_</st><st c="26765">2</st>
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26715">标准差 =</st> <st c="26737">√</st><st c="26738">_</st><st c="26739">方差</st>
    <st c="26747">=</st> <st c="26749">[</st><st c="26750">∑</st><st c="26751">x</st><st
    c="26752">(</st><st c="26753">x</st><st c="26754">−</st> <st c="26755">μ</st><st
    c="26756">)</st><st c="26757">2</st> <st c="26758">p</st><st c="26759">(</st><st
    c="26760">x</st><st c="26761">)</st><st c="26762">]</st><st c="26763">1</st><st
    c="26764">_</st><st c="26765">2</st>
- en: <st c="26766">Eq.</st> <st c="26770">12</st>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26766">公式</st> <st c="26770">12</st>
- en: <st c="26772">In general, we have</st> <st c="26793">the following:</st>
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26772">一般来说，我们有</st> <st c="26793">以下内容：</st>
- en: <st c="26807">Variance =</st> <st c="26819">Standard</st> <st c="26828">Deviation</st><st
    c="26837">2</st>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26807">方差 =</st> <st c="26819">标准</st> <st c="26828">差异</st><st c="26837">2</st>
- en: <st c="26839">Eq.</st> <st c="26843">13</st>
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26839">公式</st> <st c="26843">13</st>
- en: <st c="26845">We use the symbol</st> <st c="26864">σ</st> <st c="26865">for
    the standard deviation, and so from the preceding equation, we can also use</st>
    <st c="26946">σ</st><st c="26947">2</st> <st c="26948">to denote the variance.</st>
    <st c="26973">Sometimes, you will also see</st> <st c="27002">Var</st> <st c="27005">used
    as shorthand for the variance.</st> <st c="27042">For example, we might write</st>
    <st c="27070">Var</st><st c="27073">(</st><st c="27075">X</st><st c="27076">)</st>
    <st c="27077">to indicate the variance of the random</st> <st c="27117">variable</st>
    <st c="27126">X</st><st c="27127">.</st>
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26845">我们用符号</st> <st c="26864">σ</st> <st c="26865">表示标准差，因此从前面的方程可以看出，我们也可以用</st>
    <st c="26946">σ</st><st c="26947">2</st> <st c="26948">表示方差。</st> <st c="26973">有时，你还会看到</st>
    <st c="27002">Var</st> <st c="27005">作为方差的简写。</st> <st c="27042">例如，我们可能会写作</st>
    <st c="27070">Var</st><st c="27073">(</st><st c="27075">X</st><st c="27076">)</st>
    <st c="27077">来表示随机变量</st> <st c="27117">X</st><st c="27126">的方差。</st>
- en: <st c="27128">What does the standard deviation tell us?</st> <st c="27171">Well,
    the clue is in the name.</st> <st c="27202">It is the standard, typical, or expected
    size of deviation from the mean that we should expect when we draw a number from
    the distribution.</st> <st c="27342">If we draw a number from the distribution,
    we should not be surprised if it differs from the mean by something comparable
    to the standard deviation; for example, by as much as</st> <st c="27518">1</st><st
    c="27519">σ</st> <st c="27520">or</st> <st c="27523">2</st><st c="27524">σ</st><st
    c="27525">.</st>
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27128">标准差告诉我们什么？</st> <st c="27171">嗯，线索就在名称中。</st> <st c="27202">它是我们从分布中抽取一个数字时，应该期望的与均值的偏差的标准、典型或预期的大小。</st>
    <st c="27342">如果我们从分布中抽取一个数字，不应该感到惊讶，若它与均值的偏差与标准差相当；例如，偏差为</st> <st c="27518">1</st><st
    c="27519">σ</st> <st c="27520">或</st> <st c="27523">2</st><st c="27524">σ</st><st
    c="27525">。</st>
- en: <st c="27526">We’ve said that the standard deviation of a distribution is the
    size of the typical deviation we should</st> **<st c="27631">expect</st>** <st
    c="27637">when drawing a number from the distribution.</st> <st c="27683">So,
    you might ask, can the standard deviation be written</st> <st c="27740">as an</st>
    **<st c="27746">expectation value</st>** <st c="27763">of some random variable?</st>
    <st c="27789">Not quite.</st> <st c="27800">But the variance can.</st> <st c="27822">If
    we look at</st> *<st c="27836">Eq.</st> <st c="27840">11</st>*<st c="27842">,
    we can see that it is a weighted average of the squared deviation.</st> <st c="27911">So,
    we can write the variance calculation in</st> *<st c="27956">Eq.</st> <st c="27960">11</st>*
    <st c="27962">as follo</st><st c="27971">ws:</st>
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27526">我们已经说过，分布的标准差是我们从分布中抽取一个数字时，应该期望的典型偏差的大小。</st> **<st c="27631">期望</st>**
    <st c="27637">从分布中抽取一个数字时。</st> <st c="27683">所以，你可能会问，标准差能否写成某个随机变量的</st> **<st
    c="27746">期望值</st>** <st c="27763">呢？</st> <st c="27789">不完全是。</st> <st c="27800">但方差可以。</st>
    <st c="27822">如果我们看看</st> *<st c="27836">公式</st> <st c="27840">11</st>*<st c="27842">，我们可以看到它是平方偏差的加权平均。</st>
    <st c="27911">因此，我们可以将方差计算写成</st> *<st c="27956">公式</st> <st c="27960">11</st>*
    <st c="27962">如下：</st>
- en: <st c="27975">Variance</st><st c="27984">(</st><st c="27986">X</st><st c="27987">)</st>
    <st c="27988">=</st> <st c="27991">𝔼</st><st c="27993">(</st><st c="27995">(</st><st
    c="27996">X</st><st c="27997">−</st> <st c="27998">μ</st><st c="27999">)</st><st
    c="28000">2</st><st c="28001">)</st> <st c="28002">=</st> <st c="28003">𝔼</st><st
    c="28005">(</st><st c="28007">(</st><st c="28008">X</st><st c="28009">−</st> <st
    c="28010">𝔼</st><st c="28012">(</st><st c="28014">X</st><st c="28015">)</st><st
    c="28016">)</st><st c="28017">2</st><st c="28018">)</st>
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27975">方差</st><st c="27984">(</st><st c="27986">X</st><st c="27987">)</st>
    <st c="27988">=</st> <st c="27991">𝔼</st><st c="27993">(</st><st c="27995">(</st><st
    c="27996">X</st><st c="27997">−</st> <st c="27998">μ</st><st c="27999">)</st><st
    c="28000">2</st><st c="28001">)</st> <st c="28002">=</st> <st c="28003">𝔼</st><st
    c="28005">(</st><st c="28007">(</st><st c="28008">X</st><st c="28009">−</st> <st
    c="28010">𝔼</st><st c="28012">(</st><st c="28014">X</st><st c="28015">)</st><st
    c="28016">)</st><st c="28017">2</st><st c="28018">)</st>
- en: <st c="28019">Eq.</st> <st c="28023">14</st>
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28019">公式</st> <st c="28023">14</st>
- en: <st c="28025">The</st> <st c="28030">second part of the formula on the right-hand
    side in</st> *<st c="28083">Eq.</st> <st c="28087">14</st>* <st c="28089">just
    comes from replacing</st> <st c="28116">μ</st> <st c="28117">=</st> <st c="28118">𝔼</st><st
    c="28120">(</st><st c="28122">X</st><st c="28123">)</st><st c="28124">. The formula
    in</st> *<st c="28141">Eq.</st> <st c="28145">14</st>* <st c="28147">tells us
    that the variance of the random variable</st> <st c="28198">X</st> <st c="28199">is
    the same as the expectation value of the random variable</st> <st c="28260">(</st><st
    c="28261">X</st><st c="28262">−</st> <st c="28263">μ</st><st c="28264">)</st><st
    c="28265">2</st><st c="28266">. The left-hand side of the preceding equation shows
    that calculating the variance of a distribution is a function or operation that
    we apply to a random variable, so you might ask whether there is a special symbol
    we use when calculating the variance of a distribution, just like we use the symbol</st>
    <st c="28565">𝔼</st> <st c="28567">when calculating the expectation value of a
    random variable.</st> <st c="28629">Well, there is.</st> <st c="28645">We have
    already used it.</st> <st c="28670">It is</st> <st c="28676">Var</st><st c="28679">(</st><st
    c="28681">X</st><st c="28682">)</st><st c="28683">. But you may also see</st>
    <st c="28706">𝕍</st><st c="28708">(</st><st c="28710">X</st><st c="28711">)</st>
    <st c="28712">used to represent the operation of evaluating the variance of the
    random variable</st> <st c="28795">X</st><st c="28796">. However, in my personal
    experience,</st> <st c="28834">𝕍</st><st c="28836">(</st><st c="28838">X</st><st
    c="28839">)</st> <st c="28840">is a lot less commonly used compared</st> <st c="28878">to</st>
    <st c="28881">Var</st><st c="28884">(</st><st c="28886">X</st><st c="28887">)</st><st
    c="28888">.</st>
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28025">公式右侧的第二部分来自于将</st> *<st c="28083">方程</st> <st c="28087">14</st>*
    <st c="28089">中的</st> <st c="28116">μ</st> <st c="28117">=</st> <st c="28118">𝔼</st><st
    c="28120">(</st><st c="28122">X</st><st c="28123">)</st><st c="28124">代入。方程</st>
    *<st c="28141">14</st>* <st c="28145">中的公式告诉我们，随机变量</st> <st c="28198">X</st>
    <st c="28199">的方差与随机变量</st> <st c="28260">(</st><st c="28261">X</st><st c="28262">−</st>
    <st c="28263">μ</st><st c="28264">)</st><st c="28265">2</st><st c="28266">的期望值相同。前面的方程左侧显示，计算一个分布的方差是我们对随机变量应用的一个函数或操作，因此你可能会问，计算分布方差时是否有特殊符号，就像我们在计算随机变量期望值时使用</st>
    <st c="28565">𝔼</st> <st c="28567">一样。</st> <st c="28629">答案是肯定的。</st> <st c="28645">我们已经使用过了。</st>
    <st c="28670">它是</st> <st c="28676">Var</st><st c="28679">(</st><st c="28681">X</st><st
    c="28682">)</st><st c="28683">。但你也可能看到</st> <st c="28706">𝕍</st><st c="28708">(</st><st
    c="28710">X</st><st c="28711">)</st> <st c="28712">用于表示评估随机变量</st> <st c="28795">X</st><st
    c="28796">方差的操作。</st> <st c="28834">然而，根据我个人的经验，</st> <st c="28836">𝕍</st><st
    c="28838">（</st><st c="28839">X</st><st c="28840">）</st> <st c="28840">的使用远远不如</st>
    <st c="28878">Var</st><st c="28884">(</st><st c="28886">X</st><st c="28887">)</st>
    <st c="28888">常见。</st>
- en: <st c="28889">Other characteristics of a distribution</st>
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="28889">分布的其他特征</st>
- en: <st c="28929">When</st> <st c="28935">summarizing a distribution, it is common
    to give just the mean and standard deviation, or equivalently the mean and the
    variance.</st> <st c="29065">Are these two numbers enough to summarize a distribution?</st>
    <st c="29123">The answer is no.</st> <st c="29141">Sometimes, we may want to quote
    higher-order moments about the mean</st> <st c="29209">μ</st><st c="29210">. For
    example, the third moment looks</st> <st c="29248">like this:</st>
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28929">当</st> <st c="28935">总结一个分布时，通常只给出均值和标准差，或者等价地给出均值和方差。</st> <st
    c="29065">这两个数字足以总结一个分布吗？</st> <st c="29123">答案是否定的。</st> <st c="29141">有时，我们可能需要引用关于均值</st>
    <st c="29209">μ</st><st c="29210">的高阶矩。例如，第三阶矩如下所示：</st> <st c="29248">如下所示：</st>
- en: <st c="29258">𝔼</st><st c="29261">(</st><st c="29263">(</st><st c="29264">X</st><st
    c="29265">−</st> <st c="29266">μ</st><st c="29267">)</st><st c="29268">3</st><st
    c="29269">)</st> <st c="29270">=</st> <st c="29271">∑</st><st c="29272">x</st><st
    c="29273">(</st><st c="29274">x</st><st c="29275">−</st> <st c="29276">μ</st><st
    c="29277">)</st><st c="29278">3</st> <st c="29279">p</st><st c="29280">(</st><st
    c="29281">x</st><st c="29282">)</st>
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29258">𝔼</st><st c="29261">(</st><st c="29263">(</st><st c="29264">X</st><st
    c="29265">−</st> <st c="29266">μ</st><st c="29267">)</st><st c="29268">3</st><st
    c="29269">)</st> <st c="29270">=</st> <st c="29271">∑</st><st c="29272">x</st><st
    c="29273">(</st><st c="29274">x</st><st c="29275">−</st> <st c="29276">μ</st><st
    c="29277">)</st><st c="29278">3</st> <st c="29279">p</st><st c="29280">(</st><st
    c="29281">x</st><st c="29282">)</st>
- en: <st c="29283">Eq.</st> <st c="29287">15</st>
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29283">方程</st> <st c="29287">15</st>
- en: <st c="29289">This can tell us about how lop-sided or asymmetric a distribution
    is.</st> <st c="29360">Using this third</st> **<st c="29377">central moment</st>**<st
    c="29391">, we</st> <st c="29396">can calculate the skewness of</st> <st c="29426">a
    distribution:</st>
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29289">这可以告诉我们分布的偏斜或不对称程度。</st> <st c="29360">使用这个第三</st> **<st c="29377">中心矩</st>**<st
    c="29391">，我们</st> <st c="29396">可以计算分布的偏度：</st>
- en: <st c="29441">Skewness =</st> <st c="29453">μ</st><st c="29454">3</st> <st c="29455">=</st>
    <st c="29456">𝔼</st><st c="29458">(</st><st c="29460">(</st><st c="29461">(</st><st
    c="29462">X</st><st c="29463">−</st> <st c="29464">μ</st><st c="29465">)</st><st
    c="29466">_</st><st c="29467">σ</st><st c="29468">)</st><st c="29469">3</st><st
    c="29470">)</st>
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29441">偏度 =</st> <st c="29453">μ</st><st c="29454">3</st> <st c="29455">=</st>
    <st c="29456">𝔼</st><st c="29458">(</st><st c="29460">(</st><st c="29461">(</st><st
    c="29462">X</st><st c="29463">−</st> <st c="29464">μ</st><st c="29465">)</st><st
    c="29466">_</st><st c="29467">σ</st><st c="29468">)</st><st c="29469">3</st><st
    c="29470">)</st>
- en: <st c="29471">Eq.</st> <st c="29475">16</st>
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29471">方程式</st> <st c="29475">16</st>
- en: <st c="29477">The graph on the left-hand side of</st> *<st c="29513">Figure
    2</st>**<st c="29521">.6</st>* <st c="29523">has a skewness of zero, while the
    middle graph has a</st> <st c="29577">positive skewness, and the right-hand graph
    has a negative skewness.</st> <st c="29646">The dashed line in each of the plots
    shows the position of the mean of each distribution, so we can see how the skewness
    reflects the shift in probability mass from one side of the</st> <st c="29826">mean
    to</st> <st c="29835">the other:</st>
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29477">图 2.6 的左侧图表示偏度为零，而中间的图具有</st> *<st c="29513">正偏度</st>**<st c="29521">。</st>*
    <st c="29523">右侧图具有负偏度。</st> <st c="29646">每个图中的虚线显示了每个分布均值的位置，因此我们可以看到偏度如何反映概率质量从均值的一侧向另一侧的转移：</st>
- en: '![Figure 2.6: Example probability distributions with different skewness values](img/B19496_02_07.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6：具有不同偏度值的概率分布示例](img/B19496_02_07.jpg)'
- en: '<st c="29998">Figure 2.6: Example probability distributions with different
    skewness values</st>'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29998">图 2.6：具有不同偏度值的概率分布示例</st>
- en: <st c="30074">The symbol</st> <st c="30086">μ</st><st c="30087">3</st> <st c="30088">is</st>
    <st c="30092">typically used for the skewness.</st> <st c="30125">Likewise, we
    can use the fourth central moment to calculate what is called the</st> **<st c="30204">kurtosis</st>**
    <st c="30212">of a</st> <st c="30218">distribution.</st> <st c="30232">We won’t
    define the kurtosis</st> <st c="30261">here, other than to say that the kurtosis
    measures relatively how fat or thin a distribution is.</st> <st c="30358">If you
    want to convey to another data scientist characteristics such as how lop-sided
    or thin a distribution is, it is often easier just to show a plot of the distribution.</st>
    <st c="30531">So, most data scientists tend to calculate only the mean and standard
    deviation of a distribution and then show a plot if they want to communicate</st>
    <st c="30678">additional details.</st>
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30074">符号</st> <st c="30086">μ</st><st c="30087">3</st> <st c="30088">通常用于表示偏度。</st>
    <st c="30125">同样，我们可以使用第四中心矩来计算所谓的</st> **<st c="30204">峰度</st>** <st c="30212">的</st>
    <st c="30218">分布。</st> <st c="30232">我们在这里不定义峰度</st> <st c="30261">，只说峰度衡量的是分布相对的胖瘦程度。</st>
    <st c="30358">如果你想向其他数据科学家传达分布的特征，比如它的偏斜度或薄厚度，通常通过展示分布图会更容易。</st> <st c="30531">因此，大多数数据科学家倾向于只计算分布的均值和标准差，如果他们想传达</st>
    <st c="30678">更多细节时，则会展示一个图表。</st>
- en: <st c="30697">Having learned how to summarize and characterize a probability
    distribution for random variables that have discrete outcomes, we are going to
    learn how to extend this to continuous-valued</st> <st c="30886">random variables.</st>
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30697">在学习如何总结和描述具有离散结果的随机变量的概率分布后，我们将学习如何将其扩展到具有连续值的</st> <st c="30886">随机变量。</st>
- en: <st c="30903">Continuous distributions</st>
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="30903">连续分布</st>
- en: <st c="30928">The</st> <st c="30932">sharp-eyed among you will have spotted
    that all the examples of probability distributions that we have given so far in
    this section are of discrete outcomes – outcomes that are clearly distinct, such
    as tea and coffee, or the integer numbers 1, 2, 3…and so on.</st> <st c="31194">Surely
    some outcomes can be continuous.</st> <st c="31234">The ship’s barometer example
    we started the chapter with is an example of a continuous quantity.</st> <st c="31331">So,
    yes – an outcome can be continuous, but there are some subtleties with continuous-valued
    outcomes that we will</st> <st c="31446">now explain.</st>
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30928">你们中的一些眼尖的人可能已经注意到，我们在这一节中给出的所有概率分布的例子都是离散结果——那些显然是不同的结果，比如茶和咖啡，或者整数
    1、2、3 ……等等。</st> <st c="31194">当然，也有一些结果可以是连续的。</st> <st c="31234">我们在章节开头提到的船只气压计的例子就是一个连续量的例子。</st>
    <st c="31331">所以，没错——一个结果可以是连续的，但对于连续值的结果，有一些微妙之处，我们接下来会解释。</st>
- en: <st c="31458">The first subtlety stems from the number of possible outcomes.</st>
    <st c="31522">Imagine I have a random variable</st> <st c="31555">X</st> <st c="31556">that
    is a real number and can take any value between</st> <st c="31610">−</st> <st
    c="31611">∞</st> <st c="31612">and</st> <st c="31617">+</st> <st c="31618">∞</st><st
    c="31619">. It has an infinite number of possible outcomes.</st> <st c="31669">Given
    we have said the sum of the probabilities across all outcomes must be 1, then
    what happens when we sum an infinite number of probabilities?</st> <st c="31815">Doesn’t
    this mean the probability of any particular outcome is zero?</st> <st c="31884">Even
    the answer to this question is slightly complicated, but just asking this question
    does highlight that the concept of a probability distribution needs modification
    when we are dealing with continuous-valued outcomes.</st> <st c="32106">Instead
    of talking about probability distributions, we talk about</st> **<st c="32172">probability
    density</st>** **<st c="32192">functions</st>** <st c="32201">(</st>**<st c="32203">PDFs</st>**<st
    c="32207">).</st>
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31458">第一个微妙之处来自于可能结果的数量。</st> <st c="31522">假设我有一个随机变量</st> <st c="31555">X</st>
    <st c="31556">是一个实数，可以取从</st> <st c="31610">−</st> <st c="31611">∞</st> <st c="31612">到</st>
    <st c="31617">+</st> <st c="31618">∞</st><st c="31619">之间的任意值。它有无限多种可能的结果。</st>
    <st c="31669">考虑到我们已经说过，所有结果的概率总和必须为 1，那么当我们对无限多的概率求和时，会发生什么呢？</st> <st c="31815">难道这意味着任何特定结果的概率为零吗？</st>
    <st c="31884">即便是这个问题的答案也稍显复杂，但仅仅提出这个问题就突显了在处理连续值结果时，概率分布的概念需要修改。</st> <st c="32106">我们不再讨论概率分布，而是讨论</st>
    **<st c="32172">概率密度</st>** **<st c="32192">函数</st>** <st c="32201">(</st>**<st
    c="32203">PDFs</st>**<st c="32207">)。</st>
- en: <st c="32210">A PDF, as</st> <st c="32221">the name suggests, tells me the density
    of probability in the region around a particular outcome point</st> <st c="32324">x</st><st
    c="32325">. With physical densities, we can calculate the amount of material;
    for example, the number of atoms or molecules, present in a volume</st> <st c="32460">V</st><st
    c="32461">, by multiplying the density</st> <st c="32490">ρ</st> <st c="32491">by
    the volume.</st> <st c="32507">Similarly, with a PDF, to calculate the amount
    of probability in a small interval of width</st> <st c="32598">dx</st> <st c="32600">between</st>
    <st c="32609">x</st> <st c="32610">and</st> <st c="32615">x</st> <st c="32616">+</st>
    <st c="32617">dx</st><st c="32619">, we simply multiply the PDF by the interval
    width</st> <st c="32670">dx</st><st c="32672">. This gives us</st> <st c="32688">the</st>
    <st c="32691">following:</st>
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32210">正如其名称所示，PDF 告诉我某个特定结果点附近区域的概率密度</st> <st c="32324">x</st><st c="32325">。对于物理密度，我们可以通过将密度</st>
    <st c="32490">ρ</st> <st c="32491">乘以体积</st> <st c="32460">V</st><st c="32461">来计算在一个体积中存在的物质量；例如，原子或分子的数量。</st>
    <st c="32507">类似地，对于 PDF，要计算在宽度为</st> <st c="32598">dx</st> <st c="32600">的一个小区间内的概率量，我们只需将
    PDF 乘以该区间的宽度</st> <st c="32670">dx</st><st c="32672">。这给我们带来了以下结果：</st>
- en: <st c="32702">Prob</st><st c="32707">(</st><st c="32709">x</st> <st c="32710"><</st>
    <st c="32711">X</st> <st c="32712"><</st> <st c="32713">x</st> <st c="32714">+</st>
    <st c="32715">dx</st><st c="32717">)</st> <st c="32719">=</st> <st c="32720">pdf</st><st
    c="32723">(</st><st c="32725">x</st><st c="32726">)</st> <st c="32727">dx</st>
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32702">Prob</st><st c="32707">(</st><st c="32709">x</st> <st c="32710"><</st>
    <st c="32711">X</st> <st c="32712"><</st> <st c="32713">x</st> <st c="32714">+</st>
    <st c="32715">dx</st><st c="32717">)</st> <st c="32719">=</st> <st c="32720">pdf</st><st
    c="32723">(</st><st c="32725">x</st><st c="32726">)</st> <st c="32727">dx</st>
- en: <st c="32729">Eq.</st> <st c="32734">17</st>
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32729">公式</st> <st c="32734">17</st>
- en: <st c="32736">So, for a continuous-valued outcome, we talk not of the probability
    of having a particular outcome</st> <st c="32836">x</st> <st c="32837">but of
    the probability of having an outcome in</st> <st c="32885">a range.</st>
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32736">因此，对于一个连续值的结果，我们讨论的不是某个特定结果的概率</st> <st c="32836">x</st> <st c="32837">，而是结果在</st>
    <st c="32885">某个范围内的概率。</st>
- en: <st c="32893">Note that we have used here the differential calculus concept
    of a small interval</st> <st c="32976">dx</st><st c="32978">. This is necessary
    because, unlike with physical densities and physical material where the density
    may be constant over a significant sized volume, the probability density can vary
    markedly as we change the outcome</st> <st c="33194">value</st> <st c="33200">x</st><st
    c="33201">.</st>
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32893">请注意，我们在这里使用了微分学中小区间</st> <st c="32976">dx</st><st c="32978">的概念。这样做是必要的，因为，与物理密度和物理材料中的密度可能在较大体积内保持恒定不同，概率密度在我们改变结果</st>
    <st c="33194">值</st> <st c="33200">x</st><st c="33201">时可以发生显著变化。</st>
- en: <st c="33202">Secondly, note</st> <st c="33218">that if we decrease the size
    of the interval</st> <st c="33263">dx</st> <st c="33265">down to zero so that
    we are looking at a single outcome point and not an interval, then the right-rand-side
    of</st> *<st c="33377">Eq.</st> <st c="33381">17</st>* <st c="33383">becomes zero
    – just as we explained previously.</st> <st c="33432">So, the probability of a
    point outcome is zero, but the probability density at that point can</st> <st
    c="33526">be nonzero.</st>
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33202">其次，注意</st> <st c="33218">如果我们将区间</st> <st c="33263">dx</st> <st
    c="33265">的大小减小到零，从而我们看的是一个单一的结果点，而不是一个区间，那么</st> *<st c="33377">公式</st> <st c="33381">17</st>*
    <st c="33383">的右边将变为零——就像我们之前解释的那样。</st> <st c="33432">所以，单一结果点的概率是零，但该点的概率密度可以</st>
    <st c="33526">不为零。</st>
- en: <st c="33537">Just in case you’re wondering if the aforementioned line of reasoning
    is dependent on the range of possible outcomes being</st> <st c="33661">−</st>
    <st c="33662">∞</st> <st c="33663">to</st> <st c="33667">+</st> <st c="33668">∞</st><st
    c="33669">, the answer is no.</st> <st c="33689">If the range of outcomes is in
    a finite interval, say between -10 and 10, we still have an infinite number of
    outcomes, and so everything we have said before still holds.</st> <st c="33860">It
    just means the PDF is zero outside of that interval -10</st> <st c="33919">to
    10.</st>
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33537">如果你在想，前面提到的推理是否依赖于可能结果的范围是</st> <st c="33661">−</st> <st c="33662">∞</st>
    <st c="33663">到</st> <st c="33667">+</st> <st c="33668">∞</st><st c="33669">，答案是否定的。</st>
    <st c="33689">如果结果的范围在一个有限区间内，比如从 -10 到 10，我们依然有无限多个结果，因此之前说过的一切仍然成立。</st> <st
    c="33860">这只是意味着 PDF 在该区间 -10</st> <st c="33919">到 10 之外为零。</st>
- en: <st c="33925">Now that we have explained the subtle difference between a probability
    distribution and a PDF, it is worth highlighting</st> <st c="34046">the following:</st>
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33925">现在我们已经解释了概率分布和 PDF 之间的微妙区别，值得强调</st> <st c="34046">以下几点：</st>
- en: <st c="34060">Most statisticians and data scientists will use the term</st>
    *<st c="34118">probability distribution</st>* <st c="34142">when they mean PDF,
    with the assumption that the reader will implicitly know what is</st> <st c="34228">really
    meant.</st>
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="34060">大多数统计学家和数据科学家会使用术语</st> *<st c="34118">概率分布</st>* <st c="34142">来表示
    PDF，假设读者会隐含地理解其</st> <st c="34228">真正的含义。</st>
- en: <st c="34241">Given an infinite number of possible outcomes and probabilities
    referring to small intervals, all the results we have given about expectation
    values for discrete random variables also hold for continuous random variables,
    with the simple replacement of the probability distribution</st> <st c="34524">p</st><st
    c="34525">(</st><st c="34526">x</st><st c="34527">)</st> <st c="34528">by the
    density function</st> <st c="34552">f</st><st c="34553">(</st><st c="34554">x</st><st
    c="34555">)</st><st c="34556">, and the summation symbol</st> <st c="34583">Σ</st>
    <st c="34584">by the integration symbol</st> <st c="34611">∫</st><st c="34612">.
    We will recap those results now, with</st> <st c="34652">those replacements.</st>
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="34241">给定一个可能结果和概率的无限数量，且这些概率指向小区间，我们之前关于离散随机变量期望值的所有结果同样适用于连续随机变量，只需将概率分布</st>
    <st c="34524">p</st><st c="34525">（</st><st c="34526">x</st><st c="34527">）</st>
    <st c="34528">替换为密度函数</st> <st c="34552">f</st><st c="34553">（</st><st c="34554">x</st><st
    c="34555">）</st><st c="34556">，并且将求和符号</st> <st c="34583">Σ</st> <st c="34584">替换为积分符号</st>
    <st c="34611">∫</st><st c="34612">。我们将现在回顾这些结果，使用</st> <st c="34652">这些替换。</st>
- en: <st c="34671">If we have a continuous-valued random variable</st> <st c="34719">X</st>
    <st c="34720">with outcomes denoted by</st> <st c="34746">x</st> <st c="34747">and
    a PDF</st> <st c="34758">f</st><st c="34759">(</st><st c="34760">x</st><st c="34761">)</st><st
    c="34762">, then we have the</st> <st c="34781">following results:</st>
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34671">如果我们有一个连续取值的随机变量</st> <st c="34719">X</st> <st c="34720">，其结果由</st>
    <st c="34746">x</st> <st c="34747">表示，并且有一个PDF</st> <st c="34758">f</st><st c="34759">(</st><st
    c="34760">x</st><st c="34761">)</st><st c="34762">，那么我们得到以下结果：</st>
- en: <st c="34799">∫</st><st c="34801">−</st><st c="34802">∞</st><st c="34803">+</st><st
    c="34804">∞</st><st c="34805">f</st><st c="34806">(</st><st c="34807">x</st><st
    c="34808">)</st> <st c="34809">dx</st> <st c="34811">=</st> <st c="34813">1</st>
    <st c="34814">Normalization</st>
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34799">∫</st><st c="34801">−</st><st c="34802">∞</st><st c="34803">+</st><st
    c="34804">∞</st><st c="34805">f</st><st c="34806">(</st><st c="34807">x</st><st
    c="34808">)</st> <st c="34809">dx</st> <st c="34811">=</st> <st c="34813">1</st>
    <st c="34814">归一化</st>
- en: <st c="34827">Eq.</st> <st c="34832">18</st>
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34827">方程</st> <st c="34832">18</st>
- en: <st c="34834">𝔼</st><st c="34837">(</st><st c="34839">X</st><st c="34840">)</st>
    <st c="34841">=</st> <st c="34842">μ</st> <st c="34843">=</st> <st c="34844">∫</st><st
    c="34845">−</st><st c="34846">∞</st><st c="34847">+</st><st c="34848">∞</st><st
    c="34849">xf</st><st c="34851">(</st><st c="34853">x</st><st c="34854">)</st>
    <st c="34855">dx</st> <st c="34857">Mean</st>
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34834">𝔼</st><st c="34837">(</st><st c="34839">X</st><st c="34840">)</st>
    <st c="34841">=</st> <st c="34842">μ</st> <st c="34843">=</st> <st c="34844">∫</st><st
    c="34845">−</st><st c="34846">∞</st><st c="34847">+</st><st c="34848">∞</st><st
    c="34849">xf</st><st c="34851">(</st><st c="34853">x</st><st c="34854">)</st>
    <st c="34855">dx</st> <st c="34857">均值</st>
- en: <st c="34862">Eq.</st> <st c="34867">19</st>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34862">方程</st> <st c="34867">19</st>
- en: <st c="34869">𝔼</st><st c="34872">(</st><st c="34874">(</st><st c="34875">X</st><st
    c="34876">−</st> <st c="34877">μ</st><st c="34878">)</st><st c="34879">2</st><st
    c="34880">)</st> <st c="34881">=</st> <st c="34882">σ</st><st c="34883">2</st>
    <st c="34884">=</st> <st c="34885">∫</st><st c="34886">−</st><st c="34887">∞</st><st
    c="34888">+</st><st c="34889">∞</st><st c="34890">(</st><st c="34891">x</st><st
    c="34892">−</st> <st c="34893">μ</st><st c="34894">)</st><st c="34895">2</st><st
    c="34896">f</st><st c="34897">(</st><st c="34898">x</st><st c="34899">)</st> <st
    c="34900">dx</st> <st c="34902">Variance</st>
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34869">𝔼</st><st c="34872">(</st><st c="34874">(</st><st c="34875">X</st><st
    c="34876">−</st> <st c="34877">μ</st><st c="34878">)</st><st c="34879">2</st><st
    c="34880">)</st> <st c="34881">=</st> <st c="34882">σ</st><st c="34883">2</st>
    <st c="34884">=</st> <st c="34885">∫</st><st c="34886">−</st><st c="34887">∞</st><st
    c="34888">+</st><st c="34889">∞</st><st c="34890">(</st><st c="34891">x</st><st
    c="34892">−</st> <st c="34893">μ</st><st c="34894">)</st><st c="34895">2</st><st
    c="34896">f</st><st c="34897">(</st><st c="34898">x</st><st c="34899">)</st> <st
    c="34900">dx</st> <st c="34902">方差</st>
- en: <st c="34911">Eq.</st> <st c="34916">20</st>
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34911">方程</st> <st c="34916">20</st>
- en: <st c="34918">Now we have</st> <st c="34931">learned about single random variables,
    whether discrete or continuous, we are next going to learn how to transform and
    combine multiple random variables.</st> <st c="35085">This will enable us to describe
    and handle the impact of randomness in data when we apply transformations and
    aggregations</st> <st c="35208">to data.</st>
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34918">现在我们已经了解了单个随机变量，无论是离散的还是连续的，接下来我们将学习如何变换和组合多个随机变量。</st> <st c="35085">这将使我们能够在应用变换和聚合</st>
    <st c="35208">到数据时描述和处理数据中的随机性影响。</st>
- en: <st c="35216">Transforming and combining random variables</st>
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="35216">变换和组合随机变量</st>
- en: <st c="35260">Now we have learned some properties of random variables, we are
    going to learn about what happens when we combine</st> <st c="35375">random variables.</st>
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35260">现在我们已经了解了随机变量的一些性质，接下来我们将学习当我们组合</st> <st c="35375">随机变量时会发生什么。</st>
- en: <st c="35392">Why is this important?</st> <st c="35416">Well, often, we will
    want to modify or aggregate our data.</st> <st c="35475">If each observation in
    a dataset is a random variable, then what does that mean for the total of all
    the observations?</st> <st c="35594">We know the total is also a random variable,
    but what are</st> <st c="35652">its properties?</st>
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35392">为什么这很重要？</st> <st c="35416">嗯，通常我们需要修改或聚合我们的数据。</st> <st c="35475">如果数据集中的每个观察值都是一个随机变量，那么这意味着什么呢？</st>
    <st c="35594">我们知道总和也是一个随机变量，但它的</st> <st c="35652">性质是什么呢？</st>
- en: <st c="35667">As a simple example, consider whether an individual shopper buys
    an item from a website.</st> <st c="35757">We can model that individual purchase
    decision as a Bernoulli random variable.</st> <st c="35836">But what about the
    total number of items sold in a day, bought by the 1,000 visitors to the website?</st>
    <st c="35937">How do we model</st> <st c="35953">that total?</st>
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35667">作为一个简单的例子，考虑一个个体购物者是否从一个网站购买商品。</st> <st c="35757">我们可以将这个个体的购买决策建模为一个伯努利随机变量。</st>
    <st c="35836">但是，如何建模一天内由1,000名访问者购买的商品总数呢？</st> <st c="35937">我们该如何建模</st> <st
    c="35953">这个总数呢？</st>
- en: <st c="35964">Linear transformations</st>
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="35964">线性变换</st>
- en: <st c="35987">We’ll start</st> <st c="35999">with something simpler.</st> <st
    c="36024">What happens when we just linearly transform a random variable?</st>
    <st c="36088">If we have a random variable</st> <st c="36117">X</st><st c="36118">,
    we</st> <st c="36122">can create a new random variable</st> <st c="36156">Y</st>
    <st c="36157">=</st> <st c="36158">aX</st> <st c="36160">+</st> <st c="36162">b</st><st
    c="36163">. What does this transformation mean?</st> <st c="36201">Well, if the
    random variable</st> <st c="36230">X</st> <st c="36231">has possible outcomes</st>
    <st c="36254">x</st><st c="36255">, then it means that the random variable</st>
    <st c="36296">Y</st> <st c="36297">has possible outcomes</st> <st c="36320">y</st>
    <st c="36321">=</st> <st c="36322">ax</st> <st c="36324">+</st> <st c="36326">b</st><st
    c="36327">. In terms of a dataset, it means that if we have a particular value
    – say, 10 – for an outcome of</st> <st c="36426">X</st><st c="36427">, then the
    corresponding outcome value of</st> <st c="36469">Y</st> <st c="36470">is just</st>
    <st c="36479">a</st> <st c="36480">×</st> <st c="36481">10</st> <st c="36483">+</st>
    <st c="36485">b</st><st c="36486">.</st>
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35987">我们从一个更简单的情况开始。</st> <st c="35999">当我们线性变换一个随机变量时会发生什么？</st> <st
    c="36024">如果我们有一个随机变量</st> <st c="36088">X</st><st c="36118">, 我们</st> <st c="36122">可以创建一个新的随机变量</st>
    <st c="36156">Y</st> <st c="36157">=</st> <st c="36158">aX</st> <st c="36160">+</st>
    <st c="36162">b</st><st c="36163">。这个变换意味着什么呢？</st> <st c="36201">嗯，如果随机变量</st>
    <st c="36230">X</st> <st c="36231">的可能结果是</st> <st c="36254">x</st><st c="36255">，那么这意味着随机变量</st>
    <st c="36296">Y</st> <st c="36297">的可能结果是</st> <st c="36320">y</st> <st c="36321">=</st>
    <st c="36322">ax</st> <st c="36324">+</st> <st c="36326">b</st><st c="36327">。就数据集而言，这意味着如果我们有一个特定的值——例如，10——作为</st>
    <st c="36426">X</st><st c="36427">的结果，那么对应的</st> <st c="36469">Y</st> <st c="36470">的结果值就是</st>
    <st c="36479">a</st> <st c="36480">×</st> <st c="36481">10</st> <st c="36483">+</st>
    <st c="36485">b</st><st c="36486">。</st>
- en: <st c="36487">Given the linear transformation</st> <st c="36520">Y</st> <st
    c="36521">=</st> <st c="36522">aX</st> <st c="36524">+</st> <st c="36526">b</st><st
    c="36527">, how does the mean of</st> <st c="36550">Y</st> <st c="36551">relate
    to the mean of</st> <st c="36574">X</st><st c="36575">? From</st> *<st c="36582">Eq.</st>
    <st c="36586">7</st>*<st c="36587">, we find that for discrete random variables,
    the</st> <st c="36637">foll</st><st c="36641">owing applies:</st>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="36487">给定线性变换</st> <st c="36520">Y</st> <st c="36521">=</st> <st c="36522">aX</st>
    <st c="36524">+</st> <st c="36526">b</st><st c="36527">，那么</st> <st c="36550">Y</st>
    <st c="36551">的均值与</st> <st c="36574">X</st><st c="36575">的均值有什么关系呢？从</st> *<st
    c="36582">公式</st> <st c="36586">7</st>*<st c="36587">中，我们可以得出对于离散随机变量，以下关系成立：</st>
- en: <st c="36656">𝔼</st><st c="36659">(</st><st c="36661">Y</st><st c="36662">)</st>
    <st c="36663">=</st> <st c="36664">𝔼</st><st c="36666">(</st><st c="36668">aX</st>
    <st c="36670">+</st> <st c="36672">b</st><st c="36673">)</st> <st c="36674">=</st>
    <st c="36675">∑</st><st c="36676">x</st><st c="36677">(</st><st c="36678">ax</st>
    <st c="36680">+</st> <st c="36682">b</st><st c="36683">)</st> <st c="36684">p</st><st
    c="36685">(</st><st c="36686">x</st><st c="36687">)</st> <st c="36688">=</st>
    <st c="36689">a</st><st c="36690">∑</st><st c="36691">x</st><st c="36692">x</st>
    <st c="36693">p</st><st c="36694">(</st><st c="36695">x</st><st c="36696">)</st>
    <st c="36697">+</st> <st c="36698">b</st><st c="36699">∑</st><st c="36700">x</st><st
    c="36701">p</st><st c="36702">(</st><st c="36703">x</st><st c="36704">)</st> <st
    c="36705">=</st> <st c="36706">a</st><st c="36707">𝔼</st><st c="36709">(</st><st
    c="36711">X</st><st c="36712">)</st> <st c="36713">+</st> <st c="36714">b</st>
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="36656">𝔼</st><st c="36659">(</st><st c="36661">Y</st><st c="36662">)</st>
    <st c="36663">=</st> <st c="36664">𝔼</st><st c="36666">(</st><st c="36668">aX</st>
    <st c="36670">+</st> <st c="36672">b</st><st c="36673">)</st> <st c="36674">=</st>
    <st c="36675">∑</st><st c="36676">x</st><st c="36677">(</st><st c="36678">ax</st>
    <st c="36680">+</st> <st c="36682">b</st><st c="36683">)</st> <st c="36684">p</st><st
    c="36685">(</st><st c="36686">x</st><st c="36687">)</st> <st c="36688">=</st>
    <st c="36689">a</st><st c="36690">∑</st><st c="36691">x</st><st c="36692">x</st>
    <st c="36693">p</st><st c="36694">(</st><st c="36695">x</st><st c="36696">)</st>
    <st c="36697">+</st> <st c="36698">b</st><st c="36699">∑</st><st c="36700">x</st><st
    c="36701">p</st><st c="36702">(</st><st c="36703">x</st><st c="36704">)</st> <st
    c="36705">=</st> <st c="36706">a</st><st c="36707">𝔼</st><st c="36709">(</st><st
    c="36711">X</st><st c="36712">)</st> <st c="36713">+</st> <st c="36714">b</st>
- en: <st c="36715">Eq.</st> <st c="36719">21</st>
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="36715">公式</st> <st c="36719">21</st>
- en: <st c="36721">So, the</st> <st c="36729">mean of</st> <st c="36738">Y</st> <st
    c="36739">is simply related to the mean of</st> <st c="36773">X</st> <st c="36774">by
    the same linear transformation that we applied to the random variable.</st> <st
    c="36849">An</st> <st c="36852">identical result holds for continuous-valued random
    variables – as you might have guessed, we simply replace</st> <st c="36961">∑</st>
    <st c="36962">with</st> <st c="36968">∫</st><st c="36969">and the probability</st>
    <st c="36989">p</st><st c="36990">(</st><st c="36991">x</st><st c="36992">)</st>
    <st c="36993">with the PDF</st> <st c="37007">f</st><st c="37008">(</st><st c="37009">x</st><st
    c="37010">)</st> <st c="37011">in</st> *<st c="37015">Eq.</st> <st c="37019">21</st>*<st
    c="37021">.</st>
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="36721">因此，</st> <st c="36729">Y</st> <st c="36738">的均值与</st> <st c="36773">X</st>
    <st c="36774">的均值通过我们对随机变量应用的相同线性变换直接相关。</st> <st c="36849">对于连续值随机变量，</st> <st
    c="36852">相同的结果也成立——正如你可能已经猜到的，我们只需要将</st> <st c="36961">∑</st> <st c="36962">替换为</st>
    <st c="36968">∫</st><st c="36969">，并将概率</st> <st c="36989">p</st><st c="36990">(</st><st
    c="36991">x</st><st c="36992">)</st> <st c="36993">替换为PDF</st> <st c="37007">f</st><st
    c="37008">(</st><st c="37009">x</st><st c="37010">)</st> <st c="37011">，</st>
    *<st c="37015">公式</st> <st c="37019">21</st>*<st c="37021">中。</st>
- en: <st c="37022">What happens to the variance?</st> <st c="37053">A similar simple
    calculation shows that for both discrete and continuous random variables, if</st>
    <st c="37147">Y</st> <st c="37148">=</st> <st c="37149">aX</st> <st c="37151">+</st>
    <st c="37153">b</st><st c="37154">, then the</st> <st c="37165">following applies:</st>
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37022">方差会发生什么变化？</st> <st c="37053">一个类似的简单计算表明，对于离散型和连续型随机变量，如果</st>
    <st c="37147">Y</st> <st c="37148">=</st> <st c="37149">aX</st> <st c="37151">+</st>
    <st c="37153">b</st><st c="37154">，那么以下公式成立：</st>
- en: <st c="37183">Var(</st><st c="37188">Y</st><st c="37190">)</st> <st c="37191">=</st>
    <st c="37192">a</st><st c="37193">2</st> <st c="37194">Var(X)</st>
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37183">Var(</st><st c="37188">Y</st><st c="37190">)</st> <st c="37191">=</st>
    <st c="37192">a</st><st c="37193">2</st> <st c="37194">Var(X)</st>
- en: <st c="37200">Eq.</st> <st c="37205">22</st>
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37200">公式</st> <st c="37205">22</st>
- en: <st c="37207">Non-linear transformations</st>
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="37207">非线性变换</st>
- en: <st c="37234">What</st> <st c="37239">happens if we apply a more general</st>
    <st c="37275">non-linear transformation to a random variable?</st> <st c="37323">This
    would be the case if we were to apply a non-linear transformation to our dataset.</st>
    <st c="37410">Let’s apply</st> <st c="37422">the function</st> <st c="37434">h</st><st
    c="37436">(</st><st c="37437">x</st><st c="37438">)</st> <st c="37439">to the
    values</st> <st c="37454">x</st> <st c="37455">in our dataset.</st> <st c="37472">We
    model this by saying we have a random variable</st> <st c="37522">Y</st> <st c="37523">=</st>
    <st c="37524">h</st><st c="37525">(</st><st c="37526">X</st><st c="37527">)</st><st
    c="37528">. For discrete outcomes, to calculate the mean of</st> <st c="37578">Y</st>
    <st c="37579">we just calculate</st> <st c="37598">∑</st><st c="37599">y</st><st
    c="37600">y</st> <st c="37601">p</st><st c="37602">(</st><st c="37603">y</st><st
    c="37604">)</st><st c="37605">, so we just need to know the probability,</st>
    <st c="37648">p</st><st c="37649">(</st><st c="37650">y</st><st c="37651">)</st><st
    c="37652">, of each outcome.</st> <st c="37671">But since for each value of</st>
    <st c="37699">x</st> <st c="37700">we know the corresponding value of</st> <st
    c="37736">y</st> <st c="37737">and we know the probabilities</st> <st c="37768">p</st><st
    c="37769">(</st><st c="37770">x</st><st c="37771">)</st><st c="37772">, then calculating
    the mean of</st> <st c="37803">Y</st> <st c="37804">is easy:</st>
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37234">如果我们对一个随机变量应用更一般的</st> <st c="37239">非线性变换会发生什么呢？</st> <st c="37275">如果我们对数据集应用非线性变换，情况就是这样。</st>
    <st c="37323">让我们将</st> <st c="37410">函数</st> <st c="37422">h</st><st c="37434">(</st><st
    c="37437">x</st><st c="37438">)</st> <st c="37439">应用于数据集中的值</st> <st c="37454">x</st>
    <st c="37455">。</st> <st c="37472">我们通过说我们有一个随机变量</st> <st c="37522">Y</st> <st
    c="37523">=</st> <st c="37524">h</st><st c="37525">(</st><st c="37526">X</st><st
    c="37527">)</st><st c="37528">来建模这个过程。对于离散结果，计算</st> <st c="37578">Y</st> <st
    c="37579">的均值，我们只需计算</st> <st c="37598">∑</st><st c="37599">y</st><st c="37600">y</st>
    <st c="37601">p</st><st c="37602">(</st><st c="37603">y</st><st c="37604">)</st><st
    c="37605">，所以我们只需要知道每个结果的概率</st> <st c="37648">p</st><st c="37649">(</st><st c="37650">y</st><st
    c="37651">)</st><st c="37652">。</st> <st c="37671">但是由于我们对于每个</st> <st c="37699">x</st>
    <st c="37700">的值，我们知道对应的</st> <st c="37736">y</st> <st c="37737">的值，并且我们知道概率</st>
    <st c="37768">p</st><st c="37769">(</st><st c="37770">x</st><st c="37771">)</st><st
    c="37772">，所以计算</st> <st c="37803">Y</st> <st c="37804">的均值很简单：</st>
- en: <st c="37812">𝔼</st><st c="37815">(</st><st c="37817">Y</st><st c="37818">)</st>
    <st c="37819">=</st> <st c="37820">∑</st><st c="37821">y</st><st c="37822">y</st>
    <st c="37823">p</st><st c="37824">(</st><st c="37825">y</st><st c="37826">)</st>
    <st c="37827">=</st> <st c="37828">∑</st><st c="37829">x</st><st c="37830">h</st><st
    c="37831">(</st><st c="37832">x</st><st c="37833">)</st><st c="37834">p</st><st
    c="37835">(</st><st c="37836">x</st><st c="37837">)</st>
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37812">𝔼</st><st c="37815">(</st><st c="37817">Y</st><st c="37818">)</st>
    <st c="37819">=</st> <st c="37820">∑</st><st c="37821">y</st><st c="37822">y</st>
    <st c="37823">p</st><st c="37824">(</st><st c="37825">y</st><st c="37826">)</st>
    <st c="37827">=</st> <st c="37828">∑</st><st c="37829">x</st><st c="37830">h</st><st
    c="37831">(</st><st c="37832">x</st><st c="37833">)</st><st c="37834">p</st><st
    c="37835">(</st><st c="37836">x</st><st c="37837">)</st>
- en: <st c="37838">Eq.</st> <st c="37842">23</st>
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37838">公式</st> <st c="37842">23</st>
- en: <st c="37844">The formal proof of the right-hand side of the formula in Eq.</st>
    <st c="37907">23 is more nuanced.</st> <st c="37927">In the way we have simply
    written the right-hand side, we are making use of “the law of the unconscious</st>
    <st c="38031">statistician.” For the purposes of this book, we will take the right-hand
    side of</st> *<st c="38113">Eq.</st> <st c="38117">23</st>* <st c="38119">as the
    definition of</st> <st c="38141">𝔼</st><st c="38143">(</st><st c="38145">Y</st><st
    c="38146">)</st> <st c="38147">when</st> <st c="38153">Y</st> <st c="38154">is
    a transformation of another</st> <st c="38186">random variable.</st>
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37844">公式右侧的正式证明在</st> <st c="37907">公式</st> <st c="37927">23</st> <st
    c="37927">中更为复杂。</st> <st c="37927">在我们简单地写出公式右侧的方式时，我们使用了“无意识统计学家的法则”。对于本书的目的，我们将采用</st>
    *<st c="38113">公式</st> <st c="38117">23</st>* <st c="38119">右侧作为</st> <st c="38141">𝔼</st><st
    c="38143">(</st><st c="38145">Y</st><st c="38146">)</st> <st c="38147">的定义，当</st>
    <st c="38153">Y</st> <st c="38154">是另一个</st> <st c="38186">随机变量的变换时。</st>
- en: <st c="38202">For the</st> <st c="38211">case where the transformation</st>
    <st c="38241">h</st><st c="38242">(</st><st c="38243">x</st><st c="38244">)</st>
    <st c="38245">is linear, it is easy to see we get the same result as in</st> *<st
    c="38304">Eq.</st> <st c="38308">21</st>*<st c="38310">.</st>
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38202">对于</st> <st c="38211">当变换</st> <st c="38241">h</st><st c="38242">(</st><st
    c="38243">x</st><st c="38244">)</st> <st c="38245">是线性时的情况，很容易看出我们得到的结果与</st>
    *<st c="38304">公式</st> <st c="38308">21</st>*<st c="38310">相同。</st>
- en: <st c="38311">Now, for continuous random variables, we have a</st> <st c="38360">similar
    result:</st>
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38311">现在，对于连续随机变量，我们有一个</st> <st c="38360">类似的结果：</st>
- en: <st c="38375">𝔼</st><st c="38378">(</st><st c="38380">Y</st><st c="38381">)</st>
    <st c="38382">=</st> <st c="38383">∫</st><st c="38384">−</st><st c="38385">∞</st><st
    c="38386">+</st><st c="38387">∞</st><st c="38388">h</st><st c="38389">(</st><st
    c="38390">x</st><st c="38391">)</st><st c="38392">f</st><st c="38393">(</st><st
    c="38394">x</st><st c="38395">)</st><st c="38396">dx</st>
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38375">𝔼</st><st c="38378">(</st><st c="38380">Y</st><st c="38381">)</st>
    <st c="38382">=</st> <st c="38383">∫</st><st c="38384">−</st><st c="38385">∞</st><st
    c="38386">+</st><st c="38387">∞</st><st c="38388">h</st><st c="38389">(</st><st
    c="38390">x</st><st c="38391">)</st><st c="38392">f</st><st c="38393">(</st><st
    c="38394">x</st><st c="38395">)</st><st c="38396">dx</st>
- en: <st c="38398">Eq.</st> <st c="38403">24</st>
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38398">公式</st> <st c="38403">24</st>
- en: <st c="38405">To write</st> <st c="38415">𝔼</st><st c="38417">(</st><st c="38419">Y</st><st
    c="38420">)</st> <st c="38421">as an integral over outcomes</st> <st c="38451">y</st>
    <st c="38452">we would have to perform a change of variable under the integration
    sign.</st> <st c="38527">For simplicity, we’ll assume the transformation</st>
    <st c="38575">h</st><st c="38576">(</st><st c="38577">x</st><st c="38578">)</st>
    <st c="38579">is monotonic.</st> <st c="38594">If we do this, w</st><st c="38610">e
    get</st> <st c="38617">the following:</st>
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38405">为了将</st> <st c="38415">𝔼</st><st c="38417">(</st><st c="38419">Y</st><st
    c="38420">)</st> <st c="38421">表示为一个关于结果的积分</st> <st c="38451">y</st> <st c="38452">，我们需要在积分符号下进行变量替换。</st>
    <st c="38527">为简便起见，我们假设变换</st> <st c="38575">h</st><st c="38576">(</st><st c="38577">x</st><st
    c="38578">)</st> <st c="38579">是单调的。</st> <st c="38594">如果这样做，我们得到如下结果：</st>
- en: <st c="38631">𝔼</st><st c="38634">(</st><st c="38636">Y</st><st c="38637">)</st>
    <st c="38638">=</st> <st c="38639">∫</st><st c="38640">−</st><st c="38641">∞</st><st
    c="38642">+</st><st c="38643">∞</st><st c="38644">h</st><st c="38645">(</st><st
    c="38646">x</st><st c="38647">)</st><st c="38648">f</st><st c="38649">(</st><st
    c="38650">x</st><st c="38651">)</st><st c="38652">dx</st> <st c="38654">=</st>
    <st c="38656">∫</st><st c="38657">f</st><st c="38658">(</st><st c="38659">−</st><st
    c="38660">∞</st><st c="38661">)</st><st c="38662">f</st><st c="38663">(</st><st
    c="38664">+</st><st c="38665">∞</st><st c="38666">)</st><st c="38667">yf</st><st
    c="38669">(</st><st c="38671">x</st> <st c="38672">=</st> <st c="38673">h</st><st
    c="38674">−</st><st c="38675">1</st><st c="38676">(</st><st c="38677">y</st><st
    c="38678">)</st><st c="38679">)</st> <st c="38680">dx</st><st c="38682">_</st><st
    c="38684">dy</st> <st c="38686">dy</st>
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38631">𝔼</st><st c="38634">(</st><st c="38636">Y</st><st c="38637">)</st>
    <st c="38638">=</st> <st c="38639">∫</st><st c="38640">−</st><st c="38641">∞</st><st
    c="38642">+</st><st c="38643">∞</st><st c="38644">h</st><st c="38645">(</st><st
    c="38646">x</st><st c="38647">)</st><st c="38648">f</st><st c="38649">(</st><st
    c="38650">x</st><st c="38651">)</st><st c="38652">dx</st> <st c="38654">=</st>
    <st c="38656">∫</st><st c="38657">f</st><st c="38658">(</st><st c="38659">−</st><st
    c="38660">∞</st><st c="38661">)</st><st c="38662">f</st><st c="38663">(</st><st
    c="38664">+</st><st c="38665">∞</st><st c="38666">)</st><st c="38667">yf</st><st
    c="38669">(</st><st c="38671">x</st> <st c="38672">=</st> <st c="38673">h</st><st
    c="38674">−</st><st c="38675">1</st><st c="38676">(</st><st c="38677">y</st><st
    c="38678">)</st> <st c="38679">)</st> <st c="38680">dx</st><st c="38682">_</st><st
    c="38684">dy</st> <st c="38686">dy</st>
- en: <st c="38689">Eq.</st> <st c="38694">25</st>
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38689">公式</st> <st c="38694">25</st>
- en: <st c="38696">Looking at what is inside the integral in the last expression
    on the right-hand side of</st> *<st c="38785">Eq.</st> <st c="38789">25</st>*<st
    c="38791">, we can see we have an effective PDF for the random variable</st> <st
    c="38853">Y</st><st c="38854">. That effective P</st><st c="38872">DF is</st>
    <st c="38879">the following:</st>
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38696">查看右侧最后表达式中的积分内容，</st> *<st c="38785">公式</st> <st c="38789">25</st>*<st
    c="38791">，我们可以看到我们得到了随机变量</st> <st c="38853">Y</st><st c="38854">的有效概率密度函数（PDF）。这个有效的概率密度函数是</st>
    <st c="38879">如下：</st>
- en: <st c="38893">f</st><st c="38895">(</st><st c="38896">h</st><st c="38897">−</st><st
    c="38898">1</st><st c="38899">(</st><st c="38900">y</st><st c="38901">)</st><st
    c="38902">)</st><st c="38903">|</st><st c="38904">dx</st><st c="38906">_</st><st
    c="38908">dy</st><st c="38910">|</st> <st c="38912">=</st> <st c="38913">f</st><st
    c="38914">(</st><st c="38915">h</st><st c="38916">−</st><st c="38917">1</st><st
    c="38918">(</st><st c="38919">y</st><st c="38920">)</st><st c="38921">)</st> <st
    c="38922">1</st><st c="38923">_</st><st c="38924">|</st><st c="38925">h</st><st
    c="38926">′</st><st c="38927">(</st><st c="38928">h</st><st c="38929">−</st><st
    c="38930">1</st><st c="38931">(</st><st c="38932">y</st><st c="38933">)</st><st
    c="38934">)</st><st c="38935">|</st>
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38893">f</st><st c="38895">(</st><st c="38896">h</st><st c="38897">−</st><st
    c="38898">1</st><st c="38899">(</st><st c="38900">y</st><st c="38901">)</st><st
    c="38902">)</st><st c="38903">|</st><st c="38904">dx</st><st c="38906">_</st><st
    c="38908">dy</st><st c="38910">|</st> <st c="38912">=</st> <st c="38913">f</st><st
    c="38914">(</st><st c="38915">h</st><st c="38916">−</st><st c="38917">1</st><st
    c="38918">(</st><st c="38919">y</st><st c="38920">)</st><st c="38921">)</st> <st
    c="38922">1</st><st c="38923">_</st><st c="38924">|</st><st c="38925">h</st><st
    c="38926">′</st><st c="38927">(</st><st c="38928">h</st><st c="38929">−</st><st
    c="38930">1</st><st c="38931">(</st><st c="38932">y</st><st c="38933">)</st><st
    c="38934">)</st><st c="38935">|</st>
- en: <st c="38936">Eq.</st> <st c="38940">26</st>
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38936">方程</st> <st c="38940">26</st>
- en: <st c="38942">We can make some immediate comments on the</st> <st c="38986">preceding
    result:</st>
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38942">我们可以对前面的结果做一些直接的评论：</st>
- en: <st c="39003">Firstly, the obvious – if we apply a transformation to a continuous
    random variable, the probability</st> <st c="39105">density changes.</st>
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="39003">首先，显而易见——如果我们对一个连续随机变量进行变换，概率</st> <st c="39105">密度会发生变化。</st>
- en: <st c="39121">We can calculate the PDF of the new transformed random variable
    using the expression in</st> *<st c="39210">Eq.</st> <st c="39214">26</st>*<st
    c="39216">, but only because the function</st> <st c="39248">h</st><st c="39249">−</st><st
    c="39250">1</st><st c="39251">(</st><st c="39252">y</st><st c="39253">)</st> <st
    c="39254">exists and can be calculated.</st> <st c="39285">This is because the
    transformation</st> <st c="39320">y</st> <st c="39321">=</st> <st c="39322">h</st><st
    c="39323">(</st><st c="39324">x</st><st c="39325">)</st> <st c="39326">is monotonic
    and so invertible, meaning that a single value of</st> <st c="39390">y</st> <st
    c="39391">can only have come from a single possible value of</st> <st c="39443">x</st><st
    c="39444">. If the transformation</st> <st c="39468">y</st> <st c="39469">=</st>
    <st c="39470">h</st><st c="39471">(</st><st c="39472">x</st><st c="39473">)</st>
    <st c="39474">is not monotonic it is still possible to determine a PDF for</st>
    <st c="39536">y</st> <st c="39537">by dividing</st> <st c="39550">h</st><st c="39551">(</st><st
    c="39552">x</st><st c="39553">)</st> <st c="39554">into individual monotonic segments,
    but the resulting expression is</st> <st c="39623">more complicated.</st>
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="39121">我们可以使用</st> *<st c="39210">方程</st> <st c="39214">26</st>*<st c="39216">中给出的表达式来计算新的变换后随机变量的概率密度函数（PDF），但前提是</st>
    <st c="39248">h</st><st c="39249">−</st><st c="39250">1</st><st c="39251">(</st><st
    c="39252">y</st><st c="39253">)</st> <st c="39254">是存在的且能够计算。</st> <st c="39285">这是因为变换</st>
    <st c="39320">y</st> <st c="39321">=</st> <st c="39322">h</st><st c="39323">(</st><st
    c="39324">x</st><st c="39325">)</st> <st c="39326">是单调的，因此是可逆的，这意味着</st> <st c="39390">y</st>
    <st c="39391">的单一值只能来自于一个唯一的</st> <st c="39443">x</st><st c="39444">值。如果变换</st>
    <st c="39468">y</st> <st c="39469">=</st> <st c="39470">h</st><st c="39471">(</st><st
    c="39472">x</st><st c="39473">)</st> <st c="39474">不是单调的，仍然可以通过将</st> <st c="39550">h</st><st
    c="39551">(</st><st c="39552">x</st><st c="39553">)</st> <st c="39554">分成单独的单调段来确定</st>
    <st c="39536">y</st> <st c="39537">的PDF，但最终得到的表达式会更加复杂。</st>
- en: <st c="39640">The</st> <st c="39645">expression in</st> *<st c="39659">Eq.</st>
    <st c="39663">26</st>* <st c="39665">looks complicated, but underneath it is a
    very simple principle.</st> <st c="39731">Probability is about counting how many
    outcomes of a particular type we see.</st> <st c="39808">If we count how many</st>
    <st c="39829">outcomes we see in an interval between</st> <st c="39868">x</st>
    <st c="39869">and</st> <st c="39874">x</st> <st c="39875">+</st> <st c="39876">dx</st><st
    c="39878">, then that number is simply the density times the volume of the interval
    (using our physical analogy).</st> <st c="39982">That number is also the same
    (it is invariant) whether we count using</st> <st c="40052">x</st> <st c="40053">as
    our measure of volume or whether we count using</st> <st c="40105">y</st> <st
    c="40106">as our measure of volume.</st> <st c="40133">It is like counting the
    number of molecules in a given volume – it is the same number of molecules whether
    we measure volume in millimeters or centimeters.</st> <st c="40289">So, for probability
    densities, we have</st> <st c="40328">the following:</st>
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="39640">在</st> *<st c="39659">公式</st> <st c="39663">26</st>* <st c="39665">中的表达式看起来很复杂，但其背后是一个非常简单的原理。</st>
    <st c="39731">概率的本质是计算我们看到的某一类型结果的数量。</st> <st c="39808">如果我们计算在</st> <st c="39829">区间</st>
    <st c="39868">x</st> <st c="39869">与</st> <st c="39874">x</st> <st c="39875">+</st>
    <st c="39876">dx</st><st c="39878">之间的结果数量，那么这个数字实际上就是密度乘以区间的体积（用我们的物理类比来看）。</st>
    <st c="39982">这个数字在两种计数方法下都是一样的（它是不可变的），无论我们是用</st> <st c="40052">x</st> <st c="40053">作为体积度量，还是用</st>
    <st c="40105">y</st> <st c="40106">作为体积度量。</st> <st c="40133">就像是计算在给定体积内的分子数量一样，不管我们是用毫米还是用厘米来测量体积，分子数量都是一样的。</st>
    <st c="40289">因此，对于概率密度，我们有</st> <st c="40328">如下公式：</st>
- en: <st c="40342">Probability Density of</st> <st c="40366">Y</st> <st c="40367">×</st>
    <st c="40368">Volume of interval for</st> <st c="40391">Y</st> <st c="40392">=</st>
    <st c="40393">Probability Density of</st> <st c="40416">X</st> <st c="40417">×
    Volume of interval for</st> <st c="40443">X</st>
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40342">随机变量</st> <st c="40366">Y</st> <st c="40367">的概率密度</st> <st c="40368">×</st>
    <st c="40391">Y</st> <st c="40392">的区间体积</st> <st c="40393">=</st> <st c="40416">随机变量</st>
    <st c="40417">X</st> <st c="40443">的概率密度</st> <st c="40443">×</st> <st c="40443">X</st>
- en: <st c="40444">Eq.</st> <st c="40448">27</st>
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40444">公式</st> <st c="40448">27</st>
- en: <st c="40450">Or, more exactly, w</st><st c="40470">e have</st> <st c="40478">the
    following:</st>
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40450">或者，更准确地说，我们有</st><st c="40470">如下公式：</st>
- en: <st c="40492">|</st> <st c="40494">f</st><st c="40495">Y</st><st c="40496">(</st><st
    c="40497">y</st><st c="40498">)</st><st c="40499">dy</st><st c="40501">|</st>
    <st c="40503">=</st> <st c="40504">|</st><st c="40505">f</st><st c="40506">X</st><st
    c="40507">(</st><st c="40508">x</st><st c="40509">)</st><st c="40510">dx</st><st
    c="40512">|</st>
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40492">|</st> <st c="40494">f</st><st c="40495">Y</st><st c="40496">(</st><st
    c="40497">y</st><st c="40498">)</st><st c="40499">dy</st><st c="40501">|</st>
    <st c="40503">=</st> <st c="40504">|</st><st c="40505">f</st><st c="40506">X</st><st
    c="40507">(</st><st c="40508">x</st><st c="40509">)</st><st c="40510">dx</st><st
    c="40512">|</st>
- en: <st c="40514">Eq.</st> <st c="40518">28</st>
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40514">公式</st> <st c="40518">28</st>
- en: <st c="40520">Here, we have been more explicit and used</st> <st c="40563">f</st><st
    c="40564">X</st><st c="40565">(</st><st c="40566">x</st><st c="40567">)</st> <st
    c="40568">to denote the PDF of the random variable</st> <st c="40610">X</st><st
    c="40611">, evaluated at outcome value</st> <st c="40640">x</st><st c="40641">,
    and</st> <st c="40647">f</st><st c="40648">Y</st><st c="40649">(</st><st c="40650">y</st><st
    c="40651">)</st> <st c="40652">to denote the PDF of the random variable</st> <st
    c="40694">Y</st><st c="40695">, evaluated at outcome</st> <st c="40718">value</st>
    <st c="40724">y</st><st c="40725">.</st>
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40520">在这里，我们更加明确地使用了</st> <st c="40563">f</st><st c="40564">X</st><st
    c="40565">(</st><st c="40566">x</st><st c="40567">)</st> <st c="40568">来表示随机变量</st>
    <st c="40610">X</st><st c="40611">的概率密度函数（PDF），该函数在结果值</st> <st c="40640">x</st><st
    c="40641">处的值，以及</st> <st c="40647">f</st><st c="40648">Y</st><st c="40649">(</st><st
    c="40650">y</st><st c="40651">)</st> <st c="40652">来表示随机变量</st> <st c="40694">Y</st><st
    c="40695">的概率密度函数（PDF），该函数在结果值</st> <st c="40718">y</st><st c="40724">处的值。</st>
- en: <st c="40726">If you just then plug the transformation</st> <st c="40768">y</st>
    <st c="40769">=</st> <st c="40770">h</st><st c="40771">(</st><st c="40772">x</st><st
    c="40773">)</st> <st c="40774">into</st> *<st c="40780">Eq.</st> <st c="40784">28</st>*<st
    c="40786">, you will get the same result as in</st> *<st c="40823">Eq.</st> <st
    c="40827">26</st>*<st c="40829">. Personally, I prefer this method of working
    out how a PDF transforms because I can never remember the complex formula in</st>
    *<st c="40952">Eq.</st> <st c="40956">26</st>*<st c="40958">, and because the
    result in</st> *<st c="40986">Eq.</st> <st c="40990">28</st>* <st c="40992">is
    based on a simple principle that I can remember – it doesn’t matter how you count
    how many things are in a given volume; the number is always</st> <st c="41138">the
    same.</st>
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="40726">如果你直接将变换</st> <st c="40768">y</st> <st c="40769">=</st> <st c="40770">h</st><st
    c="40771">(</st><st c="40772">x</st><st c="40773">)</st> <st c="40774">代入</st>
    *<st c="40780">方程</st> <st c="40784">28</st>*<st c="40786">，你将得到与</st> *<st c="40823">方程</st>
    <st c="40827">26</st>*<st c="40829">相同的结果。个人来说，我更喜欢这种推导PDF变换的方法，因为我总是记不住</st>
    *<st c="40952">方程</st> <st c="40956">26</st>*<st c="40958">中的复杂公式，而且因为</st> *<st
    c="40986">方程</st> <st c="40990">28</st>* <st c="40992">中的结果基于一个我可以记住的简单原理——不管你如何计算某一体积中的事物数量，这个数字总是</st>
    <st c="41138">相同的。</st>
- en: <st c="41147">Combining random variables</st>
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="41147">组合随机变量</st>
- en: <st c="41174">Now, let’s get</st> <st c="41190">back to our original question
    of how to combine random variables.</st> <st c="41256">Imagine I have two random
    variables</st> <st c="41292">X</st><st c="41293">1</st> <st c="41294">and</st>
    <st c="41299">X</st><st c="41300">2</st> <st c="41301">that have outcomes</st>
    <st c="41321">x</st><st c="41322">1</st> <st c="41323">and</st> <st c="41328">x</st><st
    c="41329">2</st> <st c="41330">respectively.</st> <st c="41345">What is the mean
    of the random variable</st> <st c="41385">Y</st> <st c="41386">=</st> <st c="41387">X</st><st
    c="41388">1</st><st c="41389">+</st> <st c="41390">X</st><st c="41391">2</st><st
    c="41392">? You can probably guess, but let’s wo</st><st c="41430">rk things</st>
    <st c="41441">out properly:</st>
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41174">现在，让我们回到最初的问题：如何组合随机变量。</st> <st c="41190">想象我有两个随机变量</st> <st
    c="41292">X</st><st c="41293">1</st> <st c="41294">和</st> <st c="41299">X</st><st
    c="41300">2</st> <st c="41301">它们分别有结果</st> <st c="41321">x</st><st c="41322">1</st>
    <st c="41323">和</st> <st c="41328">x</st><st c="41329">2</st> <st c="41330">。</st>
    <st c="41345">那么，随机变量</st> <st c="41385">Y</st> <st c="41386">=</st> <st c="41387">X</st><st
    c="41388">1</st><st c="41389">+</st> <st c="41390">X</st><st c="41391">2</st><st
    c="41392">的均值是多少？你可能能猜到，但让我们正式推导一下：</st>
- en: <st c="41454">𝔼</st><st c="41457">(</st><st c="41459">Y</st><st c="41460">)</st>
    <st c="41461">=</st> <st c="41462">∑</st><st c="41463">x</st><st c="41464">1</st><st
    c="41465">,</st> <st c="41466">x</st><st c="41467">2</st><st c="41468">(</st><st
    c="41469">x</st><st c="41470">1</st><st c="41471">+</st> <st c="41472">x</st><st
    c="41473">2</st><st c="41474">)</st> <st c="41475">p</st><st c="41476">(</st><st
    c="41477">x</st><st c="41478">1</st><st c="41479">,</st> <st c="41480">x</st><st
    c="41481">2</st><st c="41482">)</st> <st c="41483">=</st> <st c="41484">∑</st><st
    c="41485">x</st><st c="41486">1</st><st c="41487">x</st><st c="41488">1</st> <st
    c="41489">∑</st><st c="41490">x</st><st c="41491">2</st><st c="41492">p</st><st
    c="41493">(</st><st c="41494">x</st><st c="41495">1</st><st c="41496">,</st> <st
    c="41497">x</st><st c="41498">2</st><st c="41499">)</st> <st c="41500">+</st>
    <st c="41501">∑</st><st c="41502">x</st><st c="41503">2</st><st c="41504">x</st><st
    c="41505">2</st><st c="41506">∑</st><st c="41507">x</st><st c="41508">1</st><st
    c="41509">p</st><st c="41510">(</st><st c="41511">x</st><st c="41512">1</st><st
    c="41513">,</st> <st c="41514">x</st><st c="41515">2</st><st c="41516">)</st>
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41454">𝔼</st><st c="41457">(</st><st c="41459">Y</st><st c="41460">)</st>
    <st c="41461">=</st> <st c="41462">∑</st><st c="41463">x</st><st c="41464">1</st><st
    c="41465">,</st> <st c="41466">x</st><st c="41467">2</st><st c="41468">(</st><st
    c="41469">x</st><st c="41470">1</st><st c="41471">+</st> <st c="41472">x</st><st
    c="41473">2</st><st c="41474">)</st> <st c="41475">p</st><st c="41476">(</st><st
    c="41477">x</st><st c="41478">1</st><st c="41479">,</st> <st c="41480">x</st><st
    c="41481">2</st><st c="41482">)</st> <st c="41483">=</st> <st c="41484">∑</st><st
    c="41485">x</st><st c="41486">1</st><st c="41487">x</st><st c="41488">1</st> <st
    c="41489">∑</st><st c="41490">x</st><st c="41491">2</st><st c="41492">p</st><st
    c="41493">(</st><st c="41494">x</st><st c="41495">1</st><st c="41496">,</st> <st
    c="41497">x</st><st c="41498">2</st><st c="41499">)</st> <st c="41500">+</st>
    <st c="41501">∑</st><st c="41502">x</st><st c="41503">2</st><st c="41504">x</st><st
    c="41505">2</st><st c="41506">∑</st><st c="41507">x</st><st c="41508">1</st><st
    c="41509">p</st><st c="41510">(</st><st c="41511">x</st><st c="41512">1</st><st
    c="41513">,</st> <st c="41514">x</st><st c="41515">2</st><st c="41516">)</st>
- en: <st c="41517">Eq.</st> <st c="41521">29</st>
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41517">方程。</st> <st c="41521">29</st>
- en: <st c="41523">Now,</st> <st c="41529">p</st><st c="41530">(</st><st c="41531">x</st><st
    c="41532">1</st><st c="41533">,</st> <st c="41534">x</st><st c="41535">2</st><st
    c="41536">)</st> <st c="41537">is the probability of seeing outcomes</st> <st
    c="41576">x</st><st c="41577">1</st> <st c="41578">and</st> <st c="41583">x</st><st
    c="41584">2</st> <st c="41585">together, or jointly, and so is called the</st>
    **<st c="41629">joint probability</st>** <st c="41646">or</st> **<st c="41650">joint
    distribution</st>** <st c="41668">of</st> <st c="41672">X</st><st c="41673">1</st>
    <st c="41674">and</st> <st c="41679">X</st><st c="41680">2</st><st c="41681">.
    One of the properties of the</st> <st c="41712">joint distribution is that if
    we sum over all the possible values of</st> <st c="41781">x</st><st c="41782">2</st>
    <st c="41783">we get</st> <st c="41791">p</st><st c="41792">(</st><st c="41793">x</st><st
    c="41794">1</st><st c="41795">)</st><st c="41796">, or in other words, we get</st>
    <st c="41824">the following:</st>
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41523">现在，</st> <st c="41529">p</st><st c="41530">(</st><st c="41531">x</st><st
    c="41532">1</st><st c="41533">,</st> <st c="41534">x</st><st c="41535">2</st><st
    c="41536">)</st> <st c="41537">是看到结果</st> <st c="41576">x</st><st c="41577">1</st>
    <st c="41578">和</st> <st c="41583">x</st><st c="41584">2</st> <st c="41585">一起出现的概率，或者说是它们的联合概率，</st>
    **<st c="41629">联合概率</st>** <st c="41646">或</st> **<st c="41650">联合分布</st>** <st
    c="41668">是</st> <st c="41672">X</st><st c="41673">1</st> <st c="41674">和</st>
    <st c="41679">X</st><st c="41680">2</st><st c="41681">的</st>。其中一个联合分布的性质是，如果我们对所有可能的</st>
    <st c="41781">x</st><st c="41782">2</st> <st c="41783">求和，我们得到</st> <st c="41791">p</st><st
    c="41792">(</st><st c="41793">x</st><st c="41794">1</st><st c="41795">)</st><st
    c="41796">，换句话说，我们得到</st> <st c="41824">以下结果：</st>
- en: <st c="41838">∑</st><st c="41840">x</st><st c="41841">2</st><st c="41842">p</st><st
    c="41843">(</st><st c="41844">x</st><st c="41845">1</st><st c="41846">,</st> <st
    c="41847">x</st><st c="41848">2</st><st c="41849">)</st> <st c="41850">=</st>
    <st c="41851">p</st><st c="41852">(</st><st c="41853">x</st><st c="41854">1</st><st
    c="41855">)</st> <st c="41856">and similarly</st> <st c="41871">∑</st><st c="41872">x</st><st
    c="41873">1</st><st c="41874">p</st><st c="41875">(</st><st c="41876">x</st><st
    c="41877">1</st><st c="41878">,</st> <st c="41879">x</st><st c="41880">2</st><st
    c="41881">)</st> <st c="41882">=</st> <st c="41883">p</st><st c="41884">(</st><st
    c="41885">x</st><st c="41886">2</st><st c="41887">)</st>
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41838">∑</st><st c="41840">x</st><st c="41841">2</st><st c="41842">p</st><st
    c="41843">(</st><st c="41844">x</st><st c="41845">1</st><st c="41846">,</st> <st
    c="41847">x</st><st c="41848">2</st><st c="41849">)</st> <st c="41850">=</st>
    <st c="41851">p</st><st c="41852">(</st><st c="41853">x</st><st c="41854">1</st><st
    c="41855">)</st> <st c="41856">且类似地</st> <st c="41871">∑</st><st c="41872">x</st><st
    c="41873">1</st><st c="41874">p</st><st c="41875">(</st><st c="41876">x</st><st
    c="41877">1</st><st c="41878">,</st> <st c="41879">x</st><st c="41880">2</st><st
    c="41881">)</st> <st c="41882">=</st> <st c="41883">p</st><st c="41884">(</st><st
    c="41885">x</st><st c="41886">2</st><st c="41887">)</st>
- en: <st c="41888">Eq.</st> <st c="41892">30</st>
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41888">方程</st> <st c="41892">30</st>
- en: <st c="41894">Plugging this into</st> *<st c="41914">Eq.</st> <st c="41918">2</st><st
    c="41919">9</st>*<st c="41920">, we get</st> <st c="41929">the following:</st>
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41894">将其代入</st> *<st c="41914">方程</st> <st c="41918">29</st>*<st c="41920">，我们得到</st>
    <st c="41929">以下结果：</st>
- en: <st c="41943">𝔼</st><st c="41946">(</st><st c="41948">X</st><st c="41949">1</st><st
    c="41950">+</st> <st c="41951">X</st><st c="41952">2</st><st c="41953">)</st>
    <st c="41954">=</st> <st c="41955">∑</st><st c="41956">x</st><st c="41957">1</st><st
    c="41958">x</st><st c="41959">1</st> <st c="41960">p</st><st c="41961">(</st><st
    c="41962">x</st><st c="41963">1</st><st c="41964">)</st><st c="41965">+</st> <st
    c="41966">∑</st><st c="41967">x</st><st c="41968">2</st><st c="41969">x</st><st
    c="41970">2</st> <st c="41971">p</st><st c="41972">(</st><st c="41973">x</st><st
    c="41974">2</st><st c="41975">)</st> <st c="41976">=</st> <st c="41977">𝔼</st><st
    c="41979">(</st><st c="41981">X</st><st c="41982">1</st><st c="41983">)</st><st
    c="41984">+</st> <st c="41985">𝔼</st><st c="41987">(</st><st c="41989">X</st><st
    c="41990">2</st><st c="41991">)</st>
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41943">𝔼</st><st c="41946">(</st><st c="41948">X</st><st c="41949">1</st><st
    c="41950">+</st> <st c="41951">X</st><st c="41952">2</st><st c="41953">)</st>
    <st c="41954">=</st> <st c="41955">∑</st><st c="41956">x</st><st c="41957">1</st><st
    c="41958">x</st><st c="41959">1</st> <st c="41960">p</st><st c="41961">(</st><st
    c="41962">x</st><st c="41963">1</st><st c="41964">)</st><st c="41965">+</st> <st
    c="41966">∑</st><st c="41967">x</st><st c="41968">2</st><st c="41969">x</st><st
    c="41970">2</st> <st c="41971">p</st><st c="41972">(</st><st c="41973">x</st><st
    c="41974">2</st><st c="41975">)</st> <st c="41976">=</st> <st c="41977">𝔼</st><st
    c="41979">(</st><st c="41981">X</st><st c="41982">1</st><st c="41983">)</st><st
    c="41984">+</st> <st c="41985">𝔼</st><st c="41987">(</st><st c="41989">X</st><st
    c="41990">2</st><st c="41991">)</st>
- en: <st c="41992">Eq.</st> <st c="41996">31</st>
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41992">方程</st> <st c="41996">31</st>
- en: <st c="41998">Hopefully, this is what you will have guessed.</st> <st c="42046">The
    same result holds for continuous-valued random variables, again just changing
    summation</st> <st c="42138">for integration.</st>
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41998">希望这是你所猜到的结果。</st> <st c="42046">对于连续值随机变量，相同的结果成立，只是将求和改为</st>
    <st c="42138">积分。</st>
- en: <st c="42154">We can iteratively apply the result in</st> *<st c="42194">Eq.</st>
    <st c="42198">31</st>* <st c="42200">to adding together many random variabl</st><st
    c="42239">es to get</st> <st c="42250">the following:</st>
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42154">我们可以通过递归地应用</st> *<st c="42194">等式</st> <st c="42198">31</st>*
    <st c="42200">的结果，将多个随机变量相加，得到</st> <st c="42250">以下结果：</st>
- en: <st c="42264">𝔼</st><st c="42267">(</st><st c="42269">X</st><st c="42270">1</st><st
    c="42271">+</st> <st c="42272">X</st><st c="42273">2</st><st c="42274">+</st>
    <st c="42275">⋯</st> <st c="42276">+</st> <st c="42277">X</st><st c="42278">N</st><st
    c="42279">)</st> <st c="42280">=</st> <st c="42281">𝔼</st><st c="42283">(</st><st
    c="42285">X</st><st c="42286">1</st><st c="42287">)</st><st c="42288">+</st> <st
    c="42289">𝔼</st><st c="42291">(</st><st c="42293">X</st><st c="42294">2</st><st
    c="42295">)</st><st c="42296">+</st> <st c="42297">⋯</st> <st c="42298">+</st>
    <st c="42299">𝔼</st><st c="42301">(</st><st c="42303">X</st><st c="42304">N</st><st
    c="42305">)</st>
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42264">𝔼</st><st c="42267">(</st><st c="42269">X</st><st c="42270">1</st><st
    c="42271">+</st> <st c="42272">X</st><st c="42273">2</st><st c="42274">+</st>
    <st c="42275">⋯</st> <st c="42276">+</st> <st c="42277">X</st><st c="42278">N</st><st
    c="42279">)</st> <st c="42280">=</st> <st c="42281">𝔼</st><st c="42283">(</st><st
    c="42285">X</st><st c="42286">1</st><st c="42287">)</st><st c="42288">+</st> <st
    c="42289">𝔼</st><st c="42291">(</st><st c="42293">X</st><st c="42294">2</st><st
    c="42295">)</st><st c="42296">+</st> <st c="42297">⋯</st> <st c="42298">+</st>
    <st c="42299">𝔼</st><st c="42301">(</st><st c="42303">X</st><st c="42304">N</st><st
    c="42305">)</st>
- en: <st c="42306">Eq.</st> <st c="42310">32</st>
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42306">等式</st> <st c="42310">32</st>
- en: <st c="42312">It is also a simple extension to include linear transformations
    of those</st> <st c="42386">N</st> <st c="42387">random variables to give</st>
    <st c="42413">the following:</st>
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42312">同样，我们可以简单地扩展，包括这些</st> <st c="42386">N</st> <st c="42387">个随机变量的线性变换，从而得到</st>
    <st c="42413">以下结果：</st>
- en: <st c="42427">𝔼</st><st c="42430">(</st><st c="42432">a</st><st c="42433">1</st>
    <st c="42434">X</st><st c="42435">1</st><st c="42436">+</st> <st c="42437">a</st><st
    c="42438">2</st> <st c="42439">X</st><st c="42440">2</st><st c="42441">+</st>
    <st c="42442">⋯</st> <st c="42443">+</st> <st c="42444">a</st><st c="42445">N</st>
    <st c="42446">X</st><st c="42447">N</st><st c="42448">)</st> <st c="42449">=</st>
    <st c="42450">a</st><st c="42451">1</st> <st c="42452">𝔼</st><st c="42454">(</st><st
    c="42456">X</st><st c="42457">1</st><st c="42458">)</st><st c="42459">+</st> <st
    c="42460">a</st><st c="42461">2</st> <st c="42462">𝔼</st><st c="42464">(</st><st
    c="42466">X</st><st c="42467">2</st><st c="42468">)</st><st c="42469">+</st> <st
    c="42470">⋯</st> <st c="42471">+</st> <st c="42472">a</st><st c="42473">N</st>
    <st c="42474">𝔼</st><st c="42476">(</st><st c="42478">X</st><st c="42479">N</st><st
    c="42480">)</st>
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42427">𝔼</st><st c="42430">(</st><st c="42432">a</st><st c="42433">1</st>
    <st c="42434">X</st><st c="42435">1</st><st c="42436">+</st> <st c="42437">a</st><st
    c="42438">2</st> <st c="42439">X</st><st c="42440">2</st><st c="42441">+</st>
    <st c="42442">⋯</st> <st c="42443">+</st> <st c="42444">a</st><st c="42445">N</st>
    <st c="42446">X</st><st c="42447">N</st><st c="42448">)</st> <st c="42449">=</st>
    <st c="42450">a</st><st c="42451">1</st> <st c="42452">𝔼</st><st c="42454">(</st><st
    c="42456">X</st><st c="42457">1</st><st c="42458">)</st><st c="42459">+</st> <st
    c="42460">a</st><st c="42461">2</st> <st c="42462">𝔼</st><st c="42464">(</st><st
    c="42466">X</st><st c="42467">2</st><st c="42468">)</st><st c="42469">+</st> <st
    c="42470">⋯</st> <st c="42471">+</st> <st c="42472">a</st><st c="42473">N</st>
    <st c="42474">𝔼</st><st c="42476">(</st><st c="42478">X</st><st c="42479">N</st><st
    c="42480">)</st>
- en: <st c="42481">Eq.</st> <st c="42485">33</st>
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42481">等式</st> <st c="42485">33</st>
- en: <st c="42487">Here, the weights</st> <st c="42506">a</st><st c="42507">1</st><st
    c="42508">,</st> <st c="42509">a</st><st c="42510">2</st><st c="42511">,</st>
    <st c="42512">⋯</st> <st c="42513">,</st> <st c="42514">a</st><st c="42515">N</st>
    <st c="42516">are</st> <st c="42521">fixed numbers.</st>
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42487">这里，权重</st> <st c="42506">a</st><st c="42507">1</st><st c="42508">,</st>
    <st c="42509">a</st><st c="42510">2</st><st c="42511">,</st> <st c="42512">⋯</st>
    <st c="42513">,</st> <st c="42514">a</st><st c="42515">N</st> <st c="42516">是</st>
    <st c="42521">固定的数字。</st>
- en: <st c="42535">Okay – but what about the variance of</st> <st c="42574">X</st><st
    c="42575">1</st><st c="42576">+</st> <st c="42577">X</st><st c="42578">2</st><st
    c="42579">+</st> <st c="42580">⋯</st> <st c="42581">+</st> <st c="42582">X</st><st
    c="42583">N</st><st c="42584">? A lengthy, but similar calculation to that in</st>
    *<st c="42632">Eq.</st> <st c="42636">29</st>* <st c="42638">shows that if</st>
    <st c="42653">X</st><st c="42654">1</st><st c="42655">,</st> <st c="42656">X</st><st
    c="42657">2</st><st c="42658">,</st> <st c="42659">⋯</st> <st c="42660">,</st>
    <st c="42661">X</st><st c="42662">N</st> <st c="42663">are independent of each
    other, the</st><st c="42698">n the</st> <st c="42705">following applies:</st>
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42535">好吧——那么</st> <st c="42574">X</st><st c="42575">1</st><st c="42576">+</st>
    <st c="42577">X</st><st c="42578">2</st><st c="42579">+</st> <st c="42580">⋯</st>
    <st c="42581">+</st> <st c="42582">X</st><st c="42583">N</st><st c="42584">的方差如何呢？一个冗长的，但与</st>
    *<st c="42632">等式</st> <st c="42636">29</st>* <st c="42638">类似的计算显示，如果</st> <st
    c="42653">X</st><st c="42654">1</st><st c="42655">,</st> <st c="42656">X</st><st
    c="42657">2</st><st c="42658">,</st> <st c="42659">⋯</st> <st c="42660">,</st>
    <st c="42661">X</st><st c="42662">N</st> <st c="42663">是彼此独立的，则</st><st c="42698">则</st>
    <st c="42705">以下公式适用：</st>
- en: <st c="42723">Var</st><st c="42727">(</st><st c="42729">X</st><st c="42730">1</st><st
    c="42731">+</st> <st c="42732">X</st><st c="42733">2</st><st c="42734">+</st>
    <st c="42735">⋯</st> <st c="42736">+</st> <st c="42737">X</st><st c="42738">N</st><st
    c="42739">)</st> <st c="42740">=</st> <st c="42741">Var</st><st c="42744">(</st><st
    c="42746">X</st><st c="42747">1</st><st c="42748">)</st><st c="42749">+</st> <st
    c="42750">Var</st><st c="42753">(</st><st c="42755">X</st><st c="42756">2</st><st
    c="42757">)</st><st c="42758">+</st> <st c="42759">⋯</st> <st c="42760">+</st>
    <st c="42761">Var</st><st c="42764">(</st><st c="42766">X</st><st c="42767">N</st><st
    c="42768">)</st>
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42723">Var</st><st c="42727">(</st><st c="42729">X</st><st c="42730">1</st><st
    c="42731">+</st> <st c="42732">X</st><st c="42733">2</st><st c="42734">+</st>
    <st c="42735">⋯</st> <st c="42736">+</st> <st c="42737">X</st><st c="42738">N</st><st
    c="42739">)</st> <st c="42740">=</st> <st c="42741">Var</st><st c="42744">(</st><st
    c="42746">X</st><st c="42747">1</st><st c="42748">)</st><st c="42749">+</st> <st
    c="42750">Var</st><st c="42753">(</st><st c="42755">X</st><st c="42756">2</st><st
    c="42757">)</st><st c="42758">+</st> <st c="42759">⋯</st> <st c="42760">+</st>
    <st c="42761">Var</st><st c="42764">(</st><st c="42766">X</st><st c="42767">N</st><st
    c="42768">)</st>
- en: <st c="42769">Eq.</st> <st c="42773">34</st>
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42769">等式</st> <st c="42773">34</st>
- en: <st c="42775">Likewise, if the different random variables are independent of
    each other, we have</st> <st c="42859">the following:</st>
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42775">同样地，如果不同的随机变量彼此独立，我们有</st> <st c="42859">如下公式：</st>
- en: <st c="42873">Var</st><st c="42877">(</st><st c="42879">a</st><st c="42880">1</st>
    <st c="42881">X</st><st c="42882">1</st><st c="42883">+</st> <st c="42884">a</st><st
    c="42885">2</st> <st c="42886">X</st><st c="42887">2</st><st c="42888">+</st>
    <st c="42889">⋯</st> <st c="42890">+</st> <st c="42891">a</st><st c="42892">N</st>
    <st c="42893">X</st><st c="42894">N</st><st c="42895">)</st> <st c="42896">=</st>
    <st c="42897">a</st><st c="42898">1</st><st c="42899">2</st> <st c="42900">Var</st><st
    c="42903">(</st><st c="42905">X</st><st c="42906">1</st><st c="42907">)</st><st
    c="42908">+</st> <st c="42909">a</st><st c="42910">2</st><st c="42911">2</st>
    <st c="42912">Var</st><st c="42915">(</st><st c="42917">X</st><st c="42918">2</st><st
    c="42919">)</st><st c="42920">+</st> <st c="42921">⋯</st> <st c="42922">+</st>
    <st c="42923">a</st><st c="42924">N</st><st c="42925">2</st> <st c="42926">Var</st><st
    c="42929">(</st><st c="42931">X</st><st c="42932">N</st><st c="42933">)</st>
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42873">Var</st><st c="42877">(</st><st c="42879">a</st><st c="42880">1</st>
    <st c="42881">X</st><st c="42882">1</st><st c="42883">+</st> <st c="42884">a</st><st
    c="42885">2</st> <st c="42886">X</st><st c="42887">2</st><st c="42888">+</st>
    <st c="42889">⋯</st> <st c="42890">+</st> <st c="42891">a</st><st c="42892">N</st>
    <st c="42893">X</st><st c="42894">N</st><st c="42895">)</st> <st c="42896">=</st>
    <st c="42897">a</st><st c="42898">1</st><st c="42899">2</st> <st c="42900">Var</st><st
    c="42903">(</st><st c="42905">X</st><st c="42906">1</st><st c="42907">)</st><st
    c="42908">+</st> <st c="42909">a</st><st c="42910">2</st><st c="42911">2</st>
    <st c="42912">Var</st><st c="42915">(</st><st c="42917">X</st><st c="42918">2</st><st
    c="42919">)</st><st c="42920">+</st> <st c="42921">⋯</st> <st c="42922">+</st>
    <st c="42923">a</st><st c="42924">N</st><st c="42925">2</st> <st c="42926">Var</st><st
    c="42929">(</st><st c="42931">X</st><st c="42932">N</st><st c="42933">)</st>
- en: <st c="42934">Eq.</st> <st c="42938">35</st>
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42934">等式</st> <st c="42938">35</st>
- en: '<st c="42940">Now we</st> <st c="42948">have learned the basics of random variables
    and probability distributions, we will describe in detail some of the most common
    distributions you will encounter as a data scientist.</st> <st c="43128">These
    are the distributions you will make extensive use of in your career as a data
    scientist.</st> <st c="43223">We divide our descriptions into two obvious categories:
    descriptions of discrete-valued distributions and descriptions of</st> <st c="43345">continuous-valued
    distributions.</st>'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42940">现在我们</st> <st c="42948">已经学习了随机变量和概率分布的基础知识，接下来我们将详细描述一些你作为数据科学家最常遇到的分布。</st>
    <st c="43128">这些是你在数据科学家职业生涯中会广泛使用的分布。</st> <st c="43223">我们将描述分为两个明显的类别：离散值分布的描述和</st>
    <st c="43345">连续值分布的描述。</st>
- en: <st c="43377">Named distributions</st>
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="43377">命名分布</st>
- en: <st c="43397">There are a</st> <st c="43410">few distributions that we encounter
    a lot as data scientists.</st> <st c="43472">These are the distributions that
    have characteristics that match the sort of data we encounter in real-world datasets,
    so it is unsurprising that we should use these common distributions when analyzing
    real data or when building predictive models.</st> <st c="43720">For that reason,
    it is worth understanding these distributions in a little more detail.</st> <st
    c="43808">We will go into that</st> <st c="43829">detail now.</st>
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43397">有一些</st> <st c="43410">我们作为数据科学家经常遇到的分布。</st> <st c="43472">这些分布具有与我们在真实数据集中遇到的数据特征相匹配的特点，因此，在分析真实数据或构建预测模型时，使用这些常见分布并不令人惊讶。</st>
    <st c="43720">因此，值得更详细地了解这些分布。</st> <st c="43808">我们现在将深入探讨这些细节。</st>
- en: <st c="43840">Discrete distributions</st>
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="43840">离散分布</st>
- en: <st c="43863">We’ll start with</st> <st c="43881">some of the most important</st>
    <st c="43907">named</st> <st c="43914">discrete distributions.</st>
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43863">我们将从</st> <st c="43881">一些最重要的</st> <st c="43907">命名</st> <st
    c="43914">离散分布开始。</st>
- en: <st c="43937">The Bernoulli distribution</st>
  id: totrans-226
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <st c="43937">伯努利分布</st>
- en: <st c="43964">We</st> <st c="43968">already met the Bernoulli distribution</st>
    <st c="44006">when we first introduced random variables.</st> <st c="44050">However,
    we can calculate some of its key properties with what we have learned since then.</st>
    <st c="44141">You’ll recall that a Bernoulli random variable has two outcomes,
    0 and 1\.</st> <st c="44215">If</st> <st c="44218">X</st> <st c="44219">~</st>
    <st c="44220">Bernoulli</st><st c="44229">(</st><st c="44231">p</st><st c="44232">)</st>
    <st c="44233">and we draw an observation, then</st> <st c="44267">Prob</st><st
    c="44271">(</st><st c="44273">X</st> <st c="44274">=</st> <st c="44275">0</st><st
    c="44276">)</st> <st c="44277">=</st> <st c="44278">(</st><st c="44279">1</st>
    <st c="44280">−</st> <st c="44281">p</st><st c="44282">)</st> <st c="44283">,</st>
    <st c="44284">Prob</st><st c="44288">(</st><st c="44290">X</st> <st c="44291">=</st>
    <st c="44292">1</st><st c="44293">)</st> <st c="44294">=</st> <st c="44295">p</st><st
    c="44296">. The mean of the Bernoulli distribution is then calculated</st> <st
    c="44356">as follows:</st>
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43964">我们</st> <st c="43968">在首次介绍随机变量时已经遇到过伯努利分布。</st> <st c="44006">然而，我们可以利用从那时起所学到的知识来计算它的一些关键属性。</st>
    <st c="44141">你会记得，伯努利随机变量有两个结果，0 和 1。</st> <st c="44215">如果</st> <st c="44218">X</st>
    <st c="44219">~</st> <st c="44220">伯努利</st><st c="44229">(</st><st c="44231">p</st><st
    c="44232">)</st> <st c="44233">并且我们进行一次观察，那么</st> <st c="44267">Prob</st><st c="44271">(</st><st
    c="44273">X</st> <st c="44274">=</st> <st c="44275">0</st><st c="44276">)</st>
    <st c="44277">=</st> <st c="44278">(</st><st c="44279">1</st> <st c="44280">−</st>
    <st c="44281">p</st><st c="44282">)</st> <st c="44283">,</st> <st c="44284">Prob</st><st
    c="44288">(</st><st c="44290">X</st> <st c="44291">=</st> <st c="44292">1</st><st
    c="44293">)</st> <st c="44294">=</st> <st c="44295">p</st><st c="44296">。伯努利分布的均值可以通过以下方式计算：</st>
- en: <st c="44367">μ</st> <st c="44369">=</st> <st c="44370">∑</st><st c="44371">x</st><st
    c="44372">x</st> <st c="44373">p</st><st c="44374">(</st><st c="44375">x</st><st
    c="44376">)</st> <st c="44377">=</st> <st c="44378">[</st><st c="44379">0</st>
    <st c="44380">×</st> <st c="44381">(</st><st c="44382">1</st> <st c="44383">−</st>
    <st c="44384">p</st><st c="44385">)</st><st c="44386">]</st> <st c="44387">+</st>
    <st c="44388">[</st><st c="44389">1</st> <st c="44390">×</st> <st c="44391">p</st><st
    c="44392">]</st> <st c="44393">=</st> <st c="44394">p</st>
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44367">μ</st> <st c="44369">=</st> <st c="44370">∑</st><st c="44371">x</st><st
    c="44372">x</st> <st c="44373">p</st><st c="44374">(</st><st c="44375">x</st><st
    c="44376">)</st> <st c="44377">=</st> <st c="44378">[</st><st c="44379">0</st>
    <st c="44380">×</st> <st c="44381">(</st><st c="44382">1</st> <st c="44383">−</st>
    <st c="44384">p</st><st c="44385">)</st><st c="44386">]</st> <st c="44387">+</st>
    <st c="44388">[</st><st c="44389">1</st> <st c="44390">×</st> <st c="44391">p</st><st
    c="44392">]</st> <st c="44393">=</st> <st c="44394">p</st>
- en: <st c="44395">Eq.</st> <st c="44399">36</st>
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44395">方程</st> <st c="44399">36</st>
- en: <st c="44401">Similarly, the variance is calculated</st> <st c="44440">as follows:</st>
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44401">类似地，方差的计算公式为</st> <st c="44440">如下：</st>
- en: <st c="44451">σ</st><st c="44453">2</st> <st c="44454">=</st> <st c="44455">∑</st><st
    c="44456">x</st><st c="44457">(</st><st c="44458">x</st><st c="44459">−</st> <st
    c="44460">μ</st><st c="44461">)</st><st c="44462">2</st> <st c="44463">p</st><st
    c="44464">(</st><st c="44465">x</st><st c="44466">)</st> <st c="44467">=</st>
    <st c="44468">[</st><st c="44469">(</st><st c="44470">0</st> <st c="44471">−</st>
    <st c="44472">p</st><st c="44473">)</st><st c="44474">2</st> <st c="44475">×</st>
    <st c="44476">(</st><st c="44477">1</st> <st c="44478">−</st> <st c="44479">p</st><st
    c="44480">)</st><st c="44481">]</st><st c="44482">+</st> <st c="44483">[</st><st
    c="44484">(</st><st c="44485">1</st> <st c="44486">−</st> <st c="44487">p</st><st
    c="44488">)</st><st c="44489">2</st> <st c="44490">×</st> <st c="44491">p</st><st
    c="44492">]</st> <st c="44493">=</st> <st c="44494">p</st><st c="44495">(</st><st
    c="44496">1</st> <st c="44497">−</st> <st c="44498">p</st><st c="44499">)</st>
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44451">σ</st><st c="44453">2</st> <st c="44454">=</st> <st c="44455">∑</st><st
    c="44456">x</st><st c="44457">(</st><st c="44458">x</st><st c="44459">−</st> <st
    c="44460">μ</st><st c="44461">)</st><st c="44462">2</st> <st c="44463">p</st><st
    c="44464">(</st><st c="44465">x</st><st c="44466">)</st> <st c="44467">=</st>
    <st c="44468">[</st><st c="44469">(</st><st c="44470">0</st> <st c="44471">−</st>
    <st c="44472">p</st><st c="44473">)</st><st c="44474">2</st> <st c="44475">×</st>
    <st c="44476">(</st><st c="44477">1</st> <st c="44478">−</st> <st c="44479">p</st><st
    c="44480">)</st><st c="44481">]</st><st c="44482">+</st> <st c="44483">[</st><st
    c="44484">(</st><st c="44485">1</st> <st c="44486">−</st> <st c="44487">p</st><st
    c="44488">)</st><st c="44489">2</st> <st c="44490">×</st> <st c="44491">p</st><st
    c="44492">]</st> <st c="44493">=</st> <st c="44494">p</st><st c="44495">(</st><st
    c="44496">1</st> <st c="44497">−</st> <st c="44498">p</st><st c="44499">)</st>
- en: <st c="44500">Eq.</st> <st c="44504">37</st>
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44500">方程</st> <st c="44504">37</st>
- en: <st c="44506">Note the symmetry in the expression for the variance.</st> <st
    c="44561">If we swapped</st> <st c="44575">p</st> <st c="44576">for</st> <st c="44581">(</st><st
    c="44582">1</st> <st c="44583">−</st> <st c="44584">p</st><st c="44585">)</st>
    <st c="44586">and vice versa, we would get the same expression.</st> <st c="44637">This
    is because the choice of how we encode outcomes is arbitrary; that is, it is our
    subjective choice whether we use 1/0 or 0/1 to represent success/failure, and
    so certain properties of the distribution will be invariant to our choice of encoding.</st>
    <st c="44888">Switching from an encoding of 1/0 to 0/1 would obviously lead to
    us swapping the values</st> <st c="44976">p</st> <st c="44977">and</st> <st c="44982">(</st><st
    c="44983">1</st> <st c="44984">−</st> <st c="44985">p</st><st c="44986">)</st><st
    c="44987">.</st>
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44506">注意方差表达式中的对称性。</st> <st c="44561">如果我们将</st> <st c="44575">p</st>
    <st c="44576">替换为</st> <st c="44581">(</st><st c="44582">1</st> <st c="44583">−</st>
    <st c="44584">p</st><st c="44585">)</st> <st c="44586">并且反过来，我们会得到相同的表达式。</st>
    <st c="44637">这是因为我们选择如何编码结果是任意的；也就是说，成功/失败的表示方式（1/0 或 0/1）是我们的主观选择，因此分布的某些属性对于我们的编码选择是恒定不变的。</st>
    <st c="44888">从 1/0 编码切换到 0/1 编码显然会导致我们交换</st> <st c="44976">p</st> <st c="44977">和</st>
    <st c="44982">(</st><st c="44983">1</st> <st c="44984">−</st> <st c="44985">p</st><st
    c="44986">)</st><st c="44987">的值。</st>
- en: <st c="44988">The binomial distribution</st>
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <st c="44988">二项分布</st>
- en: <st c="45014">Obviously, a</st> <st c="45028">Bernoulli random variable</st>
    <st c="45053">can be used to model data where we have two possible outcomes, such
    as whether a user clicked a button on an e-commerce website or whether a shopper
    bought a particular product.</st> <st c="45232">However, in a real-world situation,
    we are more interested in how many items we sell in total or how many website
    users in total click the button.</st> <st c="45379">Each individual choice to
    click or choice to buy is a Bernoulli random variable, but what is the distribution
    of</st> <st c="45492">their sum?</st>
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="45014">显然，</st> <st c="45028">伯努利随机变量</st> <st c="45053">可以用来建模具有两个可能结果的数据，例如用户是否点击了电子商务网站上的按钮，或者购物者是否购买了某个特定产品。</st>
    <st c="45232">然而，在现实情况下，我们更关心的是我们总共售出了多少商品，或者有多少网站用户点击了按钮。</st> <st c="45379">每一个单独的点击选择或购买选择都是一个伯努利随机变量，但它们的和的分布是什么？</st>
- en: <st c="45502">Imagine we</st> <st c="45513">have</st> <st c="45519">N</st> <st
    c="45520">shoppers, each deciding to buy or not, so we can model each shopper
    choice as a Bernoulli random variable,</st> <st c="45628">X</st><st c="45629">i</st>
    <st c="45630">,</st> <st c="45631">i</st> <st c="45632">=</st> <st c="45633">1</st><st
    c="45634">,</st> <st c="45635">⋯</st> <st c="45636">,</st> <st c="45637">N</st><st
    c="45638">. For simplicity, we will assume that the shoppers are all similar so
    that the probability that any shopper makes a purchase is the same; that is,</st>
    <st c="45785">p</st><st c="45786">. This means</st> <st c="45799">X</st><st c="45800">i</st>
    <st c="45801">~</st> <st c="45802">Bernoulli</st><st c="45811">(</st><st c="45813">p</st><st
    c="45814">)</st> <st c="45815">for all values of</st> <st c="45834">i</st> <st
    c="45835">=</st> <st c="45836">1,2</st><st c="45839">,</st> <st c="45840">⋯</st>
    <st c="45841">,</st> <st c="45842">N</st><st c="45843">. Each of these random
    variables has</st> <st c="45880">the same distribution.</st> <st c="45903">Note
    this doesn’t mean they are all the same random variable, nor does it mean that
    all shoppers are making the same choice.</st> <st c="46028">It just means the
    distribution of possible outcomes is the same for each shopper.</st> <st c="46110">We
    consider this to be a reasonable assumption for our problem because our shoppers
    are all similar in other characteristics, and so we might expect them to have
    a similar level of preference for the shopping item we are modeling.</st> <st
    c="46341">When we have a set of random variables that all follow the same distribution,
    we say they are</st> **<st c="46435">identically distributed</st>** <st c="46458">(</st>**<st
    c="46460">i.d.</st>**<st c="46464">).</st> <st c="46468">If the</st> <st c="46474">random
    variables are also</st> **<st c="46501">independent</st>** <st c="46512">of each
    other, (in this case, that means the choice of one shopper does</st> <st c="46585">not
    have an influence on the choice of another shopper), then we say the random variables
    are</st> **<st c="46679">independently and identically distributed</st>**<st c="46720">,
    or</st> **<st c="46725">i.i.d</st>**<st c="46730">.</st> <st c="46732">for short.</st>
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="45502">假设我们</st> <st c="45513">有</st> <st c="45519">N</st> <st c="45520">个购物者，每个购物者决定是否购买，因此我们可以将每个购物者的选择建模为一个伯努利随机变量，</st>
    <st c="45628">X</st><st c="45629">i</st> <st c="45630">，</st> <st c="45631">i</st>
    <st c="45632">=</st> <st c="45633">1</st><st c="45634">，</st> <st c="45635">⋯</st>
    <st c="45636">，</st> <st c="45637">N</st><st c="45638">。为了简化问题，我们假设所有购物者相似，因此任何一个购物者购买的概率是相同的；即，</st>
    <st c="45785">p</st><st c="45786">。这意味着</st> <st c="45799">X</st><st c="45800">i</st>
    <st c="45801">~</st> <st c="45802">伯努利</st><st c="45811">(</st><st c="45813">p</st><st
    c="45814">)</st> <st c="45815">对于所有值的</st> <st c="45834">i</st> <st c="45835">=</st>
    <st c="45836">1,2</st><st c="45839">，</st> <st c="45840">⋯</st> <st c="45841">，</st>
    <st c="45842">N</st><st c="45843">。这些随机变量中的每一个都有</st> <st c="45880">相同的分布。</st>
    <st c="45903">请注意，这并不意味着它们都是相同的随机变量，也不意味着所有购物者都做出相同的选择。</st> <st c="46028">这只是意味着每个购物者的可能结果分布是相同的。</st>
    <st c="46110">我们认为这是一个合理的假设，因为我们的购物者在其他特征上都很相似，因此我们可能会期望他们对我们建模的购物商品有类似的偏好。</st>
    <st c="46341">当我们有一组遵循相同分布的随机变量时，我们称它们是</st> **<st c="46435">同分布</st>** <st c="46458">(</st>**<st
    c="46460">i.d.</st>**<st c="46464">)。</st> <st c="46468">如果这些随机变量彼此</st> **<st
    c="46501">独立</st>** <st c="46512">，（在这种情况下，意味着一个购物者的选择</st> <st c="46585">不会影响另一个购物者的选择），那么我们称这些随机变量是</st>
    **<st c="46679">独立同分布</st>**<st c="46720">，或</st> **<st c="46725">i.i.d</st>**<st
    c="46730">。</st> <st c="46732">简称为。</st>
- en: <st c="46742">Now, what we are interested in is the total number of items sold.</st>
    <st c="46809">This is</st> <st c="46817">S</st> <st c="46818">=</st> <st c="46819">X</st><st
    c="46820">1</st><st c="46821">+</st> <st c="46822">X</st><st c="46823">2</st><st
    c="46824">+</st> <st c="46825">⋯</st> <st c="46826">+</st> <st c="46827">X</st><st
    c="46828">N</st><st c="46829">. What is the distribution of</st> <st c="46859">S</st><st
    c="46860">? Well, let’s use</st> <st c="46878">n</st> <st c="46879">to represent
    the actual number of units sold and consider one particular set of outcomes that
    would give us</st> <st c="46988">n</st> <st c="46989">=</st> <st c="46990">4</st>
    <st c="46991">items sold when we had</st> <st c="47015">N</st> <st c="47016">=</st>
    <st c="47017">10</st> <st c="47019">shoppers.</st> <st c="47030">The seque</st><st
    c="47039">nce in</st> *<st c="47047">Figure 2</st>**<st c="47055">.7</st>* <st
    c="47057">shows one such set</st> <st c="47077">of outcomes:</st>
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="46742">现在，我们关心的是总共售出的商品数量。</st> <st c="46809">这就是</st> <st c="46817">S</st>
    <st c="46818">=</st> <st c="46819">X</st><st c="46820">1</st><st c="46821">+</st>
    <st c="46822">X</st><st c="46823">2</st><st c="46824">+</st> <st c="46825">⋯</st>
    <st c="46826">+</st> <st c="46827">X</st><st c="46828">N</st><st c="46829">。那么，</st>
    <st c="46859">S</st><st c="46860">的分布是怎样的？</st> <st c="46879">我们用</st> <st c="46878">n</st>
    <st c="46879">表示实际售出的商品数量，并考虑一种特定的结果集，当我们有</st> <st c="46988">n</st> <st c="46989">=</st>
    <st c="46990">4</st> <st c="46991">件商品售出时，</st> <st c="47015">N</st> <st c="47016">=</st>
    <st c="47017">10</st> <st c="47019">个购物者。</st> <st c="47030">下面的</st><st c="47039">序列</st>
    *<st c="47047">图 2.7</st>* <st c="47055">显示了这样的一个结果集：</st>
- en: '![Figure 2.7: Outcomes from a sequence of 10 Bernoulli trials with their corresponding
    probabilities below](img/B19496_02_08.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7：一组由 10 次伯努利试验组成的结果，下面是它们对应的概率](img/B19496_02_08.jpg)'
- en: '<st c="47197">Figure 2.7: Outcomes from a sequence of 10 Bernoulli trials with
    their corresponding probabilities below</st>'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="47197">图 2.7：一组由 10 次伯努利试验组成的结果，下面是它们对应的概率</st>
- en: <st c="47301">Here, we have used</st> *<st c="47321">Yes</st>* <st c="47324">to
    indicate a shopper purchased the item and</st> *<st c="47370">No</st>* <st c="47372">to
    indicate that they didn’t.</st> <st c="47403">What is the probability of this
    outcome?</st> <st c="47444">Since the random variables are independent of each
    other, we can multiply their individual outcome probabilities together, as shown
    in the lower row of</st> *<st c="47596">Figure 2</st>**<st c="47604">.7</st>*<st
    c="47606">. So, the probability of this particular pattern is</st> <st c="47658">p</st><st
    c="47659">4</st> <st c="47660">(</st><st c="47661">1</st> <st c="47662">−</st>
    <st c="47663">p</st><st c="47664">)</st><st c="47665">6</st><st c="47666">. Now,
    you may have spotted that the reason we got a factor of</st> <st c="47729">p</st><st
    c="47730">4</st> <st c="47731">in that result was because four shoppers bought
    the item, but it didn’t matter which four.</st> <st c="47823">So, another but
    different pattern with four shoppers buying the item would also have a probability
    of occurring of</st> <st c="47938">p</st><st c="47939">4</st> <st c="47940">(</st><st
    c="47941">1</st> <st c="47942">−</st> <st c="47943">p</st><st c="47944">)</st><st
    c="47945">6</st><st c="47946">. To find the total probability of</st> <st c="47981">n</st>
    <st c="47982">=</st> <st c="47983">4</st> <st c="47984">items sold in a set of
    ten shoppers, we just need to find how many patterns of ten shoppers we</st> <st
    c="48079">can have where there are four</st> <st c="48109">shoppers who buy.</st>
    <st c="48128">In other words, how many ways can we distribute the</st> <st c="48180">n</st>
    <st c="48181">=</st> <st c="48182">4</st> <st c="48183">successes among</st> <st
    c="48200">N</st> <st c="48201">=</st> <st c="48202">10</st> <st c="48204">attempts
    (trials)?</st> <st c="48224">This is the binomial coefficient</st> <st c="48257">(</st><st
    c="48258">10</st><st c="48260">4</st><st c="48262">)</st> <st c="48263">that we
    recapped in</st> [*<st c="48284">Chapter 1</st>*](B19496_01.xhtml#_idTextAnchor014)<st
    c="48293">. So, the overall probability of four items being bought by ten shoppers
    is</st> <st c="48369">(</st><st c="48370">10</st><st c="48372">4</st><st c="48374">)</st>
    <st c="48375">p</st><st c="48376">4</st> <st c="48377">(</st><st c="48378">1</st>
    <st c="48379">−</st> <st c="48380">p</st><st c="48381">)</st><st c="48382">6</st>
    <st c="48383">. It is straightforward to generalize to</st> <st c="48424">N</st>
    <st c="48425">shoppers and</st> <st c="48439">n</st> <st c="48440">items bought,
    to get the probability of</st> <st c="48481">n</st> <st c="48482">items bought</st>
    <st c="48496">as follows:</st>
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了*<st c="47321">是</st>*<st c="47324">来表示顾客购买了该商品，而</st>*<st c="47370">否</st>*<st
    c="47372">表示顾客没有购买。</st> <st c="47403">这个结果的概率是多少？</st> <st c="47444">由于随机变量是彼此独立的，我们可以将它们各自的结果概率相乘，如下行所示</st>*<st
    c="47596">图 2</st>**<st c="47604">.7</st>*<st c="47606">。因此，这种特定模式的概率是</st> <st
    c="47658">p</st><st c="47659">4</st> <st c="47660">(</st><st c="47661">1</st>
    <st c="47662">−</st> <st c="47663">p</st><st c="47664">)</st><st c="47665">6</st><st
    c="47666">。现在，你可能已经注意到，我们在结果中得到了</st> <st c="47729">p</st><st c="47730">4</st>
    <st c="47731">的因素，是因为四个顾客购买了商品，但哪个四个顾客并不重要。</st> <st c="47823">因此，另一个但不同的模式，四个顾客购买该商品的概率也是</st>
    <st c="47938">p</st><st c="47939">4</st> <st c="47940">(</st><st c="47941">1</st>
    <st c="47942">−</st> <st c="47943">p</st><st c="47944">)</st><st c="47945">6</st><st
    c="47946">。要找到在十个顾客中卖出</st> <st c="47981">n</st> <st c="47982">=</st> <st c="47983">4</st>
    <st c="47984">个商品的总概率，我们只需要找出十个顾客中有四个购买商品的模式数。</st> <st c="48079">换句话说，我们要找到如何在</st>
    <st c="48180">n</st> <st c="48181">=</st> <st c="48182">4</st> <st c="48183">次成功尝试中，分配给</st>
    <st c="48200">N</st> <st c="48201">=</st> <st c="48202">10</st> <st c="48204">次尝试（试验）的方法有多少种？</st>
    <st c="48224">这就是二项式系数</st> <st c="48257">(</st><st c="48258">10</st><st c="48260">4</st><st
    c="48262">)</st> <st c="48263">，我们在</st> [*<st c="48284">第1章</st>*](B19496_01.xhtml#_idTextAnchor014)<st
    c="48293">中回顾过。<st c="48369">因此，四个商品被十个顾客购买的整体概率是</st> <st c="48369">(</st><st
    c="48370">10</st><st c="48372">4</st><st c="48374">)</st> <st c="48375">p</st><st
    c="48376">4</st> <st c="48377">(</st><st c="48378">1</st> <st c="48379">−</st>
    <st c="48380">p</st><st c="48381">)</st><st c="48382">6</st> <st c="48383">。我们可以轻松地将其推广到</st>
    <st c="48424">N</st> <st c="48425">个顾客和</st> <st c="48439">n</st> <st c="48440">个购买商品的情况，从而得到</st>
    <st c="48481">n</st> <st c="48482">个商品被购买的概率如下：</st>
- en: <st c="48507">Prob</st><st c="48512">(</st><st c="48514">S</st> <st c="48515">=</st>
    <st c="48516">n</st><st c="48517">)</st> <st c="48518">=</st> <st c="48519">(</st><st
    c="48520">N</st><st c="48521">n</st><st c="48522">)</st> <st c="48523">p</st><st
    c="48524">n</st> <st c="48525">(</st><st c="48526">1</st> <st c="48527">−</st>
    <st c="48528">p</st><st c="48529">)</st><st c="48530">N</st><st c="48531">−</st><st
    c="48532">n</st>
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48507">Prob</st><st c="48512">(</st><st c="48514">S</st> <st c="48515">=</st>
    <st c="48516">n</st><st c="48517">)</st> <st c="48518">=</st> <st c="48519">(</st><st
    c="48520">N</st><st c="48521">n</st><st c="48522">)</st> <st c="48523">p</st><st
    c="48524">n</st> <st c="48525">(</st><st c="48526">1</st> <st c="48527">−</st>
    <st c="48528">p</st><st c="48529">)</st><st c="48530">N</st><st c="48531">−</st><st
    c="48532">n</st>
- en: <st c="48533">Eq.</st> <st c="48537">38</st>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48533">公式</st> <st c="48537">38</st>
- en: <st c="48539">This is the</st> **<st c="48552">binomial distribution</st>**<st
    c="48573">. It is the distribution of the sum of</st> <st c="48612">N</st> <st
    c="48613">i.i.d.</st> <st c="48621">Bernoulli random variables (or trials) each
    with success probability</st> <st c="48690">p</st><st c="48691">. Notice that
    the probability</st> <st c="48721">Prob</st><st c="48725">(</st><st c="48727">n</st><st
    c="48728">)</st> <st c="48729">depends upon two quantities or parameters:</st>
    <st c="48773">N</st> <st c="48774">and</st> <st c="48779">p</st><st c="48780">.
    When we write that a random variable has a binomial distribution, we write</st>
    <st c="48857">Binomial</st><st c="48865">(</st><st c="48867">N</st><st c="48868">,</st>
    <st c="48869">p</st><st c="48870">)</st> <st c="48871">or</st> <st c="48875">Binom</st><st
    c="48880">(</st><st c="48882">N</st><st c="48883">,</st> <st c="48884">p</st><st
    c="48885">)</st><st c="48886">. In our example, the total number of items sold,</st>
    <st c="48936">S</st><st c="48937">, has a binomial distribution, so we would write</st>
    <st c="48986">S</st> <st c="48987">~</st> <st c="48988">Binomial</st><st c="48996">(</st><st
    c="48998">N</st><st c="48999">,</st> <st c="49000">p</st><st c="49001">)</st><st
    c="49002">. In a modern e-commerce setting where we potentially have tens of millions
    of visitors to a website,</st> <st c="49104">N</st> <st c="49105">can be very,</st>
    <st c="49119">very big.</st>
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48539">这是</st> **<st c="48552">二项分布</st>**<st c="48573">。它是</st> <st
    c="48612">N</st> <st c="48613">个独立同分布（i.i.d.）的伯努利随机变量（或实验）的和，每个变量的成功概率为</st> <st
    c="48690">p</st><st c="48691">。注意，概率</st> <st c="48721">Prob</st><st c="48725">(</st><st
    c="48727">n</st><st c="48728">)</st> <st c="48729">取决于两个量或参数：</st> <st c="48773">N</st>
    <st c="48774">和</st> <st c="48779">p</st><st c="48780">。当我们写一个随机变量服从二项分布时，我们写作</st>
    <st c="48857">Binomial</st><st c="48865">(</st><st c="48867">N</st><st c="48868">,</st>
    <st c="48869">p</st><st c="48870">)</st> <st c="48871">或</st> <st c="48875">Binom</st><st
    c="48880">(</st><st c="48882">N</st><st c="48883">,</st> <st c="48884">p</st><st
    c="48885">)</st><st c="48886">。在我们的例子中，总销售量</st> <st c="48936">S</st><st c="48937">服从二项分布，因此我们会写作</st>
    <st c="48986">S</st> <st c="48987">~</st> <st c="48988">Binomial</st><st c="48996">(</st><st
    c="48998">N</st><st c="48999">,</st> <st c="49000">p</st><st c="49001">)</st><st
    c="49002">。在现代电子商务环境中，我们可能会有数千万的访客访问一个网站，</st> <st c="49104">N</st> <st c="49105">可能非常</st>
    <st c="49119">大。</st>
- en: <st c="49128">Now we have derived the probabilities of the binomial distribution,
    we can calculate some of its characteristics, such as its mean</st> <st c="49260">and
    variance:</st>
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49128">现在我们已经推导出了二项分布的概率，我们可以计算其一些特征，比如它的均值</st> <st c="49260">和方差：</st>
- en: <st c="49273">Mean</st> <st c="49278">=</st> <st c="49280">μ</st> <st c="49281">=</st>
    <st c="49282">∑</st><st c="49283">n</st><st c="49284">=</st><st c="49285">0</st><st
    c="49286">N</st><st c="49287">(</st><st c="49288">N</st><st c="49289">n</st><st
    c="49290">)</st> <st c="49291">n</st> <st c="49292">p</st><st c="49293">n</st>
    <st c="49294">(</st><st c="49295">1</st> <st c="49296">−</st> <st c="49297">p</st><st
    c="49298">)</st><st c="49299">N</st><st c="49300">−</st><st c="49301">n</st> <st
    c="49302">=</st> <st c="49303">Np</st>
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49273">均值</st> <st c="49278">=</st> <st c="49280">μ</st> <st c="49281">=</st>
    <st c="49282">∑</st><st c="49283">n</st><st c="49284">=</st><st c="49285">0</st><st
    c="49286">N</st><st c="49287">(</st><st c="49288">N</st><st c="49289">n</st><st
    c="49290">)</st> <st c="49291">n</st> <st c="49292">p</st><st c="49293">n</st>
    <st c="49294">(</st><st c="49295">1</st> <st c="49296">−</st> <st c="49297">p</st><st
    c="49298">)</st><st c="49299">N</st><st c="49300">−</st><st c="49301">n</st> <st
    c="49302">=</st> <st c="49303">Np</st>
- en: <st c="49305">Eq.</st> <st c="49310">39</st>
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49305">公式</st> <st c="49310">39</st>
- en: <st c="49312">Variance</st> <st c="49321">=</st> <st c="49323">σ</st><st c="49324">2</st>
    <st c="49325">=</st> <st c="49326">∑</st><st c="49327">n</st><st c="49328">=</st><st
    c="49329">0</st><st c="49330">N</st><st c="49331">(</st><st c="49332">N</st><st
    c="49333">n</st><st c="49334">)</st> <st c="49335">(</st><st c="49336">n</st>
    <st c="49337">−</st> <st c="49338">Np</st><st c="49340">)</st><st c="49342">2</st>
    <st c="49343">p</st><st c="49344">n</st> <st c="49345">(</st><st c="49346">1</st>
    <st c="49347">−</st> <st c="49348">p</st><st c="49349">)</st><st c="49350">N</st><st
    c="49351">−</st><st c="49352">n</st> <st c="49353">=</st> <st c="49354">Np</st><st
    c="49356">(</st><st c="49358">1</st> <st c="49359">−</st> <st c="49360">p</st><st
    c="49361">)</st>
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49312">方差</st> <st c="49321">=</st> <st c="49323">σ</st><st c="49324">2</st>
    <st c="49325">=</st> <st c="49326">∑</st><st c="49327">n</st><st c="49328">=</st><st
    c="49329">0</st><st c="49330">N</st><st c="49331">(</st><st c="49332">N</st><st
    c="49333">n</st><st c="49334">)</st> <st c="49335">(</st><st c="49336">n</st>
    <st c="49337">−</st> <st c="49338">Np</st><st c="49340">)</st><st c="49342">2</st>
    <st c="49343">p</st><st c="49344">n</st> <st c="49345">(</st><st c="49346">1</st>
    <st c="49347">−</st> <st c="49348">p</st><st c="49349">)</st><st c="49350">N</st><st
    c="49351">−</st><st c="49352">n</st> <st c="49353">=</st> <st c="49354">Np</st><st
    c="49356">(</st><st c="49358">1</st> <st c="49359">−</st> <st c="49360">p</st><st
    c="49361">)</st>
- en: <st c="49362">Eq.</st> <st c="49366">40</st>
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49362">方程</st> <st c="49366">40</st>
- en: <st c="49368">So, to summarize, for a binomial distribution the mean is</st>
    <st c="49427">Np</st> <st c="49429">and the variance is</st> <st c="49450">Np</st><st
    c="49452">(</st><st c="49454">1</st> <st c="49455">−</st> <st c="49456">p</st><st
    c="49457">)</st><st c="49458">. These results can be derived very simply.</st>
    <st c="49502">Since we know what the mean and variance of a</st> <st c="49548">Bernoulli</st><st
    c="49557">(</st><st c="49559">p</st><st c="49560">)</st> <st c="49561">random
    variable is, and our total</st> <st c="49596">S</st> <st c="49597">=</st> <st
    c="49598">X</st><st c="49599">1</st> <st c="49600">+</st> <st c="49601">X</st><st
    c="49602">2</st> <st c="49603">+</st> <st c="49604">⋯</st> <st c="49605">+</st>
    <st c="49606">X</st><st c="49607">N</st> <st c="49608">is just a sum of i.i.d.</st>
    <st c="49633">Bernoulli</st><st c="49642">(</st><st c="49644">p</st><st c="49645">)</st>
    <st c="49646">random variables, we can just use the results in</st> *<st c="49696">Eq.</st>
    <st c="49700">32</st>* <st c="49702">and</st> *<st c="49707">Eq.</st> <st c="49711">34</st>*
    <st c="49713">to derive them – see if you can do this</st> <st c="49754">for yourself.</st>
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49368">因此，总结一下，对于二项分布，均值为</st> <st c="49427">Np</st> <st c="49429">，方差为</st>
    <st c="49450">Np</st><st c="49452">(</st><st c="49454">1</st> <st c="49455">−</st>
    <st c="49456">p</st><st c="49457">)</st><st c="49458">。这些结果可以很简单地推导出来。</st> <st
    c="49502">因为我们知道一个</st> <st c="49548">伯努利</st><st c="49557">(</st><st c="49559">p</st><st
    c="49560">)</st> <st c="49561">随机变量的均值和方差，并且我们的总和</st> <st c="49596">S</st> <st
    c="49597">=</st> <st c="49598">X</st><st c="49599">1</st> <st c="49600">+</st>
    <st c="49601">X</st><st c="49602">2</st> <st c="49603">+</st> <st c="49604">⋯</st>
    <st c="49605">+</st> <st c="49606">X</st><st c="49607">N</st> <st c="49608">只是i.i.d.的</st>
    <st c="49633">伯努利</st><st c="49642">(</st><st c="49644">p</st><st c="49645">)</st>
    <st c="49646">随机变量的和，我们可以直接使用</st> *<st c="49696">方程</st> <st c="49700">32</st>*
    <st c="49702">和</st> *<st c="49707">方程</st> <st c="49711">34</st>* <st c="49713">中的结果来推导它们——看看你是否能自己做到这一点。</st>
- en: <st c="49767">The Poisson distribution</st>
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <st c="49767">泊松分布</st>
- en: <st c="49792">For</st> <st c="49797">the binomial distribution, we were</st>
    <st c="49832">interested in the distribution of the total number of successes
    when performing</st> <st c="49912">N</st> <st c="49913">independent trials.</st>
    <st c="49934">Another situation where we may be interested in looking at the distribution
    of counts of something is when we want to count how many occurrences of something
    we get within, say, a given time interval or within a given area.</st> <st c="50158">For
    example, continuing our e-commerce example, we may be interested in the number
    of items sold within an hour.</st> <st c="50271">If we make the simplest possible
    assumption that the average rate of sale is constant, then the distribution of
    the number of actual items sold is a</st> **<st c="50420">Poisson</st>** <st c="50427">distribution.</st>
    <st c="50442">The Poisson distribution is a discrete distribution – it tells us
    how counts (that is, integer values) are distributed.</st> <st c="50562">The possible
    outcome,</st> <st c="50584">k</st><st c="50585">, can be</st> <st c="50594">0,1</st><st
    c="50597">,</st> <st c="50598">…</st> <st c="50599">,</st> <st c="50600">∞</st><st
    c="50601">. The probabilities of those outco</st><st c="50635">mes are given by
    the</st> <st c="50657">following formula:</st>
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49792">对于</st> <st c="49797">二项分布，我们关注的是在进行</st> <st c="49912">N</st>
    <st c="49913">次独立试验时成功总次数的分布。</st> <st c="49934">另一种我们可能对某些计数分布感兴趣的情况是，当我们想要统计某个事物在特定时间区间或特定区域内的发生次数时。</st>
    <st c="50158">例如，继续我们电商的例子，我们可能对在一小时内售出的商品数量感兴趣。</st> <st c="50271">如果我们做出最简单的假设，即销售的平均速率是恒定的，那么实际售出的商品数量的分布就是**泊松**分布。</st>
    <st c="50442">泊松分布是一种离散分布——它告诉我们计数（即整数值）是如何分布的。</st> <st c="50562">可能的结果</st>，<st
    c="50584">k</st><st c="50585">，可以是</st> <st c="50594">0,1</st><st c="50597">,…</st>
    <st c="50599">,</st> <st c="50600">∞</st><st c="50601">。这些结果的概率由以下公式给出：</st>
- en: <st c="50675">Prob</st><st c="50680">(</st><st c="50682">k</st><st c="50683">)</st>
    <st c="50684">=</st> <st c="50685">λ</st><st c="50686">k</st> <st c="50687">e</st><st
    c="50688">−</st><st c="50689">λ</st><st c="50690">_</st><st c="50691">k</st> <st
    c="50692">!</st>
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="50675">Prob</st><st c="50680">(</st><st c="50682">k</st><st c="50683">)</st>
    <st c="50684">=</st> <st c="50685">λ</st><st c="50686">k</st> <st c="50687">e</st><st
    c="50688">−</st><st c="50689">λ</st><st c="50690">_</st><st c="50691">k</st> <st
    c="50692">!</st>
- en: <st c="50693">Eq.</st> <st c="50697">41</st>
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="50693">公式</st> <st c="50697">41</st>
- en: <st c="50699">Here,</st> <st c="50706">λ</st> <st c="50707">is the mean outcome
    value, so it is the constant rate that formed our starting assumption.</st> <st
    c="50799">There are two things to highlight about</st> <st c="50839">λ</st><st
    c="50840">. Firstly,</st> <st c="50851">λ</st> <st c="50852">can be a non-integer
    even though the Poisson distribution is a distribution of integer counts.</st>
    <st c="50948">For example, if</st> <st c="50964">λ</st> <st c="50965">=</st> <st
    c="50966">3.4</st> <st c="50969">in our e-commerce example, it means we sell on
    average 3.4 items per hour.</st> <st c="51045">The actual number of items sold
    in any hour period will be an integer; for example, 2, 3, or 4 items.</st> <st
    c="51147">The second thing to highlight about</st> <st c="51183">λ</st> <st c="51184">is
    that it is the only parameter that is in</st> *<st c="51229">Eq.</st> <st c="51233">41</st>*<st
    c="51235">. This implies that the variance of the Poisson distribution will be
    some function of</st> <st c="51321">λ</st><st c="51322">. Likewise, other characteristics
    such as the skewness and the kurtosis.</st> <st c="51395">The variance of the
    Poisson distribution is easily calculated and turns out to also be</st> <st c="51482">λ</st><st
    c="51483">. To recap, that means that if</st> <st c="51514">X</st> <st c="51515">~</st>
    <st c="51516">Poisson</st><st c="51523">(</st><st c="51525">λ</st><st c="51526">)</st><st
    c="51527">, then the</st> <st c="51538">following applies:</st>
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="50699">在这里，</st> <st c="50706">λ</st> <st c="50707">是均值，所以它是形成我们起始假设的常数速率。</st>
    <st c="50799">关于</st> <st c="50839">λ</st><st c="50840">，有两点需要强调。首先，</st> <st
    c="50851">λ</st> <st c="50852">可以是非整数，尽管 Poisson 分布是整数计数的分布。</st> <st c="50948">例如，在我们的电子商务例子中，如果</st>
    <st c="50964">λ</st> <st c="50965">=</st> <st c="50966">3.4</st> <st c="50969">，这意味着我们平均每小时售出
    3.4 件商品。</st> <st c="51045">在任何一个小时内，实际售出的商品数量将是整数；例如，2、3 或 4 件。</st> <st c="51147">第二点需要强调的是，</st>
    <st c="51183">λ</st> <st c="51184">是唯一出现在</st> *<st c="51229">公式 41</st>*<st c="51233">中的参数</st><st
    c="51235">。这意味着 Poisson 分布的方差将是 λ 的某个函数。</st> <st c="51321">同样，其他特征，如偏度和峰度。</st>
    <st c="51395">Poisson 分布的方差可以轻松计算，并且结果也是</st> <st c="51482">λ</st><st c="51483">。总结来说，这意味着如果</st>
    <st c="51514">X</st> <st c="51515">~</st> <st c="51516">Poisson</st><st c="51523">(</st><st
    c="51525">λ</st><st c="51526">)</st><st c="51527">，那么以下公式成立：</st>
- en: <st c="51556">𝔼</st><st c="51559">(</st><st c="51561">X</st><st c="51562">)</st>
    <st c="51563">=</st> <st c="51564">λ</st> <st c="51565">and Var</st><st c="51573">(</st><st
    c="51575">X</st><st c="51576">)</st> <st c="51577">=</st> <st c="51578">λ</st>
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="51556">𝔼</st><st c="51559">(</st><st c="51561">X</st><st c="51562">)</st>
    <st c="51563">=</st> <st c="51564">λ</st> <st c="51565">和 Var</st><st c="51573">(</st><st
    c="51575">X</st><st c="51576">)</st> <st c="51577">=</st> <st c="51578">λ</st>
- en: <st c="51579">Eq.</st> <st c="51583">42</st>
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="51579">公式</st> <st c="51583">42</st>
- en: <st c="51585">An immediate implication of this is that if the mean of a Poisson
    random variable is increased, then so does its variance and so does its standard
    deviation.</st> <st c="51744">As the bulk of a Poisson distribution</st> <st c="51781">is
    shifted to the right, then it also spreads out.</st> *<st c="51833">Figure 2</st>**<st
    c="51841">.8</st>* <st c="51843">shows two examples of a Poisson distribution.</st>
    <st c="51890">The left-hand plot is for</st> <st c="51916">λ</st> <st c="51917">=</st>
    <st c="51918">2.5</st><st c="51921">, while the right-hand plot is for</st> <st
    c="51956">λ</st> <st c="51957">=</st> <st c="51958">7.5</st><st c="51961">. We
    can see from the right-hand plot that more of the distribution</st> <st c="52028">is
    at higher values, but it</st> <st c="52057">is also more spread out compared to
    the</st> <st c="52097">left-hand plot:</st>
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="51585">这一点的直接影响是，如果 Poisson 随机变量的均值增加，那么它的方差和标准差也会增加。</st> <st c="51744">随着
    Poisson 分布的大部分</st> <st c="51781">被向右偏移，分布也会变得更加分散。</st> *<st c="51833">图 2</st>**<st
    c="51841">.8</st>* <st c="51843">展示了 Poisson 分布的两个示例。</st> <st c="51890">左侧的图是</st>
    <st c="51916">λ</st> <st c="51917">=</st> <st c="51918">2.5</st><st c="51921">，而右侧的图是</st>
    <st c="51956">λ</st> <st c="51957">=</st> <st c="51958">7.5</st><st c="51961">。我们可以从右侧的图中看到，分布的更多部分位于较高的数值，但它也比左侧的图更为分散：</st>
- en: '![Figure 2.8: Two examples of a Poisson distribution with different means](img/B19496_02_09.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.8：具有不同均值的 Poisson 分布的两个示例](img/B19496_02_09.jpg)'
- en: '<st c="52213">Figure 2.8: Two examples of a Poisson distribution with different
    means</st>'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="52213">图 2.8：具有不同均值的 Poisson 分布的两个示例</st>
- en: <st c="52284">Continuous distributions</st>
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="52284">连续分布</st>
- en: <st c="52309">Now, we’ll</st> <st c="52321">introduce some of the most important
    named</st> <st c="52364">continuous distributions.</st>
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="52309">现在，我们将</st> <st c="52321">介绍一些最重要的命名</st> <st c="52364">连续分布。</st>
- en: <st c="52389">The uniform distribution</st>
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <st c="52389">均匀分布</st>
- en: <st c="52414">The</st> <st c="52419">uniform distribution is a continuous distribution.</st>
    <st c="52470">It has a</st> <st c="52479">minimum possible outcome value (let’s
    call that</st> <st c="52527">a</st><st c="52528">) and a maximum possible outcome
    value (let’s call that</st> <st c="52584">b</st><st c="52585">).</st> <st c="52588">By
    definition, the probability of getting an outcome smaller than</st> <st c="52654">a</st>
    <st c="52655">or an outcome larger than</st> <st c="52682">b</st> <st c="52683">is
    zero.</st> <st c="52693">As the name suggests, in between</st> <st c="52726">a</st>
    <st c="52727">and</st> <st c="52732">b</st> <st c="52733">the probability of getting
    any outcome is the same; that is, the probability is uniform between</st> <st
    c="52830">a</st> <st c="52831">and</st> <st c="52836">b</st><st c="52837">. Consequently,
    the uniform distribution is a two-parameter distribution, meaning once we know
    the</st> <st c="52935">two parameters</st> <st c="52951">a</st> <st c="52952">and</st>
    <st c="52957">b</st><st c="52958">, we know everything there is to know about
    it.</st> <st c="53006">If a random variable</st> <st c="53027">X</st> <st c="53028">is
    distributed according to a uniform distribution between</st> <st c="53088">a</st>
    <st c="53089">and</st> <st c="53094">b</st><st c="53095">, we write</st> <st c="53106">X</st><st
    c="53107">~</st> <st c="53108">Uniform</st><st c="53115">(</st><st c="53117">a</st><st
    c="53118">,</st> <st c="53119">b</st><st c="53120">)</st> <st c="53121">or using
    a shorthand notation,</st> <st c="53153">X</st> <st c="53154">~</st> <st c="53155">U</st><st
    c="53156">(</st><st c="53157">a</st><st c="53158">,</st> <st c="53159">b</st><st
    c="53160">)</st><st c="53161">. The PDF,</st> <st c="53172">f</st><st c="53173">(</st><st
    c="53174">x</st><st c="53175">)</st><st c="53176">, is given by</st> <st c="53190">the
    following:</st>
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="52414">均匀分布是一种连续分布。</st> <st c="52470">它有一个</st> <st c="52479">最小可能结果值（我们称之为</st>
    <st c="52527">a</st><st c="52528">）和一个最大可能结果值（我们称之为</st> <st c="52584">b</st><st
    c="52585">）。</st> <st c="52588">根据定义，得到小于</st> <st c="52654">a</st> <st c="52655">或大于</st>
    <st c="52682">b</st> <st c="52683">的结果的概率为零。</st> <st c="52693">正如名称所示，在</st>
    <st c="52726">a</st> <st c="52727">和</st> <st c="52732">b</st> <st c="52733">之间，获得任何结果的概率是相同的；也就是说，概率在</st>
    <st c="52830">a</st> <st c="52831">和</st> <st c="52836">b</st><st c="52837">之间是均匀的。</st>
    <st c="52935">因此，均匀分布是一个双参数分布，这意味着一旦我们知道</st> <st c="52951">两个参数</st> <st c="52952">a</st>
    <st c="52957">和</st> <st c="52958">b</st><st c="52959">，我们就知道了它的所有信息。</st> <st
    c="53006">如果一个随机变量</st> <st c="53027">X</st> <st c="53028">按照均匀分布分布在</st> <st
    c="53088">a</st> <st c="53089">和</st> <st c="53094">b</st><st c="53095">之间，我们写作</st>
    <st c="53106">X</st><st c="53107">~</st> <st c="53108">Uniform</st><st c="53115">(</st><st
    c="53117">a</st><st c="53118">,</st> <st c="53119">b</st><st c="53120">)</st>
    <st c="53121">或者使用简写表示法，</st> <st c="53153">X</st> <st c="53154">~</st> <st c="53155">U</st><st
    c="53156">(</st><st c="53157">a</st><st c="53158">,</st> <st c="53159">b</st><st
    c="53160">)</st><st c="53161">。其概率密度函数（PDF），</st> <st c="53172">f</st><st c="53173">(</st><st
    c="53174">x</st><st c="53175">)</st><st c="53176">，由以下公式给出：</st>
- en: <st c="53204">f</st><st c="53206">(</st><st c="53207">x</st><st c="53208">)</st>
    <st c="53209">=</st> <st c="53210">1</st><st c="53211">_</st><st c="53212">b</st>
    <st c="53213">−</st> <st c="53214">a</st> <st c="53215">for</st> <st c="53220">a</st>
    <st c="53221">≤</st> <st c="53222">x</st> <st c="53223">≤</st> <st c="53224">b</st>
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53204">f</st><st c="53206">(</st><st c="53207">x</st><st c="53208">)</st>
    <st c="53209">=</st> <st c="53210">1</st><st c="53211">_</st><st c="53212">b</st>
    <st c="53213">−</st> <st c="53214">a</st> <st c="53215">当</st> <st c="53220">a</st>
    <st c="53221">≤</st> <st c="53222">x</st> <st c="53223">≤</st> <st c="53224">b</st>
- en: <st c="53225">Eq.</st> <st c="53229">43</st>
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53225">公式</st> <st c="53229">43</st>
- en: <st c="53231">This</st> <st c="53236">follows simply from the need to have the
    probabilities of all possible outcomes add up to 1\.</st> <st c="53330">The mean
    and variance are also easily calculated using high</st> <st c="53390">school math:</st>
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53231">这</st> <st c="53236">只是因为所有可能结果的概率总和必须等于1\。</st> <st c="53330">均值和方差也可以通过高</st>
    <st c="53390">中数学轻松计算：</st>
- en: <st c="53402">𝔼</st><st c="53405">(</st><st c="53407">X</st><st c="53408">)</st>
    <st c="53409">=</st> <st c="53410">1</st><st c="53411">_</st><st c="53412">2</st>
    <st c="53413">(</st><st c="53414">a</st> <st c="53415">+</st> <st c="53416">b</st><st
    c="53417">)</st> <st c="53418">Var</st><st c="53421">(</st><st c="53423">X</st><st
    c="53424">)</st> <st c="53425">=</st> <st c="53426">1</st><st c="53427">_</st><st
    c="53428">12</st> <st c="53430">(</st><st c="53432">b</st> <st c="53433">−</st>
    <st c="53434">a</st><st c="53435">)</st><st c="53436">2</st>
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 𝔼(X) = 1/2 (a + b) 方差(X) = 1/12 (b − a)²
- en: <st c="53437">Eq.</st> <st c="53441">44</st>
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 44
- en: <st c="53443">The uniform distribution may look like it is a bit boring, but
    in practical terms, it forms the building block when we want to generate example
    random data from other distributions, so it is a distribution worth</st> <st c="53656">knowing
    about.</st>
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 均匀分布看起来可能有点单调，但从实际应用角度来看，它在我们想从其他分布生成随机数据时是一个构建模块，因此它是一个值得了解的分布。
- en: <st c="53670">The Gaussian distribution</st>
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 高斯分布
- en: <st c="53696">The</st> <st c="53700">Gaussian distribution is a two-parameter</st>
    <st c="53742">continuous distribution, so its density function is characterized
    by two parameters – in this case, its mean</st> <st c="53851">μ</st> <st c="53852">and
    its variance</st> <st c="53870">σ</st><st c="53871">2</st><st c="53872">. The
    formula for its PDF is</st> <st c="53901">given next:</st>
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯分布是一个具有两个参数的连续分布，因此它的密度函数由两个参数表示——在本例中，它的均值**μ**和方差**σ**²。它的概率密度函数（PDF）公式如下所示：
- en: <st c="53912">f</st><st c="53914">(</st><st c="53915">x</st><st c="53916">)</st>
    <st c="53917">=</st> <st c="53918">1</st><st c="53919">_</st><st c="53920">√</st><st
    c="53921">_</st><st c="53922">2</st><st c="53923">π</st> <st c="53924">σ</st><st
    c="53925">2</st> <st c="53926">exp</st><st c="53929">(</st><st c="53931">−</st>
    <st c="53932">1</st><st c="53933">_</st><st c="53934">2</st><st c="53935">(</st><st
    c="53936">x</st><st c="53937">−</st> <st c="53938">μ</st><st c="53939">_</st><st
    c="53940">σ</st><st c="53941">)</st><st c="53942">2</st><st c="53943">)</st>
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: f(x) = 1/√(2πσ²) exp(−(x−μ)² / 2σ²)
- en: <st c="53944">Eq.</st> <st c="53948">45</st>
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 45
- en: <st c="53950">A plot of the</st> <st c="53964">density function for</st> <st
    c="53986">μ</st> <st c="53987">=</st> <st c="53988">0</st><st c="53989">,</st>
    <st c="53990">σ</st> <st c="53991">=</st> <st c="53992">1</st> <st c="53993">is
    shown in</st> *<st c="54006">Figure 2</st>**<st c="54014">.9</st>*<st c="54016">:</st>
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是均值**μ** = 0，方差**σ** = 1时的密度函数图示，见*图2.9*：
- en: '![Figure 2.9: The probability density of the standard normal distribution](img/B19496_02_10.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9：标准正态分布的概率密度](img/B19496_02_10.jpg)'
- en: '<st c="54068">Figure 2.9: The probability density of the standard normal distribution</st>'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9：标准正态分布的概率密度
- en: <st c="54139">As the</st> <st c="54147">shape of the density function</st> <st
    c="54176">resembles a bell, the Gaussian distribution is sometimes called the
    bell-curve distribution.</st> <st c="54270">However, it is more commonly referred
    to as the normal distribution, so much so that if</st> <st c="54358">X</st> <st
    c="54359">is a Gaussian random variable, we write</st> <st c="54400">X</st> <st
    c="54401">~</st> <st c="54402">Normal</st><st c="54408">(</st><st c="54410">μ</st><st
    c="54411">,</st> <st c="54412">σ</st><st c="54413">2</st><st c="54414">)</st><st
    c="54415">. This notation also highlights that the distribution depends on the
    two parameters</st> <st c="54499">μ</st> <st c="54500">and</st> <st c="54505">σ</st><st
    c="54506">2</st><st c="54507">. A warning – sometimes you will also see some authors
    write</st> <st c="54568">X</st> <st c="54569">~</st> <st c="54570">Normal</st><st
    c="54576">(</st><st c="54578">μ</st><st c="54579">,</st> <st c="54580">σ</st><st
    c="54581">)</st><st c="54582">, meaning that the value they are giving as the
    second argument is the standard deviation, not the variance.</st> <st c="54691">However,
    whether you are given</st> <st c="54722">σ</st> <st c="54723">or</st> <st c="54727">σ</st><st
    c="54728">2</st><st c="54729">, the density is always given by the formula in</st>
    *<st c="54777">Eq.</st> <st c="54781">45</st>*<st c="54783">.</st>
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="54139">由于</st> <st c="54147">密度函数的形状</st> <st c="54176">像钟形曲线，故高斯分布有时被称为钟形曲线分布。</st>
    <st c="54270">然而，它更常被称为正态分布，以至于如果</st> <st c="54358">X</st> <st c="54359">是一个高斯随机变量，我们写作</st>
    <st c="54400">X</st> <st c="54401">~</st> <st c="54402">Normal</st><st c="54408">(</st><st
    c="54410">μ</st><st c="54411">,</st> <st c="54412">σ</st><st c="54413">2</st><st
    c="54414">)</st><st c="54415">。这个符号也强调了分布依赖于两个参数</st> <st c="54499">μ</st> <st
    c="54500">和</st> <st c="54505">σ</st><st c="54506">2</st><st c="54507">。一个警告—有时你也会看到一些作者写作</st>
    <st c="54568">X</st> <st c="54569">~</st> <st c="54570">Normal</st><st c="54576">(</st><st
    c="54578">μ</st><st c="54579">,</st> <st c="54580">σ</st><st c="54581">)</st><st
    c="54582">，意味着他们所给出的第二个参数是标准差，而不是方差。</st> <st c="54691">然而，无论是给定</st> <st c="54722">σ</st>
    <st c="54723">还是</st> <st c="54727">σ</st><st c="54728">2</st><st c="54729">，密度总是通过</st>
    *<st c="54777">公式</st> <st c="54781">45</st>*<st c="54783">给出的。</st>
- en: <st c="54784">Why are we interested in the Gaussian distribution?</st> <st c="54837">The
    Gaussian distribution is probably the most common distribution you will encounter
    as a data scientist.</st> <st c="54944">Many natural processes produce data that
    follow a Gaussian distribution, and so many datasets you will analyze will be
    best modeled as Gaussian random variables.</st> <st c="55106">There are some very
    natural reasons for this, which we will touch upon at the end of</st> <st c="55191">this
    chapter.</st>
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="54784">为什么我们对高斯分布感兴趣？</st> <st c="54837">高斯分布可能是数据科学家最常遇到的分布。</st> <st
    c="54944">许多自然过程生成的数据遵循高斯分布，因此你将分析的许多数据集最好被建模为高斯随机变量。</st> <st c="55106">对此有一些非常自然的原因，我们将在</st>
    <st c="55191">本章末尾进行讨论。</st>
- en: <st c="55204">From the rules applying to linear transformations of random variables,
    we know that if we have Gaussian random variable</st> <st c="55325">X</st> <st
    c="55326">~</st> <st c="55327">Normal</st><st c="55333">(</st><st c="55335">μ</st><st
    c="55336">,</st> <st c="55337">σ</st><st c="55338">2</st><st c="55339">)</st>
    <st c="55340">and we construct a new random variable</st> <st c="55380">Y</st>
    <st c="55381">=</st> <st c="55382">X</st><st c="55383">−</st> <st c="55384">μ</st><st
    c="55385">_</st><st c="55386">σ</st><st c="55387">, then</st> <st c="55394">Y</st><st
    c="55395">~</st><st c="55396">Normal</st><st c="55402">(</st><st c="55404">0</st><st
    c="55405">,</st> <st c="55406">1</st><st c="55407">)</st><st c="55408">. What
    this means is that we can understand the properties of any Gaussian random variable
    by understanding the behavior of the distribution</st> <st c="55549">Normal</st><st
    c="55555">(</st><st c="55557">0</st><st c="55558">,</st> <st c="55559">1</st><st
    c="55560">)</st><st c="55561">. Given the central importance of the Gaussian distribution,
    this makes the distribution</st> <st c="55650">Normal</st><st c="55656">(</st><st
    c="55658">0</st><st c="55659">,</st> <st c="55660">1</st><st c="55661">)</st>
    <st c="55662">a key distribution in its own right, and it has its own special
    name – it is</st> <st c="55740">called the</st> **<st c="55751">standard</st>**
    <st c="55759">normal distribution, reflecting the fact it has standardized values
    for the mean and variance.</st> <st c="55855">The values</st> <st c="55866">μ</st>
    <st c="55867">=</st> <st c="55868">0</st> <st c="55869">and</st> <st c="55874">σ</st><st
    c="55875">2</st> <st c="55876">=</st> <st c="55877">1</st> <st c="55878">also
    have their own special names.</st> <st c="55914">We refer to these values</st>
    <st c="55939">as</st> **<st c="55942">zero mean and unit variance</st>**<st c="55969">,
    with unit meaning a</st> <st c="55990">value of 1 here.</st> <st c="56008">So,
    the standard normal distribution is a normal distribution with zero mean and</st>
    <st c="56089">unit variance.</st>
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="55204">从适用于随机变量线性变换的规则中，我们知道如果我们有高斯随机变量</st> <st c="55325">X</st> <st
    c="55326">~</st> <st c="55327">正态</st><st c="55333">(</st><st c="55335">μ</st><st
    c="55336">,</st> <st c="55337">σ</st><st c="55338">2</st><st c="55339">)</st>
    <st c="55340">且我们构造一个新的随机变量</st> <st c="55380">Y</st> <st c="55381">=</st> <st
    c="55382">X</st><st c="55383">−</st> <st c="55384">μ</st><st c="55385">_</st><st
    c="55386">σ</st><st c="55387">，那么</st> <st c="55394">Y</st><st c="55395">~</st><st
    c="55396">正态</st><st c="55402">(</st><st c="55404">0</st><st c="55405">,</st>
    <st c="55406">1</st><st c="55407">)</st><st c="55408">。这意味着我们可以通过理解分布</st> <st
    c="55549">正态</st><st c="55555">(</st><st c="55557">0</st><st c="55558">,</st>
    <st c="55559">1</st><st c="55560">)</st><st c="55561">的行为来理解任何高斯随机变量的属性。</st>
    <st c="55650">鉴于高斯分布的重要性，这使得分布</st><st c="55656">正态</st><st c="55658">(</st><st
    c="55659">0</st><st c="55660">,</st> <st c="55661">1</st><st c="55662">)</st>
    <st c="55662">本身成为一个关键分布，并且它有一个特别的名称——它被称为**标准**正态分布，反映了它具有标准化的均值和方差。</st> <st
    c="55855">这些值</st> <st c="55866">μ</st> <st c="55867">=</st> <st c="55868">0</st>
    <st c="55869">和</st> <st c="55874">σ</st><st c="55875">2</st> <st c="55876">=</st>
    <st c="55877">1</st> <st c="55878">也有它们自己的特殊名称。</st> <st c="55914">我们称这些值为</st>
    <st c="55939">**零均值和单位方差**</st><st c="55969">，其中单位表示这里的值为1。</st> <st c="56008">因此，标准正态分布是一个均值为零且</st>
    <st c="56089">方差为单位的正态分布。</st>
- en: <st c="56103">Phew!</st> <st c="56110">That</st> <st c="56115">was a long section.</st>
    <st c="56135">But it will be worth it.</st> <st c="56160">Data underpins everything
    in data science, and all data contains a random component, so learning the basics
    about how we use math to describe and handle randomness will pay big dividends.</st>
    <st c="56348">For now, though, let’s do a short recap of what we learned in</st>
    <st c="56410">this section.</st>
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="56103">呼！</st> <st c="56110">这一节</st> <st c="56115">确实很长。</st> <st c="56135">但这将是值得的。</st>
    <st c="56160">数据是数据科学的基础，所有数据都包含随机成分，因此学习如何使用数学来描述和处理随机性将带来巨大的回报。</st> <st c="56348">不过，暂时让我们快速回顾一下我们在</st>
    <st c="56410">这一节学到的内容。</st>
- en: <st c="56423">What we learned</st>
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="56423">我们学到的内容</st>
- en: <st c="56439">In this section, we have learned</st> <st c="56473">the following:</st>
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="56439">在这一节中，我们学到了</st> <st c="56473">以下内容：</st>
- en: <st c="56487">Random variables are the natural math concept to describe randomness.</st>
    <st c="56558">Probability distributions give the probabilities of possible outcomes
    of a discrete random variable, while PDFs perform a similar role for continuous</st>
    <st c="56708">random variables.</st>
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="56487">随机变量是描述随机性的自然数学概念。</st> <st c="56558">概率分布给出了离散随机变量可能结果的概率，而概率密度函数（PDF）则对连续随机变量起着类似的作用。</st>
    <st c="56708">随机变量。</st>
- en: <st c="56725">Probability distributions and random variables can be characterized
    by their mean and variance, and other characteristics such as their skewness</st>
    <st c="56871">and kurtosis.</st>
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="56725">概率分布和随机变量可以通过它们的均值和方差以及其他特征（如偏度</st> <st c="56871">和峰度）来表征。</st>
- en: <st c="56884">How to transform and combine random variables and how to calculate
    the mean and variance of</st> <st c="56977">transformed quantities.</st>
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="56884">如何变换和组合随机变量，以及如何计算变换后量的均值和方差。</st>
- en: <st c="57000">The details of the most important discrete and continuous probability
    distributions we will encounter in</st> <st c="57106">data science.</st>
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="57000">我们将在数据科学中遇到的最重要的离散和连续概率分布的详细内容。</st>
- en: <st c="57119">Now we have learned about the basics of random variables and probability
    distributions, we are going to learn in the next section how datasets are generated
    from</st> <st c="57282">probability distributions.</st>
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="57119">现在我们已经了解了随机变量和概率分布的基础知识，接下来我们将学习如何从</st> <st c="57282">概率分布中生成数据集。</st>
- en: <st c="57308">Sampling from distributions</st>
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="57308">从分布中采样</st>
- en: <st c="57336">So far, we’ve learned a lot about random variables, probability
    distributions, and how to calculate some of the key characteristics of a distribution
    such as its mean and variance, and we’ve learned about some commonly occurring
    distributions.</st> <st c="57581">But so far, it doesn’t feel like we’ve learned
    much about data.</st> <st c="57645">We’ll now</st> <st c="57655">change that.</st>
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="57336">到目前为止，我们已经学到了很多关于随机变量、概率分布的内容，以及如何计算分布的某些关键特征，如其均值和方差，我们还学习了一些常见的分布。</st>
    <st c="57581">但到目前为止，我们似乎还没有学到太多关于数据的知识。</st> <st c="57645">现在我们将</st> <st c="57655">改变这一点。</st>
- en: <st c="57667">How datasets relate to random variables and probability distributions</st>
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="57667">数据集如何与随机变量和概率分布相关</st>
- en: <st c="57737">We</st> <st c="57740">said at the beginning of this chapter that
    all data is random.</st> <st c="57804">This means when data is captured or generated,
    we are drawing or</st> **<st c="57869">sampling</st>** <st c="57877">values from
    some underlying probabil</st><st c="57914">ity distribution.</st> <st c="57933">This
    is illustrated schematically in</st> *<st c="57970">Figure 2</st>**<st c="57978">.10</st>*<st
    c="57981">:</st>
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="57737">我们</st> <st c="57740">在本章开始时提到过，所有数据都是随机的。</st> <st c="57804">这意味着，当数据被捕获或生成时，我们是在从某个潜在的概率分布中抽取或</st>
    **<st c="57869">采样</st>** <st c="57877">值。</st><st c="57914">这在图示中得到了说明</st> *<st
    c="57970">图 2.10</st>*<st c="57978">：</st>
- en: '![Figure 2.10: Diagram illustrating how real data is generated as samples from
    a population](img/B19496_02_11.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.10：说明如何从总体生成实际数据作为样本的图示](img/B19496_02_11.jpg)'
- en: '<st c="58309">Figure 2.10: Diagram illustrating how real data is generated
    as samples from a population</st>'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="58309">图 2.10：说明如何从总体生成实际数据作为样本的图示</st>
- en: <st c="58398">A sample is finite.</st> <st c="58419">It represents a snapshot
    or subset of the entirety of possible outcomes; for example, a subset of all users
    who might visit a website.</st> <st c="58554">But from a business perspective,
    it is the behavior of the collection of all users I want to understand.</st> <st
    c="58659">When we analyze a dataset, what we really want to understand are the
    characteristics of the underlying distribution that we think the data has come
    from.</st> <st c="58813">We call this underlying</st> <st c="58837">distribution
    the</st> **<st c="58854">population</st>** <st c="58864">distribution.</st>
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="58398">一个样本是有限的。</st> <st c="58419">它代表了所有可能结果的一个快照或子集；例如，所有可能访问网站的用户的子集。</st>
    <st c="58554">但从商业角度来看，我想要理解的是所有用户的行为。</st> <st c="58659">当我们分析一个数据集时，实际上我们想要了解的是我们认为数据来源于的潜在分布的特征。</st>
    <st c="58813">我们将这种潜在的</st> <st c="58837">分布称为</st> **<st c="58854">总体</st>**
    <st c="58864">分布。</st>
- en: <st c="58878">Unfortunately, the underlying population distribution from which
    a dataset is generated is usually hidden from us.</st> <st c="58994">Instead,
    we use the sampled data as a proxy for the underlying population and use the summary
    characteristics of the sample as proxies for their population counterparts.</st>
    <st c="59164">Due to randomness, no sample is a perfect copy of the underlying
    population distribution from which it was taken.</st> <st c="59278">Consequently,
    different samples (datasets) taken from the same population can have different
    characteristics.</st> <st c="59388">This is</st> <st c="59396">called</st> **<st
    c="59403">sampling variation</st>** <st c="59421">and can lead us to different
    conclusions if we don’t know how to correctly account for this randomness inherent
    in any sample.</st> <st c="59549">Alternatively, an individual dataset can give
    misleading conclusions about the underlying population if we analyze it naively
    and aren’t aware of the random nature of the data.</st> <st c="59726">This is
    why we have spent a lot of effort on understanding randomness, random variables,
    and</st> <st c="59819">distributions and why we consider this to be the most important
    chapter in</st> <st c="59894">the book.</st>
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="58878">不幸的是，通常我们无法得知生成数据集的基础人口分布。</st> <st c="58994">相反，我们使用采样数据作为基础人口的代理，并使用样本的汇总特征作为其人口对应特征的代理。</st>
    <st c="59164">由于随机性，任何样本都不是其来源基础人口分布的完美复制。</st> <st c="59278">因此，从同一人口中抽取的不同样本（数据集）可能具有不同的特征。</st>
    <st c="59388">这就是</st> <st c="59396">所谓的</st> **<st c="59403">抽样变异</st>** <st
    c="59421">，如果我们不知道如何正确地考虑样本中固有的随机性，这可能会导致我们得出不同的结论。</st> <st c="59549">另外，如果我们天真地分析某个数据集，而没有意识到数据的随机性，那么它可能会给出关于基础人口的误导性结论。</st>
    <st c="59726">这就是为什么我们花费了大量精力来理解随机性、随机变量和</st> <st c="59819">分布，并且为什么我们认为这一章是</st>
    <st c="59894">本书中最重要的章节。</st>
- en: <st c="59903">Take my e-commerce example.</st> <st c="59932">I want to understand
    what the</st> **<st c="59962">click-through-rate</st>** <st c="59980">(</st>**<st
    c="59982">CTR</st>**<st c="59985">) of a</st> <st c="59993">particular advertisement
    design is.</st> <st c="60029">I want to understand what proportion of the 10 million
    visitors I get to the website each year will click the ad.</st> <st c="60143">So,
    I track 20 visitors to the website, see whether they click or not, and find 12
    of them did.</st> <st c="60239">That CTR of 12/20 = 60% may be good enough for
    my business model to succeed, so I go away with the intention of using that ad
    design for all website visitors.</st> <st c="60398">However, the CTR of all 10
    million visitors can be very, very different from the CTR of 60% of those 20 people
    I tracked.</st> <st c="60520">Those 20 people are human beings, and humans have
    their own quirks and idiosyncrasies and so have a degree of randomness to their
    click behavior.</st> <st c="60666">Those 20 people we tracked are a sample of
    the 10 million – a very small sample.</st> <st c="60747">And we have seen that
    when we take a sample – when we draw each of their click behaviors from a Bernoulli
    click/no-click distribution – then we could get anywhere between 0 and 20 clicks.</st>
    <st c="60935">The true CTR of the 10 million annual visitors – the number I’m
    basing my business decisions on – might be 40%, but I could still see a CTR in
    that sample of 20 people that is anywhere between 0% and 100%.</st> <st c="61141">Suddenly,
    I don’t feel so confident that the sample of 20 people is helping me make good
    business decisions.</st> <st c="61250">What should</st> <st c="61262">we do?</st>
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="59903">以我的电商例子为例。</st> <st c="59932">我想了解某个</st> **<st c="59962">点击率</st>**
    <st c="59980">(</st>**<st c="59982">CTR</st>**<st c="59985">) 是多少，针对某个特定的广告设计。</st>
    <st c="59993">我想了解每年访问网站的1000万访客中，会有多少比例点击该广告。</st> <st c="60143">于是，我追踪了20个访问者，观察他们是否点击广告，结果发现其中12个点击了。</st>
    <st c="60239">这个12/20 = 60%的CTR，可能足以让我的商业模式成功，因此我打算使用这个广告设计来面向所有网站访客。</st> <st
    c="60398">然而，所有1000万访客的CTR可能与我追踪的那20人中的60% CTR相差很大。</st> <st c="60520">这20个人是人类，而人类有自己的怪癖和特征，因此他们的点击行为也有一定的随机性。</st>
    <st c="60666">这20个我们追踪的人只是1000万访客中的一个样本——一个非常小的样本。</st> <st c="60747">我们已经看到，当我们取样时——当我们从一个伯努利点击/不点击分布中抽取每个点击行为时——我们可能得到0到20次点击之间的任何结果。</st>
    <st c="60935">1000万年度访客的真实CTR——我用它来做商业决策的那个数值——可能是40%，但我在这20个样本中看到的CTR却可能在0%到100%之间变化。</st>
    <st c="61141">突然间，我开始对这20个人的样本是否能帮助我做出好的商业决策产生了怀疑。</st> <st c="61250">我们应该怎么办？</st>
- en: <st c="61268">This is where math comes to our rescue.</st> <st c="61309">Our
    inferences about the CTR of all 10 million website visitors have some randomness
    or uncertainty within them.</st> <st c="61422">Using our knowledge of distributions,
    we can quantify that uncertainty and so control the level of risk associated with
    our inferences and decisions.</st> <st c="61572">We are taking the situation sho</st><st
    c="61603">wn in</st> *<st c="61610">Figure 2</st>**<st c="61618">.10</st>* <st
    c="61621">and closing the loop, as illustrated in</st> *<st c="61662">Figure 2</st>**<st
    c="61670">.11</st>*<st c="61673">:</st>
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="61268">这就是数学派上用场的时候。</st> <st c="61309">我们对所有 1000 万网站访问者的点击率（CTR）的推断中存在一定的随机性或不确定性。</st>
    <st c="61422">通过利用我们对分布的知识，我们可以量化这种不确定性，从而控制与我们的推断和决策相关的风险水平。</st> <st c="61572">我们正在处理的情况如</st><st
    c="61603">图</st> *<st c="61610">2.10</st>* <st c="61618">所示</st>，并将其闭合，正如在</st>
    *<st c="61662">图 2.11</st>* <st c="61670">中所示：</st>
- en: '![Figure 2.11: Diagram illustrating how we close the loop and use knowledge
    of probability distributions to go from samples back to making inferences about
    the underlying population](img/B19496_02_12.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.11：图示说明了我们如何闭合循环，并利用概率分布的知识从样本推断出潜在的总体](img/B19496_02_12.jpg)'
- en: '<st c="62275">Figure 2.11: Diagram illustrating how we close the loop and use
    knowledge of probability distributions to go from samples back to making inferences
    about the underlying population</st>'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="62275">图 2.11：图示说明了我们如何闭合循环，并利用概率分布的知识从样本推断出潜在的总体</st>
- en: <st c="62454">How big is the population from which a dataset is sampled?</st>
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="62454">从哪个总体抽样得到数据集，样本的总体有多大？</st>
- en: <st c="62513">In theoretical</st> <st c="62529">situations, we can usually consider
    the population to be of infinite size, meaning that I can obtain finite-sized
    sample datasets from it as big as I want.</st> <st c="62685">In real-world situations,
    the population may also be of finite size due to genuine constraints.</st> <st
    c="62781">For example, in our CTR example, we have 10 million visitors a year
    to the website, so the largest sample I could study in a year would consist of
    10 million people.</st> <st c="62947">Often, even if the true population is of
    finite size, it is so big compared to the typical dataset (sample) we will study
    that we can consider the population to be effectively infinite and ignore the
    finite size implications of the population.</st> <st c="63191">However, I say
    this to point out that sometimes, we can’t ignore the finite size of the population
    from which we are drawing our samples, and so it is always worth thinking about
    this aspect; that is, how big is our sample and how big do we think the population
    is from which the sample</st> <st c="63478">was obtained.</st>
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="62513">在理论情境中，我们通常可以认为总体是无限大的，这意味着我可以从中获取大小为有限的样本数据集，并且可以随意增大样本的规模。</st>
    <st c="62685">在现实情境中，由于实际限制，总体也可能是有限的。</st> <st c="62781">例如，在我们的点击率示例中，我们每年有
    1000 万访客访问该网站，因此我在一年内能够研究的最大样本将包含 1000 万人。</st> <st c="62947">通常，即使真实总体是有限的，与我们将研究的典型数据集（样本）相比，它的规模如此之大，以至于我们可以将总体视为有效的无限大，并忽略总体的有限规模所带来的影响。</st>
    <st c="63191">然而，我这么说是为了指出，有时候我们不能忽略我们抽样所选总体的有限规模，因此总是值得思考这一点；也就是说，我们的样本有多大，以及我们认为样本来自的总体有多大。</st>
- en: <st c="63491">Now we have seen that a dataset can be considered as a sample
    from an underlying probability distribution, we will learn how to generate our
    own samples using snippets of Python code.</st> <st c="63676">We will also learn
    why it is useful to be able to generate our</st> <st c="63739">own samples.</st>
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="63491">现在我们已经了解到，数据集可以视为来自潜在概率分布的样本，我们将学习如何通过 Python 代码片段生成我们自己的样本。</st>
    <st c="63676">我们还将学习为什么能够生成自己的样本是有用的。</st> <st c="63739">生成样本是有用的。</st>
- en: <st c="63751">How to sample</st>
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="63751">如何抽样</st>
- en: <st c="63765">Why is being able to generate a sample useful?</st> <st c="63813">There
    are two</st> <st c="63827">main reasons:</st>
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="63765">为什么能够生成样本是有用的？</st> <st c="63813">有两个</st> <st c="63827">主要原因：</st>
- en: <st c="63840">We can use sampling to create simulated data.</st> <st c="63887">Simulated
    data can be used to test data science algorithms and is particularly useful where
    we don’t have any existing real ground-truth data.</st> <st c="64030">We can use
    the simulation process to generate as much data as we want and where we specify
    what the true underlying parameter values</st> <st c="64163">should be.</st>
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="63840">我们可以使用抽样来创建模拟数据。</st> <st c="63887">模拟数据可以用来测试数据科学算法，特别是在我们没有任何真实的基准数据时，模拟数据尤为有用。</st>
    <st c="64030">我们可以使用模拟过程生成任意数量的数据，并且可以指定真实的潜在参数值</st> <st c="64163">应该是什么。</st>
- en: <st c="64173">Sometimes it is easier to use sampling to approximate a statistical
    calculation, such as the calculation of an expectation value, rather than try
    to calculate the expectation value exactly using rigorous mathematics.</st> <st
    c="64391">Sometimes, we may be dealing with complex data generation processes
    for which exact mathematical evaluation of a mean is just not possible, but it
    is possible to sample from the data generation process.</st> <st c="64594">In
    these situations, we can generate large numbers of samples and use a simple numerical
    average to give us a very accurate approximation of the</st> <st c="64739">population
    mean.</st>
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="64173">有时，使用抽样来近似统计计算，比如计算期望值，可能比试图通过严格的数学方法精确计算期望值更容易。</st> <st c="64391">有时，我们可能在处理复杂的数据生成过程，无法通过精确的数学方法计算均值，但可以从数据生成过程中抽样。</st>
    <st c="64594">在这些情况下，我们可以生成大量的样本，并使用简单的数值平均值来提供对</st> <st c="64739">总体均值</st>的非常准确的近似值。</st>
- en: <st c="64755">Let’s say we</st> <st c="64768">have a binomial distribution</st>
    <st c="64798">N</st> <st c="64799">=</st> <st c="64800">20</st><st c="64802">,</st>
    <st c="64804">p</st> <st c="64805">=</st> <st c="64806">0.6</st><st c="64809">.
    Now, given that information, we can use the formula in</st> *<st c="64866">Eq.</st>
    <st c="64870">38</st>* <st c="64872">to calculate the probability of, say, getting
    a count outcome of</st> <st c="64938">n</st> <st c="64939">=</st> <st c="64940">9</st>
    <st c="64941">or fewer successes.</st> <st c="64962">We find this probability
    is 0.1275\.</st> <st c="64998">This means that if I were to repeatedly sample
    from a Binomial(20, 0.6) distribution, I would expect about 12.75% of the time
    I would get a number 9 or less.</st> <st c="65156">In fact, I can do this calculation
    for all possible values of</st> <st c="65218">n</st><st c="65219">. This calculation
    is easy to do – it just involves cumulatively adding up the probabilities from
    the smallest value of the outcome to the largest value of the outcome.</st> <st
    c="65388">This is illustrated in</st> *<st c="65411">Figure 2</st>**<st c="65419">.12</st>*<st
    c="65422">. The resulting curve is called the</st> **<st c="65458">cumulative
    probability distribution</st>** <st c="65493">(</st>**<st c="65495">CDF</st>**<st
    c="65498">) for</st> <st c="65505">obvious reasons.</st> <st c="65522">The CDF
    for a</st><st c="65535">ny distribution always monotonically increases from 0
    to a maximum</st> <st c="65603">of 1:</st>
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="64755">假设我们</st> <st c="64768">有一个二项分布</st> <st c="64798">N</st> <st
    c="64799">=</st> <st c="64800">20</st><st c="64802">,</st> <st c="64804">p</st>
    <st c="64805">=</st> <st c="64806">0.6</st><st c="64809">。现在，给定这些信息，我们可以使用</st>
    *<st c="64866">公式</st>* <st c="64870">38</st>* <st c="64872">来计算，例如，获得</st> <st
    c="64938">n</st> <st c="64939">=</st> <st c="64940">9</st> <st c="64941">次或更少成功的概率。</st>
    <st c="64962">我们发现这个概率是 0.1275\。</st> <st c="64998">这意味着，如果我不断地从一个二项分布（20, 0.6）中抽样，我预计大约12.75%的时间会得到9次或更少的成功。</st>
    <st c="65156">事实上，我可以对所有可能的</st> <st c="65218">n</st><st c="65219">值进行这样的计算。这个计算很容易做——它只是将从最小值到最大值的概率累加起来。</st>
    <st c="65388">这在</st> *<st c="65411">图 2</st>**<st c="65419">.12</st>*<st c="65422">中进行了说明。得到的曲线被称为</st>
    **<st c="65458">累计概率分布</st>** <st c="65493">(</st>**<st c="65495">CDF</st>**<st
    c="65498">)，</st> <st c="65505">显而易见。</st> <st c="65522">任何分布的CDF总是从0单调增加到最大值</st>
    <st c="65603">1：</st>
- en: '![Figure 2.12: The CDF of the Binomial(20,0.6) distribution](img/B19496_02_13.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.12：二项分布（20,0.6）的累计分布函数（CDF）](img/B19496_02_13.jpg)'
- en: '<st c="65700">Figure 2.12: The CDF of the Binomial(20,0.6) distribution</st>'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="65700">图 2.12：二项分布（20,0.6）的累计分布函数（CDF）</st>
- en: '<st c="65757">Now, let’s</st> <st c="65769">say I draw a number from the uniform
    distribution</st> <st c="65819">U</st><st c="65820">(</st><st c="65821">0,1</st><st
    c="65824">)</st><st c="65826">. The number I get from that uniform distribution
    effectively splits the interval [0,1] into two portions.</st> <st c="65933">Or
    equivalently, it splits the range 0%-100% into two regions.</st> <st c="65996">Let’s
    say the number I got was 0.41, so I’ve split the 0%-100% range into two portions:
    one containing a total probability of 0.41 (or 41%) and the other containing a
    total probability of 0.59 (or 59%).</st> <st c="66199">What I can now do is ask
    what value of</st> <st c="66238">n</st> <st c="66239">in my binomial distribution
    example would give me that same split.</st> <st c="66307">Given the cumulative
    distribution shown in</st> *<st c="66350">Figure 2</st>**<st c="66358">.12</st>*<st
    c="66361">, that is easy to do, and we find we get the same 41%-59% split at</st>
    <st c="66428">n</st> <st c="66429">=</st> <st c="66430">11</st><st c="66432">.
    This is illustrated by the blue horizontal dashed line in the middle of</st> *<st
    c="66506">Figure 2</st>**<st c="66514">.12</st>*<st c="66517">. So, what we now
    have is a method for going from generating uniform random numbers to giving numbers
    drawn from the actual distribution I’m interested in – the Binomial(20,0.6) distribution
    in this example.</st> <st c="66725">Most computer programming languages will provide
    you with an easy way to generate random numbers from</st> <st c="66827">U</st><st
    c="66828">(</st><st c="66829">0,1</st><st c="66832">)</st><st c="66834">. The
    Python code snippet shown next shows how to use the</st> `<st c="66892">numpy</st>`
    <st c="66897">uniform random number generator to do this and shows how to generate
    1,000 Binomial(20, 0.6)</st> <st c="66991">random numbers.</st>'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="65757">现在，假设我从均匀分布</st> <st c="65769">U</st><st c="65770">(</st><st c="65771">0,1</st><st
    c="65774">)</st><st c="65776">中抽取了一个数字。这个数字将均匀分布[0,1]区间有效地分成了两部分。</st> <st c="65933">或者说，它把0%-100%的范围分成了两部分。</st>
    <st c="65996">假设我得到的数字是0.41，那么我把0%-100%的范围分成了两部分：一部分的总概率为0.41（或41%），另一部分的总概率为0.59（或59%）。</st>
    <st c="66199">接下来，我可以询问我的二项分布示例中，什么值的</st> <st c="66238">n</st> <st c="66239">会给我相同的划分。</st>
    <st c="66307">根据在</st> *<st c="66350">图2</st>**<st c="66358">.12</st>*<st c="66361">中展示的累积分布，这很容易实现，结果我们得到了相同的41%-59%的划分，在</st>
    <st c="66428">n</st> <st c="66429">=</st> <st c="66430">11</st><st c="66432">。这一点在</st>
    *<st c="66506">图2</st>**<st c="66514">.12</st>*<st c="66517">的中间通过蓝色的虚线显示出来。因此，现在我们得到了一个方法，可以从生成均匀随机数转变为得到我感兴趣的实际分布中的数字——在这个例子中是Binomial(20,
    0.6)分布。</st> <st c="66725">大多数计算机编程语言会提供一种简便的方法来生成从</st> <st c="66827">U</st><st
    c="66828">(</st><st c="66829">0,1</st><st c="66832">)</st><st c="66834">中抽取的随机数。</st>
    <st c="66892">接下来显示的Python代码片段演示了如何使用</st> `<st c="66892">numpy</st>` <st c="66897">均匀随机数生成器来做到这一点，并展示了如何生成1,000个Binomial(20,
    0.6)</st> <st c="66991">随机数。</st>
- en: <st c="67006">Generating your own random numbers code example</st>
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="67006">生成你自己的随机数代码示例</st>
- en: <st c="67054">A fuller</st> <st c="67064">version of the following code is given
    in the</st> `<st c="67110">Code_Examples_Chap2.ipynb</st>` <st c="67135">Jupyter
    notebook in the</st> <st c="67160">GitHub repository:</st>
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="67054">以下代码的完整版本可以在</st> `<st c="67110">Code_Examples_Chap2.ipynb</st>`
    <st c="67135">Jupyter笔记本中找到，该笔记本位于</st> <st c="67160">GitHub仓库：</st>
- en: '[PRE0]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: <st c="67921">This method</st> <st c="67934">can be applied to any discrete
    distribution.</st> <st c="67979">A modified version can be used to sample from
    continuous distributions, but it can be a</st> <st c="68067">bit harder.</st>
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '<st c="67921">这个方法</st> <st c="67934">可以应用于任何离散分布。</st> <st c="67979">一个修改版的方法可以用来从连续分布中抽样，但它可能会稍微难一点。</st> '
- en: <st c="68078">Okay – now I’m going to let you into a little secret.</st> <st
    c="68133">You don’t have to do any of this.</st> <st c="68167">The specialist
    numerical modules or packages of most modern general-purpose programming languages
    come with in-built methods for sampling from the most common distributions you
    are likely to encounter (and some more obscure ones as well).</st> <st c="68406">We’ll
    now take a brief tour of some of those methods with some bits of example</st>
    <st c="68485">Python code.</st>
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="68078">好吧，现在我将给你透露一个小秘密。</st> <st c="68133">你不必做这些事情。</st> <st c="68167">大多数现代通用编程语言的专业数值模块或包都内置了从你可能遇到的最常见分布中抽样的方法（也包括一些更冷门的分布）。</st>
    <st c="68406">接下来，我们将简要介绍一些这些方法，并展示一些示例</st> <st c="68485">Python代码。</st>
- en: <st c="68497">Sampling from numpy distributions code example</st>
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="68497">来自numpy分布的抽样代码示例</st>
- en: <st c="68544">First, here’s</st> <st c="68559">how to sample from a binomial
    distribution</st> <st c="68602">using</st> `<st c="68608">numpy</st>`<st c="68613">:</st>
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="68544">首先，以下是如何从二项分布中抽样</st> <st c="68559">，使用</st> `<st c="68608">numpy</st>`<st
    c="68613">：</st>
- en: '[PRE1]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: <st c="68784">Second, here’s how to sample from a Poisson distribution</st>
    <st c="68842">using</st> `<st c="68848">numpy</st>`<st c="68853">:</st>
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="68784">其次，以下是如何从泊松分布中抽样</st> <st c="68842">，使用</st> `<st c="68848">numpy</st>`<st
    c="68853">：</st>
- en: '[PRE2]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: <st c="69111">Finally, here’s</st> <st c="69128">how to sample from a Gaussian
    distribution</st> <st c="69171">using</st> `<st c="69177">numpy</st>`<st c="69182">:</st>
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="69111">最后，以下是</st> <st c="69128">如何从高斯分布中抽样</st> <st c="69171">，使用</st>
    `<st c="69177">numpy</st>`<st c="69182">：</st>
- en: '[PRE3]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: <st c="69740">All the</st> <st c="69749">preceding code snippets can be found
    in full in the</st> `<st c="69801">Code_Examples_Chap2.ipynb</st>` <st c="69826">Jupyter
    notebook in the</st> <st c="69851">GitHub repository.</st>
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="69740">所有</st> <st c="69749">前面的代码片段可以在</st> `<st c="69801">Code_Examples_Chap2.ipynb</st>`
    <st c="69826">Jupyter notebook中找到，位于</st> <st c="69851">GitHub 仓库中。</st>
- en: <st c="69869">That code example is a good place to end this shorter section,
    so let’s summarize what we have learned about generating our own</st> <st c="69998">random
    data.</st>
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="69869">这个代码示例是结束这一小节的一个好地方，所以让我们总结一下我们关于生成自己</st> <st c="69998">随机数据</st>的学习内容。
- en: <st c="70010">What we learned</st>
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="70010">我们学到的内容</st>
- en: <st c="70026">In this section, we have learned</st> <st c="70060">the following:</st>
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="70026">在这一节中，我们学到了以下内容：</st>
- en: <st c="70074">How the datasets we work with as data scientists can be considered
    as samples from</st> <st c="70158">a distribution</st>
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="70074">我们作为数据科学家所处理的数据集可以被视为来自</st> <st c="70158">一个分布</st>的样本。
- en: <st c="70172">How to generate our own samples from any</st> <st c="70214">probability
    distribution</st>
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="70172">如何从任何</st> <st c="70214">概率分布</st>中生成我们自己的样本。
- en: <st c="70238">Why and when generating our own samples from a probability distribution</st>
    <st c="70311">is useful</st>
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="70238">为什么以及何时从概率分布中生成我们自己的样本</st> <st c="70311">是有用的</st>
- en: <st c="70320">Having learned how datasets can be viewed as samples from a distribution,
    we will learn in the next section how to characterize and summarize a sample and
    how those summaries of a sample can be used to make accurate inferences about
    the underlying population distribution from which we think the data</st> <st c="70622">was
    drawn.</st>
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="70320">在了解数据集如何被视为来自分布的样本之后，我们将在下一节学习如何表征和总结样本，以及如何利用这些样本总结对我们认为数据来自的基础总体分布进行准确推断</st>
    <st c="70622">。</st>
- en: <st c="70632">Understanding statistical estimators</st>
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="70632">理解统计估计量</st>
- en: '<st c="70669">When we</st> <st c="70678">were looking at various example probability
    distributions, we learned how to calculate their mean and variance.</st> <st c="70790">Now,
    you may ask: Is it possible to calculate the mean and variance of a sample (of
    a dataset)?</st> <st c="70886">The answer is yes.</st> <st c="70905">You have
    probably done this before in high school or college.</st> <st c="70967">So, you
    may be wondering how the mean and variance of a dataset are connected to the mean
    and variance of a</st> <st c="71075">population distribution.</st> <st c="71100">What
    we are going to do now is explain</st> <st c="71139">the following:</st>'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="70669">当我们</st> <st c="70678">查看各种示例概率分布时，我们学习了如何计算它们的均值和方差。</st> <st
    c="70790">现在，你可能会问：是否可以计算一个样本（数据集）的均值和方差？</st> <st c="70886">答案是肯定的。</st> <st
    c="70905">你可能以前在高中或大学时就做过这件事。</st> <st c="70967">所以，你可能会想，数据集的均值和方差是如何与</st> <st
    c="71075">总体分布的均值和方差相关联的。</st> <st c="71100">我们接下来要做的是解释</st> <st c="71139">以下内容：</st>
- en: <st c="71153">How to calculate the mean and variance of</st> <st c="71196">a
    sample</st>
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="71153">如何计算</st> <st c="71196">一个样本</st>的均值和方差。
- en: <st c="71204">How they differ from the mean and variance of the population distribution
    from which the sample</st> <st c="71301">was generated</st>
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="71204">它们与生成样本的总体分布的均值和方差有何不同</st> <st c="71301">。</st>
- en: <st c="71314">How they are connected to the mean and variance of the population
    distribution from which the sample</st> <st c="71416">was generated</st>
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="71314">它们是如何与生成该样本的总体分布的均值和方差相联系的</st> <st c="71416">。</st>
- en: <st c="71429">How to use our understanding of the population distribution to
    make quantified inferences about it from</st> <st c="71534">the sample</st>
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="71429">如何利用我们对总体分布的理解，从</st> <st c="71534">样本</st>中进行量化推断。
- en: <st c="71544">Let’s start with the first of those.</st> <st c="71582">Given
    a set of</st> <st c="71597">n</st> <st c="71598">numbers (a s</st><st c="71611">ample)</st>
    <st c="71619">x</st><st c="71620">1</st><st c="71621">,</st> <st c="71622">x</st><st
    c="71623">2</st><st c="71624">,</st> <st c="71625">⋯</st> <st c="71626">,</st>
    <st c="71627">x</st><st c="71628">n</st><st c="71629">, the</st> **<st c="71635">sample
    mean</st>** <st c="71646">is</st> <st c="71650">calculated</st> <st c="71661">as
    follows:</st>
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="71544">让我们从第一个开始。</st> <st c="71582">给定一组</st> <st c="71597">n</st> <st
    c="71598">个数字（一个样本）</st><st c="71611">x</st><st c="71620">1</st><st c="71621">,</st>
    <st c="71622">x</st><st c="71623">2</st><st c="71624">,</st> <st c="71625">⋯</st>
    <st c="71626">,</st> <st c="71627">x</st><st c="71628">n</st><st c="71629">，样本均值</st>
    **<st c="71635">计算公式如下：</st>**
- en: <st c="71672">Sample mean =</st> <st c="71687">m</st> <st c="71688">=</st> <st
    c="71689">1</st><st c="71690">_</st><st c="71691">n</st> <st c="71692">∑</st><st
    c="71693">i</st><st c="71694">=</st><st c="71695">1</st><st c="71696">n</st><st
    c="71697">x</st><st c="71698">i</st> <st c="71699">.</st>
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="71672">样本均值 =</st> <st c="71687">m</st> <st c="71688">=</st> <st c="71689">1</st><st
    c="71690">_</st><st c="71691">n</st> <st c="71692">∑</st><st c="71693">i</st><st
    c="71694">=</st><st c="71695">1</st><st c="71696">n</st><st c="71697">x</st><st
    c="71698">i</st> <st c="71699">。</st>
- en: <st c="71700">Eq.</st> <st c="71705">46</st>
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="71700">方程</st> <st c="71705">46</st>
- en: <st c="71707">This is the formula you will have learned in high school.</st>
    <st c="71766">For example, if my sample consists of the five numbers 3.7, 1.2,
    2.3, 4.1, 2.7, then the sample mean is</st> <st c="71870">the following:</st>
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="71707">这是你在高中学过的公式。</st> <st c="71766">例如，如果我的样本由五个数字 3.7、1.2、2.3、4.1、2.7
    组成，则样本均值为：</st> <st c="71870">如下：</st>
- en: <st c="71884">1</st><st c="71886">_</st><st c="71887">5</st> <st c="71888">×</st>
    <st c="71889">(</st><st c="71890">3.7</st> <st c="71893">+</st> <st c="71895">1.2</st>
    <st c="71898">+</st> <st c="71900">2.3</st> <st c="71903">+</st> <st c="71905">4.1</st>
    <st c="71908">+</st> <st c="71910">2.7</st><st c="71913">)</st> <st c="71915">=</st>
    <st c="71916">2.8</st>
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="71884">1</st><st c="71886">_</st><st c="71887">5</st> <st c="71888">×</st>
    <st c="71889">(</st><st c="71890">3.7</st> <st c="71893">+</st> <st c="71895">1.2</st>
    <st c="71898">+</st> <st c="71900">2.3</st> <st c="71903">+</st> <st c="71905">4.1</st>
    <st c="71908">+</st> <st c="71910">2.7</st><st c="71913">)</st> <st c="71915">=</st>
    <st c="71916">2.8</st>
- en: <st c="71919">Eq.</st> <st c="71924">47</st>
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="71919">方程</st> <st c="71924">47</st>
- en: <st c="71926">You will see that we have used a different symbol for the sample
    mean.</st> <st c="71998">We have used</st> <st c="72011">m</st> <st c="72012">and
    not</st> <st c="72021">μ</st><st c="72022">. This is to distinguish it from a
    population mean.</st> <st c="72074">In fact, we have explicitly called it “the
    sample mean.” We will show how</st> <st c="72148">m</st> <st c="72149">is related
    to</st> <st c="72164">μ</st> <st c="72165">later.</st>
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="71926">你会发现我们使用了一个不同的符号表示样本均值。</st> <st c="71998">我们使用了</st> <st c="72011">m</st>
    <st c="72012">而不是</st> <st c="72021">μ</st><st c="72022">。这是为了将其与总体均值区分开。</st>
    <st c="72074">实际上，我们明确地称它为“样本均值”。我们稍后将展示</st> <st c="72148">m</st> <st c="72149">与</st>
    <st c="72164">μ</st> <st c="72165">的关系。</st>
- en: <st c="72172">Similarly, we can calculate</st> <st c="72201">the</st> **<st
    c="72205">sample variance</st>** <st c="72220">as the average squared deviation</st>
    <st c="72254">of the data from its mean.</st> <st c="72281">Here, I’m going to
    define it</st> <st c="72310">as follows:</st>
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72172">类似地，我们可以计算</st> <st c="72201">样本方差</st> **<st c="72205">作为数据偏离其均值的平均平方差</st>**
    <st c="72220">。</st> <st c="72254">在这里，我将其定义为：</st>
- en: <st c="72321">Sample Variance =</st> <st c="72340">s</st><st c="72341">2</st>
    <st c="72342">=</st> <st c="72343">1</st><st c="72344">_</st><st c="72345">n</st>
    <st c="72346">−</st> <st c="72347">1</st> <st c="72348">∑</st><st c="72349">i</st><st
    c="72350">=</st><st c="72351">1</st><st c="72352">n</st><st c="72353">(</st><st
    c="72354">x</st><st c="72355">i</st> <st c="72356">−</st> <st c="72357">m</st><st
    c="72358">)</st><st c="72359">2</st>
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72321">样本方差 =</st> <st c="72340">s</st><st c="72341">2</st> <st c="72342">=</st>
    <st c="72343">1</st><st c="72344">_</st><st c="72345">n</st> <st c="72346">−</st>
    <st c="72347">1</st> <st c="72348">∑</st><st c="72349">i</st><st c="72350">=</st><st
    c="72351">1</st><st c="72352">n</st><st c="72353">(</st><st c="72354">x</st><st
    c="72355">i</st> <st c="72356">−</st> <st c="72357">m</st><st c="72358">)</st><st
    c="72359">2</st>
- en: <st c="72360">Eq.</st> <st c="72364">48</st>
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72360">方程</st> <st c="72364">48</st>
- en: <st c="72366">For the example</st> <st c="72383">five numbers shown previously,
    the sample variance is</st> <st c="72437">the following:</st>
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72366">对于前面显示的五个数字示例，样本方差为：</st> <st c="72383">如下：</st> <st c="72437">。</st>
- en: <st c="72451">1</st><st c="72453">_</st><st c="72454">4</st> <st c="72455">×</st>
    <st c="72456">[</st><st c="72457">(</st><st c="72458">3.7</st> <st c="72461">−</st>
    <st c="72463">2.8</st><st c="72466">)</st><st c="72468">2</st><st c="72469">+</st>
    <st c="72470">(</st><st c="72471">1.2</st> <st c="72474">−</st> <st c="72476">2.8</st><st
    c="72479">)</st><st c="72481">2</st><st c="72482">+</st> <st c="72483">(</st><st
    c="72484">2.3</st> <st c="72487">−</st> <st c="72489">2.8</st><st c="72492">)</st><st
    c="72494">2</st><st c="72495">+</st> <st c="72496">(</st><st c="72497">4.1</st>
    <st c="72500">−</st> <st c="72502">2.8</st><st c="72505">)</st><st c="72507">2</st><st
    c="72508">+</st> <st c="72509">(</st><st c="72510">2.7</st> <st c="72513">−</st>
    <st c="72515">2.8</st><st c="72518">)</st><st c="72520">2</st><st c="72521">]</st>
    <st c="72522">=</st> <st c="72523">1.33</st>
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72451">1</st><st c="72453">_</st><st c="72454">4</st> <st c="72455">×</st>
    <st c="72456">[</st><st c="72457">(</st><st c="72458">3.7</st> <st c="72461">−</st>
    <st c="72463">2.8</st><st c="72466">)</st><st c="72468">2</st><st c="72469">+</st>
    <st c="72470">(</st><st c="72471">1.2</st> <st c="72474">−</st> <st c="72476">2.8</st><st
    c="72479">)</st><st c="72481">2</st><st c="72482">+</st> <st c="72483">(</st><st
    c="72484">2.3</st> <st c="72487">−</st> <st c="72489">2.8</st><st c="72492">)</st><st
    c="72494">2</st><st c="72495">+</st> <st c="72496">(</st><st c="72497">4.1</st>
    <st c="72500">−</st> <st c="72502">2.8</st><st c="72505">)</st><st c="72507">2</st><st
    c="72508">+</st> <st c="72509">(</st><st c="72510">2.7</st> <st c="72513">−</st>
    <st c="72515">2.8</st><st c="72518">)</st><st c="72520">2</st><st c="72521">]</st>
    <st c="72522">=</st> <st c="72523">1.33</st>
- en: <st c="72527">Eq.</st> <st c="72532">49</st>
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72527">Eq.</st> <st c="72532">49</st>
- en: <st c="72534">Again, we</st> <st c="72545">have used a different symbol,</st>
    <st c="72575">s</st><st c="72576">2</st><st c="72577">, for the sample variance,
    and not</st> <st c="72612">σ</st><st c="72613">2</st> <st c="72614">that we use
    for the population variance.</st> <st c="72656">As you may have guessed, the sample
    standard deviation is simply the square root of the sample variance, so the sample
    standard deviation</st> <st c="72794">is</st> <st c="72797">s</st><st c="72798">.</st>
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72534">同样，我们</st> <st c="72545">为样本方差使用了不同的符号，</st> <st c="72575">s</st><st
    c="72576">2</st><st c="72577">，而不是我们用于总体方差的</st> <st c="72612">σ</st><st c="72613">2</st>
    <st c="72614">。正如你可能猜到的那样，样本标准差就是样本方差的平方根，因此样本标准差</st> <st c="72794">是</st> <st
    c="72797">s</st><st c="72798">。</st>
- en: <st c="72799">Now, you will probably be wondering why we had</st> <st c="72847">n</st>
    <st c="72848">−</st> <st c="72849">1</st> <st c="72850">in the denominator on
    the right-hand side of</st> *<st c="72896">Eq.</st> <st c="72900">48</st>*<st
    c="72902">.</st> <st c="72904">Why didn’t we calculate the sample variance using
    a formula,</st> <st c="72965">like so?</st>
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72799">现在，你可能会想知道为什么在等式右侧的分母上我们使用了</st> *<st c="72896">Eq.</st> <st c="72900">48</st>*<st
    c="72902">。</st> <st c="72904">为什么我们没有像这样计算样本方差呢？</st>
- en: <st c="72973">1</st><st c="72975">_</st><st c="72976">n</st> <st c="72977">∑</st><st
    c="72978">i</st><st c="72979">=</st><st c="72980">1</st><st c="72981">n</st><st
    c="72982">(</st><st c="72983">x</st><st c="72984">i</st> <st c="72985">−</st>
    <st c="72986">m</st><st c="72987">)</st><st c="72988">2</st>
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72973">1</st><st c="72975">_</st><st c="72976">n</st> <st c="72977">∑</st><st
    c="72978">i</st><st c="72979">=</st><st c="72980">1</st><st c="72981">n</st><st
    c="72982">(</st><st c="72983">x</st><st c="72984">i</st> <st c="72985">−</st>
    <st c="72986">m</st><st c="72987">)</st><st c="72988">2</st>
- en: <st c="72989">Eq.</st> <st c="72993">50</st>
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72989">Eq.</st> <st c="72993">50</st>
- en: <st c="72995">The short answer is that using a denominator of</st> <st c="73044">n</st>
    <st c="73045">−</st> <st c="73046">1</st> <st c="73047">means the resulting value
    of</st> <st c="73077">s</st><st c="73078">2</st> <st c="73079">gives us a more
    accurate estimate of the true population variance</st> <st c="73146">σ</st><st
    c="73147">2</st> <st c="73148">than if we had used a denominator of</st> <st c="73186">n</st><st
    c="73187">. Remember – it is the underlying population distribution and its properties
    that we are ultimately</st> <st c="73287">interested in.</st>
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="72995">简而言之，使用分母为</st> <st c="73044">n</st> <st c="73045">−</st> <st
    c="73046">1</st> <st c="73047">意味着</st> <st c="73077">s</st><st c="73078">2</st>
    <st c="73079">会给出一个比使用分母为</st> <st c="73186">n</st><st c="73187">时更准确的总体方差</st>
    <st c="73146">σ</st><st c="73147">2</st> <st c="73148">的估计值。请记住，我们最终关心的是基础的总体分布及其特性。</st>
- en: <st c="73301">Consistency, bias, and efficiency</st>
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="73301">一致性、偏差和效率</st>
- en: <st c="73335">Now, let’s give the long answer and explain in more detail.</st>
    <st c="73396">Those five numbers in the preceding example came from a normal distribution
    with a mean</st> <st c="73484">μ</st> <st c="73485">=</st> <st c="73486">2.5</st>
    <st c="73489">and a variance</st> <st c="73505">σ</st><st c="73506">2</st> <st
    c="73507">=</st> <st c="73508">1.5</st><st c="73511">. I used the code example
    given in the</st> *<st c="73550">How to sample</st>* <st c="73563">subsection
    to generate them.</st> <st c="73593">I also rounded to 1 decimal place for convenience
    of presentation.</st> <st c="73660">You can see that the sample mean</st> <st
    c="73693">m</st> <st c="73694">and sample variance</st> <st c="73715">s</st><st
    c="73716">2</st> <st c="73717">are different from the mean</st> <st c="73746">μ</st>
    <st c="73747">and variance</st> <st c="73761">σ</st><st c="73762">2</st> <st c="73763">of
    the distribution from which the five numbers were sampled.</st> <st c="73826">Ideally,
    we want</st> <st c="73843">m</st> <st c="73844">and</st> <st c="73849">s</st><st
    c="73850">2</st> <st c="73851">to be good estimates of</st> <st c="73876">μ</st>
    <st c="73877">and</st> <st c="73882">σ</st><st c="73883">2</st><st c="73884">,
    and so be close in numerical value to</st> <st c="73924">μ</st> <st c="73925">and</st>
    <st c="73930">σ</st><st c="73931">2</st><st c="73932">. You would suspect that
    the reason</st> <st c="73968">m</st> <st c="73969">and</st> <st c="73974">s</st><st
    c="73975">2</st> <st c="73976">are different from</st> <st c="73996">μ</st> <st
    c="73997">and</st> <st c="74002">σ</st><st c="74003">2</st> <st c="74004">is the
    small sample</st> <st c="74025">size; that is, because we have used only five
    numbers in our sample.</st> <st c="74094">We would hope that</st> <st c="74113">m</st>
    <st c="74114">and</st> <st c="74119">s</st><st c="74120">2</st> <st c="74121">get
    closer to</st> <st c="74136">μ</st> <st c="74137">and</st> <st c="74142">σ</st><st
    c="74143">2</st> <st c="74144">as we increase the sample size</st> <st c="74176">n</st><st
    c="74177">.</st> *<st c="74179">Figure 2</st>**<st c="74187">.13</st>* <st c="74190">shows
    what happens to</st> <st c="74213">m</st> <st c="74214">and</st> <st c="74219">s</st><st
    c="74220">2</st> <st c="74221">as we increase the</st> <st c="74241">number of
    samples we draw from the distribution</st> <st c="74289">Normal</st><st c="74295">(</st><st
    c="74297">2.5</st><st c="74300">,</st> <st c="74301">1.5</st><st c="74304">)</st><st
    c="74306">:</st>
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="73335">现在，让我们给出详细的长答案并进行更深入的解释。</st> <st c="73396">前面示例中的那五个数字来自均值</st>
    <st c="73484">μ</st> <st c="73485">=</st> <st c="73486">2.5</st> <st c="73489">和方差</st>
    <st c="73505">σ</st><st c="73506">2</st> <st c="73507">=</st> <st c="73508">1.5</st><st
    c="73511">的正态分布。我使用了</st> *<st c="73550">如何抽样</st>* <st c="73563">小节中给出的代码示例来生成这些数字。</st>
    <st c="73593">为了便于展示，我还将其四舍五入到小数点后1位。</st> <st c="73660">你可以看到，样本均值</st> <st c="73693">m</st>
    <st c="73694">和样本方差</st> <st c="73715">s</st><st c="73716">2</st> <st c="73717">与从中抽取这五个数字的分布的均值</st>
    <st c="73746">μ</st> <st c="73747">和方差</st> <st c="73761">σ</st><st c="73762">2</st>
    <st c="73763">不同。</st> <st c="73826">理想情况下，我们希望</st> <st c="73843">m</st> <st
    c="73844">和</st> <st c="73849">s</st><st c="73850">2</st> <st c="73851">能够很好地估计</st>
    <st c="73876">μ</st> <st c="73877">和</st> <st c="73882">σ</st><st c="73883">2</st><st
    c="73884">，因此它们的数值应接近</st> <st c="73924">μ</st> <st c="73925">和</st> <st c="73930">σ</st><st
    c="73931">2</st><st c="73932">。</st> <st c="73968">你可能会怀疑，</st> <st c="73969">m</st>
    <st c="73974">和</st> <st c="73975">s</st><st c="73976">2</st> <st c="73976">与</st>
    <st c="73996">μ</st> <st c="73997">和</st> <st c="74002">σ</st><st c="74003">2</st>
    <st c="74004">不同的原因是小样本大小；也就是说，因为我们只用了五个数字来构成样本。</st> <st c="74094">我们希望，随着样本量的增加</st>
    <st c="74113">m</st> <st c="74114">和</st> <st c="74119">s</st><st c="74120">2</st>
    <st c="74121">能够更接近</st> <st c="74136">μ</st> <st c="74137">和</st> <st c="74142">σ</st><st
    c="74143">2</st> <st c="74144">。</st> *<st c="74179">图 2</st>**<st c="74187">.13</st>*
    <st c="74190">展示了随着我们增加从正态分布</st> <st c="74289">Normal</st><st c="74295">(</st><st
    c="74297">2.5</st><st c="74300">,</st> <st c="74301">1.5</st><st c="74304">)</st><st
    c="74306">中抽取的样本数，</st> <st c="74213">m</st> <st c="74214">和</st> <st c="74219">s</st><st
    c="74220">2</st> <st c="74221">会发生什么变化</st> <st c="74241">。</st>
- en: '![Figure 2.13: Running sample mean and sample variance for samples drawn from
    Normal(2.5, 1.5)](img/B19496_02_14.jpg)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.13: 从正态分布(2.5, 1.5)抽取样本的运行样本均值和样本方差](img/B19496_02_14.jpg)'
- en: '<st c="74492">Figure 2.13: Running sample mean and sample variance for samples
    drawn from Normal(2.5, 1.5)</st>'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '<st c="74492">图 2.13: 从正态分布(2.5, 1.5)抽取样本的运行样本均值和样本方差</st>'
- en: <st c="74584">Here, we have generated 5,000 random values from</st> <st c="74634">Normal</st><st
    c="74640">(</st><st c="74642">2.5</st><st c="74645">,</st> <st c="74646">1.5</st><st
    c="74649">)</st> <st c="74651">and then calculated the running sample mean; that
    is, the average of the first</st> <st c="74731">n</st> <st c="74732">numbers,
    for</st> <st c="74746">n</st> <st c="74747">=</st> <st c="74748">50</st><st c="74750">,</st>
    <st c="74751">…</st> <st c="74752">,</st> <st c="74753">5000</st><st c="74757">.
    In the right-hand plot, we have also plotted the running sample variance.</st>
    <st c="74833">In the left-hand and right-hand plots, the horizontal gray lines
    show the values of the population mean and population variance, respectively.</st>
    <st c="74976">We can see that visually, the sample mean and sample variance appear
    to converge to their population values as the sample size increases.</st> <st
    c="75114">That is, we have</st> <st c="75131">the following:</st>
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="74584">在这里，我们从</st> <st c="74634">正态分布</st><st c="74640">(</st><st c="74642">2.5</st><st
    c="74645">,</st> <st c="74646">1.5</st><st c="74649">)</st> <st c="74651">生成了5,000个随机值，并计算了累计样本均值；即前</st>
    <st c="74731">n</st> <st c="74732">个数字的平均值，对于</st> <st c="74746">n</st> <st c="74747">=</st>
    <st c="74748">50</st><st c="74750">,</st> <st c="74751">…</st> <st c="74752">,</st>
    <st c="74753">5000</st><st c="74757">。在右侧的图中，我们还绘制了累计样本方差。</st> <st c="74833">在左右两侧的图中，水平灰线分别表示总体均值和总体方差。</st>
    <st c="74976">我们可以看出，从视觉上看，样本均值和样本方差似乎随着样本大小的增加而收敛到它们的总体值。</st> <st c="75114">也就是说，我们有</st>
    <st c="75131">如下结果：</st>
- en: <st c="75145">m</st> <st c="75147">→</st> <st c="75148">μ</st> <st c="75149">s</st><st
    c="75150">2</st> <st c="75151">→</st> <st c="75152">σ</st><st c="75153">2</st>
    <st c="75154">as</st> <st c="75156">n</st> <st c="75158">→</st> <st c="75159">∞</st>
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="75145">m</st> <st c="75147">→</st> <st c="75148">μ</st> <st c="75149">s</st><st
    c="75150">2</st> <st c="75151">→</st> <st c="75152">σ</st><st c="75153">2</st>
    <st c="75154">随着</st> <st c="75156">n</st> <st c="75158">→</st> <st c="75159">∞</st>
- en: <st c="75160">Eq.</st> <st c="75164">51</st>
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="75160">方程</st> <st c="75164">51</st>
- en: <st c="75166">Because of this, we say that</st> <st c="75196">m</st> <st c="75197">and</st>
    <st c="75202">s</st><st c="75203">2</st> <st c="75204">are</st> **<st c="75209">consistent
    estimators</st>**<st c="75230">. They get better at estimating the</st> <st c="75266">things
    we want them to estimate as we use more and more data, until ultimately with an
    infinite amount of data they are consistent with (give the same value) as the
    things we want to calculate (</st><st c="75460">μ</st> <st c="75462">and</st>
    <st c="75467">σ</st><st c="75468">2</st><st c="75469">)</st><st c="75470">.</st>
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="75166">因此，我们可以说</st> <st c="75196">m</st> <st c="75197">和</st> <st c="75202">s</st><st
    c="75203">2</st> <st c="75204">是</st> **<st c="75209">一致性估计量</st>**<st c="75230">。随着我们使用越来越多的数据，它们在估计我们想要估计的值时变得更准确，直到最终在数据量无限时，它们与我们要计算的值（</st><st
    c="75460">μ</st> <st c="75462">和</st> <st c="75467">σ</st><st c="75468">2</st><st
    c="75469">）一致（给出相同的值）。</st>
- en: <st c="75471">Excellent!</st> <st c="75483">Well</st> <st c="75487">not quite.</st>
    <st c="75499">Usually, we don’t have an infinite amount of data in our real-world
    data science problems.</st> <st c="75590">So, while an estimator that is consistent
    is almost a minimum requirement, it still doesn’t guarantee that when we have
    a finite-sized dataset, our estimator is based upon a</st> <st c="75764">good
    formula.</st>
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="75471">太棒了！</st> <st c="75483">嗯，</st> <st c="75487">其实不完全是。</st> <st
    c="75499">通常，在我们的真实世界数据科学问题中，我们不可能拥有无限的数据量。</st> <st c="75590">所以，尽管一致性估计量几乎是最基本的要求，但它仍然不能保证当我们拥有一个有限大小的数据集时，我们的估计量是基于一个</st>
    <st c="75764">良好的公式。</st>
- en: <st c="75777">How could we</st> <st c="75791">even tell if a formula gives a
    good estimator at finite</st> <st c="75847">n</st><st c="75848">? Remember what
    we said at the very start of this chapter that all data has a random component,
    and so all quantities derived from data also have a random component?</st> <st
    c="76014">Well, that means that the sample mean and sample variance have a random
    component and so are random variables.</st> <st c="76125">As</st> <st c="76128">m</st>
    <st c="76129">is a random variable, we accept that any individual instance of</st>
    <st c="76194">m</st><st c="76195">, calculated from an individual dataset of size</st>
    <st c="76243">n</st><st c="76244">, will differ from</st> <st c="76263">μ</st><st
    c="76264">, but we would want the average value of</st> <st c="76305">m</st> <st
    c="76306">to be the same as</st> <st c="76325">μ</st> <st c="76326">if we were
    using a good estimator.</st> <st c="76362">That means, that if we repeat lots
    of times our little experiment of drawing five numbers from</st> <st c="76457">Normal</st><st
    c="76463">(</st><st c="76465">2.5</st><st c="76468">,</st> <st c="76469">1.5</st><st
    c="76472">)</st> <st c="76474">and calculate a value of</st> <st c="76500">m</st>
    <st c="76501">for each of those experiments, we want the average value of</st>
    <st c="76562">m</st> <st c="76563">to be equal to</st> <st c="76579">μ</st><st
    c="76580">.</st> *<st c="76582">Table 2.2</st>* <st c="76591">shows 10 such experiments,
    with the values of</st> <st c="76638">m</st> <st c="76639">and</st> <st c="76644">s</st><st
    c="76645">2</st> <st c="76646">given for each of the 10 experiments.</st> <st
    c="76685">The bottom row of the table s</st><st c="76714">hows the average values
    of</st> <st c="76742">m</st> <st c="76743">and</st> <st c="76748">s</st><st c="76749">2</st>
    <st c="76750">across the</st> <st c="76762">10 experiments:</st>
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="75777">我们怎么</st> <st c="75791">知道一个公式在有限的</st> <st c="75847">n</st><st
    c="75848">下是否给出了一个良好的估计量呢？还记得我们在本章开始时说过，所有数据都有随机成分，因此所有从数据中派生的量也具有随机成分吗？</st>
    <st c="76014">这意味着样本均值和样本方差具有随机成分，因此它们是随机变量。</st> <st c="76125">由于</st> <st c="76128">m</st>
    <st c="76129">是随机变量，我们接受这样一个事实：从单个数据集（大小为</st> <st c="76243">n</st><st c="76244">）计算出来的</st>
    <st c="76194">m</st><st c="76195">的每一个实例都会与</st> <st c="76263">μ</st><st c="76264">不同，但我们希望</st>
    <st c="76305">m</st> <st c="76306">的平均值与</st> <st c="76325">μ</st> <st c="76326">相同，前提是我们使用的是一个良好的估计量。</st>
    <st c="76362">这意味着，如果我们多次重复从</st> <st c="76457">正态分布</st><st c="76463">(</st><st
    c="76465">2.5</st><st c="76468">,</st> <st c="76469">1.5</st><st c="76472">)</st>
    <st c="76474">中抽取5个数字的实验，并为每次实验计算</st> <st c="76500">m</st> <st c="76501">的值，我们希望</st>
    <st c="76562">m</st> <st c="76563">的平均值等于</st> <st c="76579">μ</st><st c="76580">。</st>
    *<st c="76582">表 2.2</st>* <st c="76591">展示了10次这样的实验，给出了每次实验中的</st> <st c="76638">m</st>
    <st c="76639">和</st> <st c="76644">s</st><st c="76645">2</st> <st c="76646">的值。</st>
    <st c="76685">表格的最底行展示了</st><st c="76714">10次实验中</st> <st c="76742">m</st> <st
    c="76743">和</st> <st c="76748">s</st><st c="76749">2</st> <st c="76750">的平均值：</st>
- en: '![Table 2.2: Sample mean and sample variance values in 10 experiments drawing
    samples of 5 numbers from Normal(2.5, 1.5)](img/B19496_02_15.jpg)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![表 2.2：从正态分布（2.5, 1.5）中抽取5个数字的10次实验中的样本均值和样本方差值](img/B19496_02_15.jpg)'
- en: '<st c="76964">Table 2.2: Sample mean and sample variance values in 10 experiments
    drawing samples of 5 numbers from Normal(2.5, 1.5)</st>'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="76964">表 2.2：从正态分布（2.5, 1.5）中抽取5个数字的10次实验中的样本均值和样本方差值</st>
- en: <st c="77082">You can</st> <st c="77091">see from</st> *<st c="77100">Table
    2.2</st>* <st c="77109">that the average across the 10 experiments of the sample
    mean is reasonably close to the true population mean of</st> <st c="77223">μ</st>
    <st c="77224">=</st> <st c="77225">2.5</st><st c="77228">. In fact, if we took
    the average over an infinite number of experiments, we</st> <st c="77304">would
    get an average value of 2.5 exactly.</st> <st c="77348">So,</st> **<st c="77352">on
    average</st>**<st c="77362">, the sample mean gives the same value as the population
    mean.</st> <st c="77425">We will prove</st> <st c="77439">that now.</st>
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77082">你可以</st> <st c="77091">从</st> *<st c="77100">表 2.2</st>* <st c="77109">看出，10次实验中样本均值的平均值与真实总体均值</st>
    <st c="77223">μ</st> <st c="77224">=</st> <st c="77225">2.5</st><st c="77228">非常接近。事实上，如果我们对无限次实验取平均值，我们</st>
    <st c="77304">将得到精确的2.5作为平均值。</st> <st c="77348">所以，</st> **<st c="77352">平均而言</st>**<st
    c="77362">，样本均值与总体均值相同。</st> <st c="77425">我们现在就来证明这一点。</st>
- en: <st c="77448">Since the sample mean is a random variable, we can just calculate
    its expectation value.</st> <st c="77538">The sample mean is defined</st> <st
    c="77565">as fo</st><st c="77570">llows:</st>
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77448">由于样本均值是一个随机变量，我们可以计算它的期望值。</st> <st c="77538">样本均值定义为</st> <st
    c="77565">如下：</st>
- en: <st c="77577">m</st> <st c="77579">=</st> <st c="77580">1</st><st c="77581">_</st><st
    c="77582">n</st> <st c="77583">∑</st><st c="77584">i</st><st c="77585">=</st><st
    c="77586">1</st><st c="77587">n</st><st c="77588">x</st><st c="77589">i</st>
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77577">m</st> <st c="77579">=</st> <st c="77580">1</st><st c="77581">_</st><st
    c="77582">n</st> <st c="77583">∑</st><st c="77584">i</st><st c="77585">=</st><st
    c="77586">1</st><st c="77587">n</st><st c="77588">x</st><st c="77589">i</st>
- en: <st c="77590">Eq.</st> <st c="77594">52</st>
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77590">方程</st> <st c="77594">52</st>
- en: <st c="77596">So, its expectation value is</st> <st c="77626">the following:</st>
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77596">因此，它的期望值是</st> <st c="77626">如下：</st>
- en: <st c="77640">𝔼</st><st c="77643">(</st><st c="77645">m</st><st c="77646">)</st>
    <st c="77647">=</st> <st c="77648">𝔼</st><st c="77650">(</st><st c="77652">1</st><st
    c="77653">_</st><st c="77654">n</st> <st c="77655">∑</st><st c="77656">i</st><st
    c="77657">=</st><st c="77658">1</st><st c="77659">n</st><st c="77660">x</st><st
    c="77661">i</st><st c="77662">)</st> <st c="77663">=</st> <st c="77664">1</st><st
    c="77665">_</st><st c="77666">n</st> <st c="77667">∑</st><st c="77668">i</st><st
    c="77669">=</st><st c="77670">1</st><st c="77671">n</st><st c="77672">𝔼</st><st
    c="77674">(</st><st c="77676">x</st><st c="77677">i</st><st c="77678">)</st>
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77640">𝔼</st><st c="77643">(</st><st c="77645">m</st><st c="77646">)</st>
    <st c="77647">=</st> <st c="77648">𝔼</st><st c="77650">(</st><st c="77652">1</st><st
    c="77653">_</st><st c="77654">n</st> <st c="77655">∑</st><st c="77656">i</st><st
    c="77657">=</st><st c="77658">1</st><st c="77659">n</st><st c="77660">x</st><st
    c="77661">i</st><st c="77662">)</st> <st c="77663">=</st> <st c="77664">1</st><st
    c="77665">_</st><st c="77666">n</st> <st c="77667">∑</st><st c="77668">i</st><st
    c="77669">=</st><st c="77670">1</st><st c="77671">n</st><st c="77672">𝔼</st><st
    c="77674">(</st><st c="77676">x</st><st c="77677">i</st><st c="77678">)</st>
- en: <st c="77679">Eq.</st> <st c="77683">53</st>
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77679">方程</st> <st c="77683">53</st>
- en: <st c="77685">The last part on the right-hand side of</st> *<st c="77726">Eq.</st>
    <st c="77730">53</st>* <st c="77732">follows on from the rules of expectations
    of linear transformations of random variables.</st> <st c="77822">Now, if we have
    i.i.d.</st> <st c="77845">data, then since each random variable</st> <st c="77883">x</st><st
    c="77884">i</st> <st c="77885">is drawn from the same population distribution
    we have</st> <st c="77941">𝔼</st><st c="77943">(</st><st c="77945">x</st><st c="77946">i</st><st
    c="77947">)</st> <st c="77948">=</st> <st c="77949">μ</st> <st c="77950">for all</st>
    <st c="77959">i</st><st c="77960">. Plugging that result into</st> *<st c="77988">Eq.</st>
    <st c="77992">53</st>*<st c="77994">, we then get</st> <st c="78008">the following:</st>
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="77685">右边最后一部分来自</st> *<st c="77726">方程</st> <st c="77730">53</st>* <st
    c="77732">的结果，遵循了随机变量线性变换的期望规则。</st> <st c="77822">现在，如果我们有独立同分布（i.i.d.）</st>
    <st c="77845">数据，那么由于每个随机变量</st> <st c="77883">x</st><st c="77884">i</st> <st
    c="77885">都是从同一总体分布中抽取的，我们有</st> <st c="77941">𝔼</st><st c="77943">(</st><st c="77945">x</st><st
    c="77946">i</st><st c="77947">)</st> <st c="77948">=</st> <st c="77949">μ</st>
    <st c="77950">对于所有的</st> <st c="77959">i</st><st c="77960">. 将这个结果代入</st> *<st
    c="77988">方程</st> <st c="77992">53</st>*<st c="77994">，我们得到</st> <st c="78008">如下：</st>
- en: <st c="78022">𝔼</st><st c="78025">(</st><st c="78027">m</st><st c="78028">)</st>
    <st c="78029">=</st> <st c="78030">n</st><st c="78031">_</st><st c="78032">n</st>
    <st c="78033">μ</st> <st c="78034">=</st> <st c="78035">μ</st>
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="78022">𝔼</st><st c="78025">(</st><st c="78027">m</st><st c="78028">)</st>
    <st c="78029">=</st> <st c="78030">n</st><st c="78031">_</st><st c="78032">n</st>
    <st c="78033">μ</st> <st c="78034">=</st> <st c="78035">μ</st>
- en: <st c="78036">Eq.</st> <st c="78040">54</st>
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="78036">方程</st> <st c="78040">54</st>
- en: <st c="78042">So, on average, for i.i.d.</st> <st c="78070">data, the sample
    mean will equal the true underlying population mean we are trying to estimate.</st>
    <st c="78166">This is true even though our sample mean is based on a finite sample
    size!</st> <st c="78241">We say that the</st> <st c="78256">sample mean is an</st>
    **<st c="78275">unbiased estimator</st>** <st c="78293">of the population mean.</st>
    <st c="78318">Even if the different random variables</st> <st c="78357">x</st><st
    c="78358">i</st> <st c="78359">are not independent of each other but they still
    have the same mean – that is, we still have</st> <st c="78453">𝔼</st><st c="78455">(</st><st
    c="78457">x</st><st c="78458">i</st><st c="78459">)</st> <st c="78460">=</st>
    <st c="78461">μ</st> <st c="78462">– then the sample mean</st> <st c="78486">m</st>
    <st c="78487">is still an unbiased estimator of the population</st> <st c="78537">mean</st>
    <st c="78542">μ</st><st c="78543">.</st>
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="78042">因此，平均而言，对于独立同分布（i.i.d.）数据，样本均值将等于我们尝试估计的真实总体均值。</st> <st c="78070">即使我们的样本均值是基于有限的样本量，这一点依然成立！</st>
    <st c="78166">我们称样本均值是总体均值的**无偏估计量**。</st> <st c="78241">即使不同的随机变量</st> <st c="78357">x</st><st
    c="78358">i</st> <st c="78359">之间并不独立，但它们仍然具有相同的均值——也就是说，我们依然有</st> <st c="78453">𝔼</st><st
    c="78455">(</st><st c="78457">x</st><st c="78458">i</st><st c="78459">)</st> <st
    c="78460">=</st> <st c="78461">μ</st> <st c="78462">——那么样本均值</st> <st c="78486">m</st>
    <st c="78487">仍然是总体均值</st> <st c="78537">μ</st><st c="78542">的无偏估计量。</st>
- en: <st c="78544">Now, it turns out that for the sample variance, if we have</st>
    <st c="78604">n</st> <st c="78605">−</st> <st c="78606">1</st> <st c="78607">in
    the denominator of the definition of</st> <st c="78648">s</st><st c="78649">2</st><st
    c="78650">, then</st> <st c="78657">s</st><st c="78658">2</st> <st c="78659">is
    an unbiased estimator of the population variance</st> <st c="78712">σ</st><st
    c="78713">2</st><st c="78714">. That is,</st> <st c="78725">𝔼</st><st c="78727">(</st><st
    c="78729">s</st><st c="78730">2</st><st c="78731">)</st> <st c="78732">=</st>
    <st c="78733">σ</st><st c="78734">2</st> <st c="78735">for any value of</st> <st
    c="78753">n</st><st c="78754">. We can prove this as well using a similar proof
    to that in</st> *<st c="78815">Eq.</st> <st c="78819">53</st>*<st c="78821">,
    but we will simply state it here and leave the proof as an exercise for the reader.</st>
    <st c="78907">If we had used</st> <st c="78922">n</st> <st c="78923">in the denominator
    of</st> *<st c="78946">Eq.</st> <st c="78950">48</st>* <st c="78952">instead of</st>
    <st c="78964">n</st> <st c="78965">−</st> <st c="78966">1</st><st c="78967">,
    our definition of</st> <st c="78987">s</st><st c="78988">2</st> <st c="78989">would
    not give us an unbiased estimator of</st> <st c="79033">σ</st><st c="79034">2</st><st
    c="79035">.</st>
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="78544">现在，事实证明，对于样本方差，如果在定义中我们有</st> <st c="78604">n</st> <st c="78605">−</st>
    <st c="78606">1</st> <st c="78607">作为分母，那么</st> <st c="78657">s</st><st c="78658">2</st>
    <st c="78659">是总体方差</st> <st c="78712">σ</st><st c="78713">2</st><st c="78714">的无偏估计量。</st>
    <st c="78725">也就是说，</st> <st c="78727">(</st><st c="78729">s</st><st c="78730">2</st><st
    c="78731">)</st> <st c="78732">=</st> <st c="78733">σ</st><st c="78734">2</st>
    <st c="78735">对于任何的</st> <st c="78753">n</st><st c="78754">值都成立。</st> <st c="78757">我们也可以通过类似于</st>
    *<st c="78815">方程 53</st>*<st c="78821">的证明来证明这一点，但我们将在此简单陈述，并将证明留给读者作为练习。</st>
    <st c="78907">如果我们在</st> *<st c="78946">方程 48</st>* <st c="78952">的分母中使用了</st>
    <st c="78964">n</st> <st c="78965">而不是</st> <st c="78966">n</st> <st c="78967">−</st>
    <st c="78987">1</st><st c="78989">，那么我们的</st> <st c="78987">s</st><st c="78988">2</st>
    <st c="78989">的定义将不会给我们提供总体方差</st> <st c="79033">σ</st><st c="79034">2</st><st
    c="79035">的无偏估计量。</st>
- en: <st c="79036">Since the difference between having</st> <st c="79073">n</st>
    <st c="79074">−</st> <st c="79075">1</st> <st c="79076">or</st> <st c="79080">n</st>
    <st c="79081">in the denominator of</st> *<st c="79104">Eq.</st> <st c="79108">48</st>*
    <st c="79110">vanishes as</st> <st c="79123">n</st> <st c="79124">→</st> <st c="79125">∞</st><st
    c="79126">, it becomes clear that an estimator can be biased at finite</st> <st
    c="79187">n</st> <st c="79188">but still consistent; that is, if the bias at finite</st>
    <st c="79242">n</st> <st c="79243">vanishes as</st> <st c="79256">n</st> <st c="79257">→</st>
    <st c="79258">∞</st><st c="79259">. So, bias and consistency are two different
    concepts – we will summarize them in</st> <st c="79341">a moment.</st>
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在*<st c="79104">公式</st> <st c="79108">48</st>* 的分母中，**n** − 1 和 **n** 之间的差异随着**n**
    → ∞ 时消失，因此可以清楚地看出，一个估计量在有限的**n**下可能存在偏差，但仍然是一致的；也就是说，如果在有限的**n**下偏差随着**n** → ∞
    时消失。 所以，偏差和一致性是两个不同的概念 —— 我们将在稍后总结它们。
- en: <st c="79350">Tip</st>
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: <st c="79354">We have said that the sample variance (defined with a denominator
    of</st> <st c="79424">n</st> <st c="79425">−</st> <st c="79426">1</st><st c="79427">)</st>
    <st c="79428">is an unbiased estimator of the population variance.</st> <st c="79482">This
    means</st> <st c="79493">𝔼</st><st c="79495">(</st><st c="79497">s</st><st c="79498">2</st><st
    c="79499">)</st> <st c="79500">=</st> <st c="79501">σ</st><st c="79502">2</st><st
    c="79503">. However, this does not mean that the sample standard deviation is
    an unbiased estimator of the population standard deviation.</st> <st c="79631">We
    do not have</st> <st c="79646">𝔼</st><st c="79648">(</st><st c="79650">s</st><st
    c="79651">)</st> <st c="79652">=</st> <st c="79653">σ</st><st c="79654">. Why
    not?</st> <st c="79665">Well,</st> <st c="79671">s</st> <st c="79672">=</st> <st
    c="79673">√</st><st c="79674">_</st><st c="79675">s</st><st c="79676">2</st> <st
    c="79677">and taking the square root is a non-linear operation.</st> <st c="79732">Wherever
    we introduce a non-linear operation, we potentially introduce new biases when
    we take the expectation.</st> <st c="79844">So, i) be aware that applying a non-linear
    transformation to data can introduce biases in estimates calculated from that
    transformed data, ii) the sample standard deviation is not an unbiased estimate
    of the population standard deviation.</st> <st c="80083">This explains this seeming
    cryptic note in the documentation of the</st> `<st c="80151">numpy.std</st>` <st
    c="80160">function, “</st>*<st c="80172">The standard deviation computed in this
    function is the square root of the estimated variance, so even with ddof=1, it
    will not be an unbiased estimate of the standard deviation per se.</st>*<st c="80358">”
    This note in the documentation always seems to confuse people on first reading,
    but it is just saying</st> <st c="80463">s</st> <st c="80464">is not unbiased
    even if</st> <st c="80489">s</st><st c="80490">2</st> <st c="80491">is.</st>
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经说过，样本方差（分母为**n** − 1时定义）是总体方差的无偏估计量。 这意味着𝔼(**s²**) = σ²。 然而，这并不意味着样本标准差是总体标准差的无偏估计量。
    我们没有𝔼(**s**) = σ。 为什么呢？ 因为 **s** = √**s²**，而取平方根是一个非线性操作。 无论何时我们引入一个非线性操作，都会在求期望时可能引入新的偏差。
    因此，i) 注意对数据应用非线性变换可能会引入来自变换数据的估计偏差，ii) 样本标准差不是总体标准差的无偏估计。 这也解释了在`numpy.std`函数文档中的这条看似晦涩的备注，“*此函数计算的标准差是估计方差的平方根，因此即使ddof=1，它仍然不是标准差的无偏估计。*”
    这条文档中的备注总是让人第一次阅读时感到困惑，但它只是说明**s** 即使在**s²**是无偏的情况下，**s** 也是有偏的。
- en: <st c="80495">Let’s recap what we have learned</st> <st c="80529">so far:</st>
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下到目前为止学到的内容：
- en: <st c="80536">The sample mean and sample variance converge to their population
    equivalents as we use</st> <st c="80624">more data</st>
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着我们使用**更多数据**，样本均值和样本方差会趋近于它们的总体对应值。
- en: <st c="80633">The sample mean and sample variance (with appropriate denominator)
    are unbiased estimates of their population counterparts at</st> <st c="80760">finite</st>
    <st c="80767">n</st>
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="80633">样本均值和样本方差（使用适当的分母）是它们总体对应量的无偏估计量，适用于</st> <st c="80760">有限</st>
    <st c="80767">n</st>
- en: <st c="80768">So, the sample mean and sample variance look like pretty good
    formulas to use, right?</st> <st c="80854">But in the real world, we can’t do
    an infinite number of experiments.</st> <st c="80924">So, knowing that the sample
    mean is an unbiased estimator of the population mean isn’t exactly helpful.</st>
    <st c="81028">For a finite-sized sample, we know that the sample mean will be
    in the right ballpark, but how good is</st> <st c="81131">m</st> <st c="81132">from
    any single dataset?</st> <st c="81158">Look at</st> *<st c="81166">Table 2.2</st>*<st
    c="81175">. In experiment number 4, the sample mean is quite a long way from the
    population value of 2.5\.</st> <st c="81271">Since the sample mean</st> <st c="81293">m</st>
    <st c="81294">is a random variable, we know it will vary around its expectation
    value.</st> <st c="81368">In this case, it looks like for</st> <st c="81400">n</st>
    <st c="81401">=</st> <st c="81402">5</st> <st c="81403">the variations of</st>
    <st c="81422">m</st> <st c="81423">around the population mean of</st> <st c="81454">μ</st>
    <st c="81455">=</st> <st c="81456">2.5</st> <st c="81459">can be large.</st> <st
    c="81474">Those variations are quantified by the standard deviation of</st> <st
    c="81535">m</st><st c="81536">, the size of the typical or expected deviation
    of</st> <st c="81587">m</st> <st c="81588">from</st> <st c="81593">μ</st><st c="81594">.
    Unsurprisingly, the variance of</st> <st c="81628">m</st> <st c="81629">decreases
    as</st> <st c="81643">n</st> <st c="81644">increases, meaning that the sample
    mean calculated from larger samples typically has smaller deviations from</st>
    <st c="81754">μ</st> <st c="81755">than the sample mean calculated from smaller
    samples.</st> <st c="81810">Ultimately, the variance of</st> <st c="81838">m</st>
    <st c="81839">becomes zero as</st> <st c="81856">n</st> <st c="81857">→</st> <st
    c="81858">∞</st><st c="81859">. How quickly the variance of an estimate of a population
    quantity converges to its population equivalent is termed its</st> **<st c="81979">efficiency</st>**<st
    c="81989">. The</st> <st c="81995">efficiency tells us how well the formula makes
    use of the data given to it to construct its estimate of the population quantity.</st>
    <st c="82124">The efficiency of an estimator depends upon the details of the formula
    and the distribution from which we assume the data is</st> <st c="82249">coming.</st>
    <st c="82257">For i.i.d.</st> <st c="82268">data, the variance of the sample mean
    has a</st> <st c="82312">simple form:</st>
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="80768">因此，样本均值和样本方差看起来是非常不错的公式，对吧？</st> <st c="80854">但在现实世界中，我们无法进行无限次实验。</st>
    <st c="80924">所以，知道样本均值是总体均值的无偏估计量并不是特别有用。</st> <st c="81028">对于有限大小的样本，我们知道样本均值会接近总体均值，但对于任何单一数据集，</st>
    <st c="81131">m</st> <st c="81132">到底有多准确呢？</st> <st c="81158">看看</st> *<st c="81166">表
    2.2</st>*<st c="81175">。在实验 4 中，样本均值与总体值 2.5 相差较远。</st> <st c="81271">由于样本均值</st>
    <st c="81293">m</st> <st c="81294">是一个随机变量，我们知道它会围绕其期望值波动。</st> <st c="81368">在这种情况下，看起来对于</st>
    <st c="81400">n</st> <st c="81401">=</st> <st c="81402">5</st> <st c="81403">，</st>
    <st c="81422">m</st> <st c="81423">围绕总体均值</st> <st c="81454">μ</st> <st c="81455">=</st>
    <st c="81456">2.5</st> <st c="81459">的波动可能很大。</st> <st c="81474">这些波动通过</st> <st
    c="81535">m</st><st c="81536">的标准差来量化，表示</st> <st c="81587">m</st> <st c="81588">相对于</st>
    <st c="81593">μ</st><st c="81594">的典型偏差或预期偏差的大小。</st> <st c="81628">不出所料，</st>
    <st c="81629">m</st> <st c="81643">的方差随着</st> <st c="81644">n</st> <st c="81644">的增加而减少，意味着从较大样本中计算出的样本均值通常比从较小样本中计算出的样本均值偏差更小。</st>
    <st c="81754">最终，</st> <st c="81810">当</st> <st c="81838">m</st> <st c="81839">的方差会随着</st>
    <st c="81856">n</st> <st c="81857">→</st> <st c="81858">∞</st><st c="81859">而变为零。</st>
    <st c="81859">一个估计量的方差收敛到其总体等价物的速度被称为其**<st c="81979">效率</st>**<st c="81989">。该</st>
    <st c="81995">效率告诉我们该公式如何利用给定的数据来构建其总体量估计。</st> <st c="82124">估计量的效率取决于公式的细节以及我们假设数据来自的分布</st>
    <st c="82249">。</st> <st c="82257">对于独立同分布（i.i.d.）数据，样本均值的方差有一个</st> <st c="
- en: <st c="82324">Var(</st><st c="82329">m</st><st c="82331">)</st> <st c="82332">=</st>
    <st c="82333">σ</st><st c="82334">2</st><st c="82335">_</st><st c="82336">n</st>
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="82324">Var(</st><st c="82329">m</st><st c="82331">)</st> <st c="82332">=</st>
    <st c="82333">σ</st><st c="82334">2</st><st c="82335">_</st><st c="82336">n</st>
- en: <st c="82337">Eq.</st> <st c="82341">55</st>
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="82337">公式</st> <st c="82341">55</st>
- en: <st c="82343">So, the standard deviation of the sample mean (for i.i.d.</st>
    <st c="82402">data) is</st> <st c="82411">σ</st> <st c="82412">/</st> <st c="82413">√</st><st
    c="82414">_</st><st c="82415">n</st> <st c="82416">. This is also referred to
    as</st> <st c="82445">the</st> **<st c="82450">standard error</st>** <st c="82464">of
    the sample mean – it is the typical size of error that the sample mean will make
    when we use it as an estimate of the population mean</st> <st c="82602">μ</st><st
    c="82603">. Remember also here that</st> <st c="82629">σ</st> <st c="82630">is
    the population standard deviation of each individual data point.</st> <st c="82699">So,
    no matter how big</st> <st c="82721">σ</st> <st c="82722">is, we can still come
    up with a good estimate of the population mean if we have a sufficiently big sample
    size</st> <st c="82834">n</st><st c="82835">, and the preceding formula helps
    us work out how big that sample size needs to be.</st> <st c="82919">This is one
    of the beauties of statistical analysis.</st> <st c="82972">No matter how big
    the noise in individual data points is, we can still recover an accurate estimate
    of the population mean by having</st> <st c="83105">enough datapoints.</st>
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="82343">因此，样本均值的标准差（对于独立同分布的数据）为</st> <st c="82402">σ</st> <st c="82411">/</st>
    <st c="82412">√</st><st c="82413">_</st><st c="82414">n</st> <st c="82416">。这也被称为</st>
    <st c="82445">样本均值的</st> **<st c="82450">标准误差</st>** <st c="82464">– 它是样本均值作为总体均值的估计时所产生的典型误差大小</st>
    <st c="82602">μ</st><st c="82603">。还要记住，</st> <st c="82629">σ</st> <st c="82630">是每个数据点的总体标准差。</st>
    <st c="82699">因此，无论</st> <st c="82721">σ</st> <st c="82722">多大，如果样本量足够大，我们仍然可以得到一个很好的总体均值估计</st>
    <st c="82834">n</st><st c="82835">，而前面的公式帮助我们算出需要的样本量。</st> <st c="82919">这就是统计分析的魅力之一。</st>
    <st c="82972">无论个别数据点的噪声有多大，我们只要有足够的数据点，仍然可以恢复一个准确的总体均值估计。</st>
- en: '*<st c="83123">To sum up</st>*<st c="83133">: For any statistical estimator
    (that is, for any formula we use to estimate a population quantity), we ideally
    want three criteria to be met.</st> <st c="83277">Those criteria are</st> <st
    c="83296">the following:</st>'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '*<st c="83123">总结</st>*<st c="83133">：对于任何统计估计量（即，我们用来估计总体量的公式），我们理想中希望满足三个标准。</st>
    <st c="83277">这三个标准是</st> <st c="83296">以下内容：</st>'
- en: '**<st c="83310">Consistency</st>** <st c="83322">– An</st> <st c="83327">estimator
    converges to the (population) quantity it is attempting to estimate as the sample
    size</st> <st c="83425">n</st> <st c="83426">→</st> <st c="83427">∞</st><st c="83428">.
    In simple terms, the estimator gets better and better as we give it more data.</st>
    <st c="83509">The sample mean and sample variance are</st> <st c="83549">consistent
    estimators.</st>'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="83310">一致性</st>** <st c="83322">– 估计量随着样本量</st> <st c="83425">n</st>
    <st c="83426">→</st> <st c="83427">∞</st><st c="83428">的增大，逐渐收敛于它试图估计的（总体）量。</st>
    <st c="83428">简单来说，随着我们提供更多的数据，估计量变得越来越好。</st> <st c="83509">样本均值和样本方差是</st> <st
    c="83549">一致的估计量。</st>'
- en: '**<st c="83571">Unbiasedness</st>** <st c="83584">– An</st> <st c="83590">unbiased
    estimator has an expectation value equal to the (population) quantity it is attempting
    to estimate.</st> <st c="83699">In simple terms, the estimate is accurate on average,
    even for finite sample sizes.</st> <st c="83783">The sample mean and sample variance
    (with a denominator of</st> <st c="83842">n</st> <st c="83843">−</st> <st c="83844">1</st><st
    c="83845">) are</st> <st c="83851">unbiased estimators.</st>'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="83571">无偏性</st>** <st c="83584">– 无偏估计量的期望值等于它试图估计的（总体）量。</st> <st
    c="83590">简单来说，估计量在平均值上是准确的，即使对于有限样本量也是如此。</st> <st c="83699">样本均值和样本方差（分母为</st>
    <st c="83842">n</st> <st c="83843">−</st> <st c="83844">1</st><st c="83845">）是</st>
    <st c="83851">无偏估计量。</st>'
- en: '**<st c="83871">Efficiency</st>** <st c="83882">– Efficiency</st> <st c="83896">measures
    how quickly the variance of an unbiased estimator converges to zero as the sample
    size</st> <st c="83992">n</st> <st c="83993">→</st> <st c="83994">∞</st><st c="83995">.
    In simple terms, an efficient unbiased estimator makes good use of the data given
    to it.</st> <st c="84086">It turns out that the sample mean has the best efficiency
    of any linear estimator of the</st> <st c="84175">population mean.</st>'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="83871">效率</st>** <st c="83882">– 效率</st> <st c="83896">衡量无偏估计量的方差如何随着样本量</st>
    <st c="83992">n</st> <st c="83993">→</st> <st c="83994">∞</st><st c="83995">快速收敛至零。</st>
    <st c="84086">简单来说，一个高效的无偏估计量能够充分利用所给的数据。</st> <st c="84086">结果证明，样本均值是所有线性估计量中效率最高的估计量。</st>
    <st c="84175">总体均值。</st>'
- en: <st c="84191">Applying the concept of efficiency</st>
  id: totrans-393
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <st c="84191">应用效率的概念</st>
- en: <st c="84226">Let’s</st> <st c="84232">return to our CTR example.</st> <st c="84260">We
    had a sample size of</st> <st c="84284">n</st> <st c="84285">=</st> <st c="84286">20</st><st
    c="84288">. Our single sample had a sample mean of 0.6 (60%).</st> <st c="84340">We
    can model each user’s decision to click as a</st> <st c="84388">Bernoulli</st><st
    c="84397">(</st><st c="84399">p</st><st c="84400">)</st> <st c="84401">random
    variable.</st> <st c="84419">We know that the variance of each Bernoulli trial
    is</st> <st c="84472">p</st><st c="84473">(</st><st c="84474">1</st> <st c="84475">−</st>
    <st c="84476">p</st><st c="84477">)</st><st c="84478">, and so the standard error
    of the sample mean is</st> <st c="84528">√</st><st c="84529">_</st><st c="84530">p</st><st
    c="84531">(</st><st c="84532">1</st> <st c="84533">−</st> <st c="84534">p</st><st
    c="84535">)</st> <st c="84536">/</st> <st c="84537">20</st> <st c="84539">. But
    we don’t know what the true value of</st> <st c="84582">p</st> <st c="84583">is,
    the true CTR.</st> <st c="84602">But we do have our estimate of the CTR, so we
    can plug our sample mean of 0.6 into the formula</st> <st c="84697">√</st><st
    c="84698">_</st><st c="84699">p</st><st c="84700">(</st><st c="84701">1</st> <st
    c="84702">−</st> <st c="84703">p</st><st c="84704">)</st> <st c="84705">/</st>
    <st c="84706">20</st> <st c="84708">to get an approximate value of the standard
    error.</st> <st c="84760">In this case, we find</st> <st c="84782">√</st><st c="84783">____________</st><st
    c="84795">0.6</st> <st c="84799">×</st> <st c="84801">0.4</st> <st c="84804">/</st>
    <st c="84806">20</st> <st c="84808">≈</st> <st c="84810">0.11</st><st c="84814">.
    So, we should not be surprised if the real (population) CTR was as low as 0.5
    or 0.4\.</st> <st c="84902">As we have already said, our sample of 20 website
    visitors does not give us confidence in our conclusions.</st> <st c="85009">However,
    we can easily work out how big our sample size would need to be for us to be confident
    in that estimated CTR of 0.6\.</st> <st c="85135">Let’s say I wanted the standard
    error to be smaller than 0.01\.</st> <st c="85198">Again, if we assume our initial
    estimate of 0.6 is in the right ballpark, we can simply equate the formula in</st>
    *<st c="85308">Eq.</st> <st c="85312">55</st>* <st c="85314">for the standard
    error of the sample mean with 0.01 and solve for the required sample size</st>
    <st c="85406">n</st><st c="85407">. That is, we solve for</st> <st c="85431">the
    following:</st>
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="84226">让我们</st> <st c="84232">回到我们的CTR示例。</st> <st c="84260">我们的样本大小是</st>
    <st c="84284">n</st> <st c="84285">=</st> <st c="84286">20</st><st c="84288">。我们的单一样本的样本均值为0.6（60%）。</st>
    <st c="84340">我们可以将每个用户点击的决策建模为一个</st> <st c="84388">伯努利</st><st c="84397">(</st><st
    c="84399">p</st><st c="84400">)</st> <st c="84401">随机变量。</st> <st c="84419">我们知道，每个伯努利试验的方差为</st>
    <st c="84472">p</st><st c="84473">(</st><st c="84474">1</st> <st c="84475">−</st>
    <st c="84476">p</st><st c="84477">)</st><st c="84478">，因此样本均值的标准误差为</st> <st c="84528">√</st><st
    c="84529">_</st><st c="84530">p</st><st c="84531">(</st><st c="84532">1</st> <st
    c="84533">−</st> <st c="84534">p</st><st c="84535">)</st> <st c="84536">/</st>
    <st c="84537">20</st> <st c="84539">。但是我们并不知道</st> <st c="84582">p</st> <st c="84583">的真实值，也就是实际CTR。</st>
    <st c="84602">但我们确实有CTR的估计值，因此我们可以将样本均值0.6代入公式</st> <st c="84697">√</st><st c="84698">_</st><st
    c="84699">p</st><st c="84700">(</st><st c="84701">1</st> <st c="84702">−</st>
    <st c="84703">p</st><st c="84704">)</st> <st c="84705">/</st> <st c="84706">20</st>
    <st c="84708">以获得标准误差的近似值。</st> <st c="84760">在这种情况下，我们得到</st> <st c="84782">√</st><st
    c="84783">____________</st><st c="84795">0.6</st> <st c="84799">×</st> <st c="84801">0.4</st>
    <st c="84804">/</st> <st c="84806">20</st> <st c="84808">≈</st> <st c="84810">0.11</st><st
    c="84814">。所以，如果实际（总体）CTR低至0.5或0.4，我们不应该感到惊讶。</st> <st c="84902">正如我们之前所说，我们的20个网站访客样本并不能给我们带来足够的信心来得出结论。</st>
    <st c="85009">然而，我们可以轻松地计算出，为了让我们对估计的0.6 CTR有信心，样本大小应该有多大。</st> <st c="85135">假设我希望标准误差小于0.01。</st>
    <st c="85198">再一次，如果我们假设最初的0.6估计值是正确的，我们可以简单地将</st> *<st c="85308">公式</st> <st
    c="85312">55</st>* <st c="85314">中关于样本均值标准误差的公式与0.01相等，然后解出所需的样本大小</st> <st c="85406">n</st><st
    c="85407">。也就是说，我们需要解以下方程：</st>
- en: <st c="85445">p</st><st c="85447">(</st><st c="85448">1</st> <st c="85449">−</st>
    <st c="85450">p</st><st c="85451">)</st><st c="85452">_</st><st c="85453">n</st>
    <st c="85454">=</st> <st c="85455">0.01</st><st c="85459">2</st>
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="85445">p</st><st c="85447">(</st><st c="85448">1</st> <st c="85449">−</st>
    <st c="85450">p</st><st c="85451">)</st><st c="85452">_</st><st c="85453">n</st>
    <st c="85454">=</st> <st c="85455">0.01</st><st c="85459">2</st>
- en: <st c="85461">Eq.</st> <st c="85465">56</st>
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="85461">公式</st> <st c="85465">56</st>
- en: <st c="85467">This is done for</st> <st c="85485">n</st> <st c="85486">and where
    we plug in our sample mean of 0.6 as the value of</st> <st c="85547">p</st><st
    c="85548">. Solving the preceding equation for</st> <st c="85585">n</st><st c="85586">,
    we find the required sample size is</st> <st c="85624">the following:</st>
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="85467">这是针对</st> <st c="85485">n</st> <st c="85486">进行的计算，我们将样本均值0.6代入作为</st>
    <st c="85547">p</st><st c="85548">的值。解出前面的方程得到</st> <st c="85585">n</st><st c="85586">，我们发现所需的样本量为</st>
    <st c="85624">如下：</st>
- en: <st c="85638">n</st> <st c="85640">=</st> <st c="85641">0.6</st> <st c="85644">×</st>
    <st c="85646">0.4</st><st c="85649">_</st><st c="85651">0.01</st><st c="85655">2</st>
    <st c="85657">=</st> <st c="85658">2400</st>
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="85638">n</st> <st c="85640">=</st> <st c="85641">0.6</st> <st c="85644">×</st>
    <st c="85646">0.4</st><st c="85649">_</st><st c="85651">0.01</st><st c="85655">2</st>
    <st c="85657">=</st> <st c="85658">2400</st>
- en: <st c="85662">Eq.</st> <st c="85667">57</st>
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="85662">公式</st> <st c="85667">57</st>
- en: <st c="85669">So, we need a couple of thousand website visitors for our experiment
    to reach a sound business conclusion.</st> <st c="85777">With 10 million annual
    visitors this is still entirely doable, but now we are basing our method</st>
    <st c="85873">and decisions on some sound statistical analysis and data science
    rather than guesswork.</st> <st c="85962">The calculation of the required sample
    size we have just walked through is somewhat hand-waving in places.</st> <st c="86069">When
    we come to</st> [*<st c="86085">Chapter 7</st>*](B19496_07.xhtml#_idTextAnchor369)<st
    c="86094">, we will learn how to do these calculations of the required sample
    size more rigorously.</st> <st c="86184">They are</st> <st c="86192">called</st>
    **<st c="86200">power calculations</st>**<st c="86218">. However, the principles
    and spirit of those rigorous power calculations are essentially the same as we
    have</st> <st c="86328">just outlined.</st>
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="85669">因此，为了得出有效的商业结论，我们的实验需要几千名网站访问者。</st> <st c="85777">对于年访问量为1000万的情况，这是完全可行的，但现在我们的方式</st>
    <st c="85873">和决策是基于可靠的统计分析和数据科学，而非猜测。</st> <st c="85962">我们刚才讲解的所需样本量的计算方法在某些地方显得有些随意。</st>
    <st c="86069">当我们进入</st> [*<st c="86085">第7章</st>*](B19496_07.xhtml#_idTextAnchor369)<st
    c="86094">时，我们将学习如何更严格地进行这些样本量计算。</st> <st c="86184">这些计算被称为</st> <st c="86192">**<st
    c="86200">效能计算</st>**</st><st c="86218">。然而，这些严格的效能计算的原则和精神，本质上与我们刚才概述的相同。</st>
- en: <st c="86342">The empirical distribution function</st>
  id: totrans-401
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="86342">经验分布函数</st>
- en: <st c="86378">We have now linked the properties and characteristics of samples
    of data to the properties and characteristics of the underlying population distributions
    from which we have assumed the data comes.</st> <st c="86576">We’re now going
    to make the link between samples and distributions stronger by asking if we</st>
    <st c="86667">can view a sample as being some sort of distribution.</st> <st c="86722">The
    answer is yes.</st> <st c="86741">Enter the</st> **<st c="86751">empirical distribution
    function</st>** <st c="86782">(</st>**<st c="86784">EDF</st>**<st c="86787">)
    or, equivalently, the</st> **<st c="86812">empirical cumulative probability function</st>**
    <st c="86853">(</st>**<st c="86855">eCDF</st>**<st c="86859">).</st> <st c="86863">We</st>
    <st c="86866">use the word</st> *<st c="86879">empirical</st>* <st c="86888">to
    emphasize that this distribution is based on real observations; that</st> <st
    c="86961">is, data.</st>
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="86378">现在我们已经将数据样本的属性和特征与我们假设数据来自的底层总体分布的属性和特征联系起来。</st> <st c="86576">接下来，我们将通过问自己能否将样本视为某种分布，来加强样本与分布之间的联系。</st>
    <st c="86667">答案是肯定的。</st> <st c="86722">这时，引入</st> **<st c="86751">经验分布函数</st>**
    <st c="86782">（</st>**<st c="86784">EDF</st>**<st c="86787">）或者等价地，</st> **<st
    c="86812">经验累计概率函数</st>** <st c="86853">（</st>**<st c="86855">eCDF</st>**<st c="86859">）。</st>
    <st c="86863">我们使用“</st> *<st c="86879">经验</st>* <st c="86888">”这个词来强调这个分布是基于真实观测的；也就是说，基于数据。</st>
- en: <st c="86970">If we had a sample of 30 data values</st> <st c="87008">x</st><st
    c="87009">1</st><st c="87010">,</st> <st c="87011">x</st><st c="87012">2</st><st
    c="87013">,</st> <st c="87014">⋯</st> <st c="87015">,</st> <st c="87016">x</st><st
    c="87017">30</st> <st c="87019">and we wanted to think of them as some sort of
    probability distribution, we would have to be able to plot them as a collection
    of bars as in</st> *<st c="87161">Figure 2</st>**<st c="87169">.4</st>*<st c="87171">.
    We have 30 datapoints, so we can think of the distribution as 30 vertical bars,
    each centered on one of the datapoints.</st> <st c="87293">Since the total probability
    in a distribution must add up to 1, each bar has a weight 1/30\.</st> <st c="87385">And
    since we have only seen values corresponding to the actual data values</st> <st
    c="87460">x</st><st c="87461">1</st><st c="87462">,</st> <st c="87463">x</st><st
    c="87464">2</st><st c="87465">,</st> <st c="87466">⋯</st> <st c="87467">,</st>
    <st c="87468">x</st><st c="87469">30</st><st c="87471">, those bars are infinitesimally
    thin – there is no probability of getting any possible value other than</st> <st
    c="87576">x</st><st c="87577">1</st> <st c="87578">or</st> <st c="87582">x</st><st
    c="87583">2</st> <st c="87584">or…..</st><st c="87590">x</st><st c="87592">30</st><st
    c="87594">. So, our empirical distribution is actually a series of infinitely
    narrow s</st><st c="87670">pikes.</st> <st c="87678">We have drawn that schematically
    in</st> *<st c="87714">Figure 2</st>**<st c="87722">.14</st>* <st c="87725">for
    a set of 30 real</st> <st c="87747">x</st> <st c="87748">values:</st>
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="86970">如果我们有一个包含 30 个数据值的样本</st> <st c="87008">x</st><st c="87009">1</st><st
    c="87010">,</st> <st c="87011">x</st><st c="87012">2</st><st c="87013">,</st>
    <st c="87014">⋯</st> <st c="87015">,</st> <st c="87016">x</st><st c="87017">30</st>
    <st c="87019">，并且我们希望将它们视为某种概率分布，那么我们就需要能够将它们绘制为一组条形图，如</st> *<st c="87161">图
    2</st>**<st c="87169">.4</st>*<st c="87171">所示。我们有 30 个数据点，所以我们可以将分布看作是 30 根垂直的条形图，每根条形图都以一个数据点为中心。</st>
    <st c="87293">由于分布中的总概率必须加起来为 1，所以每根条形图的权重为 1/30。</st> <st c="87385">而且由于我们只看到了与实际数据值对应的值</st>
    <st c="87460">x</st><st c="87461">1</st><st c="87462">,</st> <st c="87463">x</st><st
    c="87464">2</st><st c="87465">,</st> <st c="87466">⋯</st> <st c="87467">,</st>
    <st c="87468">x</st><st c="87469">30</st><st c="87471">，这些条形图是无限薄的——没有任何其他可能值的概率，除了</st>
    <st c="87576">x</st><st c="87577">1</st> <st c="87578">或</st> <st c="87582">x</st><st
    c="87583">2</st> <st c="87584">或…..</st><st c="87590">x</st><st c="87592">30</st><st
    c="87594">。所以，我们的经验分布实际上是一系列无限窄的尖峰。</st> <st c="87670">我们已在</st> *<st c="87714">图
    2</st>**<st c="87722">.14</st>* <st c="87725">中以示意图的形式绘制了这一点，针对一组 30 个真实的</st>
    <st c="87747">x</st> <st c="87748">值：</st>
- en: '![Figure 2.14: Representing a sample as a series of spikes](img/B19496_02_16.jpg)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.14：将样本表示为一系列尖峰](img/B19496_02_16.jpg)'
- en: '<st c="87797">Figure 2.14: Representing a sample as a series of spikes</st>'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="87797">图 2.14：将样本表示为一系列尖峰</st>
- en: '*<st c="87853">Figure 2</st>**<st c="87862">.14</st>* <st c="87865">shows a</st>
    <st c="87874">schematic representation of the EDF, but how do we represent it
    mathematically?</st> <st c="87954">We’ll build it up mathematically in stages.</st>
    <st c="87998">Mathematically, we want to represent the first spike as a function
    that picks out only the value</st> <st c="88095">x</st><st c="88096">1</st><st
    c="88097">, which is 0.3 in this example.</st> <st c="88129">The mathematical
    function that does this is the Dirac delta function, or Dirac δ function, named
    after the famous physicist Paul Dirac.</st> <st c="88265">The Dirac delta function,</st>
    <st c="88291">δ</st><st c="88292">(</st><st c="88293">x</st><st c="88294">)</st><st
    c="88295">, is actually a distribution.</st> <st c="88325">It is sometimes referred
    to as being a generalized function, but it is easier to loose</st><st c="88411">ly
    think of it as a cont</st><st c="88436">inuous probability distribution with the</st>
    <st c="88478">following properties:</st>'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '*<st c="87853">图 2</st>**<st c="87862">.14</st>* <st c="87865">显示了经验分布函数（EDF）的示意图，但我们如何用数学表示它呢？</st>
    <st c="87954">我们将分阶段地构建它。</st> <st c="87998">从数学上讲，我们希望将第一个尖峰表示为一个只选取值</st> <st
    c="88095">x</st><st c="88096">1</st><st c="88097">的函数，在这个例子中，x<sub>1</sub> 的值是
    0.3。</st> <st c="88129">实现这一功能的数学函数是狄拉克δ函数，或称狄拉克 δ 函数，以著名物理学家保罗·狄拉克命名。</st> <st
    c="88265">狄拉克δ函数</st>，<st c="88291">δ</st><st c="88292">(</st><st c="88293">x</st><st
    c="88294">)</st><st c="88295">，实际上是一个分布。</st> <st c="88325">它有时被称为广义函数，但更容易把它看作一个连续的概率分布，具备以下特性：</st>'
- en: <st c="88499">∫</st><st c="88501">c</st><st c="88502">−</st><st c="88503">ε</st><st
    c="88504">c</st><st c="88505">+</st><st c="88506">ε</st><st c="88507">δ</st><st
    c="88508">(</st><st c="88509">x</st> <st c="88510">−</st> <st c="88511">c</st><st
    c="88512">)</st> <st c="88513">dx</st> <st c="88515">=</st> <st c="88517">1</st>
    <st c="88518">for any</st> <st c="88526">ε</st> <st c="88527">></st> <st c="88528">0</st>
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="88499">∫</st><st c="88501">c</st><st c="88502">−</st><st c="88503">ε</st><st
    c="88504">c</st><st c="88505">+</st><st c="88506">ε</st><st c="88507">δ</st><st
    c="88508">(</st><st c="88509">x</st> <st c="88510">−</st> <st c="88511">c</st><st
    c="88512">)</st> <st c="88513">dx</st> <st c="88515">=</st> <st c="88517">1</st>
    <st c="88518">对于任意</st> <st c="88526">ε</st> <st c="88527">></st> <st c="88528">0</st>
- en: <st c="88529">Eq.</st> <st c="88533">58</st>
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="88529">公式</st> <st c="88533">58</st>
- en: <st c="88535">∫</st><st c="88537">c</st><st c="88538">−</st><st c="88539">ε</st><st
    c="88540">c</st><st c="88541">+</st><st c="88542">ε</st><st c="88543">δ</st><st
    c="88544">(</st><st c="88545">x</st> <st c="88546">−</st> <st c="88547">c</st><st
    c="88548">)</st><st c="88549">g</st><st c="88550">(</st><st c="88551">x</st><st
    c="88552">)</st><st c="88553">dx</st> <st c="88555">=</st> <st c="88557">g</st><st
    c="88558">(</st><st c="88559">c</st><st c="88560">)</st> <st c="88561">for any</st>
    <st c="88570">ε</st> <st c="88571">> 0</st>
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="88535">∫</st><st c="88537">c</st><st c="88538">−</st><st c="88539">ε</st><st
    c="88540">c</st><st c="88541">+</st><st c="88542">ε</st><st c="88543">δ</st><st
    c="88544">(</st><st c="88545">x</st> <st c="88546">−</st> <st c="88547">c</st><st
    c="88548">)</st><st c="88549">g</st><st c="88550">(</st><st c="88551">x</st><st
    c="88552">)</st><st c="88553">dx</st> <st c="88555">=</st> <st c="88557">g</st><st
    c="88558">(</st><st c="88559">c</st><st c="88560">)</st> <st c="88561">对于任意</st>
    <st c="88570">ε</st> <st c="88571">> 0</st>
- en: <st c="88575">Eq.</st> <st c="88580">59</st>
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="88575">公式</st> <st c="88580">59</st>
- en: <st c="88582">So, if we have a delta function,</st> <st c="88616">δ</st><st
    c="88617">(</st><st c="88618">x</st><st c="88619">−</st> <st c="88620">x</st><st
    c="88621">1</st><st c="88622">)</st><st c="88623">, centered on</st> <st c="88637">x</st><st
    c="88638">1</st><st c="88639">, then using</st> *<st c="88652">Eq.</st> <st c="88656">19</st>*
    <st c="88658">and</st> *<st c="88663">Eq.</st> <st c="88667">20</st>* <st c="88669">for
    the mean and variance of a continuous probability distribution, we can think of</st>
    <st c="88754">δ</st><st c="88755">(</st><st c="88756">x</st><st c="88757">−</st>
    <st c="88758">x</st><st c="88759">1</st><st c="88760">)</st> <st c="88761">as
    a probability distribution with mean</st> <st c="88802">x</st><st c="88803">1</st>
    <st c="88804">and variance zero.</st> <st c="88824">So, sampling from</st> <st
    c="88842">δ</st><st c="88843">(</st><st c="88844">x</st><st c="88845">−</st> <st
    c="88846">x</st><st c="88847">1</st><st c="88848">)</st> <st c="88849">would only
    ever give us the value</st> <st c="88884">x</st><st c="88885">1</st><st c="88886">,
    which is what</st> <st c="88902">we want.</st>
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="88582">因此，如果我们有一个狄拉克 delta 函数，</st> <st c="88616">δ</st><st c="88617">(</st><st
    c="88618">x</st><st c="88619">−</st> <st c="88620">x</st><st c="88621">1</st><st
    c="88622">)</st><st c="88623">，以</st> <st c="88637">x</st><st c="88638">1</st><st
    c="88639">为中心，那么使用</st> *<st c="88652">公式</st> <st c="88656">19</st>* <st c="88658">和</st>
    *<st c="88663">公式</st> <st c="88667">20</st>* <st c="88669">来计算连续概率分布的均值和方差，我们可以将</st>
    <st c="88754">δ</st><st c="88755">(</st><st c="88756">x</st><st c="88757">−</st>
    <st c="88758">x</st><st c="88759">1</st><st c="88760">)</st> <st c="88761">视为一个均值为</st>
    <st c="88802">x</st><st c="88803">1</st> <st c="88804">且方差为零的概率分布。</st> <st c="88824">因此，从</st>
    <st c="88842">δ</st><st c="88843">(</st><st c="88844">x</st><st c="88845">−</st>
    <st c="88846">x</st><st c="88847">1</st><st c="88848">)</st> <st c="88849">进行采样将始终只给我们值</st>
    <st c="88884">x</st><st c="88885">1</st><st c="88886">，这正是</st> <st c="88902">我们想要的。</st>
- en: <st c="88910">If we repeat the process by putting a Dirac delta function centered
    on each of our 30 datapoints</st> <st c="89008">x</st><st c="89009">1</st><st
    c="89010">,</st> <st c="89011">x</st><st c="89012">2</st><st c="89013">,</st>
    <st c="89014">⋯</st> <st c="89015">,</st> <st c="89016">x</st><st c="89017">30</st><st
    c="89019">, we can think of our sample as being equivalent to the</st> <st c="89075">following
    PDF:</st>
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="88910">如果我们通过将一个 Dirac delta 函数置于我们的 30 个数据点每个点上来重复这个过程，</st> <st c="89008">x</st><st
    c="89009">1</st><st c="89010">，</st> <st c="89011">x</st><st c="89012">2</st><st
    c="89013">，</st> <st c="89014">⋯</st> <st c="89015">，</st> <st c="89016">x</st><st
    c="89017">30</st><st c="89019">，我们可以将我们的样本视为等价于以下的概率密度函数（PDF）：</st>
- en: <st c="89089">1</st><st c="89091">_</st><st c="89092">30</st> <st c="89094">∑</st><st
    c="89096">i</st><st c="89097">=</st><st c="89098">1</st><st c="89099">30</st><st
    c="89101">δ</st><st c="89103">(</st><st c="89104">x</st><st c="89105">−</st> <st
    c="89106">x</st><st c="89107">i</st><st c="89108">)</st>
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="89089">1</st><st c="89091">_</st><st c="89092">30</st> <st c="89094">∑</st><st
    c="89096">i</st><st c="89097">=</st><st c="89098">1</st><st c="89099">30</st><st
    c="89101">δ</st><st c="89103">(</st><st c="89104">x</st><st c="89105">−</st> <st
    c="89106">x</st><st c="89107">i</st><st c="89108">)</st>
- en: <st c="89109">Eq.</st> <st c="89113">60</st>
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="89109">公式</st> <st c="89113">60</st>
- en: <st c="89115">For a sample,</st> <st c="89130">x</st><st c="89131">1</st><st
    c="89132">,</st> <st c="89133">x</st><st c="89134">2</st><st c="89135">,</st>
    <st c="89136">⋯</st> <st c="89137">,</st> <st c="89138">x</st><st c="89139">n</st><st
    c="89140">, of</st> <st c="89145">n</st> <st c="89146">datapoints, the ge</st><st
    c="89165">neralization is obvious – we can view our sample as being a distribution</st>
    <st c="89239">with density:</st>
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="89115">对于一个样本，</st> <st c="89130">x</st><st c="89131">1</st><st c="89132">,</st>
    <st c="89133">x</st><st c="89134">2</st><st c="89135">,</st> <st c="89136">⋯</st>
    <st c="89137">,</st> <st c="89138">x</st><st c="89139">n</st><st c="89140">, 包含</st>
    <st c="89145">n</st> <st c="89146">个数据点，概括是显而易见的——我们可以将样本看作是一个分布</st> <st c="89239">，其密度为：</st>
- en: <st c="89252">1</st><st c="89254">_</st><st c="89255">n</st> <st c="89256">∑</st><st
    c="89257">i</st><st c="89258">=</st><st c="89259">1</st><st c="89260">n</st><st
    c="89261">δ</st><st c="89262">(</st><st c="89263">x</st><st c="89264">−</st> <st
    c="89265">x</st><st c="89266">i</st><st c="89267">)</st>
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="89252">1</st><st c="89254">_</st><st c="89255">n</st> <st c="89256">∑</st><st
    c="89257">i</st><st c="89258">=</st><st c="89259">1</st><st c="89260">n</st><st
    c="89261">δ</st><st c="89262">(</st><st c="89263">x</st><st c="89264">−</st> <st
    c="89265">x</st><st c="89266">i</st><st c="89267">)</st>
- en: <st c="89268">Eq.</st> <st c="89272">61</st>
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="89268">公式</st> <st c="89272">61</st>
- en: <st c="89274">Why is this useful?</st> <st c="89295">Well, sometimes</st> <st
    c="89310">we have a metric or expression or concept that we know how to compute
    for continuous probability distributions, but we don’t quite know how to calculate
    the equivalent or corresponding metric or formula for a sample of data.</st> <st
    c="89536">No problem!</st> <st c="89548">Simply plug</st> *<st c="89560">Eq.</st>
    <st c="89564">61</st>* <st c="89566">into the formula for continuous probability
    distributions, simplify using</st> *<st c="89641">Eq.</st> <st c="89645">59</st>*<st
    c="89647">, and you have an answer.</st> <st c="89673">You don’t believe me?</st>
    <st c="89695">Plug the distribution in</st> *<st c="89720">Eq.</st> <st c="89724">61</st>*
    <st c="89726">into</st> *<st c="89732">Eq.</st> <st c="89736">19</st>* <st c="89738">and</st>
    *<st c="89743">Eq.</st> <st c="89747">20</st>* <st c="89749">for the mean and
    variance of a continuous probability distribution and what you get out are the
    expressions in</st> *<st c="89861">Eq.</st> <st c="89865">46</st>* <st c="89867">and</st>
    *<st c="89872">Eq.</st> <st c="89876">48</st>*<st c="89878">, for the sample mean
    and sample variance (up to a factor of</st> <st c="89939">n</st><st c="89940">_</st><st
    c="89941">n</st> <st c="89942">−</st> <st c="89943">1</st> <st c="89944">).</st>
    <st c="89948">Give it</st> <st c="89956">a try.</st>
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="89274">这为什么有用？</st> <st c="89295">有时，</st> <st c="89310">我们知道如何计算连续概率分布的某些度量、表达式或概念，但不清楚如何计算数据样本的等效度量或公式。</st>
    <st c="89536">没问题！</st> <st c="89548">只需将</st> *<st c="89560">公式</st> <st c="89564">61</st>*
    <st c="89566">代入连续概率分布的公式，使用</st> *<st c="89641">公式</st> <st c="89645">59</st>*<st
    c="89647">进行简化，你就能得到答案。</st> <st c="89673">你不相信我？</st> <st c="89695">将分布代入</st>
    *<st c="89720">公式</st> <st c="89724">61</st>* <st c="89726">到</st> *<st c="89732">公式</st>
    <st c="89736">19</st>* <st c="89738">和</st> *<st c="89743">公式</st> <st c="89747">20</st>*
    <st c="89749">中，得到的均值和方差的表达式就是</st> *<st c="89861">公式</st> <st c="89865">46</st>*
    <st c="89867">和</st> *<st c="89872">公式</st> <st c="89876">48</st>*<st c="89878">，分别是样本均值和样本方差（最多差一个因子</st>
    <st c="89939">n</st><st c="89940">_</st><st c="89941">n</st> <st c="89942">−</st>
    <st c="89943">1</st> <st c="89944">）。</st> <st c="89948">试试看吧。</st>
- en: <st c="89962">From the EDF in</st> *<st c="89979">Eq.</st> <st c="89983">61</st>*<st
    c="89985">, we can calculate the corresponding eCDF.</st> <st c="90028">The cumulative
    probability function</st> <st c="90064">CDF</st><st c="90067">(</st><st c="90069">x</st><st
    c="90070">)</st> <st c="90071">is the probability of getting a value less than
    or equal to</st> <st c="90132">x</st><st c="90133">. So for a continuous ra</st><st
    c="90157">ndom variable with density function</st> <st c="90194">f</st><st c="90195">(</st><st
    c="90196">x</st><st c="90197">)</st><st c="90198">, the CDF is given by</st> <st
    c="90220">the following:</st>
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="89962">从</st> *<st c="89979">公式</st> <st c="89983">61</st>*<st c="89985">中，我们可以计算出相应的经验累计分布函数（eCDF）。</st>
    <st c="90028">累积分布函数</st> <st c="90064">CDF</st><st c="90067">(</st><st c="90069">x</st><st
    c="90070">)</st> <st c="90071">是获取小于或等于</st> <st c="90132">x</st><st c="90133">的概率。所以，对于一个具有密度函数</st>
    <st c="90157">f</st><st c="90195">(</st><st c="90196">x</st><st c="90197">)</st><st
    c="90198">的连续随机变量，其CDF由以下给出：</st> <st c="90220">公式：</st>
- en: <st c="90234">CDF</st><st c="90238">(</st><st c="90240">x</st><st c="90241">)</st>
    <st c="90242">=</st> <st c="90243">∫</st><st c="90244">−</st><st c="90245">∞</st><st
    c="90246">x</st><st c="90247">f</st><st c="90248">(</st><st c="90249">s</st><st
    c="90250">)</st><st c="90251">ds</st>
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="90234">CDF</st><st c="90238">(</st><st c="90240">x</st><st c="90241">)</st>
    <st c="90242">=</st> <st c="90243">∫</st><st c="90244">−</st><st c="90245">∞</st><st
    c="90246">x</st><st c="90247">f</st><st c="90248">(</st><st c="90249">s</st><st
    c="90250">)</st><st c="90251">ds</st>
- en: <st c="90253">Eq.</st> <st c="90258">62</st>
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="90253">公式</st> <st c="90258">62</st>
- en: <st c="90260">Plugging the empirical density function in</st> *<st c="90304">Eq.</st>
    <st c="90308">61</st>* <st c="90310">into</st> *<st c="90316">Eq.</st> <st c="90320">62</st>*<st
    c="90322">, we get the eCDF.</st> <st c="90341">Using</st> *<st c="90347">Eq.</st>
    <st c="90351">58</st>*<st c="90353">, we can see that the eCDF goes through a
    series of steps, increasing by</st> <st c="90426">1</st><st c="90427">_</st><st
    c="90428">n</st> <st c="90429">every time</st> <st c="90441">x</st> <st c="90442">passes
    one of the datapoints.</st> <st c="90473">The eCDF for the sample shown in</st>
    *<st c="90506">Figure 2</st>**<st c="90514">.14</st>* <st c="90517">is shown in</st>
    *<st c="90530">Figure 2</st>**<st c="90538">.15</st>*<st c="90541">:</st>
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="90260">将经验密度函数代入</st> *<st c="90304">公式</st> <st c="90308">61</st>* <st
    c="90310">到</st> *<st c="90316">公式</st> <st c="90320">62</st>*<st c="90322">中，我们得到eCDF。</st>
    <st c="90341">使用</st> *<st c="90347">公式</st> <st c="90351">58</st>*<st c="90353">，我们可以看到，eCDF通过一系列步骤变化，每次</st>
    <st c="90426">x</st> <st c="90427">经过一个数据点时，增加</st> <st c="90441">1</st><st c="90442">_</st><st
    c="90443">n</st>。<st c="90429">eCDF对于示例中展示的样本</st> *<st c="90506">图 2</st>**<st
    c="90514">.14</st>* <st c="90517">如</st> *<st c="90530">图 2</st>**<st c="90538">.15</st>*<st
    c="90541">所示：</st>
- en: '![Figure 2.15: The eCDF for the series of 30 x values shown in Figure 2.14](img/B19496_02_17.jpg)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.15：图 2.14中所示的30个x值的eCDF](img/B19496_02_17.jpg)'
- en: '<st c="90570">Figure 2.15: The eCDF for the series of 30 x values shown in
    Figure 2.14</st>'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="90570">图 2.15：图 2.14中所示的30个x值的eCDF</st>
- en: <st c="90642">The</st> <st c="90647">stepped nature of the eCDF is clearly visible
    in</st> *<st c="90696">Figure 2</st>**<st c="90704">.15</st>*<st c="90707">. As
    the sample size</st> <st c="90728">n</st> <st c="90729">increases, the size of
    those steps decreases and the eCDF looks smoother and smoother.</st> <st c="90817">In
    fact, as</st> <st c="90829">n</st> <st c="90830">→</st> <st c="90831">∞</st><st
    c="90832">, the EDF in</st> *<st c="90845">Eq.</st> <st c="90849">61</st>* <st
    c="90851">and its associated eCDF converge to their population counterparts.</st>
    <st c="90919">So, just like we have used the sample mean and the sample variance
    as approximations of the population mean and population variance, we can use (when</st>
    <st c="91069">n</st> <st c="91070">is reasonably large) the empirical distribution
    in</st> *<st c="91122">Eq.</st> <st c="91126">61</st>* <st c="91128">as an approximation
    of the</st> <st c="91156">population distribution.</st>
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="90642">eCDF的阶梯状特征在</st> *<st c="90696">图 2</st>**<st c="90704">.15</st>*<st
    c="90707">中清晰可见。随着样本量</st> <st c="90728">n</st> <st c="90729">的增加，这些阶梯的大小逐渐减小，eCDF变得越来越平滑。</st>
    <st c="90817">事实上，当</st> <st c="90829">n</st> <st c="90830">→</st> <st c="90831">∞</st><st
    c="90832">时，</st> *<st c="90845">公式</st> <st c="90849">61</st>* <st c="90851">中的经验分布函数（EDF）及其相关的eCDF会收敛到它们的总体对应值。</st>
    <st c="90919">所以，就像我们将样本均值和样本方差作为总体均值和总体方差的近似一样，我们也可以在</st> <st c="91069">n</st>
    <st c="91070">足够大的时候，将</st> *<st c="91122">公式</st> <st c="91126">61</st>* <st
    c="91128">中的经验分布作为总体分布的近似。</st>
- en: <st c="91180">Excellent!</st> <st c="91192">We are making good progress on understanding
    and taming randomness in data.</st> <st c="91268">Having seen how we can use the
    eCDF to approximate a population CDF, let’s summarize what we have learned about
    statistical estimators and formulas in this section before we move on to our final
    section of</st> <st c="91474">the chapter.</st>
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="91180">太棒了！</st> <st c="91192">我们在理解和控制数据中的随机性方面取得了良好的进展。</st> <st c="91268">在了解如何使用经验累积分布函数（eCDF）来近似总体累积分布函数（CDF）之后，让我们总结一下这一部分中关于统计估计量和公式的内容，然后再进入本章的最后一部分。</st>
- en: <st c="91486">What we learned</st>
  id: totrans-427
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="91486">我们学到的内容</st>
- en: <st c="91502">In this section, we have learned</st> <st c="91536">the following:</st>
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="91502">在这一部分，我们学到了以下内容：</st>
- en: <st c="91550">How to calculate the sample mean and</st> <st c="91588">sample
    variance</st>
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="91550">如何计算样本均值和</st> <st c="91588">样本方差</st>
- en: <st c="91603">How the sample mean and sample variance converge to their population
    counterparts as we increase the</st> <st c="91705">sample size</st>
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="91603">样本均值和样本方差如何随着样本量的增加，逐渐接近其总体对应值</st>
- en: <st c="91716">How the sample mean and sample variance are unbiased estimators
    of their</st> <st c="91790">population counterparts</st>
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="91716">样本均值和样本方差如何成为其</st> <st c="91790">总体对应量的无偏估计量</st>
- en: <st c="91813">How to calculate the standard error (standard deviation) of the
    sample mean and how to use this to approximately calculate the sample size required
    to ensure the sample mean is a sufficiently accurate estimate of the</st> <st
    c="92031">population mean</st>
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="91813">如何计算样本均值的标准误差（标准差），以及如何利用这一点来近似计算确保样本均值是总体均值的足够准确估计所需的样本大小</st>
    <st c="92031">总体均值</st>
- en: <st c="92046">How to construct the EDF and use it as an approximation of the</st>
    <st c="92110">population distribution</st>
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="92046">如何构建经验分布函数（EDF）并将其用作</st> <st c="92110">总体分布的近似</st>
- en: <st c="92133">Having learned how to relate the characteristics of a sample to
    the characteristics of the underlying population, in the next section we will
    learn why a particular distribution, the normal distribution, is the most common
    distribution from which data</st> <st c="92386">is generated.</st>
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="92133">在学习了如何将样本的特征与基础总体的特征关联之后，在接下来的部分我们将学习为什么一种特定的分布——正态分布，是数据生成最常见的分布。</st>
- en: <st c="92399">The Central Limit Theorem</st>
  id: totrans-435
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="92399">中心极限定理</st>
- en: <st c="92425">Earlier in the chapter, when</st> <st c="92454">we were introducing
    specific continuous-valued distributions, we described the Gaussian or normal
    distribution and we said that it was an extremely important distribution because
    it was an extremely common distribution.</st> <st c="92675">By this, we meant
    that many datasets you will encounter will effectively have been drawn from a
    normal distribution, or you will use a normal distribution to model those datasets.</st>
    <st c="92855">We will now</st> <st c="92867">explain why.</st>
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="92425">在本章早些时候，当</st> <st c="92454">我们介绍特定的连续值分布时，我们描述了高斯分布或正态分布，并且我们说它是一个极其重要的分布，因为它是一个非常常见的分布。</st>
    <st c="92675">通过这点，我们的意思是，许多你将遇到的数据集实际上是从正态分布中抽取的，或者你将使用正态分布来建模这些数据集。</st> <st
    c="92855">我们现在将</st> <st c="92867">解释为什么。</st>
- en: <st c="92879">Sums of random variables</st>
  id: totrans-437
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="92879">随机变量的和</st>
- en: <st c="92904">Lots of the</st> <st c="92916">quantities we analyze as data scientists
    are aggregations of other data.</st> <st c="92990">Aggregating observations over
    some dimension to simplify the data is a very natural thing</st> <st c="93080">to
    do.</st>
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="92904">我们作为数据科学家分析的许多</st> <st c="92916">量是其他数据的聚合。</st> <st c="92990">在某个维度上聚合观测值以简化数据是一个非常自然的过程。</st>
- en: <st c="93086">For example, consider our e-commerce scenario where we are interested
    in how many items are sold.</st> <st c="93185">The number of items sold on any
    day of the year we might model as a binomial random variable, but what about for
    the whole year?</st> <st c="93314">Imagine we have a relatively niche website
    where we only get, say, 20 visitors a day who are thinking about buying a particular
    product, and the probability of any one of those visitors buying the product is
    0.3\.</st> <st c="93527">So, on any day</st> <st c="93542">t</st><st c="93543">,
    we can model the total items sold</st> <st c="93579">X</st><st c="93580">t</st>
    <st c="93581">as</st> <st c="93585">X</st><st c="93586">t</st> <st c="93587">~</st>
    <st c="93588">Binomial</st><st c="93596">(</st><st c="93598">20</st><st c="93600">,</st>
    <st c="93601">0.3</st><st c="93604">)</st><st c="93606">. We know from the properties
    of the binomial distribution that the mean number of items sold on any day is</st>
    <st c="93714">20</st> <st c="93716">×</st> <st c="93718">0.3</st><st c="93721">,
    while its variance is</st> <st c="93745">20</st> <st c="93747">×</st> <st c="93749">0.3</st>
    <st c="93752">×</st> <st c="93754">(</st><st c="93755">1</st> <st c="93756">−</st>
    <st c="93757">0.3</st><st c="93760">)</st><st c="93762">. The total number of
    items sold in a year is, simply,</st> <st c="93817">X</st><st c="93818">1</st><st
    c="93819">+</st> <st c="93820">X</st><st c="93821">2</st><st c="93822">+</st>
    <st c="93823">⋯</st> <st c="93824">+</st> <st c="93825">X</st><st c="93826">365</st><st
    c="93829">. This sum is a random variable itself.</st> <st c="93869">We will denote
    this sum by</st> <st c="93896">S</st><st c="93897">. As</st> <st c="93902">S</st>
    <st c="93903">is a sum of random variables, we can use the rules for combining
    random variables that we explained earlier in the chapter, to find</st> <st c="94036">the
    following:</st>
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="93086">例如，考虑我们的电子商务场景，其中我们关心的是每天售出的商品数量。</st> <st c="93185">每年任何一天的售出商品数量我们可以建模为一个二项分布随机变量，但全年呢？</st>
    <st c="93314">假设我们有一个相对小众的网站，每天大约有20个访客，他们正在考虑购买某个特定的产品，而这些访客中每一个人购买该产品的概率是0.3\。</st>
    <st c="93527">因此，在任何一天</st> <st c="93542">t</st><st c="93543">，我们可以将售出的总商品数量建模为</st>
    <st c="93579">X</st><st c="93580">t</st> <st c="93581">为</st> <st c="93585">X</st><st
    c="93586">t</st> <st c="93587">~</st> <st c="93588">Binomial</st><st c="93596">(</st><st
    c="93598">20</st><st c="93600">,</st> <st c="93601">0.3</st><st c="93604">)</st><st
    c="93606">。我们知道，依据二项分布的性质，任何一天售出的商品的平均数量为</st> <st c="93714">20</st> <st c="93716">×</st>
    <st c="93718">0.3</st><st c="93721">，而其方差为</st> <st c="93745">20</st> <st c="93747">×</st>
    <st c="93749">0.3</st> <st c="93752">×</st> <st c="93754">(</st><st c="93755">1</st>
    <st c="93756">−</st> <st c="93757">0.3</st><st c="93760">)</st><st c="93762">。全年售出的商品总数简单地为</st>
    <st c="93817">X</st><st c="93818">1</st><st c="93819">+</st> <st c="93820">X</st><st
    c="93821">2</st><st c="93822">+</st> <st c="93823">⋯</st> <st c="93824">+</st>
    <st c="93825">X</st><st c="93826">365</st><st c="93829">。这个和本身是一个随机变量。</st> <st
    c="93869">我们将这个和记作</st> <st c="93896">S</st><st c="93897">。由于</st> <st c="93902">S</st>
    <st c="93903">是随机变量的和，我们可以使用前面在章节中解释的组合随机变量的规则，来找出</st> <st c="94036">以下结果：</st>
- en: <st c="94050">𝔼</st><st c="94053">(</st><st c="94055">S</st><st c="94056">)</st>
    <st c="94057">=</st> <st c="94058">365</st> <st c="94061">×</st> <st c="94063">20</st>
    <st c="94065">×</st> <st c="94067">0.3</st> <st c="94070">=</st> <st c="94072">2190</st>
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94050">𝔼</st><st c="94053">(</st><st c="94055">S</st><st c="94056">)</st>
    <st c="94057">=</st> <st c="94058">365</st> <st c="94061">×</st> <st c="94063">20</st>
    <st c="94065">×</st> <st c="94067">0.3</st> <st c="94070">=</st> <st c="94072">2190</st>
- en: <st c="94076">Eq.</st> <st c="94081">63</st>
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94076">等式</st> <st c="94081">63</st>
- en: <st c="94083">We will also use the aforementioned rules to find</st> <st c="94134">the
    following:</st>
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94083">我们还将使用前面提到的规则来找出</st> <st c="94134">以下结果：</st>
- en: <st c="94148">Var</st><st c="94152">(</st><st c="94154">S</st><st c="94155">)</st>
    <st c="94156">=</st> <st c="94157">365</st> <st c="94160">×</st> <st c="94162">20</st>
    <st c="94164">×</st> <st c="94166">0.3</st> <st c="94169">×</st> <st c="94171">(</st><st
    c="94172">1</st> <st c="94173">−</st> <st c="94174">0.3</st><st c="94177">)</st>
    <st c="94179">=</st> <st c="94180">1533</st>
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94148">Var</st><st c="94152">(</st><st c="94154">S</st><st c="94155">)</st>
    <st c="94156">=</st> <st c="94157">365</st> <st c="94160">×</st> <st c="94162">20</st>
    <st c="94164">×</st> <st c="94166">0.3</st> <st c="94169">×</st> <st c="94171">(</st><st
    c="94172">1</st> <st c="94173">−</st> <st c="94174">0.3</st><st c="94177">)</st>
    <st c="94179">=</st> <st c="94180">1533</st>
- en: <st c="94184">Eq.</st> <st c="94189">64</st>
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94184">等式</st> <st c="94189">64</st>
- en: <st c="94191">We can</st> <st c="94199">see that we know the mean and variance
    of the yearly total sales</st> <st c="94264">S</st><st c="94265">, but what about
    the shape of the distribution of</st> <st c="94315">S</st><st c="94316">? There
    are many distributions of different shapes that could have a mean of 2190 and
    a variance</st> <st c="94413">of 1533.</st>
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94191">我们可以</st> <st c="94199">看到，我们知道年销售总额</st> <st c="94264">S</st><st
    c="94265">的均值和方差</st>，但</st> <st c="94315">S</st><st c="94316">的分布形态呢？有许多不同形态的分布，其均值为2190，方差为</st>
    <st c="94413">1533</st>。
- en: <st c="94421">This is where a very famous piece of math comes to our aid.</st>
    <st c="94482">The Central Limit Theorem (CLT) tells us that as we add more and
    more random variables together, their sum behaves more and more like a Gaussian
    random variable.</st> <st c="94644">Since we already know the mean and variance
    of the sum</st> <st c="94699">S</st><st c="94700">, we can write a mathematical
    statement of the CLT.</st> <st c="94752">Specifically, if we have</st> <st c="94777">n</st>
    <st c="94778">i.i.d.</st> <st c="94786">random variables</st> <st c="94803">X</st><st
    c="94804">i</st> <st c="94805">,</st> <st c="94806">i</st> <st c="94807">=</st>
    <st c="94808">1</st><st c="94809">,</st> <st c="94810">⋯</st> <st c="94811">,</st>
    <st c="94812">n</st><st c="94813">, each of which has mean</st> <st c="94838">μ</st>
    <st c="94839">and variance</st> <st c="94853">σ</st><st c="94854">2</st><st c="94855">,
    then if we define</st> <st c="94875">S</st> <st c="94876">=</st> <st c="94877">X</st><st
    c="94878">1</st> <st c="94879">+</st> <st c="94880">X</st><st c="94881">2</st><st
    c="94882">+</st> <st c="94883">⋯</st> <st c="94884">+</st> <st c="94885">X</st><st
    c="94886">n</st><st c="94887">, the distribution of</st> <st c="94909">S</st>
    <st c="94910">has the following</st> <st c="94929">limiting behavior:</st>
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94421">这时，一段非常著名的数学定理为我们提供了帮助。</st> <st c="94482">中心极限定理（CLT）告诉我们，当我们将越来越多的随机变量相加时，它们的和越来越像高斯随机变量。</st>
    <st c="94644">由于我们已经知道了总和</st> <st c="94699">S</st><st c="94700">的均值和方差</st>，<st
    c="94752">我们可以写出中心极限定理的数学表达式。</st> <st c="94752">具体来说，如果我们有</st> <st c="94777">n</st>
    <st c="94778">个独立同分布（i.i.d.）</st> <st c="94786">随机变量</st> <st c="94803">X</st><st
    c="94804">i</st> <st c="94805">，其中</st> <st c="94806">i</st> <st c="94807">=</st>
    <st c="94808">1</st><st c="94809">，</st> <st c="94810">⋯</st> <st c="94811">，</st>
    <st c="94812">n</st><st c="94813">，每个变量的均值为</st> <st c="94838">μ</st> <st c="94839">，方差为</st>
    <st c="94853">σ</st><st c="94854">²</st>，那么如果我们定义</st> <st c="94875">S</st> <st
    c="94876">=</st> <st c="94877">X</st><st c="94878">1</st> <st c="94879">+</st>
    <st c="94880">X</st><st c="94881">2</st> <st c="94882">+</st> <st c="94883">⋯</st>
    <st c="94884">+</st> <st c="94885">X</st><st c="94886">n</st><st c="94887">，则</st>
    <st c="94909">S</st> <st c="94910">的分布具有以下极限行为：</st>
- en: <st c="94947">S</st> <st c="94949">→</st> <st c="94950">Normal</st><st c="94956">(</st><st
    c="94958">nμ</st><st c="94960">,</st> <st c="94961">n</st> <st c="94962">σ</st><st
    c="94963">2</st><st c="94964">)</st> <st c="94965">as</st> <st c="94968">n</st>
    <st c="94969">→</st> <st c="94970">∞</st>
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94947">S</st> <st c="94949">→</st> <st c="94950">正态</st><st c="94956">(</st><st
    c="94958">nμ</st><st c="94960">,</st> <st c="94961">n</st> <st c="94962">σ</st><st
    c="94963">²</st> <st c="94964">)</st> <st c="94965">当</st> <st c="94968">n</st>
    <st c="94969">→</st> <st c="94970">∞</st>
- en: <st c="94971">Eq.</st> <st c="94975">65</st>
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94971">方程</st> <st c="94975">65</st>
- en: <st c="94977">As the mean</st> <st c="94990">nμ</st> <st c="94992">and variance</st>
    <st c="95006">n</st> <st c="95007">σ</st><st c="95008">2</st> <st c="95009">of
    the distribution on the right-hand side of</st> *<st c="95056">Eq.</st> <st c="95060">65</st>*
    <st c="95062">become infini</st><st c="95076">te as</st> <st c="95083">n</st>
    <st c="95084">→</st> <st c="95085">∞</st><st c="95086">, we need to write</st>
    *<st c="95105">Eq.</st> <st c="95109">65</st>* <st c="95111">in a slightly more
    rigorous way</st> <st c="95144">as follows:</st>
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="94977">由于</st> <st c="94990">nμ</st> <st c="94992">和</st> <st c="95006">n</st>
    <st c="95007">σ</st><st c="95008">²</st> <st c="95009">是右侧分布的均值和方差，</st> *<st
    c="95056">方程</st> <st c="95060">65</st>* <st c="95062">在</st> <st c="95076">n</st>
    <st c="95083">→</st> <st c="95085">∞</st> 时趋于无穷大，我们需要以稍微更严格的方式写出</st> *<st c="95105">方程</st>
    <st c="95109">65</st>* <st c="95111">，其形式如下：</st>
- en: <st c="95155">S</st> <st c="95157">−</st> <st c="95158">nμ</st><st c="95160">_</st><st
    c="95162">σ</st> <st c="95163">√</st><st c="95164">_</st><st c="95165">n</st>
    <st c="95166">→</st> <st c="95167">Normal</st><st c="95173">(</st><st c="95175">0,1</st><st
    c="95178">)</st> <st c="95180">as</st> <st c="95183">n</st> <st c="95184">→</st>
    <st c="95185">∞</st>
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="95155">S</st> <st c="95157">−</st> <st c="95158">nμ</st><st c="95160">_</st><st
    c="95162">σ</st> <st c="95163">√</st><st c="95164">_</st><st c="95165">n</st>
    <st c="95166">→</st> <st c="95167">正态</st><st c="95173">(</st><st c="95175">0,1</st><st
    c="95178">)</st> <st c="95180">当</st> <st c="95183">n</st> <st c="95184">→</st>
    <st c="95185">∞</st>
- en: <st c="95186">Eq.</st> <st c="95190">66</st>
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="95186">方程</st> <st c="95190">66</st>
- en: <st c="95192">We won’t go into the proof of the CLT as it involves some additional
    math techniques that we won’t</st> <st c="95292">be covering in this book.</st>
    <st c="95318">What is more important is that you are aware of the CLT, specifically
    that when we sum up lots of random variables, the distribution of that sum will
    be very well approximated by a Gaussian random variable.</st> <st c="95525">Let’s
    illustrate this with a</st> <st c="95554">code example.</st>
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="95192">我们不会详细讲解 CLT 的证明，因为它涉及一些额外的数学技巧，这些内容我们不会</st> <st c="95292">在本书中覆盖。</st>
    <st c="95318">更重要的是你要了解 CLT，特别是当我们将许多随机变量相加时，这些和的分布将非常接近一个高斯随机变量。</st> <st c="95525">接下来我们通过一个</st>
    <st c="95554">代码示例来说明。</st>
- en: <st c="95567">CLT code example</st>
  id: totrans-453
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="95567">CLT 代码示例</st>
- en: <st c="95584">For our first</st> <st c="95599">code example, we’ll start slightly
    simpler.</st> <st c="95643">We’ll add 20</st> <st c="95656">Uniform</st><st c="95663">(</st><st
    c="95665">0,1</st><st c="95668">)</st> <st c="95670">random variables together.</st>
    <st c="95698">We’ll do this lots of times and plot the resulting histogram of
    those totals to see if it looks anything like a normal distribution.</st> <st
    c="95831">The code is shown next and is also in the</st> `<st c="95873">Code_Examples_Chap2.ipynb</st>`
    <st c="95898">Jupyter notebook in the</st> <st c="95923">GitHub repository:</st>
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="95584">对于我们的第一个</st> <st c="95599">代码示例，我们将稍微简化一下。</st> <st c="95643">我们将相加
    20 个</st> <st c="95656">Uniform</st><st c="95663">(</st><st c="95665">0,1</st><st
    c="95668">)</st> <st c="95670">随机变量。</st> <st c="95698">我们会多次进行这个操作，并绘制这些总和的直方图，以查看它是否类似于正态分布。</st>
    <st c="95831">代码如下所示，也可以在</st> `<st c="95873">Code_Examples_Chap2.ipynb</st>`
    <st c="95898">Jupyter 笔记本中的</st> <st c="95923">GitHub 仓库中找到：</st>
- en: '[PRE4]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <st c="98741">An example</st> <st c="98753">output from the code is shown in</st>
    *<st c="98786">Figure 2</st>**<st c="98794">.16</st>*<st c="98797">:</st>
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="98741">一个示例</st> <st c="98753">代码输出如</st> *<st c="98786">图 2.16</st>**<st
    c="98794">.16</st>*<st c="98797">所示：</st>
- en: '![Figure 2.16: Example of the CLT when adding together the values of 20 Uniform(0,1)
    random variables](img/B19496_02_18.jpg)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.16：当将 20 个 Uniform(0,1) 随机变量相加时的 CLT 示例](img/B19496_02_18.jpg)'
- en: '<st c="98962">Figure 2.16: Example of the CLT when adding together the values
    of 20 Uniform(0,1) random variables</st>'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="98962">图 2.16：当将 20 个 Uniform(0,1) 随机变量相加时的 CLT 示例</st>
- en: <st c="99061">By comparing</st> <st c="99074">the red line of the CLT approximation
    to the histogram values, you can see how good the approximation of the CLT-based
    approximation is, even though we are only adding 20 random variables together
    in</st> <st c="99275">this example.</st>
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="99061">通过将</st> <st c="99074">CLT 近似的红线与直方图的值进行比较，你可以看到 CLT 基于近似的效果有多好，即使我们在</st>
    <st c="99275">这个例子中只相加了 20 个随机变量。</st>
- en: <st c="99288">We have said that the CLT gives us an approximation here because
    technically, the CLT is an asymptotic result.</st> *<st c="99400">Eq.</st> <st
    c="99404">66</st>* <st c="99406">tells us we only get a normal distribution when
    we add an infinite number of random variables together.</st> <st c="99511">What
    we have done is to take the CLT and say, well, when we add a finite number of
    random variables together, we will get something that is approximately normal.</st>
    <st c="99673">As you can see from this example, that approximation can be pretty
    good even when we are a long way from adding an infinite number of random values
    together.</st> <st c="99831">As you would expect, the more random variables we
    add together, the better the CLT approximation gets, and the approximation is
    better in the center of the distribution (around the mean) than in the tails (at
    the edges).</st> <st c="100052">How quickly the distribution of the sum of random
    values converges to a normal distribution as</st> <st c="100147">n</st> <st c="100148">increases
    depends not only on</st> <st c="100179">n</st> <st c="100180">(the number of random
    variables) but also on the details of the distribution of each random variable;
    for example, are they uniform random variables, binomial random variables, and</st>
    <st c="100362">so on.</st>
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="99288">我们已经说过，中心极限定理在这里给我们的是一个近似，因为严格来说，中心极限定理是一个渐近结果。</st> *<st c="99400">公式</st>
    <st c="99404">66</st>* <st c="99406">告诉我们，只有当我们将无限多个随机变量相加时，才会得到正态分布。</st> <st
    c="99511">我们所做的是应用中心极限定理，并指出，当我们将有限数量的随机变量相加时，得到的将是一个近似正态分布。</st> <st c="99673">从这个例子中可以看出，即使我们还远没有加到无限多个随机值，这个近似也可以相当准确。</st>
    <st c="99831">正如你所预期的那样，添加的随机变量越多，中心极限定理的近似效果就越好，而且在分布的中心（均值附近）的近似效果优于尾部（边缘部分）。</st>
    <st c="100052">随机值和的分布如何随着</st> <st c="100147">n</st> <st c="100148">的增加迅速收敛到正态分布，不仅取决于</st>
    <st c="100179">n</st> <st c="100180">(随机变量的数量)，还取决于每个随机变量的分布细节；例如，它们是均匀随机变量、二项式随机变量，还是</st>
    <st c="100362">等等。</st>
- en: <st c="100368">The reason we chose adding</st> <st c="100396">Uniform</st><st
    c="100403">(</st><st c="100405">0,1</st><st c="100408">)</st> <st c="100410">random
    variables to illustrate our first example of the CLT is partly because the shape
    of the density function of each of the random variables is flat, and so it is
    very different from the normal distribution that results from their sum.</st>
    <st c="100650">This emphasizes the fact that the resulting normal distribution
    shape is because we are adding lots of random variables together, not because
    of the properties or shape (within reason) of the individual random variables
    we are adding together.</st> <st c="100894">The</st> <st c="100897">normal distribution
    shape that results from adding lots of random variables together is a</st> <st
    c="100988">universal outcome.</st>
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="100368">我们选择添加</st> <st c="100396">均匀</st><st c="100403">(</st><st c="100405">0,1</st><st
    c="100408">)</st> <st c="100410">随机变量来说明中心极限定理（CLT）的第一个例子，部分原因是每个随机变量的密度函数形状是平坦的，因此它与由它们的和产生的正态分布有很大的不同。</st>
    <st c="100650">这强调了一个事实，即结果的正态分布形状是因为我们将大量随机变量相加，而不是因为我们相加的每个随机变量的性质或形状（在合理范围内）。</st>
    <st c="100894">由将大量随机变量相加得到的</st> <st c="100897">正态分布形状是一个</st> <st c="100988">普遍结果。</st>
- en: <st c="101006">We also chose to add</st> <st c="101028">Uniform</st><st c="101035">(</st><st
    c="101037">0,1</st><st c="101040">)</st> <st c="101042">random variables to illustrate
    the CLT because</st> <st c="101090">Uniform</st><st c="101097">(</st><st c="101099">0,1</st><st
    c="101102">)</st> <st c="101104">is a continuous distribution.</st> <st c="101135">Consequently,
    the sum of many</st> <st c="101165">Uniform</st><st c="101172">(</st><st c="101174">0,1</st><st
    c="101177">)</st> <st c="101179">random variables will also be continuous, and
    when we compare the normal distribution of the CLT approximation, which is also
    continuous, it is possible to see a very good agreement between the histogram
    of the experimental sums and the CLT approximation, even when we are adding only
    a finite number of random</st> <st c="101491">values together.</st>
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="101006">我们还选择了添加</st> <st c="101028">均匀分布</st><st c="101035">(</st><st
    c="101037">0,1</st><st c="101040">)</st> <st c="101042">随机变量，以说明中心极限定理，因为</st>
    <st c="101090">均匀分布</st><st c="101097">(</st><st c="101099">0,1</st><st c="101102">)</st>
    <st c="101104">是一种连续分布。</st> <st c="101135">因此，许多</st> <st c="101165">均匀分布</st><st
    c="101172">(</st><st c="101174">0,1</st><st c="101177">)</st> <st c="101179">随机变量的和也将是连续的，当我们比较中心极限定理近似的正态分布时（它也是连续的），就可以看到实验和的直方图与中心极限定理近似之间有非常好的吻合，即使我们仅仅加和了有限数量的随机</st>
    <st c="101491">值。</st>
- en: <st c="101507">CLT example with discrete variables</st>
  id: totrans-463
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="101507">使用离散变量的中心极限定理示例</st>
- en: <st c="101543">When</st> <st c="101548">our starting random variables are discrete,
    then so is their sum.</st> <st c="101615">Let’s simulate our “items sold in a
    year” example, where we add together 365</st> <st c="101692">Binomial</st><st
    c="101700">(</st><st c="101702">20</st><st c="101704">,</st> <st c="101705">0.3</st><st
    c="101708">)</st> <st c="101710">random variables.</st> <st c="101729">We can
    do this using very similar code to that shown previously by simply replacing</st>
    <st c="101813">Uniform</st><st c="101820">(</st><st c="101822">0,1</st><st c="101825">)</st>
    <st c="101827">with</st> <st c="101833">Binomial</st><st c="101841">(</st><st
    c="101843">20</st><st c="101845">,</st> <st c="101846">0.3</st><st c="101849">)</st>
    <st c="101851">and updating the mean and variance calculations of the CLT approximation.</st>
    <st c="101926">Example code to do this simulation is given in the</st> `<st c="101977">Code_Examples_Chap2.ipynb</st>`
    <st c="102002">Jupyter notebook in the GitHub repository, but we only show example
    output from that code in</st> *<st c="102096">Figure 2</st>**<st c="102104">.17</st>*<st
    c="102107">. The granular or discrete na</st><st c="102136">ture of the sum of
    the 365 discrete values is clear, but the CLT still provides us with a</st> <st
    c="102227">good approximation:</st>
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="101543">当</st> <st c="101548">我们的初始随机变量是离散的时，它们的和也将是离散的。</st> <st c="101615">让我们模拟一下“每年售出的商品数量”这个例子，在这个例子中，我们将365个</st>
    <st c="101692">二项分布</st><st c="101700">(</st><st c="101702">20</st><st c="101704">,</st>
    <st c="101705">0.3</st><st c="101708">)</st> <st c="101710">随机变量相加。</st> <st c="101729">我们可以通过使用与之前类似的代码来完成这项任务，方法是简单地将</st>
    <st c="101813">均匀分布</st><st c="101820">(</st><st c="101822">0,1</st><st c="101825">)</st>
    <st c="101827">替换为</st> <st c="101833">二项分布</st><st c="101841">(</st><st c="101843">20</st><st
    c="101845">,</st> <st c="101846">0.3</st><st c="101849">)</st> <st c="101851">并更新CLT近似的均值和方差计算。</st>
    <st c="101926">进行该模拟的示例代码可以在</st> `<st c="101977">Code_Examples_Chap2.ipynb</st>`
    <st c="102002">GitHub仓库中的Jupyter笔记本中找到，但我们只展示了该代码的示例输出</st> *<st c="102096">图2.17</st>**<st
    c="102104">.</st>*<st c="102107">365个离散值的和的粒度或离散性质是显而易见的，但中心极限定理仍然为我们提供了一个</st>
    <st c="102227">很好的近似：</st>
- en: '![Figure 2.17: Example of the CLT when adding together the values of 365 Binomial(20,
    0.3) random variables](img/B19496_02_19.jpg)'
  id: totrans-465
  prefs: []
  type: TYPE_IMG
  zh: '![图2.17：当将365个二项分布(20, 0.3)随机变量的值相加时，中心极限定理的示例](img/B19496_02_19.jpg)'
- en: '<st c="102436">Figure 2.17: Example of the CLT when adding together the values
    of 365 Binomial(20, 0.3) random variables</st>'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="102436">图2.17：当将365个二项分布(20, 0.3)随机变量的值相加时，中心极限定理的示例</st>
- en: <st c="102541">The CLT is incredibly</st> <st c="102564">important when we analyze
    a dataset because it tells us what probability density shape we should expect
    for a quantity that is a sum of many other things.</st> <st c="102719">But what
    if we are analyzing a quantity in a dataset that isn’t an aggregation and we want
    to know its density shape?</st> <st c="102837">We will now show how to do this
    computationally, with some</st> <st c="102896">code examples.</st>
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="102541">中心极限定理（CLT）在我们分析数据集时极其重要，因为它告诉我们，对于一个由多个其他元素之和组成的量，我们应该预期它的概率密度分布形状。</st>
    <st c="102564">但是，如果我们分析的数据集中有一个量不是聚合的，并且我们想知道它的密度分布形状，该怎么办呢？</st> <st c="102719">接下来，我们将展示如何通过计算方式实现这一点，并提供一些</st>
    <st c="102896">代码示例。</st>
- en: <st c="102910">Computational estimation of a PDF from data</st>
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="102910">从数据中计算PDF的估计值</st>
- en: <st c="102954">Here, we</st> <st c="102963">will show you how to use functions
    from the</st> `<st c="103008">scikit-learn</st>` <st c="103020">package to calculate
    a computational estimate of a PDF.</st> <st c="103077">To do this, we use something
    called</st> **<st c="103113">kernel density estimation</st>** <st c="103138">(</st>**<st
    c="103140">KDE</st>**<st c="103143">).</st> <st c="103147">KDE</st> <st c="103151">works
    by approximating the PDF that underlies the data by a series of fixed-shape distributions,
    one placed at each data point.</st> <st c="103279">If</st> <st c="103282">x</st><st
    c="103283">1</st><st c="103284">,</st> <st c="103285">x</st><st c="103286">2</st><st
    c="103287">,</st> <st c="103288">⋯</st> <st c="103289">,</st> <st c="103290">x</st><st
    c="103291">n</st> <st c="103292">are the data values in our sample, the KDE</st>
    <st c="103336">estimates the PDF as</st> <st c="103357">ˆ</st><st c="103358">f</st><st
    c="103359">(</st><st c="103360">x</st><st c="103361">)</st><st c="103362">, with</st>
    <st c="103369">ˆ</st><st c="103370">f</st><st c="103371">(</st><st c="103372">x</st><st
    c="103373">)</st> <st c="103374">calculated from the</st> <st c="103395">following
    formula:</st>
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="102954">在这里，</st> <st c="102963">我们将向你展示如何使用</st> `<st c="103008">scikit-learn</st>`
    <st c="103020">包中的函数来计算PDF的计算估计值。</st> <st c="103077">为此，我们使用了一种叫做</st> **<st
    c="103113">核密度估计</st>** <st c="103138">(</st>**<st c="103140">KDE</st>**<st c="103143">)。</st>
    <st c="103147">KDE</st> <st c="103151">通过将数据背后的PDF用一系列固定形状的分布进行逼近，每个分布放置在一个数据点上，来工作。</st>
    <st c="103279">如果</st> <st c="103282">x</st><st c="103283">1</st><st c="103284">,</st>
    <st c="103285">x</st><st c="103286">2</st><st c="103287">,</st> <st c="103288">⋯</st>
    <st c="103289">,</st> <st c="103290">x</st><st c="103291">n</st> <st c="103292">是我们样本中的数据值，则KDE</st>
    <st c="103336">估计的PDF为</st> <st c="103357">ˆ</st><st c="103358">f</st><st c="103359">(</st><st
    c="103360">x</st><st c="103361">)</st><st c="103362">，其</st> <st c="103369">ˆ</st><st
    c="103370">f</st><st c="103371">(</st><st c="103372">x</st><st c="103373">)</st>
    <st c="103374">根据以下公式计算：</st>
- en: <st c="103413">ˆ</st><st c="103415">f</st><st c="103416">(</st><st c="103417">x</st><st
    c="103418">)</st> <st c="103419">=</st> <st c="103420">1</st><st c="103421">_</st><st
    c="103422">nh</st> <st c="103424">∑</st><st c="103426">i</st><st c="103427">=</st><st
    c="103428">1</st><st c="103429">n</st><st c="103430">K</st><st c="103431">(</st><st
    c="103432">x</st><st c="103433">−</st> <st c="103434">x</st><st c="103435">i</st><st
    c="103436">_</st><st c="103437">h</st><st c="103438">)</st>
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="103413">ˆ</st><st c="103415">f</st><st c="103416">(</st><st c="103417">x</st><st
    c="103418">)</st> <st c="103419">=</st> <st c="103420">1</st><st c="103421">_</st><st
    c="103422">nh</st> <st c="103424">∑</st><st c="103426">i</st><st c="103427">=</st><st
    c="103428">1</st><st c="103429">n</st><st c="103430">K</st><st c="103431">(</st><st
    c="103432">x</st><st c="103433">−</st> <st c="103434">x</st><st c="103435">i</st><st
    c="103436">_</st><st c="103437">h</st><st c="103438">)</st>
- en: <st c="103439">Eq.</st> <st c="103443">67</st>
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="103439">方程式</st> <st c="103443">67</st>
- en: <st c="103445">The hat symbol on</st> <st c="103464">ˆ</st><st c="103465">f</st><st
    c="103466">(</st><st c="103467">x</st><st c="103468">)</st> <st c="103469">is
    used to denote the fact that</st> <st c="103502">ˆ</st><st c="103503">f</st><st
    c="103504">(</st><st c="103505">x</st><st c="103506">)</st> <st c="103507">is
    an</st> **<st c="103514">estimate</st>** <st c="103522">of the true PDF,</st>
    <st c="103540">f</st><st c="103541">(</st><st c="103542">x</st><st c="103543">)</st><st
    c="103544">. In</st> *<st c="103549">Eq.</st> <st c="103553">67</st>*<st c="103555">,
    the function</st> <st c="103570">K</st><st c="103571">(</st><st c="103572">x</st><st
    c="103573">)</st> <st c="103574">is called</st> <st c="103584">the</st> **<st
    c="103589">kernel</st>** <st c="103595">function.</st> <st c="103606">It is also</st>
    <st c="103617">called a</st> **<st c="103626">window</st>** <st c="103632">function
    because, as we will see, it specifies the window or range over which data is smoothed.</st>
    <st c="103729">It is typically a function that is highest at</st> <st c="103775">x</st>
    <st c="103776">=</st> <st c="103777">0</st> <st c="103778">and falls away symmetrically
    to zero on either side, possibly within a finite distance from</st> <st c="103871">x</st>
    <st c="103872">=</st> <st c="103873">0</st><st c="103874">.</st> *<st c="103876">Figure
    2</st>**<st c="103884">.18</st>* <st c="103887">shows two</st> <st c="103897">example
    kernel functions; on the left is the Parzen window, which is a Gaussian, a</st><st
    c="103980">nd on the right is the Tricube kernel function, which has finite support
    (it is zero outside of</st> <st c="104077">|</st><st c="104078">x</st><st c="104079">|</st>
    <st c="104080">=</st> <st c="104081">1</st><st c="104082">):</st>
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="103445">帽子符号</st> <st c="103464">ˆ</st><st c="103465">f</st><st c="103466">(</st><st
    c="103467">x</st><st c="103468">)</st> <st c="103469">用于表示</st> <st c="103502">ˆ</st><st
    c="103503">f</st><st c="103504">(</st><st c="103505">x</st><st c="103506">)</st>
    <st c="103507">是</st> **<st c="103514">真实概率密度函数</st>** <st c="103522">f</st><st
    c="103541">(</st><st c="103542">x</st><st c="103543">)</st><st c="103544">的估计值。</st>
    在 *<st c="103549">公式</st> <st c="103553">67</st>*<st c="103555">中，函数</st> <st
    c="103570">K</st><st c="103571">(</st><st c="103572">x</st><st c="103573">)</st>
    <st c="103574">被称为</st> <st c="103584">**核函数**</st> <st c="103595">。</st> <st
    c="103606">它也被称为</st> <st c="103617">**窗口函数**</st> <st c="103632">，因为正如我们将看到的，它指定了数据平滑的窗口或范围。</st>
    <st c="103729">它通常是一个在</st> <st c="103775">x</st> <st c="103776">=</st> <st c="103777">0</st>
    <st c="103778">处最大，并在两侧对称地下降至零的函数，可能在</st> <st c="103871">x</st> <st c="103872">=</st>
    <st c="103873">0</st><st c="103874">附近的有限距离内。</st> *<st c="103876">图 2</st>**<st
    c="103884">.18</st>* <st c="103887">展示了两个示例核函数；左侧是Parzen窗口，它是一个高斯函数，右侧是Tricube核函数，它具有有限支撑（在</st>
    <st c="104077">|</st><st c="104078">x</st><st c="104079">|</st> <st c="104080">=</st>
    <st c="104081">1</st><st c="104082">外为零）：</st>
- en: '![Figure 2.18: Two examples of commonly used kernel functions](img/B19496_02_20.jpg)'
  id: totrans-473
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.18：常用核函数的两个示例](img/B19496_02_20.jpg)'
- en: '<st c="104233">Figure 2.18: Two examples of commonly used kernel functions</st>'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="104233">图 2.18：常用核函数的两个示例</st>
- en: <st c="104292">Given each datapoint has a total weight</st> <st c="104333">1</st>
    <st c="104334">/</st> <st c="104335">n</st> <st c="104336">when we calculate a
    sample average, we can see that the function</st> <st c="104402">K</st> <st c="104403">smooths
    out the impact of having a datapoint at</st> <st c="104452">x</st><st c="104453">i</st><st
    c="104454">. How much it smooths out that impact is determined by, obviously,
    the shape of the function</st> <st c="104547">K</st><st c="104548">, but also
    the parameter</st> <st c="104573">h</st><st c="104574">, which modifies the width
    of the impact of the kernel smoothing.</st> <st c="104640">The parameter</st>
    <st c="104654">h</st> <st c="104655">is called</st> <st c="104665">the</st> **<st
    c="104670">kernel width</st>**<st c="104682">, or sometimes</st> <st c="104696">the</st>
    **<st c="104701">bandwidth</st>**<st c="104710">. A large value of</st> <st c="104729">h</st>
    <st c="104730">will mean each datapoint is smoothed out considerably, with the
    impact of each datapoint overlapping and the resulting approximation</st> <st
    c="104864">ˆ</st><st c="104865">f</st><st c="104866">(</st><st c="104867">x</st><st
    c="104868">)</st> <st c="104869">looking almost like a uniform distribution.</st>
    <st c="104914">A small value of</st> <st c="104931">h</st> <st c="104932">means
    each datapoint is smoothed out only a little and essentially is still a spike.</st>
    <st c="105018">With a small value of</st> <st c="105040">h</st><st c="105041">,
    the resulting approximation</st> <st c="105071">ˆ</st><st c="105072">f</st><st
    c="105073">(</st><st c="105074">x</st><st c="105075">)</st> <st c="105076">doesn’t
    look that much different from the EDF of the</st> <st c="105130">sample data.</st>
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="104292">考虑到每个数据点在计算样本平均值时有一个总权重</st> <st c="104333">1</st> <st c="104334">/</st>
    <st c="104335">n</st> <st c="104336">，我们可以看到，函数</st> <st c="104402">K</st> <st
    c="104403">平滑了数据点</st> <st c="104452">x</st><st c="104453">i</st><st c="104454">的影响。它平滑的程度显然取决于函数</st>
    <st c="104547">K</st><st c="104548">的形状，但也与参数</st> <st c="104573">h</st><st c="104574">有关，后者修改了核平滑的影响范围。</st>
    <st c="104640">这个参数</st> <st c="104654">h</st> <st c="104655">被称为</st> **<st c="104670">核宽度</st>**<st
    c="104682">，有时也叫做</st> **<st c="104701">带宽</st>**<st c="104710">。较大的</st> <st
    c="104729">h</st> <st c="104730">值意味着每个数据点的平滑效果会显著，导致每个数据点的影响重叠，最终得到的近似值</st>
    <st c="104864">ˆ</st><st c="104865">f</st><st c="104866">(</st><st c="104867">x</st><st
    c="104868">)</st> <st c="104869">看起来几乎像一个均匀分布。</st> <st c="104914">较小的</st> <st
    c="104931">h</st> <st c="104932">值意味着每个数据点的平滑效果很小，基本上仍然是一个尖峰。</st> <st c="105018">当</st>
    <st c="105040">h</st><st c="105041">值较小的时候，得到的近似值</st> <st c="105071">ˆ</st><st
    c="105072">f</st><st c="105073">(</st><st c="105074">x</st><st c="105075">)</st>
    <st c="105076">看起来与样本数据的经验分布函数（EDF）相差无几。</st>
- en: <st c="105142">So, how do we choose a value for</st> <st c="105176">h</st><st
    c="105177">, or indeed a kernel function</st> <st c="105207">K</st><st c="105208">(</st><st
    c="105209">x</st><st c="105210">)</st><st c="105211">? We won’t go into that here.</st>
    <st c="105241">There is a whole field of statistics devoted to how to automatically
    determine from the data a suitable value for</st> <st c="105355">h</st><st c="105356">,
    and we will make use of one of them (Silverman’s rule of thumb) now in a</st>
    <st c="105431">code example.</st>
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="105142">那么，我们如何选择一个合适的</st> <st c="105176">h</st><st c="105177">值，或者说选择一个合适的核函数</st>
    <st c="105207">K</st><st c="105208">(</st><st c="105209">x</st><st c="105210">)</st><st
    c="105211">呢？我们在这里不深入讨论这个问题。</st> <st c="105241">有一个专门的统计学领域致力于如何从数据中自动确定一个合适的</st>
    <st c="105355">h</st><st c="105356">值，我们将在这里使用其中的一种方法（Silverman的经验法则），并在</st>
    <st c="105431">代码示例中演示。</st>
- en: <st c="105444">KDE code example</st>
  id: totrans-477
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="105444">KDE代码示例</st>
- en: <st c="105461">The following</st> <st c="105475">code constructs kernel</st>
    <st c="105499">density estimates from 30 values drawn from a gamma distribution.</st>
    <st c="105565">We do this for two different kernel functions – a Parzen kernel
    and an exponential kernel.</st> <st c="105656">This code example can be found
    in the</st> `<st c="105694">Code_Examples_Chap2.ipynb</st>` <st c="105719">Jupyter
    notebook in the</st> <st c="105744">GitHub repository:</st>
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="105461">以下</st> <st c="105475">代码从一个伽马分布中抽取30个值，构造了核密度估计。</st> <st c="105565">我们为两种不同的核函数进行此操作——一个是Parzen核，一个是指数核。</st>
    <st c="105656">该代码示例可以在</st> `<st c="105694">Code_Examples_Chap2.ipynb</st>` <st
    c="105719">Jupyter笔记本中找到，位于</st> <st c="105744">GitHub仓库中：</st>
- en: '[PRE5]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: <st c="107580">The output</st> <st c="107591">from the code is shown in</st>
    *<st c="107618">Figure 2</st>**<st c="107626">.19</st>*<st c="107629">:</st>
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="107580">代码的输出结果如</st> *<st c="107618">图 2</st>**<st c="107626">.19</st>*<st
    c="107629">所示：</st>
- en: '![Figure 2.19: Example of KDE using different kernel functions](img/B19496_02_21.jpg)'
  id: totrans-481
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.19：使用不同核函数的KDE示例](img/B19496_02_21.jpg)'
- en: '<st c="107789">Figure 2.19: Example of KDE using different kernel functions</st>'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="107789">图 2.19：使用不同核函数的KDE示例</st>
- en: '*<st c="107849">Figure 2</st>**<st c="107858">.19</st>* <st c="107861">also</st>
    <st c="107867">shows the true PDF of the gamma</st> <st c="107898">distribution,
    and we can see that, even though we have only 30 datapoints in our sample, the
    kernel density estimates are close to the</st> <st c="108034">true density.</st>'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '*<st c="107849">图 2</st>**<st c="107858">.19</st>* <st c="107861">也</st> <st
    c="107867">展示了伽马分布的真实PDF，我们可以看到，尽管我们的样本中只有30个数据点，但核密度估计接近</st> <st c="108034">真实密度。</st>'
- en: <st c="108047">That practical example of how to estimate probability densities
    from data brings us neatly to the end of this section, so let’s recap what we
    learned about KDE, and then wrap up by summarizing the chapter as</st> <st c="108256">a
    whole.</st>
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="108047">通过这个实际的例子，展示了如何从数据中估计概率密度，这也恰到好处地引出了本节的结尾，所以让我们回顾一下我们对KDE的理解，然后通过总结本章的内容来结束。</st>
    <st c="108256">整体内容。</st>
- en: <st c="108264">What we learned</st>
  id: totrans-485
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="108264">我们学到的内容</st>
- en: <st c="108280">In this section, we have learned</st> <st c="108314">the following:</st>
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="108280">在这一节中，我们学到了</st> <st c="108314">以下内容：</st>
- en: <st c="108328">How adding together lots of i.i.d.</st> <st c="108364">random
    variables produces a random variable whose distribution is</st> <st c="108430">approximately
    normal.</st>
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="108328">将大量独立同分布（i.i.d.）的随机变量相加，能够产生一个其分布大致为</st> <st c="108364">正态分布的随机变量。</st>
    <st c="108430">正态。</st>
- en: <st c="108451">How many datasets we analyze will naturally contain variables
    that are themselves aggregations of many random values; for example, yearly total
    sales as the aggregation of 365 daily</st> <st c="108634">sales values.</st>
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="108451">我们分析的许多数据集自然会包含变量，而这些变量本身就是许多随机值的聚合；例如，年度总销售额是365天的</st> <st
    c="108634">销售值的总和。</st>
- en: <st c="108647">How the approximation by a normal distribution improves the more
    random values we are adding together.</st> <st c="108751">This is</st> <st c="108759">the
    CLT.</st>
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="108647">如何通过正态分布的近似来改进，我们加入的随机值越多，近似效果越好。</st> <st c="108751">这就是</st>
    <st c="108759">中心极限定理（CLT）。</st>
- en: <st c="108767">How to use KDE to construct an estimate of a probability density
    from data even when we can’t or don’t want to make use of</st> <st c="108891">the
    CLT.</st>
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="108767">如何使用KDE从数据中构建概率密度的估计，即使我们不能或不想利用</st> <st c="108891">中心极限定理（CLT）</st>。
- en: <st c="108899">Summary</st>
  id: totrans-491
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="108899">总结</st>
- en: <st c="108907">This chapter has been a long one.</st> <st c="108942">The effort
    will be worthwhile.</st> <st c="108973">Random variation is a component of any
    dataset, so knowing how to characterize and describe that random variation when
    analyzing data is a key skill for any data scientist.</st> <st c="109146">In this
    chapter, we have learned</st> <st c="109179">the following:</st>
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="108907">这一章内容较长。</st> <st c="108942">但这努力是值得的。</st> <st c="108973">随机变化是任何数据集的一个组成部分，因此，了解如何在分析数据时描述和表征这些随机变化是每位数据科学家的关键技能。</st>
    <st c="109146">在这一章中，我们学到了</st> <st c="109179">以下内容：</st>
- en: <st c="109193">How and why randomness arises</st> <st c="109224">in data</st>
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="109193">随机性如何以及为何会出现在数据中</st> <st c="109224">中</st>
- en: <st c="109231">How random variables are a natural concept to describe randomness</st>
    <st c="109298">in data</st>
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="109231">随机变量是描述数据中随机性的一种自然概念</st> <st c="109298">。</st>
- en: <st c="109305">Key aspects of random variables, such as their probability distributions,
    and how to use key metrics such as the mean and variance of a distribution to
    characterize</st> <st c="109471">a distribution</st>
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="109305">随机变量的关键特征，比如它们的概率分布，以及如何使用均值和方差等关键指标来描述</st> <st c="109471">一个分布</st>
- en: <st c="109485">How we can think of datasets as being samples drawn from an underlying
    distribution, and it is the underlying distribution we are really interested</st>
    <st c="109634">in understanding</st>
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="109485">我们可以将数据集视为从一个潜在的分布中抽取的样本，而我们真正感兴趣的是理解</st> <st c="109634">这个潜在的分布</st>
- en: <st c="109650">How to summarize a sample using the sample mean and</st> <st
    c="109703">sample variance</st>
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="109650">如何使用样本均值和</st> <st c="109703">样本方差来总结一个样本</st>
- en: <st c="109718">How sample characteristics, such as the sample mean and sample
    variance, can be related back to the corresponding quantities of the underlying
    population distribution that we are</st> <st c="109898">interested in</st>
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="109718">如何将样本特征，如样本均值和样本方差，关联到我们感兴趣的基础总体分布的相应量。</st>
- en: <st c="109911">How the normal or Gaussian distribution is a commonly occurring
    distribution because it arises from the CLT, which tells us what happens when
    we add lots of data values together – a common task in</st> <st c="110109">data
    science</st>
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="109911">正态分布或高斯分布为何是常见的分布，因为它是由中央极限定理（CLT）引起的，这告诉我们当我们将大量数据值相加时会发生什么——这是数据科学中的常见任务。</st>
- en: <st c="110121">Randomness in data also flows through into any downstream calculation
    involving a dataset.</st> <st c="110213">Consequently, when constructing various
    data science algorithms, we need to take into account randomness within the data
    that those algorithms process.</st> <st c="110365">Unsurprisingly, many data science
    algorithms, such as</st> **<st c="110419">maximum likelihood estimation</st>**
    <st c="110448">(</st>**<st c="110450">MLE</st>**<st c="110453">) of model parameters
    and Bayesian probabilistic modeling, start by building from first principles upon
    the random nature of data.</st> <st c="110585">We will cover these concepts in</st>
    [*<st c="110617">Chapter 5</st>*](B19496_05.xhtml#_idTextAnchor261)<st c="110626">.
    We can do so only because we have laid the solid foundations in</st> <st c="110692">this
    chapter.</st>
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="110121">数据中的随机性也会影响到涉及数据集的任何下游计算。</st> <st c="110213">因此，在构建各种数据科学算法时，我们需要考虑到算法处理的数据中的随机性。</st>
    <st c="110365">不出所料，许多数据科学算法，如</st> **<st c="110419">最大似然估计</st>** <st c="110448">(</st>**<st
    c="110450">MLE</st>**<st c="110453">) 进行模型参数估计和贝叶斯概率建模，都是从数据的随机特性出发，依据基本原理进行构建的。</st>
    <st c="110585">我们将在</st> [*<st c="110617">第5章</st>*](B19496_05.xhtml#_idTextAnchor261)
    <st c="110626">中讲解这些概念。我们之所以能这么做，是因为我们在</st> <st c="110692">本章中奠定了坚实的基础。</st>
- en: <st c="110705">Exercises</st>
  id: totrans-501
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="110705">练习</st>
- en: <st c="110715">Next is a series of short exercises.</st> <st c="110753">They
    start easy and increase in difficulty.</st> <st c="110797">Answers to all the
    exercises are given in the</st> `<st c="110843">Answers_to_Exercises_Chap2.ipynb</st>`
    <st c="110875">Jupyter notebook in the GitHub repository.</st> <st c="110919">The
    exercises are a mix of code exercises and mathematical derivation exercises –
    this is designed to get you to start flexing your mathematical muscles.</st> <st
    c="111073">Give them a go and</st> <st c="111092">have fun:</st>
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="110715">接下来是一系列简短的练习。</st> <st c="110753">它们从简单开始，逐渐增加难度。</st> <st c="110797">所有练习的答案都给出了在</st>
    `<st c="110843">Answers_to_Exercises_Chap2.ipynb</st>` <st c="110875">GitHub 仓库中的
    Jupyter notebook 文件里。</st> <st c="110919">这些练习是代码练习和数学推导练习的结合——旨在让你开始锻炼你的数学能力。</st>
    <st c="111073">试试看并</st> <st c="111092">玩得开心：</st>
- en: <st c="111101">Use the</st> `<st c="111110">numpy</st>` <st c="111115">package
    to sample 1,000 random values from a Beta distribution with</st> <st c="111184">α</st>
    <st c="111185">=</st> <st c="111186">2</st><st c="111187">,</st> <st c="111188">β</st>
    <st c="111189">=</st> <st c="111190">5</st><st c="111191">, and plot a histogram
    of the resulting</st> <st c="111231">1,000 values.</st>
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="111101">使用</st> `<st c="111110">numpy</st>` <st c="111115">包从 Beta 分布中抽取
    1,000 个随机值，其中</st> <st c="111184">α</st> <st c="111185">=</st> <st c="111186">2</st><st
    c="111187">,</st> <st c="111188">β</st> <st c="111189">=</st> <st c="111190">5</st><st
    c="111191">，并绘制得到的</st> <st c="111231">1,000 个值的直方图。</st>
- en: <st c="111244">A mixture distribution is a distribution where the random variable
    has a certain specified probability of coming from one distribution, a certain
    specified probability of coming from a second distribution, a certain specified
    probability of coming from a third distribution, and so on.</st> <st c="111531">The
    number of different distributions is called the number of components in the mixture.</st>
    <st c="111620">We have a two-component mixture distribution, which we can write</st>
    <st c="111685">as follows:</st>
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="111244">混合分布是指随机变量具有一定的指定概率来自一个分布，具有一定的指定概率来自第二个分布，具有一定的指定概率来自第三个分布，以此类推。</st>
    <st c="111531">不同分布的数量称为混合成分的数量。</st> <st c="111620">我们有一个两成分的混合分布，可以写作：</st>
- en: <st c="111696">A</st> <st c="111698">~</st> <st c="111699">Bernoulli</st><st
    c="111708">(</st><st c="111710">0.4</st><st c="111713">)</st>
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="111696">一个</st> <st c="111698">~</st> <st c="111699">伯努利</st><st c="111708">(</st><st
    c="111710">0.4</st><st c="111713">)</st>
- en: <st c="111715">z</st><st c="111716">1</st> <st c="111717">~</st> <st c="111718">Normal</st><st
    c="111724">(</st><st c="111726">μ</st> <st c="111727">=</st> <st c="111728">1</st><st
    c="111729">,</st> <st c="111730">σ</st><st c="111731">2</st> <st c="111732">=</st>
    <st c="111733">3.5</st><st c="111736">)</st> <st c="111738">z</st><st c="111739">2</st>
    <st c="111740">~</st> <st c="111741">Laplace</st><st c="111748">(</st><st c="111750">μ</st>
    <st c="111751">=</st> <st c="111752">10</st><st c="111754">,</st> <st c="111755">λ</st>
    <st c="111756">=</st> <st c="111757">1.5</st><st c="111760">)</st>
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="111715">z</st><st c="111716">1</st> <st c="111717">~</st> <st c="111718">正态分布</st><st
    c="111724">(</st><st c="111726">μ</st> <st c="111727">=</st> <st c="111728">1</st><st
    c="111729">,</st> <st c="111730">σ</st><st c="111731">2</st> <st c="111732">=</st>
    <st c="111733">3.5</st><st c="111736">)</st> <st c="111738">z</st><st c="111739">2</st>
    <st c="111740">~</st> <st c="111741">拉普拉斯分布</st><st c="111748">(</st><st c="111750">μ</st>
    <st c="111751">=</st> <st c="111752">10</st><st c="111754">,</st> <st c="111755">λ</st>
    <st c="111756">=</st> <st c="111757">1.5</st><st c="111760">)</st>
- en: <st c="111762">X</st> <st c="111763">=</st> <st c="111764">A</st> <st c="111765">×</st>
    <st c="111766">z</st><st c="111767">1</st> <st c="111768">+</st> <st c="111769">(</st><st
    c="111770">1</st> <st c="111771">−</st> <st c="111772">A</st><st c="111773">)</st>
    <st c="111774">×</st> <st c="111775">z</st><st c="111776">2</st>
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="111762">X</st> <st c="111763">=</st> <st c="111764">A</st> <st c="111765">×</st>
    <st c="111766">z</st><st c="111767">1</st> <st c="111768">+</st> <st c="111769">(</st><st
    c="111770">1</st> <st c="111771">−</st> <st c="111772">A</st><st c="111773">)</st>
    <st c="111774">×</st> <st c="111775">z</st><st c="111776">2</st>
- en: <st c="111777">Eq.</st> <st c="111781">68</st>
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="111777">公式</st> <st c="111781">68</st>
- en: <st c="111783">This means that with 40% probability</st> <st c="111821">X</st>
    <st c="111822">is drawn from a normal distribution with mean=1 and variance=3.5,
    and with 60% probability it is drawn from a Laplace distribution with mean=10</st>
    <st c="111967">and scale=1.5.</st>
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="111783">这意味着，具有 40% 的概率，</st> <st c="111821">X</st> <st c="111822">来自均值=1、方差=3.5
    的正态分布，且具有 60% 的概率，</st> 它来自均值=10、尺度=1.5 的拉普拉斯分布。
- en: <st c="111981">Using</st> `<st c="111988">numpy.random.randn</st>` <st c="112006">and</st>
    `<st c="112011">numpy.random.laplace</st>` <st c="112031">functions, draw 3,000
    values from this mixture distribution and plot a histogram of the</st> <st c="112120">resulting
    values.</st>
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="111981">使用</st> `<st c="111988">numpy.random.randn</st>` <st c="112006">和</st>
    `<st c="112011">numpy.random.laplace</st>` <st c="112031">函数，从该混合分布中抽取 3,000 个值，并绘制结果值的直方图。</st>
- en: <st c="112137">In</st> *<st c="112141">Eq.</st> <st c="112145">14</st>*<st c="112147">,
    we have given a definition of the variance of a random variable</st> <st c="112213">X</st>
    <st c="112214">as follows:</st>
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="112137">在</st> *<st c="112141">公式</st> <st c="112145">14</st>*<st c="112147">中，我们已给出随机变量</st>
    <st c="112213">X</st> <st c="112214">的方差定义如下：</st>
- en: <st c="112225">Variance =</st> <st c="112237">𝔼</st><st c="112239">(</st><st
    c="112241">(</st><st c="112242">X</st><st c="112243">−</st> <st c="112244">𝔼</st><st
    c="112246">(</st><st c="112248">X</st><st c="112249">)</st><st c="112250">)</st><st
    c="112251">2</st><st c="112252">)</st>
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="112225">方差 =</st> <st c="112237">𝔼</st><st c="112239">(</st><st c="112241">(</st><st
    c="112242">X</st><st c="112243">−</st> <st c="112244">𝔼</st><st c="112246">(</st><st
    c="112248">X</st><st c="112249">)</st><st c="112250">)</st><st c="112251">2</st><st
    c="112252">)</st>
- en: <st c="112253">Eq.</st> <st c="112257">69</st>
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="112253">公式</st> <st c="112257">69</st>
- en: <st c="112259">An alternative way of writing this, which is sometimes useful
    computationally, is</st> <st c="112342">the following:</st>
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="112259">一种可写出该式的替代方式，在某些计算中可能更有用，如下所示：</st>
- en: <st c="112356">Variance =</st> <st c="112368">𝔼</st><st c="112370">(</st><st
    c="112372">X</st><st c="112373">2</st><st c="112374">)</st><st c="112375">−</st>
    <st c="112376">(</st><st c="112377">𝔼</st><st c="112379">(</st><st c="112381">X</st><st
    c="112382">)</st><st c="112383">)</st><st c="112384">2</st>
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="112356">方差 =</st> <st c="112368">𝔼</st><st c="112370">(</st><st c="112372">X</st><st
    c="112373">2</st><st c="112374">)</st><st c="112375">−</st> <st c="112376">(</st><st
    c="112377">𝔼</st><st c="112379">(</st><st c="112381">X</st><st c="112382">)</st><st
    c="112383">)</st><st c="112384">2</st>
- en: <st c="112385">Eq.</st> <st c="112389">70</st>
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="112385">公式</st> <st c="112389">70</st>
- en: <st c="112391">Derive this second way of writing the variance</st> <st c="112439">of</st>
    <st c="112442">X</st><st c="112443">.</st>
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="112391">推导这种方差的第二种写法</st> <st c="112439">的</st> <st c="112442">X</st><st
    c="112443">。</st>
- en: <st c="112444">Create a dataset of 30 values sampled from the distribution</st>
    <st c="112505">Normal</st><st c="112511">(</st><st c="112513">μ</st> <st c="112514">=</st>
    <st c="112515">2</st><st c="112516">,</st> <st c="112517">σ</st><st c="112518">2</st>
    <st c="112519">=</st> <st c="112520">1.5</st><st c="112523">)</st><st c="112525">.
    Using this data, create and plot kernel density estimates using a Parzen kernel,
    but with three different bandwidth values,</st> <st c="112651">h</st> <st c="112652">=</st>
    <st c="112653">0.1</st><st c="112656">,</st> <st c="112658">h</st> <st c="112659">=</st>
    <st c="112660">1.0</st><st c="112663">, and</st> <st c="112669">h</st> <st c="112670">=</st>
    <st c="112671">3.0</st><st c="112674">. Add the true probability density to the
    plot.</st> <st c="112722">What do you notice about the three different</st> <st
    c="112767">density estimates?</st>
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含 30 个从分布 <st c="112505">Normal</st><st c="112511">(</st><st c="112513">μ</st>
    <st c="112514">=</st> <st c="112515">2</st><st c="112516">,</st> <st c="112517">σ</st><st
    c="112518">2</st> <st c="112519">=</st> <st c="112520">1.5</st><st c="112523">)</st>
    采样的数据集。使用这些数据，创建并绘制三种不同带宽值的 Parzen 核密度估计：<st c="112651">h</st> <st c="112652">=</st>
    <st c="112653">0.1</st><st c="112656">,</st> <st c="112658">h</st> <st c="112659">=</st>
    <st c="112660">1.0</st><st c="112663">,</st> 和 <st c="112669">h</st> <st c="112670">=</st>
    <st c="112671">3.0</st>。并将真实的概率密度添加到图表中。<st c="112722">你注意到这三种不同的密度估计有什么不同吗？</st>
- en: <st c="112785">If we have i.i.d.</st> <st c="112804">data values</st> <st c="112816">x</st><st
    c="112817">1</st><st c="112818">,</st> <st c="112819">x</st><st c="112820">2</st><st
    c="112821">,</st> <st c="112822">⋯</st> <st c="112823">,</st> <st c="112824">x</st><st
    c="112825">n</st> <st c="112826">with</st> <st c="112832">𝔼</st><st c="112834">(</st><st
    c="112836">x</st><st c="112837">i</st><st c="112838">)</st> <st c="112839">=</st>
    <st c="112840">μ</st> <st c="112841">and</st> <st c="112846">Var</st><st c="112849">(</st><st
    c="112851">x</st><st c="112852">i</st><st c="112853">)</st> <st c="112854">=</st>
    <st c="112855">σ</st><st c="112856">2</st><st c="112857">, prove that the expression
    in</st> *<st c="112888">Eq.</st> <st c="112892">48</st>* <st c="112894">for the
    sample variance</st> <st c="112919">s</st><st c="112920">2</st> <st c="112921">gives
    an unbiased estimator for the population variance</st> <st c="112977">σ</st><st
    c="112978">2</st><st c="112979">.</st>
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们有 i.i.d. 数据值 <st c="112785">x</st><st c="112817">1</st><st c="112818">,</st>
    <st c="112819">x</st><st c="112820">2</st><st c="112821">,</st> <st c="112822">⋯</st>
    <st c="112823">,</st> <st c="112824">x</st><st c="112825">n</st>，并且 <st c="112832">𝔼</st><st
    c="112834">(</st><st c="112836">x</st><st c="112837">i</st><st c="112838">)</st>
    <st c="112839">=</st> <st c="112840">μ</st> 且 <st c="112846">Var</st><st c="112849">(</st><st
    c="112851">x</st><st c="112852">i</st><st c="112853">)</st> <st c="112854">=</st>
    <st c="112855">σ</st><st c="112856">2</st>，证明 *<st c="112888">公式</st> <st c="112892">48</st>*
    中关于样本方差 <st c="112919">s</st><st c="112920">2</st> 的表达式是总体方差 <st c="112977">σ</st><st
    c="112978">2</st> 的无偏估计量。
