["```py\n import numpy as np\n# Create the two vectors\na = np.array([1.0, -4.0, 0.5])\nb = np.array([0.0, 3.5, 2.0])\n# Calculate the inner product\n# The answer should be = (1*0)+(-4.0*3.5)+(0.5*2.0) = 0-14+1 = -13\nnp.inner(a,b)\n```", "```py\n # Calculate the outer product\n# The answer should be a 3x3 array of the form\n# [[1*0, 1*3.5, 1*2], [-4*0, -4*3.5, -4*2], [0.5*0, 0.5*3.5, 0.5*2]]\n# which gives [[0, 3.5, 2], [0, -14, -8], [0, 1.75, 1]]\nnp.outer(a,b)\n```", "```py\n import numpy as np\n# Create 3x3 matrices\nA = np.array([[1.0, 2.0, 1.0], [-2.5, 1.0, 0.0], [3.0, 1.0, 1.5]])\nB = np.array([[1.0, -1.0, -1.0], [5, 2.0, 3.0], [3.0, 1.0, 2.0]])\n# Multiply the matrices together\nnp.matmul(A, B)\n```", "```py\n array([[14.,  4\\. ,  7\\. ],\n       [2.5,  4.5,  5.5],\n       [12.5, 0.5,  3\\. ]])\n```", "```py\n # Create a 4-dimensional vector\na = np.array([1.0, 2.0, 3.0, -2.0])\n# Create a 3x4 matrix\nA = np.array([\n    [1.0, 1.0, 0.0, 1.0], [-2.0, 2.5, 1.5, 3.0], \n    [0.0, 1.0, 1.0, 4.0]])\n# We'll use the matrix multiplication function to calculate # A*a\nnp.matmul(A, a)\n```", "```py\n array([ 1\\. ,  1.5, -3\\. ])\n```", "```py\n # Create a 4x4 square matrix\nA = np.array( [[1, 2, 3, 4],\n               [2, 1, 2, 1],\n               [0, 1, 3, 2],\n               [1, 1, 2, 2]])\n# Calculate and store the inverse matrix\nAinv = np.linalg.inv(A)\n# Multiply the matrix by its inverse. # We should get the identity matrix \n#[[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]]\n# up to numerical precision\nnp.matmul(Ainv, A)\n```", "```py\n import numpy as np\n# Create a 4x4 symmetric square matrix\nA = np.array( [[1, 2, 3, 4],\n               [2, 1, 2, 1],\n               [3, 2, 3, 2],\n               [4, 1, 2, 2]])\n# Calculate the eigen-decomposition\neigvals, eigvecs = np.linalg.eigh(A)\n```", "```py\n array([-2.84382794, -0.22727708, 1.02635, 9.04475502])\n```", "```py\n # Check that the eigenvectors are orthogonal to each other\n# and are of unit length. We can do this by calculating the\n# inner product for each pair of eigenvectors\nfor i in range(A.shape[0]):\n     for j in range(i,A.shape[0]):\n         print(\"i=\",i, \"j=\",j, \"Inner product = \", \n               np.inner(eigvecs[:, i], eigvecs[:, j]))\n```", "```py\n i= 0 j= 0 Inner product =  1.0\ni= 0 j= 1 Inner product =  -2.7755575615628914e-17\ni= 0 j= 2 Inner product =  -5.551115123125783e-17\ni= 0 j= 3 Inner product =  -1.6653345369377348e-16\ni= 1 j= 1 Inner product =  1.0\ni= 1 j= 2 Inner product =  5.551115123125783e-17\ni= 1 j= 3 Inner product =  0.0\ni= 2 j= 2 Inner product =  0.9999999999999993\ni= 2 j= 3 Inner product =  -8.326672684688674e-17\ni= 3 j= 3 Inner product =  0.9999999999999999\n```", "```py\n import numpy as np\n# Create a 5x3 matrix\nA = np.array([[1.0, 2.0, 3.0],\n              [-1.0, 0.0, 1.0],\n              [3.0, 3.0, 2.0],\n              [2.0, 4.0, 7.0],\n              [1.0, -0.5, -2.0]])\n```", "```py\n # Calculate SVD. In this instance the matrix\n# u will be a square matrix with the same number of rows\n# as the input matrix A has\nu, d, v_transpose = np.linalg.svd(A, full_matrices=True)\n```", "```py\n # Calculate the compact form of the SVD. In this instance\n# the matrix u_compact will have the same shape as the input\n# matrix A\nu_compact, d_compact, v_transpose_compact = np.linalg.svd(\n    A, full_matrices=False)\n```", "```py\n # Let's check that the matrix U has different shapes in\n# compact and non-compact forms of the SVD\nprint(u.shape, u_compact.shape)\n```", "```py\n (5, 5) (5, 3)\n```", "```py\n import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n## Read in the raw data into a pandas dataframe. sp500_returns = pd.read_csv('../Data/SP500_log_returns.csv')\n## Instantiate a PCA object and fit it to the SP500 returns matrix. ## Note that we convert the pandas dataframe to a numpy array first\npca = PCA()\npca.fit(sp500_returns.to_numpy())\n```", "```py\n pca.singular_values_[0:5]\n```", "```py\n array([6.81525175, 1.91949441, 1.63241764, 1.50134004, 1.28434791])\n```", "```py\n # Convert standard deviations into variances\npc_variance = np.power(pca.singular_values_, 2.0)\n# Calculate total variance\ntotal_variance = np.sum(pc_variance)\n# Calculate cumulative total variance\ncumulative_variance = 100.0*np.cumsum(pc_variance)/total_variance\n# Plot\nplt.plot(np.arange(1, 21), cumulative_variance[0:20], \n         color='b', marker='o')\nplt.title('Cumulative variance explained by first 20 PCs')\nplt.xlabel('PC')\nplt.ylabel('Cumulative % of total variance')\nplt.show()\n```", "```py\n # Plot\nplt.rcParams[\"figure.figsize\"] = (20,6)\nplt.stem(np.arange(1, pca.components_.shape[1] + 1), \n         -pca.components_[0, :], markerfmt=' ')\nplt.title('Loading values for PC1', fontsize=24)\nplt.xlabel('Stock', fontsize=20)\nplt.ylabel('Loading', fontsize=20)\nplt.show()\n```", "```py\n #Plot\nplt.scatter( x=scores[:,1], y=scores[:,2])\nplt.title('PC3 score vs PC2 score', fontsize=24)\nplt.xlabel('PC2 :' + str(round(100.0*(\n    pc_variance[1]/total_variance),2)) + '%', fontsize=20)\nplt.ylabel('PC3 :' + str(round(100.0*(\n    pc_variance[2]/total_variance),2)) + '%', fontsize=20)\nplt.xticks(fontsize=18, rotation=45)\nplt.yticks(fontsize=18)\nplt.show()\n```", "```py\n import numpy as np\nfrom sklearn.decomposition import NMF\n# Create a customer-purchase matrix. We'll use the one\n# in the main text. X = np.array([[1, 1, 1, 0],\n              [1, 1, 1, 1],\n              [0, 1, 0, 0],\n              [1, 1, 0, 0],\n              [1, 0, 1, 1],\n              [1, 1, 0, 1],\n              [1, 1, 1, 1]])\n# Instantiate the NMF model\nmodel = NMF(n_components=2, init='random', random_state=0)\n# Fit the model to the data matrix\nW = model.fit_transform(X)\n# Extract the component vectors\nH = model.components_\n# Compute the difference between NMF approximation and the #data\nnp.matmul(W, H) - X\n```", "```py\n array([[-0.09412173,  0.04403871, -0.46340574, <st c=\"81953\">0.53659426]</st>,\n       [ 0.16151778, -0.07560645, -0.06281629, -0.06281629],\n       [ 0.38384462, -0.17957389,  0\\. 0\\. ],\n       [-0.34976125,  0.16368387,  0.13600481,  0.13600481],\n       [-0.14594226,  0.06843165,  0.05675037,  0.05675037],\n       [-0.09412173,  0.04403871,  0.53659426, -0.46340574],\n       [ 0.16151778, -0.07560645, -0.06281629, -0.06281629]])\n```"]