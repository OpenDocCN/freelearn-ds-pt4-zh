<html><head></head><body>
		<div id="_idContainer2085">
			<h1 id="_idParaDest-144" class="chapter-number"><a id="_idTextAnchor261"/><st c="0">5</st></h1>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor262"/><st c="2">Probabilistic Modeling</st></h1>
			<p><st c="24">At the heart of probabilistic modeling is the idea that because data is random, and so follows a </st><a id="_idIndexMarker459"/><st c="122">probability distribution, our models of that data must also follow a </st><a id="_idIndexMarker460"/><st c="191">probability distribution and be probabilistic models from the outset. </st><st c="261">To understand how to build those models, we must first understand the probability distribution that the data follows. </st><st c="379">From this, we can calculate the distribution that our model parameters follow by using one of the most famous theorems in probability theory. </st><st c="521">To do all of this, we will cover the </st><span class="No-Break"><st c="558">following topics:</st></span></p>
			<ul>
				<li><em class="italic"><st c="575">Likelihood</st></em><st c="586">: In this section, we will learn about the probability distribution of the data given </st><span class="No-Break"><st c="673">a model</st></span></li>
				<li><em class="italic"><st c="680">Bayes’ theorem</st></em><st c="695">: In this section, we will learn how to work with conditional probabilities and calculate the probability of a model given </st><span class="No-Break"><st c="819">the data</st></span></li>
				<li><em class="italic"><st c="827">Bayesian modeling</st></em><st c="845">: In this section, we will learn how to use the probability of the model given the data to make </st><span class="No-Break"><st c="942">useful inferences</st></span></li>
				<li><em class="italic"><st c="959">Bayesian modeling in practice</st></em><st c="989">: In this section, we will learn practical computational techniques and mathematical approximations for doing </st><span class="No-Break"><st c="1100">Bayesian modeling</st></span></li>
			</ul>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor263"/><st c="1117">Technical requirements</st></h1>
			<p><st c="1140">All code examples given in this chapter (and additional examples) can be found at the GitHub repository: </st><a href="https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter05"><st c="1246">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter05</st></a><st c="1350">. To run the Jupyter notebooks, you will need a full Python installation, including the </st><span class="No-Break"><st c="1438">following packages:</st></span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline"><st c="1457">pandas</st></strong></span><span class="No-Break"><st c="1464"> (&gt;=2.0.3)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="1474">numpy</st></strong></span><span class="No-Break"><st c="1480"> (&gt;=1.3)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="1488">scipy</st></strong></span><span class="No-Break"><st c="1494"> (&gt;=1.1)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="1502">matplotlib</st></strong></span><span class="No-Break"><st c="1513"> (&gt;=3.7.2)</st></span></li>
			</ul>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor264"/><st c="1523">Likelihood</st></h1>
			<p><st c="1534">To</st><a id="_idIndexMarker461"/><st c="1537"> understand the probability distribution that the data follows, we’ll look at an explicit example of how a random component is incorporated </st><span class="No-Break"><st c="1677">into data.</st></span></p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor265"/><st c="1687">A simple probabilistic model</st></h2>
			<p><st c="1716">We’ll start </st><a id="_idIndexMarker462"/><st c="1729">with the simplest way in which we can introduce a random component into our observations of the response (target) variable </st><img src="image/24.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.441em"/><st c="1852"/><st c="1875">, namely by adding noise to a deterministic quantity. </st><st c="1929">In fact, we’ll just consider the observations </st><img src="image/1521.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.593em"/><st c="1975"/><st c="1976"> in our dataset to be noise-corrupted versions of a model output </st><img src="image/1522.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.460em"/><st c="2041"/><st c="2050">. So, we have </st><span class="No-Break"><st c="2064">this relationship:</st></span></p>
			<p><img src="image/1523.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.407em;height:1.322em;width:6.695em"/><st c="2082"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="2084">Eq. </st><st c="2088">1</st></p>
			<p><st c="2089">Here, </st><img src="image/1524.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.526em"/><st c="2095"/><st c="2096"> is the noise value that has been added to the model output </st><img src="image/1525.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:4.885em"/><st c="2156"/><st c="2157"> to get the observation </st><img src="image/1526.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.588em"/><st c="2181"/><st c="2182"> for the </st><img src="image/1186.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.760em;width:0.802em"/><st c="2191"/><st c="2195"> datapoint. </st><st c="2206">The value </st><img src="image/1528.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.533em"/><st c="2216"/><st c="2217"> is a random variable. </st><st c="2240">Without loss of generality, we can assume its expectation value is zero, so we have </st><img src="image/1529.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.001em;width:3.689em"/><st c="2324"/><st c="2325">. We can make this assumption because if the expectation of </st><img src="image/1528.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.532em"/><st c="2385"/><st c="2386"> was non-zero, it would mean we have a non-zero deterministic average contribution from </st><img src="image/1528.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.532em"/><st c="2474"/><st c="2475"> that we could just absorb into the definition of </st><img src="image/1532.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.018em;width:0.824em"/><st c="2525"/><st c="2526">. This is just the same as saying that we </st><span class="No-Break"><st c="2568">can write:</st></span></p>
			<p class="IMG---Figure"><img src="image/1533.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;ε&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo mathvariant=&quot;italic&quot;&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo mathvariant=&quot;italic&quot;&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;ε&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;~&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.307em;height:0.903em;width:4.158em"/><st c="2578"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="2585">Eq. </st><st c="2589">2</st></p>
			<p><img src="image/1534.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;ε&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.001em;width:3.386em"/><st c="2590"/><st c="2591">, and </st><img src="image/1535.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;~&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.976em;width:0.665em"/><st c="2597"/><st c="2598"> is just a new random variable that does have zero expectation (by construction). </st><st c="2680">We then just add </st><img src="image/285.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.489em"/><st c="2697"/><st c="2698"> into the definition of our </st><span class="No-Break"><st c="2726">model </st></span><span class="No-Break"><img src="image/1537.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.935em;width:0.785em"/><st c="2732"/></span><span class="No-Break"><st c="2733">.</st></span></p>
			<p><st c="2734">The simple scenario we shall consider is where the noise values </st><img src="image/1538.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.579em"/><st c="2799"/><st c="2800"> for the different data points are uncorrelated with each other. </st><st c="2865">Mathematically, we write this assumption as </st><img src="image/1539.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;'&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.058em;width:4.630em"/><st c="2909"/><st c="2910">, for </st><span class="No-Break"><st c="2916">all </st></span><span class="No-Break"><img src="image/1540.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;'&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;≠&lt;/mml:mo&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.689em;width:2.274em"/><st c="2920"/></span><span class="No-Break"><st c="2921">.</st></span></p>
			<p><st c="2922">Now, if each </st><a id="_idIndexMarker463"/><st c="2936">noise value </st><img src="image/1541.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;ε&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:0.988em;width:5.851em"/><st c="2948"/><st c="2949"> is a random variable; what probability distributions should those random noise values come from? </st><st c="3047">Again, we consider the simplest situation, where each noise value </st><img src="image/1542.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.537em"/><st c="3113"/><st c="3114"> is drawn from the same distribution. </st><st c="3152">Note that this doesn’t mean that all the noise values are identical; it means that they are </st><span class="No-Break"><st c="3244">identically distributed.</st></span></p>
			<p><st c="3268">What should we use for this common noise distribution? </st><st c="3324">Let’s use one of the most common distributions, the Gaussian (or normal) distribution. </st><st c="3411">So, we can write the probability density of </st><img src="image/1542.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.537em"/><st c="3455"/> <span class="No-Break"><st c="3456">as follows:</st></span></p>
			<p><img src="image/1544.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;π&lt;/mml:mi&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mtext&gt;exp&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.684em;height:1.698em;width:11.034em"/><st c="3467"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="3469">Eq. </st><st c="3473">3</st></p>
			<p><st c="3474">The quantity </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.474em"/><st c="3487"/><st c="3488"> is the standard deviation of the noise value </st><img src="image/1546.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.535em"/><st c="3534"/><st c="3535">, and this is the same for all data points </st><img src="image/106.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.651em;width:0.272em"/><st c="3578"/><st c="3579">. The bigger the value of </st><img src="image/1548.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.454em"/><st c="3605"/><st c="3606">, the bigger the typical values of the noise will be, i.e., the more the observations </st><img src="image/1521.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.593em"/><st c="3692"/><st c="3693"> will differ from the deterministic output from </st><span class="No-Break"><st c="3741">our model.</st></span></p>
			<p><st c="3751">Since we are using a Gaussian distribution for each of the noise values, the fact that different noise values are uncorrelated means they are statistically independent. </st><st c="3921">So, our noise values</st><a id="_idIndexMarker464"/><st c="3941"> are </st><strong class="bold"><st c="3946">independently and identically distributed</st></strong><st c="3987">, </st><span class="No-Break"><st c="3989">or </st></span><span class="No-Break"><strong class="bold"><st c="3992">i.i.d</st></strong></span><span class="No-Break"><st c="3997">.</st></span></p>
			<p><st c="3998">In </st><a href="B19496_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic"><st c="4002">Chapter 2</st></em></span></a><st c="4011">, we said that anything derived from a random variable was itself a random variable. </st><st c="4096">Well, if </st><img src="image/1550.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.527em"/><st c="4105"/><st c="4106"> is a random variable, then Eq. </st><st c="4138">1 means that </st><img src="image/1551.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.583em"/><st c="4151"/><st c="4152"> is a random variable – as we would expect, it is data after all. </st><st c="4218">But what is the probability distribution for </st><img src="image/1521.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.593em"/><st c="4263"/><st c="4264">? The combination of Eq. </st><st c="4289">1 and Eq. </st><st c="4299">3 tells us. </st><st c="4311">If we re-arrange Eq. </st><st c="4332">1 we </st><span class="No-Break"><st c="4337">get this:</st></span></p>
			<p><img src="image/1553.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;.&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.407em;height:1.322em;width:10.398em"/><st c="4346"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="4348">Eq. </st><st c="4352">4</st></p>
			<p><st c="4353">If we plug the expression for </st><img src="image/1554.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;ε&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:0.822em;width:0.535em"/><st c="4383"/><st c="4384"> in Eq. </st><st c="4392">4 into Eq. </st><st c="4403">3, we </st><span class="No-Break"><st c="4409">get this:</st></span></p>
			<p><img src="image/1555.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;π&lt;/mml:mi&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mtext&gt;exp&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.684em;height:1.698em;width:15.234em"/><st c="4418"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="4420">Eq. </st><st c="4424">5</st></p>
			<p><st c="4425">This means that </st><img src="image/1556.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:0.822em;width:0.625em"/><st c="4441"/><st c="4442"> is a Gaussian random variable distributed around a mean of </st><img src="image/1557.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.028em;width:0.816em"/><st c="4502"/><st c="4503"> with a standard deviation of </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="4533"/><st c="4534">. Since </st><img src="image/1559.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.028em;width:0.771em"/><st c="4542"/><st c="4543"> is a deterministic function of the input features </st><img src="image/1560.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:0.822em;width:0.685em"/><st c="4594"/><st c="4598"> and the model parameters </st><img src="image/1561.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.521em"/><st c="4623"/><st c="4624">, then </st><img src="image/1562.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.445em;height:1.403em;width:3.324em"/><st c="4631"/><st c="4640"> means </st><img src="image/1563.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.445em;height:1.403em;width:4.408em"/><st c="4646"/><st c="4647">, so we can re-write the probability density for </st><img src="image/1564.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:0.822em;width:0.592em"/><st c="4696"/><st c="4697"> in Eq. </st><st c="4705">5 </st><span class="No-Break"><st c="4707">as follows:</st></span></p>
			<p><img src="image/1565.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;π&lt;/mml:mi&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mtext&gt;exp&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.684em;height:1.884em;width:18.985em"/><st c="4718"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="4720">Eq. </st><st c="4724">6</st></p>
			<p><st c="4725">This is the </st><a id="_idIndexMarker465"/><st c="4737">probability density for the </st><img src="image/1566.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.760em;width:0.808em"/><st c="4765"/><st c="4769"> observation </st><img src="image/1567.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.593em"/><st c="4781"/><st c="4782">. Since the observations are independent, then the probability density for the whole set of observations is just the product of the individual densities, and so we </st><span class="No-Break"><st c="4946">have this:</st></span></p>
			<p><img src="image/1568.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:munderover&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∏&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munderover&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.767em;height:2.191em;width:10.962em"/><st c="4956"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="4958">Eq. </st><st c="4962">7</st></p>
			<p><st c="4963">This probability </st><a id="_idIndexMarker466"/><st c="4980">density function gives the probability density of the observed data </st><img src="image/1569.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:0.805em;width:0.442em"/><st c="5048"/><st c="5049">. It is called the </st><strong class="bold"><st c="5068">likelihood of the data</st></strong><st c="5090">, or simply the </st><strong class="bold"><st c="5106">likelihood</st></strong><st c="5116">, and is usually denoted by the symbol </st><img src="image/1570.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.531em"/><st c="5155"/><st c="5156">. If we were dealing with discrete observations instead of continuous ones then we would compute the probability of the data, rather than the probability density of the data, but in either case, we refer to the resulting function as </st><span class="No-Break"><st c="5389">the likelihood.</st></span></p>
			<p><st c="5404">The expression in Eq. </st><st c="5427">7 is the general form for the likelihood when we have independent observations. </st><st c="5507">If we plug in the expression in Eq. </st><st c="5543">6 into Eq. </st><st c="5554">7, we obtain an explicit expression for the likelihood </st><span class="_-----MathTools-_Math_Variable"><st c="5609">L</st></span><st c="5610"> for our specific model. </st><st c="5635">In this case, the likelihood is </st><span class="No-Break"><st c="5667">as </st></span><span class="No-Break"><st c="5670">follows:</st></span></p>
			<p><span class="_-----MathTools-_Math_Variable"><img src="image/1571.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.767em;height:2.191em;width:16.368em"/><st c="5678"/></span></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="5680">Eq. </st><st c="5684">8</st></p>
			<p><st c="5685">In shorthand, whether we are dealing with a probability or a probability density, we often refer to the likelihood using the notation </st><img src="image/1572.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.100em;width:6.571em"/><st c="5819"/><st c="5835">, </st><img src="image/1573.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.100em;width:6.515em"/><st c="5837"/><st c="5854">, or </st><img src="image/1574.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:4.682em"/><st c="5859"/><st c="5872">. This is sometimes shortened to </st><img src="image/1575.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;D&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.100em;width:5.283em"/><st c="5905"/><st c="5918">, </st><img src="image/1576.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;D&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.100em;width:5.215em"/><st c="5920"/><st c="5933">, or </st><img src="image/1577.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;D&lt;/mtext&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.384em"/><st c="5938"/><st c="5947">, with </st><img src="image/1578.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mtext&gt;D&lt;/mml:mtext&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.649em;width:0.734em"/><st c="5954"/><st c="5955"> standing </st><span class="No-Break"><st c="5965">for data.</st></span></p>
			<p><st c="5974">The</st><a id="_idIndexMarker467"/><st c="5978"> likelihood is an extremely useful quantity. </st><st c="6023">In fact, it is the central quantity when developing probabilistic models, and as we have learned, all models should be probabilistic. </st><st c="6157">Given the importance of the likelihood, we’re going to look at some of its properties </st><span class="No-Break"><st c="6243">in detail.</st></span></p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor266"/><st c="6253">Log likelihood</st></h2>
			<p><st c="6268">The</st><a id="_idIndexMarker468"/><st c="6272"> expression in Eq. </st><st c="6291">8 looks complicated. </st><st c="6312">It’s a horrible, complicated product of expressions. </st><st c="6365">We can simplify it a bit by converting it to a sum. </st><st c="6417">We do this by taking the logarithm. </st><st c="6453">From our rules of logarithms recapped in </st><a href="B19496_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic"><st c="6494">Chapter 1</st></em></span></a><st c="6503">, we </st><span class="No-Break"><st c="6508">have </st></span><span class="No-Break"><st c="6513">this:</st></span></p>
			<p><img src="image/1579.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;log&lt;/mtext&gt;&lt;mtext&gt;Likelihood&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mtext&gt;log&lt;/mtext&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.767em;height:2.191em;width:16.685em"/><st c="6518"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="6565">Eq. </st><st c="6569">9</st></p>
			<p><st c="6570">And for our example in Eq. </st><st c="6597">8, we </st><span class="No-Break"><st c="6603">have this:</st></span></p>
			<p><img src="image/1580.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;log&lt;/mtext&gt;&lt;mtext&gt;Likelihood&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mtext&gt;log&lt;/mtext&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.767em;height:2.191em;width:25.185em"/><st c="6613"/></p>
			<p class="First-Paragraph"><img src="image/1581.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;π&lt;/mml:mi&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:munderover&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∑&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munderover&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.767em;height:2.191em;width:15.722em"/><st c="6689"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="6720">Eq. </st><st c="6724">10</st></p>
			<p><st c="6726">The first thing to point out is that the typical value of the log-likelihood scales linearly with the number of data points </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="6851"/><st c="6852">. For independent observations, each data point will make a contribution </st><span class="_-----MathTools-_Math_Function_v-normal"><st c="6925">log</st></span><span class="_-----MathTools-_Math_Variable"><st c="6928">p</st></span><span class="_-----MathTools-_Math_Base"><st c="6930">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="6931">y</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="6932">i</st></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><st c="6933">|</st></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Base"><st c="6934">ˆ</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="6935">y</st></span><span class="_-----MathTools-_Math_Variable"/><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="6936">i</st></span><span class="_-----MathTools-_Math_Base"><st c="6937">)</st></span><st c="6938">, and these contributions build up with each observation. </st><st c="6996">Even when the observations are not independent, but are correlated, we would still expect the </st><img src="image/1583.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;log&lt;/mtext&gt;&lt;mtext&gt;Likelihood&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.307em;height:1.068em;width:7.111em"/><st c="7090"/><st c="7108"> to scale linearly with </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="7131"/><st c="7132">, as </st><img src="image/1585.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:2.985em"/><st c="7137"/><st c="7138">, in most cases. </st><st c="7155">The correlations between observations will reduce the amount of information that each observation adds to the log-likelihood, but each observation will still add some information. </st><st c="7335">Overall, this means that the larger the </st><img src="image/443.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.699em"/><st c="7375"/><st c="7376">, the larger the magnitude of </st><span class="No-Break"><st c="7406">the log-likelihood.</st></span></p>
			<p><st c="7425">The</st><a id="_idIndexMarker469"/><st c="7429"> second thing we can point out about the log-likelihood is that it is not only a function of the model parameters </st><img src="image/1587.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.518em"/><st c="7543"/><st c="7544">, but also of the parameters that control the random component in our data; in this case the </st><span class="No-Break"><st c="7637">parameter </st></span><span class="No-Break"><img src="image/1588.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mo mathvariant=&quot;italic&quot;&gt;.&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.710em"/><st c="7647"/></span></p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor267"/><st c="7648">Maximum likelihood estimation</st></h2>
			<p><st c="7677">The </st><a id="_idIndexMarker470"/><st c="7682">likelihood is </st><img src="image/1589.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.022em;width:4.509em"/><st c="7696"/><st c="7709">, where we mean either probability or probability density depending on whether we are talking about discrete</st><a id="_idIndexMarker471"/><st c="7817"> data or continuous data. </st><st c="7843">How can we use the likelihood to estimate model parameter values that are a good fit for </st><span class="No-Break"><st c="7932">the data?</st></span></p>
			<p><st c="7941">If we have a good model, we expect the probability of the observed data to be high. </st><st c="8026">After all, we have observed the data. </st><st c="8064">If we had parameter values for which </st><img src="image/1590.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.022em;width:4.091em"/><st c="8101"/><st c="8113"> is low, that would say the probability of the data we have actually observed is low. </st><st c="8198">This would seem strange and perhaps just the result of the random sampling variation – it is possible but unlikely. </st><st c="8314">In contrast, parameter values for which </st><img src="image/1591.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.484em"/><st c="8354"/><span class="_-----MathTools-_Math_Variable"><img src="image/1592.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.022em;width:3.946em"/><st c="8355"/></span><st c="8366"> is high appear to be more appropriate and a more credible explanation of the data. </st><st c="8449">This gives us a means of estimating the model parameters </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.522em"/><st c="8506"/><st c="8507">. We estimate </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.522em"/><st c="8521"/><st c="8522"> by maximizing </st><img src="image/1595.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.022em;width:4.216em"/><st c="8537"/><st c="8549"> with respect to </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.527em"/><st c="8565"/><st c="8566">. This is called </st><strong class="bold"><st c="8583">maximum </st></strong><span class="No-Break"><strong class="bold"><st c="8591">likelihood estimation</st></strong></span><span class="No-Break"><st c="8612">.</st></span></p>
			<p class="callout-heading"><st c="8613">Pro tip</st></p>
			<p class="callout"><st c="8621">As a technique, maximum likelihood is widely used in data science. </st><st c="8689">However, maximum likelihood was used long before the term data science was coined. </st><st c="8772">Maximum likelihood is taught as part of traditional courses in statistics. </st><st c="8847">The abbreviation </st><strong class="bold"><st c="8864">ML</st></strong><st c="8866"> for </st><strong class="bold"><st c="8871">maximum likelihood</st></strong><st c="8889"> is still used in some research areas. </st><st c="8928">In data science, this has the potential to confuse, since most practitioners of data science would interpret </st><strong class="bold"><st c="9037">ML</st></strong><st c="9039"> to mean </st><strong class="bold"><st c="9048">machine</st></strong> <strong class="bold"><st c="9055">learning</st></strong><st c="9064">. So, be aware there may be data science circumstances where </st><strong class="bold"><st c="9125">ML</st></strong><st c="9127"> means </st><span class="No-Break"><strong class="bold"><st c="9134">maximum likelihood</st></strong></span><span class="No-Break"><st c="9152">.</st></span></p>
			<h3><st c="9153">Least squares as an example of maximum likelihood</st></h3>
			<p><st c="9203">We’ll look at what happens if we estimate the parameters of our model </st><img src="image/1597.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.009em;width:2.743em"/><st c="9274"/><st c="9275"> via </st><span class="No-Break"><st c="9280">maximum likelihood.</st></span></p>
			<p><st c="9299">You’ll </st><a id="_idIndexMarker472"/><st c="9307">recall from the recap in </st><a href="B19496_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic"><st c="9332">Chapter 1</st></em></span></a><st c="9341"> that the location of the maximum of a function is the same as the location of the maximum of the logarithm of the function. </st><st c="9466">This is because the logarithm is a monotonically increasing transformation. </st><st c="9542">Maximizing the likelihood </st><img src="image/1598.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.549em"/><st c="9568"/><st c="9569"> with respect to the model parameters </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.520em"/><st c="9607"/><st c="9608"> is the same as maximizing the log-likelihood, </st><img src="image/1600.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:1.724em"/><st c="9655"/><st c="9656">, with respect to the model parameters </st><img src="image/1561.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.516em"/><st c="9695"/><st c="9696">. The latter is easier to do. </st><st c="9726">For our model, the log-likelihood is given by Eq. </st><st c="9776">10. </st><st c="9780">So, let’s maximize </st><span class="No-Break"><st c="9799">Eq. </st><st c="9803">10.</st></span></p>
			<p><st c="9806">Technically, we should maximize </st><img src="image/1602.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:1.739em"/><st c="9839"/><st c="9844"> with respect to all the parameters of the log-likelihood, so with respect to </st><img src="image/1603.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.555em"/><st c="9921"/><st c="9922"> and </st><img src="image/1604.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.498em"/><st c="9927"/><st c="9928">. We will do this, but for now, let’s take </st><img src="image/1604.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.498em"/><st c="9971"/><st c="9972"> as given, i.e., fixed. </st><st c="9996">We can, in theory, maximize with respect to </st><img src="image/1561.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.527em"/><st c="10040"/><st c="10041"> at fixed </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="10051"/><st c="10052"> to find the maximum likelihood values </st><img src="image/1608.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.221em;width:1.798em"/><st c="10091"/><st c="10096"> as a function of </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="10113"/><st c="10114"> and plug </st><img src="image/1608.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.221em;width:1.798em"/><st c="10124"/><st c="10129"> back into Eq. </st><st c="10143">10, and then finally maximize the resulting expression with respect to </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="10214"/><st c="10215">. However, for now </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="10234"/><st c="10235"> is fixed. </st><st c="10246">From the relatively simple form of Eq. </st><st c="10285">10, we can see that maximizing Eq. </st><st c="10320">10 with respect to </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.527em"/><st c="10339"/><st c="10340">  at fixed </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="10350"/><st c="10351"> is the same as maximizing </st><span class="No-Break"><st c="10378">the following:</st></span></p>
			<p><img src="image/1615.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.848em;height:2.374em;width:7.727em"/><st c="10392"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="10411">Eq. </st><st c="10415">11</st></p>
			<p><st c="10417">This is clearly the same as minimizing (on dropping the </st><span class="No-Break"><st c="10474">minus sign):</st></span></p>
			<p><img src="image/1616.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munderover&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∑&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munderover&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.767em;height:2.191em;width:7.281em"/><st c="10486"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="10504">Eq. </st><st c="10508">12</st></p>
			<p><st c="10510">So, to maximize the likelihood, we minimize the expression in Eq. </st><st c="10577">12. </st><st c="10581">Wait a minute! </st><st c="10596">Haven’t we seen the expression in Eq. </st><st c="10634">12 somewhere before, and even minimized it? </st><st c="10678">The answer is yes. </st><st c="10697">Estimating the model parameters </st><img src="image/1561.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.527em"/><st c="10729"/><st c="10730"> by minimizing the expression in Eq. </st><st c="10767">12 is least </st><span class="No-Break"><st c="10779">squares estimation!</st></span></p>
			<p><st c="10798">We covered least squares in </st><a href="B19496_04.xhtml#_idTextAnchor216"><span class="No-Break"><em class="italic"><st c="10827">Chapter 4</st></em></span></a><st c="10836">, so we don’t need to go into further detail in this chapter. </st><st c="10898">However, it does show that we can begin to put least squares onto a more </st><span class="No-Break"><st c="10971">rigorous footing.</st></span></p>
			<p><st c="10988">So far, we </st><a id="_idIndexMarker473"/><st c="11000">have kept the noise standard deviation </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.480em"/><st c="11039"/><st c="11040"> fixed. </st><st c="11048">Do we still have this equivalence between maximum likelihood estimation and least squares estimation if we maximize the likelihood with respect to all parameters, not just </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.526em"/><st c="11220"/><st c="11221">? Let’s see. </st><st c="11234">To locate the maximum of </st><img src="image/1620.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:1.759em"/><st c="11259"/><st c="11260">, we use the differential calculus we recapped in </st><a href="B19496_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic"><st c="11310">Chapter 1</st></em></span></a><st c="11319">. Specifically, we solve the </st><span class="No-Break"><st c="11348">following equations:</st></span></p>
			<p><img src="image/1621.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mfenced open=&quot;&quot; close=&quot;|&quot; separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;∂&lt;/mml:mo&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;∂&lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mfenced open=&quot;&quot; close=&quot;|&quot; separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;∂&lt;/mml:mo&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;∂&lt;/mml:mo&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-1.294em;height:2.543em;width:16.041em"/><st c="11368"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="11375">Eq. </st><st c="11379">13</st></p>
			<p><st c="11381">Solving the equations in Eq. </st><st c="11411">13 will give us the maximum likelihood estimates </st><img src="image/1622.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.221em;width:0.646em"/><st c="11460"/><st c="11461"> and </st><img src="image/1623.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.830em;width:0.657em"/><st c="11466"/><st c="11467">. If we take the left-hand equation in Eq. </st><st c="11510">13 for our particular log-likelihood expression in Eq. </st><st c="11565">10, then differentiating with respect to </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.527em"/><st c="11606"/><st c="11607"> gives the </st><span class="No-Break"><st c="11618">following equation:</st></span></p>
			<p><img src="image/1625.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mover&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msub&gt;&lt;mfenced open=&quot;&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mover&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-1.372em;height:2.897em;width:13.679em"/><st c="11637"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="11639">Eq. </st><st c="11643">14</st></p>
			<p><st c="11645">We can re-arrange this to get </st><span class="No-Break"><st c="11676">the </st></span><span class="No-Break"><st c="11680">following:</st></span></p>
			<p><img src="image/1626.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mfenced open=&quot;&quot; close=&quot;|&quot; separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;∂&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;∂&lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:munderover&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∑&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munderover&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-1.294em;height:2.718em;width:12.273em"/><st c="11690"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="11692">Eq. </st><st c="11696">15</st></p>
			<p><st c="11698">This is the criterion we would get if we were minimizing Eq. </st><st c="11760">12. </st><st c="11764">So, in this instance, solving for the maximum likelihood value of </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.520em"/><st c="11830"/><st c="11831"> is the same as least squares minimization, irrespective of the particular value </st><span class="No-Break"><st c="11912">of </st></span><span class="No-Break"><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="11915"/></span><span class="No-Break"><st c="11916">.</st></span></p>
			<p><st c="11917">If we take the right-hand equation in Eq. </st><st c="11960">13 for our log-likelihood expression in Eq. </st><st c="12004">10, then differentiating with respect to </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.475em"/><st c="12045"/><st c="12046"> gives the </st><span class="No-Break"><st c="12057">following equation:</st></span></p>
			<p><img src="image/1630.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mover&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msup&gt;&lt;mover&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mover&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.848em;height:2.374em;width:12.747em"/><st c="12076"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="12078">Eq. </st><st c="12082">16</st></p>
			<p><st c="12084">We can re-arrange this to get </st><span class="No-Break"><st c="12115">the following:</st></span></p>
			<p><img src="image/1631.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:munderover&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∑&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munderover&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.767em;height:2.191em;width:11.047em"/><st c="12129"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="12131">Eq. </st><st c="12135">17</st></p>
			<p><st c="12137">Eq. </st><st c="12142">17 tells </st><a id="_idIndexMarker474"/><st c="12151">us that our estimate of the noise variance is just the mean squared residual once we have solved Eq. </st><st c="12252">15 to get the value of </st><img src="image/1622.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.221em;width:0.645em"/><st c="12275"/><st c="12276">. So, we can determine the maximum likelihood estimate </st><img src="image/1623.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.830em;width:0.651em"/><st c="12331"/><st c="12332"> after and separately from calculating the maximum likelihood </st><span class="No-Break"><st c="12394">estimate </st></span><span class="No-Break"><img src="image/1622.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.221em;width:0.643em"/><st c="12403"/></span><span class="No-Break"><st c="12404">.</st></span></p>
			<p><st c="12405">This convenient separation of the maximum likelihood estimation into the estimation of the model parameters </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.522em"/><st c="12514"/><st c="12515"> distinctly from the estimation of the parameters controlling the random component is a consequence of the noise being Gaussian additive. </st><st c="12653">For many modeling problems, the random component is not Gaussian additive. </st><st c="12728">So, what does maximum likelihood estimation look like in </st><span class="No-Break"><st c="12785">these situations?</st></span></p>
			<h3><st c="12802">Maximum likelihood estimation for non-additive randomness</st></h3>
			<p><st c="12860">We</st><a id="_idIndexMarker475"/><st c="12863"> often start with the form of the distribution that we think the data follows. </st><st c="12942">For example, for an observation </st><img src="image/1636.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.620em"/><st c="12974"/><st c="12975"> that is a positive and continuous quantity, we might have good reason to model the observation using an exponential distribution. </st><st c="13106">The exponential distribution has a single parameter, </st><img src="image/826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.486em"/><st c="13159"/><st c="13160">. In terms of </st><img src="image/826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.486em"/><st c="13174"/><st c="13175"> we would </st><span class="No-Break"><st c="13185">write this:</st></span></p>
			<p><a id="_idTextAnchor268"/><img src="image/1639.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mtext&gt;Exponential&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.101em;width:7.656em"/><st c="13196"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="13215">Eq. </st><st c="13219">18</st></p>
			<p><st c="13221">The mean of an exponential distribution is easily calculated in terms of </st><img src="image/817.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.473em"/><st c="13295"/><st c="13296">, and so we have </st><span class="No-Break"><st c="13313">the following:</st></span></p>
			<p><a id="_idTextAnchor269"/><img src="image/1641.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.513em;height:1.477em;width:5.944em"/><st c="13327"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="13329">Eq. </st><st c="13333">19</st></p>
			<p><st c="13335">Obviously, the mean </st><img src="image/1642.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.547em"/><st c="13356"/><st c="13357"> is the typical value we would see for </st><img src="image/1643.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.673em"/><st c="13396"/><st c="13397">, and so </st><img src="image/1642.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.548em"/><st c="13406"/><st c="13407"> specifies the systematic component in the data. </st><st c="13456">Now, our model </st><img src="image/1645.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.018em;width:0.847em"/><st c="13471"/><st c="13472"> is deterministic, so we should relate it to</st><a id="_idIndexMarker476"/><st c="13516"> the systematic component of </st><img src="image/1521.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.593em"/><st c="13545"/><st c="13546"> in some form. </st><st c="13561">We often construct our model </st><img src="image/1645.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.018em;width:0.828em"/><st c="13590"/><st c="13591"> as being a model of the mean of </st><img src="image/1648.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.596em"/><st c="13624"/><st c="13625">, so we can write </st><img src="image/1649.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.018em;width:3.793em"/><st c="13643"/><st c="13644">. Given the relation in Eq. </st><st c="13672">19 and equating </st><img src="image/1649.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.018em;width:3.799em"/><st c="13688"/><st c="13689">, we can re-arrange to get </st><img src="image/1651.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:3.642em"/><st c="13716"/><st c="13717">. Plugging this into Eq. </st><st c="13742">18 gives </st><span class="No-Break"><st c="13751">us this:</st></span><a id="_idTextAnchor270"/></p>
			<p><img src="image/1652.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mtext&gt;Exponential&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.813em;height:1.828em;width:8.377em"/><st c="13759"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="13781">Eq. </st><st c="13785">20</st></p>
			<p><st c="13787">The probability density of the exponential distribution in Eq. </st><st c="13851">18 is given by </st><span class="No-Break"><st c="13866">the following:</st></span><a id="_idTextAnchor271"/></p>
			<p><img src="image/1653.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.363em;height:1.303em;width:8.466em"/><st c="13880"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="13901">Eq. </st><st c="13905">21</st></p>
			<p><st c="13907">So, if we plug </st><img src="image/1654.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:3.659em"/><st c="13923"/><st c="13924"> into Eq. </st><st c="13934">21 and take logs, we can write </st><span class="No-Break"><st c="13965">the following:</st></span><a id="_idTextAnchor272"/></p>
			<p><img src="image/1655.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.727em;height:1.758em;width:10.440em"/><st c="13979"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="14007">Eq. </st><st c="14011">22</st></p>
			<p><st c="14013">From Eq. </st><st c="14023">22, we can then write down the log-likelihood of </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="14072"/><st c="14073"> exponentially distributed independent observations </st><span class="No-Break"><st c="14125">as follows:</st></span><a id="_idTextAnchor273"/></p>
			<p><img src="image/1657.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.999em;height:2.423em;width:13.793em"/><st c="14136"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="14161">Eq. </st><st c="14165">23</st></p>
			<p><st c="14167">From Eq. </st><st c="14177">18 to Eq. </st><st c="14187">23, we have gone from specifying what shape of random variation we think we will see in each observation through to deriving the log-likelihood in Eq. </st><st c="14338">23. </st><st c="14342">We have done this by linking the parameters of the distribution, in this case, its mean </st><img src="image/826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.490em"/><st c="14430"/><st c="14431">, to our model. </st><st c="14447">This is the general approach we take when building probabilistic models. </st><st c="14520">This approach can be summarized </st><span class="No-Break"><st c="14552">as follows:</st></span></p>
			<ol>
				<li><st c="14563">Specify the mathematical form of the distribution of the random component in </st><span class="No-Break"><st c="14641">the data.</st></span></li>
				<li><st c="14650">Specify a predictive model from which we calculate the parameters of the distribution of the </st><span class="No-Break"><st c="14744">random component.</st></span></li>
				<li><st c="14761">Calculate the likelihood of the data in terms of the distribution parameters and hence in terms of the </st><span class="No-Break"><st c="14865">predictive model.</st></span></li>
			</ol>
			<p><st c="14882">Later on in</st><a id="_idIndexMarker477"/><st c="14894"> this chapter, we will meet other ways of estimating the model parameters that make use of the likelihood but do not use maximum likelihood estimation. </st><st c="15046">However, even for these alternative methods of parameter estimation, we will still follow the three broad steps </st><span class="No-Break"><st c="15158">outlined above.</st></span></p>
			<p><st c="15173">At first sight, the process we went through to derive the log-likelihood in Eq. </st><st c="15254">23 looks very different to the process we used to derive the log-likelihood in Eq. </st><st c="15337">10 for independent observations with Gaussian additive noise. </st><st c="15399">Actually, it isn’t. </st><st c="15419">We’ll show this by re-deriving the log-likelihood in Eq. </st><st c="15476">10 for independent observations with Gaussian additive noise but using the steps </st><span class="No-Break"><st c="15557">outlined above.</st></span></p>
			<p><strong class="bold"><st c="15572">Step 1</st></strong><st c="15579">: We have observations </st><img src="image/1521.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.593em"/><st c="15603"/><st c="15604"> that are continuous, and we think their random variation will cause them to follow a Gaussian (normal) distribution. </st><st c="15722">So we will </st><span class="No-Break"><st c="15733">write this:</st></span></p>
			<p><img src="image/1660.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mtext&gt;Normal&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.361em;height:1.151em;width:7.563em"/><st c="15744"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="15763">Eq. </st><st c="15767">24</st></p>
			<p><st c="15769">Here, we have been explicit that the mean of each observation can be different, while we consider the standard deviation of the random variation to be the same for </st><span class="No-Break"><st c="15934">each observation.</st></span></p>
			<p><strong class="bold"><st c="15951">Step 2</st></strong><st c="15958">: We specify a mathematical form for a predictive model </st><img src="image/1661.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.173em"/><st c="16015"/><st c="16016">, which we will use as a model of the mean parameter </st><img src="image/1662.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.662em"/><st c="16069"/><st c="16070">. That is, we will put </st><img src="image/1663.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:5.077em"/><st c="16093"/><st c="16094">, and so we </st><span class="No-Break"><st c="16106">have this:</st></span></p>
			<p><img src="image/1664.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mtext&gt;Normal&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.409em;height:1.403em;width:10.538em"/><st c="16116"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="16145">Eq. </st><st c="16149">25</st></p>
			<p><st c="16151">We have not specified the precise details of the predictive model at this stage. </st><st c="16233">That’s because we don’t need to yet. </st><st c="16270">You are free to choose. </st><st c="16294">You could use a simple linear model for </st><img src="image/1661.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.168em"/><st c="16334"/><st c="16335">, or you could use a neural network if you felt that was justified. </st><st c="16403">You can use your favorite machine learning model to model the relationship between the features </st><img src="image/1666.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.737em"/><st c="16499"/><st c="16503"> and the expectation </st><img src="image/1667.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.001em;width:1.907em"/><st c="16523"/><st c="16524">, as long as it is a suitably </st><span class="No-Break"><st c="16554">appropriate model.</st></span></p>
			<p><strong class="bold"><st c="16572">Step 3</st></strong><st c="16579">: The log </st><a id="_idIndexMarker478"/><st c="16590">of the probability density of a Gaussian random variable is, in terms of </st><img src="image/1668.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.716em"/><st c="16663"/><st c="16664"> and </st><img src="image/1669.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.898em"/><st c="16669"/><st c="16672">, </st><span class="No-Break"><st c="16674">as follow</st><a id="_idTextAnchor274"/><st c="16683">s:</st></span></p>
			<p><img src="image/1670.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.454em;height:1.395em;width:16.953em"/><st c="16686"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="16728">Eq. </st><st c="16732">26</st></p>
			<p><st c="16734">Using Eq. </st><st c="16745">26 and plugging in our model </st><img src="image/1537.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.935em;width:0.785em"/><st c="16774"/><st c="16775"> for </st><img src="image/1662.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.662em"/><st c="16780"/><st c="16781">, we get the log-likelihood of </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="16812"/><st c="16813"> Gaussian distributed </st><span class="No-Break"><st c="16835">independent observations:</st></span></p>
			<p><img src="image/1674.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.709em;height:2.024em;width:17.179em"/><st c="16860"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="16900">Eq. </st><st c="16904">27</st></p>
			<p><st c="16906">This is the same as </st><span class="No-Break"><st c="16927">Eq. </st><st c="16931">10.</st></span></p>
			<h3><st c="16934">Maximum likelihood for non-linear models</st></h3>
			<p><st c="16975">It is worth noting</st><a id="_idIndexMarker479"/><st c="16994"> that for both of the preceding examples, our predictive model was directly a model of the expectation value of the observations. </st><st c="17124">That is, we equated, </st><img src="image/1675.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:11.649em"/><st c="17145"/><st c="17146">. This doesn’t always have to be the case. </st><st c="17189">The wording of step 2 was very deliberate – </st><em class="italic"><st c="17233">“Specify a predictive model from which we calculate the parameters of the distribution of the random component.”</st></em><st c="17345"> Imagine we have a predictive model </st><img src="image/1676.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:4.287em"/><st c="17381"/><st c="17382">. We can apply transformations to the output of our predictive model </st><img src="image/1677.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:4.486em"/><st c="17451"/><st c="17452"> to calculate the expectation value of the observation variable </st><img src="image/769.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.453em"/><st c="17516"/><st c="17526">. In this case, we would equate </st><span class="No-Break"><st c="17558">the following:</st></span></p>
			<p><img src="image/1679.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.376em;height:1.333em;width:9.365em"/><st c="17572"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="17593">Eq. </st><st c="17597">28</st></p>
			<p><st c="17599">The function </st><img src="image/1680.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.419em"/><st c="17613"/><st c="17614"> is called a </st><strong class="bold"><st c="17627">link function</st></strong><st c="17640">. It links</st><a id="_idIndexMarker480"/><st c="17650"> the expectation of the observations to the predictive model. </st><st c="17712">It is traditional to specify the transformation as the inverse of a function </st><img src="image/1681.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.416em"/><st c="17789"/><st c="17790">. Now, you may ask, why not just include the final transformation </st><img src="image/1682.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.960em;width:1.124em"/><st c="17856"/><st c="17857"> in the definition of our predictive model </st><img src="image/1683.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.509em"/><st c="17900"/><st c="17901">? This is because the terminology of “link functions” comes from classical statistics, where our predictive model </st><img src="image/126.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.281em"/><st c="18015"/><st c="18069"> would typically be linear. </st><st c="18096">The downstream application of a transformation </st><img src="image/1685.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.960em;width:1.105em"/><st c="18143"/><st c="18144"> was then a way of modeling non-linear relationships in </st><span class="No-Break"><st c="18200">classical statistics.</st></span></p>
			<p><st c="18221">The best </st><a id="_idIndexMarker481"/><st c="18231">way to understand how link functions are used is to see one used in practice. </st><st c="18309">We’ll model shoppers’ decisions about whether to buy a product or not. </st><st c="18380">We have </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.710em"/><st c="18388"/><st c="18389"> shoppers in our dataset and we know whether they bought the product in question or not. </st><st c="18478">We’ll represent the outcome of the </st><img src="image/909.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.760em;width:0.809em"/><st c="18513"/><st c="18525"> shopper’s decision by the binary outcome variable </st><img src="image/1688.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.744em"/><st c="18575"/><st c="18576">. So, </st><img src="image/1689.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:2.838em"/><st c="18582"/><st c="18583"> if the </st><img src="image/1690.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.760em;width:0.881em"/><st c="18591"/><st c="18595"> shopper didn’t buy the product, and </st><img src="image/1691.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:2.722em"/><st c="18631"/><st c="18632"> if they did. </st><st c="18646">The outcome </st><img src="image/1692.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.692em"/><st c="18658"/><st c="18659"> can be affected by several factors, such as the price of the product at the time, or the age demographic the shopper is in. </st><st c="18784">We can put all the relevant factors into our feature </st><span class="No-Break"><st c="18837">vector </st></span><span class="No-Break"><img src="image/1693.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.682em"/><st c="18844"/></span><span class="No-Break"><st c="18848">.</st></span></p>
			<p><st c="18849">Now let’s follow our 3-step recipe to derive </st><span class="No-Break"><st c="18895">the log-likelihood.</st></span></p>
			<p><strong class="bold"><st c="18914">Step 1</st></strong><st c="18921">: The outcome variable </st><img src="image/1694.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.675em"/><st c="18945"/><st c="18946"> is a random variable. </st><st c="18969">Why is this so? </st><st c="18985">Well, even if the price and other factors in </st><img src="image/1695.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.672em"/><st c="19030"/><st c="19034"> are such that you’d think a particular shopper was ideally suited to the product, they may not buy it. </st><st c="19137">The expectation of this random variable, </st><img src="image/1696.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.390em;height:1.288em;width:3.311em"/><st c="19178"/><st c="19179">, is the probability </st><img src="image/1697.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.858em;width:0.627em"/><st c="19200"/><st c="19201"> that the </st><img src="image/909.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.760em;width:0.809em"/><st c="19211"/><st c="19223"> shopper will buy the product. </st><st c="19253">The variable </st><img src="image/1699.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.678em"/><st c="19266"/><st c="19267"> is an example of a Bernoulli random variable that we introduced in </st><a href="B19496_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic"><st c="19335">Chapter 2</st></em></span></a><st c="19344">. Modeling the shopper choice as a Bernoulli random variable is our choice for the mathematical form of the randomness in the </st><span class="No-Break"><st c="19470">observed data.</st></span></p>
			<p><strong class="bold"><st c="19484">Step 2</st></strong><st c="19491">: Since </st><img src="image/1700.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.685em"/><st c="19500"/><st c="19501"> is a discrete random variable, unlike our previous two examples, we write down the probability distribution for </st><img src="image/1701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.726em"/><st c="19614"/><st c="19615"> instead of a probability density. </st><st c="19650">We need to express this probability distribution in terms of </st><img src="image/1697.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.858em;width:0.627em"/><st c="19711"/><st c="19712">. For a Bernoulli distribution, this is straightforward to do, and we </st><span class="No-Break"><st c="19782">get t</st><a id="_idTextAnchor275"/><st c="19787">his:</st></span></p>
			<p><img src="image/1703.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;P&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.390em;height:1.288em;width:9.328em"/><st c="19792"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="19815">Eq. </st><st c="19819">29</st></p>
			<p><st c="19821">Plugging in values of </st><img src="image/1704.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:2.703em"/><st c="19844"/><st c="19845"> and </st><img src="image/1691.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:2.703em"/><st c="19850"/><st c="19851"> into Eq. </st><st c="19861">29 should convince you that we recover the correct probabilities. </st><st c="19927">On the log scale, we have </st><span class="No-Break"><st c="19953">the following:</st></span></p>
			<p><img src="image/1706.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;P&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.440em;height:1.388em;width:16.726em"/><st c="19967"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="20012">Eq. </st><st c="20016">30</st></p>
			<p><st c="20018">The probability </st><img src="image/1707.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.858em;width:0.624em"/><st c="20035"/><st c="20036"> depends upon the feature vector </st><img src="image/1708.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.678em"/><st c="20069"/><st c="20073">, and it is this relationship that we will build our predictive model for. </st><st c="20148">We’ll consider the simplest possible form for our predictive </st><a id="_idIndexMarker482"/><st c="20209">model, namely a linear one. </st><st c="20237">Without loss of generality, we can write this linear model in the form </st><img src="image/1709.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.075em;width:1.424em"/><st c="20308"/><st c="20309"> , where we have used our usual trick of including a constant by having a feature </st><img src="image/1710.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:2.961em"/><st c="20390"/><st c="20391"> for all shoppers, with a corresponding parameter </st><img src="image/1711.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.737em"/><st c="20441"/><st c="20442">. However, we have a problem! </st><st c="20472">Our linear model can potentially take any value between </st><img src="image/1712.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.390em;width:1.338em"/><st c="20528"/><st c="20529"> and </st><img src="image/1713.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.486em;width:1.338em"/><st c="20534"/><st c="20535">, but a probability can only be between 0 and 1. </st><st c="20584">So, we need a transformation that will map the whole real line </st><img src="image/1714.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.117em;height:0.742em;width:4.220em"/><st c="20647"/><st c="20648"> to the interval [0,1]. </st><st c="20672">To do this, we </st><a id="_idIndexMarker483"/><st c="20687">use a simple sigmoid transformation called the </st><span class="No-Break"><strong class="bold"><st c="20734">logistic fu</st><a id="_idTextAnchor276"/><st c="20745">nction</st></strong></span><span class="No-Break"><st c="20752">:</st></span></p>
			<p><img src="image/1715.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msubsup&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msubsup&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msubsup&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msubsup&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.897em;height:2.321em;width:18.070em"/><st c="20754"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="20798">Eq. </st><st c="20802">31</st></p>
			<p><st c="20804">The quantity </st><img src="image/1716.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.075em;width:1.422em"/><st c="20818"/><st c="20819"> is called </st><a id="_idIndexMarker484"/><st c="20830">the </st><strong class="bold"><st c="20834">linear predictor</st></strong><st c="20850"> because it is the linear part of the prediction model. </st><st c="20906">It is often denoted by the symbol </st><img src="image/1717.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;η&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.495em"/><st c="20940"/><st c="20941">. The plot in </st><span class="No-Break"><em class="italic"><st c="20955">Figure 5</st></em></span><em class="italic"><st c="20963">.1</st></em><st c="20965"> shows how the logistic function transformation function in Eq. </st><st c="21029">31 varies with the linear </st><span class="No-Break"><st c="21055">pred</st><a id="_idTextAnchor277"/><st c="21059">ictor </st></span><span class="No-Break"><img src="image/1482.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;η&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.508em"/><st c="21066"/></span><span class="No-Break"><st c="21067">.</st></span></p>
			<div>
				<div id="_idContainer1781" class="IMG---Figure">
					<img src="image/B19496_05_1.jpg" alt="Figure﻿ 5.1: The logistic function"/><st c="21068"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21091">Figure 5.1: The logistic function</st></p>
			<p><st c="21124">The plot in </st><span class="No-Break"><em class="italic"><st c="21137">Figure 5</st></em></span><em class="italic"><st c="21145">.1</st></em><st c="21147"> is a plot of the function </st><img src="image/1719.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;η&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.307em;height:1.010em;width:2.324em"/><st c="21174"/><st c="21180">, with </st><img src="image/1719.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;η&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.307em;height:1.010em;width:2.324em"/><st c="21187"/><st c="21193"> given by </st><span class="No-Break"><st c="21202">the fol</st><a id="_idTextAnchor278"/><st c="21209">lowing:</st></span></p>
			<p><img src="image/1721.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;η&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;1&lt;/mtext&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;η&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.698em;height:1.662em;width:7.549em"/><st c="21217"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21237">Eq. </st><st c="21241">32</st></p>
			<p><st c="21243">This</st><a id="_idIndexMarker485"/><st c="21248"> function is the inverse of our link function, so what does the link function </st><img src="image/1722.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.022em;width:1.597em"/><st c="21326"/><st c="21327"> look like? </st><st c="21339">If we invert Eq. </st><st c="21356">32, we </st><span class="No-Break"><st c="21363">get this:</st></span></p>
			<p><img src="image/1723.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.701em;height:1.831em;width:6.911em"/><st c="21372"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21389">Eq. </st><st c="21393">33</st></p>
			<p><st c="21395">This is our link function. </st><st c="21423">It is called</st><a id="_idIndexMarker486"/><st c="21435"> the </st><span class="No-Break"><strong class="bold"><st c="21440">logit function</st></strong></span><span class="No-Break"><st c="21454">.</st></span></p>
			<p><strong class="bold"><st c="21455">Step 3</st></strong><st c="21462">: Now that we have our predictive model, we can calculate the log-likelihood. </st><st c="21541">For each of our </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="21557"/><st c="21558"> shoppers, we have the observation </st><img src="image/1725.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.683em"/><st c="21593"/><st c="21594"> and the feature vector </st><img src="image/1693.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.682em"/><st c="21618"/><st c="21622">. Putting together Eq. </st><st c="21645">30 and Eq. </st><st c="21656">31, we </st><span class="No-Break"><st c="21663">get this:</st></span></p>
			<p><img src="image/1727.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:munderover&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∑&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munderover&gt;&lt;mml:mrow&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;exp&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mtext&gt;exp&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mtext&gt;exp&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.943em;height:2.559em;width:23.689em"/><st c="21672"/></p>
			<p><img src="image/1728.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;msubsup&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msubsup&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msubsup&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.767em;height:2.191em;width:13.054em"/><st c="21674"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21705">Eq. </st><st c="21709">34</st></p>
			<p><st c="21711">The log-likelihood in Eq. </st><st c="21738">34 can then be maximized with respect to the model parameters </st><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.513em"/><st c="21800"/><st c="21801"> to give the maximum likelihood estimate for </st><img src="image/1730.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.527em"/><st c="21846"/><st c="21847">. From this example, we can see how we can use maximum likelihood to train a model that includes a </st><span class="No-Break"><st c="21946">link function.</st></span></p>
			<p><st c="21960">That is enough for now about likelihood, so let’s finish this section by summarizing what we </st><span class="No-Break"><st c="22054">have learned.</st></span></p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor279"/><st c="22067">What we have learned</st></h2>
			<p><st c="22088">In this section, we have learned </st><span class="No-Break"><st c="22122">the following:</st></span></p>
			<ul>
				<li><st c="22136">How the likelihood measures the probability of a dataset given the parameters of a predictive model and the parameters of a </st><span class="No-Break"><st c="22261">random process</st></span></li>
				<li><st c="22275">How maximum likelihood provides us with a way to use the likelihood to estimate the model parameters </st><span class="No-Break"><st c="22377">from data</st></span></li>
				<li><st c="22386">How maximum likelihood estimation of a predictive model’s parameters corresponds to least squares estimation of the parameters, when we have data that contains i.i.d. </st><st c="22554">Gaussian </st><span class="No-Break"><st c="22563">additive noise</st></span></li>
				<li><st c="22577">How to formulate a probabilistic model for any modeling problem using a short series </st><span class="No-Break"><st c="22663">of steps</st></span></li>
			</ul>
			<p><st c="22671">Having learned about likelihood as the probability of the data given the model parameters, in the next section, we will move on to learning how to formulate the probability of the model parameters given </st><span class="No-Break"><st c="22875">the data.</st></span></p>
			<h1 id="_idParaDest-152"><a id="_idTextAnchor280"/><st c="22884">Bayes’ theorem</st></h1>
			<p><st c="22899">When </st><a id="_idIndexMarker487"/><st c="22905">we learned about maximum likelihood for estimating the parameters of a model, it felt like an intuitively sensible thing to do. </st><st c="23033">Who can argue with the idea of choosing the model parameters </st><img src="image/1561.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.527em"/><st c="23094"/><st c="23095"> so that we have the highest possible probability of obtaining the data we have actually observed? </st><st c="23194">But we didn’t really derive maximum likelihood in any formal way. </st><st c="23260">Yes, choosing parameters by maximizing </st><img src="image/1732.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.062em"/><st c="23299"/><st c="23314">) seems reasonable, but aren’t we really interested in the probability of the parameters given the data, that is </st><img src="image/1733.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.169em;height:0.880em;width:3.711em"/><st c="23427"/><st c="23436">| Data)? </st><st c="23445">Working with the likelihood </st><img src="image/1734.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.456em"/><st c="23473"/><st c="23489"> seems close to what we want, but not quite there. </st><st c="23539">If only there was a way we could calculate </st><img src="image/1735.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Data)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.509em"/><st c="23582"/><st c="23599"> from </st><img src="image/1734.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.459em"/><st c="23604"/><st c="23620">. There is. </st><st c="23632">Enter </st><span class="No-Break"><strong class="bold"><st c="23638">Bayes’ theorem</st></strong></span><span class="No-Break"><st c="23652">.</st></span></p>
			<p><st c="23653">This section will be relatively short as we will only introduce Bayes’ theorem here. </st><st c="23739">In the next two sections, we will explain how Bayes’ theorem is used </st><span class="No-Break"><st c="23808">in practice.</st></span></p>
			<h2 id="_idParaDest-153"><a id="_idTextAnchor281"/><st c="23820">Conditional probability and Bayes’ theorem</st></h2>
			<p><st c="23863">Bayes’ theorem, named</st><a id="_idIndexMarker488"/><st c="23885"> after the Reverend Thomas Bayes, is about conditional probabilities. </st><st c="23955">The probability </st><img src="image/1737.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.669em"/><st c="23971"/><st c="23987"> is a conditional probability. </st><st c="24017">It is the probability of the data </st><strong class="bold"><st c="24051">given</st></strong><st c="24056"> the model, or in other words the probability of the data conditional on having that particular model form with that particular set of model </st><span class="No-Break"><st c="24197">parameter values.</st></span></p>
			<p><st c="24214">Bayes’ theorem says that if we have two events </st><img src="image/1738.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.663em;width:0.663em"/><st c="24262"/><st c="24263"> and </st><img src="image/1739.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.578em"/><st c="24268"/><st c="24269"> (things whose probabilities we are interested in knowing), then the conditional probabilities </st><img src="image/1740.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.123em;height:0.805em;width:2.751em"/><st c="24364"/><st c="24371"> and </st><img src="image/1741.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced close=&quot;|&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.118em;height:0.850em;width:2.751em"/><st c="24375"/><st c="24376"> are related via </st><span class="No-Break"><st c="24393">th</st><a id="_idTextAnchor282"/><st c="24395">is formula:</st></span></p>
			<p><img src="image/1742.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.515em;height:1.919em;width:8.370em"/><st c="24407"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="24433">Eq. </st><st c="24437">35</st></p>
			<p><st c="24439">You may wonder where Eq. </st><st c="24465">35 comes from. </st><st c="24480">The form in Eq. </st><st c="24496">35 hides its simplicity. </st><st c="24521">Consider, instead the joint probability </st><img src="image/1743.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.142em;height:0.865em;width:2.842em"/><st c="24561"/><st c="24562">. Now, from the rules of conditional probability, </st><img src="image/1744.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.250em;height:1.058em;width:9.044em"/><st c="24612"/><st c="24632">. In words, the probability of </st><img src="image/1738.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.663em;width:0.681em"/><st c="24663"/><st c="24664"> and </st><img src="image/1746.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.595em"/><st c="24669"/><st c="24670"> happening together is the probability of </st><img src="image/1738.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.663em;width:0.681em"/><st c="24712"/><st c="24713"> happening given I know </st><img src="image/1739.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.578em"/><st c="24737"/><st c="24738"> has happened, multiplied by the probability that </st><img src="image/1739.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.578em"/><st c="24788"/><st c="24789"> has indeed actually happened. </st><st c="24820">But here’s the neat trick. </st><st c="24847">The joint probability </st><img src="image/1750.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.197em;height:0.969em;width:7.079em"/><st c="24869"/><st c="24886"> is just the probability of both </st><img src="image/1751.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.663em;width:0.647em"/><st c="24918"/><st c="24919"> and </st><img src="image/1752.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.563em"/><st c="24924"/><st c="24925"> happening together, or both being true, so the ordering doesn’t matter. </st><st c="24998">This means we can also write </st><span class="_-----MathTools-_Math_Variable"><st c="25027">P</st></span><span class="_-----MathTools-_Math_Base"><st c="25028">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="25029">A</st></span><span class="_-----MathTools-_Math_Operator"><st c="25030">,</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><st c="25031">B</st></span><span class="_-----MathTools-_Math_Variable"><st c="25032">)</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><st c="25033">=</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><st c="25034">P</st></span><span class="_-----MathTools-_Math_Base"><st c="25035">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="25036">B</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><st c="25037">|</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><st c="25038">A</st></span><span class="_-----MathTools-_Math_Variable"><st c="25039">)</st></span><span class="_-----MathTools-_Math_Variable"><st c="25040">P</st></span><span class="_-----MathTools-_Math_Base"><st c="25041">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="25042">A</st></span><span class="_-----MathTools-_Math_Base"><st c="25043">)</st></span><st c="25044">. Again, in words this make sense – it is the probability of </st><img src="image/1753.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.576em"/><st c="25105"/><st c="25106"> happening given I know </st><img src="image/1754.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.663em;width:0.660em"/><st c="25130"/><st c="25131"> has happened, multiplied by the probability that </st><img src="image/1754.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.663em;width:0.661em"/><st c="25181"/><st c="25182"> has indeed actually happened. </st><st c="25213">If we now equate these two expressions for </st><img src="image/1743.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.142em;height:0.865em;width:2.841em"/><st c="25256"/><st c="25257"> w</st><a id="_idTextAnchor283"/><st c="25259">e </st><span class="No-Break"><st c="25261">get this:</st></span></p>
			<p><img src="image/1757.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.250em;height:1.015em;width:15.327em"/><st c="25270"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="25303">Eq. </st><st c="25307">36</st></p>
			<p><st c="25309">If we re-arrange Eq. </st><st c="25331">36, we get Bayes’ theorem in Eq. </st><st c="25364">35. </st><st c="25368">In fact, the expression in Eq. </st><st c="25399">36 is how I always remember Bayes’ theorem when doing Bayesian modeling. </st><st c="25472">If I have to derive or understand what looks like a complicated Bayesian formula, I just write out the joint probability of whatever events (</st><span class="_-----MathTools-_Math_Variable"><st c="25613">A</st></span><span class="_-----MathTools-_Math_Operator"><st c="25615">,</st></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><st c="25616">B</st></span><span class="_-----MathTools-_Math_Operator"><st c="25617">,</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><st c="25618">…</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><st c="25619">.</st></span><span class="_-----MathTools-_Math_Base"><st c="25620">)</st></span><st c="25622"> I’m interested in (in the multiple ways involving conditional probabilities), and then I </st><span class="No-Break"><st c="25712">re-arrange it.</st></span></p>
			<p><st c="25726">So, how does Bayes’ theorem help us with working out </st><img src="image/1758.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Data)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.366em"/><st c="25780"/><st c="25797">? Well, let’s put </st><img src="image/1759.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mtext&gt;Data&lt;/mml:mtext&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.675em;width:4.069em"/><st c="25815"/><st c="25816"> and </st><img src="image/1760.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mtext&gt;Model&lt;/mml:mtext&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:4.698em"/><st c="25821"/><st c="25831">, and plug them into Bayes’ theorem in Eq. </st><st c="25874">35. </st><st c="25878">W</st><a id="_idTextAnchor284"/><st c="25879">e </st><span class="No-Break"><st c="25881">get this:</st></span></p>
			<p><img src="image/1761.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;)&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model)&lt;/mtext&gt;&lt;mtext&gt;×&lt;/mtext&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model)&lt;/mtext&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.657em;height:1.965em;width:17.952em"/><st c="25890"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="25949">Eq. </st><st c="25953">37</st></p>
			<p><st c="25955">Excellent! </st><st c="25967">We have a means of </st><span class="No-Break"><st c="25986">calculating </st></span><span class="No-Break"><img src="image/1762.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Data)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.459em"/><st c="25998"/></span><span class="No-Break"><st c="26015">.</st></span></p>
			<p><st c="26016">We have </st><a id="_idIndexMarker489"/><st c="26025">written Bayes’ theorem in terms of probabilities. </st><st c="26075">However, for many of our discussions on likelihood, we have been talking about probability densities. </st><st c="26177">As you might expect, we can also apply Bayes’ theorem to probability densities by replacing the probabilities in Eq. </st><st c="26294">37 with the corresponding densities. </st><st c="26331">From now on, when discussing Bayes’ theorem, we will for brevity refer to probabilities even when we mean probability densities. </st><st c="26460">It will be clear from the context whether we are dealing with a probability or a </st><span class="No-Break"><st c="26541">probability density.</st></span></p>
			<p><st c="26561">Finally, we should emphasize that when we refer to a model, for example, in Eq. </st><st c="26642">37, we mean both the parameters </st><img src="image/1561.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.519em"/><st c="26674"/><st c="26675"> for the predictive model, but also the parameters that control the random component of the data, such as the noise variance </st><img src="image/1764.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.748em;width:0.840em"/><st c="26800"/><st c="26801"> in our model in Eq. </st><st c="26822">1. </st><st c="26825">We will use the symbol </st><img src="image/1765.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:0.560em"/><st c="26848"/><st c="26849"> in general to represent the combined parameters from the predictive model and the random component, so </st><img src="image/1766.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.108em;height:0.819em;width:1.376em"/><st c="26953"/><span class="_-----MathTools-_Math_Space"><img src="image/1767.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.031em;width:2.501em"/><st c="26954"/></span><st c="26955"> for our model in Eq. </st><st c="26977">1. </st><st c="26980">We will use the word “model” and the symbol </st><img src="image/1765.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:0.558em"/><st c="27024"/> <span class="No-Break"><st c="27025">interchangeably.</st></span></p>
			<h2 id="_idParaDest-154"><a id="_idTextAnchor285"/><st c="27041">Priors</st></h2>
			<p><st c="27048">Let’s</st><a id="_idIndexMarker490"/><st c="27054"> unpack Eq. </st><st c="27066">37 in a bit more detail. </st><st c="27091">Firstly, what is the quantity </st><img src="image/1769.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mtext&gt;(Model)&lt;/mml:mtext&gt;&lt;/mml:math&gt;" style="vertical-align:-0.170em;height:0.881em;width:3.831em"/><st c="27121"/><st c="27131">? At face value it is the probability of the model. </st><st c="27183">But conditional on what? </st><st c="27208">Well, nothing. </st><st c="27223">Not on the data. </st><st c="27240">So, it is just the probability of the model before, or prior, to us receiving the data. </st><st c="27328">For this reason, it is called a prior probability, or simply </st><span class="No-Break"><st c="27389">a </st></span><span class="No-Break"><strong class="bold"><st c="27391">prior</st></strong></span><span class="No-Break"><st c="27396">.</st></span></p>
			<p><st c="27397">The symbol </st><img src="image/1770.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:0.584em"/><st c="27409"/><st c="27410"> summarizes the model, so </st><img src="image/1771.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mtext&gt;(Model)&lt;/mml:mtext&gt;&lt;/mml:math&gt;" style="vertical-align:-0.170em;height:0.881em;width:3.963em"/><st c="27436"/><st c="27446"> is </st><img src="image/1772.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.160em;height:0.912em;width:1.826em"/><st c="27449"/><st c="27450"> and is the probability we attach to the parameters </st><img src="image/1770.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:0.572em"/><st c="27502"/><st c="27503"> before we have seen any data. </st><st c="27534">It therefore encapsulates our pre-defined beliefs about what values </st><img src="image/1765.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:0.554em"/><st c="27602"/><st c="27603"> should take. </st><st c="27617">So, in most cases, </st><img src="image/1775.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.120em;height:0.831em;width:1.702em"/><st c="27636"/><st c="27637"> is subjective – the probability that you might attach to a particular value of </st><img src="image/1765.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:0.558em"/><st c="27717"/><st c="27718"> could be different from the probability that I attach to that same value </st><span class="No-Break"><st c="27792">of </st></span><span class="No-Break"><img src="image/1765.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:0.558em"/><st c="27795"/></span><span class="No-Break"><st c="27796">.</st></span></p>
			<p><st c="27797">This subjective element of the prior is the reason why some people are not keen on Bayesian methods. </st><st c="27899">Consequently, an alternative and often used approach is to use an </st><strong class="bold"><st c="27965">uninformative prior</st></strong><st c="27984">; that is a</st><a id="_idIndexMarker491"/><st c="27996"> prior that is not based on any subjective belief, but only on incontrovertible facts we know about </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.489em"/><st c="28096"/><st c="28097">, such as the upper and lower bounds for parameter values or based on the geometry of the space in which the </st><span class="No-Break"><st c="28206">parameters lie.</st></span></p>
			<p><st c="28221">Whether we use </st><a id="_idIndexMarker492"/><st c="28237">a subjective prior or uninformative prior, in both cases we are constructing the prior from information. </st><st c="28342">In the case of an uninformative prior, that information is the minimal properties that the parameters must satisfy, while in the case where I have constructed the prior from my own subjective beliefs, I am constructing the prior based upon information coming from my expert judgment, possibly based on years of domain experience. </st><st c="28672">So, another way to think about the prior </st><img src="image/1779.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.160em;height:0.912em;width:2.552em"/><st c="28713"/><st c="28714"> is that it is the distribution of </st><img src="image/1780.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.108em;height:0.819em;width:1.286em"/><st c="28749"/><st c="28750"> based upon whatever information we have available to us before we have received the data for the current analysis. </st><st c="28866">The prior information that we have available to us could even be from a </st><span class="No-Break"><st c="28938">previous analysis.</st></span></p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor286"/><st c="28956">The posterior</st></h2>
			<p><st c="28970">We dealt </st><a id="_idIndexMarker493"/><st c="28980">with and explained the factor </st><img src="image/1781.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.162em;height:0.923em;width:1.770em"/><st c="29010"/><st c="29011"> in the Eq. </st><st c="29023">37 form of Bayes’ theorem. </st><st c="29050">What about the probability </st><img src="image/1782.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mtext&gt;Data)&lt;/mml:mtext&gt;&lt;/mml:math&gt;" style="vertical-align:-0.202em;height:0.911em;width:3.156em"/><st c="29077"/><st c="29085"> in the denominator of Eq. </st><st c="29111">37? </st><st c="29115">It looks like a prior. </st><st c="29138">The more appropriate way to interpret </st><img src="image/1783.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mtext&gt;(Data)&lt;/mml:mtext&gt;&lt;/mml:math&gt;" style="vertical-align:-0.170em;height:0.879em;width:3.216em"/><st c="29176"/><st c="29185"> is as a normalizing factor for the probability </st><img src="image/1784.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Data)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.615em"/><st c="29232"/><st c="29249">. From the rules of probability, we </st><span class="No-Break"><st c="29285">have this:</st></span></p>
			<p><img src="image/1785.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data)&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mtext&gt;Data,&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.108em;width:19.098em"/><st c="29295"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29346">Eq. </st><st c="29350">38</st></p>
			<p><st c="29352">This means we can write Bayes’ theorem in Eq. </st><st c="29399">37 </st><span class="No-Break"><st c="29402">as </st></span><span class="No-Break"><st c="29405">follows:</st></span></p>
			<p><img src="image/1786.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;|&quot;&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mfenced&gt;&lt;mtext&gt;Data)&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.832em;height:2.192em;width:12.079em"/><st c="29413"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29463">Eq. </st><st c="29467">39</st></p>
			<p><st c="29469">The denominator is just making sure the probabilities over all possible values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="29552"/><st c="29553"> add up </st><span class="No-Break"><st c="29561">to 1.</st></span></p>
			<p><st c="29566">Let’s return to the numerator of Eq. </st><st c="29604">37. </st><st c="29608">The probability </st><img src="image/1788.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Data&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Model)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:6.392em"/><st c="29624"/><st c="29640"> is the likelihood. </st><st c="29659">This means Bayes’ theorem can be written </st><span class="No-Break"><st c="29700">as follows:</st></span></p>
			<p><img src="image/1789.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Data)&lt;/mtext&gt;&lt;mtext&gt;∝&lt;/mtext&gt;&lt;mtext&gt;Likelihood&lt;/mtext&gt;&lt;mtext&gt;×&lt;/mtext&gt;&lt;mtext&gt;Prior&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:15.047em"/><st c="29711"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29750">Eq. </st><st c="29754">40</st></p>
			<p><st c="29756">We can just re-arrange tha</st><a id="_idTextAnchor287"/><st c="29783">t to </st><span class="No-Break"><st c="29789">write this:</st></span></p>
			<p><img src="image/1790.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mtext&gt;(Model&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mtext&gt;Data)&lt;/mtext&gt;&lt;mtext&gt;∝&lt;/mtext&gt;&lt;mtext&gt;Prior&lt;/mtext&gt;&lt;mtext&gt;×&lt;/mtext&gt;&lt;mtext&gt;Likelihood&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.250em;height:1.000em;width:15.047em"/><st c="29800"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29839">Eq. </st><st c="29843">41</st></p>
			<p><st c="29845">How </st><a id="_idIndexMarker494"/><st c="29850">does Eq. </st><st c="29859">41 help us? </st><st c="29871">It tells us that the probability of the model </st><img src="image/1791.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.511em"/><st c="29917"/><st c="29918"> given the data is our prior probability multiplied by the likelihood (and appropriately normalized). </st><st c="30020">The likelihood has updated the distribution of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.473em"/><st c="30067"/><st c="30068"> from what we believed before we got the data – the prior </st><img src="image/1793.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.162em;height:0.923em;width:1.662em"/><st c="30126"/><st c="30127"> – to what we believe after we get the data – the distribution </st><img src="image/1794.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.314em"/><st c="30190"/><st c="30202">. Because of this, </st><img src="image/1795.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.313em"/><st c="30221"/><st c="30233"> is called the </st><strong class="bold"><st c="30247">posterior distribution</st></strong><st c="30269"> or </st><a id="_idIndexMarker495"/><st c="30273">simply the </st><strong class="bold"><st c="30284">posterior</st></strong><st c="30293">. In simple terms, the prior is what we think is the distribution of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.481em"/><st c="30362"/> <strong class="bold"><st c="30363">before</st></strong><st c="30369"> we get the data, while the posterior is what we think is the distribution of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.481em"/><st c="30447"/> <strong class="bold"><st c="30448">after</st></strong><st c="30453"> we get the data – hence the </st><span class="No-Break"><st c="30482">name posterior.</st></span></p>
			<p><st c="30497">We said this section would be short, so we’ll now recap what we </st><span class="No-Break"><st c="30562">have learned.</st></span></p>
			<h2 id="_idParaDest-156"><a id="_idTextAnchor288"/><st c="30575">What we have learned</st></h2>
			<p><st c="30596">In this section, we have learned about </st><span class="No-Break"><st c="30636">the following:</st></span></p>
			<ul>
				<li><st c="30650">Bayes’ theorem and how we can use it to calculate the probability distribution of the model parameters given </st><span class="No-Break"><st c="30760">the data</st></span></li>
				<li><st c="30768">Prior distributions and how they encode the beliefs we already have about model parameters before we have received any new data </st><span class="No-Break"><st c="30897">or information</st></span></li>
				<li><st c="30911">The posterior distribution and how it is calculated by multiplying the likelihood of the data and </st><span class="No-Break"><st c="31010">the prior</st></span></li>
				<li><st c="31019">How the posterior distribution represents our belief of the distribution of the model parameters after we have received the new data </st><span class="No-Break"><st c="31153">or information</st></span></li>
			</ul>
			<p><st c="31167">Having introduced Bayes’ theorem and the concepts of prior and posterior distributions, in the next section, we’re going to move onto how the posterior distribution is used in </st><span class="No-Break"><st c="31344">Bayesian modeling.</st></span></p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor289"/><st c="31362">Bayesian modeling</st></h1>
			<p><st c="31380">The </st><a id="_idIndexMarker496"/><st c="31385">posterior </st><img src="image/1798.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.217em"/><st c="31395"/><st c="31407"> encapsulates the philosophy of Bayesian modeling and changes how we view the model represented by </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="31505"/><st c="31506">. In Bayesian modeling, there is not a single “correct” underlying value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.473em"/><st c="31582"/><st c="31583">, for which we construct uncertain estimates. </st><st c="31629">Instead, different values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.473em"/><st c="31658"/><st c="31659"> have different probabilities given the available data or evidence. </st><img src="image/1791.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.515em"/><st c="31727"/><st c="31728"> is a random variable, and we update what we think is the distribution of that random variable using Bayes’ theorem and the additional data or information </st><span class="No-Break"><st c="31883">we receive.</st></span></p>
			<p><st c="31894">With that statement about the philosophical interpretation of the posterior made, we now move on to how we use the posterior in a calculational sense. </st><st c="32046">There are two potential ways in which we can use the </st><span class="No-Break"><st c="32099">posterior distribution:</st></span></p>
			<ul>
				<li><st c="32122">To evaluate expectation values. </st><st c="32155">Here, we are using the posterior as it is intended, as a distribution. </st><st c="32226">Here, the posterior is used to calculate predictions over lots of different</st><a id="_idIndexMarker497"/><st c="32301"> models. </st><st c="32310">This is called </st><em class="italic"><st c="32325">Bayesian </st></em><span class="No-Break"><em class="italic"><st c="32334">model averaging</st></em></span><span class="No-Break"><st c="32349">.</st></span></li>
				<li><st c="32350">To identify a suitable single value, or point estimate, of the parameter vector </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="32431"/><st c="32432"> that we can use as a single model to make predictions with. </st><st c="32493">The most obvious point value we can use is the value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.471em"/><st c="32549"/><st c="32550"> that is the most probable given the data. </st><st c="32593">We can identify this value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.472em"/><st c="32623"/><st c="32624"> by maximizing the posterior </st><img src="image/1806.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.204em"/><st c="32653"/><st c="32665"> with respect to </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.473em"/><st c="32681"/><st c="32682">. Since we are maximizing the </st><a id="_idIndexMarker498"/><st c="32712">posterior, this is known as the </st><strong class="bold"><st c="32744">maximum a posteriori</st></strong><st c="32764"> estimate, or </st><strong class="bold"><st c="32778">MAP</st></strong><st c="32781"> estimate for short. </st><st c="32802">The MAP estimate of </st><img src="image/1808.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.495em"/><st c="32822"/> <span class="No-Break"><st c="32823">satisfies this:</st></span></li>
			</ul>
			<p><img src="image/1809.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtable columnwidth=&quot;auto&quot; columnalign=&quot;center&quot; rowspacing=&quot;1.0000ex&quot; rowalign=&quot;baseline baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mtext&gt;argmax&lt;/mtext&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.679em;height:1.836em;width:10.542em"/><st c="32838"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="32865">Eq. </st><st c="32869">42</st></p>
			<p class="list-inset"><st c="32871">We will normally try and identify MAP estimates by solving the </st><span class="No-Break"><st c="32935">stationarity condition:</st></span></p>
			<p><img src="image/1810.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mfenced open=&quot;&quot; close=&quot;|&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.902em;height:2.214em;width:8.477em"/><st c="32958"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="32975">Eq. </st><st c="32979">43</st></p>
			<p><st c="32981">Bayesian model averaging and MAP estimation both have their advantages and disadvantages. </st><st c="33072">It is worth covering those advantages and disadvantages in detail, so we will do </st><span class="No-Break"><st c="33153">so next.</st></span></p>
			<h2 id="_idParaDest-158"><a id="_idTextAnchor290"/><st c="33161">Bayesian model averaging</st></h2>
			<p><st c="33186">Bayesian model averaging </st><a id="_idIndexMarker499"/><st c="33212">can be as simple as wanting to know what the typical value of the model parameters is given all the data or information available to us to date. </st><st c="33357">In this case, we would calculate the expectation </st><img src="image/1811.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.418em"/><st c="33406"/><st c="33418"> over the posterior distribution, so in other words, we </st><span class="No-Break"><st c="33473">calculate this:</st></span></p>
			<p><img src="image/1812.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.044em;width:11.932em"/><st c="33488"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="33520">Eq. </st><st c="33524">44</st></p>
			<p><st c="33526">We can also use Bayesian model averaging to calculate the posterior covariance of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.482em"/><st c="33609"/><st c="33610">. This would be calculated </st><span class="No-Break"><st c="33637">as follows:</st></span></p>
			<p><img src="image/1814.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;msup&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msup&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;msup&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msup&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.260em;height:1.050em;width:34.779em"/><st c="33648"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="33734">Eq. </st><st c="33738">45</st></p>
			<p><st c="33740">Bayesian averaging gives us a convenient method for quantifying the spread of values that are possible for the model parameters </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="33869"/><st c="33870"> given the data we </st><span class="No-Break"><st c="33889">have received.</st></span></p>
			<p><st c="33903">In another situation, we might want to calculate the model prediction for some new feature value </st><img src="image/1816.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.560em;width:0.472em"/><st c="34001"/><st c="34002">. We want to calculate </st><img src="image/1817.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.245em"/><st c="34025"/><st c="34026">. But what value of model parameters </st><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.510em"/><st c="34063"/><st c="34064"> do we use? </st><st c="34076">Obviously, we want to use values of </st><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.510em"/><st c="34112"/><st c="34113"> that are guided by the data. </st><st c="34143">However, remember in a Bayesian framework that </st><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.510em"/><st c="34190"/><st c="34191"> is a random variable, so this makes the prediction </st><img src="image/1821.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.349em"/><st c="34243"/><st c="34244"> also a random variable. </st><st c="34269">The solution is to calculate the expectation value of the prediction </st><img src="image/1537.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.935em;width:0.797em"/><st c="34338"/><st c="34339"> over the posterior distribution. </st><st c="34373">So, we ca</st><a id="_idTextAnchor291"/><st c="34382">lculate </st><span class="No-Break"><st c="34391">the following:</st></span></p>
			<p><img src="image/1823.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.457em;height:1.422em;width:17.520em"/><st c="34405"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="34455">Eq. </st><st c="34459">46</st></p>
			<p><st c="34461">You may ask why the expression in Eq. </st><st c="34500">46 is an average over the parameters </st><img src="image/1808.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.496em"/><st c="34537"/><st c="34538"> and not over just </st><img src="image/1730.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.530em"/><st c="34557"/><st c="34558">? After all, it is the average of the prediction we are interested in calculating, and the predictive model only depends on the parameter </st><img src="image/1826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.507em"/><st c="34696"/><st c="34697">. The answer is that there may be correlations</st><a id="_idIndexMarker500"/><st c="34743"> between the parameter </st><img src="image/1730.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.523em"/><st c="34766"/><st c="34767"> and the parameters controlling the random component in the data. </st><st c="34833">So when, say, </st><img src="image/1828.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.860em"/><st c="34847"/><st c="34850"> changes, we can’t ignore the fact that this will change the probability of a given value of </st><img src="image/1829.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.510em"/><st c="34942"/><st c="34943">. Consequently, we must average over both </st><img src="image/1830.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.505em"/><st c="34985"/><st c="34986"> and any parameters controlling the random component in the data, i.e., we average </st><span class="No-Break"><st c="35069">over </st></span><span class="No-Break"><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.473em"/><st c="35074"/></span><span class="No-Break"><st c="35075">.</st></span></p>
			<h3><st c="35076">Bayesian model averaging constructs a consensus from many models</st></h3>
			<p><st c="35141">The </st><a id="_idIndexMarker501"/><st c="35146">expression in Eq. </st><st c="35164">46 is useful because it allows us to calculate the typical value we would expect from our prediction, given the new input feature </st><span class="No-Break"><st c="35294">vector </st></span><span class="No-Break"><img src="image/1816.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.560em;width:0.472em"/><st c="35301"/></span><span class="No-Break"><st c="35302">.</st></span></p>
			<p><st c="35303">One of the real benefits of Bayesian model averaging is the fact that we are taking an average over multiple models. </st><st c="35421">The models that contribute most to the average in Eq. </st><st c="35475">46 will be those that have the highest probability given the data. </st><st c="35542">There can be many models that are nearly all equally likely but some of which may give very different values for the prediction </st><img src="image/1833.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.415em"/><st c="35670"/><st c="35671">. Averaging over all these high-probability models ensures we have a suitable and sensible consensus for our prediction of what will happen at the new feature vector </st><img src="image/1816.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.560em;width:0.472em"/><st c="35837"/><st c="35838">. In this way, we can think of Bayesian model averaging as a formal and rigorous way of doing model averaging, or committee voting, which are well-known techniques in </st><span class="No-Break"><st c="36005">machine learning.</st></span></p>
			<p><st c="36022">The expression in Eq. </st><st c="36045">46 is a mathematical one. </st><st c="36071">It doesn’t tell us how to calculate the Bayesian average in practice. </st><st c="36141">Doing so can be hard. </st><st c="36163">We will learn about some computational</st><a id="_idIndexMarker502"/><st c="36201"> techniques in the next section, such as </st><strong class="bold"><st c="36242">Markov Chain Monte Carlo</st></strong><st c="36266"> (</st><strong class="bold"><st c="36268">MCMC</st></strong><st c="36272">) simulation, that approximate the calculation of the Bayesian average in </st><span class="No-Break"><st c="36347">Eq. </st><st c="36351">46.</st></span></p>
			<p><st c="36354">Another way to approximate the calculation in Eq. </st><st c="36405">46 is to assume that a single model is representative of all the high probability models, and also representative in any downstream calculations, such as the calculation of the prediction </st><img src="image/1817.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.322em;width:3.251em"/><st c="36593"/><st c="36594">. If we are comfortable with this assumption, then the most sensible single model to use is the MAP </st><span class="No-Break"><st c="36694">estimate </st></span><span class="No-Break"><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.747em"/><st c="36703"/></span><span class="No-Break"><st c="36708">.</st></span></p>
			<h2 id="_idParaDest-159"><a id="_idTextAnchor292"/><st c="36709">MAP estimation</st></h2>
			<p><st c="36724">For </st><a id="_idIndexMarker503"/><st c="36729">our model in Eq. </st><st c="36746">1, our model parameters </st><img src="image/1808.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.495em"/><st c="36770"/><st c="36771"> are </st><img src="image/1838.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.407em;height:1.168em;width:2.708em"/><st c="36776"/><st c="36777">, so </st><img src="image/1839.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.601em;height:1.362em;width:8.133em"/><st c="36782"/><st c="36800"> and we would make predictions using the model </st><img src="image/1840.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.601em;height:1.710em;width:5.050em"/><st c="36846"/><st c="36847">. Obviously, when using just </st><img src="image/1841.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.846em"/><st c="36876"/><st c="36881"> we don’t get the benefits</st><a id="_idIndexMarker504"/><st c="36906"> of Bayesian model averaging, but sometimes the posterior distribution is so tightly distributed around its maximum at </st><img src="image/1842.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.897em"/><st c="37025"/><st c="37030"> that only a small range of models </st><img src="image/1843.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.541em"/><st c="37064"/><st c="37065"> have any reasonable posterior probability associated with them, and they are all reasonably well approximated by the MAP </st><span class="No-Break"><st c="37187">value </st></span><span class="No-Break"><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.747em"/><st c="37193"/></span><span class="No-Break"><st c="37198">.</st></span></p>
			<p><st c="37199">This is equivalent to approximating the true posterior </st><img src="image/1845.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.346em"/><st c="37255"/><st c="37267"> by a delta function. </st><st c="37288">That is,</st><a id="_idTextAnchor293"/><st c="37296"> we are approximating in the </st><span class="No-Break"><st c="37325">following way:</st></span></p>
			<p><img src="image/1846.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mi&gt;δ&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.383em;height:1.144em;width:9.825em"/><st c="37339"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37368">Eq. </st><st c="37372">47</st></p>
			<p><st c="37374">Now, remember from </st><a href="B19496_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic"><st c="37394">Chapter 2</st></em></span></a><st c="37403"> that we can loosely think of a Dirac delta function as an infinitely narrow, infinitely high spike. </st><st c="37504">When would this be a good approximation of the true posterior  </st><span class="_-----MathTools-_Math_Variable"><st c="37566">P</st></span><span class="_-----MathTools-_Math_Base"><st c="37567">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="37568">θ</st></span><span class="_-----MathTools-_Math_Variable"/><span class="_-----MathTools-_Math_Variable"><st c="37569">_</st></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><st c="37570">|</st></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Text"><st c="37571">Data</st></span><span class="_-----MathTools-_Math_Text"><st c="37575">)</st></span><st c="37577">? To answer that, we need to understand when the posterior becomes a narrow, tall, distribution centered around the MAP </st><span class="No-Break"><st c="37697">estimate, </st></span><span class="No-Break"><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.747em"/><st c="37707"/></span><span class="No-Break"><st c="37712">.</st></span></p>
			<p><st c="37713">Let’s look at the definition of </st><img src="image/1848.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.729em"/><st c="37746"/><st c="37752">. It is the value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.475em"/><st c="37773"/><st c="37774">  that maximizes </st><img src="image/1850.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.274em"/><st c="37790"/><st c="37801">. Again, applying our trick of maximizing the logarithm, </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.745em"/><st c="37858"/><st c="37863"> is also the value that maximizes </st><img src="image/1852.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:5.550em"/><st c="37896"/><st c="37910">. Using Bayes’ theorem to calculate </st><img src="image/1853.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:5.581em"/><st c="37946"/><st c="37961">, we find that </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.747em"/><st c="37976"/><st c="37981"> is the value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="37997"/><st c="37998"> that maximizes </st><span class="No-Break"><st c="38014">the following:</st></span></p>
			<p><img src="image/1856.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mtext&gt;Likelihood&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mtext&gt;Prior&lt;/mtext&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.968em;width:14.878em"/><st c="38028"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="38065">Eq. </st><st c="38069">48</st></p>
			<p><st c="38071">Since </st><img src="image/1857.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;Data&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.062em;height:0.761em;width:3.143em"/><st c="38078"/><st c="38079"> doesn’t depend on </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="38098"/><st c="38099"> we can ignore it when identifying </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.739em"/><st c="38134"/><st c="38139">, and so </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.739em"/><st c="38148"/><st c="38153"> is the value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="38169"/> <span class="No-Break"><st c="38170">that maximizes,</st></span></p>
			<p><img src="image/1862.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mtext&gt;Likelihood&lt;/mtext&gt;&lt;mtext&gt;+&lt;/mtext&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mtext&gt;Prior&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.968em;width:9.910em"/><st c="38185"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="38211">Eq. </st><st c="38215">49</st></p>
			<h3><st c="38217">For large sample sizes, the likelihood dominates</st></h3>
			<p><st c="38266">Now, recall we said that the log-likelihood scales linearly with the number of data points </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.710em"/><st c="38358"/><st c="38359">. So, the magnitude of the log-likelihood increases with </st><img src="image/629.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.688em"/><st c="38416"/><st c="38417">. In contrast, the prior does not, by definition, depend on the data, so the magnitude of the log-prior doesn’t scale with </st><img src="image/686.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.741em"/><st c="38540"/><st c="38541">. Firstly, this means that as </st><img src="image/686.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.730em"/><st c="38571"/><st c="38572"> increases, the expression in Eq. </st><st c="38606">49 is dominated by the log-likelihood. </st><st c="38645">So, as </st><img src="image/1867.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:2.987em"/><st c="38652"/><st c="38653">, the MAP estimate </st><img src="image/1868.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.770em"/><st c="38672"/><st c="38677"> tends to the maximum-likelihood estimate </st><img src="image/1869.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.368em"/><st c="38718"/><st c="38727">. Secondly, since the magnitude of the log-likelihood is increasing as </st><img src="image/1870.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.168em"/><st c="38798"/><st c="38799">, this means the magnitude of the posterior at </st><img src="image/1871.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:3.948em"/><st c="38846"/><st c="38851"> is increasing</st><a id="_idIndexMarker505"/><st c="38864"> indefinitely as </st><img src="image/1872.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.067em"/><st c="38881"/><st c="38882">. So, the posterior is becoming infinitely high. </st><st c="38931">Since the posterior is a properly normalized probability density, it also becomes infinitely thin as </st><img src="image/1873.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.112em"/><st c="39032"/><st c="39033">. So, as </st><img src="image/1874.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.027em"/><st c="39042"/><st c="39043"> the approximation in Eq. </st><st c="39069">47 becomes accurate. </st><st c="39090">While we have only given a hand-waving demonstration of this, it is still valid. </st><st c="39171">A rigorous proof of th</st><a id="_idTextAnchor294"/><st c="39193">is point is beyond the scope of </st><span class="No-Break"><st c="39226">this book.</st></span></p>
			<div>
				<div id="_idContainer1938" class="IMG---Figure">
					<img src="image/B19496_05_2.jpg" alt="Figure﻿ 5.2: Plots of the prior and posterior distributions for three games of coin tossing with different sample sizes"/><st c="39236"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="39324">Figure 5.2: Plots of the prior and posterior distributions for three games of coin tossing with different sample sizes</st></p>
			<p><span class="No-Break"><em class="italic"><st c="39442">Figure 5</st></em></span><em class="italic"><st c="39451">.2</st></em><st c="39453"> shows a </st><a id="_idIndexMarker506"/><st c="39462">numerical demonstration of this. </st><st c="39495">We have plotted the prior (the blue line) and posterior (the black line) distributions for a series of three experiments. </st><st c="39617">In each plot, the sample data is the number of times a fair coin turns up heads when tossed </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="39709"/><st c="39710"> times. </st><st c="39718">This is a chapter on Bayesian modeling, so we couldn’t not have an example about tossing coins, could we? </st><st c="39824">The plots are for different values of </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.700em"/><st c="39862"/><st c="39863"> with </st><img src="image/1877.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;30&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;100&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.117em;height:0.765em;width:6.439em"/><st c="39869"/><st c="39873"> in the plots from left to right, respectively. </st><st c="39920">To make this interesting, I have set the coin tossing in the wild west of America in the 1840s. </st><st c="40016">I’m betting against “cowboy Duke”, a hardened gambler. </st><st c="40071">Every time the coin is tossed and lands tails up, I win $1. </st><st c="40131">I suspect that Duke is cheating and has an unfair coin. </st><st c="40187">It turns out this isn’t true, but in the wild west of the 1840s I’m on my guard and suspicious, so my prior is that the probability of heads, </st><img src="image/1878.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;p&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;Head&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.798em;width:1.817em"/><st c="40329"/><st c="40336">, for this coin is 0.8. </st><st c="40360">I have used a Beta(8, 2) distribution for my prior so that the mean of my prior is 0.8, but it has some spread, as you can see by the blue line in the plots. </st><st c="40518">The prior, the blue line, is the same in each of the plots, as you expect because the prior does not depend on the data and so can’t depend on the sample </st><span class="No-Break"><st c="40672">size </st></span><span class="No-Break"><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="40677"/></span><span class="No-Break"><st c="40678">.</st></span></p>
			<p><st c="40679">For the</st><a id="_idIndexMarker507"/><st c="40687"> left-hand plot, where </st><img src="image/1880.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:3.223em"/><st c="40710"/><st c="40711">, the number of heads was 5, but the influence of the prior on the posterior is clear. </st><st c="40798">The prior has pulled the posterior away from being centered around the true value of </st><img src="image/1881.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;p&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;Head&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:4.678em"/><st c="40883"/><st c="40891"> (shown by the vertical dashed line), even though the observed proportion of heads was </st><img src="image/1882.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;5&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.044em;height:0.708em;width:4.582em"/><st c="40977"/><st c="40978">. In this case, the sample size of </st><img src="image/1880.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:3.204em"/><st c="41013"/><st c="41014">, isn’t big enough for the likelihood to override the influence of a poorly </st><span class="No-Break"><st c="41090">chosen prior.</st></span></p>
			<p><st c="41103">For the </st><a id="_idIndexMarker508"/><st c="41112">middle plot, with </st><img src="image/1884.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;30&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:3.279em"/><st c="41130"/><st c="41131"> and 16 heads observed, we can see the posterior distribution is closer to being centered around the true value of </st><img src="image/1885.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;p&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;Head&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:4.543em"/><st c="41246"/><st c="41254">, and it is narrower and taller compared to the left-hand plot, but the influence of the prior is still clear. </st><st c="41365">The maximum of the posterior is still noticeably different </st><span class="No-Break"><st c="41424">from </st></span><span class="No-Break"><img src="image/1886.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;p&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;Head&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:4.548em"/><st c="41429"/></span><span class="No-Break"><st c="41437">.</st></span></p>
			<p><st c="41438">In contrast, in the right-hand plot where </st><img src="image/1887.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;100&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:3.572em"/><st c="41481"/><st c="41482"> and 49 heads are observed, the likelihood dominates the posterior and the influence of the prior is small. </st><st c="41590">The posterior distribution is very tall and narrow and centered almost exactly over </st><img src="image/1888.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;p&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;Head&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.974em;width:4.412em"/><st c="41674"/><st c="41683">. The influence of my poorly chosen prior has been almost completely counteracted by the observation of </st><span class="No-Break"><st c="41787">the data.</st></span></p>
			<p><st c="41796">Let’s use the data from </st><span class="No-Break"><em class="italic"><st c="41821">Figure 5</st></em></span><em class="italic"><st c="41829">.2</st></em><st c="41831"> in a MAP estimation </st><span class="No-Break"><st c="41852">code example.</st></span></p>
			<h3><st c="41865">MAP estimation code example</st></h3>
			<p><st c="41893">The </st><a id="_idIndexMarker509"/><st c="41898">following code example can be found in the </st><strong class="source-inline"><st c="41941">Code_Examples_Chap5.ipynb</st></strong><st c="41966"> notebook in the </st><span class="No-Break"><st c="41983">GitHub repository.</st></span></p>
			<p><st c="42001">We’ll calculate the MAP estimate for the binomial data we illustrated in the left-hand panel of </st><span class="No-Break"><em class="italic"><st c="42098">Figure 5</st></em></span><em class="italic"><st c="42106">.2</st></em><st c="42108">. We have data from a series of Bernoulli trials. </st><st c="42158">The likelihood only depends on the number of trials, the number of successes (number of heads for the example in </st><span class="No-Break"><em class="italic"><st c="42271">Figure 5</st></em></span><em class="italic"><st c="42279">.2</st></em><st c="42281">), and the success probability </st><img src="image/1889.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.485em"/><st c="42313"/><st c="42314">. We’ll use the in-built optimization algorithms in the SciPy package to maximize the posterior. </st><st c="42411">We do this by minimizing the negative of the log-posterior. </st><st c="42471">We only need to calculate the sum of the log-likelihood and the log-prior since we can drop the normalizing constant from the log-posterior, as this does not depend upon the success probability. </st><st c="42666">The parameter we maximize the log-posterior </st><a id="_idIndexMarker510"/><st c="42710">with respect to will actually be the logit of the success probability. </st><st c="42781">Since the logistic function is a monotonic function, stationary points of the log-posterior with respect to </st><img src="image/1890.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.495em"/><st c="42889"/><st c="42890"> will also be stationary points of the log-posterior with respect to </st><img src="image/1891.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.017em;width:5.561em"/><st c="42959"/><st c="42974">. First, we’ll need to define the </st><span class="No-Break"><st c="43008">log-posterior function:</st></span></p>
			<pre class="source-code"><st c="43031">
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.special import loggamma
from scipy.optimize import minimize
 def get_neg_log_binomial_posterior(n_trial, n_success, alpha, beta):
     '''
     A function to construct a callable that returns the negative of
     the log-posterior for binomially distributed data, with a Beta
     prior for the success probability of the Bernoulli trials.
     </st><st c="43433">Returns a callable that returns the negative of the log-posterior
     (up to a global constant) and takes the logit of the success
     probability logit(p) as input.
     </st><st c="43591">'''
     def neg_log_binomial_posterior(logit_p):
         '''
         A function to compute the negative log-posterior (up to a
         global constant) for binomially distributed data, with a Beta
         prior for the success probability of the Bernoulli trials.
         </st><st c="43819">logit_p is the logit of the success probability.
         </st><st c="43868">Returns the negative of the sum of the log-likelihood and the
         the log-prior
         '''
         # Compute the success probability p from logit(p)
         p = np.exp(logit_p)/ (1.0 + np.exp(logit_p))
         # Compute the log-prior
         log_prior = loggamma(alpha + beta) - loggamma(alpha) - \
            loggamma(beta)
         log_prior += ((alpha-1.0)*np.log(p)) + \
            ((beta-1.0)*np.log(1.0 - p))
         # Compute the log-likelihood
         log_likelihood = loggamma(n_trial +1.0)
         log_likelihood -= loggamma(n_trial - n_success +1.0)
         log_likelihood -= loggamma(n_success +1.0)
         log_likelihood += (n_success*np.log(p))
         log_likelihood += ((n_trial-n_success)*np.log(1.0-p))
         # Compute the log-posterior, 
         #up to the global normalization factor,
         # as the sum of the log prior and log-likelihood
         log_posterior = log_likelihood + log_prior
         return -log_posterior
     return neg_log_binomial_posterior</st></pre>			<p><st c="44684">Now we’ll set</st><a id="_idIndexMarker511"/><st c="44698"> the data. </st><st c="44709">In this example, we’ll use the values from the left-hand panel of </st><span class="No-Break"><em class="italic"><st c="44775">Figure 5</st></em></span><span class="No-Break"><em class="italic"><st c="44783">.2</st></em></span><span class="No-Break"><st c="44785">:</st></span></p>
			<pre class="source-code"><st c="44787">
# Specify the sample size and the number of successes
n_trial = 10
n_success = 5
# Specify the parameters of the prior
alpha = 8
beta = 2
# Get the objective function to minimized
neg_log_posterior = get_neg_log_binomial_posterior(n_trial, n_success, 
                                                   alpha, beta)
# Construct an initial estimate for the optimal parameter.
</st><st c="45111"># We'll use the sample success proportion to do this 
# (and take the logit)
p0 = float(n_success)/float(n_trial)
logit_p0 = np.log(p0/(1.0-p0))
x0 = np.array([logit_p0])</st></pre>			<p><st c="45280">Now we’ll </st><a id="_idIndexMarker512"/><st c="45291">do the minimization </st><a id="_idIndexMarker513"/><st c="45311">of the negative log-posterior using the SciPy implementation of the </st><strong class="bold"><st c="45379">Broyden-Fletcher-Goldfarb-Shanno</st></strong><st c="45411"> (</st><span class="No-Break"><strong class="bold"><st c="45413">BFGS</st></strong></span><span class="No-Break"><st c="45417">) algorithm:</st></span></p>
			<pre class="source-code"><st c="45430">
map_estimate = minimize(neg_log_posterior,
                        x0,
                        method='BFGS',
                        options={'disp': True})
# Convert from logit(p) to p
p_optimal = np.exp(map_estimate['x'][0])/ (
    1.0 + np.exp(map_estimate['x'][0]))
print("MAP estimate of success probability = ", p_optimal)</st></pre>			<p><st c="45684">This gives the </st><span class="No-Break"><st c="45700">following output:</st></span></p>
			<pre class="source-code"><st c="45717">
MAP estimate of success probability = 0.666666667917668</st></pre>			<p><st c="45773">The MAP estimate of the success probability </st><img src="image/1890.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.495em"/><st c="45818"/><st c="45819"> corresponds to the position of the maximum of the posterior that we can see in the left-hand panel of </st><span class="No-Break"><em class="italic"><st c="45922">Figure 5</st></em></span><span class="No-Break"><em class="italic"><st c="45930">.2</st></em></span><span class="No-Break"><st c="45932">.</st></span></p>
			<h2 id="_idParaDest-160"><a id="_idTextAnchor295"/><st c="45933">As </st><img src="image/1893.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.673em;width:0.751em"/><st c="45937"/><st c="45938"> becomes large the prior becomes irrelevant</st></h2>
			<p><st c="45981">We have already illustrated the main consequence of the sample size </st><img src="image/629.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.688em"/><st c="46050"/><st c="46051"> becoming large – the likelihood dominates the posterior – but let’s unpack that conclusion a bit more. </st><st c="46155">Effectively, the prior becomes irrelevant as the sample size increases. </st><st c="46227">How quickly the prior becomes irrelevant depends upon the precise details of the likelihood – the predictive model and the nature of the random component in the data – but also the precise details of the prior. </st><st c="46438">A narrow prior, </st><img src="image/1781.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.162em;height:0.923em;width:1.782em"/><st c="46454"/><st c="46455">, indicates a high degree of confidence in that prior belief, and this would take a greater amount of information (data) in the likelihood for the influence of the prior to be overruled. </st><st c="46642">A high degree of confidence does not mean that the prior is correct. </st><st c="46711">Instead, it means that we have a strong </st><strong class="bold"><st c="46751">a priori</st></strong><st c="46759"> belief that the only values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.482em"/><st c="46791"/><st c="46792"> that are possible are those that are in the narrow range where </st><img src="image/1897.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.162em;height:0.923em;width:1.738em"/><st c="46856"/><st c="46857"> is high. </st><st c="46867">But even the influence of a narrow poorly chosen prior can be overcome with sufficient data. </st><st c="46960">With one exception. </st><st c="46980">If our prior </st><img src="image/1897.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.162em;height:0.923em;width:1.722em"/><st c="46993"/><st c="46994"> is itself a delta function, then no finite amount of data can overcome the influence of the prior. </st><st c="47094">In other words, if we are 100% certain in our </st><strong class="bold"><st c="47140">a priori</st></strong><st c="47148"> beliefs about the model </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.480em"/><st c="47173"/><st c="47174">, then no amount of data can convince us otherwise, even if those beliefs </st><span class="No-Break"><st c="47248">are wrong.</st></span></p>
			<h2 id="_idParaDest-161"><a id="_idTextAnchor296"/><st c="47258">Least squares as an approximation to Bayesian modeling</st></h2>
			<p><st c="47313">As a</st><a id="_idIndexMarker514"/><st c="47318"> final comment on the two main ways of using the posterior in calculations, we’ll return to a comment we made in </st><a href="B19496_04.xhtml#_idTextAnchor216"><span class="No-Break"><em class="italic"><st c="47431">Chapter 4</st></em></span></a><st c="47440"> about least squares being a heuristic algorithm, but that it was possible to provide more formal under-pinning to least squares estimation of </st><span class="No-Break"><st c="47583">model parameters.</st></span></p>
			<p><st c="47600">The delta function approximation in Eq. </st><st c="47641">47 highlights that we can view MAP estimation as an approximation to the correct posterior. </st><st c="47733">We also know that MAP estimation becomes more appropriate when we have large sample sizes </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.719em"/><st c="47823"/><st c="47824">. We also know that in the limit </st><img src="image/1873.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.129em"/><st c="47857"/><st c="47858"> the MAP estimate of </st><img src="image/1808.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.492em"/><st c="47879"/><st c="47880"> becomes the maximum likelihood estimate of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="47924"/><st c="47925">. And we know that when the random component in our data is of the form of additive Gaussian noise, then the model parameter </st><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.510em"/><st c="48050"/><st c="48051">, from the maximum-likelihood estimate of </st><img src="image/1905.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.407em;height:1.168em;width:4.978em"/><st c="48093"/><st c="48094">, is the same as the least squares estimate of </st><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.510em"/><st c="48141"/><st c="48142">. So, finally, we have the more rigorous justification for the least squares estimation of model parameters that we promised back in </st><a href="B19496_04.xhtml#_idTextAnchor216"><span class="No-Break"><em class="italic"><st c="48275">Chapter 4</st></em></span></a><st c="48284">. We can view the least squares estimation of the model parameters </st><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.513em"/><st c="48351"/><st c="48352"> as the result of a chain of approximations applied to the posterior expectation </st><span class="No-Break"><st c="48433">of </st></span><span class="No-Break"><img src="image/1729.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.357em;height:1.068em;width:0.510em"/><st c="48436"/></span><span class="No-Break"><st c="48437">.</st></span></p>
			<p><st c="48438">We have covered a lot of the theory behind Bayesian modeling in this section, so it is time to recap what we have learned before we move on to how we put that theory into practice in numerical calculations in the </st><span class="No-Break"><st c="48652">next section.</st></span></p>
			<h2 id="_idParaDest-162"><a id="_idTextAnchor297"/><st c="48665">What we have learned</st></h2>
			<p><st c="48686">In this section, we have learned about </st><span class="No-Break"><st c="48726">the following:</st></span></p>
			<ul>
				<li><st c="48740">Bayesian model averaging and how it uses the probabilities given by the posterior </st><img src="image/1909.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.348em"/><st c="48823"/><st c="48835"> to perform a weighted average calculated over a set of </st><span class="No-Break"><st c="48890">models </st></span><span class="No-Break"><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="48897"/></span></li>
				<li><strong class="bold"><st c="48898">Maximum a posteriori</st></strong><st c="48918"> (</st><strong class="bold"><st c="48920">MAP</st></strong><st c="48923">) estimation and how it approximates the posterior distribution by a single representative model, </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.747em"/><st c="49022"/><st c="49027">, that has the highest probability given </st><span class="No-Break"><st c="49068">the data</st></span></li>
				<li><st c="49076">How the MAP estimate for a model </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="49110"/><st c="49111"> tends to the maximum likelihood estimate of the model </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="49166"/><st c="49167">, as the sample </st><span class="No-Break"><st c="49183">size </st></span><span class="No-Break"><img src="image/1914.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.076em"/><st c="49188"/></span></li>
				<li><st c="49189">How MAP estimation provides a justification for the least squares estimation of a model’s parameters when the random component in the data is additive </st><span class="No-Break"><st c="49340">Gaussian noise</st></span></li>
			</ul>
			<p><st c="49354">Having learned about the theory of Bayesian modeling, in the next section we’ll learn about some of the practical aspects, and </st><a id="_idIndexMarker515"/><st c="49482">about a class of modeling tools called </st><strong class="bold"><st c="49521">Probabilistic Programming </st></strong><span class="No-Break"><strong class="bold"><st c="49547">Languages</st></strong></span><span class="No-Break"><st c="49556"> (</st></span><span class="No-Break"><strong class="bold"><st c="49558">PPLs</st></strong></span><span class="No-Break"><st c="49562">).</st></span></p>
			<h1 id="_idParaDest-163"><a id="_idTextAnchor298"/><st c="49565">Bayesian modeling in practice</st></h1>
			<p><st c="49595">Bayesian model averaging, as </st><a id="_idIndexMarker516"/><st c="49625">encapsulated by Eq. </st><st c="49645">46, is a very powerful tool for any data scientist to have in their toolkit. </st><st c="49722">In practice, it can take a bit more experience to fully make use of its potential. </st><st c="49805">We haven’t yet said how one goes about computing the expectation value in Eq. </st><st c="49883">46. </st><st c="49887">This is the practice of </st><span class="No-Break"><st c="49911">Bayesian modeling.</st></span></p>
			<p><st c="49929">To make Bayesian modeling averaging a practical tool, there are two main approaches we </st><span class="No-Break"><st c="50017">can take:</st></span></p>
			<ul>
				<li><st c="50026">Analytical calculation, whereby we approximate the posterior to the extent that calculation of the expectation in Eq. </st><st c="50145">46 can be done in closed-form or nearly in closed-form, and so we only need to perform a small number of </st><span class="No-Break"><st c="50250">numerical calculations</st></span></li>
				<li><st c="50272">Computationally intensive sampling, whereby we numerically approximate the integration in Eq. </st><st c="50367">46 by sampling many different model values </st><span class="No-Break"><st c="50410">of </st></span><span class="No-Break"><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="50413"/></span></li>
			</ul>
			<p><st c="50414">We will now cover those two approaches in </st><span class="No-Break"><st c="50456">more detail.</st></span></p>
			<h2 id="_idParaDest-164"><a id="_idTextAnchor299"/><st c="50468">Analytic approximation of the posterior</st></h2>
			<p><st c="50508">We have</st><a id="_idIndexMarker517"/><st c="50516"> already introduced an analytic approximation to the posterior in Eq. </st><st c="50586">47. </st><st c="50590">When we introduced the MAP estimate we explained that the approximation in Eq. </st><st c="50669">47 is appropriate if the posterior is tall and narrow. </st><st c="50724">We know this happens as the dataset size </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="50765"/><st c="50766"> becomes large. </st><st c="50782">But what happens if </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="50802"/><st c="50803"> is not large? </st><st c="50818">What happens if the posterior is not tall and narrow? </st><st c="50872">What analytic approximation can we use then? </st><st c="50917">The next most obvious step is to approximate the posterior by a multi-variate Gaussian distribution centered around the maximum of the posterior, i.e., centered around </st><img src="image/1918.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;MAP&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.973em"/><st c="51085"/><st c="51090"> . Effectively, we are approximating the log of </st><img src="image/1919.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.281em"/><st c="51137"/><st c="51148"> by its second order Taylor-expansion about </st><img src="image/1920.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;MAP&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.777em"/><st c="51191"/><st c="51197">. Doing s</st><a id="_idTextAnchor300"/><st c="51206">o gives us the </st><span class="No-Break"><st c="51222">following approximation:</st></span></p>
			<p><img src="image/1921.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mtext&gt;det&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.661em;height:1.675em;width:24.252em"/><st c="51246"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="51304">Eq. </st><st c="51308">50</st></p>
			<p><st c="51310">Here, </st><img src="image/1922.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.204em;height:0.915em;width:1.031em"/><st c="51317"/><st c="51318"> denotes the cardinality of the vector </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.489em"/><st c="51357"/><st c="51358">, that is, the number of components in the vector </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.489em"/><st c="51408"/><st c="51409">. The matrix </st><img src="image/1275.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.744em"/><st c="51422"/><st c="51423"> is the Hessian of the log-posterior evaluated at the MAP point </st><img src="image/1926.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.721em"/><st c="51487"/><st c="51493">, and so is calculated </st><span class="No-Break"><st c="51516">as follows:</st></span></p>
			<p><img src="image/1927.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mfenced open=&quot;&quot; close=&quot;|&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-1.002em;height:2.293em;width:9.384em"/><st c="51527"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="51562">Eq. </st><st c="51566">51</st></p>
			<p><st c="51568">If we </st><a id="_idIndexMarker518"/><st c="51575">have a function, </st><img src="image/1928.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:2.315em"/><st c="51592"/><st c="51600">, that depends upon the model </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.475em"/><st c="51630"/><st c="51631"> and we want to calculate its expectation, </st><img src="image/1930.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.399em;height:1.210em;width:4.010em"/><st c="51674"/><st c="51675">, over the posterior, then we can now </st><a id="_idTextAnchor301"/><st c="51713">approximate that expectation </st><span class="No-Break"><st c="51742">as follows:</st></span></p>
			<p><img src="image/1931.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mtext&gt;det&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;munder&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.661em;height:1.675em;width:27.957em"/><st c="51753"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="51819">Eq. </st><st c="51823">52</st></p>
			<p><st c="51825">Many integrals with Gaussian distributions can be evaluated exactly, i.e., in closed-form, and this is one of the main benefits of the analytic approximation approach. </st><st c="51994">When the integral in Eq. </st><st c="52019">52 cannot be evaluated exactly, a common approach is to also expand the function </st><img src="image/1932.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:2.506em"/><st c="52100"/><a id="_idTextAnchor302"/><st c="52101"> about </st><img src="image/1933.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.689em"/><st c="52108"/><st c="52114">, so we </st><span class="No-Break"><st c="52122">have this:</st></span></p>
			<p><img src="image/1934.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mfenced open=&quot;&quot; close=&quot;|&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mfenced open=&quot;&quot; close=&quot;|&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;⋯&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-1.002em;height:2.293em;width:34.564em"/><st c="52132"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="52153">Eq. </st><st c="52157">53</st></p>
			<p><st c="52159">Plugging Eq. </st><st c="52173">53 into Eq. </st><st c="52185">52 and evaluating th</st><a id="_idTextAnchor303"/><st c="52205">e integral in Eq. </st><st c="52224">52 then gives </st><span class="No-Break"><st c="52238">us this:</st></span></p>
			<p><img src="image/1935.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mtext&gt;tr&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mfenced open=&quot;&quot; close=&quot;|&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;⋯&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-1.052em;height:2.393em;width:20.922em"/><st c="52246"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="52306">Eq. </st><st c="52310">54</st></p>
			<p><st c="52312">We have now reduced the calculation down to an optimization problem – locating the value of </st><img src="image/1936.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.724em"/><st c="52405"/><st c="52411"> – and a linear algebra calculation in Eq. </st><st c="52453">54, both of which we have established software packages </st><span class="No-Break"><st c="52509">to do.</st></span></p>
			<p><st c="52515">One of the </st><a id="_idIndexMarker519"/><st c="52527">benefits of using a Gaussian approximation centered on the MAP estimate </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.741em"/><st c="52599"/><st c="52604"> is that we have already located the MAP value </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.747em"/><st c="52650"/><st c="52655"> when we did MAP estimation. </st><st c="52683">In fact, we can think of the delta function approximation in Eq. </st><st c="52748">47 as the first order approximation to the posterior </st><img src="image/1939.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.359em"/><st c="52801"/><st c="52813">, compared to the second-order approximation that Eq. </st><st c="52867">50 represents. </st><st c="52882">One could construct higher-order approximations to the posterior by continuing the Taylor expansion of </st><img src="image/1940.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:5.735em"/><st c="52985"/><st c="53000"> about </st><img src="image/1941.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:1.756em"/><st c="53006"/><st c="53011"> to third order or higher. </st><st c="53037">However, this is very rarely done in machine learning </st><span class="No-Break"><st c="53091">or statistics.</st></span></p>
			<p><st c="53105">Another benefit of the analytic approximation in Eq. </st><st c="53159">50 is that it is very general. </st><st c="53190">We can apply the approximate posterior distribution given in Eq. </st><st c="53255">50 to calculate the expectation of any function </st><span class="_-----MathTools-_Math_Variable"><st c="53303">f</st></span><span class="_-----MathTools-_Math_Base"><st c="53304">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="53305">x</st></span><span class="_-----MathTools-_Math_Variable"/><span class="_-----MathTools-_Math_Variable"><st c="53306">_</st></span><span class="_-----MathTools-_Math_Operator"><st c="53307">,</st></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><st c="53308">θ</st></span><span class="_-----MathTools-_Math_Variable"/><span class="_-----MathTools-_Math_Variable"><st c="53309">_</st></span><span class="_-----MathTools-_Math_Base"><st c="53310">)</st></span><span class="_-----MathTools-_Math_Operator"><st c="53311">.</st></span><st c="53312"> Likewise, the approximation in Eq. </st><st c="53348">54 can be applied to any </st><span class="No-Break"><st c="53373">function </st></span><span class="No-Break"><img src="image/1942.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:2.595em"/><st c="53382"/></span></p>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor304"/><st c="53383">Computational sampling</st></h2>
			<p><st c="53405">The idea </st><a id="_idIndexMarker520"/><st c="53415">behind sampling approaches to Bayesian averaging is very simple. </st><st c="53480">If we want to calculate the expectation, </st><img src="image/1943.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.399em;height:1.210em;width:3.933em"/><st c="53521"/><st c="53533">, over a distribution of models, then we could approximate this population average by a sample average. </st><st c="53637">In other words, we generate a random sample of values of </st><img src="image/1808.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.496em"/><st c="53694"/><st c="53695"> from the distribution in question, plug those sample values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.475em"/><st c="53759"/><st c="53760"> into </st><img src="image/1946.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:2.323em"/><st c="53766"/><st c="53774"> and calculate the sample mean. </st><st c="53805">For our Bayesian averaging challenge the distribution in question from which we sample values of </st><img src="image/1808.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.495em"/><st c="53902"/><st c="53903"> is the posterior </st><img src="image/1939.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.365em"/><st c="53921"/><st c="53933">. If we generate </st><img src="image/589.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.652em"/><st c="53950"/><st c="53963"> sample values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="53980"/><st c="53981"> from </st><img src="image/1939.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.365em"/><st c="53987"/><st c="53999">, then the expectation o</st><a id="_idTextAnchor305"/><st c="54023">f </st><img src="image/1952.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:2.367em"/><st c="54026"/><st c="54027"> is approximated </st><span class="No-Break"><st c="54044">by this:</st></span></p>
			<p><img src="image/1953.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mtext&gt;Posterior(Data)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.767em;height:2.187em;width:18.928em"/><st c="54052"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="54074">Eq. </st><st c="54078">55</st></p>
			<p><st c="54080">The larger </st><img src="image/589.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.658em"/><st c="54092"/><st c="54105"> is, i.e., the larger the number of samples of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.485em"/><st c="54151"/><st c="54152"> we generate from the posterior, the more accurate the approximation in Eq. </st><st c="54228">55 will be. </st><st c="54240">As with the analytic approximation techniques, this is a completely general approach – we haven’t said what the function </st><img src="image/1952.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:2.371em"/><st c="54361"/><st c="54362"> is, and so this method can be applied to any </st><span class="No-Break"><st c="54408">function </st></span><span class="No-Break"><img src="image/1952.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.018em;width:2.367em"/><st c="54417"/></span><span class="No-Break"><st c="54418">.</st></span></p>
			<p><st c="54419">The </st><a id="_idIndexMarker521"/><st c="54424">only question that now remains is, how do we generate samples of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.472em"/><st c="54489"/><st c="54490"> from the posterior </st><img src="image/1959.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.204em"/><st c="54510"/><st c="54522">? We covered a bit about sampling from distributions in </st><a href="B19496_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic"><st c="54578">Chapter 2</st></em></span></a><st c="54587">, but we commented that sampling from continuous distributions can sometimes be challenging. </st><st c="54680">Fortunately, there is a general computational method that comes to our rescue – </st><strong class="bold"><st c="54760">Markov Chain Monte Carlo</st></strong><st c="54784"> (</st><strong class="bold"><st c="54786">MCMC</st></strong><st c="54790">). </st><st c="54794">MCMC</st><a id="_idIndexMarker522"/><st c="54798"> is a Monte Carlo method, meaning we generate values of our random variable, </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="54875"/><st c="54876"> in this case, at random. </st><st c="54902">The Markov Chain part of the algorithm name means that when we generate our next value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.491em"/><st c="54992"/><st c="54993"> at random, we do so conditionally on our current value of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.474em"/><st c="55052"/><st c="55053">, and so we get a sequence or a </st><strong class="bold"><st c="55085">chain</st></strong><st c="55090"> of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.482em"/><st c="55094"/><st c="55095"> values. </st><st c="55104">MCMC algorithms typically take the </st><span class="No-Break"><st c="55139">following form:</st></span></p>
			<ol>
				<li><st c="55154">Set the iteration number </st><img src="image/1964.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.651em;width:2.292em"/><st c="55180"/><st c="55181"> and set </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="55190"/><st c="55191"> to some initial </st><span class="No-Break"><st c="55208">value </st></span><span class="No-Break"><img src="image/1966.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.806em"/><st c="55214"/></span><span class="No-Break"><st c="55217">.</st></span></li>
			</ol>
			<p><st c="55218">From the current value </st><img src="image/1967.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.692em"/><st c="55242"/><st c="55245">, propose a new value trial value </st><img src="image/1968.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mtext&gt;trial&lt;/mtext&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.051em;width:5.209em"/><st c="55279"/><st c="55286">, where </st><img src="image/1969.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mml:mi&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:1.124em"/><st c="55294"/><st c="55295"> is an adjustment that we sample from a simple fixed distribution, e.g. </st><st c="55367">a uniform distribution with a </st><span class="No-Break"><st c="55397">small range.</st></span></p>
			<ol>
				<li><st c="55409">Accept or reject the trial value </st><img src="image/1970.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;trial&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:1.436em"/><st c="55443"/><st c="55449"> by applying a stochastic comparison rule to the pair of values </st><img src="image/1971.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.390em;height:1.288em;width:4.577em"/><st c="55512"/> <span class="No-Break"><st c="55523">and </st></span><span class="No-Break"><img src="image/1972.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mtext&gt;trial&lt;/mtext&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.390em;height:1.288em;width:5.609em"/><st c="55527"/></span><span class="No-Break"><st c="55543">.</st></span></li>
				<li><st c="55544">If we accept the trial value </st><img src="image/1973.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;trial&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:1.448em"/><st c="55574"/><st c="55580"> then we set </st><img src="image/1974.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mtext&gt;trial&lt;/mtext&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.051em;width:3.713em"/><st c="55592"/><st c="55606">, else we set </st><img src="image/1975.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.051em;width:2.925em"/><st c="55620"/><st c="55621">. Record </st><img src="image/1976.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:1.265em"/><st c="55630"/><st c="55633">. Increment the </st><span class="No-Break"><st c="55649">iteration, </st></span><span class="No-Break"><img src="image/1977.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.028em;height:0.667em;width:3.464em"/><st c="55660"/></span><span class="No-Break"><st c="55661">.</st></span></li>
				<li><st c="55662">Repeat steps 2 – 4 until </st><img src="image/332.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.875em"/><st c="55688"/><st c="55689"> iterations have </st><span class="No-Break"><st c="55706">been performed.</st></span></li>
			</ol>
			<p><st c="55721">One of the simplest </st><a id="_idIndexMarker523"/><st c="55742">comparison rules is the </st><strong class="bold"><st c="55766">Metropolis-Hastings importance sam</st><a id="_idTextAnchor306"/><st c="55800">pling</st></strong><st c="55806"> scheme, which takes the </st><span class="No-Break"><st c="55831">following </st></span><span class="No-Break"><st c="55841">form:</st></span></p>
			<p><img src="image/1979.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Accept&lt;/mtext&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mtext&gt;trial&lt;/mtext&gt;&lt;/msub&gt;&lt;mtext&gt;with&lt;/mtext&gt;&lt;mtext&gt;probability&lt;/mtext&gt;&lt;mtext&gt;min&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mtext&gt;trial&lt;/mtext&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.980em;height:2.650em;width:21.027em"/><st c="55846"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="55922">Eq. </st><st c="55926">56</st></p>
			<p><st c="55928">Eq. </st><st c="55933">56 says that if our trial value </st><img src="image/1980.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;trial&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:1.574em"/><st c="55965"/><st c="55971"> has higher probability than our current value </st><img src="image/1981.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:0.768em"/><st c="56017"/><st c="56020">, then we move from </st><img src="image/1981.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:0.768em"/><st c="56040"/><st c="56043"> to </st><img src="image/1980.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;trial&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:1.574em"/><st c="56046"/><st c="56052"> with probability 1, i.e., we definitely move. </st><st c="56098">While if </st><img src="image/1980.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;trial&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:1.574em"/><st c="56107"/><st c="56113"> has lower probability than </st><img src="image/1981.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:0.768em"/><st c="56140"/><st c="56143"> we can still move to </st><img src="image/1986.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;trial&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:1.510em"/><st c="56164"/><st c="56170">, but it is not guaranteed. </st><st c="56198">The smaller the probability </st><img src="image/1987.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mtext&gt;trial&lt;/mtext&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.449em;height:1.411em;width:5.333em"/><st c="56226"/><st c="56239"> is compared to </st><img src="image/1988.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.445em;height:1.403em;width:4.448em"/><st c="56254"/><st c="56265">, the less likely we are to move to </st><img src="image/1989.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;trial&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.374em;height:1.085em;width:1.539em"/><st c="56301"/><st c="56307"> and so the more likely we are to stay in </st><img src="image/1990.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mtext&gt;i&lt;/mtext&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.367em;height:1.078em;width:0.796em"/><st c="56348"/><st c="56351">. Overall, this means we move, over time and in a stochastic fashion, to regions of higher and higher </st><span class="No-Break"><st c="56453">posterior probability.</st></span></p>
			<p><st c="56475">You rightly ask </st><a id="_idIndexMarker524"/><st c="56492">how we choose the initial value </st><img src="image/1991.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.916em"/><st c="56524"/><st c="56527">. It doesn’t matter. </st><st c="56548">After we have performed a reasonable number of iterations, the values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.482em"/><st c="56621"/><st c="56622"> being generated will be correctly sampled from the posterior </st><img src="image/1993.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.254em;height:1.015em;width:4.299em"/><st c="56684"/><st c="56696">. However, the early values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.476em"/><st c="56727"/><st c="56728"> will not be correctly sampled from the posterior, and therefore it is usual to discard these values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.474em"/><st c="56832"/><st c="56833"> from the early part of the chain. </st><st c="56868">The period where we are just iterating the MCMC algorithm but not recording the generated values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.491em"/><st c="56968"/><st c="56969"> is called </st><a id="_idIndexMarker525"/><st c="56980">the </st><strong class="bold"><st c="56984">burn-in</st></strong><st c="56991"> period. </st><st c="57000">After the burn-in period, we collect and use the generated values of </st><img src="image/1778.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.473em"/><st c="57069"/><st c="57070"> as our sample to plug into the sample average calculation in Eq. </st><st c="57136">55. </st><st c="57140">Let’s illustrate these concepts with a </st><span class="No-Break"><st c="57179">code example.</st></span></p>
			<h2 id="_idParaDest-166"><a id="_idTextAnchor307"/><st c="57192">MCMC code example</st></h2>
			<p><st c="57210">We’ll </st><a id="_idIndexMarker526"/><st c="57217">code up a very basic version of the Metropolis-Hastings algorithm and use it to sample </st><img src="image/1998.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mtext&gt;logit&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.302em;height:1.013em;width:2.967em"/><st c="57304"/><st c="57313"> values from the posterior </st><img src="image/1999.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mfenced&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.413em;height:1.334em;width:7.498em"/><st c="57339"/><st c="57359"> for the data in the left-hand plot of </st><span class="No-Break"><em class="italic"><st c="57397">Figure 5</st></em></span><em class="italic"><st c="57405">.2</st></em><st c="57407">. As with our earlier MAP estimation example, we are working with </st><img src="image/2000.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mtext&gt;logit&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.302em;height:1.013em;width:2.939em"/><st c="57473"/><st c="57482"> rather than the success probability </st><img src="image/1890.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.492em"/><st c="57518"/><st c="57519"> so that we can sample a parameter that is unconstrained, i.e., it lies in the range </st><img src="image/2002.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.167em;height:0.703em;width:4.458em"/><st c="57604"/><st c="57605">. This means we’ll need to calculate the posterior for </st><img src="image/2003.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.363em;height:1.186em;width:3.368em"/><st c="57660"/><st c="57661">, but we can do this using the rule for transforming probability distributions that we covered in </st><em class="italic"><st c="57759">Chapter</st></em><st c="57766">. Doing so gives </st><span class="No-Break"><st c="57783">us this:</st></span></p>
			<p><img src="image/2004.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.751em;height:2.010em;width:22.468em"/><st c="57791"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="57849">Eq. </st><st c="57853">57</st></p>
			<p><st c="57855">We’ll reuse the code from the previous MAP estimation code example to generate a callable Python function that </st><span class="No-Break"><st c="57967">returns </st></span><span class="No-Break"><img src="image/2005.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mtext&gt;Data&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.302em;height:1.112em;width:6.212em"/><st c="57975"/></span><span class="No-Break"><st c="57991">.</st></span></p>
			<p><st c="57992">The following code example can be found in the </st><strong class="source-inline"><st c="58040">Code_Examples_Chap5.ipynb</st></strong><st c="58065"> notebook in </st><a id="_idIndexMarker527"/><st c="58078">the </st><span class="No-Break"><st c="58082">GitHub repository:</st></span></p>
			<ol>
				<li><st c="58100">First, we’ll define a function to perform a single trial </st><span class="No-Break"><st c="58158">Metropolis-Hastings move:</st></span><pre class="source-code"><st c="58183">
import numpy as np
def perform_mh_trial(x, log_post, delta_x, neg_log_posterior):
     '''
     Function to perform a Metropolis-Hastings trial move.
     </st><st c="58324">x is the current logit(p) value.
     </st><st c="58357">log_post is the current log-posterior value.
     </st><st c="58402">delta_x is the half-width of the range from which the trial
     adjustments to logit(p) are made.
     </st><st c="58496">neg_log_posterior is a callable that returns the negative 
     log-posterior.
     </st><st c="58569">We return a tuple of the updated logit(p) value and updated 
     log-posterior value.
     </st><st c="58650">'''
     accept_trial = False
     x_trial = x + (delta_x*(2.0*np.random.rand(1) -0))
     p_trial = np.exp(x_trial)/(1.0 + np.exp(x_trial))
     # Calculate the log-posterior for the trial point.
     </st><st c="58827"># Note we'll need to flip the sign of neg_log_posterior, as
     # our callable returns the negative of the log-posterior.
     </st><st c="58945">log_post_trial = -neg_log_posterior(x_trial) + np.log(p_
     trial*(1.0 – p_trial))
     # Calculate the change in log-posterior if we move to the 
     # trial point
     delta_log_post = log_post_trial - log_post
     # Work out if should accept the trial point
     if delta_log_post &gt; 0.0:
         accept_trial = True
     else:
         if np.log(np.random.rand(1)) &lt; delta_log_post:
             accept_trial = True
     # If we accept the trial point then update the current 
     # value of the parameter
     # and the log-posterior
     if accept_trial==True:
         x = x_trial
         log_post = log_post_trial
     return x, log_post</st></pre></li>				<li><st c="59485">Now, we can use the preceding function to define another function that runs the </st><a id="_idIndexMarker528"/><st c="59566">Markov chain for a user-specified number of burn-in iterations, followed by a user-specified number of </st><span class="No-Break"><st c="59669">sampling iterations:</st></span><pre class="source-code"><st c="59689">
def mh_mcmc(n_burnin, n_iter, x0, delta_x, neg_log_posterior):
     '''
     A function to run a simple Metropolis-Hastings MCMC
     calculation.
     </st><st c="59822">n_burnin is the number of burnin iterations to be run.
     </st><st c="59877">n_iter is the number of sampling iterations to be run.
     </st><st c="59932">x0 is the starting value for logit(p).
     </st><st c="59971">delta_x is the half-width of the range from which the trial
     adjustments to logit(p) are made.
     </st><st c="60065">neg_log_posterior is a callable that returns the negative 
     log-posterior.
     </st><st c="60138">We return an array of the sampled logit(p) values
     '''
     #Calculate starting log_posterior
     x = x0
     p0 = np.exp(x0)/(1.0 + np.exp(x0))
     log_post = -neg_log_posterior(x) + np.log(p0*(1.0-p0))
     # Run the chain for the specified burn-in length
     for iter in range(n_burnin):
         x, log_post = perform_mh_trial(
            x, log_post, delta_x, neg_log_posterior)
     # Initialize an empty array to hold the sampled 
     # parameter values
     x_chain = np.zeros(n_iter)
     # Continue the chain for the specified number of 
     # sampling points
     # Store the sampled parameter values
     for iter in range(n_iter):
         x, log_post = perform_mh_trial(
            x, log_post, delta_x, neg_log_posterior)
         x_chain[iter] = x
     return x_chain</st></pre></li>				<li><st c="60804">Now, we’ll </st><a id="_idIndexMarker529"/><st c="60816">set the data. </st><st c="60830">Again, in this example we’ll use the values from the left-hand panel of </st><span class="No-Break"><em class="italic"><st c="60902">Figure 5</st></em></span><span class="No-Break"><em class="italic"><st c="60910">.2</st></em></span><span class="No-Break"><st c="60912">:</st></span><pre class="source-code"><st c="60914">
# Specify the sample size and the number of successes
n_trial = 10
n_success = 5
# Specify the parameters of the Beta prior
alpha = 8
beta = 2
# Construct a starting point for the MCMC calculation.
</st><st c="61113"># We'll use the sample success proportion to do this 
# (and take the logit)
p0 = float(n_success)/float(n_trial)
logit_p0 = np.log(p0/(1.0-p0))</st></pre></li>				<li><st c="61256">Now, we’ll</st><a id="_idIndexMarker530"/><st c="61267"> run the MCMC calculation. </st><st c="61294">We’ll run a long burn-in period of 20,000 iterations to be sure, and then we’ll take 1 million samples. </st><st c="61398">Finally, we convert the sampled values of </st><img src="image/2006.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mtext&gt;logit&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:1.797em"/><st c="61440"/><span class="_-----MathTools-_Math_Text"><img src="image/2007.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mtext&gt;logit&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.302em;height:0.870em;width:1.177em"/><st c="61446"/></span><st c="61447"> to values </st><span class="No-Break"><st c="61458">of </st></span><span class="No-Break"><img src="image/2008.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.485em"/><st c="61461"/></span><span class="No-Break"><st c="61462">:</st></span><pre class="source-code"><st c="61463">
# Run the MCMC calculation
x_chain = mh_mcmc(n_burnin=20000,
                  n_iter=1000000,
                  x0=logit_p0,
                  delta_x=0.1,
                  neg_log_posterior=neg_log_posterior)
# Convert the MCMC sampled logit(p) values back to values of
# the success probability
p_mcmc = np.exp(x_chain)/ (1.0 + np.exp(x_chain))</st></pre></li>				<li><st c="61740">Now, let’s look at the histogram of the MCMC sampled success probabilities and compare it to the true posterior curve. </st><st c="61860">The true posterior curve will be the same posterior </st><a id="_idIndexMarker531"/><st c="61912">curve that is shown in the left-hand panel of </st><span class="No-Break"><em class="italic"><st c="61958">Figure 5</st></em></span><span class="No-Break"><em class="italic"><st c="61966">.2</st></em></span><span class="No-Break"><st c="61968">:</st></span><pre class="source-code"><st c="61970">
import matplotlib.pyplot as plt
# Plot the histogram of posterior sampled success probabilities
# and overlay the true posterior distribution
hist = plt.hist(p_mcmc, bins=100, density=True)
posterior = plt.plot(p_sequence, true_posterior_sequence)
plt.title('Histogram of MCMC samples', fontsize=24)
plt.xlabel(r'$p$', fontsize=20)
plt.ylabel('Probability Density', font</st><a id="_idTextAnchor308"/><st c="62341">size=20)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()</st></pre></li>			</ol>
			<div>
				<div id="_idContainer2073" class="IMG---Figure">
					<img src="image/B19496_05_3.jpg" alt="Figure﻿ 5.3: Histogram of MCMC samples and the true posterior"/><st c="62409"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="62441">Figure 5.3: Histogram of MCMC samples and the true posterior</st></p>
			<p><st c="62501">We can see in </st><span class="No-Break"><em class="italic"><st c="62516">Figure 5</st></em></span><em class="italic"><st c="62524">.3</st></em><st c="62526"> how the values of </st><img src="image/2009.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.481em"/><st c="62545"/><st c="62546"> sampled using the Metropolis-Hastings algorithm match the true posterior distribution (the orange curve in </st><span class="No-Break"><em class="italic"><st c="62654">Figure </st></em></span><span class="No-Break"><em class="italic"><st c="62661">5</st></em></span><span class="No-Break"><em class="italic"><st c="62662">.3</st></em></span><span class="No-Break"><st c="62664">) exactly.</st></span></p>
			<p><st c="62675">That was a lengthy code example, and it can be tedious to write the MCMC code yourself. </st><st c="62764">If only it was easier. </st><st c="62787">This brings us neatly on to our next topic, </st><strong class="bold"><st c="62831">probabilistic </st></strong><span class="No-Break"><strong class="bold"><st c="62845">programming languages</st></strong></span><span class="No-Break"><st c="62866">.</st></span></p>
			<h2 id="_idParaDest-167"><a id="_idTextAnchor309"/><st c="62867">Probabilistic programming languages</st></h2>
			<p><st c="62903">In </st><a id="_idIndexMarker532"/><st c="62907">practice, choosing the length of the burn-in period can be a bit of an art form. </st><st c="62988">There are also other variants of MCMC algorithms that are more sophisticated than the basic Metropolis-Hastings rule. </st><st c="63106">Again, these more sophisticated MCMC algorithms can be applied to evaluate the expectation of any function and for any posterior. </st><st c="63236">Due to the wide applicability of these MCMC algorithms, many of them are coded into specialist languages </st><a id="_idIndexMarker533"/><st c="63341">called </st><strong class="bold"><st c="63348">Probabilistic Programming Languages</st></strong><st c="63383">, (</st><strong class="bold"><st c="63386">PPLs</st></strong><st c="63391">). </st><st c="63395">These programming languages allow the user to easily express a probabilistic model and configure the MCMC calculation, and then the PPL takes care of running the MCMC. </st><st c="63563">The main benefit of PPLs is that the user does not have to write any MCMC calculation code. </st><st c="63655">The user only writes code that expresses </st><span class="No-Break"><st c="63696">the model.</st></span></p>
			<p><st c="63706">Since the goal of PPLs is to make Bayesian modeling and inference easy by abstracting away a lot of the technical code that runs the MCMC calculation, many PPLs also make MAP estimation easy. </st><st c="63899">We have already mentioned that the way in which we use MAP estimates is very generic, such as through the analytic approximations to the posterior in Eq. </st><st c="64053">47 and Eq. </st><st c="64064">50. </st><st c="64068">Consequently, most PPLs also provide functionality to obtain MAP estimates without the user having to write additional MAP estimation code. </st><st c="64208">Again, the user only has to write code that expresses </st><span class="No-Break"><st c="64262">the model.</st></span></p>
			<p><st c="64272">As you might have guessed, there are many different PPLs available. </st><st c="64341">Some of the more well-established ones are </st><span class="No-Break"><st c="64384">listed here:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="64396">PyMC</st></strong><st c="64401">: One of the most widely used Python open source PPLs that uses Theano as a backend. </st><st c="64487">Details are available </st><span class="No-Break"><st c="64509">at </st></span><a href="https://www.pymc.io/welcome.html"><span class="No-Break"><st c="64512">https://www.pymc.io/welcome.html</st></span></a><span class="No-Break"><st c="64544">.</st></span></li>
				<li><strong class="bold"><st c="64545">Stan</st></strong><st c="64550">: Probably the other most widely used PPL. </st><st c="64594">Stan has its own model specification language, which is then translated to C++ code that is then compiled to machine code. </st><st c="64717">It is perhaps more widely used within the R programming community, but it has good interfaces to a number of languages, including Python. </st><st c="64855">General details are available at </st><a href="https://mc-stan.org/"><st c="64888">https://mc-stan.org/</st></a><st c="64908">. Details on the Python interface, PyStan, can be found </st><span class="No-Break"><st c="64964">at </st></span><a href="https://pystan.readthedocs.io/en/latest/"><span class="No-Break"><st c="64967">https://pystan.readthedocs.io/en/latest/</st></span></a><span class="No-Break"><st c="65007">.</st></span></li>
				<li><strong class="bold"><st c="65008">Pyro</st></strong><st c="65013">: A PPL created by Uber AI Labs with a PyTorch back-end. </st><st c="65071">Details are available </st><span class="No-Break"><st c="65093">at </st></span><a href="https://pyro.ai/"><span class="No-Break"><st c="65096">https://pyro.ai/</st></span></a><span class="No-Break"><st c="65112">.</st></span></li>
				<li><strong class="bold"><st c="65113">NumPyro</st></strong><st c="65121">: A variant of Pyro that uses a backend based on NumPy and JAX, and so can provide a speedup over Pyro for a subset of model types. </st><st c="65254">Details are available </st><span class="No-Break"><st c="65276">at </st></span><a href="https://num.pyro.ai/en/stable/"><span class="No-Break"><st c="65279">https://num.pyro.ai/en/stable/</st></span></a><span class="No-Break"><st c="65309">.</st></span></li>
			</ul>
			<p><st c="65310">You’ll </st><a id="_idIndexMarker534"/><st c="65318">have spotted that each PPL either makes use of an existing computational backend, such as Theano, PyTorch, TensorFlow, or JAX, or has its own language that ultimately can be compiled to machine code. </st><st c="65518">This computational power is necessary because of the computationally intensive nature of MCMC calculations, and also because PPLs have to be able to handle what can be very complex user-specified probabilistic models. </st><st c="65736">Because of this need for PPLs to have access to a computational backend, they can be trickier to install and set up than, say, your average Python package. </st><st c="65892">However, once you are comfortable with Bayesian modeling concepts and have gone through the pain of installing a PPL, they are very useful and fun to </st><span class="No-Break"><st c="66042">work with.</st></span></p>
			<p><st c="66052">That finishes this subsection on PPLs, so we’ll conclude by summarizing what we have learned about Bayesian modeling in practice, and then we’ll summarize the </st><span class="No-Break"><st c="66212">chapter overall.</st></span></p>
			<h2 id="_idParaDest-168"><a id="_idTextAnchor310"/><st c="66228">What we have learned</st></h2>
			<p><st c="66249">In this section, we have learned </st><span class="No-Break"><st c="66283">the following:</st></span></p>
			<ul>
				<li><st c="66297">How to make simple analytical approximations to the posterior to use in closed-form Bayesian </st><span class="No-Break"><st c="66391">averaging calculations</st></span></li>
				<li><st c="66413">About </st><strong class="bold"><st c="66420">Markov Chain Monte Carlo</st></strong><st c="66444"> (</st><strong class="bold"><st c="66446">MCMC</st></strong><st c="66450">) algorithms and how they can be used to generate samples from a posterior distribution, which then allow us to approximate an expectation over the posterior via a </st><span class="No-Break"><st c="66615">sample mean</st></span></li>
				<li><st c="66626">About </st><strong class="bold"><st c="66633">Probabilistic Programming Languages</st></strong><st c="66668"> (</st><strong class="bold"><st c="66670">PPLs</st></strong><st c="66674">) and how they automate away a lot of the cumbersome and repeated tasks involved in MCMC or MAP </st><span class="No-Break"><st c="66771">estimation calculations</st></span></li>
			</ul>
			<h1 id="_idParaDest-169"><a id="_idTextAnchor311"/><st c="66794">Summary</st></h1>
			<p><st c="66802">This chapter has been a culmination of the many ideas and concepts we have introduced in the previous three chapters. </st><st c="66921">At the heart of this chapter is the idea that because data is random, predictive models that attempt to explain and use that data should be probabilistic. </st><st c="67076">To build probabilistic models, we have had to learn about the probability distributions that describe the data and the distributions that describe the models. </st><st c="67235">Specifically, we have had to learn about </st><span class="No-Break"><st c="67276">the following:</st></span></p>
			<ul>
				<li><st c="67290">Likelihood as the probability of data given </st><span class="No-Break"><st c="67335">a model</st></span></li>
				<li><st c="67342">How to use the likelihood to estimate model parameters via </st><span class="No-Break"><st c="67402">maximum likelihood</st></span></li>
				<li><st c="67420">Bayes’ theorem and about prior and </st><span class="No-Break"><st c="67456">posterior distributions</st></span></li>
				<li><st c="67479">How the posterior distribution quantifies the probability of the model parameters given the data or information we </st><span class="No-Break"><st c="67595">have received</st></span></li>
				<li><st c="67608">How we can use the posterior in Bayesian model averaging, or MAP </st><span class="No-Break"><st c="67674">estimation calculations</st></span></li>
				<li><st c="67697">How to perform those Bayesian model averaging and MAP estimation calculations </st><span class="No-Break"><st c="67776">in practice</st></span></li>
				<li><strong class="bold"><st c="67787">Probabilistic Programming Languages</st></strong><st c="67823"> (</st><strong class="bold"><st c="67825">PPLs</st></strong><st c="67829">) and how they automate a lot of the practical tasks in </st><span class="No-Break"><st c="67886">probabilistic modeling</st></span></li>
			</ul>
			<p><st c="67908">This chapter represents the last of the core math concepts and techniques we cover in this book. </st><st c="68006">This chapter and the preceding three chapters cover what I consider to be the absolute minimum core math concepts and techniques that any data scientist should be familiar with. </st><st c="68184">For the rest of the book, we will get more specialized, covering individual math concepts that tend to be focused on a particular type of data or a particular domain. </st><st c="68351">To start, in the next chapter, we move onto time </st><span class="No-Break"><st c="68400">series data.</st></span></p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor312"/><st c="68412">Exercises</st></h1>
			<p><st c="68422">Here is a series of exercises. </st><st c="68454">Answers to all the exercises are given in the Jupyter </st><strong class="source-inline"><st c="68508">Answers_to_Exercises_Chap5.ipynb</st></strong><st c="68540"> notebook in the </st><span class="No-Break"><st c="68557">GitHub repository:</st></span></p>
			<ol>
				<li><st c="68575">For the MAP estimation code example in the text, we used the </st><strong class="source-inline"><st c="68637">scipy.optimize.minimize</st></strong><st c="68660"> function to do the optimization of the log-posterior. </st><st c="68715">The </st><strong class="source-inline"><st c="68719">minimize</st></strong><st c="68727"> function has the option for the user to supply a callable function that calculates the gradient of the objective function with respect to the objective function parameters. </st><st c="68901">Work out on paper the gradient of the log-posterior and implement a function that returns the gradient of the log-posterior. </st><st c="69026">Re-run the MAP estimation process using </st><strong class="source-inline"><st c="69066">scipy.optimize.minimize</st></strong><st c="69089">, but when you pass in your log-posterior gradient function, you’ll need to look at the online documentation for the </st><strong class="source-inline"><st c="69206">scipy.optimize.minimize</st></strong><st c="69229"> function to see how your callable gradient function should be </st><span class="No-Break"><st c="69292">passed in.</st></span></li>
				<li><st c="69302">The </st><strong class="source-inline"><st c="69307">Data/coffee_or_tea.csv</st></strong><st c="69329"> file in the GitHub repository contains two columns of data, corresponding to 250 days’ worth of observations on what drink I had each morning (tea or coffee) when I was at home, and also whether it rained the night before. </st><st c="69553">The two columns are called </st><strong class="source-inline"><st c="69580">rained</st></strong><st c="69586">, with a value of </st><strong class="source-inline"><st c="69604">1</st></strong><st c="69605"> indicating that it rained the night before (</st><strong class="source-inline"><st c="69650">0</st></strong><st c="69652"> indicating it did not), and </st><strong class="source-inline"><st c="69681">coffee</st></strong><st c="69687">, with a value of </st><strong class="source-inline"><st c="69705">1</st></strong><st c="69706"> indicating that I drank coffee that morning (</st><strong class="source-inline"><st c="69752">0</st></strong><st c="69754"> indicating I drank tea instead). </st><st c="69788">Formulate a probabilistic model (hint – look at the binomial shopper decision example in the text) that models my decision to drink coffee or not, and that uses the </st><strong class="source-inline"><st c="69953">rained</st></strong><st c="69959"> variable as a predictive feature. </st><st c="69994">The linear predictor for the model will take the form, </st><img src="image/2010.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;η&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mtext&gt;rained&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.483em;height:1.194em;width:8.450em"/><st c="70049"/><st c="70074">. Use the </st><strong class="source-inline"><st c="70084">scipy.optimize.minimize</st></strong><st c="70107"> function to obtain maximum likelihood estimates for the model </st><span class="No-Break"><st c="70170">parameters, </st></span><span class="No-Break"><img src="image/2011.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.051em;width:1.946em"/><st c="70182"/></span><span class="No-Break"><st c="70183">.</st></span></li>
				<li><st c="70184">Using a </st><img src="image/2012.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.141em;height:0.789em;width:3.009em"/><st c="70193"/><st c="70194"> prior for both </st><img src="image/2013.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.822em"/><st c="70210"/><st c="70211"> and </st><img src="image/2014.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:0.824em"/><st c="70216"/><st c="70217"> in the model you formulated in Q2, obtain MAP estimates for </st><img src="image/2015.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.745em"/><st c="70278"/><st c="70279"> and </st><img src="image/2016.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:0.745em"/><st c="70284"/><st c="70285"> using the same dataset used </st><span class="No-Break"><st c="70314">in Q2.</st></span></li>
				<li><st c="70320">Using the posterior you developed in Q3, adapt the MCMC code example in the text and obtain 10,000 samples of the tuple </st><img src="image/2017.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.390em;height:1.151em;width:2.587em"/><st c="70441"/><st c="70442">. Plot separate histograms of </st><img src="image/2018.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.681em"/><st c="70472"/><st c="70473"> and </st><img src="image/2019.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:0.769em"/><st c="70478"/><st c="70479"> from those </st><span class="No-Break"><st c="70491">10,000 samples.</st></span></li>
			</ol>
		</div>
	<div id="charCountTotal" value="70506"/>

		<div id="_idContainer2086" class="Content">
			<h1 id="_idParaDest-171" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor313"/><st c="0">Part 2: Intermediate Concepts</st></h1>
			<p><st c="30">In this part, we will introduce you to more math concepts that you are very likely to encounter the longer you work in data science. </st><st c="164">In contrast to Part 1, each chapter is focused on a standalone data science task, modeling technique, or type of data. </st><st c="283">By the end of Part 2, you will have gained a solid understanding of time series data, how to run a hypothesis test, model complexity, how to build up a function from a set of simpler parts, and </st><span class="No-Break"><st c="477">network data.</st></span></p>
			<p><st c="490">This section contains the </st><span class="No-Break"><st c="517">following chapters:</st></span></p>
			<ul>
				<li><a href="B19496_06.xhtml#_idTextAnchor314"><em class="italic"><st c="536">Chapter 6</st></em></a><st c="546">, </st><em class="italic"><st c="548">Time Series and Forecasting</st></em></li>
				<li><a href="B19496_07.xhtml#_idTextAnchor369"><em class="italic"><st c="575">Chapter 7</st></em></a><st c="585">, </st><em class="italic"><st c="587">Hypothesis Testing</st></em></li>
				<li><a href="B19496_08.xhtml#_idTextAnchor406"><em class="italic"><st c="605">Chapter 8</st></em></a><em class="italic"><st c="615">, Model Complexity</st></em></li>
				<li><a href="B19496_09.xhtml#_idTextAnchor449"><em class="italic"><st c="633">Chapter 9</st></em></a><em class="italic"><st c="643">, Function Decomposition</st></em></li>
				<li><a href="B19496_10.xhtml#_idTextAnchor501"><em class="italic"><st c="667">Chapter 10</st></em></a><em class="italic"><st c="678">, Network Analysis</st></em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer2087" class="Basic-Graphics-Frame">
			</div>
		</div>
	<div id="charCountTotal" value="696"/></body></html>