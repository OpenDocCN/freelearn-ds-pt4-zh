- en: <st c="0">7</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2">Hypothesis Testing</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="20">Hypothesis tests</st> <st c="37">are a ubiquitous part of classical
    statistics.</st> <st c="85">They often have a very simple objective, such as testing
    whether two samples of data indicate there is a difference in the means of the
    underlying populations from which those samples were taken.</st> <st c="281">Despite
    the simplicity of these aims and questions, hypothesis tests have very practical
    applications.</st> <st c="384">The question of whether two populations have different
    means is precisely what we ask when running an A/B test to decide whether the
    A variant of an e-commerce site has a higher click-through rate, compared to the
    B variant.</st> <st c="609">As such, hypothesis testing is an important skill
    to master for any data scientist working with real-world data.</st> <st c="722">Despite
    the simplicity of the question that a hypothesis test asks, the mathematical machinery
    needed to run a hypothesis test is full of concepts and nuances that can trip
    up a new data scientist – concepts such as</st> *<st c="938">p</st>*<st c="939">-values,
    degrees of freedom, confidence intervals, Type-I and Type-II errors, and power.</st>
    <st c="1028">To master hypothesis testing, it is essential to get a basic understanding
    of these concepts.</st> <st c="1122">That is what we aim to do in this chapter.</st>
    <st c="1165">We do this by covering the</st> <st c="1192">following topics:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="1209">What a hypothesis test is</st>*<st c="1235">: In this section,
    we will explore how hypothesis tests are structured and how they follow a</st>
    <st c="1329">common pattern</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<st c="1343">Confidence intervals:</st>* <st c="1365">In this section, we
    will see how confidence intervals quantify the uncertainty associated with estimates</st>
    <st c="1471">of parameters</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<st c="1484">Type I and Type II errors, and power</st>*<st c="1521">: Finally,
    will will learn how to pre-compute the sample size necessary to achieve a specified
    false</st> <st c="1623">negative rate</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1636">Technical requirements</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1659">All code examples given in this chapter (and additional examples)
    can be found at the GitHub repository:</st> [<st c="1765">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter07</st>](https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter07)<st
    c="1869">. To run the Jupyter notebooks, you will need a full Python installation
    that includes the</st> <st c="1960">following packages:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="1979">pandas</st>` <st c="1986">(>=2.0.3)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="1996">numpy</st>` <st c="2002">(>=1.24.3)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="2013">scipy</st>` <st c="2019">(>=1.11.1)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="2030">statsmodels</st>` <st c="2042">(>=0.14.0)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2053">What is a hypothesis test?</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2080">A hypothesis test</st> <st c="2099">does exactly what it says it
    does.</st> <st c="2134">It tests a hypothesis.</st> <st c="2157">Typically, the
    hypothesis we test is well formulated and can be simply and precisely expressed
    mathematically.</st> <st c="2268">For example, in a scientific experiment, we
    might want to know whether the average weight of one group of animals is different
    from that of another group of animals.</st> <st c="2434">The hypothesis here can
    be precisely expressed</st> <st c="2481">mathematically as,</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="double-struck">E</mi><mfenced open="(" close=")"><mrow><mtext>weight</mtext><mtext>of</mtext><mtext>animals</mtext><mtext>in</mtext><mtext>group</mtext><mtext>A</mtext></mrow></mfenced><mo>≠</mo><mi
    mathvariant="double-struck">E</mi><mfenced open="(" close=")"><mrow><mtext>weights</mtext><mtext>of</mtext><mtext>animals</mtext><mtext>in</mtext><mtext>group</mtext><mtext>B</mtext></mrow></mfenced></mrow></mrow></math>](img/2351.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="2567">Eq.</st> <st c="2571">1</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2572">Alternatively, we might be interested in knowing whether website
    visitors complete purchases at the same rate on variant A of an e-commerce site
    compared to variant B of the website.</st> <st c="2755">In this case, the hypothesis
    can be</st> <st c="2791">expressed as,</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced separators=""><mml:mrow><mml:mtext>Click-Through Rate for site A</mml:mtext></mml:mrow></mml:mfenced><mml:mo>≠</mml:mo><mml:mo> </mml:mo><mml:mi
    mathvariant="double-struck">E</mml:mi><mml:mfenced separators=""><mml:mrow><mml:mtext>Click-Through Rate for site B</mml:mtext></mml:mrow></mml:mfenced></mml:math>](img/2352.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="2874">Eq.</st> <st c="2878">2</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2879">Note that in both these hypotheses, the mathematical expression
    is in terms of the expectation.</st> <st c="2975">In other words, we want to test
    the hypothesis at the level of populations, not for a finite sample of the A and
    B populations.</st> <st c="3103">In the e-commerce example, we want to know that
    if everybody in our target population were to visit variant A of our website,
    would we get the same volume of purchases compared to if we had deployed variant
    B of the site.</st> <st c="3325">If we use</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2353.png)
    <st c="3335"><st c="3336">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2354.png)
    <st c="3341"><st c="3342">to denote the population mean click-through rate for
    site A and site B, respectively, then the hypothesis in Eq.</st> <st c="3456">2
    is the same</st> <st c="3470">as asking,</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>?</mml:mo></mml:math>](img/2355.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="3489">Eq.</st> <st c="3493">3</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3494">However, we usually only have data from a sample of the A and B
    populations available to us, so we can only calculate sample means.</st> <st c="3626">If
    we denote the sample means</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2356.png)
    <st c="3656"><st c="3657">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2357.png)<st
    c="3662"><st c="3663">, then the equivalent comparison to Eq.</st> <st c="3703">3
    is,</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>?</mml:mo></mml:math>](img/2358.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="3717">Eq.</st> <st c="3721">4</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3722">The</st> <st c="3726">problem is that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2359.png)
    <st c="3742"><st c="3743">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2360.png)
    <st c="3748"><st c="3749">are calculated from data, so they have random components.</st>
    <st c="3808">Those random components mean that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2356.png)
    <st c="3842"><st c="3843">could be different from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2357.png)
    <st c="3868"><st c="3869">just by chance, due to the random variation of the sample
    means.</st> <st c="3935">Consequently, we could have Eq.</st> <st c="3967">4 as
    true even if Eq.</st> <st c="3989">3 isn’t.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3997">What do we do?</st> <st c="4013">Do we just give up on using the
    sample means</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2363.png)
    <st c="4058"><st c="4059">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2364.png)
    <st c="4064"><st c="4065">to test the hypothesis in Eq.</st> <st c="4096">3?</st>
    <st c="4099">No.</st> <st c="4103">Since we can’t ask the question in Eq.</st>
    <st c="4142">3 directly, we will embrace the uncertainty inherent in</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2363.png)
    <st c="4198"><st c="4199">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2364.png)
    <st c="4204"><st c="4205">and take a statistical approach to asking the question
    in</st> <st c="4264">Eq.</st> <st c="4268">3.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4270">We will use our understanding from</st> [*<st c="4306">Chapter
    2</st>*](B19496_02.xhtml#_idTextAnchor061) <st c="4315">to quantify how frequently
    Eq.</st> <st c="4347">4 is true when Eq.</st> <st c="4366">3 isn’t.</st> <st c="4375">Doing
    so will allow us to assess whether an observation that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2367.png)
    <st c="4436"><st c="4437">provides evidence for the</st> <st c="4464">hypothesis</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>≠</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2368.png)<st
    c="4475"><st c="4476">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4477">Example</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="4485">We’ll give a</st> <st c="4498">slightly contrived example, but
    one which will help unpack how we use the statistical ideas from</st> [*<st c="4596">Chapter
    2</st>*](B19496_02.xhtml#_idTextAnchor061) <st c="4605">to assess the evidence
    contained in the values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2363.png)
    <st c="4656"><st c="4657">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2364.png)<st
    c="4661"><st c="4662">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4663">Imagine we have two samples of data, an A sample and a B sample,
    of sizes</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2371.png)
    <st c="4738"><st c="4739">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2372.png)<st
    c="4744"><st c="4745">, respectively.</st> <st c="4761">These could be the two
    datasets of observations of whether visitors to our e-commerce website made a
    purchase.</st> <st c="4872">The following provides more details on each of those</st>
    <st c="4925">two samples:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="4937">Sample A</st>**<st c="4946">:</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math>](img/2373.png)
    <st c="4949"><st c="4958">observations.</st> <st c="4972">Each observation is
    from a Gaussian random variable that has a mean</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>=</mo><mn>0.5</mn></mrow></mrow></math>](img/2374.png)<st
    c="5040"><st c="5041">and variance</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/2375.png)
    <st c="5054"><st c="5055">– that is, sample A is of 100 i.i.d.</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>l</mi><mfenced
    open="(" close=")"><mrow><mn>0.5</mn><mo>,</mo><mn>1</mn></mrow></mfenced></mrow></mrow></math>](img/2376.png)
    <st c="5093"><st c="5108">random variables.</st> <st c="5126">The sample mean
    of those 100 observations</st> <st c="5168">is</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.529</mml:mn></mml:math>](img/2377.png)<st
    c="5171"><st c="5181">.</st></st></st></st></st></st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="5182">Sample B</st>**<st c="5191">:</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math>](img/2378.png)
    <st c="5194"><st c="5204">observations.</st> <st c="5218">Each observation is
    from a Gaussian random variable that has a mean</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math>](img/2379.png)
    <st c="5286"><st c="5287">and variance</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/2380.png)
    <st c="5301"><st c="5302">– that is, sample B is of 100 i.i.d.</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>l</mi><mfenced
    open="(" close=")"><mrow><mn>0.1</mn><mo>,</mo><mn>1</mn></mrow></mfenced></mrow></mrow></math>](img/2381.png)
    <st c="5340"><st c="5355">random variables.</st> <st c="5373">The sample mean
    of those 100 observations</st> <st c="5415">is</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.176</mml:mn></mml:math>](img/2382.png)<st
    c="5418"><st c="5429">.</st></st></st></st></st></st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="5430">Let’s highlight a</st> <st c="5448">couple of things about our</st>
    <st c="5476">two samples:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5488">Firstly, to simplify the explanation, we have said our observations
    come from Gaussian random variables, so those observations could be anywhere between</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>-</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/439.png)
    <st c="5642"><st c="5643">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/2384.png)<st
    c="5648"><st c="5649">. This is not realistic for a click-through rate, but we
    mainly used the e-commerce example as a way of demonstrating why hypothesis testing
    is a relevant concept to</st> <st c="5815">know about.</st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="5826">Secondly, we know what the values of the population variances</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2385.png)
    <st c="5889"><st c="5890">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2386.png)
    <st c="5895"><st c="5896">are.</st> <st c="5902">In this example, they have a
    common value,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/1828.png)<st
    c="5945"><st c="5948">, which we have set equal to 1\.</st> <st c="5980">In real
    life, we won’t know the values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2388.png)
    <st c="6022"><st c="6023">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2389.png)<st
    c="6028"><st c="6029">. In real life, we can use the sample variances,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2390.png)
    <st c="6078"><st c="6079">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2391.png)<st
    c="6084"><st c="6085">, as estimates of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2385.png)
    <st c="6103"><st c="6104">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2389.png)<st
    c="6109"><st c="6110">. Alternatively, for simplicity, we can still assume that</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2385.png)
    <st c="6168"><st c="6169">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2389.png)
    <st c="6174"><st c="6175">have a common value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/1828.png)<st
    c="6196"><st c="6199">, and we can use the sample variances</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2397.png)
    <st c="6237"><st c="6238">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2398.png)
    <st c="6243"><st c="6244">to construct an estimate of this common value,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2399.png)<st
    c="6292"><st c="6295">. We will return later to explain the implications of only
    knowing the</st> <st c="6366">sample variances.</st></st></st></st></st></st></st></st></st></st></st></st></st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="6383">Now, if we didn’t know the values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2353.png)
    <st c="6421"><st c="6422">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2354.png)
    <st c="6427"><st c="6428">we could start our analysis by assuming that</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2402.png)
    <st c="6474"><st c="6475">and proceed from there.</st> <st c="6500">If we compare
    the sample means by calculating</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2403.png)<st
    c="6546"><st c="6547">, we get 0.529 – 0.176 = 0.353\.</st> <st c="6579">Superficially,
    it looks like the mean of group A is different from the mean of group B.</st>
    <st c="6667">This is surprising, particularly since we started with the assumption
    that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2404.png)<st
    c="6742"><st c="6743">. Does this provide evidence that our starting assumption
    is incorrect and in fact</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2405.png)<st
    c="6826"><st c="6827">? We also note that it is the magnitude of the difference
    between</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2406.png)
    <st c="6893"><st c="6894">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2407.png)
    <st c="6899"><st c="6900">that surprises us.</st> <st c="6920">We would have been
    equally surprised if</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>=</mo><mo>−</mo><mn>0.353</mn></mrow></mrow></math>](img/2408.png)<st
    c="6960">![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>=</mo><mo>−</mo><mn>0.353</mn></mrow></mrow></math>](img/2409.png)<st
    c="6961"><st c="6974">. What we want to know is how probable is a value of 0.353
    or larger for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:math>](img/2410.png)
    <st c="7047"><st c="7048">if there is, in fact, no difference between</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2411.png)
    <st c="7093"><st c="7094">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2412.png)<st
    c="7099"><st c="7100">. To calculate this, we need to work out the probability
    distribution of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2413.png)
    <st c="7173"><st c="7174">when</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2402.png)<st
    c="7180"><st c="7181">. How do we do this?</st> <st c="7202">Read on.</st></st></st></st></st></st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7210">Both</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2363.png)
    <st c="7216"><st c="7217">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2364.png)
    <st c="7222"><st c="7223">are sums of Gaussian random variables because they are
    means of our data values, which we have said are i.i.d.</st> <st c="7335">Normal.</st>
    <st c="7343">A key fact about Gaussian random variables is that when you add two
    or more Gaussian random variables, you get another Gaussian random variable.</st>
    <st c="7488">This</st> <st c="7492">makes both</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2417.png)
    <st c="7504"><st c="7505">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2418.png)
    <st c="7510"><st c="7511">Gaussian random variables.</st> <st c="7539">Since</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2419.png)
    <st c="7545"><st c="7546">is simply another sum, this means that</st> ![<math
    xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2420.png)<st
    c="7586">![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2421.png)
    <st c="7587"><st c="7588">is also a Gaussian random variable.</st> <st c="7625">Remember
    from</st> [*<st c="7639">Chapter 2</st>*](B19496_02.xhtml#_idTextAnchor061) <st
    c="7648">that a Gaussian random variable is characterized entirely by its mean
    and variance.</st> <st c="7733">That implies that once we know</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi
    mathvariant="double-struck">E</mi><mfenced open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced></mrow></mrow></math>](img/2422.png)
    <st c="7764"><st c="7772">and</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext>Var</mtext><mfenced
    open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced></mrow></mrow></math>](img/2423.png)<st
    c="7776"><st c="7791">, we know everything there is to know about the distribution</st>
    <st c="7852">of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2424.png)<st
    c="7855"><st c="7856">.</st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7857">What are the values of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi
    mathvariant="double-struck">E</mi><mfenced open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced></mrow></mrow></math>](img/2425.png)
    <st c="7881"><st c="7889">and</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext>Var</mtext><mfenced
    open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced></mrow></mrow></math>](img/2426.png)<st
    c="7893"><st c="7908">? We can use the rules established in</st> [*<st c="7946">Chapter
    2</st>*](B19496_02.xhtml#_idTextAnchor061) <st c="7955">to do this.</st> <st c="7968">If
    we write out</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2424.png)
    <st c="7984"><st c="7985">in full</st> <st c="7994">we have,</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mi>A</mi></msub></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>A</mi></msub></munderover><msub><mi>x</mi><mi>i</mi></msub></mrow><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mi>B</mi></msub></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>B</mi></msub></munderover><msub><mi>y</mi><mi>i</mi></msub></mrow></mrow></mrow></math>](img/2428.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>~</mo><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>l</mi><mfenced
    open="(" close=")"><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>,</mo><msubsup><mi>σ</mi><mi>A</mi><mn>2</mn></msubsup></mrow></mfenced><mtext>for</mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>N</mi><mi>A</mi></msub><msub><mi>y</mi><mi>i</mi></msub><mo>~</mo><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>l</mi><mfenced
    open="(" close=")"><mrow><msub><mi>μ</mi><mi>B</mi></msub><mo>,</mo><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup></mrow></mfenced><mtext>for</mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>N</mi><mi>B</mi></msub></mrow></mrow></math>](img/2429.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="8081">Eq.</st> <st c="8085">5</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8086">Using this long-hand definition of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2424.png)
    <st c="8121"><st c="8122">and the distributions of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/105.png)
    <st c="8148"><st c="8149">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1521.png)<st
    c="8154"><st c="8155">,</st> <st c="8157">we have,</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mi
    mathvariant="double-struck">E</mml:mi><mml:mfenced separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mi
    mathvariant="double-struck">E</mml:mi><mml:mfenced separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo></mml:math>](img/2433.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="8167">Eq.</st> <st c="8171">6</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8172">With our starting assumption that</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>=</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2434.png)<st
    c="8206"><st c="8207">,</st> *<st c="8209">Eq.</st> <st c="8213">6</st>* <st c="8214">tells
    us that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi
    mathvariant="double-struck">E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>](img/2435.png)<st
    c="8229"><st c="8232">. Since the observations are independent of each other,
    a similar</st> <st c="8298">calculation gives,</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>Var</mml:mtext><mml:mfenced separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mtext>Var</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mtext>Var</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo> </mml:mo></mml:math>](img/2436.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="8367">Eq.</st> <st c="8371">7</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8372">Note how the variance of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2424.png)
    <st c="8397"><st c="8398">gets smaller as we increase either</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2371.png)
    <st c="8434"><st c="8435">or</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2372.png)
    <st c="8439"><st c="8440">in</st> *<st c="8444">Eq.</st> <st c="8448">7</st>*<st
    c="8449">.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8450">Now, we want to calculate the probability of getting a value of
    0.353 or larger for</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>|</mo><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>|</mo></mrow></mrow></mrow></math>](img/2440.png)
    <st c="8535"><st c="8541">– that is, to calculate the probability</st> ![<math
    xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>P</mi><mfenced open="("
    close=")"><mrow><mfenced open="|" close="|"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced><mo>≥</mo><mn>0.353</mn></mrow></mfenced></mrow></mrow></math>](img/2441.png)<st
    c="8581"><st c="8602">. We can split this into two</st> <st c="8631">separate
    contributions:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>P</mi><mfenced
    open="(" close=")"><mrow><mfenced open="|" close="|"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced><mo>≥</mo><mn>0.353</mn></mrow></mfenced><mo>=</mo><mi>P</mi><mfenced
    open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>≤</mo><mo>−</mo><mn>0.353</mn></mrow></mfenced><mo>+</mo><mi>P</mi><mfenced
    open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>≥</mo><mn>0.353</mn></mrow></mfenced></mrow></mrow></math>](img/2442.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="8718">Eq.</st> <st c="8722">8</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8723">Since we know</st> <st c="8737">the mathematical expression for
    the probability density of a Gaussian random variable, this probability can be
    written as</st> <st c="8859">the integral:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mfenced separators=""><mml:mrow><mml:mfenced
    open="|" close="|" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>≥</mml:mo><mml:mn>0.353</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mtext>Var</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:msqrt></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∫</mml:mo><mml:mrow><mml:mn>0.353</mml:mn></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mtext>exp</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mtext>Var</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo> </mml:mo><mml:mi>d</mml:mi><mml:mi>u</mml:mi><mml:mo> </mml:mo></mml:math>](img/2443.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="8954">Eq.</st> <st c="8958">9</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8959">The integral in</st> *<st c="8975">Eq.</st> <st c="8979">9</st>*
    <st c="8980">just adds up (integrates) all the probability contributions where
    |</st>![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>|</mo><mo>≥</mo><mn>0.353</mn></mrow></mrow></mrow></math>](img/2444.png)<st
    c="9048"><st c="9063">. The probability contributions are just the probability
    density function of a Gaussian distribution, with a mean of zero and variance</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext>Var</mtext><mfenced
    open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced></mrow></mrow></math>](img/2445.png)<st
    c="9198"><st c="9213">. The integral in</st> *<st c="9231">Eq.</st> <st c="9235">9</st>*
    <st c="9236">is such a common one that we have a special mathematical function
    or symbol for it.</st> *<st c="9321">Eq.</st> <st c="9325">9</st>* <st c="9326">can
    be evaluated</st> <st c="9343">in terms of the</st> **<st c="9360">error function</st>**
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>erf(</mml:mtext><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:math>](img/2446.png)<st
    c="9374"><st c="9382">, which is</st> <st c="9393">defined as,</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>erf</mtext><mfenced
    open="(" close=")"><mi>z</mi></mfenced><mo>=</mo><mfrac><mn>2</mn><msqrt><mi>π</mi></msqrt></mfrac><mrow><munderover><mo>∫</mo><mrow><mo>−</mo><mi
    mathvariant="normal">∞</mi></mrow><mi>z</mi></munderover><mrow><msup><mi>e</mi><mrow><mo>−</mo><msup><mi>t</mi><mn>2</mn></msup></mrow></msup><mi>d</mi><mi>t</mi></mrow></mrow></mrow></mrow></math>](img/2447.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="9430">Eq.</st> <st c="9434">10</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9436">The shape of the error function is plotted in</st> *<st c="9483">Figure
    7</st>**<st c="9491">.1</st>*<st c="9493">. For visual guidance, we have added
    dashed horizontal lines at 0, 0.5, and 1 and a dashed vertical line at 0.5 to</st>
    <st c="9608">the p</st><st c="9613">lot.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_07_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="9638">Figure 7.1: The shape of the error function, erf(z).</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9690">Using this</st> <st c="9702">definition of the error function,
    we can write</st> *<st c="9749">Eq.</st> <st c="9753">9</st>*<st c="9754">, and
    hence the probability of getting a value of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>|</mo><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>|</mo></mrow></mrow></mrow></math>](img/2440.png)
    <st c="9804"><st c="9810">of 0.353 or</st> <st c="9822">larger, as,</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mfenced separators=""><mml:mrow><mml:mfenced
    open="|" close="|" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>≥</mml:mo><mml:mn>0.353</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:mtext>erf</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mn>0.353</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mtext>2Var</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:math>](img/2449.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="9878">Eq.</st> <st c="9882">11</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9884">Using the expression in</st> *<st c="9909">Eq.</st> <st c="9913">7</st>*
    <st c="9914">and the fact that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2450.png)<st
    c="9933"><st c="9934">, we can simplify</st> *<st c="9952">Eq.</st> <st c="9956">11</st>*
    <st c="9958">to get,</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mfenced separators=""><mml:mrow><mml:mfenced
    open="|" close="|" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>≥</mml:mo><mml:mn>0.353</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:mtext>erf</mml:mtext><mml:mfenced
    separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mn>0.353</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>σ</mml:mi><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:math>](img/2451.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="10001">Eq.</st> <st c="10005">12</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10007">Plugging the values</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>=</mo><msub><mi>N</mi><mi>B</mi></msub><mo>=</mo><mn>100</mn></mrow></mrow></math>](img/2452.png)
    <st c="10028"><st c="10039">and</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>=</mo><mn>1</mn></mrow></mrow></math>](img/2453.png)<st
    c="10043"><st c="10050">into</st> *<st c="10055">Eq.</st> <st c="10059">12</st>*
    <st c="10061">and using the</st> `<st c="10076">SciPy</st>` <st c="10081">implementation
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>erf</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/2454.png)<st
    c="10100"><st c="10107">, we get the value 0.01256\.</st> <st c="10135">It looks
    like we get a value of 0.353 or larger for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:math>](img/2455.png)
    <st c="10187"><st c="10194">less that 1.3% of the time if</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2456.png)<st
    c="10224"><st c="10225">. This is a low percentage, so while it is possible that
    the value of 0.353 that we observed for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2457.png)
    <st c="10322"><st c="10323">is just due to chance, can we believe we’ve been that
    unlucky and were part of that 1.3%?</st> <st c="10414">In this case, we don’t
    we can.</st> <st c="10445">I think 0.01256 is a sufficiently low enough probability
    for me to doubt the starting assumption that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2458.png)<st
    c="10547"><st c="10548">. Consequently, I reject the starting assumption that</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2402.png)<st
    c="10602"><st c="10603">, and I believe that my data provides evidence</st> <st
    c="10650">that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2460.png)<st
    c="10655"><st c="10656">.</st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10657">For the</st> <st c="10665">preceding calculation, we used the
    fact that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2461.png)
    <st c="10711"><st c="10712">is Gaussian-distributed to transform the calculation
    to one involving the standard Normal distribution</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo>)</mml:mo></mml:math>](img/2462.png)<st
    c="10816"><st c="10817">. Since the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi></mml:math>](img/22.png)
    <st c="10829"><st c="10830">symbol is commonly used for a random variable that
    is distributed according to the standard Normal distribution, the type of hypothesis
    test we have just performed is</st> <st c="10997">called</st> <st c="11005">a</st>
    **<st c="11007">z-test</st>**<st c="11013">.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11014">The wrinkle here is that usually we don’t know the population
    variance of our measured quantity</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2464.png)<st
    c="11111"><st c="11112">, and we use sample variances instead, which complicates
    the matter.</st> <st c="11181">Don’t worry, we’ll explain how we</st> <st c="11215">solve
    this complication when we introduce the</st> **<st c="11261">t-test</st>**<st
    c="11267">. While using a z-test and assuming we know the population variances</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msubsup><mi>σ</mi><mi>A</mi><mn>2</mn></msubsup><mo>=</mo><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo>=</mo><msup><mi>σ</mi><mn>2</mn></msup></mrow></mrow></math>](img/2465.png)
    <st c="11336"><st c="11337">is unrealistic, it has allowed us to simplify the
    introductory example and explanation of what a hypothesis test is.</st> <st c="11455">We
    shall make use of the z-test again for explanatory purposes later on in the chapter;
    however, be aware that, in reality, it is unlikely that you would ever perform
    a z-test on a</st> <st c="11636">real dataset.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11649">From the preceding discussion, it should be becoming clear that
    what we have are two hypotheses – one, such as that in</st> *<st c="11769">Eq.</st>
    <st c="11773">3</st>*<st c="11774">, that we are interested in understanding whether
    there is any evidence for from the data, and an opposite hypothesis that we use
    to process that evidence.</st> <st c="11930">In fact, all hypothesis tests essentially
    take this form – so much so that we can layout a general “recipe” to perform any
    hypothesis test.</st> <st c="12070">We will do</st> <st c="12081">this next.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12091">The general form of a hypothesis test</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="12129">We can boil</st> <st c="12142">any hypothesis test down to a small
    number of steps,</st> <st c="12195">as follows:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12206">Recipe for a hypothesis test</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12235">1\.</st> <st c="12239">Define the mutually exclusive hypotheses
    about the population that we want to decide between.</st> <st c="12333">These
    hypotheses are called</st> <st c="12361">the</st> **<st c="12365">null hypothesis</st>**
    <st c="12380">(denoted</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/2466.png)<st
    c="12390"><st c="12391">) and</st> <st c="12397">the</st> **<st c="12401">alternative
    hypothesis</st>** <st c="12423">(denoted</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/2467.png)<st
    c="12433"><st c="12434">).</st> <st c="12437">Usually, the alternative hypothesis
    is the one we’re interested in and represents an interesting outcome.</st> <st
    c="12543">By contrast, the null hypothesis corresponds to</st> <st c="12591">uninteresting
    behavior.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12614">2\.</st> <st c="12618">Define a metric that, when applied to population
    quantities, can distinguish the null hypothesis from the</st> <st c="12724">alternative
    hypothesis.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12747">3\.</st> <st c="12751">Calculate the value of the metric using
    the corresponding sample quantities.</st> <st c="12828">This is called the</st>
    <st c="12847">test statistic.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12862">4\.</st> <st c="12866">Calculate the probability of getting a
    value of the test statistic equal to or larger than the observed test-statistic
    value, if the null hypothesis</st> <st c="13015">were true.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13025">5\.</st> <st c="13029">If the calculated probability is sufficiently
    small, then reject the null hypothesis and accept the alternative hypothesis.</st>
    <st c="13153">Conversely, if the calculated probability is not sufficiently small,
    then accept the</st> <st c="13238">null hypothesis.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13254">We’ll leave what we mean by “sufficiently small” in</st> *<st
    c="13307">step 5</st>* <st c="13313">until the next section.</st> <st c="13338">For
    now, we’ll expand upon</st> *<st c="13365">steps 1–4</st>*<st c="13374">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13375">In our</st> <st c="13383">previous explanatory example, the metric
    we used was the difference between the means of the two A and B groups.</st> <st
    c="13496">When applied to the population means, this metric is equal to</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2468.png)<st
    c="13558"><st c="13559">, and so is zero if the null hypothesis is true and non-zero
    if the alternative hypothesis is true.</st> <st c="13659">It is common to define
    a test-statistic in this way, in which it has a value of zero for the null hypothesis
    and is non-zero for the alternative hypothesis.</st> <st c="13816">For our example,
    the metric applied to sample quantities then becomes</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2469.png)<st
    c="13886"><st c="13887">, and being calculated from sample quantities, it is now
    a random variable and has a</st> <st c="13972">probability distribution.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="13997">Step 4</st>* <st c="14004">is often the trickiest part of a
    hypothesis test.</st> <st c="14055">We can calculate the probability in</st> *<st
    c="14091">step 4</st>* <st c="14097">if we know the probability distribution of
    the test statistic, but working out the mathematical equation for the distribution
    of a test statistic can often be an advanced mathematical calculation.</st> <st
    c="14295">That is why we used a very simplified and contrived example previously,
    making</st> *<st c="14374">step 4</st>* <st c="14380">achievable using only the
    math that we’ve introduced so far in the book.</st> <st c="14454">Until the advent
    of intensive computational methods, the only way that the probability distribution
    for a given test statistic could be worked out was if some clever mathematician/statistician
    managed to do so.</st> <st c="14665">This meant that the number of different test
    statistics available for use was limited, and new test statistics and their corresponding
    probability distributions were topics of academic research.</st> <st c="14860">Later,
    we’ll touch briefly upon computational methods to calculate the probabilities
    associated with any test statistic.</st> <st c="14981">For now, let’s return to</st>
    *<st c="15006">step 5</st>*<st c="15012">.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15013">The p-value</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="15025">The</st> <st c="15030">probability we calculate in</st> *<st c="15058">step
    4</st>* <st c="15064">is called the</st> **<st c="15079">p-value</st>**<st c="15086">.
    The</st> *<st c="15092">p</st>*<st c="15093">-value</st> <st c="15099">is the
    probability of getting a value of the test statistic equal to or larger than that
    observed in the data, if the null hypothesis were true.</st> <st c="15245">For
    our example in</st> *<st c="15264">Eq.</st> <st c="15268">12</st>*<st c="15270">,
    when carrying out</st> *<st c="15290">step 5</st>*<st c="15296">, we decided that
    the calculated</st> *<st c="15329">p</st>*<st c="15330">-value was sufficiently
    small enough for us to reject the</st> <st c="15388">null hypothesis.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15404">But how did we decide that the</st> *<st c="15436">p</st>*<st
    c="15437">-value in this instance was sufficiently small?</st> <st c="15485">What
    threshold did we compare it to, and who gets to choose that threshold?</st> <st
    c="15561">The threshold we compare the</st> *<st c="15590">p</st>*<st c="15591">-value
    to is usually denoted by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)<st
    c="15623"><st c="15624">. The value chosen for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="15647"><st c="15648">is subjective.</st> <st c="15664">You are free to
    set it to whatever value between 0 and 1 you think is appropriate.</st> <st c="15747">Commonly
    used values are 0.05, 0.01, and 0.001\.</st> <st c="15795">Sometimes,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="15806"><st c="15807">is referred to in percentage terms, so the commonly
    used values are 5%, 1%, and 0.1%.</st> <st c="15894">Of these commonly used values
    for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="15928"><st c="15929">, 0.05 is the most prevalent, and that is the threshold
    I decided to use in</st> <st c="16005">my example.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16016">When the</st> *<st c="16026">p</st>*<st c="16027">-value is below
    our chosen threshold, we say that the test statistic is “statistically significant.”
    For our little example, we would say that there is “a statistically significant
    difference between the sample means of the two groups.” Because a statistically
    significant finding can represent a potentially important scientific discovery,
    there is in many fields an unhealthy fixation on just the</st> *<st c="16426">p</st>*<st
    c="16427">-value (and whether it is statistically significant) when performing
    hypothesis tests, leading to both misunderstanding of what</st> *<st c="16555">p</st>*<st
    c="16556">-values represent and also an unethical data analysis practice, known
    as “</st>*<st c="16630">p</st>*<st c="16632">-hacking,” whereby the analysis process
    is continually adjusted and changed until a statistically significant result is
    obtained.</st> <st c="16762">At the heart of these problems is a poor understanding
    of what the</st> *<st c="16829">p</st>*<st c="16830">-value and the threshold</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="16855"><st c="16856">represent.</st> <st c="16868">To counter this and
    to help you avoid these common mistakes, we’ll dig further</st> <st c="16947">into
    them.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16957">What the p-value does and does not represent</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="17002">We use the calculated</st> *<st c="17025">p</st>*<st c="17026">-value
    to reject or accept the null hypothesis.</st> <st c="17074">This does not mean
    the</st> *<st c="17097">p</st>*<st c="17098">-value is the probability that the
    null hypothesis is true.</st> <st c="17158">Similarly, 1 –</st> *<st c="17173">p</st>*<st
    c="17174">-value is not the probability that the alternative hypothesis is true.</st>
    <st c="17245">Both these viewpoints are common misconceptions of what the</st>
    *<st c="17305">p</st>*<st c="17306">-value represents.</st> <st c="17325">Nor
    is the</st> *<st c="17336">p</st>*<st c="17337">-value the probability that the
    data was generated by</st> <st c="17391">chance alone.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17404">Misconceptions</st> <st c="17419">about</st> *<st c="17426">p</st>*<st
    c="17427">-values are so prevalent and problematic that the</st> **<st c="17477">American
    Statistical Association</st>** <st c="17509">(</st>**<st c="17511">ASA</st>**<st
    c="17514">) felt it necessary in 2016 to take the highly unusual step of issuing
    explicit statements and guidance about</st> *<st c="17625">p</st>*<st c="17626">-values
    in the form of</st> <st c="17649">six principles.</st> <st c="17665">The principles
    are well worth a read.</st> <st c="17703">You can find a link to the principles
    in the</st> *<st c="17748">Notes and further reading</st>* <st c="17773">section
    at the end of this chapter.</st> <st c="17810">We can’t cover all the principles
    here, but the overall ethos of the ASA statement can be summarized</st> <st c="17911">as
    follows:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17922">You need to understand what a</st> *<st c="17953">p</st>*<st c="17954">-value
    represents</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="17971">Decisions made on applying arbitrary and subjective thresholds
    to</st> *<st c="18038">p</st>*<st c="18039">-values will always have problems,
    particularly when a</st> *<st c="18094">p</st>*<st c="18095">-value is close to</st>
    <st c="18114">a threshold</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="18125">Don’t only use the</st> *<st c="18145">p</st>*<st c="18146">-value
    to assess the support that a dataset gives toward a hypothesis</st> <st c="18216">or
    conclusion</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="18229">Despite the problems and issues with</st> *<st c="18267">p</st>*<st
    c="18268">-values, they are so entwined with the whole process of hypothesis testing
    that they are not going to disappear anytime soon.</st> <st c="18394">It is, therefore,
    important that you have a good understanding of what they are, what they are not,
    what affects them, and how we</st> <st c="18524">control them.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18537">What the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi mathvariant="bold-italic">α</mml:mi></mml:math>](img/2475.png)
    <st c="18547"><st c="18548">threshold represents</st></st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="18569">The</st> *<st c="18574">p</st>*<st c="18575">-value</st> <st c="18582">definition
    means that if the null hypothesis is true, the probability of getting a</st> *<st
    c="18665">p</st>*<st c="18666">-value less than</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi></mml:math>](img/2236.png)
    <st c="18683"><st c="18684">is</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi></mml:math>](img/2236.png)<st
    c="18688"><st c="18689">. So, even when the null hypothesis is true, there is
    a probability of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2478.png)
    <st c="18760"><st c="18761">of getting a</st> *<st c="18775">p</st>*<st c="18776">-value
    below</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2479.png)
    <st c="18789"><st c="18790">and consequently rejecting the null hypothesis.</st>
    <st c="18839">Firstly, this should emphasize to you the point that a hypothesis
    test can produce a false positive.</st> <st c="18940">Secondly, the false positive
    rate is, in fact,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="18987"><st c="18988">. Since we set</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="19003"><st c="19004">, we control the false positive rate.</st> <st c="19042">Now
    that we have a feel for what</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)
    <st c="19075"><st c="19076">represents, we have a better feel for how to set its
    value.</st> <st c="19137">A value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2483.png)
    <st c="19148"><st c="19149">corresponds to a 1-in-20 chance of a false positive.</st>
    <st c="19203">If the downside consequences of a false positive are severe (e.g.,
    life-changing), you might not think a 1-in-20 chance is that low.</st> <st c="19336">Typically,
    when the ramifications of rejecting the null hypothesis are substantial or noteworthy,
    we set the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="19454"><st c="19455">very small.</st> <st c="19468">For example, the discovery
    of new sub-atomic particles is based upon a hypothesis test.</st> <st c="19556">The
    threshold for declaring that a new particle has been discovered is set at what
    is termed “five-sigma.” This corresponds to</st> <st c="19683">setting</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>≅</mml:mo><mml:mn>2.87</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:math>](img/2485.png)<st
    c="19691"><st c="19692">.</st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19693">If we do set</st> <st c="19707">a very low value for the threshold</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="19742"><st c="19743">, are we in danger of setting too stringent a threshold
    that it is impossible to pass?</st> <st c="19830">At this stage, it is worth looking
    at what factors affect</st> <st c="19888">the</st> *<st c="19892">p</st>*<st c="19893">-value.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19900">The effect of increasing sample size</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="19937">Let’s</st> <st c="19944">return to</st> *<st c="19954">Eq.</st>
    <st c="19958">12</st>*<st c="19960">, as it helps us to highlight another important
    aspect of hypothesis testing.</st> <st c="20038">You’ll see from</st> *<st c="20054">Eq.</st>
    <st c="20058">7</st>* <st c="20059">that the variance of the test statistic in
    our example decreases as we increase either sample size</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2487.png)
    <st c="20159"><st c="20160">or</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2372.png)<st
    c="20164"><st c="20165">. In general, this should be true of any appropriately
    designed test statistic.</st> <st c="20245">For our example in</st> *<st c="20264">Eq.</st>
    <st c="20268">12</st>*<st c="20270">, the argument of the error function is our
    test statistic</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2424.png)
    <st c="20329"><st c="20330">divided by the square-root of the variance in</st>
    *<st c="20377">Eq.</st> <st c="20381">7</st>*<st c="20382">. With that variance
    decreasing as we increase either sample size, we can see that increasing the sample
    size has the effect of increasing the size of the argument in the error function.</st>
    <st c="20569">From the plot in</st> *<st c="20586">Figure 7</st>**<st c="20594">.1</st>*<st
    c="20596">, you can see that</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext>erf</mtext><mfenced
    open="(" close=")"><mi>z</mi></mfenced><mo>→</mo><msup><mn>1</mn><mo>−</mo></msup></mrow></mrow></math>](img/2490.png)
    <st c="20615"><st c="20627">monotonically as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/2491.png)<st
    c="20644"><st c="20645">. This has the effect that the</st> *<st c="20676">p</st>*<st
    c="20677">-value in our example decreases monotonically as either</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2492.png)
    <st c="20733"><st c="20734">or</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2493.png)
    <st c="20738"><st c="20739">increase.</st> <st c="20750">Again, this is true in
    general for any (appropriate) hypothesis test – larger sample sizes lead to smaller</st>
    *<st c="20857">p</st>*<st c="20858">-values.</st> <st c="20867">What are the consequences</st>
    <st c="20893">of this?</st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20901">For a given test-statistic value, the larger the sample size from
    which that test-statistic value has been calculated, the more likely it is we
    will reject the null hypothesis and declare the test-statistic value as being
    statistically significant.</st> <st c="21151">Increasing sample size is like turning
    up the resolution on a microscope.</st> <st c="21225">The larger the sample size,
    the smaller the differences between the two groups we</st> <st c="21307">can detect.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="21318">If we want to be confident in detecting a difference between two
    groups, we know that we can do this simply by ensuring a sufficiently large enough
    sample size.</st> <st c="21480">How large is large enough is something we will
    explain in the</st> *<st c="21542">Type-I and Type-II errors, and power</st>*
    <st c="21578">section later in</st> <st c="21596">this chapter.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="21609">However, be careful.</st> <st c="21631">Given a large enough sample
    size, any test-statistic value, no matter how small, will become statistically
    significant.</st> <st c="21751">This highlights that “statistically significant”
    does not necessarily mean impactful.</st> <st c="21837">We may have a large enough
    sample size in our e-commerce A/B test example to detect even very small differences
    in the click-through rate between our website variants.</st> <st c="22005">This
    does not mean those very small differences in the click-through rate are big enough
    to change a bottom-line metric that the business cares about.</st> <st c="22156">This
    can be particularly relevant in e-commerce A/B testing, where large sample sizes
    are relatively easy to come by for the more popular websites, due to potentially
    global scale traffic volumes coming to</st> <st c="22362">those websites.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="22377">The</st> <st c="22381">fact that even a very small test-statistic
    value can be statistically significant, or conversely that a large value of a
    test statistic may not be statistically significant, illustrates the problems
    with just focusing on the</st> *<st c="22607">p</st>*<st c="22608">-value in isolation
    and relates to one of the principles emphasized in the ASA statement on</st> *<st
    c="22700">p</st>*<st c="22701">-values.</st> <st c="22710">It highlights that
    whenever we perform a hypothesis test, it is good practice to report the size
    of any effect estimate (e.g., the observed difference in sample means, which is</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2413.png)
    <st c="22887"><st c="22888">in our simple example), as well as report the</st>
    *<st c="22935">p</st>*<st c="22936">-value that results from that difference.</st>
    <st c="22978">Reporting just the</st> *<st c="22997">p</st>*<st c="22998">-value
    as the only outcome of a hypothesis should be considered bad data science practice</st>
    <st c="23088">and avoided.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23100">The effect of decreasing noise</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="23131">In a</st> <st c="23136">similar fashion, we can see from</st>
    *<st c="23170">Eq.</st> <st c="23174">7</st>* <st c="23175">that the variance
    of the test statistic,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2495.png)<st
    c="23217"><st c="23218">, also decreases if the variances,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msubsup><mi>σ</mi><mi>A</mi><mn>2</mn></msubsup><mo>,</mo><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup></mrow></mrow></math>](img/2496.png)<st
    c="23253"><st c="23264">, of the noise in the observations from either group decrease.</st>
    <st c="23327">The implications of this are obvious.</st> <st c="23365">The more
    accurate (less noise) we can make our observations, the more we can detect genuine
    differences between the groups, for a given sample size.</st> <st c="23514">Performing
    accurate measurements or observations allows us to make more efficient use of
    the data we</st> <st c="23615">have collected.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23630">This is true in general, even when the variation we see in the
    sample data does not come from a measurement error.</st> <st c="23746">In general,
    the smaller the intrinsic sampling variation in the individual data points, the
    more able our hypothesis test is to reject the null hypothesis if it is</st> <st
    c="23910">indeed false.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23923">However, note that the intrinsic sampling variation is not always
    within our control.</st> <st c="24010">Where variation is due to a measurement
    error, then, yes, we may be able to design and build more sensitive measuring
    equipment.</st> <st c="24139">Where variation is due to humans making decisions
    or choices, we have less control over the magnitude of</st> <st c="24244">the
    variation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24258">Having explained what the</st> *<st c="24285">p</st>*<st c="24286">-value
    represents and what factors affect it, we’ll now briefly return to one aspect
    of the</st> *<st c="24378">p</st>*<st c="24379">-value calculation in our simple
    example that may have been</st> <st c="24439">puzzling you.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24452">One-tailed and two-tailed tests</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="24484">For the</st> <st c="24493">simple example, we have been using
    to illustrate a hypothesis test our test statistic,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2497.png)
    <st c="24580"><st c="24581">which was 0.353\.</st> <st c="24599">We calculated
    the</st> *<st c="24617">p</st>*<st c="24618">-value as the probability of getting
    a value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>≥</mml:mo><mml:mn>0.353</mml:mn></mml:math>](img/2498.png)
    <st c="24663"><st c="24678">if the null hypothesis were true.</st> <st c="24712">But
    why did we use the absolute value</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>|</mo><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>|</mo></mrow></mrow></mrow></math>](img/2499.png)
    <st c="24750"><st c="24756">in our calculation of the</st> *<st c="24782">p</st>*<st
    c="24783">-value?</st> <st c="24791">We said earlier that this was because the</st>
    *<st c="24833">p</st>*<st c="24834">-value gives us a measure of how unusual or
    surprising the observed test-statistic value is under the null hypothesis, and
    we would have been just as surprised if we had seen a test-statistic value of
    -0.353 or lower.</st> <st c="25052">In other words, the calculated</st> *<st c="25083">p</st>*<st
    c="25084">-value reflects the fact that our alternative hypothesis is</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:math>](img/2500.png)<st
    c="25144"><st c="25155">, so there would be evidence for the alternative hypothesis
    being true if we had seen a large positive value of the test statistic</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2501.png)<st
    c="25286"><st c="25287">, or if we had seen a large negative value of the test
    statistic.</st> <st c="25353">Because we are calculating the</st> *<st c="25384">p</st>*<st
    c="25385">-value as the probability of unusual values from either end or tail
    of the test-statistic probability distribution, it is called a</st> **<st c="25516">two-tailed</st>**
    <st c="25526">test.</st> <st c="25533">The</st> <st c="25537">part of the</st>
    <st c="25548">test-statistic probability distribution that contributes to the</st>
    *<st c="25613">p</st>*<st c="25614">-value is shown schematically by the gray
    area in the left-ha</st><st c="25675">nd plot of</st> *<st c="25687">Figure 7</st>**<st
    c="25695">.2</st>*<st c="25697">.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_07_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="25973">Figure 7.2: Areas contributing to the p-value for one-tailed
    and two-tailed hypothesis tests</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26065">Of course, this raises the</st> <st c="26092">question of whether
    we sometimes want to</st> <st c="26134">perform a</st> **<st c="26144">one-tailed</st>**
    <st c="26154">hypothesis test.</st> <st c="26172">The answer is yes.</st> <st
    c="26191">An example of a one-tailed test would be when we want to test an alternative
    hypothesis</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi
    mathvariant="script">H</mi><mn>1</mn></msub><mo>:</mo><msub><mi>μ</mi><mi>A</mi></msub><mo>></mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2502.png)<st
    c="26279"><st c="26290">. Our null hypothesis would still be the same (i.e.,,</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi mathvariant="script">H</mi><mn>0</mn></msub><mo>:</mo><msub><mi>μ</mi><mi>A</mi></msub><mo>=</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2503.png)<st
    c="26344"><st c="26345">).</st> <st c="26348">Now, we are saying we would only
    be surprised if we saw the sample mean</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2359.png)
    <st c="26420"><st c="26421">much larger than the sample mean</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2360.png)<st
    c="26455"><st c="26456">. We would only be surprised if the probability of getting</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>></mml:mo><mml:mn>0.353</mml:mn></mml:math>](img/2506.png)
    <st c="26515"><st c="26531">with the null hypothesis being true was very small.</st>
    <st c="26583">The part of the test-statistic probability distribution that contributes
    to the</st> *<st c="26663">p</st>*<st c="26664">-value for this one-tailed test
    is shown schematically in the gray area in the right-hand plot of</st> *<st c="26762">Figure
    7</st>**<st c="26770">.2</st>*<st c="26772">. Obviously, there may be situations
    where we would want to perform a one-tailed hypothesis, where the alternative
    hypothesis is</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi
    mathvariant="script">H</mi><mn>1</mn></msub><mo>:</mo><msub><mi>μ</mi><mi>A</mi></msub><mo><</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2507.png)<st
    c="26901"><st c="26902">. For such a one-tailed test, the</st> *<st c="26936">p</st>*<st
    c="26937">-value would come from the left-hand tail of the test-statistic</st>
    <st c="27001">probability distribution.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27026">When should we perform a two-tailed test, and when should we perform
    a one-tailed test?</st> <st c="27115">This depends upon what</st> **<st c="27138">a
    priori</st>** <st c="27146">knowledge we have about what might happen if the null
    hypothesis is not true.</st> <st c="27225">If we know beforehand that only situations
    where</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>></mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2508.png)
    <st c="27274"><st c="27275">represent genuinely interesting scenarios, then we
    would probably want to run a one-tailed test with</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi
    mathvariant="script">H</mi><mn>1</mn></msub><mo>:</mo><msub><mi>μ</mi><mi>A</mi></msub><mo>></mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2509.png)<st
    c="27377"><st c="27389">. If, however, we considered both</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo><</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2510.png)
    <st c="27423"><st c="27424">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>></mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2511.png)
    <st c="27429"><st c="27430">to represent interesting scenarios or findings, then
    we would want to run a</st> <st c="27507">two-tailed test.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27523">The difference between a one-tailed test and a two-tailed test
    may look like a philosophical one, but the difference is important to understand,
    as you may be tempted to use a</st> <st c="27700">one-tailed test just to get
    a smaller</st> *<st c="27738">p</st>*<st c="27739">-value.</st> <st c="27747">How
    so?</st> <st c="27755">Well, imagine we chose a significance threshold of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2512.png)<st
    c="27806"><st c="27807">. What would be the test-statistic value that corresponds
    to precisely this threshold?</st> <st c="27894">In other words, for a two-tailed
    test, what test-statistic value would have a</st> *<st c="27972">p</st>*<st c="27973">-value
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2513.png)<st
    c="27983"><st c="27992">? For a two-tailed test, the left-hand schematic plot
    in</st> *<st c="28049">Figure 7</st>**<st c="28057">.2</st>* <st c="28059">indicates
    that both the left-hand and right-hand gray areas contribute equally to the</st>
    *<st c="28146">p</st>*<st c="28147">-value and, therefore, contribute a probability
    of 0.025\.</st> <st c="28205">For the standard Normal distribution, we can use
    the mathematical form</st> <st c="28276">of the</st> **<st c="28283">probability
    density function</st>** <st c="28311">(</st>**<st c="28313">PDF</st>**<st c="28316">)
    to find that this corresponds to a value of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msup><mrow><msqrt><mn>2</mn></msqrt><mtext>×</mtext><mtext>erf</mtext></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>−</mo><mn>2</mn><mo>×</mo><mn>0.025</mn></mrow></mfenced><mo>≈</mo><mn>1.96</mn></mrow></mrow></math>](img/2514.png)<st
    c="28363"><st c="28394">. This means that for our simple example, if the null
    hypothesis were</st> <st c="28463">true, then,</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>P</mi><mfenced
    open="(" close=")"><mrow><mfrac><mrow><mo>|</mo><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>|</mo></mrow><msqrt><mrow><mtext>Var</mtext><mfenced
    open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced></mrow></msqrt></mfrac><mo>≥</mo><mn>1.96</mn></mrow></mfenced><mo>=</mo><mn>0.05</mn></mrow></mrow></math>](img/2515.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="28523">Eq.</st> <st c="28527">13</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28529">Now, let’s repeat that calculation for a one-tailed test, as represented
    by the schematic in the right-hand plot of</st> *<st c="28646">Figure 7</st>**<st
    c="28654">.2</st>*<st c="28656">. Now, instead, it is just the gray area in the
    right-hand tail that gives us the threshold value of 0.05\.</st> <st c="28763">This
    now corresponds to a threshold of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msup><mrow><msqrt><mn>2</mn></msqrt><mtext>×</mtext><mtext>erf</mtext></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>−</mo><mn>2</mn><mo>×</mo><mn>0.05</mn></mrow></mfenced><mo>≈</mo><mn>1.64</mn></mrow></mrow></math>](img/2516.png)<st
    c="28802"><st c="28803">. This means that if the null hypothesis were true for
    our simple example, then we</st> <st c="28886">would have,</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>P</mi><mfenced
    open="(" close=")"><mrow><mfrac><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow><msqrt><mrow><mtext>Var</mtext><mfenced
    open="(" close=")"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced></mrow></msqrt></mfrac><mo>≥</mo><mn>1.64</mn></mrow></mfenced><mo>=</mo><mn>0.05</mn></mrow></mrow></math>](img/2517.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="28933">Eq.</st> <st c="28937">14</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28939">We can immediately see that, for the same</st> *<st c="28982">p</st>*<st
    c="28983">-value threshold value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2518.png)<st
    c="29009"><st c="29010">, the equivalent threshold we apply to the test statistic
    is smaller in magnitude for a one-tailed test than a two-tailed test, 1.64 versus
    1.96\.</st> <st c="29156">Naively, it appears that the one-tailed test is less
    stringent, since the threshold that we apply to determine whether the difference</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2519.png)
    <st c="29290"><st c="29291">is statistically significant is lower.</st> <st c="29331">A
    one-tailed test is not less stringent.</st> <st c="29372">Instead, we utilized
    prior information to select a more appropriate alternative hypothesis that then
    led us to run a one-tailed test.</st> <st c="29506">However, I have seen some
    data scientists choose to run a one-tailed test after seeing what the value of</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2520.png)
    <st c="29611"><st c="29612">was.</st> <st c="29618">They were hoping to get a
    statistically significant outcome from a relatively low value of</st> ![<math
    xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2521.png)<st
    c="29709"><st c="29710">. Do not be tempted to do this!</st> <st c="29742">This
    is</st> *<st c="29750">p</st>*<st c="29751">-hacking – modifying how a test is
    run after the data has been obtained just to get a smaller</st> *<st c="29845">p</st>*<st
    c="29846">-value.</st> <st c="29854">The conclusions you reach from doing this
    will not be robust.</st> <st c="29916">You should decide whether you are running
    a one-tailed or two-tailed test before actually</st> <st c="30006">running it.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30017">Using samples variances in the test statistic – the t-test</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="30076">In our simple</st> <st c="30090">example, we started out by assuming
    we knew the population variances</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2385.png)
    <st c="30160"><st c="30161">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2523.png)<st
    c="30166"><st c="30167">. We did so because it made the calculation of the</st>
    *<st c="30218">p</st>*<st c="30219">-value simpler to derive.</st> <st c="30245">In
    real life, we won’t know the values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2385.png)
    <st c="30287"><st c="30288">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2523.png)<st
    c="30293"><st c="30294">, but we can, of course, use the sample variances</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2526.png)
    <st c="30344"><st c="30345">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2391.png)
    <st c="30350"><st c="30351">as estimates for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2385.png)
    <st c="30369"><st c="30370">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2529.png)<st
    c="30375"><st c="30376">. However, doing so introduces a complexity in calculating
    the</st> *<st c="30439">p</st>*<st c="30440">-value.</st> <st c="30448">We’ll
    now explain what that complexity is and how we</st> <st c="30501">tackle it.</st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30511">The</st> *<st c="30516">p</st>*<st c="30517">-value calculation
    in our example in</st> *<st c="30554">Eq.</st> <st c="30558">12</st>* <st c="30560">is
    equivalent to using a scaled test statistic, whereby we divide</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2413.png)
    <st c="30627"><st c="30628">by its standard deviat</st><st c="30651">ion</st>
    <st c="30656">to give,</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="normal">z</mi><mo>=</mo><mfrac><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow><msqrt><mrow><mstyle
    scriptlevel="+1"><mfrac><msubsup><mi>σ</mi><mi>A</mi><mn>2</mn></msubsup><msub><mi>N</mi><mi>A</mi></msub></mfrac></mstyle><mo>+</mo><mstyle
    scriptlevel="+1"><mfrac><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><msub><mi>N</mi><mi>B</mi></msub></mfrac></mstyle></mrow></msqrt></mfrac><mo>=</mo><mfrac><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow><mrow><mi>σ</mi><msqrt><mrow><mstyle
    scriptlevel="+1"><mfrac><mn>1</mn><msub><mi>N</mi><mi>A</mi></msub></mfrac></mstyle><mo>+</mo><mstyle
    scriptlevel="+1"><mfrac><mn>1</mn><msub><mi>N</mi><mi>B</mi></msub></mfrac></mstyle></mrow></msqrt></mrow></mfrac></mrow></mrow></math>](img/2531.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="30666">Eq.</st> <st c="30670">15</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30672">We get the results on the far right-hand side of</st> *<st c="30722">Eq.</st>
    <st c="30726">15</st>* <st c="30728">because</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2532.png)
    <st c="30737"><st c="30738">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2529.png)
    <st c="30743"><st c="30744">have a common value, which is</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2090.png)<st
    c="30775"><st c="30780">. If we now replace the population variances with sample
    variances, our new test</st> <st c="30861">statistic is,</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>t</mi><mo>=</mo><mfrac><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow><mrow><mover><mi>σ</mi><mo
    stretchy="true">ˆ</mo></mover><msqrt><mrow><mstyle scriptlevel="+1"><mfrac><mn>1</mn><msub><mi>N</mi><mi>A</mi></msub></mfrac></mstyle><mo>+</mo><mstyle
    scriptlevel="+1"><mfrac><mn>1</mn><msub><mi>N</mi><mi>B</mi></msub></mfrac></mstyle></mrow></msqrt></mrow></mfrac></mrow></mrow></math>](img/2535.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="30883">Eq.</st> <st c="30887">16</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30889">For simplicity, we have assumed in</st> *<st c="30925">Eq.</st>
    <st c="30929">16</st>* <st c="30931">that the underlying population variances</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2536.png)
    <st c="30973"><st c="30974">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2537.png)
    <st c="30979"><st c="30980">still have a common value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2538.png)<st
    c="31007"><st c="31010">, and the denominator in</st> *<st c="31035">Eq.</st>
    <st c="31039">16</st>* <st c="31041">reflects the fact that we have combined the
    sample variances</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2526.png)
    <st c="31103"><st c="31104">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2540.png)
    <st c="31109"><st c="31110">to construct an estimate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2090.png)<st
    c="31139"><st c="31144">. That estimate, denoted by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2542.png)<st
    c="31172"><st c="31173">, is</st> <st c="31178">c</st><st c="31179">alculated
    as,</st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msup><mover><mi>σ</mi><mo
    stretchy="true">ˆ</mo></mover><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mfenced
    open="(" close=")"><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>−</mo><mn>1</mn></mrow></mfenced><msubsup><mi>s</mi><mi>A</mi><mn>2</mn></msubsup><mo>+</mo><mfenced
    open="(" close=")"><mrow><msub><mi>N</mi><mi>B</mi></msub><mo>−</mo><mn>1</mn></mrow></mfenced><msubsup><mi>s</mi><mi>B</mi><mn>2</mn></msubsup></mrow><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>+</mo><msub><mi>N</mi><mi>B</mi></msub><mo>−</mo><mn>2</mn></mrow></mfrac></mrow></mrow></math>](img/2543.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="31194">Eq.</st> <st c="31198">17</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31200">The denominator in</st> *<st c="31220">Eq.</st> <st c="31224">17</st>*
    <st c="31226">has been set so that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2544.png)<st
    c="31248"><st c="31249">is an unbiased estimator</st> <st c="31274">of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2090.png)<st
    c="31277"><st c="31282">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31283">All we</st> <st c="31291">now need to do is work out the probability
    distribution for this new test statistic under the assumption that the null hypothesis,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2402.png)<st
    c="31422"><st c="31423">, is true.</st> <st c="31434">The temptation here is to
    assume that because the individual data points come from a Gaussian distribution,
    then the distribution of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>t</mml:mi></mml:math>](img/2020.png)
    <st c="31567"><st c="31568">is still Gaussian because it looks like we are still
    just taking the difference between two sums of Gaussian random variables, as we
    did in</st> *<st c="31709">Eq.</st> <st c="31713">15</st>* <st c="31715">in our
    simple example.</st> <st c="31739">This was true when we used</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2388.png)
    <st c="31766"><st c="31767">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2389.png)
    <st c="31772"><st c="31773">in the denominator of our scaled test statistic in</st>
    *<st c="31825">Eq.</st> <st c="31829">15</st>*<st c="31831">, because</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2388.png)
    <st c="31841"><st c="31842">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2389.png)
    <st c="31847"><st c="31848">are just fixed constants whose values we know.</st>
    <st c="31896">But for the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>t</mml:mi></mml:math>](img/2020.png)
    <st c="31908"><st c="31909">test statistic in</st> *<st c="31928">Eq.</st> <st
    c="31932">16</st>*<st c="31934">, the denominator is now also a function of the
    data, so we need to account for the fact that the denominator varies as the random
    variables that make up the</st> <st c="32092">data vary.</st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32102">To calculate a</st> *<st c="32118">p</st>*<st c="32119">-value
    for the test statistic</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>t</mml:mi></mml:math>](img/2020.png)<st
    c="32149"><st c="32150">, we need to see how</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>t</mml:mi></mml:math>](img/2020.png)
    <st c="32171"><st c="32172">varies under the assumption that the null hypothesis
    is true.</st> <st c="32235">This means hypothetically varying the data that goes
    into the calculation of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>t</mml:mi></mml:math>](img/2555.png)
    <st c="32312"><st c="32313">but in a way that is consistent with the null hypothesis.</st>
    <st c="32372">To do this, we need to constrain the hypothetical data so that there
    is no difference in the sample means between the two groups, A and B.</st> <st
    c="32511">This imposes two constraints on the hypothetical data.</st> <st c="32566">In
    our hypothetical data, we do not have</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>+</mo><msub><mi>N</mi><mi>B</mi></msub></mrow></mrow></math>](img/2556.png)
    <st c="32607"><st c="32613">freely varying data values, but instead, we effectively
    have</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>+</mo><msub><mi>N</mi><mi>B</mi></msub><mo>−</mo><mn>2</mn></mrow></mrow></math>](img/2557.png)
    <st c="32674"><st c="32684">freely varying values.</st> <st c="32707">This number
    is</st> <st c="32721">called the</st> **<st c="32733">degrees of freedom</st>**<st
    c="32751">, sometimes abbreviated to</st> **<st c="32778">DF</st>**<st c="32780">,
    or</st> **<st c="32785">DOF</st>**<st c="32788">, and usually denoted by the symbol</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/2558.png)<st
    c="32824"><st c="32825">. In general, the number of DOF is the total sample size
    minus the number of parameters specified in our hypotheses</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/2559.png)
    <st c="32941"><st c="32942">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/2560.png)<st
    c="32947"><st c="32948">, which we have had to estimate.</st> <st c="32981">In
    our example, we had a total sample size of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2561.png)<st
    c="33027"><st c="33034">, and we had to estimate the two means,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2562.png)
    <st c="33074"><st c="33075">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2563.png)<st
    c="33080"><st c="33081">, so the</st> <st c="33090">DOF</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:math>](img/2564.png)<st
    c="33094"><st c="33106">.</st></st></st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33107">As well as reducing the effective number of DOF, the presence
    of the constraints also changes the shape of the distribution of our test statistic.</st>
    <st c="33255">Whilst our test statistic in</st> *<st c="33284">Eq.</st> <st c="33288">15</st>*
    <st c="33290">has a Gaussian distribution if the null distribution is true, our
    new test statistic</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>t</mml:mi></mml:math>](img/2020.png)
    <st c="33376"><st c="33377">in</st> *<st c="33381">Eq.</st> <st c="33385">16</st>*
    <st c="33387">follows the more complicated probability density function shape,
    given by the</st> <st c="33466">fol</st><st c="33469">lowing formula,</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>p</mi><mfenced
    open="(" close=")"><mi>t</mi></mfenced><mo>=</mo><mfrac><mrow><mi mathvariant="normal">Γ</mi><mfenced
    open="(" close=")"><mstyle scriptlevel="+1"><mfrac><mrow><mi>ν</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mstyle></mfenced></mrow><mrow><mi
    mathvariant="normal">Γ</mi><mfenced open="(" close=")"><mstyle scriptlevel="+1"><mfrac><mi>ν</mi><mn>2</mn></mfrac></mstyle></mfenced><msqrt><mrow><mi>ν</mi><mi>π</mi></mrow></msqrt></mrow></mfrac><msup><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>+</mo><mfrac><msup><mi>t</mi><mn>2</mn></msup><mi>ν</mi></mfrac></mrow></mfenced><mrow><mo>−</mo><mstyle
    scriptlevel="+1"><mfrac><mfenced open="(" close=")"><mrow><mi>ν</mi><mo>+</mo><mn>1</mn></mrow></mfenced><mn>2</mn></mfrac></mstyle></mrow></msup></mrow></mrow></math>](img/2566.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="33491">Eq.</st> <st c="33495">18</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33497">Since it is the distribution of</st> <st c="33529">our test statistic</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>t</mml:mi></mml:math>](img/2020.png)<st
    c="33549"><st c="33550">,</st> *<st c="33552">Eq.</st> <st c="33556">18</st>*
    <st c="33558">is called the</st> `<st c="33690">SciPy</st>` <st c="33695">implementation
    when we need to calculate it.</st> <st c="33741">What you do need to understand
    is what its shape looks like.</st> <st c="33802">We have plotted its shape in</st>
    *<st c="33831">Figure 7</st>**<st c="33839">.3</st>* <st c="33841">for a few different
    values of the DOF</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/2558.png)<st
    c="33880"><st c="33881">. For comparison, we have also plotted the density function
    of</st> <st c="33944">the standard Normal distribution</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math>](img/2569.png)
    <st c="33977"><st c="33978">The standard Normal distribution is the probability
    density function of the test statistic</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi></mml:math>](img/22.png)
    <st c="34070"><st c="34071">in</st> *<st c="34075">Eq.</st> <st c="34079">15</st>*
    <st c="34081">th</st><st c="34084">at we used in our</st> <st c="34103">simple
    example.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_07_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="34168">Figure 7.3: The shape of the t distribution</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34211">From</st> *<st c="34217">Figure 7</st>**<st c="34225">.3</st>*<st
    c="34227">, we can see that for the smaller values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/2558.png)<st
    c="34271"><st c="34272">, the t-distribution has heavier tails (the shape does
    not drop to zero as fast) than the standard Normal distribution, while for the
    larger values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/2558.png)<st
    c="34423"><st c="34424">, there is very little difference between the t-distribution
    and the standard Normal distribution.</st> <st c="34523">In fact, as</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/2573.png)<st
    c="34535"><st c="34536">, the t-distribution becomes identical to the standard</st>
    <st c="34591">Normal distribution.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34611">The comparison of two sample means, using the t-distribution to
    calculate the</st> *<st c="34690">p</st>*<st c="34691">-value, is known</st> <st
    c="34708">as a</st> **<st c="34713">t-test</st>**<st c="34719">. There</st> <st
    c="34726">are several variants of a t-test.</st> <st c="34761">All of the t-test
    variants are concerned with comparing sample means to assess whether the underlying
    populations from which the data</st> <st c="34895">came are the same in all regards,
    except for the population means,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2574.png)
    <st c="34962"><st c="34963">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2575.png)<st
    c="34968"><st c="34969">. The different variants of t-test are</st> <st c="35008">as
    follows:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="35019">A two-sample t-test</st>**<st c="35039">: The</st> <st c="35046">particular
    variant we have explained previously is the “two sample” t-test, in which we have
    two independent samples, one from</st> <st c="35173">each group</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="35183">A one-sample t-test</st>**<st c="35203">: Here, we</st> <st
    c="35214">have a sample of data from a single group, and we test the hypothesis
    that the underlying population mean of that group is different</st> <st c="35348">from
    zero</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="35357">A paired-sample t-test</st>**<st c="35380">: This</st> <st
    c="35388">is where we have two samples of data, but they are related or matched
    (paired) in some way (e.g., observations from the same set of individuals before
    and after some treatment has</st> <st c="35568">been applied)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="35581">Welch’s t-test</st>**<st c="35596">: This</st> <st c="35604">variant
    of the two-sample t-test drops the assumption that the variances of the two underlying
    populations are</st> <st c="35715">the same</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35723">Because comparing the means of two groups is such a common task
    – think of the website A/B test example we mentioned earlier – several Python
    packages have made performing a t-test easier for us.</st> <st c="35920">We will
    illustrate this next with a simple</st> <st c="35963">code example.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35976">A t-test code example</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="35998">The</st> <st c="36002">following code example can also be found
    in</st> <st c="36047">the</st> `<st c="36051">Code_Examples_Chap7.ipynb</st>`
    <st c="36076">Jupyter notebook in the GitHub repository.</st> <st c="36120">The
    data we’ll use can be found in the</st> `<st c="36159">hypothesis_test_example.csv</st>`
    <st c="36186">file in the</st> `<st c="36199">Data</st>` <st c="36203">folder
    of the GitHub repository.</st> <st c="36237">The data corresponds to the simple
    example we have used for illustration purposes throughout this section.</st> <st
    c="36344">First, we’ll read in</st> <st c="36365">the data:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: <st c="36551">We can take a</st> <st c="36566">quick look at the properties
    of the data using the</st> `<st c="36617">pandas</st>` `<st c="36623">describe</st>`
    <st c="36632">function:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: <st c="36712">This</st> <st c="36718">gives the</st> <st c="36728">following
    output:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: <st c="36940">From the summary statistics, we can see there is a difference
    in the sample means, with the B group sample data having a mean of 0.176, whilst
    the A group sample data has a mean of 0.529\.</st> <st c="37129">But does this
    provide evidence for the underlying population means of group A and group B being
    different?</st> <st c="37236">Let’s run the t-test to test this.</st> <st c="37271">We’ll
    use the</st> `<st c="37285">ttest_ind</st>` <st c="37294">function</st> <st c="37304">from</st>
    `<st c="37309">scipy.stats</st>`<st c="37320">:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: <st c="37504">The output gives the</st> *<st c="37526">t</st>*<st c="37527">-value
    (the test-statistic value) and the</st> <st c="37569">associated</st> *<st c="37580">p</st>*<st
    c="37581">-value.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: <st c="37673">From this t-test, we get a test statistic (a</st> *<st c="37719">t</st>*<st
    c="37720">-value) of 2.596 and a</st> *<st c="37743">p</st>*<st c="37744">-value
    of 0.0101\.</st> <st c="37762">If we use an</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="37775"><st c="37776">threshold of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2512.png)<st
    c="37790"><st c="37791">, then we would reject the null hypothesis and conclude
    that there is evidence (not proof) that the underlying population means of the
    two groups</st> <st c="37937">are different.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37951">We have been able</st> <st c="37970">to perform this two-sample
    t-test because we can calculate the</st> *<st c="38033">p</st>*<st c="38034">-value
    using the t-distribution density function in</st> *<st c="38086">Eq.</st> <st
    c="38090">18</st>*<st c="38092">. We have only been able to do so because the
    formula for the t-distribution PDF was worked out by statisticians over 100 years
    ago.</st> <st c="38225">But</st> <st c="38229">what happens if we don’t have any
    clever statisticians or mathematicians available to us to work out the PDF of
    our test statistic or, even worse, if we’ve designed a test statistic that no
    statistician or mathematician is ever likely to be able to work out the PDF for?</st>
    <st c="38500">Fear not – the general form of hypothesis test that we laid out
    earlier is like a recipe, and in the age of computers, we can always follow that
    recipe computationally, even when some of the ingredients (the test statistic)
    are challenging.</st> <st c="38741">In the next subsection, we will briefly explore
    how computationally intensive techniques can be used to perform</st> <st c="38853">hypothesis
    tests.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38870">Computationally intensive methods for p-value estimation</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="38927">Calculating</st> <st c="38940">the</st> *<st c="38944">p</st>*<st
    c="38945">-value associated with a test-statistic value is</st> *<st c="38994">step
    4</st>* <st c="39000">of our five-step recipe for hypothesis testing.</st> <st
    c="39049">Computationally intensive approaches rely upon the fact that we have
    specified what the null hypothesis is.</st> <st c="39157">This means we can just
    generate a load of</st> <st c="39199">simulated samples from that known null hypothesis
    and count how many times we get a test-statistic value as large as that observed.</st>
    <st c="39331">It is as easy as that.</st> <st c="39354">Again, we follow a short
    recipe, given as follows (for a</st> <st c="39411">two-tailed test):</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39428">Recipe for computationally intensive estimation of the p-value</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39491">1\.</st> <st c="39495">Set the</st> <st c="39503">number of simulated
    datasets to be generated (</st><st c="39549">e.g.</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10,000</mml:mn></mml:math>](img/2578.png)<st
    c="39555"><st c="39569">).</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39571">2\.</st> <st c="39575">Set</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext>count</mtext><mtext>=</mtext><mtext>0</mtext></mrow></mrow></math>](img/2579.png)<st
    c="39579"><st c="39580">. This is to count how many times we see a test statistic
    in the simulated data that is larger than the test-statistic value we got from
    the</st> <st c="39721">real data.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39731">3\.</st> <st c="39735">Generate a simulated dataset from the known
    null hypothesis.</st> <st c="39796">The simulated dataset should be of the same
    sample size as the</st> <st c="39859">real data.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39869">4\.</st> <st c="39873">Calculate</st> <st c="39883">the test statistic
    for the simulated dataset.</st> <st c="39929">If the magnitude of the simulated
    test statistic is greater than or equal to the magnitude of the test statistic
    for the real dataset, then</st> <st c="40069">set</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext>count</mtext><mtext>=</mtext><mtext>count</mtext><mtext>+</mtext><mtext>1</mtext></mrow></mrow></math>](img/2580.png)<st
    c="40073"><st c="40074">.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40075">5\.</st> <st c="40079">Repeat</st> *<st c="40086">steps 3</st>*
    <st c="40093">and</st> *<st c="40098">4</st>*<st c="40099">,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math>](img/2581.png)
    <st c="40101"><st c="40102">times.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40108">6\.</st> <st c="40112">Calculate the estimate of the</st> *<st
    c="40142">p</st>*<st c="40143">-value as</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mi>p</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mtext>count</mtext><mo>/</mo><msub><mi>N</mi><mrow><mi>s</mi><mi>e</mi><mi>t</mi><mi>s</mi></mrow></msub></mrow></mrow></math>](img/2582.png)<st
    c="40153"><st c="40171">. Since the real data also gave us a test-statistic value
    equal to or larger to than that observed, it is more common to estimate the</st>
    *<st c="40305">p</st>*<st c="40306">-value</st> <st c="40313">as</st> ![<math
    xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mi>p</mi><mo stretchy="true">ˆ</mo></mover><mo>=</mo><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>+</mo><mtext>count</mtext></mrow></mfenced><mo>/</mo><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>+</mo><msub><mi>N</mi><mrow><mi>s</mi><mi>e</mi><mi>t</mi><mi>s</mi></mrow></msub></mrow></mfenced></mrow></mrow></math>](img/2583.png)<st
    c="40316"><st c="40350">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40351">Before we run</st> <st c="40365">a demonstration of this approach,
    there are a couple of subtleties to</st> <st c="40436">point out:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40446">Firstly, the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math>](img/2584.png)
    <st c="40469"><st c="40474">determines the granularity with which we can estimate
    the</st> *<st c="40532">p</st>*<st c="40533">-value.</st> <st c="40541">A value
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math>](img/2585.png)
    <st c="40552"><st c="40563">means we estimate the</st> *<st c="40585">p</st>*<st
    c="40586">-value to a granularity of 1 part in 100\.</st> <st c="40628">To produce
    a more precise estimate of the</st> *<st c="40670">p</st>*<st c="40671">-value
    means, we must use larger and larger values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math>](img/2586.png)<st
    c="40725"><st c="40730">, thereby increasing the overall runtime – because we
    must generate more simulated datasets and calculate more test-statistic values.</st>
    <st c="40864">Hence why methods such as this are referred to as computationally</st>
    <st c="40930">intensive methods.</st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40948">Secondly,</st> *<st c="40959">step 3</st>* <st c="40965">involves
    generating data from the known null hypothesis.</st> <st c="41023">However, the
    null hypothesis may have been specified only in vague terms.</st> <st c="41097">For
    example, the null hypothesis may be that data from the two groups,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi></mml:math>](img/1738.png)
    <st c="41168"><st c="41169">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>B</mml:mi></mml:math>](img/1739.png)<st
    c="41174"><st c="41175">, is drawn from the same distribution.</st> <st c="41214">This
    doesn’t tell us which distribution.</st> <st c="41255">But wait – didn’t we assume
    that the data was Gaussian-distributed when calculating the t distribution in</st>
    *<st c="41361">Eq.</st> <st c="41365">18</st>*<st c="41367">? Yes, we did, but
    the t distribution in</st> *<st c="41408">Eq.</st> <st c="41412">18</st>* <st
    c="41414">is only correct if our data is Gaussian.</st> <st c="41456">What happens
    if the real data is not Gaussian-distributed, or we are not willing to make that
    assumption?</st> <st c="41562">We still want to generate</st> <st c="41587">simulated
    datasets assuming the null hypothesis to be true, (i.e., that all the data points
    came from the same distribution), but now we’re going to have to use the exact
    and true distribution from which the data came.</st> <st c="41807">The trouble
    is, we’re unlikely to know what the exact true distribution was.</st> <st c="41884">We’ve
    got a problem, right?</st> <st c="41912">It turns out we can still generate simulated
    datasets from the true underlying distribution and assume that the null hypothesis
    is true, even if we don’t know what the true underlying distribution is.</st>
    <st c="42113">Let’s imagine I just</st> <st c="42134">take a copy of the original
    data and randomize which group,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi></mml:math>](img/1738.png)
    <st c="42194"><st c="42195">or</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>B</mml:mi></mml:math>](img/1739.png)<st
    c="42199"><st c="42200">, each data point belongs to.</st> <st c="42230">I can
    do this by simply permuting the labels on the original data points.</st> <st c="42304">I
    now have a copy of the data where there is no meaningful difference in the group
    means.</st> <st c="42394">If there was to begin with, I certainly destroyed that
    difference when I randomized the labels.</st> <st c="42490">So now, the null hypothesis
    is true for my randomized copy of the data.</st> <st c="42562">However, because
    the data values (not the labels) of my copy are the same as the original data,
    all the statistical properties of my copy are the same as the statistical properties
    of the original.</st> <st c="42760">This means my copy dataset has effectively
    come from the same underlying</st> <st c="42833">distribution as my original dataset.</st>
    <st c="42870">My objective is complete – by a simple permutation of the labels
    attached to each data point, I have generated a simulated dataset for which the
    null hypothesis is true, and which comes from the same underlying distribution
    as my original data.</st> <st c="43115">All I need to do now is to repeat this
    permutation process</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math>](img/2591.png)
    <st c="43174"><st c="43179">times.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="43185">The astute among you will have spotted that the number of possible
    permutations of the original dataset I can generate is finite, so given what we
    have said in the preceding bullet point, there is a finite granularity to which
    I can estimate the</st> *<st c="43432">p</st>*<st c="43433">-value using this
    permutation approach.</st> <st c="43473">This is true, but for an original dataset
    consisting of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2371.png)
    <st c="43529"><st c="43530">data points in group</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi></mml:math>](img/1738.png)
    <st c="43552"><st c="43553">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2372.png)
    <st c="43558"><st c="43559">data points in group</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>B</mml:mi></mml:math>](img/1746.png)<st
    c="43581"><st c="43582">, the</st> <st c="43587">total number of distinct possible
    permutations is</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle
    scriptlevel="+1"><mfrac><mrow><mfenced open="(" close=")"><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>+</mo><msub><mi>N</mi><mi>B</mi></msub></mrow></mfenced><mo>!</mo></mrow><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>!</mo><msub><mi>N</mi><mi>B</mi></msub><mo>!</mo></mrow></mfrac></mstyle></mrow></math>](img/2596.png)<st
    c="43638"><st c="43639">. For any medium</st> <st c="43656">or large value of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2597.png)<st
    c="43674"><st c="43682">, this is an astronomical number of possible permutations,
    so in practice, we aren’t really restricted in the kinds of values for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math>](img/2591.png)
    <st c="43812"><st c="43817">we</st> <st c="43820">can choose.</st></st></st></st></st></st></st></st></st></st></st></st></st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="43831">Let’s look at this permutation-based approach in action in a</st>
    <st c="43893">code example.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="43906">A permutation-based p-value code example</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="43947">The</st> <st c="43952">following code example can also be found
    in the</st> `<st c="44000">Code_Examples_Chap7.ipynb</st>` <st c="44025">Jupyter
    notebook in</st> <st c="44045">the</st> <st c="44050">GitHub repository.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="44068">First, we’ll set the seed for the</st> `<st c="44103">NumPy</st>`
    <st c="44108">random</st> <st c="44116">number generator:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: <st c="44173">Next, we’ll calculate the test-statistic value (the</st> *<st
    c="44226">t</st>*<st c="44227">-value) for the actual</st> <st c="44250">real
    dataset:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: <st c="45642">Now, we</st> <st c="45651">can repeat the process</st> <st c="45674">of
    calculating the</st> *<st c="45693">t</st>*<st c="45694">-value but do it for
    a sequence of</st> <st c="45729">permuted datasets:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: <st c="46805">This</st> <st c="46810">gives the</st> <st c="46821">following
    output:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: <st c="46931">The</st> <st c="46935">permutation-based</st> *<st c="46954">p</st>*<st
    c="46955">-value estimate is very close to that from the t-test run using the</st>
    `<st c="47023">scipy.stats.ttest_ind</st>` <st c="47044">function.</st> <st c="47055">Obviously,
    since the permutation-based</st> *<st c="47094">p</st>*<st c="47095">-value estimate</st>
    <st c="47111">is based on a random generation of permutations, we would expect
    to see differences.</st> <st c="47196">As we increase the number of permutations
    used, we would expect the differences in the</st> *<st c="47283">p</st>*<st c="47284">-value
    estimates between the two methods</st> <st c="47325">to decrease.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="47337">Parametric versus non-parametric hypothesis tests</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="47387">The</st> <st c="47392">permutation-based approach illustrated
    in the preceding code example is known</st> <st c="47470">as a</st> **<st c="47475">permutation
    test.</st>** <st c="47492">As we saw, one of its main advantages was that we did
    not have to assume in the null hypothesis what the shape of the distribution was
    from which the data came.</st> <st c="47654">We did not assume any</st> **<st
    c="47676">parameterized</st>** <st c="47689">equation for the probability density
    of the data.</st> <st c="47740">Consequently, this permutation test is an example
    of a</st> **<st c="47795">non-parametric hypothesis test</st>**<st c="47825">.
    In</st> <st c="47829">contrast, our t-test probability density in</st> *<st c="47874">Eq.</st>
    <st c="47878">18</st>* <st c="47880">was derived from the null hypothesis assumption
    that each</st> <st c="47939">datapoint was drawn from the same Gaussian distribution
    – that is, we assumed in the t-test a specific parameterized mathematical form
    for the probability density of the data.</st> <st c="48115">Consequently, the
    t-test example we illustrated earlier is an</st> <st c="48177">example of a</st>
    **<st c="48190">parametric</st>** **<st c="48201">hypothesis test</st>**<st c="48216">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="48217">There are many other non-parametric hypothesis tests.</st> <st
    c="48272">The aspect they all have in common is that they do not make any assumptions
    for the null hypothesis data distribution.</st> <st c="48391">Usually, this is
    done by constructing a test statistic that is calculated from the ranks of the
    data values, not the data values directly.</st> <st c="48530">This means that
    for a given ranking of the</st> <st c="48572">observations, the test statistic
    is invariant of the probability distribution from which the data is drawn.</st>
    <st c="48681">There are rank-based non-parametric hypothesis tests corresponding
    to both the one-sample and two-sample parametric t-tests we illustrated earlier.</st>
    <st c="48829">These are listed in</st> *<st c="48849">Table 7.1</st>*<st c="48858">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '| **<st c="48859">Parametric t-test</st>** | **<st c="48877">Corresponding</st>**
    **<st c="48892">rank-based test</st>** |'
  prefs: []
  type: TYPE_TB
- en: '| <st c="48907">One-sample</st> <st c="48919">or paired-sample</st> | <st c="48935">Wilcoxon</st>
    <st c="48945">signed-rank test</st> |'
  prefs: []
  type: TYPE_TB
- en: '| <st c="48961">Two-sample</st> | <st c="48972">Mann-Whitney</st> <st c="48986">U
    test</st> |'
  prefs: []
  type: TYPE_TB
- en: '<st c="48992">Table 7.1: Parametric t-tests and their corresponding non-parametric
    hypothesis test equivalents</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="49089">For the two-sample non-parametric case, you could also use Mood’s
    median test, which tests whether the samples came from distributions that have
    the</st> <st c="49239">same median.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="49251">When should we use a non-parametric test, and when should we use
    a parametric test?</st> <st c="49336">There are pros and cons for both.</st> <st
    c="49370">Because a parametric test makes an assumption about the form of the
    data distribution, it is sensitive to deviations away from that assumption.</st>
    <st c="49514">If the real data you were testing came from a distribution with
    a markedly different shape to the one assumed, the parametric test may reach the
    wrong conclusion.</st> <st c="49677">In contrast, a non-parametric hypothesis
    test is robust against the different distributions that the real data may have
    come from, as a non-parametric test does not make any assumptions about that underlying
    distribution.</st> <st c="49899">However, if the real data has come from a</st>
    <st c="49941">distribution identical to or very close to that assumed by a parametric
    test, then the correctness of that assumption allows us to identify</st> <st c="50081">differences
    between populations of data more accurately, and we have a more sensitive test.</st>
    <st c="50173">Parametric tests also have the advantage that part of the testing
    usually involves estimating a quantity that we are interested in.</st> <st c="50305">For
    example, the two-sample t-test estimates the difference in the population means,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2599.png)<st
    c="50390"><st c="50391">, so if the null hypothesis is rejected and we conclude
    that there is evidence for a difference between the population means, we get an
    estimate of that difference automatically as part of the test.</st> <st c="50590">In
    contrast, a Mann-Whitney U test may reject the null hypothesis and conclude there
    is a difference in population medians, but we do not know how big that</st> <st
    c="50746">difference is.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="50760">We will meet non-parametric statistics again in</st> *<st c="50809">Chapter
    14</st>* <st c="50819">when we learn about Bayesian non-parametric methods, but
    for the remainder of this chapter, we will discuss and use</st> <st c="50936">only
    parametric tests.</st> <st c="50959">If you want to learn more about non-parametric
    hypothesis tests, check out the second, third and fourth references in the</st>
    *<st c="51081">Notes and further reading</st>* <st c="51106">section at the end
    of the chapter for suggested</st> <st c="51155">extra material.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51170">This discussion of</st> <st c="51190">parametric and non-parametric
    tests completes what has been a long section.</st> <st c="51266">We have learned
    a lot of new ideas and concepts, so let’s end this section by summarizing what</st>
    <st c="51361">we learned.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51372">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="51388">In this section, we learned</st> <st c="51417">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="51431">What a hypothesis</st> <st c="51450">test is</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51457">A five-step recipe to perform any</st> <st c="51492">hypothesis
    test</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51507">What the</st> *<st c="51517">p</st>*<st c="51518">-value represents
    and what the significance threshold</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)
    <st c="51572"><st c="51573">represents</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51583">What factors affect</st> <st c="51604">the</st> *<st c="51608">p</st>*<st
    c="51609">-value</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51615">About one-tailed and two-tailed hypothesis tests and the difference</st>
    <st c="51684">between them</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51696">How to run</st> <st c="51708">a t-test</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51716">How to use computationally intensive methods to calculate the</st>
    *<st c="51779">p</st>*<st c="51780">-value when you have a complex</st> <st c="51811">hypothesis
    test</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51826">About parametric and non-parametric</st> <st c="51863">hypothesis
    tests</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="51879">Having learned about hypothesis tests and how to perform them,
    in the next section, we’ll look at how to calculate confidence intervals for some
    of the quantities we calculate as part of a hypothesis test, as well as what those
    confidence</st> <st c="52119">intervals represent.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="52139">Confidence intervals</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="52160">Our</st> <st c="52165">explanation of hypothesis testing in the
    previous section focused a lot on how to calculate the</st> *<st c="52261">p</st>*<st
    c="52262">-value.</st> <st c="52270">We explained that this focus on</st> *<st
    c="52302">p</st>*<st c="52303">-values can be dangerous, as well as that reporting
    results from a hypothesis test should include not just the</st> *<st c="52414">p</st>*<st
    c="52415">-value but also the estimate of the effect (e.g., the estimate of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2601.png)
    <st c="52481"><st c="52482">for our difference in means example).</st> <st c="52521">The
    only problem is that our estimate is based on sample data, so it has an inherent
    uncertainty associated with it.</st> <st c="52638">Ideally, we should also report
    the degree of uncertainty associated with</st> <st c="52711">our estimate.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="52724">To summarize our estimate of the effect and also the uncertainty
    of that estimate, we’ll introduce a new concept, a</st> **<st c="52841">confidence
    interval</st>**<st c="52860">. To explain what a confidence interval is, we’ll
    first recap some results from the</st> <st c="52944">previous section.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="52961">Suppose we have run the two-sample z-test hypothesis test of the
    previous section.</st> <st c="53045">We used the calculated value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2602.png)
    <st c="53077"><st c="53078">to reject the null hypothesis that</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>](img/2603.png)<st
    c="53114"><st c="53123">, so we believe that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:math>](img/2604.png)<st
    c="53144"><st c="53154">. But what should be our estimate of this non-zero quantity?</st>
    <st c="53215">We can use the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2605.png)
    <st c="53239"><st c="53240">as our estimate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2606.png)<st
    c="53260"><st c="53261">. We can write</st> <st c="53276">thi</st><st c="53279">s
    as,</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mover><mi>μ</mi><mo
    stretchy="true">ˆ</mo></mover><mi>A</mi></msub><mo>−</mo><mspace width="0.25em"
    /><msub><mover><mi>μ</mi><mo stretchy="true">ˆ</mo></mover><mi>B</mi></msub><mo>=</mo><mspace
    width="0.25em" /><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub><mspace
    width="0.25em" /></mrow></mrow></math>](img/2607.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="53287">Eq.</st> <st c="53291">19</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="53293">The hat</st> <st c="53302">symbols on the left-hand side of</st>
    *<st c="53335">Eq.</st> <st c="53339">19</st>* <st c="53341">mean that this quantity
    is our estimate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2608.png)
    <st c="53385"><st c="53386">, but it is not actually</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2609.png)
    <st c="53411"><st c="53412">itself.</st> <st c="53421">Due to the uncertainty
    in our estimate arising from the noise in the data, it is almost certainly true
    that</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mover><mi>μ</mi><mo
    stretchy="true">ˆ</mo></mover><mi>A</mi></msub><mo>−</mo><msub><mover><mi>μ</mi><mo
    stretchy="true">ˆ</mo></mover><mi>B</mi></msub></mrow></mrow></math>](img/2610.png)
    <st c="53529">![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2611.png)<st
    c="53530"><st c="53531">. The right-hand side of</st> *<st c="53556">Eq.</st>
    <st c="53560">19</st>* <st c="53562">just says that the numerical value of our
    estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2612.png)
    <st c="53614"><st c="53615">is given by the numerical value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math>](img/2613.png)
    <st c="53651"><st c="53652">Currently, our estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2614.png)
    <st c="53677"><st c="53678">is just a single number.</st> <st c="53704">This is</st>
    <st c="53711">called a</st> **<st c="53721">point estimate</st>**<st c="53735">.
    The true value</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2615.png)
    <st c="53752"><st c="53753">could be close to our point estimate</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2614.png)<st
    c="53791"><st c="53792">, or it could be a long way from it.</st> <st c="53829">Is
    it possible to construct a range in which we think it is likely that the true
    value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2617.png)
    <st c="53916"><st c="53917">lies?</st> <st c="53924">Yes – this is what the confidence</st>
    <st c="53958">interval quantifies.</st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="53978">The formal definition of a 95% confidence interval for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2618.png)
    <st c="54034"><st c="54035">would be a formula to calculate an interval</st> ![<math
    xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfenced open="[" close="]"><mrow><mi>l</mi><mo>,</mo><mi>u</mi></mrow></mfenced></mrow></math>](img/2619.png)<st
    c="54080"><st c="54081">, with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>l</mml:mi></mml:math>](img/2620.png)
    <st c="54088"><st c="54089">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>u</mml:mi></mml:math>](img/2621.png)
    <st c="54094"><st c="54095">calculated from the sample data, such that for 95%
    of cases, the true value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2622.png)
    <st c="54172"><st c="54173">would in lie in the</st> <st c="54194">calculated
    interval.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="54214">For our simple example in the previous section, we had sample
    sizes</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math>](img/2623.png)<st
    c="54283"><st c="54292">. From now on, we’ll assume the sample sizes are always
    the same for the A and B samples, and we’ll use</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="54396"><st c="54397">to denote this common sample size.</st> <st c="54433">If
    we know the common value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/1828.png)<st
    c="54461"><st c="54464">of the population variances</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2626.png)<st
    c="54492"><st c="54501">, then the 95% confidence interval is given by</st> <st
    c="54548">the formula,</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1.96</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mo>≤</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>≤</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1.96</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo> </mml:mo></mml:math>](img/2627.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="54615">Eq.</st> <st c="54619">20</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="54621">There are several things to note about</st> <st c="54661">this
    formula:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="54674">First, note how the confidence interval depends upon the sample
    data</st> <st c="54744">through</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2413.png)<st
    c="54752"><st c="54753">.</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="54754">Secondly, note how the width of the confidence interval decreases
    as we increase the sample size</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)<st
    c="54852"><st c="54853">. This makes intuitive sense – the more observations we
    have, the more we expect the sample means</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>,</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mrow></math>](img/2630.png)
    <st c="54951"><st c="54961">will be accurate estimates of their population counterparts</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>,</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2631.png)<st
    c="55021"><st c="55022">, so the narrower our uncertainty about the true value
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2622.png)
    <st c="55080"><st c="55081">should be.</st></st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="55091">Thirdly, note</st> <st c="55105">the value 1.96 in the formula
    for the confidence value.</st> <st c="55162">This looks like the test-statistic
    threshold in</st> *<st c="55210">Eq.</st> <st c="55214">13</st>* <st c="55216">that
    we derived from setting</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2633.png)
    <st c="55246"><st c="55247">in the z-test.</st> <st c="55263">It is.</st> <st
    c="55270">But wasn’t our choice of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="55295"><st c="55296">subjective (i.e., someone else might have chosen to
    set</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math>](img/2635.png)<st
    c="55353"><st c="55354">), and if so, does this mean that the confidence interval
    is subjective as well?</st> <st c="55435">Yes, to some degree.</st> <st c="55456">You
    are free to calculate whatever level of confidence interval you wish.</st> <st
    c="55530">We could calculate an 80% confidence interval if we wished, or a 99%
    confidence interval.</st> <st c="55620">For our simple example, the formula for
    a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:math>](img/2636.png)
    <st c="55662"><st c="55663">confidence interval is</st> <st c="55687">given by,</st></st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mtext> erf</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced
    separators=""><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mo>≤</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>≤</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msup><mml:mrow><mml:mtext>erf</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced
    separators=""><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo> </mml:mo></mml:math>](img/2637.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="55781">Eq.</st> <st c="55785">21</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="55787">From this formula and the plot in</st> *<st c="55822">Figure 7</st>**<st
    c="55830">.1</st>*<st c="55832">, we can see that the higher the value of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:math>](img/2638.png)<st
    c="55874"><st c="55875">, the wider the confidence interval is.</st> <st c="55915">Again,
    this makes intuitive sense – if we want a higher degree of confidence, we will
    need a wider interval.</st> <st c="56024">If we wanted to be 100% confident (i.e.,
    absolutely certain that the true value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2617.png)
    <st c="56107"><st c="56108">was in the interval), that interval would have to
    be</st> <st c="56162">infinitely wide.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="56178">The formula to calculate the confidence interval depends upon
    what we know about the distribution of the data.</st> <st c="56290">In our simple
    example, we started by assuming (for simplicity purposes) that we knew the value
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2640.png)<st
    c="56388"><st c="56391">, the value of the population variance for both the A
    and B populations.</st> <st c="56464">As with the z-test hypothesis test, we can
    replace the population variance</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2090.png)<st
    c="56539"><st c="56544">with its estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2642.png)
    <st c="56562"><st c="56563">in</st> *<st c="56567">Eq.</st> <st c="56571">17</st>*<st
    c="56573">, based upon the sample variances</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2643.png)
    <st c="56607"><st c="56612">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math>](img/2540.png)<st
    c="56616"><st c="56617">. The formula for the confidence interval then also changes</st>
    <st c="56677">and becomes,</st></st></st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mtext>CDF</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced
    separators=""><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mo>≤</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>≤</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mtext>CDF</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced
    separators=""><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo> </mml:mo></mml:math>](img/2645.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="56723">Eq.</st> <st c="56727">22</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="56729">The changes</st> <st c="56741">in the formula are the replacement
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi></mml:math>](img/1545.png)
    <st c="56780"><st c="56781">with its estimate,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/2647.png)<st
    c="56801"><st c="56802">, and the replacement of the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi></mml:math>](img/22.png)
    <st c="56831"><st c="56832">test-statistic threshold,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msup><mml:mrow><mml:mtext>erf</mml:mtext></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/2649.png)<st
    c="56859"><st c="56874">, with its t-distribution equivalent, which is the inverse
    of the cumulative distribution function of the t-distribution for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:math>](img/2650.png)
    <st c="56999"><st c="57000">DOF, and which we have denoted with</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mtext>CDF</mtext><mrow><mi>t</mi><mo>,</mo><mn>2</mn><mi>N</mi><mo>−</mo><mn>2</mn></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup></mrow></math>](img/2651.png)<st
    c="57037"><st c="57038">. All the previous qualitative statements we have made
    about the confidence interval</st> <st c="57123">still apply.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="57135">What does a confidence interval really represent?</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="57185">The comments</st> <st c="57199">we made about the confidence interval
    formulae in</st> *<st c="57249">Eq.</st> <st c="57253">20</st>*<st c="57255">,</st>
    *<st c="57257">Eq.</st> <st c="57261">21</st>*<st c="57263">, and</st> *<st c="57269">Eq.</st>
    <st c="57273">22</st>*<st c="57275">, were specific to those formulae, although
    some aspects, such as the confidence interval width widening with the increase
    in the level of confidence and decreasing with the sample size, are more general.</st>
    <st c="57480">However, there are also some comments we can make about any</st>
    <st c="57540">confidence interval.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="57560">The most important of these more general comments is to emphasize
    that when we calculate a confidence interval from a single dataset using, say,</st>
    *<st c="57706">Eq.</st> <st c="57710">22</st>*<st c="57712">, there is not a</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/2652.png)
    <st c="57729"><st c="57730">probability that the true value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2617.png)
    <st c="57766"><st c="57767">lies in the interval calculated from this particular
    dataset.</st> <st c="57830">It may appear that is what the formal definition says,
    but the formal definition is deliberately more nuanced than that.</st> <st c="57951">When
    we talk about a confidence interval, we make statements about the true value of
    some parameter (e.g.,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2654.png)
    <st c="58058"><st c="58059">in our example).</st> <st c="58077">Because we have
    taken a non-Bayesian approach, the true value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2655.png)
    <st c="58142"><st c="58143">is a fixed number.</st> <st c="58163">When we calculate
    a confidence interval from a single dataset using</st> *<st c="58231">Eq.</st>
    <st c="58235">22</st>*<st c="58237">, we get a single interval.</st> <st c="58265">The
    true value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2656.png)
    <st c="58283"><st c="58284">is either in this interval or it is not.</st> <st
    c="58326">It is binary – yes/no, or 0/1\.</st> <st c="58357">To attach a probability
    to a confidence interval, we must look at repeating the process multiple times
    with many different datasets under identical conditions.</st> <st c="58517">That
    is why we gave the formal definition of the 95% confidence interval as “a formula
    to calculate an interval</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfenced
    open="[" close="]"><mrow><mi>l</mi><mo>,</mo><mi>u</mi></mrow></mfenced></mrow></math>](img/2657.png)<st
    c="58629"><st c="58630">, with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>l</mml:mi></mml:math>](img/2658.png)
    <st c="58637"><st c="58638">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>u</mml:mi></mml:math>](img/2659.png)
    <st c="58643"><st c="58644">calculated from the sample data, such that for 95%
    of cases, the true value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2622.png)
    <st c="58721"><st c="58722">would in lie in the calculated interval.” This means
    that if our formula to calculate the confidence interval is valid, then if we
    repeated the process of sampling</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="58887"><st c="58888">datapoints from both the A and B populations 100 times
    and calculated a confidence interval for each of those 100 datasets, we would
    expect to see the true value inside the confidence interval approximately 95 times.</st>
    <st c="59106">It is important to realize that for each of those 100 datasets,
    we</st> <st c="59172">would get a slightly different confidence interval (because
    the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2413.png)
    <st c="59246"><st c="59247">would be different each time).</st> <st c="59279">If
    we repeated the process 1,000 times, we would expect the true value to be inside
    the confidence interval for the given dataset in 950 cases.</st> <st c="59423">The
    more times we repeat the process, the closer we get to 95% for the proportion
    of cases where the true value is inside the</st> <st c="59549">confidence interval.</st></st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="59569">Graphical interpretation of a confidence interval</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*<st c="59619">Figure 7</st>**<st c="59628">.4</st>* <st c="59630">shows</st>
    <st c="59637">schematic representations of two 95% confidence intervals for</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2615.png)<st
    c="59699"><st c="59700">. The value of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2664.png)
    <st c="59715"><st c="59716">is represented by the</st> *<st c="59739">x</st>*<st
    c="59740">-axis.</st> <st c="59747">For reference, we have also marked the position
    of zero on the</st> *<st c="59810">x</st>*<st c="59811">-axis.</st> <st c="59818">The
    two plots correspond to two different experiments (i.e., two different datasets),
    so we get two different values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2665.png)<st
    c="59938"><st c="59939">, which we have also marked on the</st> *<st c="59974">x</st>*<st
    c="59975">-axis.</st> <st c="59982">The two experiments were done under different
    conditions.</st> <st c="60040">It may be that the true value of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2666.png)
    <st c="60073"><st c="60074">is genuinely different in the two experiments.</st>
    <st c="60122">In the first experiment (the upper plot), the 95% confidence interval
    is entirely above zero.</st> <st c="60216">So, we can be reasonably confident
    that the true value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2667.png)
    <st c="60274"><st c="60275">is above zero in this first experiment.</st> <st c="60316">Contrast
    this with the second experiment (the lower plot), where the 95% confidence interval
    straddles the zero value on the</st> *<st c="60441">x</st>*<st c="60442">-axis.</st>
    <st c="60449">Despite the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2497.png)
    <st c="60470"><st c="60471">being greater than zero in this second experiment,
    we are not confident enough that the true value of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2615.png)
    <st c="60574"><st c="60575">is</st> <st c="60579">abo</st><st c="60582">ve zero.</st></st></st></st></st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_07_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="60646">Figure 7.4: Schematic plots of 95% confidence intervals from
    two experiments</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="60722">If the</st> <st c="60730">preceding discussion sounds similar
    to how we perform a hypothesis test, that is deliberate.</st> <st c="60823">Hypothesis
    testing and the calculation of confidence intervals are linked.</st> <st c="60898">If
    the 95% confidence interval includes the value represented by the null hypothesis
    (</st>![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>](img/2670.png)
    <st c="60984"><st c="60997">in this case), then we should not be able to reject
    the null hypothesis at the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mi>%</mml:mi></mml:math>](img/2671.png)
    <st c="61076"><st c="61084">level.</st> <st c="61091">More generally, if a</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:math>](img/2672.png)
    <st c="61112"><st c="61126">confidence interval includes the value represented
    by a null hypothesis, we should not be able to reject the null hypothesis at the</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2673.png)
    <st c="61258"><st c="61259">level of significance.</st> <st c="61283">This means
    that if we have confidence intervals calculated for us – say, by statistical software
    – we can quickly eyeball the confidence intervals to determine what should be
    the outcome of a</st> <st c="61475">hypothesis test.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="61491">Confidence intervals for any parameter</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="61530">This last point is</st> <st c="61550">highly relevant when we
    realize that, although the calculation of confidence intervals and hypothesis
    testing are linked, they are not inseparable.</st> <st c="61698">A confidence
    interval can be calculated for any parameter that we estimate using data, not
    just for those parameters that appear in hypothesis tests.</st> <st c="61848">Take
    the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2674.png)
    <st c="61857"><st c="61858">parameters, which are the population means of the
    A and B populations, respectively.</st> <st c="61944">In our simple hypothesis
    test example, we estimated the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2608.png)
    <st c="62000"><st c="62001">parameter.</st> <st c="62013">Let’s imagine now that
    we estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2676.png)
    <st c="62048"><st c="62049">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2677.png)
    <st c="62054"><st c="62055">separately, not as part of some hypothesis test.</st>
    <st c="62105">We could construct 95% confidence intervals for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2353.png)
    <st c="62153"><st c="62154">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2354.png)
    <st c="62159"><st c="62160">separately.</st> <st c="62173">This is shown schematically
    in</st> *<st c="62204">Figure 7</st>**<st c="62212">.5</st>*<st c="62214">. We
    won’t go into details now on how we would calculate confidence intervals for</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2680.png)
    <st c="62296"><st c="62297">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2681.png)<st
    c="62302"><st c="62303">, as that is not important for this</st> <st c="62338">qualitative
    discussion.</st> <st c="62363">The value of the parameters and the confidence
    intervals are now shown on the</st> *<st c="62441">y</st>*<st c="62442">-axis
    for the schematic in</st> *<st c="62469">Figure 7</st>**<st c="62477">.5</st>*<st
    c="62479">. We have used the</st> *<st c="62498">x</st>*<st c="62499">-axis to
    distinguish between the A population and its mean</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2353.png)<st
    c="62558"><st c="62559">, and the B population and its</st> <st c="62590">mean</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2354.png)<st
    c="62595"><st c="62596">.</st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_07_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="62668">Figure 7.5: A schematic of 95% confidence intervals for separate
    parameters</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="62743">The confidence intervals overlap, meaning that we cannot be confident
    that the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2684.png)
    <st c="62823"><st c="62824">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2685.png)
    <st c="62829"><st c="62830">parameters have different values.</st> <st c="62865">We
    can reach this conclusion even though we have not performed a hypothesis test</st>
    <st c="62946">for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2622.png)<st
    c="62950"><st c="62951">.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="62952">The preceding example was a simple one.</st> <st c="62993">Calculating
    separate estimates for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2687.png)
    <st c="63028"><st c="63029">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2688.png)
    <st c="63034"><st c="63035">is straightforward, since we can use the sample means</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2689.png)
    <st c="63090"><st c="63091">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2690.png)
    <st c="63096"><st c="63097">as estimates.</st> <st c="63112">Calculation of separate
    confidence intervals is also straightforward, since we can follow a similar approach
    to the calculation of the confidence interval for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2608.png)<st
    c="63271"><st c="63272">. This simple example illustrates that we can calculate
    a confidence interval for any population parameter.</st> <st c="63380">However,
    the more complex the form of the population parameter, the more difficult it is
    to derive a formula for the confidence interval.</st> <st c="63518">As with hypothesis
    testing, explicit and exact formulae for confidence intervals are typically derived
    by mathematicians or statisticians, and we as data scientists will then use those
    formulae.</st> <st c="63713">The confidence interval formulae in</st> *<st c="63749">Eq.</st>
    <st c="63753">20</st>*<st c="63755">,</st> *<st c="63757">Eq.</st> <st c="63761">21</st>*<st
    c="63763">, and</st> *<st c="63769">Eq.</st> <st c="63773">22</st>* <st c="63775">are
    relatively easy to derive because the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math>](img/2353.png)
    <st c="63818"><st c="63819">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2354.png)
    <st c="63824"><st c="63825">parameters affect the data distribution in a very
    simple way – they are the means of distributions from which the data is drawn.</st>
    <st c="63955">We exploit this through a process</st> <st c="63988">called</st>
    **<st c="63996">pivoting</st>** <st c="64004">to extract an exact formula for
    the confidence interval.</st> <st c="64062">For more complex parameters, we cannot
    use this pivoting technique to derive an exact</st> <st c="64148">confidence</st>
    <st c="64159">interval formula.</st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="64176">As with running t-tests, to calculate a confidence interval in
    practice, we do not have to calculate</st> *<st c="64278">Eq.</st> <st c="64282">22</st>*
    <st c="64284">ourselves.</st> <st c="64296">Instead, we can make use of the in-built
    confidence interval methods in packages such as</st> `<st c="64385">statsmodels</st>`<st
    c="64396">. Let’s look at a</st> <st c="64414">code example.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="64427">A confidence interval code example</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="64462">Let’s</st> <st c="64468">run a simple confidence interval calculation
    using classes and methods from the</st> `<st c="64549">statsmodels</st>` <st c="64560">package.</st>
    <st c="64570">We’ll use the data we used in the previous code example, so we’ll
    assume that data is already read in and held as a</st> `<st c="64686">pandas</st>`
    <st c="64692">DataFrame,</st> `<st c="64704">df_simple_example</st>`<st c="64721">.
    The following code example and more can also be found in the</st> `<st c="64784">Code_Examples_Chap7.ipynb</st>`
    <st c="64809">Jupyter notebook in the</st> <st c="64834">GitHub repository.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="64852">First, we’ll use the</st> `<st c="64874">statsmodels.stats.weightstats.CompareMeans</st>`
    <st c="64916">class to instantiate a</st> `<st c="64940">CompareMeans</st>` <st
    c="64952">object to run the confidence interval calculation.</st> <st c="65004">We
    just pass in our two samples of data, wrapped as</st> `<st c="65056">statsmodels.stats.weightstats.DescrStatsW</st>`
    <st c="65097">objects.</st> <st c="65107">Since we do not apply any non-uniform
    weights to the observations, we can pass each</st> `<st c="65191">pandas</st>`
    <st c="65197">series to the constructor for the</st> `<st c="65232">statsmodels.stats.weightstats.DescrStatsW</st>`
    <st c="65273">class:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: <st c="65457">Now, we’ll compute the 95% confidence level for the difference
    in means, using the</st> `<st c="65541">tconfint_diff</st>` <st c="65554">method
    of the</st> `<st c="65569">CompareMeans</st>` <st c="65581">class.</st> <st c="65589">The
    95% confidence level is</st> <st c="65617">the default:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: <st c="65705">This gives the</st> <st c="65721">following output:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: <st c="65779">We can see</st> <st c="65790">that the 95% confidence interval
    is entirely above zero, consistent with our earlier t-test, which was statistically
    significant</st> <st c="65920">at</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2512.png)<st
    c="65923"><st c="65924">.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="65925">With that code example complete, we have covered everything about
    confidence intervals that we need to, so we’ll now summarize what we learned</st>
    <st c="66069">about them.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="66080">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="66096">In this section, we learned</st> <st c="66125">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="66139">What a confidence interval is and how it quantifies our uncertainty
    about where the true value of a</st> <st c="66240">parameter lies</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="66254">How to calculate the confidence interval for the difference between
    two</st> <st c="66327">population means</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="66343">What factors affect a</st> <st c="66366">confidence interval</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="66385">How a confidence interval can be calculated for any</st> <st c="66438">population
    parameter</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="66458">How confidence intervals and hypothesis tests are linked and how
    to interpret a graphical depiction of a</st> <st c="66564">confidence interval</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="66583">Having introduced hypothesis tests and explained how the</st>
    *<st c="66641">p</st>*<st c="66642">-value threshold</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2695.png)
    <st c="66659"><st c="66660">controls the false positive rate, we’ll now move on
    to discussing false negatives and how to determine whether a hypothesis test has
    enough data available to reject the null hypothesis when</st> <st c="66851">it
    should.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="66861">Type I and Type II errors, and power</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="66898">We explained</st> <st c="66912">in the first section of this chapter
    that the significance threshold</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2696.png)
    <st c="66981"><st c="66982">is something we set, controlling the rate at which
    we get false positives.</st> <st c="67058">More correctly, the value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="67087"><st c="67088">is the probability of falsely rejecting the null hypothesis.</st>
    <st c="67150">It is also called the</st> **<st c="67172">Type-I error rate</st>**
    <st c="67189">(i.e., the rate at which we make errors of Type-I).</st> <st c="67242">The
    term “false positive” tends to be used more when we assess accuracy after an event,
    when we are comparing to some known ground truth (i.e., what the correct decision
    or classification should have been).</st> <st c="67449">Type-I error</st> <st
    c="67462">is a term used more when the null hypothesis is falsely rejected and
    when discussing a hypothesis test a priori (e.g., when we are designing it).</st>
    <st c="67608">The difference between the terms “false positive” and “Type-I error”
    is subtle, and for the most part, we ignore it and use the</st> <st c="67736">terms
    interchangeably.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="67758">But what about false negatives?</st> <st c="67791">What is the
    hypothesis test equivalent term for a false negative, and is there anything we
    can do to keep the false negative rate low?</st> <st c="67926">The hypothesis
    test equivalent of the false negative is</st> <st c="67981">the</st> **<st c="67986">Type-II
    error</st>**<st c="67999">. We make a Type-II error when we don’t reject the null
    hypothesis when we should have done (i.e., when the alternative hypothesis is
    true, but we accept the null hypothesis).</st> <st c="68175">So the Type-II error
    rate</st> <st c="68201">is</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext>Prob</mtext><mfenced
    open="(" close=")"><mrow><mtext>Accept</mtext><mtext>null</mtext><mtext>hypothesis</mtext><mo>|</mo><mtext>Alternative</mtext><mtext>hypothesis</mtext><mtext>is</mtext><mtext>true</mtext></mrow></mfenced></mrow></mrow></math>](img/2698.png)<st
    c="68204"><st c="68267">.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="68268">How can we make it more likely that we will reject the null hypothesis
    when we should do?</st> <st c="68359">Remember that we reject the null hypothesis
    when the</st> *<st c="68412">p</st>*<st c="68413">-value is less than the Type-I
    error rate threshold</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="68465"><st c="68466">. So, we can make it more likely that we will reject the
    null hypothesis by, first, increasing</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="68561"><st c="68562">, and second, decreasing the</st> *<st c="68591">p</st>*<st
    c="68592">-value.</st> <st c="68600">The first of these options isn’t really valid
    because increasing</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="68665"><st c="68666">would, by definition, increase our Type-I error rate.</st>
    <st c="68721">If we want to decrease the Type-II error rate while keeping the
    Type-I error rate fixed, then we need to look at what we can do to decrease the
    p-value.</st> <st c="68874">For our simple example of testing whether two means,</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>,</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mrow></math>](img/2702.png)<st
    c="68927"><st c="68928">, are different, we have already looked at what factors
    determine the</st> *<st c="68998">p</st>*<st c="68999">-value.</st> <st c="69007">To
    summarize them again, if we want to decrease the p-value, we need to do</st> <st
    c="69082">the following:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="69096">Have a larger difference in the population means (i.e.,</st> <st
    c="69153">increase</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:math>](img/2703.png)<st
    c="69162"><st c="69172">).</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="69174">Decrease the variability in the individual observations, (i.e.,
    decrease the noise</st> <st c="69258">variance</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2090.png)<st
    c="69267"><st c="69272">)</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="69273">Increase the sample</st> <st c="69293">size</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="69299">The first two of these quantities,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:math>](img/2706.png)
    <st c="69334"><st c="69344">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/1828.png)<st
    c="69348"><st c="69351">, are typically not within our control.</st> <st c="69391">So,
    the only realistic option is to increase</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)<st
    c="69436"><st c="69437">. But by how much?</st> <st c="69456">This brings us on
    to the concept of</st> **<st c="69492">power</st>**<st c="69497">. We determine
    a suitable value for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="69533"><st c="69534">by setting what we consider is an appropriate probability
    to accept the alternative hypothesis when it is true.</st> <st c="69647">The rate
    at which we accept the alternative hypothesis when it is true is called the power.</st>
    <st c="69739">It is the rate at which we detect true positives.</st> <st c="69789">For
    larger values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)<st
    c="69810"><st c="69811">, the power increases.</st> <st c="69834">If the power
    is reasonably high (e.g., > 80%), then we say that the hypothesis test is</st>
    **<st c="69921">sufficiently powered</st>**<st c="69941">. It should also be</st>
    <st c="69961">clear that,</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>1</mtext><mo>−</mo><mtext>power</mtext><mtext>=</mtext><mtext>Type-II</mtext><mtext>error</mtext><mtext>rate</mtext></mrow></mrow></math>](img/2711.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="70005">Eq.</st> <st c="70009">23</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="70011">Since the Type-I error rate</st> <st c="70039">is given the symbol</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="70060"><st c="70061">, the Type-II error rate is often given the symbol</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1503.png)<st
    c="70112"><st c="70113">, so we have 1 – power =</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1356.png)<st
    c="70138"><st c="70139">. We control the Type-I error rate by specifying a suitable
    value for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)<st
    c="70209"><st c="70210">, and we control</st> <st c="70227">the Type-II error
    rate by specifying a suitable value for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1503.png)
    <st c="70285"><st c="70286">or, equivalently, for</st> <st c="70309">the power.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="70319">Let’s look at a</st> <st c="70335">concrete example.</st> <st
    c="70354">We’ll return to our simple example in the first section of this chapter,
    where we ran a z-test on the difference between sample means coming from an A
    population and a B population.</st> <st c="70536">Let’s say that I want an 80%
    probability of accepting</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/2717.png)
    <st c="70590"><st c="70591">if</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/2717.png)
    <st c="70595"><st c="70596">is indeed true.</st> <st c="70613">We’ll assume that</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>N</mi><mi>A</mi></msub><mo>=</mo><msub><mi>N</mi><mi>B</mi></msub><mo>=</mo><mi>N</mi></mrow></mrow></math>](img/2719.png)<st
    c="70631"><st c="70632">. Now, how big does</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)
    <st c="70652"><st c="70653">need to be to give that 80% probability for a specified
    value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:math>](img/2703.png)<st
    c="70719"><st c="70729">,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/2090.png)
    <st c="70731"><st c="70736">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="70740"><st c="70741">?</st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="70742">First, we’ll convert the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="70776"><st c="70777">to its equivalent threshold for the test statistic</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi></mml:math>](img/62.png)<st
    c="70829"><st c="70830">. For a two-tailed test, this gives a threshold value
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msup><mml:mrow><mml:mtext>erf</mml:mtext></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math>](img/2726.png)
    <st c="70887"><st c="70903">For</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2727.png)<st
    c="70907"><st c="70908">, we already know that this threshold on</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi></mml:math>](img/22.png)
    <st c="70949"><st c="70950">is approximately 1.96\.</st> <st c="70974">So, for
    a power of 80% with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2512.png)<st
    c="71002"><st c="71003">, we need</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mfenced><mml:mo>></mml:mo><mml:mn>1.96</mml:mn></mml:math>](img/2730.png)
    <st c="71013"><st c="71014">to occur with a probability of 0.8 when the alternative
    hypothesis is true.</st> <st c="71091">The formula for the test statistic</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi></mml:math>](img/22.png)
    <st c="71126"><st c="71127">is shown in</st> *<st c="71140">Eq.</st> <st c="71144">15</st>*<st
    c="71146">. Combining these pieces of information gives</st> <st c="71192">the
    crite</st><st c="71201">rion,</st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Prob</mtext><mfenced
    open="(" close=")"><mrow><mo>|</mo><msub><mi>m</mi><mi>A</mi></msub><mo mathvariant="italic">−</mo><msub><mi>m</mi><mi>B</mi></msub><mo>|</mo><mo
    mathvariant="italic">></mo><mi>σ</mi><msqrt><mfrac><mn mathvariant="italic">2</mn><mi>N</mi></mfrac></msqrt><mo
    mathvariant="italic">×</mo><mn>1.96</mn></mrow></mfenced><mo>=</mo><mn>0.8</mn></mrow></mrow></math>](img/2732.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="71242">Eq.</st> <st c="71246">24</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="71248">To calculate the probability on the left-hand side of</st> *<st
    c="71303">Eq.</st> <st c="71307">24</st>*<st c="71309">, we essentially repeat
    the steps that led to</st> *<st c="71355">Eq.</st> <st c="71359">11</st>* <st
    c="71361">but with the added fact that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:math>](img/2733.png)<st
    c="71391"><st c="71392">. Doing so,</st> <st c="71404">we</st> <st c="71406">get,</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Prob</mtext><mfenced
    open="(" close=")"><mrow><mfenced open="|" close="|"><mrow><msub><mi>m</mi><mi>A</mi></msub><mo>−</mo><msub><mi>m</mi><mi>B</mi></msub></mrow></mfenced><mo>></mo><mi>σ</mi><msqrt><mfrac><mn>2</mn><mi>N</mi></mfrac></msqrt><mo>×</mo><mn>1.96</mn></mrow></mfenced><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mtext>erf</mtext><mfenced
    open="(" close=")"><mrow><mfrac><mn>1.96</mn><msqrt><mn>2</mn></msqrt></mfrac><mo>−</mo><mfrac><mrow><mfenced
    open="(" close=")"><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mfenced><msqrt><mi>N</mi></msqrt></mrow><mrow><mn>2</mn><mi>σ</mi></mrow></mfrac></mrow></mfenced><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mtext>erf</mtext><mfenced
    open="(" close=")"><mrow><mo>−</mo><mfrac><mn>1.96</mn><msqrt><mn>2</mn></msqrt></mfrac><mo>−</mo><mfrac><mrow><mfenced
    open="(" close=")"><mrow><msub><mi>μ</mi><mi>A</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>B</mi></msub></mrow></mfenced><msqrt><mi>N</mi></msqrt></mrow><mrow><mn>2</mn><mi>σ</mi></mrow></mfrac></mrow></mfenced></mrow></mrow></math>](img/2734.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="71491">Eq.</st> <st c="71495">25</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="71497">To determine</st> <st c="71510">the required sample size</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)
    <st c="71536"><st c="71537">we need to get 80% power, we simply set the right-hand
    side of</st> *<st c="71601">Eq.</st> <st c="71605">25</st>* <st c="71607">equal
    to 0.8 and solve the resulting expression</st> <st c="71656">for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)<st
    c="71660"><st c="71661">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="71662">For the t-test given in</st> *<st c="71687">Eq.</st> <st c="71691">16</st>*
    <st c="71693">to</st> *<st c="71697">Eq.</st> <st c="71701">18</st>*<st c="71703">,
    the calculation of the required value of</st> <st c="71746">N</st> <st c="71747">is
    slightly more complicated but follows the same principles.</st> <st c="71810">Fortunately,
    we don’t usually have to do the detailed calculation ourselves, as most statistical
    packages will have a power calculation function for each of the main hypothesis
    tests you are likely to carry out – for example, the</st> `<st c="72040">solve_power</st>`
    <st c="72051">function from the</st> `<st c="72070">statsmodels.stats.power.TTestIndPower</st>`
    <st c="72107">class.</st> <st c="72115">We can illustrate this with a</st> <st
    c="72145">code example.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="72158">A t-test power calculation code example</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="72198">We’ll</st> <st c="72205">calculate the sample size required to
    achieve a power of 80% when</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math>](img/2737.png)
    <st c="72271"><st c="72289">and we set</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2738.png)<st
    c="72300"><st c="72301">. This code example and more can be found in the</st>
    `<st c="72350">Code_Examples_Chap7.ipynb</st>` <st c="72375">Jupyter notebook
    in the</st> <st c="72400">GitHub repository:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: <st c="72619">This gives us the</st> <st c="72638">following output:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: <st c="72697">This means that if we have a sample size of approximately</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>64</mml:mn></mml:math>](img/2739.png)<st
    c="72756"><st c="72757">, we will have an 80% chance of rejecting the null hypothesis
    (and accepting</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/2740.png)<st
    c="72834"><st c="72835">) when</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math>](img/2741.png)
    <st c="72842"><st c="72857">and when we</st> <st c="72869">set</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2742.png)<st
    c="72873"><st c="72874">.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="72875">Although the preceding code example is very simple, and indeed
    the concept of power itself is relatively simple, there are still some nuances
    and subtleties regarding power calculations that</st> <st c="73066">you should
    be aware of.</st> <st c="73091">These include</st> <st c="73105">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="73119">The power of the t-test increases as the value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:math>](img/2743.png)
    <st c="73170"><st c="73182">increases.</st> <st c="73193">This makes intuitive
    sense.</st> <st c="73221">Bigger differences between populations are easier to
    detect (i.e., to reject the null hypothesis).</st> <st c="73320">Similarly, observations
    with lower noise levels (smaller</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/1828.png)<st
    c="73377"><st c="73380">) lead to a test with higher power, since the noise obscures
    the differences between the A and B populations to a</st> <st c="73494">lesser
    extent.</st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="73508">A smaller value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="73528"><st c="73529">requires a larger value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/686.png)
    <st c="73557"><st c="73558">to achieve a specified power.</st> <st c="73589">Again,
    this is intuitive.</st> <st c="73615">A smaller value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="73634"><st c="73635">means we are applying a more stringent criterion to
    reject the null hypothesis, and we need more evidence to support</st> <st c="73753">that
    decision.</st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="73767">The power calculation of the required sample size</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="73818"><st c="73819">requires us to know in advance suitable values for</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math>](img/2749.png)
    <st c="73871"><st c="73872">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/1669.png)<st
    c="73877"><st c="73880">. Where do we get these values from?</st> <st c="73917">The
    answer is from previous datasets, analyses, or experiments we may have run.</st>
    <st c="73997">Sometimes, it is from what seems reasonable values based on</st>
    <st c="74057">expert judgment.</st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="74073">Ideally, we should always perform a power calculation before running
    any hypothesis test.</st> <st c="74164">In some circumstances, it is mandatory
    to do so and unethical if we don’t.</st> <st c="74239">Consider a medical trial
    where we are going to expose some patients to a stressful or painful procedure
    as part of the treatment we are testing.</st> <st c="74384">If we ran an underpowered
    trial, we would be exposing patients to pain and stress unnecessarily, as there
    was no hope that the medical trial could have had a successful outcome (rejecting</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math>](img/2751.png)<st
    c="74572"><st c="74573">. We should only run a medical trial if there is a reasonable
    chance of detecting the kind of difference we expect the treatment to produce,
    so we should always run a correct and credible</st> <st c="74761">power calculation.</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="74779">For hypothesis tests that are more complex than a t-test, such
    as the sort that requires us to estimate the</st> *<st c="74888">p</st>*<st c="74889">-value
    via a computationally intensive sampling method, the calculation of power and
    estimation of required sample sizes is also computationally intensive.</st> <st
    c="75045">Computationally intensive power calculations are as straightforward
    as the computationally intensive calculation of</st> *<st c="75161">p</st>*<st
    c="75162">-values.</st> <st c="75171">Typically, we can just run several simulations
    of the hypothesis testing process at different values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="75275"><st c="75276">(and any other parameters in the test) to see how
    often we reject</st> <st c="75342">the null hypothesis.</st> <st c="75364">Once
    these “rejection rate curves” have been plotted out, we can read off the required
    value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="75460"><st c="75461">needed to achieve the desired level</st> <st c="75498">of
    power.</st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="75507">With those nuances about power calculations covered, it is time
    to wrap up this short section and the chapter as a whole.</st> <st c="75630">We’ll
    start by recapping what we learned in</st> <st c="75674">this section.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="75687">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="75703">In this section, we learned about</st> <st c="75738">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="75752">Type-I and Type-II errors and how the</st> *<st c="75791">p</st>*<st
    c="75792">-value threshold</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)
    <st c="75809"><st c="75810">sets the Type-I</st> <st c="75827">error rate</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="75837">How the Type-II error rate is set</st> <st c="75872">by power</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="75880">How a power calculation is used to determine the sample size needed
    to achieve a desired level</st> <st c="75976">of power</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="75984">How to use the inbuilt power calculations in packages such as</st>
    `<st c="76047">statsmodels</st>` <st c="76058">to perform</st> <st c="76070">power
    calculations</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="76088">Summary</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="76096">The focus of this chapter has been hypothesis testing.</st> <st
    c="76152">The chapter contained only three sections, but those sections contained
    a wealth of new ideas and concepts.</st> <st c="76260">Most of the new concepts
    centered around</st> *<st c="76301">p</st>*<st c="76302">-values – what they are,
    what they are not, how we calculate them, and how we interpret them.</st> <st
    c="76396">These are concepts that you must get to grips with as a working data
    scientist.</st> <st c="76476">To get to grips with them, we specifically learned
    about</st> <st c="76533">the following,</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="76547">How a hypothesis test consists of two hypotheses, the null hypothesis</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/2755.png)
    <st c="76618"><st c="76619">and the alternative hypothesis</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="script">H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/2756.png)<st
    c="76651"><st c="76652">, and how we calculate the</st> *<st c="76679">p</st>*<st
    c="76680">-value as the probability of getting the observed test statistic, or
    larger, if the null hypothesis</st> <st c="76780">is true.</st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="76788">How we use the numerical value of the</st> *<st c="76827">p</st>*<st
    c="76828">-value in comparison to a small threshold value,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2757.png)<st
    c="76877"><st c="76878">, as evidence to reject the null hypothesis and accept
    the</st> <st c="76937">alternative hypothesis</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="76959">How the threshold</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)
    <st c="76978"><st c="76979">controls the false positive rate of the</st> <st c="77020">hypothesis
    test</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77035">What the</st> *<st c="77045">p</st>*<st c="77046">-value is and
    what it</st> <st c="77068">is not</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77074">What factors affect</st> <st c="77095">the</st> *<st c="77099">p</st>*<st
    c="77100">-value</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77106">How all hypothesis tests approximately follow the same</st> <st
    c="77162">five-step process</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77179">How we can use computationally intensive methods to perform any
    hypothesis test</st> <st c="77260">we wish</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77267">How confidence intervals help us quantify the uncertainty associated
    with a parameter estimate and how to calculate a</st> <st c="77386">confidence
    interval</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77405">What factors affect the width of a</st> <st c="77441">confidence
    interval</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77460">What Type-I and Type-II errors are and how we control the Type-II
    error rate by specifying the required power of a</st> <st c="77576">hypothesis
    test</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77591">How to compute the sample size required to achieve a specified
    power from a</st> <st c="77668">hypothesis test</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="77683">In the next chapter, we will cover another self-contained topic
    that relates to models and how we assess them.</st> <st c="77795">We will introduce
    the idea of model complexity.</st> <st c="77843">We will learn how the complexity
    of a model we build affects</st> <st c="77904">its accuracy.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="77917">Exercises</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="77927">The following is a series of exercises.</st> <st c="77968">Answers
    to all the exercises are given in the</st> `<st c="78014">Answers_to_Exercises_Chap7.ipynb</st>`
    <st c="78046">Jupyter notebook in the</st> <st c="78071">GitHub repository:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="78089">The</st> `<st c="78094">Data/paired_sampled_ttest.csv</st>` <st
    c="78123">file in the GitHub repository contains two columns of data corresponding
    to observations on paired samples.</st> <st c="78232">Use the</st> `<st c="78240">scipy.stats.ttest_rel</st>`
    <st c="78261">function from the</st> `<st c="78280">SciPy</st>` <st c="78285">package
    to run a two-tailed paired-sample t-test.</st> <st c="78336">Is the difference
    between the sample means statistically significant at the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/2512.png)
    <st c="78412"><st c="78413">level?</st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="78419">The object returned by the</st> `<st c="78447">scipy.stats.ttest_rel</st>`
    <st c="78468">function has a method that computes a confidence interval for the
    difference between the population means.</st> <st c="78576">Look at the documentation
    on</st> `<st c="78605">scipy.stats.ttest_rel</st>` <st c="78626">to see how to
    use this confidence interval method, and use it to calculate a 95% confidence
    interval for the paired sample in</st> <st c="78753">question 1.</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="78764">A paired sample test can also be thought of as a one-sample test
    performed on the differences between the paired observations.</st> <st c="78892">The
    data in question 1 was collected from an experiment where the standardized effect
    size (the mean difference divided by the standard deviation of the differences)
    was, a priori, expected to be in the range 0.3–0.65\.</st> <st c="79111">Now,
    use the</st> `<st c="79124">statsmodels.stats.power.TTestPower.power</st>` <st
    c="79164">function from the</st> `<st c="79183">statstmodels</st>` <st c="79195">package
    to calculate the sample size required to achieve a power of 80% for a two-tailed,
    one-sample t-test, when the standardized effect is at the lower end of the expected
    range.</st> <st c="79377">What is the number of DOF you should</st> <st c="79414">use
    here?</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="79423">Notes and further reading</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '<st c="79449">A copy of the ASA statement on</st> *<st c="79481">p</st>*<st
    c="79482">-values and an interesting commentary can be found in this editorial:
    R.L.</st> <st c="79557">Wasserstein and N.A.</st> <st c="79578">Lazar,</st> *<st
    c="79585">The ASA’s Statement on p-Values: Context, Process, and Purpose</st>*<st
    c="79647">, The American Statistician, 70(2):129–133,</st> <st c="79691">2016:</st>
    [<st c="79697">https://amstat.tandfonline.com/doi/full/10.1080/00031305.2016.1154108#.ZE5wIHbMLb0</st>](https://amstat.tandfonline.com/doi/full/10.1080/00031305.2016.1154108#.ZE5wIHbMLb0)<st
    c="79779">.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="79780">A good online tutorial on non-parametric hypothesis testing with
    examples in Python is</st> *<st c="79868">How to Calculate Nonparametric Statistical
    Hypothesis Tests in Python</st>* <st c="79937">by Jason Brownlee.</st> <st c="79957">The
    article can be found at</st> [<st c="79985">https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/</st>](https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/)<st
    c="80075">. It is part of Jason Brownlee’s excellent</st> *<st c="80118">Machine
    Learning</st>* *<st c="80135">Mastery</st>* <st c="80142">website.</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '<st c="80151">For a book covering the general area of non-parametric statistics,
    I recommend</st> *<st c="80231">All of Nonparametric Statistics</st>* <st c="80262">by
    Larry Wasserman, Springer, New York, 2010\.</st> <st c="80309">ISBN: 978-1-4419-2044-7.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '<st c="80333">Some people find the Wasserman book too theoretical for their
    tastes, so a more applied book that I recommend is</st> *<st c="80447">Practical
    Nonparametric Statistics</st>*<st c="80481">,</st> *<st c="80483">3rd Edition</st>*<st
    c="80494">, by W.J.</st> <st c="80504">Conover, John Wiley & Sons, New York, 1998\.</st>
    <st c="80548">ISBN: 978-0-471-16068-7\.</st> <st c="80573">The first edition of
    the book was written in 1971, so the material is limited in its coverage of non-parametric
    statistics topics compared to the Wasserman book.</st> <st c="80735">However,
    the focus of the book is very much on learning through application</st> <st c="80811">with
    examples.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
