<html><head></head><body>
		<div id="_idContainer4581">
			<h1 id="_idParaDest-354" class="chapter-number"><a id="_idTextAnchor646"/><st c="0">1</st><a id="_idTextAnchor647"/><st c="2">3</st></h1>
			<h1 id="_idParaDest-355"><a id="_idTextAnchor648"/><st c="3">Information Theory</st></h1>
			<p><st c="21">Information theory and information-theoretic concepts are very useful, but it is unlikely that you will have to formally make use of them as a data scientist. </st><st c="181">By this, we mean that you are unlikely to have to use detailed information-theoretic mathematical proofs or techniques in your work. </st><st c="314">But – and it’s an important but – the ideas and ways of thinking that information theory introduces are worth understanding. </st><st c="439">And that is what this chapter aims to achieve. </st><st c="486">To do that, we will cover the </st><span class="No-Break"><st c="516">following topics:</st></span></p>
			<ul>
				<li><em class="italic"><st c="533">What is information and why is it useful?</st></em><st c="575">: Here, we’ll define precisely what we mean by information and how we quantify </st><span class="No-Break"><st c="655">it mathematically</st></span></li>
				<li><em class="italic"><st c="672">Entropy as expected information</st></em><st c="704">: Here, we’ll introduce the concept of the average information associated with a random variable and its </st><span class="No-Break"><st c="810">probability distribution</st></span></li>
				<li><em class="italic"><st c="834">Mutual information</st></em><st c="853">: Here, we’ll extend our information theory concepts to multiple </st><span class="No-Break"><st c="919">random variables</st></span></li>
				<li><em class="italic"><st c="935">The Kullback-Leibler divergence</st></em><st c="967">: Here, we’ll extend our information theory concepts to multiple distributions and show how we can use them to build optimal approximations </st><span class="No-Break"><st c="1108">of distributions</st></span></li>
			</ul>
			<h1 id="_idParaDest-356"><a id="_idTextAnchor649"/><st c="1124">Technical requirements</st></h1>
			<p><st c="1147">All the code examples provided in this chapter can be found in this book’s GitHub repository at </st><a href="https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter13"><st c="1244">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter13</st></a><st c="1348">. To run the Jupyter notebooks, you will need a full Python installation that includes the </st><span class="No-Break"><st c="1439">following packages:</st></span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline"><st c="1458">pandas</st></strong></span><span class="No-Break"><st c="1465"> (&gt;=2.0.3)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="1475">numpy</st></strong></span><span class="No-Break"><st c="1481"> (&gt;=1.24.3)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="1492">scipy</st></strong></span><span class="No-Break"><st c="1498"> (&gt;=1.11.1)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="1509">scikit-learn</st></strong></span><span class="No-Break"><st c="1522"> (&gt;=1.3.0)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="1532">matplotlib</st></strong></span><span class="No-Break"><st c="1543"> (&gt;=3.7.2)</st></span></li>
			</ul>
			<h1 id="_idParaDest-357"><a id="_idTextAnchor650"/><st c="1553">What is information and why is it useful?</st></h1>
			<p><st c="1595">As we said in the introduction, information theory and information-theoretic ideas are very useful. </st><st c="1696">To understand those ideas, one of the first things we must address is what we mean by </st><em class="italic"><st c="1782">information</st></em><st c="1793">. I am talking conceptually here. </st><st c="1827">Once we have nailed down our conception of what information is about, writing down a mathematical definition will </st><span class="No-Break"><st c="1941">be easier.</st></span></p>
			<h2 id="_idParaDest-358"><a id="_idTextAnchor651"/><st c="1951">The concept of information</st></h2>
			<p><st c="1978">Part of the</st><a id="_idIndexMarker1072"/><st c="1990"> difficulty in</st><a id="_idIndexMarker1073"/><st c="2004"> introducing information theory as a mathematical subject is that different people use the word “information” and apply it to different concepts. </st><st c="2150">For example, the word “information” could apply to </st><span class="No-Break"><st c="2201">the following:</st></span></p>
			<ul>
				<li><st c="2215">The semantic content or meaning of an action or event, such as a particular word being spoken or written. </st><st c="2322">This is the most common conception that people have of what information should be about. </st><st c="2411">It is the idea that the information associated with a thing should somehow be related to what that </st><span class="No-Break"><st c="2510">thing means.</st></span></li>
				<li><st c="2522">The intended effect or purpose of an action or event. </st><st c="2577">When speaking a particular word, or triggering a specific event, we usually have an intended outcome that we would like to achieve or engineer. </st><st c="2721">The association between the event and outcome may not be perfect, but we might think that the information associated with the event measures something about the </st><span class="No-Break"><st c="2882">desired outcome.</st></span></li>
				<li><st c="2898">How well an action or event encodes or identifies the thing it was intended to communicate. </st><st c="2991">This is like the previous possible interpretation of “information,” but rather than concerning ourselves with how signal and outcome are related, in this interpretation, we focus solely on the efficiency and precision of the communication process. </st><st c="3239">This is a narrower interpretation of what “information” </st><span class="No-Break"><st c="3295">is about.</st></span></li>
			</ul>
			<p><st c="3304">As you can</st><a id="_idIndexMarker1074"/><st c="3315"> imagine, the last of those interpretations of what “information” should be about is the narrowest of the three, and so also the easiest to define mathematically. </st><st c="3478">Therefore, you will not be surprised that this is the conceptual definition of what “information” is about that mathematicians and scientists have settled on. </st><st c="3637">Indeed, the founder of modern information theory, Claude Shannon, titled his 1948 landmark paper on information theory </st><em class="italic"><st c="3756">A mathematical theory of communication</st></em><st c="3794">. For mathematicians, statisticians, scientists, engineers, and data scientists, information theory concerns itself with quantifying the efficiency of communication. </st><st c="3960">For a longer discussion of the various possible interpretations of “information”, see [</st><em class="italic"><st c="4047">1</st></em><st c="4049">] in the </st><em class="italic"><st c="4058">Notes and urther reading</st></em><st c="4082"> section at the end of </st><span class="No-Break"><st c="4105">this chapter.</st></span></p>
			<p><st c="4118">So, we’ve nailed down conceptually what we mean when we use the word “information,” but how do we define it mathematically so that we can </st><span class="No-Break"><st c="4257">measure it?</st></span></p>
			<h2 id="_idParaDest-359"><a id="_idTextAnchor652"/><st c="4268">The mathematical definition of information</st></h2>
			<p><st c="4311">In </st><a id="_idIndexMarker1075"/><st c="4315">the UK, when I was growing up, there was a popular game called “Guess Who.” The game consisted of two players, who would each have an identical set of character playing cards, such as those shown in </st><span class="No-Break"><em class="italic"><st c="4514">Figure 13</st></em></span><em class="italic"><st c="4523">.1</st></em><st c="4525">. Each player would choose a character in secret. </st><st c="4575">Each player had to guess the character chosen by their opponent by asking questions about the attributes of their opponent’s chosen character – for example, “Are they wearing a hat?” or “Do they have black hair?” – with just “yes” or “no” answers to the questions. </st><st c="4840">The winner of the game was the person who could identify their opponent’s chosen </st><span class="No-Break"><st c="4921">character first.</st></span></p>
			<div>
				<div id="_idContainer4132" class="IMG---Figure">
					<img src="image/B19496_13_1.jpg" alt="Figure 13.1: The game of identifying a person from their attributes"/><st c="4937"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="4939">Figure 13.1: The game of identifying a person from their attributes</st></p>
			<p><st c="5006">Now, imagine </st><a id="_idIndexMarker1076"/><st c="5020">that you and I were playing the game and you asked me if my chosen character was working at a computer, and I said yes. </st><st c="5140">With that answer, you could immediately identify who my chosen character was from the characters in </st><span class="No-Break"><st c="5240">Figure 13</st></span><st c="5249">.1. </st><st c="5253">The information content of the answer was very high because it communicated very efficiently (precisely in fact) which character we were talking about. </st><st c="5405">The answer, “Yes, the person is working at a computer” encodes very precisely the signal about which character I selected </st><span class="No-Break"><st c="5527">in secret.</st></span></p>
			<p><st c="5537">Alternatively, if you asked the question, “Is your selected character a person,” I would also reply yes. </st><st c="5643">It would have been a very silly question to ask, but for illustration purposes, we’ll stick with it. </st><st c="5744">All the characters in </st><span class="No-Break"><st c="5766">Figure 13</st></span><st c="5775">.1 are people, so my answer, “Yes, they are a person” does not help you narrow down the identity of my selected character. </st><st c="5898">My answer does not efficiently encode the signal about who I </st><span class="No-Break"><st c="5959">have chosen.</st></span></p>
			<p><st c="5971">From this, we can see that the information content of my answers, how efficiently it communicated to you who I had chosen, was dependent on how rare the attribute you were asking about was – having a computer was rare (only one character did) while being a person was common (all the characters were people). </st><st c="6281">Since the rarity of an attribute is defined by the probability distribution of the attribute, such as </st><img src="image/3993.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Prob&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Has&lt;/mtext&gt;&lt;mtext&gt;Computer&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.290em;height:1.004em;width:8.139em"/><st c="6383"/><st c="6402"> or </st><img src="image/3994.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Prob&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Has&lt;/mtext&gt;&lt;mtext&gt;Black&lt;/mtext&gt;&lt;mtext&gt;Hair&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.062em;height:0.823em;width:8.684em"/><st c="6405"/><st c="6427">, this also tells us that the mathematical definition of information is related to probability and that information-theoretic concepts are probabilistic. </st><st c="6581">This is another reason why we emphasized the importance of understanding probability in </st><a href="B19496_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic"><st c="6669">Chapter 2</st></em></span></a><span class="No-Break"><st c="6678">.</st></span></p>
			<p><st c="6679">We now know </st><a id="_idIndexMarker1077"/><st c="6692">that the information associated with a thing or event is related to the probability of that thing or event occurring. </st><st c="6810">We also know that the lower the probability of the thing or event occurring, the higher the amount of information associated </st><span class="No-Break"><st c="6935">with it.</st></span></p>
			<p><st c="6943">The formal mathematical definition of the amount of information associated with an event, </st><img src="image/3995.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.455em"/><st c="7034"/><st c="7035">, occurring is </st><span class="No-Break"><st c="7050">as follows:</st></span></p>
			<p><img src="image/3996.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mtext&gt;Information = &lt;/mml:mtext&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:13.603em"/><st c="7061"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="7091">Eq. </st><st c="7095">1</st></p>
			<p><st c="7096">We have been very formal in Eq. </st><st c="7128">1 and used the </st><img src="image/3997.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.031em;width:4.192em"/><st c="7143"/><st c="7152"> notation to emphasize that we are dealing with a random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.638em"/><st c="7218"/><st c="7219">, and we are talking about the information associated with </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.638em"/><st c="7278"/><st c="7279"> taking a value of </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="7298"/><st c="7299">. Information itself is specifically concerned with the probability of a specific outcome, </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="7390"/><st c="7391">, not the full distribution, </st><img src="image/4002.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.031em;width:4.133em"/><st c="7420"/><st c="7429">. We will encounter information-theoretic concepts such as entropy, which are associated with probability distributions, later. </st><st c="7557">Because information increases as </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.470em"/><st c="7590"/><st c="7591"> becomes rarer, and hence more surprising if we do see it, it is also said to</st><a id="_idIndexMarker1078"/><st c="7668"> represent the </st><strong class="bold"><st c="7683">degree of surprise</st></strong> <span class="No-Break"><st c="7701">of </st></span><span class="No-Break"><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.468em"/><st c="7705"/></span><span class="No-Break"><st c="7706">.</st></span></p>
			<p><st c="7707">One of the first things you may notice about Eq. </st><st c="7757">1 is that we haven’t said which base we’re using when taking the logarithm. </st><st c="7833">Most times, when we have a logarithm in a formula, the choice of base does not affect the </st><strong class="bold"><st c="7923">decision</st></strong><st c="7931"> we make based on the formula. </st><st c="7962">Here, however, we are using the logarithm not to make a decision, but to directly quantify the amount of information associated with the outcome, </st><img src="image/4005.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:2.654em"/><st c="8108"/><st c="8109">. The choice of base will have an </st><span class="No-Break"><st c="8143">effect here.</st></span></p>
			<p><st c="8155">So, which base should we use? </st><st c="8186">It is up to you, but there are some commonly used bases. </st><st c="8243">The most common is base 2, in which case we define the information associated with the outcome, </st><img src="image/4005.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:2.655em"/><st c="8339"/><st c="8340">, to be </st><span class="No-Break"><st c="8348">as follows:</st></span></p>
			<p><img src="image/4007.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mtext&gt;Information = &lt;/mml:mtext&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:13.933em"/><st c="8359"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="8390">Eq. </st><st c="8394">2</st></p>
			<p><st c="8395">When we use base 2 for measuring information, the amount of information is said to be measured in </st><strong class="bold"><st c="8493">bits</st></strong><st c="8497">. This means that Eq. </st><st c="8519">2 tells us the number of bits of information associated with the outcome, </st><img src="image/4008.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:2.619em"/><st c="8593"/><st c="8594">. Less frequently, you may see the term </st><strong class="bold"><st c="8634">Shannon</st></strong><st c="8641"> used instead of </st><strong class="bold"><st c="8658">bit</st></strong><st c="8661"> for the unit of information when using base 2. </st><st c="8709">Of course, we could choose a different </st><a id="_idIndexMarker1079"/><st c="8748">base to use for our logarithm in Eq. </st><st c="8785">1. </st><st c="8788">The other most common choices are </st><span class="No-Break"><st c="8822">as follows:</st></span></p>
			<ul>
				<li><st c="8833">Base </st><img src="image/162.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.416em"/><st c="8839"/><st c="8840">, so that we use the natural logarithm, and the information associated with </st><img src="image/4010.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:2.724em"/><st c="8916"/><st c="8917"> is calculated as </st><img src="image/4011.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;ln&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:5.771em"/><st c="8935"/><st c="8949">. Unsurprisingly, when we use the natural logarithm, we say the information is measured </st><span class="No-Break"><st c="9037">in </st></span><span class="No-Break"><em class="italic"><st c="9040">nats</st></em></span><span class="No-Break"><st c="9044">.</st></span></li>
				<li><st c="9045">Base 10, so that the information associated with </st><img src="image/4012.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:2.683em"/><st c="9095"/><st c="9096"> is calculated as </st><img src="image/4013.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:6.803em"/><st c="9114"/><st c="9128">. In this case, we say the information is measured in </st><em class="italic"><st c="9182">Hartleys</st></em><st c="9190">, or </st><em class="italic"><st c="9195">Harts</st></em><st c="9200">, named after the electronics pioneer Ralph Hartley, who contributed to the foundations of information theory. </st><st c="9311">You may also see the words </st><em class="italic"><st c="9338">ban</st></em><st c="9341"> and </st><em class="italic"><st c="9346">dit</st></em><st c="9349"> used when measuring information with base </st><span class="No-Break"><st c="9392">10 logarithms.</st></span></li>
			</ul>
			<p><st c="9406">The second thing you should notice about Eq. </st><st c="9452">1 is that it is monotonic in terms of probability. </st><span class="No-Break"><st c="9503">Figure 13</st></span><st c="9512">.2 shows a plot of the information (measured in bits) associated with an event and the probability of </st><span class="No-Break"><st c="9614">that eve</st><a id="_idTextAnchor653"/><st c="9622">nt:</st></span></p>
			<div>
				<div id="_idContainer4154" class="IMG---Figure">
					<img src="image/B19496_13_2.jpg" alt="" role="presentation"/><st c="9626"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="9713">Figure 13.2: A plot of information content, measured in bits, of an event, and the probability of that event</st></p>
			<p><st c="9821">The monotonic nature of the curve in </st><span class="No-Break"><st c="9859">Figure 13</st></span><st c="9868">.2 confirms what we outlined earlier, namely that the rarer an event is, the more insight or information it gives us, with very rare events having high information content. </st><st c="10041">For example, an event that occurs only 1 in 100 times, and so has a probability of occurrence of 0.01, has an information content of </st><img src="image/4014.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0.01&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mn&gt;6.64&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.044em;width:7.756em"/><st c="10174"/><st c="10193"> bits. </st><st c="10199">At this point, it is also worth highlighting that an event that has a 50% probability of occurring has an information content in bits of </st><img src="image/4015.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.044em;width:5.246em"/><st c="10336"/><st c="10350">. This is a good reason for measuring information in bits because we can easily remember that an event that is equally likely to occur as not has 1 bit of information associated </st><span class="No-Break"><st c="10528">with it.</st></span></p>
			<h2 id="_idParaDest-360"><a id="_idTextAnchor654"/><st c="10536">Information theory applies to continuous distributions as well</st></h2>
			<p><st c="10599">We</st><a id="_idIndexMarker1080"/><st c="10602"> introduced the mathematical definition of information by talking about the probability of an event or outcome. </st><st c="10714">Implicit in that is that we are talking about an outcome from a discrete random variable. </st><st c="10804">This was also explicit in our “Guess Who” game example, where we spoke about the probability of a character having a particular attribute, such as black hair. </st><st c="10963">Can we generalize the definition of information to continuous probability distributions? </st><st c="11052">The answer is yes. </st><st c="11071">For a continuous random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.635em"/><st c="11105"/><st c="11106">, with probability density, </st><img src="image/4017.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.903em;width:2.008em"/><st c="11134"/><st c="11139">, we can always define a particular event that </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="11186"/><st c="11187"> takes a value between </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="11210"/><st c="11211"> and </st><img src="image/4020.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:2.527em"/><st c="11216"/><st c="11223">. So, from the density, </st><img src="image/4021.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.903em;width:2.001em"/><st c="11247"/><st c="11252">, we can always create discrete events and an associated probability distribution. </st><st c="11335">That means with a bit more mathematical work, we can extend information-theoretic concepts to continuous random variables as well. </st><st c="11466">We will see this in action when we introduce the concept of entropy in the </st><span class="No-Break"><st c="11541">next section.</st></span></p>
			<p><st c="11554">It may be tempting to think that from what we just said we can assign an information value to the value, </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.462em"/><st c="11660"/><st c="11661">, of a continuous random variable. </st><st c="11696">Surely we can just define information as </st><img src="image/4023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:4.195em"/><st c="11737"/><st c="11748">? Strictly speaking, no. </st><img src="image/4017.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.903em;width:2.008em"/><st c="11773"/><st c="11778"> is a probability density, not a probability, and information can only be measured on probabilities. </st><st c="11878">However, you may see expressions such as </st><img src="image/4025.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:3.964em"/><st c="11919"/><st c="11928"> loosely or sloppily used in informal proofs of information-theoretic formulae. </st><st c="12007">In these circumstances, it is almost always the case that the proof can easily be made more rigorous and we arrive at the </st><span class="No-Break"><st c="12129">same formulae.</st></span></p>
			<h2 id="_idParaDest-361"><a id="_idTextAnchor655"/><st c="12143">Why we measure information on a logarithmic scale</st></h2>
			<p><st c="12193">You</st><a id="_idIndexMarker1081"/><st c="12197"> may have looked at Eq. </st><st c="12221">1 and asked why we measure information on a log scale. </st><st c="12276">Why did we use the logarithm function in Eq. </st><st c="12321">1 when we could, in principle, have used any other monotonically increasing function </st><span class="No-Break"><st c="12406">of </st></span><span class="No-Break"><img src="image/4026.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.031em;width:4.240em"/><st c="12409"/></span><span class="No-Break"><st c="12418">?</st></span></p>
			<p><st c="12419">The simplest answer is the one Shannon gave in his original paper on </st><em class="italic"><st c="12488">A mathematical theory of communciation</st></em><st c="12526">. Since we think of the information associated with an event with how much it helps us narrow down possibilities, a probability of </st><img src="image/4027.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.164em;height:0.858em;width:0.284em"/><st c="12657"/><st c="12658"> helps us narrow down </st><a id="_idIndexMarker1082"/><st c="12680">possibilities twice as much as a probability of </st><img src="image/4028.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.166em;height:0.860em;width:0.279em"/><st c="12728"/><st c="12729">. In our game of “Guess Who”, an attribute that only 25% of characters have, such as possessing a stethoscope, could narrow down the field of possible characters twice as much as an attribute that 50% of the characters have, such as possessing a hat. </st><st c="12980">Likewise, a probability of </st><img src="image/4029.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;20&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.173em;height:0.867em;width:0.559em"/><st c="13007"/><st c="13008"> helps us narrow down possibilities twice as much as a probability of </st><img src="image/4030.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.173em;height:0.867em;width:0.556em"/><st c="13078"/><st c="13079">. Therefore, it is natural for us to want to measure information in such a way that the difference in information between probabilities of </st><img src="image/4027.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.164em;height:0.858em;width:0.292em"/><st c="13218"/><st c="13219"> and </st><img src="image/4028.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.166em;height:0.860em;width:0.280em"/><st c="13224"/><st c="13225"> is the same as the difference in information between probabilities of </st><img src="image/4029.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;20&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.173em;height:0.867em;width:0.559em"/><st c="13296"/><st c="13297"> and </st><img src="image/4030.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.173em;height:0.867em;width:0.559em"/><st c="13302"/><st c="13303">. This means using a monotonic function, </st><img src="image/126.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.270em"/><st c="13344"/><st c="13398">, so that we have </st><span class="No-Break"><st c="13416">the following:</st></span></p>
			<p><img src="image/4036.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;20&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.477em;height:1.546em;width:12.525em"/><st c="13430"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="13432">Eq. </st><st c="13436">3</st></p>
			<p><st c="13437">Or more generally, the function, </st><img src="image/126.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.270em"/><st c="13470"/><st c="13524">, must satisfy the </st><span class="No-Break"><st c="13543">following equation:</st></span></p>
			<p><img src="image/4038.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mtext&gt; for any &lt;/mml:mtext&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;∈&lt;/mml:mo&gt;&lt;mml:mo&gt;[&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;]&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mtext&gt; and &lt;/mml:mtext&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:mo&gt;∈&lt;/mml:mo&gt;&lt;mml:mo&gt;[&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;]&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:29.402em"/><st c="13562"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="13630">Eq. </st><st c="13634">4</st></p>
			<p><st c="13635">Eq. </st><st c="13639">4 is only satisfied by the logarithm function. </st><st c="13686">So, if we want halving the probability of occurrence to always lead to a linear increase in information, we must measure information on a </st><span class="No-Break"><st c="13824">logarithmic scale.</st></span></p>
			<h2 id="_idParaDest-362"><a id="_idTextAnchor656"/><st c="13842">Why is quantifying information useful?</st></h2>
			<p><st c="13881">In short, information theory</st><a id="_idIndexMarker1083"/><st c="13910"> is useful because it enables us to quantify how efficiently a signal is encoded when being transmitted. </st><st c="14015">That means we can use information theory to work out better encodings and ultimately optimize the encoding, and in doing so minimize any signal loss at the receiving end. </st><st c="14186">The practical applications of information theory to signal analysis and communications design </st><span class="No-Break"><st c="14280">are huge.</st></span></p>
			<p><st c="14289">In information theory, the person transmitting the signal is called the </st><strong class="bold"><st c="14362">transmitter</st></strong><st c="14373">, and the person or </st><a id="_idIndexMarker1084"/><st c="14393">process wanting to receive the signal is the </st><strong class="bold"><st c="14438">receiver</st></strong><st c="14446">. The </st><a id="_idIndexMarker1085"/><st c="14452">transmitter transmits the signal via some communication channel. </st><st c="14517">When transmitting the signal via the channel, the signal is encoded. </st><st c="14586">This scenario is represented schematically in </st><span class="No-Break"><st c="14632">Figu</st><a id="_idTextAnchor657"/><st c="14636">re 13</st></span><span class="No-Break"><st c="14642">.3:</st></span></p>
			<div>
				<div id="_idContainer4180" class="IMG---Figure">
					<img src="image/B19496_13_3.jpg" alt="" role="presentation"/><st c="14645"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="14896">Figure 13.3: Schematic of the signal transmission and receiving process</st></p>
			<p><st c="14967">For a</st><a id="_idIndexMarker1086"/><st c="14973"> specific example, think about when you have a conversation with a friend using your cell phone. </st><st c="15070">Your voice signal – changes in air pressure caused by you speaking – is encoded digitally and transmitted via radio waves, then decoded, and sent as electrical signals to the speaker in your friend’s </st><span class="No-Break"><st c="15270">cell phone.</st></span></p>
			<p><st c="15281">In our “Guess Who” game, I was (reluctantly) transmitting the signal of which character I had selected. </st><st c="15386">I encoded that signal (the chosen character’s identity) by sending details of attributes the character had – for example, they had a stethoscope. </st><st c="15532">The information associated with that single attribute, as measured by </st><img src="image/4039.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Character&lt;/mtext&gt;&lt;mtext&gt;has&lt;/mtext&gt;&lt;mtext&gt;stethoscope&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.290em;height:1.051em;width:12.768em"/><st c="15602"/><st c="15636">, quantitatively tells me how well the attribute has encoded the signal (which character I chose). </st><st c="15735">In this case, the encoding is not perfect as it only narrows down the possibilities in </st><span class="No-Break"><st c="15822">Figure 13</st></span><st c="15831">.1 to two people. </st><st c="15849">It is lossy. </st><st c="15862">I could make it better. </st><st c="15886">For example, I could increase the message length and include more attributes, such as that the character has a stethoscope and black hair, which picks out just one person in </st><span class="No-Break"><st c="16060">Figure 13</st></span><st c="16069">.1, or I could use an attribute that encodes the signal more efficiently, such as that they have a computer, which picks out </st><span class="No-Break"><st c="16194">one person.</st></span></p>
			<p><st c="16205">Signal loss in the communication process may also occur because the communication channel is itself noisy – that is, it corrupts the encoded signal as it is transmitted. </st><st c="16376">Information theory also focuses on how to design robust encoding processes that can handle noisy imperfect communication channels, so information theory is a particular focus of companies building and running cell </st><span class="No-Break"><st c="16590">phone networks.</st></span></p>
			<p><st c="16605">Having explained what we mean by information, and how and why we quantify it, this is a good place to wrap up this section with a recap of what we </st><span class="No-Break"><st c="16753">have learned.</st></span></p>
			<h2 id="_idParaDest-363"><a id="_idTextAnchor658"/><st c="16766">What we’ve learned</st></h2>
			<p><st c="16785">In this section, we’ve learned </st><span class="No-Break"><st c="16817">the following:</st></span></p>
			<ul>
				<li><st c="16831">Information theory concerns itself with the communication of signals and the efficiency of encoding </st><span class="No-Break"><st c="16932">those signals.</st></span></li>
				<li><st c="16946">Information-theoretic concepts are </st><span class="No-Break"><st c="16982">probabilistic concepts.</st></span></li>
				<li><st c="17005">The smaller the probability of an event or outcome occurring, the higher the information associated with that event </st><span class="No-Break"><st c="17122">or outcome.</st></span></li>
				<li><st c="17133">We measure information on a </st><span class="No-Break"><st c="17162">logarithmic scale.</st></span></li>
				<li><st c="17180">When we use logarithms to base 2, the resulting information is measured in bits. </st><st c="17262">When we use logarithms to base </st><img src="image/162.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.400em"/><st c="17293"/><st c="17294">, the resulting information is measured in nats. </st><st c="17343">When we use logarithms to base 10, the resulting information is measured in Hartleys, Harts, bans, </st><span class="No-Break"><st c="17442">or dits.</st></span></li>
				<li><st c="17450">When transmitting to another user (the receiver), the information associated with the encoding used tells us how efficient that encoding is in communicating the signal to </st><span class="No-Break"><st c="17622">the receiver.</st></span></li>
			</ul>
			<p><st c="17635">Having learned that the information associated with a single outcome is defined from the probability of that single outcome occurring, in the next section, we will learn about information-theoretic concepts that relate to the whole probability distribution of </st><span class="No-Break"><st c="17896">possible outcomes.</st></span></p>
			<h1 id="_idParaDest-364"><a id="_idTextAnchor659"/><st c="17914">Entropy as expected information</st></h1>
			<p><st c="17946">For our “Guess Who” game, there</st><a id="_idIndexMarker1087"/><st c="17978"> are several attributes that a character can have. </st><st c="18029">Here, I have listed the complete (for this purpose) set of </st><span class="No-Break"><st c="18088">possible attributes:</st></span></p>
			<ul>
				<li><st c="18108">Has </st><span class="No-Break"><st c="18113">a hat</st></span></li>
				<li><st c="18118">Has </st><span class="No-Break"><st c="18123">a stethoscope</st></span></li>
				<li><st c="18136">Has </st><span class="No-Break"><st c="18141">black hair</st></span></li>
				<li><st c="18151">Has </st><span class="No-Break"><st c="18156">a computer</st></span></li>
				<li><st c="18166">Has a </st><span class="No-Break"><st c="18173">chemical flask</st></span></li>
			</ul>
			<p><st c="18187">From what </st><a id="_idIndexMarker1088"/><st c="18198">we’ve learned about information theory so far, we’ve seen that if I tell you my chosen character has a computer, then you can narrow down the possibilities to a single character. </st><st c="18377">This might suggest that asking if my chosen character has a computer is the most efficient question you can ask me. </st><st c="18493">This isn’t quite true. </st><st c="18516">There is no guarantee that my chosen character does have a computer. </st><st c="18585">To identify the best question to ask, we should </st><a id="_idIndexMarker1089"/><st c="18633">look at the </st><strong class="bold"><st c="18645">expected information</st></strong><st c="18665"> you’ll get by asking </st><span class="No-Break"><st c="18687">a question.</st></span></p>
			<p><st c="18698">How do we calculate the expected amount of information you get from asking a single question? </st><st c="18793">We’ll use a character having a stethoscope to illustrate this. </st><st c="18856">Two out of the eight characters in </st><span class="No-Break"><st c="18891">Figure 13</st></span><st c="18900">.1 have a stethoscope, so </st><img src="image/4041.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Has&lt;/mtext&gt;&lt;mtext&gt;Stethoscope&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.290em;height:1.051em;width:9.271em"/><st c="18926"/><st c="18949">. So, </st><img src="image/4042.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Doesn&lt;/mtext&gt;&lt;mtext&gt;'&lt;/mtext&gt;&lt;mtext&gt;t&lt;/mtext&gt;&lt;mtext&gt;have&lt;/mtext&gt;&lt;mtext&gt;stethoscope&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.290em;height:1.051em;width:13.327em"/><st c="18955"/><st c="18987">. If you ask me the question, “Does your chosen character have a stethoscope?”, there are two possible outcomes: “yes” or “no.” If the answer is “yes,” that narrows my chosen character down to two possibilities and gives you </st><img src="image/4043.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.044em;width:2.806em"/><st c="19212"/><st c="19220">)  bits of information. </st><st c="19243">If the answer is “no,” that narrows my chosen character down to six possibilities and gives you </st><img src="image/4044.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.044em;width:3.154em"/><st c="19339"/><st c="19349">  bits </st><span class="No-Break"><st c="19354">of information.</st></span></p>
			<p><st c="19369">Now, how likely is my answer to be “yes,” and how likely is my answer to be “no?” We already know these probabilities. </st><st c="19489">They are </st><img src="image/4027.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.164em;height:0.858em;width:0.296em"/><st c="19498"/><st c="19499"> and </st><img src="image/4046.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.164em;height:0.865em;width:0.282em"/><st c="19504"/><st c="19505">, respectively. </st><st c="19521">That means we can easily calculate the average or expected amount of information you are going to get from me in response to your question. </st><st c="19661">It is </st><span class="No-Break"><st c="19667">as follows:</st></span></p>
			<p><img src="image/4047.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;mfrac&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mn&gt;0.811&lt;/mn&gt;&lt;mspace width=&quot;0.25em&quot; /&gt;&lt;mtext&gt;bits&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.434em;height:1.409em;width:13.712em"/><st c="19678"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="19714">Eq. </st><st c="19718">5</st></p>
			<p><st c="19719">Let’s write Eq. </st><st c="19735">5 </st><span class="No-Break"><st c="19737">more symbolically:</st></span></p>
			<p><img src="image/4048.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtext&gt;Has stethoscope&lt;/mtext&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtext&gt;Has stethoscope&lt;/mtext&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Doesn&lt;/mtext&gt;&lt;mtext&gt;’&lt;/mtext&gt;&lt;mtext&gt;t have stethoscope&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Doesn&lt;/mtext&gt;&lt;mtext&gt;’&lt;/mtext&gt;&lt;mtext&gt;t have stethoscope&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.094em;width:34.164em"/><st c="19755"/><span class="_-----MathTools-_Math_Base"><img src="image/4049.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtext&gt;Has stethoscope&lt;/mtext&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtext&gt;Has stethoscope&lt;/mtext&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Doesn&lt;/mtext&gt;&lt;mtext&gt;’&lt;/mtext&gt;&lt;mtext&gt;t have stethoscope&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Doesn&lt;/mtext&gt;&lt;mtext&gt;’&lt;/mtext&gt;&lt;mtext&gt;t have stethoscope&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.290em;height:1.051em;width:10.680em"/><st c="19841"/></span></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="19868">Eq. </st><st c="19872">6</st></p>
			<p><st c="19873">Eq. </st><st c="19877">6 makes the average information nature of the calculation more explicit. </st><st c="19950">We can generalize Eq. </st><st c="19972">6 to any attribute and since our answers have only two possibilities, “yes” or “no,” we can always write </st><img src="image/4050.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Doesn&lt;/mtext&gt;&lt;mtext&gt;'&lt;/mtext&gt;&lt;mtext&gt;t&lt;/mtext&gt;&lt;mtext&gt;have&lt;/mtext&gt;&lt;mtext&gt;attribute&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Has&lt;/mtext&gt;&lt;mtext&gt;attribute&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.062em;height:0.823em;width:19.910em"/><st c="20077"/><st c="20126">. For any attribute, we </st><a id="_idIndexMarker1090"/><st c="20150">can calculate the expected information you’ll get back from me when you ask about that attribute. </st><st c="20248">For convenience, we’ll shorten “Has attribute” to just “A.” This expected information is then given by the </st><span class="No-Break"><st c="20355">following equation:</st></span></p>
			<p><a id="_idTextAnchor660"/><img src="image/4051.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Expected&lt;/mtext&gt;&lt;mtext&gt;information&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtext&gt;A&lt;/mtext&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtext&gt;A&lt;/mtext&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.096em;width:27.271em"/><st c="20374"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="20440">Eq. </st><st c="20444">7</st></p>
			<p><st c="20445">Table 13.1 shows the probabilities and expected information for each of the five attributes we </st><span class="No-Break"><st c="20540">lis</st><a id="_idTextAnchor661"/><st c="20543">ted earlier:</st></span></p>
			<div>
				<div id="_idContainer4194" class="IMG---Figure">
					<img src="image/B19496_13_4.jpg" alt="" role="presentation"/><st c="20556"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="20749">Table 13.1: Character attributes and their expected information</st></p>
			<p><st c="20812">You’ll recall from the </st><em class="italic"><st c="20836">What is information and why is it useful?</st></em><st c="20877"> section that the higher the information associated with an answer, the more it allowed us to narrow down the possibilities of which character I had secretly selected. </st><st c="21045">Table 13.1 shows us that the question that allows us to narrow down the characters most effectively is asking if they have a hat since it gives us the most information on average. </st><st c="21225">Asking whether they have a computer is considerably less effective. </st><st c="21293">This doesn’t match what we were initially thinking. </st><st c="21345">How come? </st><st c="21355">It should be clear from the formula in Eq. </st><st c="21398">7 what has happened. </st><st c="21419">Although knowing a character has a computer narrows down the possibilities efficiently to just one person, it is unlikely that a person does have a computer, and this has reduced the information we get back on average when we ask if they have </st><span class="No-Break"><st c="21662">a computer.</st></span></p>
			<p><st c="21673">We can re-write the equation in Eq. </st><st c="21710">7 </st><span class="No-Break"><st c="21712">like so:</st></span></p>
			<p><img src="image/4052.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mtext&gt;Expected information&lt;/mml:mtext&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:22.233em"/><st c="21720"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21774">Eq. </st><st c="21778">8</st></p>
			<p><st c="21779">Here, we just plug in the value of </st><img src="image/4053.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;Attribute&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.062em;height:0.823em;width:4.815em"/><st c="21814"/><st c="21828"> for the value of </st><img src="image/4054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.479em"/><st c="21845"/><st c="21846">. As a function of </st><img src="image/4054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.479em"/><st c="21865"/><st c="21866">, we can ask, “What is the value of </st><img src="image/1890.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.492em"/><st c="21902"/><st c="21903"> that gives the highest expected information?” We do this by finding the maximum value of the right-hand side of Eq. </st><st c="22020">8 with respect to </st><img src="image/2008.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.485em"/><st c="22038"/><st c="22039">. We’ll use differential </st><a id="_idIndexMarker1091"/><st c="22064">calculus to do this. </st><st c="22085">We’ll differentiate the right-hand side of Eq. </st><st c="22132">8 with respect to </st><img src="image/2008.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.490em"/><st c="22150"/><st c="22151">, set the derivative to zero, and then solve for the resulting value of </st><img src="image/2008.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.770em;width:0.485em"/><st c="22223"/><st c="22224">. Doing this give us </st><span class="No-Break"><st c="22245">a condition:</st></span></p>
			<p><a id="_idTextAnchor662"/><img src="image/4060.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.044em;width:9.794em"/><st c="22257"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="22282">Eq. </st><st c="22286">9</st></p>
			<p><st c="22287">Solving Eq. </st><st c="22299">9 gives us </st><img src="image/4061.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.252em;height:0.946em;width:1.861em"/><st c="22310"/><st c="22314">. This means asking about an attribute whose probability is </st><img src="image/4062.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.166em;height:0.860em;width:0.292em"/><st c="22374"/><st c="22375"> is the most efficient question we can ask. </st><st c="22419">From Table 13.1, we can see that having a hat occurs with a probability of </st><img src="image/4063.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" style="vertical-align:-0.166em;height:0.860em;width:0.302em"/><st c="22494"/><st c="22497">, so asking whether a character has a hat is as efficient as it is possible to get in this game. </st><st c="22594">Each time we ask a question where </st><img src="image/4064.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;Has&lt;/mtext&gt;&lt;mtext&gt;Attribute&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.166em;height:0.927em;width:8.469em"/><st c="22628"/><st c="22649"> , we remove half the remaining characters. </st><st c="22692">Each time we divide the remaining characters into two groups and ask which group the chosen character is in, we are playing the game as efficiently </st><span class="No-Break"><st c="22840">as possible.</st></span></p>
			<p class="callout-heading"><st c="22852">Pro tip</st></p>
			<p class="callout"><st c="22860">Performing a task by dividing it into two parts, removing one part, and then repeating, is a very general technique for efficiently performing that task. </st><st c="23015">For example, it can be used for efficiently sorting objects (merge sort) and finding the roots of an equation (the </st><span class="No-Break"><st c="23130">bisection method).</st></span></p>
			<h2 id="_idParaDest-365"><a id="_idTextAnchor663"/><st c="23148">Entropy</st></h2>
			<p><st c="23156">In Eq. </st><st c="23164">7 and Eq. </st><st c="23174">8, we</st><a id="_idIndexMarker1092"/><st c="23179"> calculated expected information. </st><st c="23213">Expected information is the average information across the possible outcomes of a random variable. </st><st c="23312">You may have seen a formula like that in Eq. </st><st c="23357">7 or Eq. </st><st c="23366">8 before and seen it referred to as </st><strong class="bold"><st c="23402">entropy</st></strong><st c="23409">. That is because entropy and expected information are two names for the same thing, although entropy is the more commonly used name. </st><st c="23543">By now, you’ll also realize that entropy is something we calculate about </st><span class="No-Break"><st c="23616">random variables.</st></span></p>
			<p><st c="23633">For each attribute</st><a id="_idIndexMarker1093"/><st c="23652"> in our example, we had just two possible outcomes – either “yes, the character has the attribute,” or “no, the character doesn’t have the attribute.” The outcome is a random variable with two values, “yes” and “no,” which occur with probabilities </st><img src="image/4065.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.050em;height:0.763em;width:1.880em"/><st c="23900"/><st c="23901"> and </st><img src="image/4066.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.156em;height:0.818em;width:3.408em"/><st c="23906"/><st c="23911">. To calculate the entropy in Eq. </st><st c="23945">7, all we needed was those two probabilities. </st><st c="23991">This is also true when we have a random variable with more than two outcomes. </st><st c="24069">We only need its probability distribution to calculate its entropy. </st><st c="24137">For a discrete random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="24169"/><st c="24170">, with probability distribution, </st><img src="image/4068.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:0.893em"/><st c="24203"/><st c="24204">, the entropy is calculated </st><span class="No-Break"><st c="24232">as follows</st><a id="_idTextAnchor664"/><st c="24242">:</st></span></p>
			<p><img src="image/4069.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Entropy&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mtext&gt;Expected&lt;/mtext&gt;&lt;mtext&gt;information&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.656em;height:1.647em;width:26.262em"/><st c="24244"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="24299">Eq. </st><st c="24303">10</st></p>
			<p><st c="24305">Here, </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.473em"/><st c="24312"/><st c="24313"> represents an outcome of the random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.642em"/><st c="24360"/><st c="24361">, so the summation in Eq. </st><st c="24387">10 is over all the possible outcomes we can get for the </st><span class="No-Break"><st c="24443">random variable.</st></span></p>
			<p><st c="24459">Since entropy is just expected information, it is measured in the same units as we measure information. </st><st c="24564">As before, those units are determined by the base we use for the logarithm in Eq. </st><st c="24646">10. </st><st c="24650">The choice of base is up </st><span class="No-Break"><st c="24675">to you.</st></span></p>
			<p><st c="24682">We typically denote entropy by the symbol </st><img src="image/4072.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.075em"/><st c="24725"/><st c="24726">. This looks like we are applying a function, </st><img src="image/4073.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.741em"/><st c="24772"/><st c="24773">, to </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="24778"/><st c="24779">. This is deliberate, to emphasize the fact that entropy is a quantity associated with random variables, so we can think of entropy as a function </st><span class="No-Break"><st c="24925">of </st></span><span class="No-Break"><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="24928"/></span><span class="No-Break"><st c="24929">.</st></span></p>
			<h3><st c="24930">The entropy of continuous random variables</st></h3>
			<p><st c="24973">Entropy is one of </st><a id="_idIndexMarker1094"/><st c="24992">those quantities we mentioned in the previous section that we can generalize from discrete random variables to continuous random variables. </st><st c="25132">We can do so by considering discrete outcomes, </st><img src="image/4076.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.012em;height:0.676em;width:6.171em"/><st c="25179"/><st c="25193">, using the formula for the entropy of a discrete random variable, and finally using the usual calculus trick of reducing the size of our intervals, </st><img src="image/4077.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mml:mi&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.676em;width:1.071em"/><st c="25342"/><st c="25345">, to zero. </st><st c="25356">Doing so, for a continuous random variable, </st><img src="image/2026.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.608em"/><st c="25400"/><st c="25401">, with probability density, </st><img src="image/4079.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.291em"/><st c="25429"/><st c="25430">, we find the entropy is given by the </st><span class="No-Break"><st c="25468">following equatio</st><a id="_idTextAnchor665"/><st c="25485">n:</st></span></p>
			<p><img src="image/4080.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Entropy&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;Constant&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.174em;width:19.802em"/><st c="25488"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="25535">Eq. </st><st c="25539">11</st></p>
			<p><st c="25541">Unfortunately, the constant in Eq. </st><st c="25577">11 becomes infinite when we take </st><img src="image/4081.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mml:mi&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;.&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.692em;width:3.769em"/><st c="25610"/><st c="25619"> However, the constant is just that – a constant. </st><st c="25668">It does not depend on </st><img src="image/4082.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.301em"/><st c="25690"/><st c="25691"> in any way, so it is the integral term in Eq. </st><st c="25738">11 that contains the interesting and relevant behavior of </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.659em"/><st c="25796"/><st c="25797">. Because the integral term in Eq. </st><st c="25832">11 is the difference between the entropy and the constant, it is</st><a id="_idIndexMarker1095"/><st c="25896"> called the </st><strong class="bold"><st c="25908">differential entropy</st></strong><st c="25928">. That is, for</st><a id="_idIndexMarker1096"/><st c="25942"> a continuous random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="25973"/><st c="25974">, with density, </st><img src="image/4085.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.252em"/><st c="25990"/><st c="25991">, we have </st><span class="No-Break"><st c="26001">the follow</st><a id="_idTextAnchor666"/><st c="26011">ing:</st></span></p>
			<p><img src="image/4086.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Differential&lt;/mtext&gt;&lt;mtext&gt;Entropy&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:1.123em;width:16.785em"/><st c="26016"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="26059">Eq. </st><st c="26063">12</st></p>
			<p><st c="26065">Because the </st><a id="_idIndexMarker1097"/><st c="26078">expression in Eq. </st><st c="26096">12 is what we use when discussing the entropy of continuous random variables, you will frequently see the prefix </st><strong class="bold"><st c="26209">differential</st></strong><st c="26221"> dropped, and the integral on the right-hand side of Eq. </st><st c="26278">12 referred to as the entropy, </st><img src="image/4087.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.081em"/><st c="26309"/><st c="26310">, of the continuous random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.643em"/><st c="26347"/><st c="26348">. I will do so as well. </st><st c="26372">When I refer to the entropy of the continuous random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.642em"/><st c="26435"/><st c="26436">, and I use the symbol </st><img src="image/4087.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.078em"/><st c="26459"/><st c="26460">, I mean its differential entropy, as defined in </st><span class="No-Break"><st c="26509">Eq. </st><st c="26513">12.</st></span></p>
			<p><st c="26516">The integration in Eq. </st><st c="26540">12 is over the support of the random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.637em"/><st c="26587"/><st c="26588">. If </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.637em"/><st c="26593"/><st c="26594"> is a two-dimensional real random variable, the integration will be over a two-dimensional real space, while if </st><img src="image/2026.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.616em"/><st c="26706"/><st c="26707"> is one-dimensional and real, the integration will be over the </st><span class="No-Break"><st c="26770">real line.</st></span></p>
			<p><st c="26780">Calculating the entropy for some different continuous distributions can give us more insight into how entropy behaves and what it represents. </st><st c="26923">We’ll look at two common continuous distributions – the uniform distribution and the Gaussian distribution. </st><st c="27031">The formulae for the density functions </st><a id="_idIndexMarker1098"/><st c="27070">and entropies of these two distributions are </st><span class="No-Break"><st c="27115">given here.</st></span></p>
			<p><st c="27126">Uniform distribution </st><img src="image/4094.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;U&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.170em;height:0.881em;width:2.727em"/><st c="27148"/><st c="27156"> :</st></p>
			<p><img src="image/4095.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Density&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;{&quot; close=&quot;&quot;&gt;&lt;mtable columnwidth=&quot;auto&quot; columnalign=&quot;center&quot; rowspacing=&quot;1.0000ex&quot; rowalign=&quot;baseline baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mtext&gt;for&lt;/mtext&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mtext&gt;otherwise&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mfenced&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mtext&gt;Entropy&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-1.115em;height:2.738em;width:25.653em"/><st c="27157"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="27222">Eq. </st><st c="27226">13</st></p>
			<p><st c="27228">Gaussian distribution </st><img src="image/4096.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;N&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;μ&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.966em;width:3.521em"/><st c="27251"/><st c="27261"> :</st></p>
			<p><img src="image/4097.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Density&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mtext&gt;Entropy&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.684em;height:1.698em;width:25.015em"/><st c="27262"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="27339">Eq. </st><st c="27343">14</st></p>
			<p><st c="27345">Again, in Eq. </st><st c="27360">13 and Eq. </st><st c="27371">14, we haven’t specified which base we are taking logarithms to – it is your choice. </st><st c="27456">The entropy formulae in Eq. </st><st c="27484">13 and Eq. </st><st c="27495">14 are correct for any choice </st><span class="No-Break"><st c="27525">of base.</st></span></p>
			<p><st c="27533">Because we</st><a id="_idIndexMarker1099"/><st c="27544"> have been able to calculate the entropy for these two distributions in terms of the parameters of their density functions, from Eq. </st><st c="27677">13 and Eq. </st><st c="27688">14, we can see how the entropy behaves as we change those parameters and hence change the shape of </st><span class="No-Break"><st c="27787">the distributions.</st></span></p>
			<p><st c="27805">If we increase the width, </st><img src="image/4098.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;b&lt;/mml:mi&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:2.113em"/><st c="27832"/><st c="27833">, of the uniform distribution, the entropy increases. </st><st c="27887">Similarly, if we make our Gaussian distribution wider by increasing its standard deviation, </st><img src="image/1545.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.473em;width:0.488em"/><st c="27979"/><st c="27980">, we increase its entropy. </st><st c="28007">In both cases, the higher the variance of the distribution, the higher the entropy. </st><st c="28091">Also, note that in both cases, the entropy is independent of the mean of the distribution. </st><st c="28182">It doesn’t matter where we locate our distribution; the entropy is only dependent on how dispersed the </st><span class="No-Break"><st c="28285">distribution is.</st></span></p>
			<h3><st c="28301">What does entropy tell us?</st></h3>
			<p><st c="28328">Because </st><a id="_idIndexMarker1100"/><st c="28337">entropy increases with the variance of a probability distribution, many people tend to think of entropy as a measure of </st><strong class="bold"><st c="28457">uncertainty</st></strong><st c="28468"> or </st><strong class="bold"><st c="28472">disorder</st></strong><st c="28480">. This may be how you have encountered entropy before – in physics. </st><st c="28548">In physics, entropy is a concept associated with thermodynamics. </st><st c="28613">In thermodynamics, heating a system increases the disorder (think molecules moving about more rapidly with increasing temperature). </st><st c="28745">The physics formulae for entropy are the same as those from information theory, namely the formulae in Eq. </st><st c="28852">10 and </st><span class="No-Break"><st c="28859">Eq. </st><st c="28863">12.</st></span></p>
			<p><st c="28866">Yet entropy is just average information, and we have tended to think of an increase in information as increasing the certainty with which we can identify the underlying cause of the information. </st><st c="29062">How are these two viewpoints compatible with </st><span class="No-Break"><st c="29107">each other?</st></span></p>
			<p><st c="29118">A large entropy tells us that our random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.637em"/><st c="29170"/><st c="29171">, has a large variance and so tells us that the range of likely values we’d get from a single observation of that random variable is large. </st><st c="29311">It tells us about the uncertainty in that single observation before we make it. </st><st c="29391">It tells us about </st><img src="image/4101.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.482em"/><st c="29409"/><st c="29410">. In contrast, the information associated with an observation, </st><img src="image/4102.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:2.636em"/><st c="29473"/><st c="29474">, tells us how well that observation narrows down the underlying state of the system that gave rise to the value </st><img src="image/169.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.496em"/><st c="29587"/><st c="29588">. It tells us about </st><img src="image/4104.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;state&lt;/mtext&gt;&lt;mtext&gt;|&lt;/mtext&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.100em;width:4.452em"/><st c="29608"/><st c="29621">. Since entropy is just </st><a id="_idIndexMarker1101"/><st c="29645">average information, it tells us how much we can narrow down possibilities on average. </st><st c="29732">It tells us how much, on average, we can reduce uncertainty about our knowledge of a system from a single observation, </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="29851"/><st c="29852">. To reduce the uncertainty a lot with a single observation of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="29915"/><st c="29916">, there must be a lot of uncertainty, </st><strong class="bold"><st c="29954">a priori</st></strong><st c="29962">, in </st><img src="image/4107.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.621em"/><st c="29967"/><st c="29968">. So, entropy tells us about the </st><strong class="bold"><st c="30001">a priori</st></strong><st c="30009"> uncertainty in a random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="30044"/><st c="30045">, and the certainty with which we can identify the associated underlying state from observations of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.639em"/><st c="30145"/><st c="30146">. The two viewpoints of entropy are compatible with each other. </st><st c="30210">They are two sides of the </st><span class="No-Break"><st c="30236">same coin.</st></span></p>
			<h3><st c="30246">The Maximum Entropy technique</st></h3>
			<p><st c="30276">The physics view of entropy leads to an interesting inference technique called </st><strong class="bold"><st c="30356">Maximum Entropy</st></strong><st c="30371"> or </st><strong class="bold"><st c="30375">MaxEnt</st></strong> <span class="No-Break"><st c="30381">for short.</st></span></p>
			<p><st c="30392">The </st><a id="_idIndexMarker1102"/><st c="30397">physics view says that entropy tells us about the number of underlying states compatible with a density function, </st><img src="image/4082.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.310em"/><st c="30511"/><st c="30512">. Let’s suppose we have </st><a id="_idIndexMarker1103"/><st c="30536">some random variable, </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.653em"/><st c="30558"/><st c="30559">, but I don’t know what its distribution is. </st><st c="30604">However, I do know its mean value, </st><img src="image/2170.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.514em"/><st c="30639"/><st c="30640">, and its variance, </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.847em"/><st c="30660"/><st c="30665"> (or I have good estimates of them, say from a sample of data). </st><st c="30728">I want to model the distribution of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="30764"/><st c="30765"> and do some calculations with that distribution. </st><st c="30815">What distribution should I use? </st><st c="30847">One that is compatible with the values of </st><img src="image/4115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.517em"/><st c="30889"/> <span class="No-Break"><st c="30890">and </st></span><span class="No-Break"><img src="image/2146.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.838em"/><st c="30894"/></span><span class="No-Break"><st c="30899">.</st></span></p>
			<p><st c="30900">A reasonably logical choice is to use the most probable distribution, but what do we mean by that? </st><st c="31000">We can say that the most probable distribution of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.634em"/><st c="31050"/><st c="31051"> is the one that has the highest number of possible underlying states compatible with its density, </st><img src="image/4085.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.261em"/><st c="31150"/><st c="31151">. But that number is the entropy. </st><st c="31185">So, it turns out that a reasonable choice for </st><img src="image/4082.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.293em"/><st c="31231"/><st c="31232"> is one that maximizes the entropy subject to the constraints that the mean of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="31311"/><st c="31312"> is </st><img src="image/2170.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.510em"/><st c="31316"/><st c="31317"> and the variance of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="31338"/> <span class="No-Break"><st c="31339">is </st></span><span class="No-Break"><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="31342"/></span><span class="No-Break"><st c="31347">.</st></span></p>
			<p><st c="31348">How do we do that maximization calculation? </st><st c="31393">By using calculus – that is, using Lagrange multipliers as usual to impose the constraints. </st><st c="31485">The objective function we must maximize is </st><span class="No-Break"><st c="31528">a</st><a id="_idTextAnchor667"/><st c="31529">s follows:</st></span></p>
			<p><img src="image/4124.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.130em;width:24.389em"/><st c="31539"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="31597">Eq. </st><st c="31601">15</st></p>
			<p><st c="31603">The first term in our objective function in Eq. </st><st c="31652">15 is the entropy. </st><st c="31671">The next three terms impose the constraints through the Lagrange multipliers </st><img src="image/4125.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:3.000em"/><st c="31748"/><st c="31761">. The constraints are that we </st><a id="_idIndexMarker1104"/><st c="31791">must match the specified mean and variance, and we must have a properly normalized </st><span class="No-Break"><st c="31874">distribution, </st></span><span class="No-Break"><img src="image/4085.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.252em"/><st c="31888"/></span><span class="No-Break"><st c="31889">.</st></span></p>
			<p><st c="31890">Technically, to maximize the expression in Eq. </st><st c="31938">15, we must use a technique called </st><strong class="bold"><st c="31973">calculus of variations</st></strong><st c="31995">, albeit a </st><a id="_idIndexMarker1105"/><st c="32006">relatively simple version of it in this instance. </st><st c="32056">However, because of this extra complexity, we will just quote the answer. </st><st c="32130">The density, </st><img src="image/4127.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.214em"/><st c="32143"/><st c="32144">, that maximizes the entropy for a specified mean, </st><img src="image/4128.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.505em"/><st c="32195"/><st c="32196">, and variance, </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="32212"/><st c="32217">, is</st><a id="_idTextAnchor668"/> <span class="No-Break"><st c="32221">as follows:</st></span></p>
			<p><img src="image/4130.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.684em;height:1.698em;width:12.670em"/><st c="32233"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="32260">Eq. </st><st c="32264">16</st></p>
			<p><st c="32266">This is</st><a id="_idIndexMarker1106"/><st c="32274"> just the density function of the Gaussian distribution. </st><st c="32331">What does this mean? </st><st c="32352">It tells us that of all the distributions, </st><img src="image/4085.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.252em"/><st c="32395"/><st c="32396">, that have mean, </st><img src="image/2170.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.510em"/><st c="32414"/><st c="32415">, and variance, </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="32431"/><st c="32436">, the Gaussian distribution is the one that has the highest entropy. </st><st c="32505">It tells us that for mean, </st><img src="image/4134.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.510em"/><st c="32532"/><st c="32533">, and variance, </st><img src="image/2146.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.838em"/><st c="32549"/><st c="32554">, the Gaussian distribution is the most probable, in the sense that it maximizes the entropy – it has the highest number of underlying states compatible with a mean, </st><img src="image/2170.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;μ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.258em;height:0.706em;width:0.511em"/><st c="32720"/><st c="32721">, and variance, </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.840em"/><st c="32737"/><st c="32742">. This is another reason for studying the Gaussian distribution. </st><st c="32807">It is the most probable distribution if we only know the mean </st><span class="No-Break"><st c="32869">and variance.</st></span></p>
			<p><st c="32882">What happens if we don’t know the mean and variance? </st><st c="32936">What happens if we only know the minimum and maximum values of </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.671em"/><st c="32999"/><st c="33000">? What is the most probable distribution then? </st><st c="33047">Repeating the MaxEnt calculation, we find the properly normalized distribution that has the highest entropy is the uniform distribution. </st><st c="33184">You can now see why we suggested looking at the entropy of both the uniform and Gaussian distributions – they are </st><span class="No-Break"><st c="33298">exceptional distributions.</st></span></p>
			<p><st c="33324">In this section, we learned about the different aspects of entropy. </st><st c="33393">So, </st><span class="No-Break"><st c="33397">let’s recap.</st></span></p>
			<h2 id="_idParaDest-366"><a id="_idTextAnchor669"/><st c="33409">What we’ve learned</st></h2>
			<p><st c="33428">In this section, we learned </st><span class="No-Break"><st c="33457">the following:</st></span></p>
			<ul>
				<li><st c="33471">The expected information tells us the average amount of information we get from an observation of a random variable, averaged across all the possible outcomes of the </st><span class="No-Break"><st c="33638">random variable</st></span></li>
				<li><st c="33653">The expected information is more commonly known </st><span class="No-Break"><st c="33702">as entropy</st></span></li>
				<li><st c="33712">Entropy is measured in the same units </st><span class="No-Break"><st c="33751">as information</st></span></li>
				<li><st c="33765">Entropy can be defined and calculated for both discrete probability distributions and </st><span class="No-Break"><st c="33852">continuous distributions</st></span></li>
				<li><st c="33876">Entropy increases with an increase in the variance of </st><span class="No-Break"><st c="33931">a distribution</st></span></li>
				<li><st c="33945">The information theory definition of entropy is the same as the physics definition of entropy and they encapsulate the </st><span class="No-Break"><st c="34065">same concept</st></span></li>
				<li><st c="34077">The MaxEnt technique can be used to determine the most probable distribution compatible with </st><span class="No-Break"><st c="34171">specified constraints</st></span></li>
				<li><st c="34192">The Gaussian distribution has the highest entropy for a given specified mean </st><span class="No-Break"><st c="34270">and variance</st></span></li>
				<li><st c="34282">The uniform distribution has the highest entropy for a given </st><span class="No-Break"><st c="34344">finite support</st></span></li>
			</ul>
			<p><st c="34358">Having learned about the expected information (entropy) of a single random variable, in the next section, we’ll learn about the information associated with multiple </st><span class="No-Break"><st c="34524">random variables.</st></span></p>
			<h1 id="_idParaDest-367"><a id="_idTextAnchor670"/><st c="34541">Mutual information</st></h1>
			<p><st c="34560">In this </st><a id="_idIndexMarker1107"/><st c="34569">section, we’re going to look at information-theoretic concepts relating to multiple random variables. </st><st c="34671">We’ll focus on the case of just two random variables, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.646em"/><st c="34725"/><st c="34726"> and </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.599em"/><st c="34731"/><st c="34732">, but you’ll soon realize that the new calculations and concepts we’ll introduce generalize easily to more than two random variables. </st><st c="34866">As usual, we’ll start with the discrete case first before introducing the continuous </st><span class="No-Break"><st c="34951">case later.</st></span></p>
			<p><st c="34962">Because we’re looking at two discrete random variables, </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.656em"/><st c="35019"/><st c="35020"> and </st><img src="image/4142.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.625em"/><st c="35025"/><st c="35026">, we’ll need their joint probability distribution, </st><img src="image/4143.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.402em;height:1.050em;width:3.342em"/><st c="35077"/><st c="35085">, which we’ll use as shorthand for </st><img src="image/4144.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.402em;height:1.100em;width:7.774em"/><st c="35120"/><st c="35136">. The joint distribution is just a probability distribution so we can easily measure its entropy, which we’ll denote by </st><img src="image/4145.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:3.119em"/><st c="35256"/><st c="35257">. Applying the usual rules that entropy is expected information, </st><img src="image/4146.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.894em"/><st c="35322"/><st c="35323"> is given by the </st><span class="No-Break"><st c="35340">foll</st><a id="_idTextAnchor671"/><st c="35344">owing formula:</st></span></p>
			<p><img src="image/4147.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.726em;height:1.790em;width:15.237em"/><st c="35359"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="35388">Eq. </st><st c="35392">17</st></p>
			<p><st c="35394">To </st><a id="_idIndexMarker1108"/><st c="35398">understand Eq. </st><st c="35413">17, let’s look at what would happen if </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.633em"/><st c="35452"/><st c="35453"> and </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.603em"/><st c="35458"/><st c="35459"> were independent of each other. </st><st c="35492">The joint distribution would be given by </st><img src="image/4150.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.402em;height:1.311em;width:9.002em"/><st c="35533"/><st c="35551">. Plugging this into Eq. </st><st c="35576">17 and remembering the rules of logarithms of products from </st><a href="B19496_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic"><st c="35636">Chapter 1</st></em></span></a><st c="35645">, we’ll find that we have the </st><a id="_idTextAnchor672"/><span class="No-Break"><st c="35675">following here:</st></span></p>
			<p><img src="image/4151.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.799em;height:1.790em;width:26.263em"/><st c="35690"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="35748">Eq. </st><st c="35752">18</st></p>
			<p><st c="35754">Eq. </st><st c="35759">18 tells us that when </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.628em"/><st c="35781"/><st c="35782"> and </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.598em"/><st c="35787"/><st c="35788"> are independent, the entropy, </st><img src="image/4154.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.953em"/><st c="35819"/><st c="35820">, is just the sum of the entropies of the separate variables, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="35882"/><st c="35883"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="35888"/><st c="35889">. We also know that if </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="35912"/><st c="35913"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="35918"/><st c="35919"> are independent, then knowing the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.639em"/><st c="35963"/><st c="35964"> tells us nothing about the value of </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.608em"/><st c="36001"/><st c="36002">. We gain no information about </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.608em"/><st c="36033"/><st c="36034"> if we know </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.639em"/><st c="36046"/><st c="36047">. There is no information in common between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="36091"/> <span class="No-Break"><st c="36092">and </st></span><span class="No-Break"><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="36096"/></span><span class="No-Break"><st c="36097">.</st></span></p>
			<p><st c="36098">But what would happen if </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.644em"/><st c="36124"/><st c="36125"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.613em"/><st c="36130"/><st c="36131"> weren’t independent and </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.644em"/><st c="36156"/><st c="36157"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.613em"/><st c="36162"/><st c="36163"> did have some information in common? </st><st c="36201">Knowing the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="36222"/><st c="36223"> would tell us information about </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="36256"/><st c="36257"> and vice versa. </st><st c="36274">What would be the size of this common or </st><strong class="bold"><st c="36315">mutual information</st></strong><st c="36333">? Well, we can take a simple approach and define this common or mutual information to be the difference between the average information we get from the random variables separately and the average information we get from the random variables together. </st><st c="36584">This means that mutual information, </st><img src="image/4171.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.865em;width:2.606em"/><st c="36620"/><st c="36628">, is defined as a difference between entropies and is given by the </st><span class="No-Break"><st c="36695">fol</st><a id="_idTextAnchor673"/><st c="36698">lowing formula:</st></span></p>
			<p><img src="image/4172.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.167em;height:0.865em;width:13.720em"/><st c="36714"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="36744">Eq. </st><st c="36748">19</st></p>
			<p><st c="36750">Although </st><img src="image/4173.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.865em;width:2.640em"/><st c="36760"/><st c="36768"> is called mutual information, it is defined from entropies of the random variables, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.635em"/><st c="36852"/><st c="36853"> and </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.604em"/><st c="36858"/><st c="36859">, not the specific outcomes, </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.467em"/><st c="36888"/><st c="36889"> and </st><img src="image/24.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.436em"/><st c="36894"/><st c="36917">, of those random variables. </st><st c="36946">This is why the symbol we use for mutual information, </st><img src="image/4178.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.632em"/><st c="37000"/><st c="37001">, looks like a function that’s applied to </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="37043"/><st c="37044"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="37049"/><st c="37050">. And being defined as a difference between entropies, </st><img src="image/4181.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.728em"/><st c="37105"/><st c="37106"> is measured in whatever units you use for the base of your logarithms – bits if you’re taking logarithms to base 2, nats if you’re taking logarithms to base </st><img src="image/162.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.399em"/><st c="37264"/><st c="37265">, and </st><span class="No-Break"><st c="37271">so on.</st></span></p>
			<h2 id="_idParaDest-368"><a id="_idTextAnchor674"/><st c="37277">Conditional entropy</st></h2>
			<p><st c="37297">To get an</st><a id="_idIndexMarker1109"/><st c="37307"> intuition about what the mutual information, </st><img src="image/4183.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.598em"/><st c="37353"/><st c="37354">, tells us, we’ll use Bayes’ theorem from </st><a href="B19496_05.xhtml#_idTextAnchor261"><span class="No-Break"><em class="italic"><st c="37396">Chapter 5</st></em></span></a><st c="37405"> to re-wr</st><a id="_idTextAnchor675"/><st c="37414">ite </st><span class="No-Break"><st c="37419">our formula:</st></span></p>
			<p><img src="image/4184.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.415em;height:1.230em;width:21.032em"/><st c="37431"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37472">Eq. </st><st c="37476">20</st></p>
			<p><st c="37478">The</st><a id="_idIndexMarker1110"/><st c="37482"> notation, </st><img src="image/4185.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.415em;height:1.063em;width:1.393em"/><st c="37493"/><st c="37497">, represents the conditional distribution of </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.608em"/><st c="37542"/><st c="37543"> – that is, the distribution of </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.608em"/><st c="37575"/><st c="37576"> once we know the value of </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.680em"/><st c="37603"/><st c="37604">. From Eq. </st><st c="37615">20, we can calculate the entropy, </st><img src="image/4189.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:3.252em"/><st c="37649"/><st c="37650">, and hence the mutual information, </st><img src="image/4178.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.632em"/><st c="37686"/><st c="37687">. By doing so, we g</st><a id="_idTextAnchor676"/><st c="37706">et </st><span class="No-Break"><st c="37710">the following:</st></span></p>
			<p><img src="image/4191.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.100em;width:10.558em"/><st c="37724"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37749">Eq. </st><st c="37753">21</st></p>
			<p><st c="37755">Here, </st><img src="image/4192.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.949em"/><st c="37762"/><st c="37763"> is the entropy defined from the conditional distribution, </st><img src="image/4193.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.415em;height:1.230em;width:7.603em"/><st c="37822"/><st c="37837">, averaged over all possible values of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="37876"/><st c="37877">. So, </st><img src="image/4195.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.949em"/><st c="37883"/><st c="37884"> is given by the </st><span class="No-Break"><st c="37901">following formula:</st></span></p>
			<p><img src="image/4196.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.726em;height:1.790em;width:24.400em"/><st c="37919"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37971">Eq. </st><st c="37975">22</st></p>
			<p><st c="37977">Since the entropy, </st><img src="image/4197.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.300em;height:1.100em;width:3.123em"/><st c="37997"/><st c="38004">, is calculated from the conditional distribution, </st><img src="image/4198.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.415em;height:1.063em;width:1.467em"/><st c="38055"/><st c="38059">, it is known as the </st><strong class="bold"><st c="38080">conditional entropy</st></strong><st c="38099">. You’ll recall from the previous section that entropy measures the uncertainty of a random variable. </st><st c="38201">So, </st><img src="image/4199.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.300em;height:1.100em;width:3.079em"/><st c="38205"/><st c="38212"> is the average uncertainty in </st><img src="image/4142.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.621em"/><st c="38242"/><st c="38243"> after we know </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.652em"/><st c="38258"/><st c="38259">. And since </st><img src="image/4202.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.050em;height:0.748em;width:2.072em"/><st c="38271"/><st c="38272"> measures the uncertainty in </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.609em"/><st c="38301"/><st c="38302"> when we don’t know </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.640em"/><st c="38322"/><st c="38323">, the expression in Eq. </st><st c="38347">21 now gives us a way to understand the mutual information. </st><st c="38407">Eq. </st><st c="38411">21 tells us that </st><img src="image/4173.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.865em;width:2.632em"/><st c="38428"/><st c="38436"> is the reduction in uncertainty about </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="38474"/><st c="38475"> that we get on average from knowing the value </st><span class="No-Break"><st c="38522">of </st></span><span class="No-Break"><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="38525"/></span><span class="No-Break"><st c="38526">.</st></span></p>
			<p><st c="38527">We can use Bayes’ theorem to write </st><span class="No-Break"><st c="38563">the following:</st></span></p>
			<p><img src="image/4208.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.383em;height:1.205em;width:20.985em"/><st c="38577"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="38623">Eq. </st><st c="38627">23</st></p>
			<p><st c="38629">This means we can also write the mutual information, </st><img src="image/4209.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.169em;height:0.880em;width:2.619em"/><st c="38683"/><st c="38691">, </st><span class="No-Break"><st c="38693">as follows:</st></span></p>
			<p><img src="image/4210.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.358em;height:1.172em;width:10.685em"/><st c="38704"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="38728">Eq. </st><st c="38732">24</st></p>
			<p><st c="38734">Here, the </st><a id="_idIndexMarker1111"/><st c="38745">entropy, </st><img src="image/4211.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.300em;height:1.100em;width:3.074em"/><st c="38754"/><st c="38761">, is the conditional entropy calculated from the conditional distribution, </st><img src="image/4212.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.415em;height:1.063em;width:1.347em"/><st c="38836"/><st c="38839">. Eq. </st><st c="38845">24 means we can also</st><a id="_idIndexMarker1112"/><st c="38865"> interpret the mutual information, </st><img src="image/4213.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.865em;width:2.544em"/><st c="38900"/><st c="38908">, as the reduction in uncertainty about </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.642em"/><st c="38948"/><st c="38949"> that we get on average from knowing the value of </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.611em"/><st c="38999"/><st c="39000">. Because we have two different ways of interpreting </st><img src="image/4178.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.632em"/><st c="39053"/><st c="39054">, they must be equivalent. </st><st c="39081">This means we can use the</st><a id="_idTextAnchor677"/> <span class="No-Break"><st c="39106">following formula:</st></span></p>
			<p><img src="image/4217.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Average&lt;/mtext&gt;&lt;mtext&gt;reduction&lt;/mtext&gt;&lt;mtext&gt;in&lt;/mtext&gt;&lt;mtext&gt;uncertainty&lt;/mtext&gt;&lt;mtext&gt;about&lt;/mtext&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mtext&gt;from&lt;/mtext&gt;&lt;mtext&gt;knowing&lt;/mtext&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;Average&lt;/mtext&gt;&lt;mtext&gt;reduction&lt;/mtext&gt;&lt;mtext&gt;in&lt;/mtext&gt;&lt;mtext&gt;uncertainty&lt;/mtext&gt;&lt;mtext&gt;about&lt;/mtext&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mtext&gt;from&lt;/mtext&gt;&lt;mtext&gt;knowing&lt;/mtext&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.968em;width:39.601em"/><st c="39125"/><span class="_-----MathTools-_Math_Text"><img src="image/4218.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Average&lt;/mtext&gt;&lt;mtext&gt;reduction&lt;/mtext&gt;&lt;mtext&gt;in&lt;/mtext&gt;&lt;mtext&gt;uncertainty&lt;/mtext&gt;&lt;mtext&gt;about&lt;/mtext&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mtext&gt;from&lt;/mtext&gt;&lt;mtext&gt;knowing&lt;/mtext&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;Average&lt;/mtext&gt;&lt;mtext&gt;reduction&lt;/mtext&gt;&lt;mtext&gt;in&lt;/mtext&gt;&lt;mtext&gt;uncertainty&lt;/mtext&gt;&lt;mtext&gt;about&lt;/mtext&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mtext&gt;from&lt;/mtext&gt;&lt;mtext&gt;knowing&lt;/mtext&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.968em;width:7.641em"/><st c="39223"/></span></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="39240">Eq. </st><st c="39244">25</st></p>
			<p><st c="39246">This reduction in uncertainty is always non-negative. </st><st c="39301">If </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.652em"/><st c="39304"/><st c="39305"> and </st><img src="image/4142.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.621em"/><st c="39310"/><st c="39311"> are independent, then we gain no information about </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="39363"/><st c="39364"> from knowing the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="39391"/><st c="39392">, while if </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="39403"/><st c="39404"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="39409"/><st c="39410"> are correlated, then knowing the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="39453"/><st c="39454"> does tell us something about the value </st><span class="No-Break"><st c="39494">of </st></span><span class="No-Break"><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="39497"/></span><span class="No-Break"><st c="39498">:</st></span></p>
			<p><img src="image/4227.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;≥&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.167em;height:0.865em;width:4.599em"/><st c="39499"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="39511">Eq. </st><st c="39515">26</st></p>
			<p><st c="39517">By comparing Eq. </st><st c="39535">21 and Eq. </st><st c="39546">24, we can also see that we have </st><img src="image/4228.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.865em;width:6.805em"/><st c="39579"/><st c="39597">, as we would expect for a measure of the mutual information between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="39666"/> <span class="No-Break"><st c="39667">and </st></span><span class="No-Break"><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="39671"/></span><span class="No-Break"><st c="39672">.</st></span></p>
			<h2 id="_idParaDest-369"><a id="_idTextAnchor678"/><st c="39673">Mutual information for continuous variables</st></h2>
			<p><st c="39717">As we did with</st><a id="_idIndexMarker1113"/><st c="39732"> entropy, we can define mutual information for continuous random variables, </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.638em"/><st c="39808"/><st c="39809"> and </st><img src="image/4142.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.607em"/><st c="39814"/><st c="39815">. We can do this by constructing discrete random variables using small intervals, </st><img src="image/4233.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;∆&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.676em;width:1.125em"/><st c="39897"/><st c="39901"> and </st><img src="image/4234.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;∆&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.921em;width:1.094em"/><st c="39905"/><st c="39908">, of </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.465em"/><st c="39913"/><st c="39914"> and </st><img src="image/769.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.433em"/><st c="39919"/><st c="39929">, and then taking the limit, </st><img src="image/4237.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;∆&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msup&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;∆&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msup&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.921em;width:7.507em"/><st c="39958"/><st c="39974">. As before, we must deal with constants that become infinite as </st><img src="image/4238.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;∆&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msup&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;∆&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msup&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:0.921em;width:7.753em"/><st c="40039"/><st c="40055">. However, once we do the formula for the (differential) entropy, </st><img src="image/4239.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.865em;width:3.147em"/><st c="40121"/><st c="40129"> is given in terms of the joint density, </st><img src="image/4240.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.402em;height:1.311em;width:3.634em"/><st c="40169"/><st c="40180">, and is </st><span class="No-Break"><st c="40189">as follows:</st></span></p>
			<p><img src="image/4241.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.402em;height:1.192em;width:15.289em"/><st c="40200"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="40237">Eq. </st><st c="40241">27</st></p>
			<p><st c="40243">Here, mutual information is still defined via the </st><span class="No-Break"><st c="40294">following formula:</st></span></p>
			<p><img src="image/4242.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.300em;height:1.100em;width:28.817em"/><st c="40312"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="40372">Eq. </st><st c="40376">28</st></p>
			<p><st c="40378">The</st><a id="_idIndexMarker1114"/><st c="40382"> conditional entropies, </st><img src="image/4243.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.300em;height:1.100em;width:3.033em"/><st c="40406"/><st c="40414"> and </st><img src="image/4244.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.949em"/><st c="40418"/><st c="40419">, are defined from the conditional densities, </st><img src="image/4245.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.415em;height:1.338em;width:3.467em"/><st c="40465"/><st c="40473"> and </st><img src="image/4246.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.415em;height:1.338em;width:3.467em"/><st c="40477"/><st c="40485">, in the way you </st><span class="No-Break"><st c="40502">would expect:</st></span></p>
			<p><img src="image/4247.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;∬&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.415em;height:1.238em;width:15.122em"/><st c="40515"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="40553">Eq. </st><st c="40557">29</st></p>
			<p><img src="image/4248.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;∬&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.415em;height:1.238em;width:15.576em"/><st c="40559"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="40596">Eq. </st><st c="40600">30</st></p>
			<h2 id="_idParaDest-370"><a id="_idTextAnchor679"/><st c="40602">Mutual information as a measure of correlation</st></h2>
			<p><st c="40649">Since </st><a id="_idIndexMarker1115"/><st c="40656">the mutual information, </st><img src="image/4178.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.632em"/><st c="40680"/><st c="40681">, measures the information that </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="40713"/><st c="40714"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="40719"/><st c="40720"> have in common, it is a measure of the strength of the relationship between </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.681em"/><st c="40797"/><st c="40798"> and </st><img src="image/4253.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.649em"/><st c="40803"/><st c="40804">, just like the Pearson correlation coefficient. </st><st c="40853">The advantage of the mutual information is that it is invariant to the monotonic transformation of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.640em"/><st c="40952"/><st c="40953"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.609em"/><st c="40958"/><st c="40959">. This means that we could create new random variables, </st><img src="image/4256.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;'&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.022em;width:3.961em"/><st c="41015"/><st c="41026"> and </st><img src="image/4257.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;'&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:1.022em;width:4.047em"/><st c="41030"/><st c="41031">, and so long as the functions, </st><img src="image/126.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.270em"/><st c="41063"/><st c="41117"> and </st><img src="image/1680.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.419em"/><st c="41121"/><st c="41122">, are monotonic, </st><a id="_idTextAnchor680"/><st c="41139">we have </st><span class="No-Break"><st c="41147">the following:</st></span></p>
			<p><img src="image/4260.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;′&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;′&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.167em;height:0.894em;width:7.410em"/><st c="41161"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="41181">Eq. </st><st c="41185">31</st></p>
			<p><st c="41187">This tells us that if we have a non-linear relationship between our random variables, </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.662em"/><st c="41274"/><st c="41275"> and </st><img src="image/4142.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.631em"/><st c="41280"/><st c="41281">, the mutual information will be just as confident at identifying and quantifying that relationship as when the relationship is linear. </st><st c="41417">The mutual information is a sort of “non-linear correlation coefficient.” In contrast, the Pearson correlation coefficient value would be different for a non-linear relationship between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.640em"/><st c="41603"/><st c="41604"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.609em"/><st c="41609"/><st c="41610"> compared to a linear relationship. </st><st c="41646">The Pearson correlation coefficient may not spot that there is a strong relationship between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="41739"/><st c="41740"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="41745"/><st c="41746">, if that relationship </st><span class="No-Break"><st c="41769">is non-linear.</st></span></p>
			<p><st c="41783">This </st><a id="_idIndexMarker1116"/><st c="41789">makes mutual information a popular tool for feature selection in machine learning, by filtering out features that have low mutual information scores with the target variable. </st><st c="41964">Because many machine learning algorithms can build predictive models of non-linear relationships between features and targets, mutual information is excellent at identifying features a machine learning algorithm can make good </st><span class="No-Break"><st c="42190">use of.</st></span></p>
			<p><st c="42197">Let’s illustrate Eq. </st><st c="42219">31 with a code example. </st><st c="42243">First, we’ll introduce the data we’ll use in the code example. </st><st c="42306">The plots in </st><span class="No-Break"><st c="42319">Figure 13</st></span><st c="42328">.4 show scatter plots of two variables, </st><img src="image/24.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.441em"/><st c="42368"/><st c="42391"> and </st><img src="image/22.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.020em;height:0.482em;width:0.417em"/><st c="42395"/><st c="42396">, again</st><a id="_idTextAnchor681"/><st c="42403">st a third </st><span class="No-Break"><st c="42415">variable, </st></span><span class="No-Break"><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="42425"/></span><span class="No-Break"><st c="42426">:</st></span></p>
			<div>
				<div id="_idContainer4413" class="IMG---Figure">
					<img src="image/B19496_13_5.jpg" alt="" role="presentation"/><st c="42427"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="42568">Figure 13.4: Plots of y and z against x</st></p>
			<p><st c="42607">There is a clear strong linear relationship between </st><img src="image/24.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.441em"/><st c="42660"/><st c="42683"> and </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="42687"/><st c="42688">, while the relationship between </st><img src="image/22.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.020em;height:0.482em;width:0.417em"/><st c="42721"/><st c="42722"> and </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="42727"/><st c="42728"> is non-linear. </st><st c="42744">It won’t surprise you to learn that the </st><img src="image/62.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.020em;height:0.482em;width:0.426em"/><st c="42784"/><st c="42785"> values have been constructed from the </st><img src="image/769.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.450em"/><st c="42824"/><st c="42834"> values via </st><img src="image/4276.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;8&lt;/mml:mn&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.960em;width:3.354em"/><st c="42845"/><st c="42846">. If we wanted to build a model of </st><img src="image/24.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.440em"/><st c="42881"/><st c="42904"> or </st><img src="image/22.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.020em;height:0.482em;width:0.416em"/><st c="42907"/><st c="42908">, then </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.471em"/><st c="42915"/><st c="42916"> would be a good feature to use. </st><st c="42949">Let’s look at a code example showing how the mutual information is just as good at identifying that </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="43049"/><st c="43050"> is a good feature for predicting </st><img src="image/22.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.020em;height:0.482em;width:0.417em"/><st c="43084"/><st c="43085"> as it is at identifying </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="43110"/><st c="43111"> is a good feature for </st><span class="No-Break"><st c="43134">predicting </st></span><span class="No-Break"><img src="image/24.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.441em"/><st c="43145"/></span><span class="No-Break"><st c="43168">.</st></span></p>
			<h2 id="_idParaDest-371"><a id="_idTextAnchor682"/><st c="43169">Mutual information code example</st></h2>
			<p><st c="43201">You’ll find this </st><a id="_idIndexMarker1117"/><st c="43219">code example in the </st><strong class="source-inline"><st c="43239">Code_Examples_Chap13.ipynb</st></strong><st c="43265"> Jupyter notebook in this book’s </st><span class="No-Break"><st c="43298">GitHub repository.</st></span></p>
			<p><st c="43316">The first problem we must address is that the definition of mutual information in Eq. </st><st c="43403">19 is for random variables. </st><st c="43431">In </st><span class="No-Break"><st c="43434">Figure 13</st></span><st c="43443">.4, we have data – that is, a sample from random variables. </st><st c="43503">This means we can only estimate the mutual information and we must construct an estimation algorithm to do that. </st><st c="43616">Fortunately, someone has already done that for us. </st><st c="43667">We can use the </st><strong class="source-inline"><st c="43682">scikit-learn</st></strong><st c="43694"> library’s </st><strong class="source-inline"><st c="43705">mutual_info_regression</st></strong><st c="43727"> function from </st><strong class="source-inline"><st c="43742">sklearn.feature_selection</st></strong><st c="43767"> to estimate the mutual information from</st><a id="_idIndexMarker1118"/><st c="43807"> samples of two variables. </st><st c="43834">We’ll use the data that is plotted in </st><span class="No-Break"><st c="43872">Figure 13</st></span><st c="43881">.4. </st><st c="43885">The data is stored in the </st><strong class="source-inline"><st c="43911">mutual_information_data.csv</st></strong><st c="43938"> file in the </st><strong class="source-inline"><st c="43951">Data</st></strong><st c="43955"> directory of this book’s GitHub repository. </st><st c="44000">The data contains three columns called </st><img src="image/4284.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:1.289em"/><st c="44039"/><st c="44040"> and </st><img src="image/22.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.020em;height:0.482em;width:0.417em"/><st c="44045"/><st c="44046">. First, we must read in </st><span class="No-Break"><st c="44071">the data:</st></span></p>
			<pre class="source-code"><st c="44080">
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_selection import mutual_info_regression
from scipy.stats import pearsonr
# Read in the data
df_mutual = pd.read_csv('../Data/mutual_information_data.csv')</st></pre>			<p><st c="44327">We’ll calculate the Pearson correlation coefficient between </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.470em"/><st c="44388"/><st c="44389"> and </st><img src="image/24.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.705em;width:0.439em"/><st c="44394"/><st c="44417"> and between </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.470em"/><st c="44429"/><st c="44430"> and </st><img src="image/22.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;z&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.020em;height:0.482em;width:0.415em"/><st c="44435"/><st c="44436">. We’ll use the </st><strong class="source-inline"><st c="44452">scipy.stats.pearsonr</st></strong><st c="44472"> function to calculate the Pearson correlations </st><span class="No-Break"><st c="44520">for us:</st></span></p>
			<pre class="source-code"><st c="44527">
print("Pearson correlation between y and x = ", 
      pearsonr(df_mutual['x'], df_mutual['y'])[0])
print("Pearson correlation between z and x = ", 
      pearsonr(df_mutual['x'], df_mutual['z'])[0])</st></pre>			<p><st c="44713">This gives us the </st><span class="No-Break"><st c="44732">following output:</st></span></p>
			<pre class="source-code"><st c="44749">
Pearson correlation between y and x =  0.9801371625555979
Pearson correlation between z and x =  0.7569629714461419</st></pre>			<p><st c="44863">There is a 26% difference between the two Pearson correlation coefficient values. </st><st c="44946">Using the Pearson correlation coefficient to identify relationships between variables, from samples of those variables, works well when the relationship is linear. </st><st c="45110">However, when the relationship</st><a id="_idIndexMarker1119"/><st c="45140"> between two variables is non-linear, the Pearson correlation coefficient is not so good at identifying that a relationship </st><span class="No-Break"><st c="45264">is present.</st></span></p>
			<p><st c="45275">Now, for comparison, we’ll estimate the mutual information between </st><span class="_-----MathTools-_Math_Variable"><st c="45343">x</st></span><st c="45344"> and </st><span class="_-----MathTools-_Math_Variable"><st c="45349">y</st></span><st c="45350"> and between </st><span class="_-----MathTools-_Math_Variable"><st c="45363">x</st></span> <span class="No-Break"><st c="45364">and </st></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><st c="45368">z</st></span></span><span class="No-Break"><st c="45369">:</st></span></p>
			<pre class="source-code"><st c="45370">
print("Mutual information between y and x = ",
       mutual_info_regression(df_mutual['x'].values.reshape(-1,1), 
                              df_mutual['y'])[0])
print("Mutual information between z and x = ", 
       mutual_info_regression(df_mutual['x'].values.reshape(-1,1), df_                           mutual['z'])[0])</st></pre>			<p><st c="45625">This gives us the </st><span class="No-Break"><st c="45644">following output:</st></span></p>
			<pre class="source-code"><st c="45661">
Mutual information between y and x =  1.6219665917644344
Mutual information between z and x =  1.6154808774857417</st></pre>			<p><st c="45773">There is a 0.4% difference between those two estimates of mutual information. </st><st c="45852">This says that mutual information is just as good at identifying a relationship between two variables when that relationship is non-linear as when the relationship </st><span class="No-Break"><st c="46016">is linear.</st></span></p>
			<p><st c="46026">This code example concludes this section on mutual information, so let’s recap what </st><span class="No-Break"><st c="46111">we’ve learned.</st></span></p>
			<h2 id="_idParaDest-372"><a id="_idTextAnchor683"/><st c="46125">What we’ve learned</st></h2>
			<p><st c="46144">In this section, we’ve learned </st><span class="No-Break"><st c="46176">the following:</st></span></p>
			<ul>
				<li><st c="46190">The idea of entropy can be generalized to multiple </st><span class="No-Break"><st c="46242">random variables</st></span></li>
				<li><st c="46258">The mutual information, </st><img src="image/4290.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.669em"/><st c="46283"/><st c="46284">, tells us how much reduction in uncertainty about </st><img src="image/4142.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.618em"/><st c="46335"/><st c="46336"> we get on average from knowing the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="46381"/><st c="46382">, and </st><span class="No-Break"><st c="46388">vice versa</st></span></li>
				<li><st c="46398">Random variables that are independent of each other have zero </st><span class="No-Break"><st c="46461">mutual information</st></span></li>
				<li><st c="46479">The conditional entropy, </st><img src="image/4195.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.949em"/><st c="46505"/><st c="46506">, tells us the average entropy of </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="46540"/><st c="46541"> when we know the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="46568"/><st c="46569">, and so tells us about the average uncertainty in </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="46620"/><st c="46621"> after we </st><span class="No-Break"><st c="46631">know </st></span><span class="No-Break"><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="46636"/></span></li>
				<li><st c="46637">Mutual information and conditional entropy can be calculated for continuous </st><span class="No-Break"><st c="46713">random variables</st></span></li>
				<li><st c="46729">The mutual information between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.636em"/><st c="46761"/><st c="46762"> and </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.605em"/><st c="46767"/><st c="46768"> gives us a measure of the correlation between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.636em"/><st c="46815"/><st c="46816"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="46821"/><st c="46822">, even when the relationship between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="46859"/><st c="46860"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="46865"/> <span class="No-Break"><st c="46866">is non-linear</st></span></li>
			</ul>
			<p><st c="46879">Having learned how to quantify the information that is common between two different random variables, in the next section, we’ll learn how to quantify the information that is in common between two different distributions of the same single </st><span class="No-Break"><st c="47120">random variable.</st></span></p>
			<h1 id="_idParaDest-373"><a id="_idTextAnchor684"/><st c="47136">The Kullback-Leibler divergence</st></h1>
			<p><st c="47168">In the </st><a id="_idIndexMarker1120"/><st c="47176">previous section, we learned about the similarities between random variables from an information theory perspective. </st><st c="47293">But let’s return to just a single random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="47344"/><st c="47345">, and ask what would happen if we had two different distributions for that variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="47430"/><st c="47431">. As ever, we’ll start with the </st><span class="No-Break"><st c="47463">discrete case.</st></span></p>
			<p><st c="47477">Wait a moment! </st><st c="47493">How can we have two different distributions for the same random variable? </st><st c="47567">The variable is either random, and so has a given distribution, or it is not random. </st><st c="47652">Yes, that’s correct, but imagine that we have its true distribution, </st><img src="image/4306.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.289em"/><st c="47721"/><st c="47722">, and an approximation to its true distribution. </st><st c="47771">We’ll call the approximation </st><img src="image/4307.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.455em"/><st c="47800"/><st c="47801">. It may be that the true distribution is too complex to practically work with in a data science algorithm, so we want to replace it with a more tractable distribution, </st><img src="image/4308.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.470em"/><st c="47970"/><st c="47971">. Ideally, we’d like some way of measuring the difference between </st><img src="image/4309.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.302em"/><st c="48037"/><st c="48038"> and </st><img src="image/4307.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.455em"/><st c="48043"/><st c="48044"> so that we can tell how good an approximation </st><img src="image/4307.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.455em"/><st c="48091"/><st c="48092"> is. </st><st c="48097">We need a measure of the “distance” between </st><img src="image/4309.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.302em"/><st c="48141"/><st c="48142"> and </st><span class="_-----MathTools-_Math_Variable"><st c="48147">Q</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="48148">X</st></span><span class="_-----MathTools-_Math_Base"><st c="48149">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="48150">x</st></span><span class="_-----MathTools-_Math_Base"><st c="48151">)</st></span><st c="48152">. Even better, if </st><img src="image/4313.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.347em"/><st c="48170"/><st c="48171"> had some parameters, such as hyperparameters, we could use them to minimize that distance and make </st><img src="image/4314.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:2.150em"/><st c="48271"/><st c="48275"> look as much like </st><img src="image/4315.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.228em"/><st c="48293"/><st c="48294"> as we possibly can. </st><st c="48315">That way, we’d get the benefit of a tractable and easy-to-use distribution, </st><img src="image/4307.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.455em"/><st c="48391"/><st c="48392">, that is as close as possible to the </st><span class="No-Break"><st c="48430">true distribution.</st></span></p>
			<p><st c="48448">So, how do we measure the difference between </st><img src="image/4309.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.302em"/><st c="48494"/><st c="48495"> and </st><img src="image/4307.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.455em"/><st c="48500"/><st c="48501">? Using information, </st><span class="No-Break"><st c="48522">of course!</st></span></p>
			<h2 id="_idParaDest-374"><a id="_idTextAnchor685"/><st c="48532">Relative entropy</st></h2>
			<p><st c="48549">For</st><a id="_idIndexMarker1121"/><st c="48553"> any outcome value, </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.469em"/><st c="48573"/><st c="48574">, we can calculate the difference in information that we’d get according to </st><span class="_-----MathTools-_Math_Variable"><st c="48650">P</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="48651">X</st></span><span class="_-----MathTools-_Math_Base"><st c="48652">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="48653">x</st></span><span class="_-----MathTools-_Math_Base"><st c="48654">)</st></span><st c="48655"> and according to </st><img src="image/4307.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.455em"/><st c="48673"/><st c="48674">. This informatio</st><a id="_idTextAnchor686"/><st c="48691">n difference is </st><span class="No-Break"><st c="48708">as follows:</st></span></p>
			<p><img src="image/4321.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Information&lt;/mtext&gt;&lt;mtext&gt;difference&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.751em;height:2.147em;width:24.733em"/><st c="48719"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="48780">Eq. </st><st c="48784">32</st></p>
			<p><st c="48786">But this is the information difference at a single value, </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="48845"/><st c="48846">, so to construct a difference between </st><img src="image/4323.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.112em"/><st c="48885"/><st c="48886">and </st><img src="image/4324.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.126em"/><st c="48890"/><st c="48891">, we must calculate the average of Eq. </st><st c="48930">32 over all possible values of </st><img src="image/169.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.509em"/><st c="48961"/><st c="48962">, weighted with the true probabilities, </st><img src="image/4309.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.302em"/><st c="49002"/><st c="49003">. Doing so give</st><a id="_idTextAnchor687"/><st c="49018">s us the </st><span class="No-Break"><st c="49028">following formula:</st></span></p>
			<p><img src="image/4327.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Average&lt;/mtext&gt;&lt;mtext&gt;Information&lt;/mtext&gt;&lt;mtext&gt;Difference&lt;/mtext&gt;&lt;mtext&gt;=&lt;/mtext&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.946em;height:2.419em;width:22.355em"/><st c="49046"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="49103">Eq. </st><st c="49107">33</st></p>
			<p><st c="49109">Because Eq. </st><st c="49122">33 measures the difference in two average information values – that is, a difference in entropies – it is called</st><a id="_idIndexMarker1122"/><st c="49234"> the </st><strong class="bold"><st c="49239">relative entropy</st></strong><st c="49255">. However, it has another more commonly used name, as we </st><span class="No-Break"><st c="49312">shall see.</st></span></p>
			<p><st c="49322">The expression on the right-hand side of Eq. </st><st c="49368">33 is not a measure of distance between </st><img src="image/4328.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:0.861em"/><st c="49408"/><st c="49409"> and </st><img src="image/4329.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.011em"/><st c="49414"/><st c="49415"> because it is not symmetric – that is, if we swap </st><img src="image/4330.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.008em"/><st c="49466"/><st c="49467"> and </st><img src="image/4331.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.170em"/><st c="49472"/><st c="49473"> around in Eq. </st><st c="49488">33, we get a slightly different mathematical expression. </st><st c="49545">Instead, we refer to Eq. </st><st c="49570">33 as a </st><strong class="bold"><st c="49578">divergence</st></strong><st c="49588">. In this case, it is called the Kullback-Leibler divergence, or KL-divergence for short, and given the symbol </st><img src="image/4332.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:5.175em"/><st c="49699"/><st c="49700">. So, for</st><a id="_idTextAnchor688"/><st c="49709">mally we have </st><span class="No-Break"><st c="49724">the following:</st></span></p>
			<p><img src="image/4333.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.795em;height:2.268em;width:14.443em"/><st c="49738"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="49770">Eq. </st><st c="49774">34</st></p>
			<p><st c="49776">We also</st><a id="_idTextAnchor689"/><st c="49784"> have the </st><span class="No-Break"><st c="49794">following formula:</st></span></p>
			<p><img src="image/4334.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.900em;height:2.469em;width:15.089em"/><st c="49812"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="49814">Eq. </st><st c="49818">35</st></p>
			<p><st c="49820">Although</st><a id="_idIndexMarker1123"/><st c="49829"> we can see from Eq. </st><st c="49850">34 and Eq. </st><st c="49861">35 that </st><img src="image/4335.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;≠&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:11.218em"/><st c="49869"/><st c="49870"> and so we cannot take </st><img src="image/4336.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:4.939em"/><st c="49893"/><st c="49894"> as a distance measure, we can still use it as a measure of the difference between </st><img src="image/4337.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:0.925em"/><st c="49977"/><st c="49978"> and </st><img src="image/4338.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.037em"/><st c="49983"/><st c="49984">. This means we can still use </st><img src="image/4339.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:4.652em"/><st c="50014"/><st c="50015"> for our original goal of finding an optimized approximation to the distribution, </st><img src="image/4337.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:0.922em"/><st c="50097"/><st c="50098">. In particular, </st><img src="image/4341.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:4.928em"/><st c="50115"/><st c="50116"> has the following </st><span class="No-Break"><st c="50135">useful properties:</st></span></p>
			<p><img src="image/4342.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mtext&gt;if&lt;/mtext&gt;&lt;mtext&gt;and&lt;/mtext&gt;&lt;mtext&gt;only&lt;/mtext&gt;&lt;mtext&gt;if&lt;/mtext&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.383em;height:1.274em;width:16.488em"/><st c="50153"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="50193">Eq. </st><st c="50197">36</st></p>
			<p><img src="image/4343.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;&gt;&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mtext&gt;if&lt;/mtext&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;≠&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.383em;height:1.274em;width:12.420em"/><st c="50199"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="50230">Eq. </st><st c="50234">37</st></p>
			<p><st c="50236">These properties tell us that the KL-divergence is only zero if our approximation is perfect. </st><st c="50331">By adjusting any parameters in </st><img src="image/4344.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.054em"/><st c="50362"/><st c="50363"> to make the KL-divergence smaller, we will be making our approximation </st><img src="image/4344.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.052em"/><st c="50435"/><st c="50436"> closer </st><span class="No-Break"><st c="50444">to </st></span><span class="No-Break"><img src="image/4068.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:0.893em"/><st c="50447"/></span><span class="No-Break"><st c="50448">.</st></span></p>
			<h2 id="_idParaDest-375"><a id="_idTextAnchor690"/><st c="50449">KL-divergence for continuous variables</st></h2>
			<p><st c="50488">As you</st><a id="_idIndexMarker1124"/><st c="50495"> have probably already guessed, all the results about KL-divergences for discrete random variables can be generalized to continuous random variables. </st><st c="50645">The formulae are those you would guess, so we will just state them here. </st><st c="50718">For a continuous random variable, </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.665em"/><st c="50752"/><st c="50753">, the KL-divergence between probability densities </st><img src="image/4085.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.252em"/><st c="50803"/><st c="50804"> and </st><img src="image/4349.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.260em"/><st c="50809"/><st c="50810"> is g</st><a id="_idTextAnchor691"/><st c="50815">iven by the </st><span class="No-Break"><st c="50828">following formula:</st></span></p>
			<p><img src="image/4350.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.966em;height:2.439em;width:14.833em"/><st c="50846"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="50885">Eq. </st><st c="50889">38</st></p>
			<h2 id="_idParaDest-376"><a id="_idTextAnchor692"/><st c="50891">Using the KL-divergence for approximation</st></h2>
			<p><st c="50933">To finish</st><a id="_idIndexMarker1125"/><st c="50943"> this chapter, we’ll give an example of how we can use the KL-divergence for approximating a distribution. </st><st c="51050">This example is deliberately simple to help illustrate the ideas. </st><st c="51116">Don’t worry – there is a more complex example that has been set as an exercise at the end of </st><span class="No-Break"><st c="51209">this chapter.</st></span></p>
			<p><st c="51222">We will use a continuous random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.630em"/><st c="51265"/><st c="51266">, whose true density is a Laplace distribution with density given by the </st><span class="No-Break"><st c="51339">following formula:</st></span></p>
			<p><img src="image/4352.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.563em;height:1.527em;width:8.508em"/><st c="51357"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="51359">Eq. </st><st c="51363">39</st></p>
			<p><st c="51365">Here, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="51372"/><st c="51373"> has a mean of zero and a variance of </st><img src="image/4354.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:1.420em"/><st c="51411"/><st c="51412">. We are going to approximate </st><img src="image/4085.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.174em;width:2.252em"/><st c="51442"/><st c="51443"> by a Gaussian distribution with mean zero and variance, </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="51500"/><st c="51505">, so we’ll write </st><span class="No-Break"><st c="51522">the following:</st></span></p>
			<p><img src="image/4357.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.684em;height:1.766em;width:10.770em"/><st c="51536"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="51563">Eq. </st><st c="51567">40</st></p>
			<p><st c="51569">The variance, </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.841em"/><st c="51584"/><st c="51589">, is the parameter we will adjust to make </st><img src="image/4359.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.781em;width:0.853em"/><st c="51631"/><st c="51632"> as close as possible to </st><img src="image/4360.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.851em;width:0.845em"/><st c="51657"/><st c="51658"> by minimizing the KL-divergence, </st><img src="image/4361.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:4.723em"/><st c="51692"/><st c="51697">, given in Eq. </st><st c="51712">38. </st><st c="51716">We can simplify the calculation by first re-writi</st><a id="_idTextAnchor693"/><st c="51765">ng </st><img src="image/4362.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.383em;height:1.274em;width:4.646em"/><st c="51769"/><st c="51774">, </st><span class="No-Break"><st c="51776">as follows:</st></span></p>
			<p><img src="image/4363.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.383em;height:1.274em;width:22.310em"/><st c="51787"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="51842">Eq. </st><st c="51846">41</st></p>
			<p><st c="51848">The second integral on the right-hand side of Eq. </st><st c="51899">41 only depends on </st><img src="image/4364.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.851em;width:0.869em"/><st c="51918"/><st c="51919">, so it does not depend on our parameter, </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="51961"/><st c="51966">. To determine the optimal value of </st><img src="image/4366.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.117em;height:0.820em;width:1.067em"/><st c="52002"/><st c="52007"> we only need minimize the first integral on the right-hand side of Eq. </st><st c="52078">41. </st><st c="52082">Th</st><a id="_idTextAnchor694"/><st c="52084">e first integral is </st><span class="No-Break"><st c="52105">as follows:</st></span></p>
			<p><img src="image/4367.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;/mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;/msubsup&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.555em;height:1.707em;width:19.899em"/><st c="52116"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="52154">Eq. </st><st c="52158">42</st></p>
			<p><st c="52160">So, to determine the optimal value of </st><img src="image/4368.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.824em"/><st c="52199"/><st c="52202">, we must minimize the right-hand side of Eq. </st><st c="52248">42 with respect to </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="52267"/><st c="52272">. We can do this by differentiating with respect to </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="52324"/><st c="52329"> and setting the derivative equal to zero. </st><st c="52371">By doing this</st><a id="_idTextAnchor695"/><st c="52384">, we get the </st><span class="No-Break"><st c="52397">following formula:</st></span></p>
			<p><img src="image/4371.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;∂&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.555em;height:1.645em;width:13.849em"/><st c="52415"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="52443">Eq. </st><st c="52447">43</st></p>
			<p><st c="52449">Solving Eq. </st><st c="52462">43 for </st><img src="image/2090.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.839em"/><st c="52469"/><st c="52474">, we find </st><span class="No-Break"><st c="52484">that </st></span><span class="No-Break"><img src="image/4373.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:3.800em"/><st c="52489"/></span><span class="No-Break"><st c="52499">.</st></span></p>
			<p><st c="52500">This </st><a id="_idIndexMarker1126"/><st c="52506">result is somewhat trivial. </st><st c="52534">It says that the optimal value of </st><img src="image/4374.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:0.918em"/><st c="52568"/><st c="52571">, the variance of our Gaussian approximation, is equal to the variance of our true distribution. </st><st c="52668">We could have guessed that. </st><st c="52696">There are also other simpler methods, such as moment matching, for setting the variance parameter of an approximation. </st><st c="52815">However, our main goal here was to illustrate, in as simple a way as possible, the main steps in using the KL-divergence to derive an optimal approximation to another distribution. </st><st c="52996">There is another reason why we chose to use this very simple example, and why our exercises are still relatively simple at the end of this chapter. </st><st c="53144">It is because, for these examples, we can calculate </st><span class="_-----MathTools-_Math_Variable"><st c="53196">D</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="53197">K</st></span><span class="_-----MathTools-_Math_Variable"><st c="53198">L</st></span><span class="_-----MathTools-_Math_Base"><st c="53199">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="53200">p</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="53201">X</st></span><span class="_-----MathTools-_Math_Base"><st c="53202">|</st></span><span class="_-----MathTools-_Math_Base"><st c="53203">|</st></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><st c="53204">q</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="53205">X</st></span><span class="_-----MathTools-_Math_Base"><st c="53206">)</st></span><st c="53207"> exactly and minimize it exactly. </st><st c="53241">This is not always </st><span class="No-Break"><st c="53260">the case.</st></span></p>
			<h2 id="_idParaDest-377"><a id="_idTextAnchor696"/><st c="53269">Variational inference</st></h2>
			<p><st c="53291">When we use</st><a id="_idIndexMarker1127"/><st c="53303"> KL-divergences in real data science algorithms, we are typically constructing some approximation, </st><img src="image/4375.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.399em;height:0.847em;width:0.761em"/><st c="53402"/><st c="53403">, to the Bayesian posterior probability, </st><img src="image/4376.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mtext&gt;Prob&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mtext&gt;Data&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.399em;height:1.160em;width:7.567em"/><st c="53444"/><st c="53462">, where </st><img src="image/4377.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.112em;height:0.823em;width:0.526em"/><st c="53470"/><st c="53471"> represents the parameters of a probabilistic model we have used to model our training data. </st><st c="53564">The practice of constructing an approximation to a model posterior by varying the parameters of the approximation until a KL-divergence is optimal, is part of a wider field of machine learning </st><a id="_idIndexMarker1128"/><st c="53757">methods known as </st><strong class="bold"><st c="53774">variational inference techniques</st></strong><st c="53806">, or </st><span class="No-Break"><strong class="bold"><st c="53811">variational inference</st></strong></span><span class="No-Break"><st c="53832">.</st></span></p>
			<p><st c="53833">In general, calculating and minimizing </st><img src="image/4378.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:3.965em"/><st c="53873"/><st c="53883"> can be hard and the resulting optimized approximation, </st><img src="image/4379.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.399em;height:0.847em;width:0.849em"/><st c="53938"/><st c="53939">, is not always an accurate approximation, or as accurate as we would like it to be. </st><st c="54024">Instead, in variational inference, it is more common to work with </st><img src="image/4380.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:4.552em"/><st c="54090"/><st c="54095">. Here, we minimize </st><img src="image/4380.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:4.554em"/><st c="54115"/><st c="54120"> with respect to the parameters of the approximate </st><span class="No-Break"><st c="54170">density, </st></span><span class="No-Break"><img src="image/4375.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.399em;height:0.847em;width:0.760em"/><st c="54179"/></span><span class="No-Break"><st c="54180">.</st></span></p>
			<p><st c="54181">Minimizing </st><img src="image/4383.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:4.500em"/><st c="54193"/><st c="54198"> has some nice properties. </st><st c="54224">Deriving those properties is beyond the scope of this short section on the KL-divergence, so we will just state the main property at a high level. </st><st c="54371">Minimizing the KL-divergence, </st><img src="image/4384.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:4.201em"/><st c="54401"/><st c="54406">, is equivalent to maximizing a lower </st><a id="_idIndexMarker1129"/><st c="54444">bound on the Bayesian evidence of the model. </st><st c="54489">You may recall from </st><a href="B19496_08.xhtml#_idTextAnchor406"><span class="No-Break"><em class="italic"><st c="54509">Chapter 8</st></em></span></a><st c="54518"> that the Bayesian evidence is a quantity that measures how good our probabilistic model form is, given the data. </st><st c="54632">From this, we can rigorously show that minimizing </st><img src="image/4385.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:4.272em"/><st c="54682"/><st c="54687"> does indeed obtain the best possible approximation, </st><img src="image/4386.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.399em;height:0.847em;width:0.734em"/><st c="54739"/><st c="54740">, and this motivates us to work </st><span class="No-Break"><st c="54772">with </st></span><span class="No-Break"><img src="image/4387.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:4.464em"/><st c="54777"/></span><span class="No-Break"><st c="54782">.</st></span></p>
			<p><st c="54783">Minimizing </st><img src="image/4388.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:5.209em"/><st c="54795"/><st c="54808"> when working with real data science algorithms can also require using sophisticated optimization techniques, so we won’t go into the details here. </st><st c="54955">However, it does explain why our introductory examples needed to be simple and why we focused on minimizing </st><img src="image/4389.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.449em;height:1.405em;width:4.816em"/><st c="55063"/> <span class="No-Break"><st c="55077">instead.</st></span></p>
			<p><st c="55085">This section provided a concise introduction to the KL-divergence. </st><st c="55153">So, let’s summarize what we’ve learned about it before wrapping up </st><span class="No-Break"><st c="55220">this chapter.</st></span></p>
			<h2 id="_idParaDest-378"><a id="_idTextAnchor697"/><st c="55233">What we’ve learned</st></h2>
			<p><st c="55252">In this section, we’ve learned </st><span class="No-Break"><st c="55284">the following:</st></span></p>
			<ul>
				<li><st c="55298">Relative entropy measures the average difference in information between two different distributions for the same </st><span class="No-Break"><st c="55412">random variable</st></span></li>
				<li><st c="55427">Relative entropy is also known as the KL-divergence and can be used as an asymmetric measure of the difference between </st><span class="No-Break"><st c="55547">two distributions</st></span></li>
				<li><st c="55564">We can use the KL-divergence to optimize how well one distribution </st><span class="No-Break"><st c="55632">approximates another</st></span></li>
			</ul>
			<h1 id="_idParaDest-379"><a id="_idTextAnchor698"/><st c="55652">Summary</st></h1>
			<p><st c="55660">This chapter was about information theory. </st><st c="55704">Although you are less likely to directly use the calculations demonstrated in this chapter compared to the material from other chapters, the concepts and ideas behind information theory can be invaluable. </st><st c="55909">Information-theoretic concepts give us a different way to think about probability, distributions, and what is conveyed when we observe a piece of data. </st><st c="56061">Those concepts are </st><span class="No-Break"><st c="56080">as follows:</st></span></p>
			<ul>
				<li><st c="56091">Information theory concerns itself with the communication of signals and the efficiency of encoding </st><span class="No-Break"><st c="56192">those signals.</st></span></li>
				<li><st c="56206">The smaller the probability of an event or outcome occurring, the higher the information associated with that event </st><span class="No-Break"><st c="56323">or outcome.</st></span></li>
				<li><st c="56334">We measure information on a </st><span class="No-Break"><st c="56363">logarithmic scale.</st></span></li>
				<li><st c="56381">The expected information tells us the average amount of information we get from an observation of a random variable. </st><st c="56499">The expected information is more commonly known </st><span class="No-Break"><st c="56547">as entropy.</st></span></li>
				<li><st c="56558">Entropy increases with the variance of a distribution, so it quantifies the uncertainty about an outcome before we have </st><span class="No-Break"><st c="56679">measured it.</st></span></li>
				<li><st c="56691">The MaxEnt technique can be used to determine the most probable distribution compatible with </st><span class="No-Break"><st c="56785">specified constraints.</st></span></li>
				<li><st c="56807">The idea of entropy can be generalized to multiple </st><span class="No-Break"><st c="56859">random variables.</st></span></li>
				<li><st c="56876">The mutual information, </st><img src="image/4290.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.669em"/><st c="56901"/><st c="56902">, tells us how much reduction in uncertainty about </st><img src="image/4142.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.618em"/><st c="56953"/><st c="56954"> we get on average from knowing the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="56999"/><st c="57000">, and </st><span class="No-Break"><st c="57006">vice versa.</st></span></li>
				<li><st c="57017">The conditional entropy, </st><img src="image/4195.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.949em"/><st c="57043"/><st c="57044">, tells us the average entropy of </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="57078"/><st c="57079"> when we know the value of </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="57106"/><st c="57107">, so it tells us about the average uncertainty in </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="57157"/><st c="57158"> after we </st><span class="No-Break"><st c="57168">know </st></span><span class="No-Break"><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="57173"/></span><span class="No-Break"><st c="57174">.</st></span></li>
				<li><st c="57175">The mutual information between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.636em"/><st c="57207"/><st c="57208"> and </st><img src="image/4140.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.605em"/><st c="57213"/><st c="57214"> gives us a measure of the correlation between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.636em"/><st c="57261"/><st c="57262"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="57267"/><st c="57268">, even when the relationship between </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.641em"/><st c="57305"/><st c="57306"> and </st><img src="image/2023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.610em"/><st c="57311"/> <span class="No-Break"><st c="57312">is non-linear.</st></span></li>
				<li><st c="57326">Relative entropy measures the average difference in information between two different distributions for the same </st><span class="No-Break"><st c="57440">random variable.</st></span></li>
				<li><st c="57456">Relative entropy is also known as the KL-divergence and can be used as an asymmetric measure of the difference between </st><span class="No-Break"><st c="57576">two distributions.</st></span></li>
				<li><st c="57594">We can use the KL-divergence to optimize how well one distribution </st><span class="No-Break"><st c="57662">approximates another.</st></span></li>
			</ul>
			<p><st c="57683">This was a very brief introduction to a very large topic. </st><st c="57742">For more extensive introductions to information theory, see the books suggested in [</st><em class="italic"><st c="57826">2</st></em><st c="57828">] of the </st><em class="italic"><st c="57837">Notes and further </st></em><span class="No-Break"><em class="italic"><st c="57855">reading</st></em></span><span class="No-Break"><st c="57862"> section.</st></span></p>
			<p><st c="57871">Like this chapter on information theory, our next chapter will also make use of probabilistic concepts. </st><st c="57976">The next chapter will also cover an advanced topic: Bayesian </st><span class="No-Break"><st c="58037">non-parametric modeling.</st></span></p>
			<h1 id="_idParaDest-380"><a id="_idTextAnchor699"/><st c="58061">Exercises</st></h1>
			<p><st c="58071">This section contains a series of exercises. </st><st c="58117">The answers to all these can be found in the </st><strong class="source-inline"><st c="58162">Answers_to_Exercises_Chap13.ipynb</st></strong><st c="58195"> Jupyter notebook in this book’s </st><span class="No-Break"><st c="58228">GitHub repository.</st></span></p>
			<p><st c="58246">We have a composite random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.645em"/><st c="58284"/><st c="58285">, that consists of three binary random variables, </st><img src="image/4405.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.003em;width:3.678em"/><st c="58335"/><st c="58343">. We denote this as </st><img src="image/4406.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.390em;height:1.103em;width:6.399em"/><st c="58363"/><st c="58380">. We’ll use </st><img src="image/4407.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.781em;width:0.761em"/><st c="58392"/><st c="58393"> for the outcome for </st><img src="image/4408.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:0.905em"/><st c="58414"/><st c="58415">, </st><img src="image/4409.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.781em;width:0.761em"/><st c="58417"/><st c="58418"> for the outcome of </st><img src="image/4410.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:0.905em"/><st c="58438"/><st c="58439">, and </st><img src="image/4411.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.788em;width:0.761em"/><st c="58445"/><st c="58446"> for the outcome of </st><img src="image/4412.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.003em;width:0.905em"/><st c="58466"/><st c="58467">. This </st><span class="No-Break"><st c="58474">means </st></span><span class="No-Break"><img src="image/4413.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mfenced open=&quot;{&quot; close=&quot;}&quot;&gt;&lt;mn&gt;0,1&lt;/mn&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:1.024em;width:6.620em"/><st c="58480"/></span><span class="No-Break"><st c="58497">.</st></span></p>
			<p><st c="58498">We can write the outcome, </st><img src="image/311.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.460em"/><st c="58525"/><st c="58526">, for the overall random variable, </st><img src="image/2022.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.626em"/><st c="58561"/><st c="58562">, as a three-digit bit-string For example, </st><img src="image/4416.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;010&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:3.454em"/><st c="58605"/><st c="58606"> –to represent the outcome, </st><img src="image/4417.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:0.974em;width:9.171em"/><st c="58634"/><st c="58635">. There are </st><img src="image/4418.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;8&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.715em;width:2.832em"/><st c="58647"/><st c="58648"> possible values for </st><img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.473em"/><st c="58669"/><st c="58670">; these are 000,001,010,011,100,101,110,111. </st><st c="58715">We can also denote the true probability distribution, </st><span class="_-----MathTools-_Math_Variable"><st c="58769">P</st></span><span class="_-----MathTools-_Math_Base"/><span class="_-----MathTools-_Math_Variable"><st c="58770">X</st></span><span class="_-----MathTools-_Math_Base"><st c="58771">(</st></span><span class="_-----MathTools-_Math_Variable"><st c="58772">x</st></span><span class="_-----MathTools-_Math_Base"><st c="58773">)</st></span><st c="58774">, as </st><img src="image/4420.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.532em;height:1.180em;width:6.054em"/><st c="58779"/><st c="58795">; it corresponds to eight numbers (between 0 and 1) that all add up </st><span class="No-Break"><st c="58863">to 1.</st></span></p>
			<p><st c="58868">Now, let’s introduce our approximation, </st><img src="image/4324.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.121em"/><st c="58909"/><st c="58910">. We will use a product approxima</st><a id="_idTextAnchor700"/><st c="58943">tion, so we’ll write </st><span class="No-Break"><st c="58965">the following:</st></span></p>
			<p><img src="image/4422.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mtext&gt;approx)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;msubsup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mtext&gt;approx)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;msubsup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mtext&gt;approx)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.532em;height:1.300em;width:20.018em"/><st c="58979"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="59030">Eq. </st><st c="59034">44</st></p>
			<p><st c="59036">We’ve put the superscript “approx” on the distributions on the right-hand side of Eq. </st><st c="59123">44 to emphasize that we’re constructing an approximation and that </st><img src="image/4423.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mtext&gt;approx)&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.528em;height:1.296em;width:4.156em"/><st c="59189"/><st c="59208"> is not the true marginal distribution, </st><img src="image/4424.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.528em;height:1.176em;width:2.502em"/><st c="59247"/><st c="59248">, but an approximation </st><span class="No-Break"><st c="59271">to it.</st></span></p>
			<p><st c="59277">Here are the exercises concerning </st><span class="No-Break"><st c="59312">this question:</st></span></p>
			<ol>
				<li><st c="59326">What is the only form the approximation, </st><img src="image/4425.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mtext&gt;approx)&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.528em;height:1.296em;width:4.202em"/><st c="59368"/><st c="59387">, can take? </st><st c="59399">What are the parameters of </st><span class="No-Break"><st c="59426">this approximation?</st></span></li>
				<li><st c="59445">Using this approximation for </st><img src="image/4426.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mtext&gt;approx)&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.528em;height:1.296em;width:4.728em"/><st c="59475"/><st c="59495">, and similar approximations for </st><img src="image/4427.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mtext&gt;approx)&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.528em;height:1.296em;width:4.963em"/><st c="59528"/><st c="59548"> and </st><img src="image/4428.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mtext&gt;approx)&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.532em;height:1.300em;width:5.000em"/><st c="59552"/><st c="59572">, substitute these into Eq. </st><st c="59600">44 to write down the full mathematical form for the </st><span class="No-Break"><st c="59652">approximation, </st></span><span class="No-Break"><img src="image/4429.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.532em;height:1.195em;width:6.574em"/><st c="59667"/></span><span class="No-Break"><st c="59685">.</st></span></li>
				<li><st c="59686">Using the mathematical expression for </st><img src="image/4430.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.532em;height:1.195em;width:6.207em"/><st c="59725"/><st c="59740"> that you wrote in question 2, derive an expression for the KL-divergence, </st><img src="image/4431.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;K&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.582em;height:1.671em;width:8.086em"/><st c="59814"/><st c="59833">, in terms of the parameters of </st><img src="image/4432.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.532em;height:1.195em;width:7.008em"/><st c="59865"/><st c="59880"> and the true marginal distributions, </st><img src="image/4433.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.528em;height:1.176em;width:2.472em"/><st c="59917"/><st c="59918">, </st><img src="image/4434.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.528em;height:1.176em;width:2.472em"/><st c="59920"/><st c="59921">, </st><span class="No-Break"><st c="59923">and </st></span><span class="No-Break"><img src="image/4435.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.532em;height:1.180em;width:2.508em"/><st c="59927"/></span><span class="No-Break"><st c="59928">.</st></span></li>
				<li><st c="59929">Minimize the expression for the KL-divergence you derived in question 3 concerning the parameters of </st><img src="image/4430.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.532em;height:1.195em;width:6.207em"/><st c="60031"/><st c="60046">. Comment on </st><span class="No-Break"><st c="60059">the solution.</st></span></li>
			</ol>
			<h1 id="_idParaDest-381"><a id="_idTextAnchor701"/><st c="60072">Notes and further reading</st></h1>
			<p><st c="60098">To learn more about the topics that were covered in this chapter, take a look at the </st><span class="No-Break"><st c="60184">following resources:</st></span></p>
			<ol>
				<li><st c="60204">For a short but very readable discussion on the broader aspects of what information is, I like the book by L. </st><st c="60315">Floridi, </st><em class="italic"><st c="60324">Information: A Very Short Introduction</st></em><st c="60362">, 1</st><span class="superscript"><st c="60365">st</st></span><st c="60368"> Edition (2010), Oxford University Press, Oxford, UK. </st><span class="No-Break"><st c="60422">ISBN: 978-0199551378.</st></span></li>
				<li><st c="60443">For additional texts on the mathematical aspects of information theory, see </st><span class="No-Break"><st c="60520">the following:</st></span><ol><li class="Alphabets"><st c="60534">For a modern readable introduction to the mathematical theory of information, I like the book by J.V. </st><st c="60637">Stone, </st><em class="italic"><st c="60644">Information Theory: A Tutorial Introduction</st></em><st c="60687">, 1</st><span class="superscript"><st c="60690">st</st></span><st c="60693"> Edition (2015), Sebtel Press. </st><span class="No-Break"><st c="60724">ISBN: 978-0956372857.</st></span></li><li class="Alphabets"><st c="60745">Another accessible and well-established account of mathematical information theory is the book by J.R. </st><st c="60849">Pierce, </st><em class="italic"><st c="60857">An Introduction to Information Theory: Symbols, Signals and Noise</st></em><st c="60922">, Revised 2</st><span class="superscript"><st c="60933">nd</st></span><st c="60936"> Edition (2003), Dover Publications, New York, USA. </st><span class="No-Break"><st c="60988">ISBN: 978-0486240619.</st></span></li><li class="Alphabets"><st c="61009">The most authoritative textbook on information theory is probably </st><em class="italic"><st c="61076">Elements of Information Theory</st></em><st c="61106">, 2</st><span class="superscript"><st c="61109">nd</st></span><st c="61112"> Edition (2006), by T.M. </st><st c="61137">Cover and J.A. </st><st c="61152">Thomas. </st><st c="61160">It is published by Wiley-Interscience, Hoboken, New Jersey, USA. </st><st c="61225">It is a lengthy textbook (nearly </st><span class="No-Break"><st c="61258">800 pages).</st></span></li><li class="Alphabets"><st c="61269">A modern and well-known book linking aspects of information theory and machine learning is that by D.J.C. </st><st c="61376">MacKay, </st><em class="italic"><st c="61384">Information Theory, Inference and Learning Algorithms</st></em><st c="61437">, 1</st><span class="superscript"><st c="61440">st</st></span><st c="61443"> Edition (2003), Cambridge University Press, Cambridge, UK. </st><st c="61503">ISBN: 978-0521642989. </st><st c="61525">A PDF copy of the book can be found online </st><span class="No-Break"><st c="61568">at </st></span><a href="https://www.inference.org.uk/itila/book.html"><span class="No-Break"><st c="61571">https://www.inference.org.uk/itila/book.html</st></span></a><span class="No-Break"><st c="61615">.</st></span></li></ol></li>
			</ol>
		</div>
	<div id="charCountTotal" value="61616"/></body></html>