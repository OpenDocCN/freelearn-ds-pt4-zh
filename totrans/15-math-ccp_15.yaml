- en: <st c="0">1</st><st c="2">4</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="3">Non-Parametric Bayesian Methods</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="34">Building a predictive model requires us to make assumptions.</st>
    <st c="96">For example, we often need to assume some fixed mathematical form for
    the relationship between our predictive features and the response variable.</st>
    <st c="242">It is the parameters within that mathematical form that we usually
    vary and optimize through a training process, not the mathematical form.</st>
    <st c="382">If those parametric assumptions are incorrect, we get a poorly performing
    model.</st> <st c="463">Often it would be better to not make those parametric
    assumptions and to use a non-parametric modeling approach.</st> <st c="576">That
    is what we do in this chapter.</st> <st c="612">We do so by putting Bayesian priors
    on the functions and relationships that we model.</st> <st c="698">This makes
    the methods we use non-parametric Bayesian methods.</st> <st c="761">To learn
    about them we must introduce some new modeling ideas and concepts.</st> <st c="837">We
    do that by covering the</st> <st c="864">following topics:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="881">What are non-parametric Bayesian methods?</st>*<st c="923">: This
    is where we learn about the key concept of not making parametric assumptions about
    the relationship between features and</st> <st c="1052">response variables</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<st c="1070">Gaussian processes</st>*<st c="1089">: This is where we learn
    what</st> **<st c="1120">Gaussian processes</st>** <st c="1138">(</st>**<st c="1140">GPs</st>**<st
    c="1143">) are and how they can be used as a prior on the relationship between
    our features and our</st> <st c="1235">response variable</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<st c="1252">Dirichlet processes</st>*<st c="1272">: This is where we learn
    what</st> **<st c="1303">Dirichlet processes</st>** <st c="1322">(</st>**<st c="1324">DPs</st>**<st
    c="1327">) are and how they can be used as a prior on a</st> <st c="1375">probability
    distribution</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1399">Technical requirements</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1422">All code examples given in this chapter can be found in the GitHub
    repository at</st> [<st c="1504">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter14</st>](https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter14)<st
    c="1608">. To run the Jupyter Notebooks, you will need a full Python installation
    including the</st> <st c="1695">following packages:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="1714">pandas</st>` <st c="1721">(>=2.0.3)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="1731">numpy</st>` <st c="1737">(>=1.24.3)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="1748">scikit-learn</st>` <st c="1761">(>=1.3.0)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="1771">matplotlib</st>` <st c="1782">(>=3.7.2)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1792">What are non-parametric Bayesian methods?</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1834">As the name suggests, non-parametric Bayesian methods are Bayesian,
    so it may be a good time to review the section in</st> [*<st c="1953">Chapter
    5</st>*](B19496_05.xhtml#_idTextAnchor261) <st c="1962">on Bayesian probabilistic
    modeling.</st> <st c="1999">Because we are using</st> <st c="2020">Bayesian methods,
    we will be using priors.</st> <st c="2063">As usual with Bayesian methods, there
    is a subjective element to setting the prior.</st> <st c="2147">The prior is something
    we choose.</st> <st c="2181">Choose a slightly different prior and we will get
    slightly different inferences.</st> <st c="2262">However, it is what we use the
    prior for that is the interesting aspect of non-parametric</st> <st c="2352">Bayesian
    methods.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2369">In</st> [*<st c="2373">Chapter 5</st>*](B19496_05.xhtml#_idTextAnchor261)<st
    c="2382">, when we were using Bayesian methods to build probabilistic models,
    we had the data points,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mfenced
    open="(" close=")"><mrow><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub></mrow></mfenced><mo>,</mo><mi>i</mi><mo>=</mo><mn>1,2</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>N</mi></mrow></mrow></math>](img/4437.png)<st
    c="2475"><st c="2476">. We modeled the target variable values,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4438.png)<st
    c="2517"><st c="2518">, as random variables whose probability density function
    was given by some function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4439.png)<st
    c="2603"><st c="2604">, with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1765.png)
    <st c="2611"><st c="2612">being the model parameters.</st> <st c="2641">We’d write
    this in statistical modeling notation</st> <st c="2690">as follows:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>~</mo><mi>f</mi><mfenced
    open="(" close=")"><mrow><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>i</mi></msub><mo>|</mo><munder><mi>θ</mi><mo
    stretchy="true">_</mo></munder></mrow></mfenced><mi>i</mi><mo>=</mo><mn>1,2</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>N</mi></mrow></mrow></math>](img/4441.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="2703">Eq.</st> <st c="2707">1</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2708">What</st> *<st c="2713">Eq.</st> <st c="2717">1</st>* <st c="2718">says
    is that the observations of the target (response) variable,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)<st
    c="2784"><st c="2794">, are random variables whose distribution changes with the
    predictive features,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4443.png)<st
    c="2874"><st c="2875">. For example, the mean of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="2902"><st c="2925">changes with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4443.png)<st
    c="2938"><st c="2939">, and how those changes occur is controlled by the model
    parameters,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1765.png)<st
    c="3008"><st c="3009">.</st> *<st c="3011">Eq.</st> <st c="3015">1</st>* <st c="3016">allows
    us to calculate the likelihood of the observations,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>y</mi><mi>N</mi></msub></mrow></mrow></math>](img/4447.png)<st
    c="3076"><st c="3087">. We would then put a prior,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>P</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4448.png)<st
    c="3116"><st c="3117">, on the parameters,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1765.png)<st
    c="3138"><st c="3139">. Combining the prior and the likelihood gives us the</st>
    <st c="3193">posterior, the probability of the model parameters,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder><mml:mo>,</mml:mo></mml:math>](img/4450.png)
    <st c="3245"><st c="3246">given the data.</st> <st c="3263">This is</st> **<st
    c="3271">Bayesian</st>** **<st c="3280">parametric modeling</st>**<st c="3299">.</st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3300">In</st> *<st c="3304">Eq.</st> <st c="3308">1</st>*<st c="3309">,
    we have a fixed mathematical form for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)
    <st c="3349"><st c="3403">and it is the model parameters,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1765.png)<st
    c="3435"><st c="3436">, that control the variation in the target values,</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><mfenced open="(" close=")"><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>y</mi><mi>N</mi></msub></mrow></mfenced></mrow></mrow></math>](img/4453.png)<st
    c="3487"><st c="3506">. Typically, the more model parameters we have, the more
    flexibility we have in the possible variation of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4454.png)<st
    c="3612"><st c="3613">. However, because the number of model parameters is finite,
    we always have a finite-dimensional model.</st> <st c="3717">Because of this,
    we are restricting the possible variation in</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4454.png)
    <st c="3779"><st c="3780">that our model can capture</st> <st c="3808">or learn.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3817">An alternative approach is to allow the function to be infinite
    dimensional.</st> <st c="3895">In doing so, we are effectively taking the parameters,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1765.png)<st
    c="3950"><st c="3951">, out of the problem.</st> <st c="3973">Instead, we just
    have the function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="4009"><st c="4063">, which describes</st> <st c="4081">a surface over</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4443.png)<st
    c="4096"><st c="4097">. We still want to put some restrictions on the possible
    shapes</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)
    <st c="4161"><st c="4215">can take.</st> <st c="4225">For example, we may want
    it to be smoothly varying and not have spiky up and down sections to it.</st>
    <st c="4323">In other words, we want to draw or sample</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)
    <st c="4365"><st c="4419">from some space of (reasonably behaved) functions that
    we specify.</st> <st c="4486">We do this by putting a prior on</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="4519"><st c="4573">. Once we have a prior on</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="4599"><st c="4653">, we can again use it to calculate a posterior probability
    for the function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="4730"><st c="4784">, given the</st> <st c="4795">data.</st> <st c="4802">This
    is</st> **<st c="4810">Bayesian</st>** **<st c="4819">non-parametric modeling</st>**<st
    c="4842">.</st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4843">We still have parameters</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="4868">The name</st> *<st c="4878">Bayesian non-parametric modeling</st>*
    <st c="4910">can be confusing when you first encounter it.</st> <st c="4957">We
    still have some</st> <st c="4975">parameters in the overall calculation that are
    part of our prediction algorithm.</st> <st c="5057">It would be difficult to run
    a machine learning algorithm that had no parameters whatsoever.</st> <st c="5150">We
    still have parameters in our algorithm, and we will even optimize those parameters
    on a training set.</st> <st c="5255">However, those parameters relate to a different
    part of the overall calculation – typically, they are part of the mathematical
    specification of the prior on the function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="5426"><st c="5480">. The word “non-parametric” in Bayesian non-parametric modeling
    refers to the fact that we have no explicit parameters in the relationship that
    links the response,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4465.png)<st
    c="5644"><st c="5645">, to the</st> <st c="5654">features,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1560.png)<st
    c="5664"><st c="5668">.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5669">The different types of non-parametric Bayesian methods</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="5724">The idea we have introduced is a very general one.</st> <st c="5776">It
    is the idea that instead of specifying a model function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="5836"><st c="5890">, by specifying some fixed parametric form (with parameters,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1765.png)<st
    c="5951"><st c="5952">) and putting a</st> <st c="5967">prior on the function
    parameters, instead we introduce flexibility into the choice of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)
    <st c="6054"><st c="6108">by drawing it from some space of functions by putting
    a prior directly on</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/3951.png)<st
    c="6182"><st c="6183">. Because of the generality of the idea, it can be applied
    in many ways.</st> <st c="6256">Two of the most common types of priors we put
    on</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)
    <st c="6305"><st c="6359">come from</st> <st c="6369">the following:</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6383">Gaussian Processes</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="6402">Dirichlet Processes</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="6422">These are the priors we shall focus on in this chapter, with most
    of our focus being on</st> **<st c="6511">Gaussian process regression</st>** <st
    c="6538">(</st>**<st c="6540">GPR</st>**<st c="6543">) since that is a</st> <st
    c="6562">very intuitive way to understand the power of</st> <st c="6607">non-parametric</st>
    <st c="6623">Bayesian methods.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6640">The pros and cons of non-parametric Bayesian methods</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="6693">Non-parametric Bayesian methods specify how the function,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="6752"><st c="6806">, in</st> *<st c="6811">Eq.</st> <st c="6815">1</st>* <st
    c="6816">can vary.</st> <st c="6827">Since</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)
    <st c="6833"><st c="6887">controls the distribution of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="6916"><st c="6939">, this</st> <st c="6946">means that non-parametric Bayesian
    methods focus on how the data,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="7012"><st c="7035">, varies from one data point to another</st> <st c="7075">given
    changes in the feature vector,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4443.png)<st
    c="7112"><st c="7113">, from one data point to another.</st> <st c="7147">This
    makes Bayesian non-parametric models about smoothing or interpolating between
    the training data observations.</st> <st c="7262">This also makes Bayesian non-parametric
    models extremely flexible and relatively easy to use.</st> <st c="7356">Instead,
    using the parametric approach in</st> *<st c="7398">Eq.</st> <st c="7402">1</st>*<st
    c="7403">, we’d probably have to bake domain-specific knowledge into the model,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4477.png)<st
    c="7474"><st c="7475">. In contrast, in non-parametric Bayesian models, we’d typically
    just get the data and let the model interpolate between the observations for us.</st>
    <st c="7621">Non-parametric Bayesian models are very</st> <st c="7661">data driven.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7673">The downside to that is, i) Non-parametric Bayesian models do not
    scale well with increases in</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)<st
    c="7769"><st c="7770">, the size of the training dataset, since they are directly
    using all the training data to make the predictions, ii) non-parametric Bayesian
    models are less able to extrapolate compared to say a parametric model whose mathematical
    form has been constructed using explicit domain knowledge.</st> <st c="8060">Finally,
    as with all Bayesian methods, there is some art and subjectivity in specifying
    the choice of</st> <st c="8162">any priors.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8173">That’s the introduction complete, so, let’s summarize what we</st>
    <st c="8236">have learned.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8249">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="8265">In this section, we have learned</st> <st c="8299">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8313">Non-parametric Bayesian methods focus on specifying a modeling
    function as coming from a prior distribution over functions, instead of being
    of a fixed</st> <st c="8466">mathematical form</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8483">Non-parametric Bayesian models still</st> <st c="8521">have parameters</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8536">Having learned in general what non-parametric Bayesian methods
    are, in the next section, we’ll look at a specific method, that</st> <st c="8664">of
    GPR.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8671">Gaussian processes</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="8690">We’re going to look in detail at a</st> <st c="8725">specific non-parametric
    Bayesian method that makes use of GPs.</st> <st c="8789">As the name suggests,
    GPs involve a Gaussian distribution.</st> <st c="8848">In fact, the Gaussian distribution
    is the prior that we put on our function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="8925"><st c="8979">. This makes GPs widely used in non-parametric Bayesian
    methods.</st> <st c="9044">We can use them for constructing both regression models
    and classification models.</st> <st c="9127">To keep this chapter short, we’ll
    only illustrate GPR, but many of the concepts and ideas are the same for both
    GPR and GP classification.</st> <st c="9266">Personally, I also find GPR the easiest
    non-parametric Bayesian method to understand, so it is a good place</st> <st c="9374">to
    start.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9383">To start we need to set up our model.</st> <st c="9422">We’ll model
    our observations,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4465.png)<st
    c="9452"><st c="9453">,</st> <st c="9455">as follows:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mfenced
    separators=""><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>N</mml:mi></mml:math>](img/4481.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="9498">Eq.</st> <st c="9502">2</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9503">For a fixed choice of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="9525"><st c="9579">,</st> *<st c="9581">Eq.</st> <st c="9585">2</st>* <st c="9586">says
    that our observation,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4465.png)<st
    c="9614"><st c="9615">, is a Gaussian noise corrupted version of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/126.png)<st
    c="9658">![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4485.png)<st
    c="9712"><st c="9714">. We will also assume that the noise values,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4486.png)<st
    c="9759"><st c="9760">, from different observations are independent of</st> <st
    c="9809">each other.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="9820">Eq.</st> <st c="9825">2</st>* <st c="9826">looks like</st> *<st
    c="9838">Eq.</st> <st c="9842">1</st>* <st c="9843">but we don’t have any parameters,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1765.png)<st
    c="9878"><st c="9879">, because we’re not specifying a fixed parametric form for</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/2990.png)<st
    c="9938"><st c="9939">. All we’re saying in</st> *<st c="9961">Eq.</st> <st c="9965">2</st>*
    <st c="9966">is that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/2990.png)
    <st c="9975"><st c="9976">is some function.</st> <st c="9995">If we were to calculate
    the joint distribution of the observations,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4490.png)<st
    c="10063"><st c="10078">, it would be boring, as it is a multivariate Gaussian
    with a diagonal covariance matrix.</st> <st c="10168">It would be</st> <st c="10180">the
    following:</st></st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mfenced
    separators=""><mml:mrow><mml:munder><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4491.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="10217">Eq.</st> <st c="10221">3</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10222">In</st> *<st c="10225">Eq.</st> <st c="10229">3</st>*<st c="10230">,
    the vector,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4492.png)<st
    c="10244"><st c="10245">, is given by</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><munder><mi>f</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><mfenced open="(" close=")"><mrow><mi>f</mi><mfenced
    open="(" close=")"><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mn>1</mn></msub></mfenced><mo>,</mo><mi>f</mi><mfenced
    open="(" close=")"><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mn>2</mn></msub></mfenced><mo>,</mo><mo>…</mo><mo>,</mo><mi>f</mi><mfenced
    open="(" close=")"><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mfenced></mrow></mfenced></mrow></mrow></math>](img/4493.png)<st
    c="10259"><st c="10260">. So far, in</st> *<st c="10273">Eq.</st> <st c="10277">3</st>*<st
    c="10278">, we have only considered the variation in the random noise variables,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4494.png)<st
    c="10349"><st c="10350">, when deriving the distribution of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4454.png)<st
    c="10386"><st c="10387">. Now, we</st> <st c="10396">introduce our prior on the
    function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="10434"><st c="10488">. In GPR, we put a GP prior on</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="10519"><st c="10573">. This is denoted by saying</st> <st c="10601">the following:</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:mo> </mml:mo><mml:mi
    mathvariant="script">G</mml:mi><mml:mi mathvariant="script">P</mml:mi><mml:mfenced
    separators=""><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/4498.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="10629">Eq.</st> <st c="10633">4</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10634">What</st> *<st c="10639">Eq.</st> <st c="10643">4</st>* <st c="10644">says
    is that the function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="10672"><st c="10726">, has some distribution.</st> <st c="10751">It is like
    an infinite dimensional random variable.</st> <st c="10803">Its random variation
    is controlled by the function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)
    <st c="10855"><st c="10868">– more on that in</st> <st c="10886">a moment.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10895">In practical terms, what this means is that as we vary the possible
    choice of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="10974"><st c="11028">, the values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4502.png)
    <st c="11044"><st c="11045">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4503.png)
    <st c="11050"><st c="11051">will be correlated.</st> <st c="11072">In fact, the
    value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4504.png)
    <st c="11094"><st c="11095">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4505.png)
    <st c="11100"><st c="11101">will be correlated for any values of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi></mml:math>](img/106.png)
    <st c="11139"><st c="11140">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>j</mml:mi></mml:math>](img/3373.png)<st
    c="11145"><st c="11146">. A</st> <st c="11149">GP prior on</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)
    <st c="11162"><st c="11216">says that</st> **<st c="11226">a priori</st>**<st
    c="11234">:</st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:munder><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mfenced
    separators=""><mml:mrow><mml:munder><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4509.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="11253">Eq.</st> <st c="11257">5</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11258">The</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow></mrow></math>](img/4510.png)<st
    c="11262"><st c="11263">matrix,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4511.png)<st
    c="11271"><st c="11275">, has matrix elements,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>K</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>=</mo><mn>1,2</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>N</mi></mrow></mrow></math>](img/4512.png)<st
    c="11298"><st c="11299">, and these are calculated from the function,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)<st
    c="11345"><st c="11358">, via</st> <st c="11364">the following:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4514.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="11380">Eq.</st> <st c="11384">6</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11385">Now, if we combine the variation of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4492.png)
    <st c="11421"><st c="11422">in</st> *<st c="11426">Eq.</st> <st c="11430">5</st>*
    <st c="11431">with the variation of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4454.png)
    <st c="11454"><st c="11455">in</st> *<st c="11459">Eq.</st> <st c="11463">3</st>*<st
    c="11464">, we get that the overall variation of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4454.png)
    <st c="11503"><st c="11504">is given by</st> <st c="11517">the following:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mfenced
    separators=""><mml:mrow><mml:munder><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>+</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4518.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="11558">Eq.</st> <st c="11562">7</st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="11563">Eq.</st> <st c="11567">7</st>* <st c="11568">gives us the distribution
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4519.png)
    <st c="11598"><st c="11599">once we have incorporated both the variation over
    the random noise variables,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1554.png)<st
    c="11678"><st c="11679">, and the variation over the possible</st> <st c="11717">functions,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="11728"><st c="11782">.</st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11783">Our model for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4522.png)
    <st c="11798"><st c="11799">in</st> *<st c="11803">Eq.</st> <st c="11807">7</st>*
    <st c="11808">is very simple.</st> <st c="11825">It says</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4522.png)
    <st c="11833"><st c="11834">is a multivariate Gaussian with a mean vector of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4524.png)
    <st c="11884"><st c="11885">and covariance matrix,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><munder><munder><mi>K</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mrow></math>](img/4525.png)<st
    c="11909"><st c="11920">. The zero mean vector relates to the 0 in the notation,</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>f</mi><mo>~</mo><mi
    mathvariant="script">G</mi><mi mathvariant="script">P</mi><mfenced open="(" close=")"><mrow><mn>0</mn><mo>,</mo><mi>K</mi></mrow></mfenced></mrow></mrow></math>](img/4526.png)
    <st c="11977"><st c="11989">. It means that our prior expectation for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4527.png)
    <st c="12031"><st c="12032">was zero for any value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4528.png)<st
    c="12059"><st c="12060">, and so once we’ve incorporated the variation over</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="12112"><st c="12166">, we’re assuming that the expected value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4530.png)
    <st c="12210"><st c="12211">is zero.</st> <st c="12221">Without loss of generality,
    we can always mean center our data sample,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>y</mi><mi>N</mi></msub></mrow></mrow></math>](img/4531.png)<st
    c="12292"><st c="12296">, before we start modeling, so that our GP prior in</st>
    *<st c="12348">Eq.</st> <st c="12352">4</st>* <st c="12353">is always appropriate.</st>
    <st c="12377">It is</st> <st c="12383">also easy to generalize the GP prior to
    include a mean function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>μ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4532.png)<st
    c="12448"><st c="12449">, by writing</st> <st c="12462">the following:</st></st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>f</mi><mo>~</mo><mi
    mathvariant="script">G</mi><mi mathvariant="script">P</mi><mfenced open="(" close=")"><mrow><mi>μ</mi><mo>,</mo><mi>K</mi></mrow></mfenced></mrow></mrow></math>](img/4533.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="12489">Eq.</st> <st c="12493">8</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12494">In this case,</st> *<st c="12508">Eq.</st> <st c="12512">7</st>*
    <st c="12513">would become</st> <st c="12527">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder><mo>~</mo><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>l</mi><mfenced
    open="(" close=")"><mrow><munder><mi>μ</mi><mo stretchy="true">_</mo></munder><mo>,</mo><msup><mrow><munder><munder><mi>K</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>+</mo><mi>σ</mi></mrow><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mfenced></mrow></mrow></math>](img/4534.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="12566">Eq.</st> <st c="12570">9</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12571">where the vector,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4535.png)<st
    c="12589"><st c="12590">, is given by</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><munder><mi>μ</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><mfenced open="(" close=")"><mrow><mi>μ</mi><mfenced
    open="(" close=")"><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mn>1</mn></msub></mfenced><mo>,</mo><mi>μ</mi><mfenced
    open="(" close=")"><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mn>2</mn></msub></mfenced><mo>,</mo><mo>…</mo><mo>,</mo><mi>μ</mi><mfenced
    open="(" close=")"><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mfenced></mrow></mfenced></mrow></mrow></math>](img/4536.png)<st
    c="12604"><st c="12605">. For simplicity of illustration, from now on we’re going
    to assume</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>μ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>](img/4537.png)
    <st c="12673"><st c="12682">for any</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4443.png)
    <st c="12690"><st c="12691">(i.e., our target values,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4465.png)<st
    c="12718"><st c="12719">, have expectations</st> <st c="12739">of zero).</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12748">The kernel function</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="12768">To model our data using</st> <st c="12792">a (zero mean) GP, we
    just need to know the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/4540.png)
    <st c="12845"><st c="12846">and the choice of function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)<st
    c="12875"><st c="12888">. What is this function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)<st
    c="12913"><st c="12926">? What does it do?</st> <st c="12945">From</st> *<st c="12950">Eq.</st>
    <st c="12954">7</st>*<st c="12955">, we can see that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)
    <st c="12973"><st c="12986">determines the covariance between</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4544.png)
    <st c="13020"><st c="13021">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/4545.png)<st
    c="13026"><st c="13027">. A high covariance value means we expect that</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4544.png)
    <st c="13074"><st c="13075">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/4545.png)
    <st c="13080"><st c="13081">vary in a similar way (i.e., they are similar).</st>
    <st c="13130">That similarity is quantified</st> <st c="13160">by</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/4548.png)<st
    c="13163"><st c="13164">.</st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13165">In</st> [*<st c="13169">Chapter 12</st>*](B19496_12.xhtml#_idTextAnchor612)<st
    c="13179">, we encountered functions that measure the similarity between feature
    vectors,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1560.png)
    <st c="13259"><st c="13263">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/4550.png)<st
    c="13267"><st c="13271">. They were called</st> **<st c="13290">kernel functions</st>**<st
    c="13306">. That is what the function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/4551.png)<st
    c="13335"><st c="13336">, is.</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/4551.png)
    <st c="13342"><st c="13343">is a kernel function.</st> <st c="13366">Unsurprisingly,
    the</st> <st c="13385">types of kernel functions that we use in GPR are the same
    as we used in kernel methods in</st> **<st c="13476">Chapter 12</st>**<st c="13486">.
    Common choices for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/4553.png)
    <st c="13507"><st c="13508">are</st> <st c="13512">the RBF (squared-exponential)
    kernel, dot-product kernels, and the</st> **<st c="13580">Matérn kernel</st>**<st
    c="13593">.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13594">When we use an RBF kernel, we are using a function,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)<st
    c="13647"><st c="13660">, of the</st> <st c="13669">following form:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>K</mi><mfenced
    open="(" close=")"><mrow><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>i</mi></msub><mo>,</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>j</mi></msub></mrow></mfenced><mo>=</mo><mi>A</mi><mo>×</mo><mtext>exp</mtext><mfenced
    open="(" close=")"><mrow><mo>−</mo><mfrac><msup><mrow><mo>|</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>−</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>j</mi></msub><mo>|</mo></mrow><mn>2</mn></msup><mrow><mn>2</mn><msup><mi>b</mi><mn>2</mn></msup></mrow></mfrac></mrow></mfenced></mrow></mrow></math>](img/4555.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="13702">Eq.</st> <st c="13706">10</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13708">This is the RBF kernel we encountered in</st> [*<st c="13750">Chapter
    12</st>*](B19496_12.xhtml#_idTextAnchor612) <st c="13760">but with the addition
    of the extra parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi></mml:math>](img/1738.png)<st
    c="13807"><st c="13808">. From this, it should be clear that GPR is not parameter
    free.</st> <st c="13872">If we were to use the RBF kernel in</st> *<st c="13908">Eq.</st>
    <st c="13912">10</st>* <st c="13914">in combination with</st> *<st c="13935">Eq.</st>
    <st c="13939">7</st>*<st c="13940">, then our GPR model has three parameters,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:math>](img/4557.png)<st
    c="13983"><st c="13984">, and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/4540.png)<st
    c="13990"><st c="13991">. But</st> <st c="13997">how do we determine appropriate
    values for those parameters?</st> <st c="14058">By fitting the GPR model to training
    data.</st> <st c="14101">We do</st> <st c="14107">that next.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14117">Fitting GPR models</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="14136">The parameters of our GPR model are</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/4540.png)
    <st c="14173"><st c="14174">and whatever parameters we have in our kernel function,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)<st
    c="14231"><st c="14244">.</st> *<st c="14246">Eq.</st> <st c="14250">7</st>* <st
    c="14251">tells us the</st> <st c="14265">probability of the data,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4454.png)<st
    c="14290"><st c="14291">, given the parameters.</st> <st c="14315">We can view
    this as a likelihood.</st> <st c="14349">It is the marginal likelihood because
    we have integrated over all the possible functions,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="14439"><st c="14493">, coming from our GP prior.</st> <st c="14521">We can
    use the marginal likelihood to estimate the GPR model parameters by maximum likelihood.</st>
    <st c="14616">Alternatively, if we put priors on those GPR parameters, we can</st>
    <st c="14679">estimate them via</st> **<st c="14698">maximum a posteriori</st>**
    <st c="14718">(</st>**<st c="14720">MAP</st>**<st c="14723">) estimation, or even
    sample directly from the Bayesian posterior of the model parameters – see</st>
    [*<st c="14820">Chapter 5</st>*](B19496_05.xhtml#_idTextAnchor261) <st c="14829">for
    a reminder of these techniques.</st> <st c="14866">For simplicity, we’ll stick
    to maximum likelihood estimation.</st> <st c="14928">We’ll write out the log-likelihood
    explicitly</st> <st c="14974">as follow</st><st c="14983">s:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>log-likelihood</mtext><mtext>=</mtext><mo>−</mo><mfrac><mi>N</mi><mn>2</mn></mfrac><mi>log</mi><mn>2</mn><mi>π</mi><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>log</mi><mtext>det</mtext><mfenced
    open="(" close=")"><mrow><munder><munder><mi>K</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mfenced><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><msup><mfenced
    open="(" close=")"><mrow><munder><munder><mi>K</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mfenced><mrow><mo>−</mo><mn>1</mn></mrow></msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/4563.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="15051">Eq.</st> <st c="15055">11</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15057">Fitting our GPR model by maximum likelihood requires us to calculate
    derivatives of the log-likelihood in</st> *<st c="15164">Eq.</st> <st c="15168">11</st>*
    <st c="15170">with respect to</st> <st c="15187">its parameters.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15202">In practice, there are several existing Python packages for doing
    GPR, so we don’t have to do the differentiation and equation solving ourselves,
    however, instead, we just specify what sort of kernel function we want to use
    in our model.</st> <st c="15441">In a moment, we’ll demonstrate GPR using the</st>
    `<st c="15486">scikit-learn</st>` <st c="15498">package, but before we do, we’ll
    explain how we use a fitted GPR model to</st> <st c="15573">make predictions.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15590">Prediction using GPR models</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="15618">Okay, so imagine we’ve fitted our</st> <st c="15652">GPR model
    using maximum likelihood to obtain optimal values for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/4564.png)
    <st c="15717"><st c="15718">and the kernel function parameters.</st> <st c="15755">How
    do we use the fitted model to make predictions?</st> <st c="15807">We just use</st>
    *<st c="15819">Eq.</st> <st c="15823">7</st>* <st c="15824">again.</st> <st c="15832">Imagine
    we</st> <st c="15842">are trying to make a prediction of the value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)
    <st c="15891"><st c="15901">at the point,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4566.png)<st
    c="15915"><st c="15921">. We’ll denote that value by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4567.png)
    <st c="15950"><st c="15951">. By extending the derivation behind</st> *<st c="15988">Eq.</st>
    <st c="15992">7</st>*<st c="15993">, we can derive the joint distribution of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4568.png)
    <st c="16035"><st c="16036">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4454.png)<st
    c="16041"><st c="16042">. In doing so, we get</st> <st c="16064">the follow</st><st
    c="16074">ing:</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfenced
    open="(" close=")"><mrow><munder><mi>y</mi><mo stretchy="true">_</mo></munder><mo>,</mo><msub><mi>y</mi><mi
    mathvariant="normal">*</mi></msub></mrow></mfenced><mo>~</mo><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>l</mi><mfenced
    open="(" close=")"><mrow><munder><mn>0</mn><mo stretchy="true">_</mo></munder><mo>,</mo><msub><munder><munder><mi>K</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mrow><mi>N</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></mfenced></mrow></mrow></math>](img/4570.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="16117">Eq.</st> <st c="16121">12</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16123">In</st> *<st c="16127">Eq.</st> <st c="16131">12</st>*<st c="16133">,
    we are modeling</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math>](img/4571.png)
    <st c="16151"><st c="16152">data points, whilst in</st> *<st c="16176">Eq.</st>
    <st c="16180">7</st>*<st c="16181">, we were modeling</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/686.png)<st
    c="16200"><st c="16201">. In</st> *<st c="16206">Eq.</st> <st c="16210">12</st>*<st
    c="16212">, the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    separators="|"><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math>](img/4573.png)
    <st c="16218"><st c="16219">matrix,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4574.png)
    <st c="16228"><st c="16231">is of the following</st> <st c="16251">block form:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><munder><munder><mi>K</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub><mo>=</mo><mfenced
    open="(" close=")"><mtable columnspacing="0.8000em" columnwidth="auto auto" columnalign="center
    center" rowspacing="1.0000ex" rowalign="baseline baseline"><mtr><mtd><munder><munder><mi>K</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder></mtd><mtd><msub><munder><mi>k</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub></mtd></mtr><mtr><mtd><msubsup><munder><mi>k</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi><mi mathvariant="normal">⊤</mi></msubsup></mtd><mtd><mrow><mi>K</mi><mfenced
    open="(" close=")"><mrow><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi
    mathvariant="normal">*</mi></msub><mo>,</mo><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi
    mathvariant="normal">*</mi></msub></mrow></mfenced></mrow></mtd></mtr></mtable></mfenced></mrow></mrow></math>](img/4575.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="16264">Eq.</st> <st c="16268">13</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16270">The matrix,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4576.png)<st
    c="16283"><st c="16286">, is the same as in</st> *<st c="16306">Eq.</st> <st c="16310">7</st>*<st
    c="16311">. The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)<st
    c="16317"><st c="16318">-dimensional column vector,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4578.png)<st
    c="16346"><st c="16347">, is given by</st> <st c="16361">the following:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msubsup><munder><mi>k</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi><mi mathvariant="normal">⊤</mi></msubsup><mo>=</mo><mfenced
    open="(" close=")"><mrow><mi>K</mi><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mn>1</mn></msub><mo>,</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub></mrow></mfenced><mo>,</mo><mi>K</mi><mfenced
    open="(" close=")"><mrow><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mn>2</mn></msub><mo>,</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub></mrow></mfenced><mo>,</mo><mo>…</mo><mo>,</mo><mi>K</mi><mfenced
    open="(" close=")"><mrow><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>N</mi></msub><mo>,</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub></mrow></mfenced></mrow></mfenced></mrow></mrow></math>](img/4579.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="16377">Eq.</st> <st c="16381">14</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16383">To calculate the joint distribution in</st> *<st c="16423">Eq.</st>
    <st c="16427">12</st>*<st c="16429">, all we need is our kernel function and the
    value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/4540.png)<st
    c="16483"><st c="16484">. From the Gaussian distribution in</st> *<st c="16520">Eq.</st>
    <st c="16524">12</st>*<st c="16526">, we can calculate the conditional density,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4581.png)<st
    c="16570"><st c="16580">, by applying Bayes’ theorem.</st> <st c="16610">For a
    Gaussian distribution, it is a straightforward calculation, so we’ll just give
    the</st> <st c="16699">following res</st><st c="16712">ult:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><msub><mi>y</mi><mi
    mathvariant="normal">*</mi></msub><mo>|</mo><munder><mi>y</mi><mo stretchy="true">_</mo></munder><mo>~</mo><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>l</mi><mfenced
    open="(" close=")"><mrow><msubsup><munder><mi>k</mi><mo stretchy="true">_</mo></munder><mi
    mathvariant="normal">*</mi><mi mathvariant="normal">⊤</mi></msubsup><msup><mfenced
    open="(" close=")"><mrow><munder><munder><mi>K</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mfenced><mrow><mo>−</mo><mn>1</mn></mrow></msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder><mo>,</mo><mi>K</mi><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub><mo>,</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub></mrow></mfenced><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><mo>−</mo><msubsup><munder><mi>k</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi><mi mathvariant="normal">⊤</mi></msubsup><msup><mfenced
    open="(" close=")"><mrow><munder><munder><mi>K</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mfenced><mrow><mo>−</mo><mn>1</mn></mrow></msup><msub><munder><mi>k</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub></mrow></mfenced></mrow></mrow></mrow></math>](img/4582.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="16774">Eq.</st> <st c="16778">15</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16780">What you’ll notice from</st> *<st c="16805">Eq.</st> <st c="16809">15</st>*
    <st c="16811">is that we get a probabilistic prediction.</st> <st c="16855">We
    get a distribution.</st> <st c="16878">We can calculate the expected value of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4583.png)<st
    c="16917"><st c="16918">. For the univariate Gaussian distribution in</st> *<st
    c="16964">Eq.</st> <st c="16968">15</st>*<st c="16970">, we can easily read off
    the expectation value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4568.png)<st
    c="17020"><st c="17021">. It is</st> <st c="17029">as foll</st><st c="17036">ows:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="double-struck">E</mi><mfenced open="(" close=")"><mrow><msub><mi>y</mi><mi
    mathvariant="normal">*</mi></msub><mo>|</mo><munder><mi>y</mi><mo stretchy="true">_</mo></munder></mrow></mfenced><mo>=</mo><msubsup><munder><mi>k</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi><mi mathvariant="normal">⊤</mi></msubsup><msup><mfenced
    open="(" close=")"><mrow><munder><munder><mi>K</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mfenced><mrow><mo>−</mo><mn>1</mn></mrow></msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/4585.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="17064">Eq.</st> <st c="17068">16</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17070">Let’s unpack</st> *<st c="17084">Eq.</st> <st c="17088">16</st>*
    <st c="17090">in more</st> <st c="17099">detail.</st> <st c="17107">We can re-write
    it</st> <st c="17126">as fol</st><st c="17132">lows:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="double-struck">E</mi><mfenced open="(" close=")"><mrow><msub><mi>y</mi><mi
    mathvariant="normal">*</mi></msub><mo>|</mo><munder><mi>y</mi><mo stretchy="true">_</mo></munder></mrow></mfenced><mo>=</mo><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>w</mi><mi>j</mi></msub><msub><mi>y</mi><mi>j</mi></msub></mrow></mrow><mo>,</mo><msub><mi>w</mi><mi>j</mi></msub><mo>=</mo><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>K</mi><mfenced
    open="(" close=")"><mrow><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>i</mi></msub><mo>,</mo><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msub></mrow></mfenced></mrow></mrow><msubsup><mfenced
    open="(" close=")"><mrow><munder><munder><mi>K</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><mi>σ</mi><mn>2</mn></msup><msub><munder><munder><mi>I</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi>N</mi></msub></mrow></mfenced><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup></mrow></mrow></math>](img/4586.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="17156">Eq.</st> <st c="17160">17</st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="17162">Eq.</st> <st c="17167">17</st>* <st c="17169">says the prediction
    is</st> <st c="17192">given by a weighted sum of the observations,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4587.png)<st
    c="17238"><st c="17251">. This is what we meant when we said non-parametric Bayesian
    methods are very data driven and smooth the training data.</st> <st c="17371">Our
    model of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4588.png)
    <st c="17384"><st c="17385">is calculated directly from all the training data,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4589.png)<st
    c="17437"><st c="17446">,, not from a fixed mathematical form whose parameters
    are determined by the data.</st> <st c="17529">This is what we mean by a non-parametric
    method.</st> <st c="17578">The downside to this is that as the amount of data
    increases, the computational cost of calculating</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4590.png)
    <st c="17678"><st c="17687">increases.</st> <st c="17698">The matrix inversions
    of the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:math>](img/4591.png)
    <st c="17727"><st c="17728">matrices in</st> *<st c="17741">Eq.</st> <st c="17745">17</st>*
    <st c="17747">scale as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>O</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math>](img/4592.png)
    <st c="17757"><st c="17758">and so become very computationally costly as</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="17804"><st c="17805">becomes large.</st></st></st></st></st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17819">If we return to the prediction distribution,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4594.png)<st
    c="17865"><st c="17868">, in</st> *<st c="17873">Eq.</st> <st c="17877">15</st>*<st
    c="17879">, we see that not only do we get the expectation of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4595.png)
    <st c="17931"><st c="17932">, but we also get the standard deviation.</st> <st
    c="17974">That means we automatically get an estimate of the uncertainty around
    the prediction.</st> <st c="18060">We can easily calculate 95% confidence intervals
    around the expectation value in</st> *<st c="18141">Eq.</st> <st c="18145">16</st>*<st
    c="18147">. So, GPR not only makes predictions of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msub></mml:math>](img/4596.png)<st
    c="18187"><st c="18188">, it also tells us when it is confident about</st> <st
    c="18234">those predictions.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18252">To see the power of GPR in action, we’ll now look at a</st> <st
    c="18308">code example.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18321">GPR code example</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="18338">The following code example can</st> <st c="18369">be found in
    the</st> `<st c="18386">Code_Examples_Chap14.ipynb</st>` <st c="18412">Jupyter
    Notebook in the</st> <st c="18437">GitHub repository.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18455">Since GPR is a commonly used technique, it is available in the</st>
    `<st c="18519">scikit-learn</st>` <st c="18531">package.</st> <st c="18541">We’ll
    use the</st> `<st c="18555">sklearn.gaussian_process.GaussianProcessRegressor</st>`
    <st c="18604">class to do our GPR.</st> <st c="18626">For our code example, we’re
    going to use a one-dimensional feature,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="18694"><st c="18695">. The training data can be found in the</st> `<st c="18735">gp_data.csv</st>`
    <st c="18746">file in the</st> `<st c="18759">Data</st>` <st c="18763">directory
    of the GitHub repository.</st> <st c="18800">The training data has two columns,
    the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="18839"><st c="18840">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="18845"><st c="18868">values.</st> <st c="18876">There are 25 data points
    in the training</st> <st c="18917">data.</st> <st c="18923">First, we’ll read
    in</st> <st c="18944">the data:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: <st c="19191">We then take a quick look at</st> <st c="19221">the data:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: <st c="19263">This then gives the</st> <st c="19284">following output:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: <st c="19401">It is also instructive to plot the training data, which we</st>
    <st c="19461">do next:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: <st c="19628">This gives us</st> <st c="19643">t</st><st c="19644">he plot in</st>
    *<st c="19655">Figure 14</st>**<st c="19664">.1</st>*<st c="19666">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_14_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="19710">Figure 14.1: Plot of training data for GPR</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19752">There is clearly some relationship between</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="19796"><st c="19797">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="19802"><st c="19825">, but it is not obvious what it is.</st> <st c="19861">It
    could be a linear relationship, but it could be more complex.</st> <st c="19926">This
    is a good example of where to apply GPR.</st> <st c="19972">We will use an RBF
    kernel for our GPR; that is, we choose our function</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)
    <st c="20043"><st c="20056">to be</st> <st c="20062">the following:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>K</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mtext>exp</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math>](img/4603.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="20113">Eq.</st> <st c="20117">18</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20119">We can do this using the RBF constructor from the</st> `<st c="20170">sklearn.gaussian_process.kernels</st>`
    <st c="20202">module.</st> <st c="20211">We’ll set</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/4604.png)
    <st c="20221"><st c="20222">but</st> `<st c="20227">scikit-learn</st>` <st c="20239">will
    optimize this value for us.</st> <st c="20273">The value,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/4604.png)<st
    c="20284"><st c="20285">, is just an initial guess.</st> <st c="20313">We specify
    the RBF kernel using the</st> <st c="20349">following syntax:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="20366">1*RBF(length_scale=1.0)</st>`'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20390">The prefactor of 1 in front</st> <st c="20419">of the RBF constructor
    call introduces an extra parameter into our RBF kernel, in this case, it is the
    parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi></mml:math>](img/2905.png)<st
    c="20533"><st c="20534">, and we have initialized its value to 1\.</st> <st c="20576">Again,</st>
    `<st c="20583">scikit-learn</st>` <st c="20595">will optimize this parameter for
    us by fitting to the data.</st> <st c="20656">We must also add a noise component
    to our kernel.</st> <st c="20706">This is the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4607.png)
    <st c="20718"><st c="20721">part of the overall covariance matrix in</st> *<st
    c="20762">Eq.</st> <st c="20766">7</st>*<st c="20767">. We do this by adding a</st>
    `<st c="20792">scikit-learn</st>` `<st c="20804">WhiteKernel</st>` <st c="20816">object
    to our RBF kernel.</st> <st c="20843">Again,</st> `<st c="20850">scikit-learn</st>`
    <st c="20862">will optimize the noise level parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/1764.png)<st
    c="20904"><st c="20905">, when it fits to</st> <st c="20923">the data:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: <st c="21033">So, now that we have our kernel, we can create a GPR object by
    calling the</st> `<st c="21109">GaussianProcessRegressor</st>` <st c="21133">constructor,
    passing in the kernel object we</st> <st c="21179">already created:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: <st c="21353">Now; we can optimize the parameters;</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:math>](img/4609.png)<st
    c="21391"><st c="21397">, by calling the fit method of</st> <st c="21428">the</st>
    `<st c="21432">Gaussian</st>` **<st c="21440">ProcessRegressor</st>** <st c="21457">object,
    into which we pass our</st> <st c="21489">training data:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: <st c="21601">Let’s look at the optimized parameters.</st> <st c="21642">We
    can do this by just looking at the</st> <st c="21680">kernel object:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: <st c="21774">This gives us the</st> <st c="21793">following output:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: <st c="21876">We can see the optimized</st> <st c="21901">kernel is of the</st>
    <st c="21919">following form:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>K</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>9.24</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>exp</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mo>×</mml:mo><mml:mn>0.412</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>8.33</mml:mn><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/4610.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="21991">Eq.</st> <st c="21995">19</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21997">This means</st> `<st c="22009">scikit-learn</st>` <st c="22021">has
    chosen the optimal values as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>9.24</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/4611.png)<st
    c="22055"><st c="22056">,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0.412</mml:mn></mml:math>](img/4612.png)<st
    c="22058"><st c="22059">, and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>8.33</mml:mn></mml:math>](img/4613.png)<st
    c="22065"><st c="22066">. Having got our optimal</st> `<st c="22091">GaussianProcessRegressor</st>`
    <st c="22115">object, let’s use it to make some predictions.</st> <st c="22163">We
    will make predictions for regularly spaced values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="22219"><st c="22220">between the maximum and minimum values of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="22263"><st c="22264">seen in the training dataset.</st> <st c="22295">The
    predictions are the expectation values of the response (target) variable at each
    of the prediction points.</st> <st c="22406">We’ll also get the standard deviations
    of the response variable at the prediction points so we can plot confidence intervals
    around</st> <st c="22538">our predictions:</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: <st c="22823">We’ll also calculate the true expectation values of the response
    variable at each of the prediction points.</st> <st c="22932">I can do this because
    I know the formula used to create the true expectation values of the response
    variable in the</st> <st c="23048">training data:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: <st c="23182">Finally, we plot the</st> <st c="23203">predictions (estimates
    of the expectation values), the 95% confidence intervals, the true expectation
    values, and the training</st> <st c="23331">data points:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: <st c="23829">This gives us</st> <st c="23843">the plot in</st> *<st c="23856">Figure
    14</st>**<st c="23865">.2</st>*<st c="23867">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2: Plot of GPR predictions](img/B19496_14_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="23989">Figure 14.2: Plot of GPR predictions</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24025">We can see from</st> *<st c="24042">Figure 14</st>**<st c="24051">.2</st>*
    <st c="24053">that the estimated expectation value (the mean prediction) follows
    the true expectation value reasonably closely, including the oscillatory pattern
    present.</st> <st c="24211">Despite</st> <st c="24218">having only 25 data points
    in the training set, we have been able to uncover a lot of the true structure
    present.</st> <st c="24333">In contrast, had we used a parametric model, we probably
    would have fitted a linear or quadratic relationship to the data, causing us to
    miss this</st> <st c="24480">oscillatory structure.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24502">Where the estimated expectation value deviates from the true expectation
    value, it is where there are fewer training data points, but in these regions,
    the 95% confidence interval is also relatively wider, telling us that the estimated
    expectation value may be less accurate in these regions.</st> <st c="24796">This
    again highlights the data-driven nature of non-parametric Bayesian methods; where
    we have lots of observations, our predictions will be accurate, and where we have
    fewer observations, our predictions will be</st> <st c="25009">less accurate.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25023">That has been a lengthy code example and a lengthy section overall,
    so, let’s wrap up the section by summarizing what we</st> <st c="25145">have learned.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25158">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="25174">In this section, we have learned</st> <st c="25208">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25222">A GP is specified by a kernel (covariance) function and a</st>
    <st c="25281">mean function.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="25295">The kernel function of a GP</st> <st c="25324">has parameters.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="25339">In GPR, our model is the mean function of the response (target)
    variable and we put a GP prior on that</st> <st c="25443">mean function.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="25457">In GPR, we can calculate the marginal likelihood of the data conditional
    on the kernel</st> <st c="25545">function parameters.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="25565">In GPR, we can fit the kernel function parameters to the training
    data by maximizing the</st> <st c="25655">marginal likelihood.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="25675">We make predictions in GPR by calculating the expectation value
    and variance of the response variable conditional on the training data.</st> <st
    c="25812">The conditional expectation value can be expressed as a weighted sum
    of the</st> <st c="25888">training data.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="25902">We can use the</st> `<st c="25918">scikit-learn</st>` <st c="25930">package
    to</st> <st c="25942">do GPR.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="25949">Having learned about GPs</st> <st c="25975">and GPR, in the next
    section, we will learn about another type of stochastic process used in Bayesian
    non-parametric analysis.</st> <st c="26102">We will learn</st> <st c="26116">about
    DPs.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26126">Dirichlet processes</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="26146">GPs are not the only type of process used in non-parametric Bayesian
    methods, although they are possibly the</st> <st c="26256">most used.</st> <st
    c="26267">In this section, we will introduce another type of stochastic process,
    the DP.</st> <st c="26346">As with GPs, we will use DPs as priors for functions
    that we want to make</st> <st c="26420">inferences about.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26437">Since the last section was a lengthy one with a lengthy code example,
    we will keep this section short and only give a high-level view</st> <st c="26572">of
    DPs.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26579">How do DPs differ from GPs?</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="26607">As you might have guessed, we use a</st> <st c="26643">DP as a
    prior on a function.</st> <st c="26673">However, GPs already did</st> <st c="26697">that
    for us, so how do DPs differ from GPs?</st> <st c="26742">When we used GPs in
    GPR, the GP provided a prior for a generic function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="26815"><st c="26869">. There were no restrictions on the type of function,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="26923"><st c="26977">, could be.</st> <st c="26989">Sometimes, we will want
    to model a particular type of function.</st> <st c="27053">For example, we might
    need to build a model of a probability distribution.</st> <st c="27128">In this
    case, we use a DP to construct</st> <st c="27167">our prior.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27177">Let’s make that more explicit.</st> <st c="27209">I want to</st>
    <st c="27218">model a probability distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)<st
    c="27253"><st c="27254">, of a discrete random variable,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2035.png)<st
    c="27287"><st c="27288">. A DP</st> <st c="27294">provides me with a prior for</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4620.png)<st
    c="27324"><st c="27325">. Sampling from the DP gives me an instance of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4620.png)<st
    c="27372"><st c="27373">. We can think of a DP as a distribution</st> <st c="27414">of
    distributions.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27431">The DP notation</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="27447">A DP is specified by two quantities,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="27485"><st c="27486">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="27491"><st c="27492">, so we</st> <st c="27500">denote the DP using the notation,</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>D</mi><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>α</mi><mo>,</mo><mi>H</mi></mrow></mfenced></mrow></mrow></math>](img/4624.png)<st
    c="27534"><st c="27543">. If our distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="27566"><st c="27567">, has a DP prior, then we wr</st><st c="27595">ite</st>
    <st c="27600">the following:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>F</mi><mo>~</mo><mi>D</mi><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>α</mi><mo>,</mo><mi>H</mi></mrow></mfenced></mrow></mrow></math>](img/4626.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="27627">Eq.</st> <st c="27631">20</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27633">But what do</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)
    <st c="27646"><st c="27647">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)
    <st c="27652"><st c="27653">mean?</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)
    <st c="27660"><st c="27661">is usually referred to as the</st> **<st c="27692">base
    distribution</st>**<st c="27709">. You can think of it as the distribution</st>
    <st c="27750">about which the DP is centered.</st> <st c="27783">In fact,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)
    <st c="27792"><st c="27793">is the expectation value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)
    <st c="27822"><st c="27823">in</st> *<st c="27827">Eq.</st> <st c="27831">20</st>*<st
    c="27833">, meaning</st> <st c="27843">the following:</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>H</mml:mi></mml:math>](img/4632.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="27859">Eq.</st> <st c="27863">21</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27865">So,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4633.png)
    <st c="27870"><st c="27871">is the distribution function we expect to get on average
    if we were to repeatedly generate functions,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="27974"><st c="27975">, according to</st> *<st c="27990">Eq.</st> <st c="27994">20</st>*<st
    c="27996">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27997">The base distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="28021"><st c="28022">, can be discrete or continuous.</st> <st c="28055">It
    is up to us to specify and will depend on what sort of problem we are modeling.</st>
    <st c="28138">You may also see the notation,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/4636.png)<st
    c="28169"><st c="28170">, used for the</st> <st c="28185">base distribution.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28203">The value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="28217"><st c="28218">controls how much variation (dispersion) we get around
    the base distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="28297"><st c="28298">. A larger value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)
    <st c="28318"><st c="28319">means we will get less variation around the base distribution
    and so the functions,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)<st
    c="28404"><st c="28405">, generated will be very close to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4641.png)<st
    c="28439"><st c="28440">. In the limit,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4642.png)<st
    c="28456"><st c="28457">, we would effectively only get the base distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4643.png)<st
    c="28512"><st c="28513">, if we were to sample</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="28536"><st c="28537">according to</st> *<st c="28551">Eq.</st> <st c="28555">20</st>*<st
    c="28557">. In contrast, a low value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/4645.png)
    <st c="28587"><st c="28588">means we get a lot of potential variation away from
    the base distribution, and instances of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="28681"><st c="28682">sampled according to</st> *<st c="28704">Eq.</st>
    <st c="28708">20</st>* <st c="28710">could look very different from</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4633.png)<st
    c="28742"><st c="28743">. You can see that the higher the value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/4648.png)<st
    c="28786"><st c="28787">, the more concentrated</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="28811"><st c="28812">will</st> <st c="28818">be around</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="28828"><st c="28829">. Hence,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)
    <st c="28838"><st c="28839">is known as the</st> **<st c="28856">concentration
    parameter</st>**<st c="28879">.</st></st></st></st></st></st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28880">We have defined a DP, but how do we begin to use one?</st> <st
    c="28935">How do we use it as a prior for our distribution</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="28984"><st c="28985">? To answer</st> <st c="28996">these questions, we must
    first learn how to sample from</st> <st c="29053">a DP.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29058">Sampling a function from a DP</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="29088">We’ve specified that distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="29124"><st c="29125">, is distributed according to</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mi>D</mi><mi>P</mi><mo>(</mo><mi>α</mi><mo>,</mo><mi>H</mi><mo>)</mo></mrow></mrow></mrow></math>](img/4654.png)<st
    c="29155"><st c="29164">, but how do we generate an</st> <st c="29192">example
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="29203"><st c="29204">? How do we sample from the DP?</st> <st c="29236">One</st>
    <st c="29239">way to do that is to make use of what is known as the</st> **<st
    c="29294">stick-breaking algorithm</st>**<st c="29318">, which is</st> <st c="29329">given
    here:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29340">Draw values,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:math>](img/4656.png)<st
    c="29354"><st c="29373">,</st> <st c="29375">from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="29380"><st c="29381">.</st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="29382">Draw values,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:math>](img/4658.png)<st
    c="29396"><st c="29414">, from the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>Beta</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/4659.png)
    <st c="29425"><st c="29436">distribution.</st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="29449">Set weight,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4660.png)<st
    c="29462"><st c="29463">, and calculate subsequent</st> <st c="29490">weights,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/4661.png)<st
    c="29499"><st c="29500">.</st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="29501">Construct the probability distribution that has probability mass,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4662.png)<st
    c="29568"><st c="29569">, at</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/105.png)<st
    c="29574"><st c="29575">. This is our sampled distribution,</st>![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi></mrow></math>](img/4664.png)<st
    c="29610"><st c="29612">, for our discrete random</st> <st c="29638">variable,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2022.png)<st
    c="29648"><st c="29649">.</st></st></st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="29650">From the last step, we can see that our sampled distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="29713"><st c="29714">,</st> <st c="29716">is given</st> <st c="29725">the following:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>](img/4667.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="29741">Eq.</st> <st c="29745">22</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29747">The Kronecker delta-function notation,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>](img/4668.png)<st
    c="29787"><st c="29788">, represents a unit probability mass located at</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4669.png)<st
    c="29836"><st c="29837">, and so is 1 if</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="29854"><st c="29855">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4671.png)
    <st c="29860"><st c="29861">are the same value and zero otherwise.</st> <st c="29901">The
    expression on the right-hand side of</st> *<st c="29942">Eq.</st> <st c="29946">22</st>*
    <st c="29948">gives the mathematical equation for the probability that our discrete
    random variable,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2022.png)<st
    c="30036"><st c="30037">, has a value</st> <st c="30051">of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="30054"><st c="30055">.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30056">The distribution in</st> *<st c="30077">Eq.</st> <st c="30081">22</st>*
    <st c="30083">is like the empirical distribution function that we met in</st>
    [*<st c="30143">Chapter 2</st>*](B19496_02.xhtml#_idTextAnchor061)<st c="30152">.
    You’ll also notice that it is discrete.</st> <st c="30194">The distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="30212"><st c="30213">, in</st> *<st c="30218">Eq.</st> <st c="30222">22</st>*
    <st c="30224">is a sum of point masses.</st> <st c="30251">The only possible values
    we can get for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2022.png)
    <st c="30291"><st c="30292">from the distribution in</st> *<st c="30318">Eq.</st>
    <st c="30322">22</st>* <st c="30324">are the distinct values,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo></mml:math>](img/4676.png)
    <st c="30350"><st c="30366">Wait?</st> <st c="30372">We get a discrete distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="30404"><st c="30405">, even if our base distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="30438"><st c="30439">, was continuous?</st> <st c="30457">Yes.</st> <st c="30462">However,
    we still have</st> <st c="30485">the following:</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>H</mml:mi></mml:math>](img/4632.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="30501">Eq.</st> <st c="30505">23</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30507">This means that if we generated lots and lots of discrete distributions
    according to the recipe in</st> *<st c="30607">Eq.</st> <st c="30611">22</st>*<st
    c="30613">, the average of all those discrete distributions would be close to</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4641.png)
    <st c="30681"><st c="30682">even if no single one of the discrete distributions
    looked that much</st> <st c="30752">like</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="30757"><st c="30758">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30759">You will also have noticed by now that the sampled distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4620.png)<st
    c="30825"><st c="30826">, in</st> *<st c="30831">Eq.</st> <st c="30835">22</st>*
    <st c="30837">consists of an infinite number of point masses.</st> <st c="30886">This
    makes the stick-breaking algorithm more of a useful theoretical construction</st>
    <st c="30967">than a practical tool.</st> <st c="30991">However, the weights,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4683.png)<st
    c="31013"><st c="31014">, in</st> *<st c="31019">Eq.</st> <st c="31023">22</st>*
    <st c="31025">get smaller and smaller as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi></mml:math>](img/102.png)
    <st c="31053"><st c="31054">increases, and so the contributions to</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="31094"><st c="31095">from larger values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi></mml:math>](img/106.png)
    <st c="31118"><st c="31119">become insignificant.</st> <st c="31142">So-called</st>
    **<st c="31152">truncated stick-breaking</st>** <st c="31176">(</st>**<st c="31178">TSB</st>**<st
    c="31181">) algorithms</st> <st c="31194">take advantage of this and replace the
    representation of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="31252"><st c="31253">in</st> *<st c="31257">Eq.</st> <st c="31261">22</st>*
    <st c="31263">with a finite sum of</st> <st c="31285">point masses.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31298">In practice, we will often be more interested in generating a
    finite sample of observations from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="31396"><st c="31397">, not sampling</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="31412"><st c="31413">itself.</st> <st c="31422">Fortunately, there are
    algorithms for generating a finite sample of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="31490"><st c="31491">values from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="31504"><st c="31505">when</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>F</mi><mo>~</mo><mi>D</mi><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>α</mi><mo>,</mo><mi>H</mi></mrow></mfenced></mrow></mrow></math>](img/4692.png)<st
    c="31511"><st c="31522">. We will meet one in a moment.</st> <st c="31554">For
    now, we’ll keep with the view that</st> *<st c="31593">Eq.</st> <st c="31597">22</st>*
    <st c="31599">is a useful way of representing what a sample from a DP</st> <st
    c="31656">looks like.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31667">Generating a sample of data from a DP</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="31705">In the recipe that led to</st> *<st c="31732">Eq.</st> <st c="31736">22</st>*<st
    c="31738">, we sampled an instance of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="31766"><st c="31767">from its DP prior,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/4694.png)<st
    c="31787"><st c="31796">. The distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4620.png)<st
    c="31816"><st c="31817">, is the distribution from which we consider our data
    variable,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2022.png)<st
    c="31881"><st c="31882">, to be drawn.</st> <st c="31897">However, when</st> <st
    c="31911">we used GP priors in GPR, we focused on the data by integrating over
    all possible functions coming from the prior to get the marginal joint distribution
    of the random variables,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4697.png)<st
    c="32089"><st c="32103">, that represent the data.</st> <st c="32130">Can we do
    the same thing here?</st> <st c="32161">Can we sample an instance of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4698.png)
    <st c="32190"><st c="32205">from the marginal joint distribution once we have
    marginalized over all values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="32287"><st c="32288">from the</st> <st c="32298">DP prior?</st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32307">The answer is yes.</st> <st c="32327">In principle, one approach
    would be to just sample lots of instances of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="32399"><st c="32400">using the recipe in</st> *<st c="32421">Eq.</st> <st
    c="32425">22</st>*<st c="32427">, and from each instance of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)<st
    c="32455"><st c="32456">, sample some values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2035.png)<st
    c="32480"><st c="32481">. However, there is a more efficient and practical algorithm
    to sample from the marginal distribution of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2022.png)<st
    c="32586"><st c="32587">. The algorithm to do so goes by the unusual name of the</st>
    **<st c="32644">Chinese restaurant process</st>**<st c="32670">. It is also called
    the</st> **<st c="32694">infinite Pólya urn sampling process</st>**<st c="32729">.
    To sample</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="32741"><st c="32742">values from the marginal joint distribution, the Chinese
    restaurant process is defined</st> <st c="32830">as follows:</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32841">Draw a value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/3234.png)
    <st c="32858"><st c="32859">from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="32864"><st c="32865">.</st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="32866">For</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi><mml:mo>≥</mml:mo><mml:mn>2</mml:mn></mml:math>](img/4707.png)<st
    c="32871"><st c="32872">, with probability,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/4708.png)<st
    c="32892"><st c="32902">, draw a value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/105.png)
    <st c="32920"><st c="32921">from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="32927"><st c="32928">, and</st> <st c="32934">with probability,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/4711.png)<st
    c="32951"><st c="32967">, draw a value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/105.png)
    <st c="32985"><st c="32986">from the empirical distribution function formed from
    the</st> <st c="33044">values,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4713.png)<st
    c="33052"><st c="33067">.</st></st></st></st></st></st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="33068">Set</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math>](img/4714.png)
    <st c="33073"><st c="33074">and repeat</st> *<st c="33086">Step 2</st>* <st c="33092">whilst</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:math>](img/4715.png)<st
    c="33100"><st c="33101">.</st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="33102">Bayesian non-parametric inference using a DP</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="33147">So far, we have learned a lot about DPs</st> <st c="33188">and
    how to sample from them, but we haven’t discussed how we combine them with observations
    (i.e., real data).</st> <st c="33299">We haven’t discussed how we would use a
    DP prior in a data science algorithm.</st> <st c="33377">Since we want to use
    a DP prior to help us model how our data is distributed, there are two kinds of
    tasks we are</st> <st c="33491">interested in:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33505">Modeling the probability distribution of a discrete</st> <st c="33558">random
    variable</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="33573">Modeling the probability density of a continuous</st> <st c="33623">random
    variable</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="33638">We’ll now look at each of those tasks</st> <st c="33677">in turn.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33685">Using a DP to model a probability distribution</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="33732">To show how to combine a DP prior on a</st> <st c="33772">discrete
    probability distribution with our data, we first need to set up our data</st>
    <st c="33854">science problem.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33870">We have a set of observations,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math>](img/4716.png)
    <st c="33902"><st c="33915">that we model as being samples of i.i.d.</st> <st
    c="33956">random variables,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4717.png)<st
    c="33974"><st c="33988">, which all have a probability distribution,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi><mml:mo>.</mml:mo></mml:math>](img/4718.png)
    <st c="34033"><st c="34034">This means we write</st> <st c="34055">the following:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><msub><mi>X</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>X</mi><mi>N</mi></msub><mo>~</mo><mi>F</mi></mrow></mrow></math>](img/4719.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="34071">Eq.</st> <st c="34075">24</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34077">Since we are taking a non-parametric Bayesian approach to our
    modeling, we say the distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="34175"><st c="34176">, is distributed</st> **<st c="34193">a pr</st><st c="34197">iori</st>**
    <st c="34202">according to a</st> <st c="34218">DP prior:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>F</mi><mo>~</mo><mi>D</mi><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>α</mi><mo>,</mo><mi>H</mi></mrow></mfenced></mrow></mrow></math>](img/4721.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="34240">Eq.</st> <st c="34244">25</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34246">What we now want is the</st> <st c="34270">posterior distribution
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="34297"><st c="34298">conditional on the values,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4723.png)<st
    c="34326"><st c="34335">. For a DP prior of the form in</st> *<st c="34367">Eq.</st>
    <st c="34371">25</st>*<st c="34373">, it turns out that the posterior of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)
    <st c="34410"><st c="34411">is very simple.</st> <st c="34428">It is also a DP.</st>
    <st c="34445">The posterior of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="34462"><st c="34463">is given by</st> <st c="34476">the following:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>F</mi><mo>(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>)</mo><mo>|</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>x</mi><mi>N</mi></msub><mo>~</mo><mi>D</mi><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>α</mi><mo>+</mo><mi>N</mi><mo>,</mo><mfrac><mi>α</mi><mrow><mi>α</mi><mo>+</mo><mi>N</mi></mrow></mfrac><mi>H</mi><mo>+</mo><mfrac><mi>N</mi><mrow><mi>α</mi><mo>+</mo><mi>N</mi></mrow></mfrac><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>δ</mi><mrow><mi>x</mi><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub></mrow></mrow></mfenced></mrow></mrow></mrow></math>](img/4726.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="34534">Eq.</st> <st c="34538">26</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34540">We’ll take a moment to delve into</st> *<st c="34575">Eq.</st>
    <st c="34579">26</st>*<st c="34581">. From the form of the DP in</st> *<st c="34610">Eq.</st>
    <st c="34614">26</st>*<st c="34616">, we can see that the base distribution is
    of the</st> <st c="34666">following form:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Posterior</mtext><mtext>Base</mtext><mtext>Distribution</mtext><mtext>=</mtext><mfrac><mi>α</mi><mrow><mi>α</mi><mo>+</mo><mi>N</mi></mrow></mfrac><mi>H</mi><mo>+</mo><mfrac><mi>N</mi><mrow><mi>α</mi><mo>+</mo><mi>N</mi></mrow></mfrac><mtext>Empirical</mtext><mtext>Distribution</mtext></mrow></mrow></math>](img/4727.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="34746">Eq.</st> <st c="34750">27</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34752">The posterior base distribution is a weighted sum of our original
    prior base distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="34844"><st c="34845">, and the empirical distribution formed from the data.</st>
    <st c="34900">As the amount of data increases and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="34936"><st c="34937">becomes very much bigger than</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/4730.png)<st
    c="34968"><st c="34969">, the posterior base distribution tends toward the empirical
    distribution function.</st> <st c="35053">But as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="35060"><st c="35061">grows, so does the posterior concentration parameter,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi></mml:math>](img/4732.png)<st
    c="35116"><st c="35122">. Overall, this means that as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="35152"><st c="35153">becomes big, the posterior distribution of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="35197"><st c="35198">becomes concentrated around the empirical distribution
    (i.e., our posterior says</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="35280"><st c="35281">is effectively just the empirical distribution).</st>
    <st c="35331">In contrast, at small</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)
    <st c="35353"><st c="35354">or when</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="35363"><st c="35364">is still comparable to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="35388"><st c="35389">, the posterior distribution of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="35421"><st c="35422">will show some variation about a posterior base distribution
    that is still a mix of the original base distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4643.png)<st
    c="35539"><st c="35540">, and the empirical distribution function.</st> <st c="35583">This
    is the usual Bayesian analysis phenomenon.</st> <st c="35631">When we have lots
    of data, our inferences are driven by the data, but when we have limited amounts
    of data, our inferences are still affected by our prior.</st> <st c="35787">From
    this, we also get an idea of how to set a suitable value for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)<st
    c="35853"><st c="35854">. It should be the amount of data above which we want
    the data to dominate</st> <st c="35929">our inferences.</st></st></st></st></st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="35944">Eq.</st> <st c="35949">26</st>* <st c="35951">tells us that
    the posterior distribution of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="35996"><st c="35997">, conditional on the data, is a DP, but how does that
    help us in practical terms?</st> <st c="36079">How can we use it to make inferences
    from the data?</st> <st c="36131">Well, we already know how to generate samples
    from a DP using the Chinese restaurant process algorithm.</st> <st c="36235">If
    we use a TSB algorithm, we can generate an example distribution from the posterior
    DP.</st> <st c="36325">This means we can generate instances of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="36365"><st c="36366">that are compatible with the training data, and we
    can generate new samples of data compatible with the training data.</st> *<st
    c="36486">Q2</st>* <st c="36488">in the exercises at the end of the chapter is
    designed to illustrate this aspect of</st> <st c="36572">using DPs</st> <st c="36583">in
    practice.</st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36595">Using a DP to model a probability density</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="36637">Because the sampled distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="36672"><st c="36673">, generated in</st> *<st c="36688">Eq.</st> <st c="36692">22</st>*
    <st c="36694">is a discrete distribution, it means that a DP is not directly a
    good choice for a prior of a probability density.</st> <st c="36810">If we want
    to use non-parametric Bayesian</st> <st c="36852">methods to model probability
    density functions, we need a different approach.</st> <st c="36930">Fortunately,
    we can do so with only a small modification.</st> <st c="36988">We do so by modeling
    the probability density as a mixture model.</st> <st c="37053">We use a mixture
    of parametric density functions of a specific form, but we put a DP prior on the
    discrete distribution from which we get the parameters of the</st> <st c="37212">mixture
    component densities.</st> <st c="37242">This is called a</st> **<st c="37259">Dirichlet
    process</st>** **<st c="37277">mixture</st>** <st c="37284">(</st>**<st c="37286">DPM</st>**<st
    c="37289">).</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37292">If we want to model a set of observations,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4745.png)<st
    c="37336"><st c="37349">, using a DPM, we again consider the observations to be
    drawn from random variables,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4717.png)<st
    c="37434"><st c="37448">. We then model those random variables by writing</st>
    <st c="37498">the following:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>X</mi><mi>i</mi></msub><mo>~</mo><mi>f</mi><mfenced
    open="(" close=")"><msub><munder><mi>θ</mi><mo stretchy="true">_</mo></munder><mi>i</mi></msub></mfenced><mi>i</mi><mo>=</mo><mn>1,2</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>N</mi></mrow></mrow></math>](img/4747.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><munder><mi>θ</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>~</mo><mi>F</mi><mi>i</mi><mo>=</mo><mn>1,2</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>N</mi></mrow></mrow></math>](img/4748.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>F</mi><mo>~</mo><mi>D</mi><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>α</mi><mo>,</mo><mi>H</mi></mrow></mfenced></mrow></mrow></math>](img/4626.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="37527">Eq.</st> <st c="37531">28</st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="37533">Eq.</st> <st c="37538">28</st>* <st c="37540">says that our
    random variable,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4750.png)<st
    c="37572"><st c="37573">, is distributed according to some parametric distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/126.png)<st
    c="37633"><st c="37687">. For example,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/3905.png)
    <st c="37702"><st c="37703">might be a Gaussian.</st> <st c="37725">The distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi></mml:math>](img/3905.png)<st
    c="37743"><st c="37744">, is characterized by parameters,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4754.png)<st
    c="37778"><st c="37781">, for example, its mean and variance.</st> <st c="37819">The
    vector of parameters,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4755.png)<st
    c="37845"><st c="37848">, is distributed according to the distribution,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)<st
    c="37896"><st c="37897">, and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4620.png)
    <st c="37903"><st c="37904">is drawn from a DP.</st> <st c="37925">Since</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4620.png)
    <st c="37931"><st c="37932">is drawn from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/4759.png)<st
    c="37947"><st c="37955">, the stick-breaking representation in</st> *<st c="37994">Eq.</st>
    <st c="37998">22</st>* <st c="38000">tells us that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1981.png)
    <st c="38015"><st c="38018">could be any of an infinite number of different possible
    values corresponding to the point masses from which</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)
    <st c="38127"><st c="38128">is made.</st> <st c="38138">This means we are modeling
    our data using an infinite mixture distribution.</st> <st c="38214">DPMs are</st>
    <st c="38223">infinite mixtures.</st></st></st></st></st></st></st></st></st></st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38241">We can also see from</st> *<st c="38263">Eq.</st> <st c="38267">28</st>*
    <st c="38269">that since the parameter vectors,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4755.png)<st
    c="38304"><st c="38307">, for the different values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi></mml:math>](img/102.png)
    <st c="38337"><st c="38338">are all drawn from the same discrete distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="38390"><st c="38391">, we will inevitably get some parameter vectors,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4754.png)<st
    c="38440"><st c="38443">, having</st> <st c="38451">the same value as each other.</st>
    <st c="38482">The number,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi></mml:math>](img/589.png)<st
    c="38494"><st c="38507">, of distinct parameter vectors, will be less than</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)<st
    c="38558"><st c="38559">. In effect, the model in</st> *<st c="38585">Eq.</st>
    <st c="38589">28</st>* <st c="38591">naturally clusters the data points,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4768.png)<st
    c="38628"><st c="38643">, into</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>K</mml:mi><mml:mo><</mml:mo><mml:mi>N</mml:mi></mml:math>](img/4769.png)
    <st c="38650"><st c="38651">clusters.</st> <st c="38662">Clustering of data is
    one of the main applications</st> <st c="38713">of DPMs.</st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38721">In practice, when using DPMs, we use advanced computational techniques
    such as</st> **<st c="38801">Gibbs sampling</st>** <st c="38815">to sample from
    the posterior.</st> <st c="38846">To</st> <st c="38848">implement this numerically,
    we must address the fact that our distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4625.png)<st
    c="38925"><st c="38926">, has an infinite number of point masses.</st> <st c="38968">As
    before, we can truncate the sum in</st> *<st c="39006">Eq.</st> <st c="39010">22</st>*
    <st c="39012">to only include a large but finite number of point mass contributions.</st>
    <st c="39084">It turns out that the number of clusters needed to model</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/686.png)
    <st c="39141"><st c="39142">data points only grows logarithmically with</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/686.png)<st
    c="39187"><st c="39188">, so that the cap on the number of point masses we include
    in</st> *<st c="39250">Eq.</st> <st c="39254">22</st>* <st c="39256">also only
    needs to grow logarithmically with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)<st
    c="39302"><st c="39303">. This means that truncating the sum in</st> *<st c="39343">Eq.</st>
    <st c="39347">22</st>* <st c="39349">at some large but tractable value is a valid
    heuristic approach for</st> <st c="39418">using DPMs.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39429">That concludes this short section on DPs and how they are used
    in non-parametric Bayesian models, so, let’s recap what we have learned in this
    section and this</st> <st c="39590">chapter overall.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39606">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="39622">In this section, we have learned</st> <st c="39656">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39670">How a DP is defined in terms of its base distribution,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="39726"><st c="39727">, and its concentration</st> <st c="39751">parameter,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="39763">How a DP can be used as prior for a</st> <st c="39799">probability
    distribution</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="39823">How to sample a distribution from</st> <st c="39858">a DP</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="39862">How to sample data from the marginal distribution induced by a</st>
    <st c="39926">DP prior</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="39934">How the posterior of a distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)<st
    c="39972"><st c="39973">, conditional on the observed data, is also a DP if its
    prior was</st> <st c="40039">a DP</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40043">How a DPM can be used to model a probability</st> <st c="40089">density
    function</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40105">Summary</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="40113">This chapter was about non-parametric Bayesian methods.</st> <st
    c="40170">Non-parametric methods are extremely useful because we don’t have to
    make parametric assumptions about the form of the relationship between our features
    and the target variable.</st> <st c="40348">That has required us to learn a new
    approach to probabilistic modeling and new concepts.</st> <st c="40437">Those
    new concepts include</st> <st c="40464">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40478">Non-parametric Bayesian methods focus on specifying a modeling
    function as coming from a prior distribution</st> <st c="40587">over functions</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40601">The priors in non-parametric Bayesian methods are stochastic processes
    such as GPs</st> <st c="40685">or DPs</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40691">A GP is specified by a kernel (covariance) function and a</st>
    <st c="40750">mean function</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40763">In GPR, our model is the mean function of the response (target)
    variable and we put a GP prior on that</st> <st c="40867">mean function</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40880">In GPR, we can fit the kernel function parameters to the training
    data by maximizing the</st> <st c="40970">marginal likelihood</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="40989">A DP is defined in terms of its base distribution,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi></mml:math>](img/4073.png)<st
    c="41041"><st c="41042">, and its concentration</st> <st c="41066">parameter,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2473.png)</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="41078">A DP can be used as a prior for a</st> <st c="41112">probability
    distribution</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="41136">The posterior of a distribution,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi></mml:math>](img/4618.png)<st
    c="41170"><st c="41171">, conditional on the observed data, is also a DP if its
    prior was</st> <st c="41237">a DP</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="41241">A DPM can be used to model a probability</st> <st c="41283">density
    function</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="41299">Our next and final chapter is another advanced topic connected
    to probability distributions.</st> <st c="41393">It is about</st> **<st c="41405">random
    matrices</st>**<st c="41420">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="41421">Exercises</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="41431">The following is a series of exercises.</st> <st c="41472">Answers
    to all the exercises are given in the</st> `<st c="41518">Answers_to_Exercises_Chap14.ipynb</st>`
    <st c="41551">Jupyter Notebook in the</st> <st c="41576">GitHub repository:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="41594">The Matérn kernel function,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>k</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder><mml:mo>,</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/4780.png)<st
    c="41623"><st c="41624">, can be thought of as a generalization of the RBF kernel.</st>
    <st c="41683">It is of the</st> <st c="41696">following form:</st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>k</mi><mfenced
    open="(" close=")"><mrow><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mo>,</mo><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder></mrow></mfenced><mo>=</mo><mfrac><mn>1</mn><mrow><mi
    mathvariant="normal">Γ</mi><mfenced open="(" close=")"><mi>ν</mi></mfenced><msup><mn>2</mn><mrow><mi
    mathvariant="normal">ν</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow></mfrac><msup><mfenced
    open="(" close=")"><mrow><mfrac><msqrt><mrow><mn>2</mn><mi>ν</mi></mrow></msqrt><mi>b</mi></mfrac><mo>|</mo><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mo>−</mo><munder><mi>y</mi><mo stretchy="true">_</mo></munder><mo>|</mo></mrow></mfenced><mi
    mathvariant="normal">ν</mi></msup><msub><mi>K</mi><mi mathvariant="normal">ν</mi></msub><mfenced
    open="(" close=")"><mrow><mfrac><msqrt><mrow><mn>2</mn><mi>ν</mi></mrow></msqrt><mi
    mathvariant="normal">b</mi></mfrac><mo>|</mo><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mo>−</mo><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder><mo>|</mo></mrow></mfenced></mrow></mrow></math>](img/4781.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="41713">Eq.</st> <st c="41717">29</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/4782.png)
    <st c="41719"><st c="41726">is the modified Bessel function of the second kind.</st>
    <st c="41778">The Matérn kernel is specified by the parameters,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/4783.png)
    <st c="41828"><st c="41829">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>b</mml:mi></mml:math>](img/4784.png)<st
    c="41834"><st c="41835">. The lengthscale parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>b</mml:mi></mml:math>](img/4784.png)<st
    c="41864"><st c="41865">, plays a similar role to the length-scale parameter,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>b</mml:mi></mml:math>](img/4786.png)<st
    c="41919"><st c="41920">, in the RBF kernel in</st> *<st c="41943">Eq.</st> <st
    c="41947">10</st>*<st c="41949">. The parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/4787.png)<st
    c="41966"><st c="41967">, controls how smooth the functions are when we use a
    GP prior with a Matérn</st> <st c="42044">covariance kernel.</st></st></st></st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42062">Using the data from the code example in the main text and a Matérn
    kernel with the default value,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:math>](img/4788.png)<st
    c="42161"><st c="42162">, fit a GPR model to the data.</st> <st c="42193">Make
    predictions for a range of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="42225"><st c="42226">values.</st> <st c="42235">Note that for the Matérn
    kernel, the parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/4790.png)<st
    c="42283"><st c="42284">, is not optimized by the</st> `<st c="42310">scikit-learn</st>`
    <st c="42322">fitting process, so if you instantiate a Matérn kernel object with</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:math>](img/4791.png)<st
    c="42390"><st c="42391">, the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>ν</mml:mi></mml:math>](img/4787.png)
    <st c="42406"><st c="42407">will remain fixed at 1.5\.</st> <st c="42434">The</st>
    `<st c="42438">scikit-learn</st>` <st c="42450">fitting will, however, optimize
    the length-scale parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>b</mml:mi></mml:math>](img/286.png)<st
    c="42511"><st c="42512">, of the</st> <st c="42521">Matérn kernel.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42535">2.</st> <st c="42539">We have a discrete random variable,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2035.png)<st
    c="42575"><st c="42576">, that takes integer values 1 to 9\.</st> <st c="42612">Fifty
    observations of the random variable are given in the</st> `<st c="42671">benford_data.csv</st>`
    <st c="42687">file in the</st> `<st c="42700">Data</st>` <st c="42704">directory
    of the GitHub repository.</st> <st c="42741">Use the DP posterior given in</st>
    *<st c="42771">Eq.</st> <st c="42775">26</st>* <st c="42777">and the Chinese restaurant
    process to sample six datasets, each of 100 data points, from the posterior DP
    and compare each of them by plotting each of them against the empirical distribution
    calculated from the data.</st> <st c="42995">You should use a concentration parameter,
    using a concentration parameter,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math>](img/4795.png)<st
    c="43070"><st c="43071">, and the base distribution of the</st> <st c="43106">following
    form:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Prob</mtext><mfenced
    open="(" close=")"><mrow><mi>X</mi><mo>=</mo><mi>x</mi></mrow></mfenced><mo>=</mo><msub><mi>log</mi><mn>10</mn></msub><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>+</mo><mfrac><mn>1</mn><mi>x</mi></mfrac></mrow></mfenced></mrow></mrow></math>](img/4796.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="43144">Eq.</st> <st c="43148">30</st>
  prefs: []
  type: TYPE_NORMAL
