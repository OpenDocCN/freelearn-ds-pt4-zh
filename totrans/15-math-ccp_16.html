<html><head></head><body>
		<div id="_idContainer5181">
			<h1 id="_idParaDest-405" class="chapter-number"><a id="_idTextAnchor739"/><st c="0">1</st><a id="_idTextAnchor740"/><st c="2">5</st></h1>
			<h1 id="_idParaDest-406"><a id="_idTextAnchor741"/><st c="3">Random Matrices</st></h1>
			<p><st c="18">This is our final chapter. </st><st c="46">It is about random matrices. </st><st c="75">That name may sound esoteric or even abstract. </st><st c="122">It suggests that random matrices may not be a very useful thing to learn about. </st><st c="202">However, by now, you’ll be very used to the idea that randomness is everywhere in data science. </st><st c="298">Dealing with matrices is a core part of data science as well, so maybe a random matrix is not so esoteric after all. </st><st c="415">This chapter will emphasize the idea that random matrices can be found everywhere in data science and are a useful way of representing large-scale interacting systems. </st><st c="583">That means that we must become familiar with the tools used to study random matrices. </st><st c="669">We will only very briefly introduce the main results and concepts connected to random matrices, so this will be a short chapter. </st><st c="798">In it, we will cover the </st><span class="No-Break"><st c="823">following topics:</st></span></p>
			<ul>
				<li><em class="italic"><st c="840">What is a random matrix</st></em><st c="864">: In this section, we introduce the basic idea of what a random matrix is and why they are common in </st><span class="No-Break"><st c="966">data science</st></span></li>
				<li><em class="italic"><st c="978">Using random matrices to represent interactions in large-scale systems</st></em><st c="1049">: In this section, we introduce the idea that large random matrices are a natural way to represent and model large-scale </st><span class="No-Break"><st c="1171">interacting systems</st></span></li>
				<li><em class="italic"><st c="1190">Universal behavior of large random matrices</st></em><st c="1234">: In this section, we show how large random matrices start to behave in a similar way to </st><span class="No-Break"><st c="1324">each other</st></span></li>
				<li><em class="italic"><st c="1334">Random matrices and high-dimensional covariance matrices</st></em><st c="1391">: In this section, we show how universal behavior is also seen in covariance matrices, which are a core part of statistical and machine learning models, and where we also learn how random matrix theory is used to understand the behavior of large </st><span class="No-Break"><st c="1638">neural networks</st></span></li>
			</ul>
			<h1 id="_idParaDest-407"><a id="_idTextAnchor742"/><st c="1653">Technical requirements</st></h1>
			<p><st c="1676">There are no code examples in this chapter, but Jupyter notebook-based answers to the exercises at the end of the chapter can be found at </st><a href="https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter15"><st c="1815">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter15</st></a><st c="1919">. To run the Jupyter notebook, you will need a full Python installation, including the </st><span class="No-Break"><st c="2006">following packages:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="2025">numpy</st></strong><st c="2031"> (&gt;= </st><span class="No-Break"><st c="2036">1.24.3)</st></span></li>
				<li><span class="No-Break"><strong class="source-inline"><st c="2043">matplotlib</st></strong></span><span class="No-Break"><st c="2054"> (&gt;=3.7.2)</st></span></li>
			</ul>
			<h1 id="_idParaDest-408"><a id="_idTextAnchor743"/><st c="2064">What is a random matrix?</st></h1>
			<p><st c="2089">A random matrix</st><a id="_idIndexMarker1185"/><st c="2105"> sounds like it is some esoteric mathematical object – the sort of thing that is studied by mathematicians for fun but is of no practical use. </st><st c="2248">Why should you care about random matrices as a </st><span class="No-Break"><st c="2295">data scientist?</st></span></p>
			<p><st c="2310">As a data scientist, you have already been working with matrices. </st><st c="2377">You know that they are useful. </st><st c="2408">You know that a matrix is made up of matrix elements and that those elements are often formed from data. </st><st c="2513">By now, you’re also most likely used to the idea that data has a random component, so a matrix formed from data must also have random matrix elements. </st><st c="2664">This is what a random matrix is. </st><st c="2697">A random matrix is just a matrix whose elements are drawn from a distribution. </st><strong class="bold"><st c="2776">Random Matrix Theory</st></strong><st c="2796"> (</st><strong class="bold"><st c="2798">RMT</st></strong><st c="2801">) is the</st><a id="_idIndexMarker1186"/><st c="2810"> study of the properties of </st><span class="No-Break"><st c="2838">random matrices.</st></span></p>
			<p><st c="2854">Usually, in RMT, the matrix elements are</st><a id="_idIndexMarker1187"/><st c="2895"> taken to be </st><strong class="bold"><st c="2908">independent and identically distributed random variables</st></strong><st c="2964"> (</st><strong class="bold"><st c="2966">iid</st></strong><st c="2969">), but recent research in the RMT field has extended this to looking at more structured randomness. </st><st c="3070">Also, early work in the RMT field looked at square, that is, </st><img src="image/726.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:2.464em"/><st c="3131"/><st c="3147">, matrices. </st><st c="3159">In doing so, RMT discovered that as </st><img src="image/1872.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.067em"/><st c="3195"/><st c="3196">, these square random matrices develop some </st><span class="No-Break"><st c="3240">interesting properties.</st></span></p>
			<p><st c="3263">Again, these RMT discoveries may sound esoteric. </st><st c="3313">However, as data scientists, we often work with big data, so we often work with large matrices with a random component. </st><st c="3433">This means that results from the RMT field can be particularly relevant to </st><span class="No-Break"><st c="3508">data science.</st></span></p>
			<p><st c="3521">We have motivated this section by highlighting that as data scientists, we naturally work with large random matrices. </st><st c="3640">However, the original motivation for RMT was to understand large-scale interacting systems. </st><st c="3732">Since interacting systems are also often what we are tasked with analyzing as data scientists, it is instructive to understand this original motivation for RMT. </st><st c="3893">This is what we will do in the next section, but for now, we’ll recap what we have learned </st><span class="No-Break"><st c="3984">so far.</st></span></p>
			<h2 id="_idParaDest-409"><a id="_idTextAnchor744"/><st c="3991">What we learned</st></h2>
			<p><st c="4007">In this section, we learned </st><span class="No-Break"><st c="4036">the following:</st></span></p>
			<ul>
				<li><st c="4050">A random matrix</st><a id="_idIndexMarker1188"/><st c="4066"> is a matrix whose matrix elements are drawn from </st><span class="No-Break"><st c="4116">a distribution.</st></span></li>
				<li><st c="4131">Since data contains a random element, a matrix formed from data can be thought of as a </st><span class="No-Break"><st c="4219">random matrix.</st></span></li>
				<li><st c="4233">RMT is</st><a id="_idIndexMarker1189"/><st c="4240"> the mathematical field that studies </st><span class="No-Break"><st c="4277">random matrices.</st></span></li>
				<li><st c="4293">When random matrices become large in terms of the number of matrix elements that they contain, they develop </st><span class="No-Break"><st c="4402">interesting properties.</st></span></li>
			</ul>
			<p><st c="4425">Having thus learned what a random matrix is at a very basic level, in the next section, we’ll see how they can be used to represent large-scale </st><span class="No-Break"><st c="4570">interacting systems.</st></span></p>
			<h1 id="_idParaDest-410"><a id="_idTextAnchor745"/><st c="4590">Using random matrices to represent interactions in large-scale systems</st></h1>
			<p><st c="4661">In </st><a href="B19496_10.xhtml#_idTextAnchor501"><span class="No-Break"><em class="italic"><st c="4665">Chapter 10</st></em></span></a><st c="4675">, we </st><a id="_idIndexMarker1190"/><st c="4680">encountered the adjacency matrix method for representing a network. </st><st c="4748">A network also represents a set of components, the nodes, and the network edges can be used to represent the pairwise interactions between the nodes. </st><span class="No-Break"><em class="italic"><st c="4898">Figure 15</st></em></span><em class="italic"><st c="4907">.1</st></em><st c="4909"> gives an example of a network and its adjacency </st><span class="No-Break"><st c="4958">matrix representatio</st><a id="_idTextAnchor746"/><st c="4978">n.</st></span></p>
			<div>
				<div id="_idContainer4947" class="IMG---Figure">
					<img src="image/B19496_15_1.jpg" alt="Figure 15.1: Network interactions represented as a matrix"/><st c="4981"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="5085">Figure 15.1: Network interactions represented as a matrix</st></p>
			<p><st c="5142">It is</st><a id="_idIndexMarker1191"/><st c="5148"> natural to use a matrix to represent pairwise interactions between elements of any interacting system and not just between nodes in a network. </st><st c="5292">Some of these systems may be physical, such as particles interacting via some force. </st><st c="5377">They may also be non-physical, where the components of the system do not directly exert forces on each other but may influence each other, such as correlations between the share prices of different companies listed on a </st><span class="No-Break"><st c="5597">stock market.</st></span></p>
			<p><st c="5610">Many of the systems that we study can be large, particularly real physical systems. </st><st c="5695">Therefore, the interactions can be represented by a large matrix. </st><st c="5761">The matrix elements that we use encode the strengths of the pairwise interactions between the components of the system. </st><st c="5881">They can differ in strength, but aside from this, we believe that the interactions are all of the same qualitative type. </st><st c="6002">Consequently, we can consider the interaction strengths as being values sampled from the same distribution. </st><st c="6110">Therefore, the interaction matrix is a large random matrix, and we are using the large random matrix as a way of representing our real system. </st><st c="6253">To study these systems, we need tools that study large random matrices, that is, RMT. </st><st c="6339">Unsurprisingly, RMT has been applied to many different interacting systems in many different fields, including </st><span class="No-Break"><st c="6450">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="6464">Energy levels of large atomic nuclei</st></strong><st c="6501">: This was the original application of RMT and stimulated the early development of RMT as an area of mathematical research. </st><st c="6626">Most of the ideas that we will introduce in the next section were discovered because of this RMT work on </st><span class="No-Break"><st c="6731">heavy nuclei.</st></span></li>
				<li><strong class="bold"><st c="6744">Neuroscience</st></strong><st c="6757">: Large-scale neuronal networks are modeled as pairwise connections, and hence dynamic interactions, between neurons in </st><span class="No-Break"><st c="6878">the brain.</st></span></li>
				<li><strong class="bold"><st c="6888">Finance</st></strong><st c="6896">: Correlations between the daily stock market movements of different stocks are modeled using a large </st><span class="No-Break"><st c="6999">random matrix.</st></span></li>
			</ul>
			<p><st c="7013">Even if a system consists of more than pairwise interactions, it is not uncommon to model it with just pairwise interactions, as a pairwise interacting system is the simplest model of an interacting system we can have. </st><st c="7233">The model interaction strengths in these cases represent effective interactions – they encapsulate the combined effects of the real pairwise interaction, as well as the real 3</st><span class="superscript"><st c="7408">rd</st></span><st c="7411">-order interactions, the real 4</st><span class="superscript"><st c="7443">th</st></span><st c="7446">-order interactions, and so on. </st><st c="7479">Again, this means that we can understand a lot about the behavior of these real systems by looking at the behavior of their random </st><span class="No-Break"><st c="7610">matrix models.</st></span></p>
			<p><st c="7624">Using </st><a id="_idIndexMarker1192"/><st c="7631">RMT to study large-scale interacting systems is particularly insightful, as we find that large random matrices follow universal laws. </st><st c="7765">It is RMT that uncovers those laws. </st><st c="7801">We will introduce this universal behavior in the next section, so for now, let’s recap what we </st><span class="No-Break"><st c="7896">have learned.</st></span></p>
			<h2 id="_idParaDest-411"><a id="_idTextAnchor747"/><st c="7909">What we learned</st></h2>
			<p><st c="7925">In this section, we learned </st><span class="No-Break"><st c="7954">the following:</st></span></p>
			<ul>
				<li><st c="7968">A system with pairwise interactions can be represented as </st><span class="No-Break"><st c="8027">a matrix.</st></span></li>
				<li><st c="8036">A large-scale interacting system can be modeled as a large </st><span class="No-Break"><st c="8096">random matrix.</st></span></li>
				<li><st c="8110">We can use the tools of RMT to study the behavior of large-scale </st><span class="No-Break"><st c="8176">interacting systems.</st></span></li>
			</ul>
			<p><st c="8196">Having learned that many large-scale interacting systems can be modeled as large random matrices and studied using the tools of RMT, in the next section, we will learn about some of the universal laws that large random </st><span class="No-Break"><st c="8416">matrices follow.</st></span></p>
			<h1 id="_idParaDest-412"><a id="_idTextAnchor748"/><st c="8432">Universal behavior of large random matrices</st></h1>
			<p><st c="8476">We have already mentioned that when </st><a id="_idIndexMarker1193"/><st c="8513">random matrices become large, they begin to display some interesting behaviors. </st><st c="8593">However, what do we mean by this and why is it useful to us as </st><span class="No-Break"><st c="8656">data scientists?</st></span></p>
			<p><st c="8672">The interesting behavior that we see is that the statistical properties of their eigen-decompositions or singular-value decompositions become </st><strong class="bold"><st c="8815">universal</st></strong><st c="8824">. By universal, we mean that the same behavior is seen across many different matrices. </st><st c="8911">In the case that we’re going to illustrate, it means that the statistical characteristics of the eigen-decomposition of any large square random matrix are </st><span class="No-Break"><st c="9066">the same.</st></span></p>
			<p><st c="9075">It is worth recalling from </st><a href="B19496_03.xhtml#_idTextAnchor141"><span class="No-Break"><em class="italic"><st c="9103">Chapter 3</st></em></span></a><st c="9112"> that eigen-decompositions of square matrices are an important and flexible way of representing any square matrix. </st><st c="9227">So, universality in parts of the eigen-decomposition of large random matrices also means that calculations and algorithms involving the matrices will have universal aspects to them. </st><st c="9409">It won’t matter which matrix </st><a id="_idIndexMarker1194"/><st c="9438">we have, we will get the same result for certain aspects of </st><span class="No-Break"><st c="9498">the calculation.</st></span></p>
			<p><st c="9514">By now, you’re probably curious to see what this universal behavior in the eigen-decomposition of large random matrices is in more detail, so we’ll illustrate it with a numerical example. </st><st c="9703">We’ll illustrate what is known as the </st><strong class="bold"><st c="9741">Wigner </st></strong><span class="No-Break"><strong class="bold"><st c="9748">semicircle law</st></strong></span><span class="No-Break"><st c="9762">.</st></span></p>
			<h2 id="_idParaDest-413"><a id="_idTextAnchor749"/><st c="9763">The Wigner semicircle law</st></h2>
			<p><st c="9789">Matrix </st><img src="image/4799.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.189em"/><st c="9797"/><st c="9800"> is a </st><img src="image/4800.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.866em"/><st c="9805"/><st c="9806"> symmetric</st><a id="_idIndexMarker1195"/><st c="9816"> random matrix that I have generated. </st><st c="9854">It has been created from matrix </st><img src="image/4801.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:0.993em"/><st c="9886"/><st c="9888"> using the </st><span class="No-Break"><st c="9898">following equation:</st></span></p>
			<p><img src="image/4802.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.437em;height:1.401em;width:7.144em"/><st c="9917"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="9919">Eq.1</st></p>
			<p><st c="9923">The </st><img src="image/4803.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.009em"/><st c="9928"/><st c="9930"> matrix is a </st><img src="image/4804.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.946em"/><st c="9942"/><st c="9943"> random matrix. </st><st c="9959">All of its matrix elements are i.i.d. </st><st c="9997">and drawn from the standard normal distribution, </st><img src="image/4805.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0,1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.851em;width:2.735em"/><st c="10046"/><st c="10047">. The calculation in </st><em class="italic"><st c="10068">Eq.1</st></em><st c="10072"> ensures that the </st><img src="image/4806.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.379em"/><st c="10090"/><st c="10092"> matrix is symmetric, even though </st><img src="image/4801.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:0.993em"/><st c="10125"/> <span class="No-Break"><st c="10127">isn’t.</st></span></p>
			<p><st c="10133">Matrix </st><img src="image/4808.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.193em"/><st c="10141"/><st c="10144"> is also a </st><img src="image/4809.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.879em"/><st c="10154"/><st c="10155"> symmetric random matrix. </st><st c="10181">I have generated it in a similar way to </st><img src="image/4810.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.193em"/><st c="10221"/><st c="10224"> but using a matrix </st><img src="image/4811.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.012em"/><st c="10243"/><st c="10245"> in </st><em class="italic"><st c="10248">Eq.1</st></em><st c="10252"> instead of </st><img src="image/4803.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.013em"/><st c="10264"/><st c="10266">. Like matrix </st><img src="image/4803.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.013em"/><st c="10280"/><st c="10282">, the </st><img src="image/4811.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:1.014em"/><st c="10288"/><st c="10290"> matrix is a </st><img src="image/4804.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.954em"/><st c="10302"/><st c="10303"> random matrix and all its matrix elements are i.i.d. </st><st c="10357">and drawn </st><span class="No-Break"><st c="10367">from </st></span><span class="No-Break"><img src="image/4816.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0,1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.167em;height:0.851em;width:2.584em"/><st c="10372"/></span><span class="No-Break"><st c="10373">.</st></span></p>
			<p><st c="10374">Although the two matrices, </st><img src="image/4817.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.176em"/><st c="10402"/><st c="10404"> and </st><img src="image/4818.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.176em"/><st c="10408"/><st c="10409">, are generated in the same way, they are two different matrices. </st><st c="10475">They have different matrix elements that are generated independently from each other. </st><st c="10561">Each matrix has </st><img src="image/4819.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mn&gt;2000&lt;/mn&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mn&gt;2000&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;/mrow&gt;&lt;mn&gt;6&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.012em;height:0.718em;width:8.502em"/><st c="10577"/><st c="10578"> matrix elements. </st><st c="10596">There are a lot of ways in which matrix </st><img src="image/4820.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.174em"/><st c="10636"/><st c="10638"> can be different from matrix </st><img src="image/4821.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.179em"/><st c="10667"/><st c="10668">. </st><span class="No-Break"><em class="italic"><st c="10670">Figure 15</st></em></span><em class="italic"><st c="10679">.2</st></em><st c="10681"> shows histograms of the scaled eigenvalues of each matrix – the left-hand panel shows the histogram for matrix </st><img src="image/4822.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.192em"/><st c="10793"/><st c="10796">, while the right-hand panel shows the histogram for matrix  </st><img src="image/4823.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.205em"/><st c="10856"/><st c="10859">.</st></p>
			<div>
				<div id="_idContainer4973" class="IMG---Figure">
					<img src="image/B19496_15_2.jpg" alt="" role="presentation"/><st c="10860"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="10955">Figure 15.2: Histograms of scaled eigenvalues for two large symmetric random matrices with Gaussian matrix elements</st></p>
			<p><st c="11070">The </st><em class="italic"><st c="11075">x</st></em><st c="11076"> axis in</st><a id="_idIndexMarker1196"/><st c="11084"> both plots shows the </st><img src="image/4824.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;msqrt&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/msqrt&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;s&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;d&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;v&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;u&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.075em;width:9.198em"/><st c="11106"/><st c="11129">, with </st><img src="image/4825.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:4.194em"/><st c="11136"/><st c="11137"> in this case. </st><st c="11152">So, for each matrix, we have taken its eigenvalues </st><img src="image/4826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt;…&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.338em;height:1.049em;width:4.447em"/><st c="11203"/><st c="11219"> and divided them by </st><img src="image/4827.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:1.388em"/><st c="11239"/><st c="11240">. The histograms are an estimate of the probability density of the </st><span class="No-Break"><st c="11307">scaled eigenvalues.</st></span></p>
			<p><st c="11326">What is remarkable is how similar the two histograms are, despite the matrices having a huge number of differences between them in terms of their individual matrix elements. </st><st c="11501">The presence of the red line in </st><span class="No-Break"><em class="italic"><st c="11533">Figure 15</st></em></span><em class="italic"><st c="11542">.2</st></em><st c="11544">, which follows the shape of the two histograms, suggests that I expected the histograms to have </st><span class="No-Break"><st c="11641">this shape.</st></span></p>
			<p><st c="11652">The red line is known as the semicircle law. </st><st c="11698">Sometimes, you will see it referred to as the </st><strong class="bold"><st c="11744">Wigner semicircle distribution</st></strong><st c="11774">, after</st><a id="_idIndexMarker1197"/><st c="11781"> Eugene Wigner, the famous theoretical physicist who used random matrices to study the properties of atomic nuclei. </st><st c="11897">The semicircle law says that in the </st><img src="image/1873.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.117em"/><st c="11933"/><st c="11934"> limit, the probability density of the scaled eigenvalues tends to the density given </st><span class="No-Break"><st c="12019">by </st></span><span class="No-Break"><em class="italic"><st c="12022">Eq.2</st></em></span><span class="No-Break"><st c="12026">.</st></span></p>
			<p><img src="image/4829.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;π&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:msqrt&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msqrt&gt;&lt;mml:mo&gt;≤&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;≤&lt;/mml:mo&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msqrt&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.298em;height:1.263em;width:14.311em"/><st c="12027"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="12029">Eq.2</st></p>
			<p><st c="12033">The red line in </st><span class="No-Break"><em class="italic"><st c="12050">Figure 15</st></em></span><em class="italic"><st c="12059">.2</st></em><st c="12061"> is the equation in </st><em class="italic"><st c="12081">Eq.2</st></em><st c="12085"> with </st><img src="image/4830.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:4.215em"/><st c="12091"/><st c="12092">. The </st><img src="image/4831.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.052em;height:0.925em;width:3.005em"/><st c="12098"/><st c="12104"> mathematical form in </st><em class="italic"><st c="12125">Eq.2</st></em><st c="12129"> tells us that this function will have a shape related to a semicircle, hence the origin of the name </st><em class="italic"><st c="12230">semicircle law</st></em><st c="12244"> (or </st><span class="No-Break"><st c="12249">semicircle distribution).</st></span></p>
			<p><st c="12274">There are a few things we should point out about the result </st><span class="No-Break"><st c="12335">in </st></span><span class="No-Break"><em class="italic"><st c="12338">Eq.2</st></em></span><span class="No-Break"><st c="12342">:</st></span></p>
			<ul>
				<li><st c="12344">It is an asymptotic result. </st><st c="12372">We have said that it is the probability density of </st><img src="image/4832.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:2.233em"/><st c="12423"/><st c="12424"> that we get in the </st><img src="image/1870.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.158em"/><st c="12444"/><st c="12445"> limit. </st><st c="12453">This may not seem like a very useful result, as no real-world matrix is of infinite size. </st><st c="12543">However, it means that for large but finite values of </st><img src="image/443.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.699em"/><st c="12597"/><st c="12598">, the density in </st><em class="italic"><st c="12615">Eq.2</st></em><st c="12619"> will still be a very good approximation for the probability density of </st><img src="image/4832.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:2.229em"/><st c="12691"/><st c="12692">. At large but finite values of </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="12724"/><st c="12725">, we will see some deviations from the semicircle law. </st><st c="12780">However, they will be small, and they will get smaller as </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.718em"/><st c="12838"/><st c="12839"> increases. </st><st c="12851">As we can see from </st><span class="No-Break"><em class="italic"><st c="12870">Figure 15</st></em></span><em class="italic"><st c="12879">.2</st></em><st c="12881">, at </st><img src="image/4838.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:4.230em"/><st c="12886"/><st c="12887">, the semicircle law is a very good approximation for the density of scaled eigenvalues. </st><st c="12976">I have even seen the semicircle law being used as a reasonable approximation for </st><img src="image/4839.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;50&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;50&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:2.999em"/><st c="13057"/> <span class="No-Break"><st c="13058">matrices.</st></span></li>
				<li><st c="13067">You’ll also notice the finite support of the semicircular law in </st><em class="italic"><st c="13133">Eq.2</st></em><st c="13137">. We can only get values between </st><img src="image/4840.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.040em;height:0.844em;width:1.748em"/><st c="13170"/><st c="13171"> and </st><img src="image/4841.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.040em;height:0.844em;width:1.122em"/><st c="13176"/><st c="13177"> for the </st><img src="image/4842.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;msqrt&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/msqrt&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;s&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;d&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;v&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;u&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.257em;height:1.075em;width:9.218em"/><st c="13186"/><st c="13209">. So, there is a minimum and maximum possible value for the scaled eigenvalue. </st><st c="13288">Again, this is an asymptotic result. </st><st c="13325">At finite </st><img src="image/4843.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.117em;height:0.765em;width:0.927em"/><st c="13335"/><st c="13336"> we will see some departure from this rule, but at large values of </st><img src="image/4844.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.117em;height:0.765em;width:0.941em"/><st c="13403"/><st c="13404"> the departures will be small, that is, </st><img src="image/4845.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;±&lt;/mml:mo&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:2.532em"/><st c="13444"/><st c="13445"> will be a good approximation to the range of eigenvalues that we would see from matrices generated in the way that matrix </st><img src="image/4846.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.205em"/><st c="13568"/><st c="13571"> and matrix </st><img src="image/4823.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.205em"/><st c="13582"/> <span class="No-Break"><st c="13585">were.</st></span></li>
			</ul>
			<p><st c="13590">The semicircle</st><a id="_idIndexMarker1198"/><st c="13605"> law of </st><em class="italic"><st c="13613">Eq.2</st></em><st c="13617"> is an example of what we mean by universal behavior or universality. </st><st c="13687">Irrespective of the individual matrix, we will get the same statistical behavior. </st><st c="13769">In this case, we get the same statistical behavior of the eigenvalue distribution of </st><span class="No-Break"><st c="13854">the matrix.</st></span></p>
			<p><st c="13865">The semicircle law is the most well-known result from RMT. </st><st c="13925">Deriving the shape of the eigenvalue distribution as </st><img src="image/4848.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.099em"/><st c="13978"/><st c="13979"> is the sort of task that RMT focuses on. </st><st c="14021">We won’t go into the methods used to derive the semicircle law or other RMT results, as they can be complex, but we will discuss more of these universal RMT results in the </st><span class="No-Break"><st c="14193">next section.</st></span></p>
			<h2 id="_idParaDest-414"><a id="_idTextAnchor750"/><st c="14206">What does RMT study?</st></h2>
			<p><st c="14227">When we study ordinary random variables using the rules of probability, the mathematical results that we obtain are about expectation values, that is, statements about the average behavior of the random variable. </st><st c="14441">It is the same when we use RMT to study random matrices. </st><st c="14498">We</st><a id="_idIndexMarker1199"/><st c="14500"> can only derive formulae and laws about the expected behavior of random matrices. </st><st c="14583">The semicircle law in </st><em class="italic"><st c="14605">Eq.2</st></em><st c="14609"> is actually a statement about what happens to the eigenvalue distribution on average as we go to the </st><img src="image/1873.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.109em"/><st c="14711"/><st c="14712"> limit. </st><st c="14720">This means that if we were to generate lots of different matrices </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.904em"/><st c="14786"/><st c="14800"> using the process described in </st><em class="italic"><st c="14831">Eq.1</st></em><st c="14835">, and we were to calculate their scaled eigenvalues and take the average of their empirical distributions, we would get something close to the semicircle law. </st><st c="14994">As we made </st><img src="image/629.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.688em"/><st c="15005"/><st c="15006"> larger and larger, this average scaled eigenvalue distribution would get closer and closer to the </st><span class="No-Break"><st c="15105">semicircle law.</st></span></p>
			<p><st c="15120">However, this raises an interesting question. </st><st c="15167">If the semicircle law is the average scaled eigenvalue distribution we’d get after averaging across all matrices </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.880em"/><st c="15280"/><st c="15294"> generated using </st><em class="italic"><st c="15310">Eq.1</st></em><st c="15314"> (and taking the </st><img src="image/4853.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.010em"/><st c="15331"/><st c="15332"> limit), how is the semicircle law such a good approximation to the eigenvalue distributions for the single </st><img src="image/4854.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.250em"/><st c="15440"/><st c="15442"> and </st><img src="image/4855.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;s&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;t&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.333em;height:0.981em;width:5.217em"/><st c="15446"/><st c="15459">? It’s like we had drawn two values from a random variable </st><img src="image/2035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.648em;width:0.654em"/><st c="15518"/><st c="15519"> and both just happened to be almost exactly the same as the </st><img src="image/4857.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;exp&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;t&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;t&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;v&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;u&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.240em;height:0.951em;width:9.197em"/><st c="15580"/><st c="15602">. Why did we not see any sampling variation (deviations) around the semicircle law when we generated </st><img src="image/4846.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.207em"/><st c="15703"/><st c="15706"> and </st><img src="image/4823.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.207em"/><st c="15710"/><st c="15713">? Were we just extraordinarily lucky? </st><st c="15751">The answer is no, and the reason why has to do with the fact that </st><img src="image/443.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.694em"/><st c="15817"/> <span class="No-Break"><st c="15818">is large.</st></span></p>
			<h3><st c="15827">Self-averaging</st></h3>
			<p><st c="15842">For a single matrix </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="15863"/><st c="15877"> generated using the </st><a id="_idIndexMarker1200"/><st c="15897">process in </st><em class="italic"><st c="15908">Eq.1</st></em><st c="15912">, we’ll use </st><img src="image/4862.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;~&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.911em;width:0.651em"/><st c="15924"/><st c="15925"> to denote a scaled eigenvalue, so </st><img src="image/4863.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;~&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.947em;width:4.407em"/><st c="15960"/><st c="15961">, and we’ll use </st><img src="image/4864.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;~&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.392em;height:1.291em;width:3.289em"/><st c="15977"/><st c="15978"> to denote the empirical density of scaled eigenvalues from </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.892em"/><st c="16038"/><st c="16052">. RMT says that the average of </st><img src="image/4866.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;~&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.392em;height:1.291em;width:3.042em"/><st c="16083"/><st c="16084"> over all matrices </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.881em"/><st c="16103"/><st c="16117"> tends to the semicircle law in </st><em class="italic"><st c="16148">Eq.2</st></em><st c="16152"> as </st><img src="image/4868.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.015em"/><st c="16156"/><st c="16157">. In mathematical language, we would say this </st><span class="No-Break"><st c="16203">as follows:</st></span></p>
			<p><img src="image/4869.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mi&gt;lim&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;~&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/mfrac&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mover&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;~&lt;/mo&gt;&lt;/mover&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.412em;height:1.816em;width:12.413em"/><st c="16214"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="16216">Eq.3</st></p>
			<p><st c="16220">However, what we will also find is that the variance of </st><img src="image/4870.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;~&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.392em;height:1.291em;width:3.312em"/><st c="16277"/><st c="16278"> around its expectation decreases to zero as </st><img src="image/4848.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.088em"/><st c="16323"/><st c="16324">. As </st><img src="image/4848.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.089em"/><st c="16329"/><st c="16330">, the empirical distribution of any single matrix </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.886em"/><st c="16380"/><st c="16394"> becomes the same as the average across all matrices of the same type as </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.897em"/><st c="16466"/><st c="16480">. In physics, we refer to this as </st><strong class="bold"><st c="16514">self-averaging</st></strong><st c="16528">. The eigenvalue distribution of a matrix </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="16570"/><st c="16584"> generated from </st><em class="italic"><st c="16599">Eq.1</st></em><st c="16603"> is a self-averaging quantity. </st><st c="16634">What we get from a single random instance is very close to the average across multiple instances and vice versa. </st><st c="16747">It is this self-averaging behavior that makes the semicircle law a useful approximation even for single instances of a </st><span class="No-Break"><st c="16866">random</st></span><span class="No-Break"><a id="_idIndexMarker1201"/></span><span class="No-Break"><st c="16872"> matrix.</st></span></p>
			<p><st c="16880">Ultimately, it is also this self-averaging behavior that makes it possible for RMT to derive formulae such as the semicircle law. </st><st c="17011">Therefore, it is ultimately by considering </st><strong class="bold"><st c="17054">large</st></strong><st c="17059"> random matrices (that is, taking </st><img src="image/443.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.697em"/><st c="17093"/><st c="17094"> to be large) that we can make progress in RMT. </st><st c="17142">However, that is not to say that RMT doesn’t also consider random matrices of small or intermediate finite size. </st><st c="17255">It is just that deriving simple closed-form laws for such matrices can be considerably </st><span class="No-Break"><st c="17342">more challenging.</st></span></p>
			<h2 id="_idParaDest-415"><a id="_idTextAnchor751"/><st c="17359">Universal is universal</st></h2>
			<p><st c="17382">You may be</st><a id="_idIndexMarker1202"/><st c="17393"> thinking that although matrices </st><img src="image/4877.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.276em"/><st c="17426"/><st c="17428"> and </st><img src="image/4878.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.173em"/><st c="17432"/><st c="17433"> in </st><span class="No-Break"><em class="italic"><st c="17437">Figure 15</st></em></span><em class="italic"><st c="17446">.2</st></em><st c="17448"> are different matrices, they were generated according to the same process. </st><st c="17524">How often are we going to be dealing with real-world matrices whose matrix elements are Gaussian distributed? </st><st c="17634">Is the behavior illustrated in </st><span class="No-Break"><em class="italic"><st c="17665">Figure 15</st></em></span><em class="italic"><st c="17674">.2</st></em><st c="17676"> really that universal? </st><st c="17700">Here’s the thing: universal behavior typically arises for reasons that are not related to the microscopic details of how a system is specified. </st><st c="17844">This means that we can often change the microscopic details, such as which precise distribution the matrix elements are drawn from, and still get the same universal behavior. </st><st c="18019">Let’s try it. </st><st c="18033">Let’s take our matrix elements from another distribution, but still with mean zero and unit variance, and see </st><span class="No-Break"><st c="18143">what happens.</st></span></p>
			<p><span class="No-Break"><em class="italic"><st c="18156">Figure 15</st></em></span><em class="italic"><st c="18166">.3</st></em><st c="18168"> shows the scaled eigenvalue histograms for two </st><img src="image/4879.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.852em"/><st c="18216"/><st c="18217"> symmetric random matrices, </st><img src="image/4880.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.988em;width:1.137em"/><st c="18245"/><st c="18248"> and </st><img src="image/4881.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.156em"/><st c="18252"/><st c="18255">, generated using </st><em class="italic"><st c="18273">Eq.1</st></em><st c="18277"> but using matrices </st><img src="image/4882.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.003em;width:0.951em"/><st c="18297"/><st c="18299"> and </st><img src="image/4883.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:0.952em"/><st c="18303"/><st c="18306"> instead, respectively. </st><st c="18329">The </st><img src="image/4884.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.003em;width:0.953em"/><st c="18333"/><st c="18334"> and </st><img src="image/4885.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:0.954em"/><st c="18339"/><st c="18341"> matrices are </st><img src="image/4886.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.782em"/><st c="18354"/><st c="18355"> random matrices whose matrix elements have been drawn from a Laplace distribution that has zero mean and </st><span class="No-Break"><st c="18461">un</st><a id="_idTextAnchor752"/><st c="18463">it variance.</st></span></p>
			<div>
				<div id="_idContainer5037" class="IMG---Figure">
					<img src="image/B19496_15_3.jpg" alt="" role="presentation"/><st c="18476"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="18569">Figure 15.3: Histograms of scaled eigenvalues for two large symmetric random matrices with matrix elements drawn from a Laplace distribution</st></p>
			<p><st c="18709">The zero mean unit </st><a id="_idIndexMarker1203"/><st c="18729">variance Laplace distribution has a probability density of </st><img src="image/4887.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:0.822em;width:1.878em"/><st c="18788"/><st c="18794"> which is given by the </st><span class="No-Break"><st c="18816">following equation:</st></span></p>
			<p><a id="_idTextAnchor753"/><img src="image/4888.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;mtext&gt;exp&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msqrt&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msqrt&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.530em;height:1.465em;width:8.883em"/><st c="18835"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="18859">Eq.4</st></p>
			<p><st c="18863">The density function of the Laplace distribution is different from the Gaussian distribution. </st><st c="18958">It decays more slowly than the Gaussian distribution. </st><st c="19012">Despite these big differences, the histograms in </st><span class="No-Break"><em class="italic"><st c="19061">Figure 15</st></em></span><em class="italic"><st c="19070">.3</st></em><st c="19072"> are almost identical to those in </st><span class="No-Break"><em class="italic"><st c="19106">Figure 15</st></em></span><em class="italic"><st c="19115">.2</st></em><st c="19117">. Again, the red lines in </st><span class="No-Break"><em class="italic"><st c="19143">Figure 15</st></em></span><em class="italic"><st c="19152">.3</st></em><st c="19154"> are the semicircle law from </st><em class="italic"><st c="19183">Eq.2</st></em><st c="19187">. You can see that the semicircle law accurately describes the density of scaled eigenvalues for this Laplace distribution case. </st><st c="19316">It turns out that the conditions on the distribution from which we can draw our matrix elements are very broad. </st><st c="19428">Typically, for a real symmetric </st><img src="image/651.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:2.503em"/><st c="19460"/><st c="19461"> matrix, as long as we have a zero mean unit variance distribution whose low-order moments are finite, then the resulting distribution of scaled eigenvalues will follow the semicircle law in the </st><img src="image/4890.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.137em"/><st c="19656"/><st c="19657"> limit. </st><st c="19665">The universality of the semicircle law is indeed universal. </st><st c="19725">You can even mix the distributions from which we draw our matrix elements and still get the semicircle law – this is one of the exercise questions at the end of </st><span class="No-Break"><st c="19886">this chapter.</st></span></p>
			<h2 id="_idParaDest-416"><a id="_idTextAnchor754"/><st c="19899">The classical Gaussian matrix ensembles</st></h2>
			<p><st c="19939">The Gaussian matrices, which we defined via </st><em class="italic"><st c="19984">Eq.1</st></em><st c="19988"> and whose eigenvalue distributions we plotted in </st><span class="No-Break"><em class="italic"><st c="20038">Figure 15</st></em></span><em class="italic"><st c="20047">.2</st></em><st c="20049">, are part of a wider family of random matrices. </st><st c="20098">It is time to meet </st><span class="No-Break"><st c="20117">that family.</st></span></p>
			<p><st c="20129">You’ll recall that we restricted our matrices in </st><span class="No-Break"><em class="italic"><st c="20179">Figure 15</st></em></span><em class="italic"><st c="20188">.2</st></em><st c="20190"> to being real, square, symmetric, and generated according to </st><em class="italic"><st c="20252">Eq.1</st></em><st c="20256">, with matrix </st><img src="image/4801.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.996em;width:0.993em"/><st c="20270"/><st c="20272"> having all of its matrix elements drawn from the standard normal distribution. </st><st c="20351">This </st><a id="_idIndexMarker1204"/><st c="20356">group, or </st><strong class="bold"><st c="20366">ensemble</st></strong><st c="20374">, of matrices is called</st><a id="_idIndexMarker1205"/><st c="20397"> the </st><strong class="bold"><st c="20402">Gaussian Orthogonal Ensemble</st></strong><st c="20430"> (</st><strong class="bold"><st c="20432">GOE</st></strong><st c="20435">). </st><st c="20439">So, overall, the GOE is defined by </st><span class="No-Break"><st c="20474">the following</st><a id="_idTextAnchor755"/><st c="20487">:</st></span></p>
			<p><img src="image/4892.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mtext&gt;GOE&lt;/mtext&gt;&lt;mtext&gt;if&lt;/mtext&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mn&gt;0,1&lt;/mn&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.483em;height:1.448em;width:17.635em"/><st c="20489"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="20527">Eq.5</st></p>
			<p><st c="20531">It is clear from </st><em class="italic"><st c="20549">Eq.5</st></em><st c="20553"> that </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.878em"/><st c="20559"/><st c="20573"> is symmetric and real. </st><st c="20596">Consequently, its eigenvalues will be real. </st><st c="20640">However, there are other ways in which we can construct a matrix </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="20705"/><st c="20719"> , similar to how it is defined in </st><em class="italic"><st c="20753">Eq.5</st></em><st c="20757"> and such that it still has real eigenvalues. </st><st c="20803">For example, if we make the matrix elements of </st><img src="image/564.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.863em;width:0.676em"/><st c="20850"/><st c="20851"> be complex numbers and draw the real and imaginary parts of the matrix elements from </st><img src="image/4896.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mn&gt;0,1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.686em"/><st c="20937"/><st c="20938">, then we can define </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="20959"/><st c="20973"> via the </st><span class="No-Break"><st c="20981">following equation:</st></span><a id="_idTextAnchor756"/></p>
			<p><img src="image/4898.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;H&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.437em;height:1.401em;width:5.754em"/><st c="21000"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21013">Eq.6</st></p>
			<p><img src="image/4899.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;H&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.911em;width:1.150em"/><st c="21017"/><st c="21020"> means the Hermitian conjugate of </st><img src="image/564.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.863em;width:0.665em"/><st c="21053"/><st c="21054">. We encountered this operation in </st><a href="B19496_03.xhtml#_idTextAnchor141"><span class="No-Break"><em class="italic"><st c="21089">Chapter 3</st></em></span></a><st c="21098">, where we used the symbol </st><img src="image/4901.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mo&gt;†&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.096em;height:0.734em;width:0.489em"/><st c="21125"/><st c="21126"> for the Hermitian conjugate. </st><st c="21156">It means taking the conjugate transpose of </st><img src="image/607.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.863em;width:0.663em"/><st c="21199"/><st c="21200"> and ensures that the matrix </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="21229"/><st c="21243"> is Hermitian and so has real eigenvalues. </st><st c="21285">Matrices defined via </st><em class="italic"><st c="21306">Eq.6</st></em><st c="21310"> form</st><a id="_idIndexMarker1206"/><st c="21315"> the </st><strong class="bold"><st c="21320">Gaussian Unitary Ensemble</st></strong><st c="21345"> (</st><strong class="bold"><st c="21347">GUE</st></strong><st c="21350">). </st><st c="21354">So, overall, the GUE is defined by </st><span class="No-Break"><st c="21389">the following</st><a id="_idTextAnchor757"/><st c="21402">:</st></span></p>
			<p><img src="image/4904.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mtext&gt;GUE&lt;/mtext&gt;&lt;mtext&gt;if&lt;/mtext&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;H&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;i&lt;/mtext&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mn&gt;0,1&lt;/mn&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.483em;height:1.448em;width:23.556em"/><st c="21404"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21447">Eq.7</st></p>
			<p><st c="21451">The matrix elements of a GUE matrix have a different number of components compared to the matrix elements of a GOE matrix. </st><st c="21575">The matrix elements of GOE matrices are real numbers and so are defined by a single real number. </st><st c="21672">Matrix elements of GUE matrices are complex numbers and so are defined by two real numbers – their real and imaginary parts. </st><st c="21797">We can extend this pattern further to define numbers with four real components. </st><st c="21877">These numbers are</st><a id="_idIndexMarker1207"/><st c="21894"> called </st><strong class="bold"><st c="21902">quaternions</st></strong><st c="21913">. We won’t go into quaternions any further here, but just like you can loosely think of complex numbers as being two-dimensional numbers because they live in a two-dimensional space called the </st><strong class="bold"><st c="22106">complex plane</st></strong><st c="22119">, you can</st><a id="_idIndexMarker1208"/><st c="22128"> also think of quaternions as being four-dimensional numbers that live in a four-dimensional space. </st><st c="22228">If we allow the matrix elements of </st><img src="image/607.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.863em;width:0.663em"/><st c="22263"/><st c="22264"> to be quaternions, then we can define a new ensemble of random matrices called</st><a id="_idIndexMarker1209"/><st c="22343"> the </st><strong class="bold"><st c="22348">Gaussian Symplectic Ensemble</st></strong><st c="22376"> (</st><strong class="bold"><st c="22378">GSE</st></strong><st c="22381">). </st><st c="22385">So, overall, the GSE is defined by </st><span class="No-Break"><st c="22420">the follow</st><a id="_idTextAnchor758"/><st c="22430">ing:</st></span></p>
			<p><img src="image/4906.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mtext&gt;GSE&lt;/mtext&gt;&lt;mtext&gt;if&lt;/mtext&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;D&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;Quaternion&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;~&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mn&gt;0,1&lt;/mn&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.483em;height:1.448em;width:31.022em"/><st c="22435"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="22500">Eq.8</st></p>
			<p><st c="22504">In </st><em class="italic"><st c="22508">Eq.8</st></em><st c="22512">, the </st><img src="image/4907.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt;D&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.911em;width:1.142em"/><st c="22518"/><st c="22520"> notation means taking the dual transpose of </st><img src="image/607.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.863em;width:0.663em"/><st c="22564"/><st c="22565"> and ensures that the matrix </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="22594"/><st c="22608"> is self-dual and so has real eigenvalues. </st><st c="22650">Since a quaternion itself can be represented as a </st><img src="image/4910.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.000em;height:0.634em;width:2.109em"/><st c="22700"/><st c="22701"> matrix of complex numbers, an </st><img src="image/819.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:2.429em"/><st c="22732"/><st c="22733"> GSE matrix can be represented as a </st><img src="image/4912.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:3.482em"/><st c="22769"/><st c="22770"> matrix of complex numbers. </st><st c="22798">This way of representing GSE matrices gives us a more practical way of </st><span class="No-Break"><st c="22869">generating them.</st></span></p>
			<p class="callout-heading"><st c="22885">Generating matrices from the Gaussian Symplectic Ensemble</st></p>
			<p class="callout"><st c="22943">1. </st><st c="22947">Generate two random complex </st><img src="image/4913.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:2.483em"/><st c="22975"/><st c="22976"> matrices, </st><img src="image/4914.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.642em"/><st c="22987"/><st c="22988"> and </st><img src="image/4915.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;Y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.611em"/><st c="22993"/><st c="22994">, whose matrix elements have their real and imaginary parts independently drawn </st><span class="No-Break"><st c="23074">from </st></span><span class="No-Break"><img src="image/4916.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mn&gt;0,1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.584em"/><st c="23079"/></span><span class="No-Break"><st c="23080">.</st></span></p>
			<p class="callout"><st c="23081">2. </st><st c="23085">Construct the </st><img src="image/4917.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:3.449em"/><st c="23099"/><st c="23100"> matrix </st><img src="image/4918.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.863em;width:0.663em"/><st c="23108"/><st c="23109"> defined in block form </st><span class="No-Break"><st c="23132">as follows:</st></span></p>
			<p class="callout">                                               <img src="image/4919.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mtable columnspacing=&quot;0.8000em&quot; columnwidth=&quot;auto auto&quot; columnalign=&quot;center center&quot; rowspacing=&quot;1.0000ex&quot; rowalign=&quot;baseline baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;*&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;*&lt;/mi&gt;&lt;/msup&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.899em;height:2.306em;width:6.692em"/><st c="23143"/> </p>
			<p class="callout"><st c="23145">3. </st><st c="23148">Calculate the GSE matrix </st><img src="image/4920.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="23173"/> <span class="No-Break"><st c="23174">as </st></span><span class="No-Break"><img src="image/4921.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;+1&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mstyle&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.251em;height:1.011em;width:6.005em"/><st c="23177"/></span><span class="No-Break"><st c="23178">.</st></span></p>
			<p><st c="23179">The GOE, GUE, and GSE</st><a id="_idIndexMarker1210"/><st c="23201"> differ in terms of the number of real </st><a id="_idIndexMarker1211"/><st c="23240">numbers used to specify each matrix element. </st><st c="23285">Traditionally, we</st><a id="_idIndexMarker1212"/><st c="23302"> use the </st><img src="image/4922.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.484em"/><st c="23311"/><st c="23312"> symbol to denote this number of real numbers. </st><st c="23359">The GOE corresponds to </st><img src="image/4923.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:2.554em"/><st c="23382"/><st c="23383">, the GUE corresponds to </st><img src="image/4924.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:2.555em"/><st c="23408"/><st c="23409">, and the GSE corresponds to </st><img src="image/4925.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:2.557em"/><st c="23438"/><st c="23439">. Overall, these three ensembles form the </st><strong class="bold"><st c="23481">classical</st></strong><st c="23490"> ensembles </st><span class="No-Break"><st c="23501">of RMT.</st></span></p>
			<p><st c="23508">Matrices from the GOE, GUE, or GSE all have real eigenvalues </st><img src="image/4926.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.671em"/><st c="23570"/><st c="23571">. For all three ensembles, if we calculate scaled eigenvalues as </st><img src="image/4927.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.221em;width:2.688em"/><st c="23636"/><st c="23643"> , then the distribution of scaled eigenvalues tends to the semicircle law of </st><em class="italic"><st c="23720">Eq.2</st></em><st c="23724"> in the </st><img src="image/1914.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.076em"/><st c="23732"/><st c="23733"> limit. </st><st c="23741">The semicircle law is universal across all three of these classical random </st><span class="No-Break"><st c="23816">matrix ensembles.</st></span></p>
			<p><st c="23833">It is not uncommon to see </st><img src="image/4929.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;~&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.239em;width:4.667em"/><st c="23860"/><st c="23869"> used to define the scaled eigenvalues from any of the classical RMT ensembles. </st><st c="23948">In this case, the limiting scaled eigenvalue distribution becomes </st><span class="No-Break"><st c="24014">the fol</st><a id="_idTextAnchor759"/><st c="24021">lowing:</st></span></p>
			<p><img src="image/4930.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mover&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;~&lt;/mo&gt;&lt;/mover&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mover&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;~&lt;/mo&gt;&lt;/mover&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;mtext&gt;for&lt;/mtext&gt;&lt;mover&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;~&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.665em;height:2.105em;width:18.398em"/><st c="24029"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="24066">Eq.9</st></p>
			<p><st c="24070">Whichever classical ensemble, and hence value of </st><img src="image/4931.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.257em;height:0.968em;width:0.509em"/><st c="24120"/><st c="24121">, we are working with, all the different variants of </st><em class="italic"><st c="24174">Eq.9</st></em><st c="24178"> tend to get referred to as the semicircle law, which can be confusing when you first see the different variants. </st><st c="24292">This is why I prefer to absorb the </st><img src="image/4932.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.297em;height:1.178em;width:1.095em"/><st c="24327"/><st c="24328"> factor into the definition of the scaled eigenvalue rather than its probability density. </st><st c="24418">That way, you get only one semicircle law for all three classical RMT ensembles: the one </st><span class="No-Break"><st c="24507">in </st></span><span class="No-Break"><em class="italic"><st c="24510">Eq.2</st></em></span><span class="No-Break"><st c="24514">.</st></span></p>
			<p><st c="24515">However, some authors also absorb the factor of </st><img src="image/4933.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:2.182em"/><st c="24564"/><st c="24570"> into the definition of the ensemble, that is, into the definition of how the matrix is constructed. </st><st c="24670">You may also see differences in pre-factors of </st><img src="image/4934.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.040em;height:0.844em;width:1.145em"/><st c="24717"/><st c="24718"> between different authors when defining the classical ensembles. </st><st c="24784">Again, these differences only lead to trivial variants of </st><em class="italic"><st c="24842">Eq.9</st></em><st c="24846"> for the form of the scaled eigenvalue density. </st><st c="24894">However, it does require you to keep your eyes open and be aware of these differences when looking at different textbooks or </st><span class="No-Break"><st c="25019">research papers.</st></span></p>
			<p><st c="25035">For much of the early history of RMT, the three classical ensembles were the focus of study, mainly because of their relevance to physics and quantum mechanics. </st><st c="25197">As RMT progressed, researchers realized that the ideas and concepts of RMT could be applied to other research areas and other ensembles of matrices, including large data matrices of the kind that we encounter when building statistical and machine learning models. </st><st c="25461">The matrices may be different (for example, a data matrix is not usually square), but they are still large and random. </st><st c="25580">Unsurprisingly, we also find universal behavior in the statistical properties of these new </st><span class="No-Break"><st c="25671">matrix ensembles.</st></span></p>
			<p><st c="25688">In the next section, we will look at ensembles of large random matrices that we encounter as data scientists, namely large covariance matrices and large weight matrices from neural networks. </st><st c="25880">In both cases, we will highlight how RMT is used to study the properties of those classes of matrices. </st><st c="25983">For now though, we’ll wrap up this section by summarizing what we </st><span class="No-Break"><st c="26049">have covered.</st></span></p>
			<h2 id="_idParaDest-417"><a id="_idTextAnchor760"/><st c="26062">What we learned</st></h2>
			<p><st c="26078">In this section, we have learned about </st><span class="No-Break"><st c="26118">the following:</st></span></p>
			<ul>
				<li><st c="26132">How the distribution of scaled eigenvalues of large symmetric random matrices can follow a </st><span class="No-Break"><st c="26224">universal pattern</st></span></li>
				<li><st c="26241">The Wigner </st><span class="No-Break"><st c="26253">semicircle law</st></span></li>
				<li><st c="26267">The </st><a id="_idIndexMarker1213"/><st c="26272">GOE, </st><a id="_idIndexMarker1214"/><st c="26277">GUE, and GSE </st><a id="_idIndexMarker1215"/><st c="26290">families </st><span class="No-Break"><st c="26299">of matrices</st></span></li>
				<li><st c="26310">How the semicircle law is the distribution of scaled eigenvalues for the GOE, GUE, and GSE in the </st><img src="image/1914.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.076em"/><st c="26409"/> <span class="No-Break"><st c="26410">limit</st></span></li>
				<li><st c="26415">How the semicircle law can apply to large square random matrices that are not drawn from the classical Gaussian random </st><span class="No-Break"><st c="26535">matrix ensembles</st></span></li>
			</ul>
			<p><st c="26551">Having learned about the semicircle law, in the next section, we will extend it by looking at large covariance matrices that arise in statistics and </st><span class="No-Break"><st c="26701">machine learning.</st></span></p>
			<h1 id="_idParaDest-418"><a id="_idTextAnchor761"/><st c="26718">Random matrices and high-dimensional covariance matrices</st></h1>
			<p><st c="26775">The examples of large random matrices in the previous section were all square matrices. </st><st c="26864">However, in real-world data science, not all matrices are square. </st><st c="26930">Take the </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.664em"/><st c="26939"/><st c="26940"> data matrix that we </st><a id="_idIndexMarker1216"/><st c="26961">encountered in </st><a href="B19496_03.xhtml#_idTextAnchor141"><span class="No-Break"><em class="italic"><st c="26976">Chapter 3</st></em></span></a><st c="26985"> when doing </st><strong class="bold"><st c="26997">Principal Component Analysis</st></strong><st c="27025"> (</st><strong class="bold"><st c="27027">PCA</st></strong><st c="27030">). </st><st c="27034">It is an </st><img src="image/1056.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:2.292em"/><st c="27043"/><st c="27044"> matrix, where </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.704em"/><st c="27059"/><st c="27060"> is the number of data points and </st><img src="image/596.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.507em"/><st c="27094"/><st c="27095"> is the number of features. </st><st c="27123">We will assume, for this section, that the data has already been mean-centered, so that the sum of each column of </st><img src="image/1054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.641em"/><st c="27237"/> <span class="No-Break"><st c="27238">is </st></span><span class="No-Break"><strong class="source-inline"><st c="27241">0</st></strong></span><span class="No-Break"><st c="27242">.</st></span></p>
			<p><st c="27243">The </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.649em"/><st c="27248"/><st c="27249"> matrix is what we use to do PCA. </st><st c="27283">It is also the design matrix that we use when building statistical models. </st><st c="27358">So, the </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.688em"/><st c="27366"/><st c="27367"> matrix is non-square (unless </st><img src="image/4943.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.204em;height:0.915em;width:3.188em"/><st c="27397"/><st c="27398">. However, in practice, we usually derive a square matrix from </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.703em"/><st c="27461"/><st c="27462">. For example, when doing PCA, we would calculate the sample covariance matrix </st><img src="image/4945.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.634em"/><st c="27541"/><st c="27542">, which is defined </st><a id="_idTextAnchor762"/><span class="No-Break"><st c="27561">as follows:</st></span></p>
			<p><img src="image/4946.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mover&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.417em;height:1.352em;width:6.330em"/><st c="27572"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="27577">Eq.10</st></p>
			<p><st c="27582">The </st><img src="image/4947.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.695em"/><st c="27587"/><st c="27588"> matrix in </st><em class="italic"><st c="27599">Eq.10</st></em><st c="27604"> is </st><img src="image/4948.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:2.124em"/><st c="27608"/><st c="27609"> and symmetric. </st><st c="27625">If we had many features, it would be a large matrix. </st><st c="27678">Since </st><img src="image/4949.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mover&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.216em;height:1.142em;width:1.145em"/><st c="27684"/><st c="27688">is derived from our data, which contains a random component, then</st><img src="image/4950.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mover&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.216em;height:1.142em;width:1.088em"/><st c="27753"/><st c="27757">is a large </st><span class="No-Break"><st c="27768">random matrix.</st></span></p>
			<p><st c="27782">The eigenvalues of  </st><img src="image/4951.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.759em"/><st c="27802"/><st c="27803">  tell us about the principal components in our dataset. </st><st c="27859">So, what would its eigenvalues look like? </st><st c="27901">Given that </st><img src="image/4952.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.660em"/><st c="27912"/><st c="27913"> is a large random matrix, should we expect some universal behavior in the distribution of eigenvalues from </st><img src="image/4945.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.634em"/><st c="28021"/><st c="28022">? Let’s do a numerical experiment to </st><span class="No-Break"><st c="28059">find out.</st></span></p>
			<p><st c="28068">For illustration purposes, we’ll use the simplest possible data matrix </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.646em"/><st c="28140"/><st c="28141"> , where we first draw the matrix elements </st><img src="image/4955.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.483em;height:1.131em;width:0.909em"/><st c="28183"/><st c="28184"> from </st><img src="image/4956.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mn&gt;0,1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.574em"/><st c="28190"/><st c="28191"> and then mean-center the columns. </st><st c="28226">The histogram in </st><span class="No-Break"><em class="italic"><st c="28243">Figure 15</st></em></span><em class="italic"><st c="28252">.4</st></em><st c="28254"> shows the approximate density of eigenvalues of a single sample covariance matrix generated in the way we have just described, with </st><img src="image/4957.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.660em;width:4.164em"/><st c="28387"/> <span class="No-Break"><st c="28388">and </st></span><span class="No-Break"><img src="image/4958.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:3.967em"/><st c="28392"/></span><span class="No-Break"><st c="28393">.</st></span></p>
			<div>
				<div id="_idContainer5110" class="IMG---Figure">
					<img src="image/B19496_15_4.jpg" alt="" role="presentation"/><st c="28394"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="28448">Figure 15.4: The distribution of sample covariance matrix eigenvalues</st></p>
			<p><st c="28517">The red line in </st><span class="No-Break"><em class="italic"><st c="28534">Figure 15</st></em></span><em class="italic"><st c="28543">.4</st></em><st c="28545"> is the </st><strong class="bold"><st c="28553">Marčenko-Pastur</st></strong><st c="28568"> distribution. </st><st c="28583">It is the equivalent of the semicircle law but for </st><a id="_idIndexMarker1217"/><st c="28634">covariance matrices formed from large random data matrices like </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.646em"/><st c="28698"/><st c="28699">. The Marčenko-Pastur formula for the density of eigenvalues, </st><img src="image/4960.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" style="vertical-align:-0.252em;height:1.013em;width:1.664em"/><st c="28761"/><st c="28765">, is give</st><a id="_idTextAnchor763"/><st c="28774">n </st><span class="No-Break"><st c="28777">by </st></span><span class="No-Break"><em class="italic"><st c="28780">Eq.11</st></em></span><span class="No-Break"><st c="28785">.</st></span></p>
			<p><img src="image/4961.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;{&quot; close=&quot;&quot;&gt;&lt;mtable columnwidth=&quot;auto&quot; columnalign=&quot;center&quot; rowspacing=&quot;1.0000ex&quot; rowalign=&quot;baseline baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;mtext&gt;for&lt;/mtext&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mtext&gt;otherwise&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-1.099em;height:2.705em;width:20.709em"/><st c="28786"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="28832">Eq.11</st></p>
			<p><st c="28837">The </st><img src="image/2470.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.555em"/><st c="28842"/><st c="28843"> value is the ratio of data to features. </st><st c="28884">That is, </st><img src="image/4963.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.044em;height:0.755em;width:3.813em"/><st c="28893"/><st c="28894"> , so </st><img src="image/2470.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.557em"/><st c="28899"/><st c="28900"> measures how non-square our matrix </st><img src="image/1054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.641em"/><st c="28936"/> <span class="No-Break"><st c="28937">is.</st></span></p>
			<p><st c="28940">Like the semicircle law, the Marčenko-Pastur distribution has finite support. </st><st c="29019">The </st><img src="image/4966.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.200em;height:0.911em;width:0.749em"/><st c="29023"/><st c="29024"> and </st><img src="image/4967.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:1.044em;width:0.766em"/><st c="29029"/><st c="29030"> values are the lower and upper ends of that support and are given by </st><span class="No-Break"><st c="29100">the</st><a id="_idTextAnchor764"/><st c="29103"> following:</st></span></p>
			<p><img src="image/4968.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.518em;height:1.717em;width:13.790em"/><st c="29114"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29116">Eq.12</st></p>
			<p><st c="29121">Strictly speaking, the Marčenko-Pastur formula in </st><em class="italic"><st c="29172">Eq.11</st></em><st c="29177"> is an asymptotic result. </st><st c="29203">It is the distribution of eigenvalues that we would get in the </st><img src="image/4969.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.037em"/><st c="29266"/><st c="29267"> limit, while also ensuring that </st><img src="image/4970.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.044em;height:0.755em;width:3.455em"/><st c="29300"/><st c="29308">. However, just like the semicircle law, it means we can also use the density in </st><em class="italic"><st c="29389">Eq.11</st></em><st c="29394"> as a very good approximation at finite </st><img src="image/115.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.008em;height:0.656em;width:0.706em"/><st c="29434"/><st c="29435"> and where we set </st><img src="image/4972.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.044em;height:0.755em;width:3.708em"/><st c="29453"/><st c="29454">. Also, just like the semicircle law, the Marčenko-Pastur formula in </st><em class="italic"><st c="29523">Eq.11</st></em><st c="29528"> is the average eigenvalue distribution that we would get in the </st><img src="image/1870.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;→&lt;/mml:mo&gt;&lt;mml:mi&gt;∞&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.028em;height:0.676em;width:3.165em"/><st c="29593"/><st c="29594"> limit. </st><st c="29602">The reason why it is such a good approximation to the single instance of a sample covariance matrix shown in </st><span class="No-Break"><em class="italic"><st c="29711">Figure 15</st></em></span><em class="italic"><st c="29720">.4</st></em><st c="29722"> is that the eigenvalue distribution of a large sample covariance matrix of the type generated in </st><span class="No-Break"><em class="italic"><st c="29820">Figure 15</st></em></span><em class="italic"><st c="29829">.4</st></em> <span class="No-Break"><st c="29831">is self-averaging.</st></span></p>
			<h2 id="_idParaDest-419"><a id="_idTextAnchor765"/><st c="29850">The Marčenko-Pastur distribution is a bulk distribution</st></h2>
			<p><st c="29906">Okay, so the Marčenko-Pastur distribution</st><a id="_idIndexMarker1218"/><st c="29948"> is a universal law for large sample covariance matrices, but how universal is it exactly? </st><st c="30039">The </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.645em"/><st c="30043"/><st c="30044"> data matrix generated in our numerical example contained only values drawn from </st><img src="image/4896.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mn&gt;0,1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.141em;height:0.789em;width:2.676em"/><st c="30125"/><st c="30126">. These would seem like just noise values, and so the result is not a very realistic </st><span class="No-Break"><st c="30211">data matrix.</st></span></p>
			<p><st c="30223">Actually, it is realistic. </st><st c="30251">In many real-world datasets and problems, we have lots of feature values. </st><st c="30325">Typically, many of these features are uninformative or have limited signal in them. </st><st c="30409">This means that in real-world datasets, the </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.681em"/><st c="30453"/><st c="30454"> data matrix can be overwhelmingly made up of noise. </st><st c="30507">Consequently, most of the eigenvalues of the resulting sample covariance matrix </st><img src="image/4945.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.637em"/><st c="30587"/><st c="30588"> still follow the Marčenko-Pastur distribution. </st><st c="30636">The Marčenko-Pastur distribution describes the </st><em class="italic"><st c="30683">bulk</st></em><st c="30687"> of the eigenvalues of </st><img src="image/4978.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.658em"/><st c="30710"/><st c="30711">, even for real-world data </st><span class="No-Break"><st c="30738">matrices </st></span><span class="No-Break"><img src="image/1054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.641em"/><st c="30747"/></span><span class="No-Break"><st c="30748">.</st></span></p>
			<h2 id="_idParaDest-420"><a id="_idTextAnchor766"/><st c="30749">Universality in the singular values of </st><img src="image/4980.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.874em;width:0.901em"/><st c="30789"/></h2>
			<p><st c="30792">We have already encountered the definition of  </st><img src="image/4945.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.648em"/><st c="30838"/><st c="30839">  in </st><em class="italic"><st c="30843">Eq.10</st></em><st c="30848">. We also came across it in </st><a href="B19496_03.xhtml#_idTextAnchor141"><span class="No-Break"><em class="italic"><st c="30876">Chapter 3</st></em></span></a><st c="30885">, where we learned about the link between singular values from the SVD of the data matrix </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.645em"/><st c="30975"/><st c="30976"> and eigenvalues of the sample covariance matrix </st><img src="image/4978.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.656em"/><st c="31025"/><st c="31026"> calculated from </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.647em"/><st c="31043"/><st c="31044">. From this link, we know that if </st><img src="image/4985.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:1.051em;width:0.579em"/><st c="31078"/><st c="31079"> is an eigenvalue of </st><img src="image/4952.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.670em"/><st c="31100"/><st c="31101"> , then </st><img src="image/4987.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msqrt&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:msqrt&gt;&lt;/mml:math&gt;" style="vertical-align:-0.380em;height:1.398em;width:4.373em"/><st c="31108"/><st c="31117"> is a singular value of </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.651em"/><st c="31140"/><st c="31141">. It immediately follows that if all or most of the eigenvalues of </st><img src="image/4945.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.646em"/><st c="31208"/><st c="31209"> follow a universal distribution when the number of features </st><img src="image/471.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.511em"/><st c="31270"/><st c="31271"> is large, then the singular values of </st><img src="image/1279.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.653em"/><st c="31310"/><st c="31311"> must also follow a universal distribution. </st><st c="31355">See whether you can derive what this universal distribution should be using the relationship between the eigenvalues of </st><img src="image/4952.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.664em"/><st c="31475"/><st c="31476"> and the singular values of </st><img src="image/1054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.641em"/><st c="31504"/><st c="31505"> and the rules for transforming probability densities that we learned about in </st><a href="B19496_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic"><st c="31584">Chapter 2</st></em></span></a><span class="No-Break"><st c="31593">.</st></span></p>
			<p><st c="31594">Overall, this means that we can also see universal behavior in the singular values of some large non-square matrices, not just square ones. </st><st c="31735">This has become particularly useful in the field of deep learning neural networks, as we shall learn </st><span class="No-Break"><st c="31836">about next.</st></span></p>
			<h2 id="_idParaDest-421"><a id="_idTextAnchor767"/><st c="31847">The Marčenko-Pastur distribution and neural networks</st></h2>
			<p><st c="31900">One of the </st><a id="_idIndexMarker1219"/><st c="31912">most interesting areas of RMT research that has emerged over the last decade or so, and that is of relevance to the field of data science, is the role that the Marčenko-Pastur distribution plays in characterizing the properties of weight matrices in large </st><span class="No-Break"><st c="32168">neural networks.</st></span></p>
			<p><st c="32184">You’re probably familiar with the idea that feed-forward neural networks consist of layers of nodes that are connected via weights. </st><st c="32317">The weights, along with the output values from the preceding layer in the network, feed into a transfer function to compute the output values of the current layer. </st><st c="32481">The schematic in </st><span class="No-Break"><em class="italic"><st c="32498">Figure 15</st></em></span><em class="italic"><st c="32507">.5</st></em><st c="32509"> shows such a</st><a id="_idTextAnchor768"/><st c="32522"> neural </st><span class="No-Break"><st c="32530">network structure.</st></span></p>
			<div>
				<div id="_idContainer5146" class="IMG---Figure">
					<img src="image/B19496_15_5.jpg" alt="" role="presentation"/><st c="32548"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="32659">Figure 15.5: The schematic of a feed-forward neural network</st></p>
			<p><st c="32718">The number of nodes in the initial input layer can be very large due to the large number of features that are input into the network. </st><st c="32853">This is particularly true for modern deep learning neural networks, where large data volumes mean it is realistic to try and learn the relationship between high-dimensional feature vectors and the target variable. </st><st c="33067">Therefore, the number of nodes, </st><img src="image/4994.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;/mml:math&gt;" style="vertical-align:-0.333em;height:0.981em;width:1.234em"/><st c="33099"/><st c="33100"> in the input layer will typically be large. </st><st c="33145">As a consequence, for subsequent layers </st><img src="image/4995.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;&gt;&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:2.278em"/><st c="33185"/><st c="33189">, the number of nodes </st><img src="image/4996.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" style="vertical-align:-0.340em;height:0.988em;width:0.820em"/><st c="33211"/><st c="33212"> will also </st><span class="No-Break"><st c="33223">be large.</st></span></p>
			<p><st c="33232">The number of nodes in a layer is usually less than the number of nodes in the preceding layer, as each layer is forced to learn an efficient representation of the information coming from the preceding layer. </st><st c="33442">This means that we will also have </st><img src="image/4997.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;&lt;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.340em;height:0.988em;width:3.437em"/><st c="33476"/><st c="33477">. Consequently, the weight matrix, </st><img src="image/4998.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;W&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.211em;height:0.988em;width:2.394em"/><st c="33512"/><st c="33516">, connecting layer </st><img src="image/2620.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.248em"/><st c="33535"/><st c="33536"> to layer </st><img src="image/5000.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:1.808em"/><st c="33546"/><st c="33547"> will be a large </st><span class="No-Break"><st c="33564">non-square matrix.</st></span></p>
			<p><st c="33582">Since the weight matrix </st><img src="image/5001.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;W&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.211em;height:0.988em;width:2.413em"/><st c="33607"/><st c="33612"> represents the interactions between nodes in layer </st><img src="image/2620.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.246em"/><st c="33663"/><st c="33664"> and nodes in layer </st><img src="image/5003.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:1.799em"/><st c="33684"/><st c="33685">, you will not be surprised to find that the distribution of its singular values can be studied using the tools of RMT. </st><st c="33805">In fact, it is usual to find that the distribution of the singular values of </st><img src="image/5004.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;W&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" style="vertical-align:-0.211em;height:0.988em;width:2.478em"/><st c="33882"/><st c="33886"> can be described using the Marčenko-Pastur distribution. </st><st c="33943">Again, the details are too extensive to go into in this short introduction – see, for example, the third point in the </st><em class="italic"><st c="34061">Notes and further reading</st></em><st c="34086"> section at the end of this </st><a id="_idIndexMarker1220"/><st c="34114">chapter. </st><st c="34123">However, it does illustrate once more that RMT is not an esoteric branch of mathematics, but a math concept of genuine relevance to data science and data </st><span class="No-Break"><st c="34277">science algorithms.</st></span></p>
			<p><st c="34296">This has been a whirlwind tour of the Marčenko-Pastur distribution and its applications, so it’s time to recap what we have learned in this section and wrap up the chapter as </st><span class="No-Break"><st c="34472">a whole.</st></span></p>
			<h2 id="_idParaDest-422"><a id="_idTextAnchor769"/><st c="34480">What we learned</st></h2>
			<p><st c="34496">In this section, we have learned about </st><span class="No-Break"><st c="34536">the following:</st></span></p>
			<ul>
				<li><st c="34550">The distribution of all or most of the eigenvalues of the sample covariance matrix calculated from a large data matrix displays a </st><span class="No-Break"><st c="34681">universal behavior</st></span></li>
				<li><st c="34699">The Marčenko-Pastur distribution and how it is the equivalent of the semicircle law for sample </st><span class="No-Break"><st c="34795">covariance matrices</st></span></li>
				<li><st c="34814">How large non-square matrices can display universal behavior in the distribution of their singular values and how this distribution can be derived from the </st><span class="No-Break"><st c="34971">Marčenko-Pastur distribution</st></span></li>
				<li><st c="34999">The tools of RMT are applied to understand the behavior of weight matrices in large deep-learning </st><span class="No-Break"><st c="35098">neural networks</st></span></li>
			</ul>
			<h1 id="_idParaDest-423"><a id="_idTextAnchor770"/><st c="35113">Summary</st></h1>
			<p><st c="35121">This chapter was about random matrices. </st><st c="35162">What started out sounding like an esoteric plaything of mathematicians turned out to be a commonly occurring concept in data science with many applications. </st><st c="35319">The tools to study random matrices come from RMT. </st><st c="35369">These tools can be very mathematically advanced, so we have only given an overview of the main results of RMT and what the implications of those results are. </st><st c="35527">We did not attempt to go into the derivations of those results. </st><st c="35591">However, we had to learn about several new concepts. </st><st c="35644">Those new concepts include </st><span class="No-Break"><st c="35671">the following:</st></span></p>
			<ul>
				<li><st c="35685">A random matrix is a matrix whose matrix elements are drawn from </st><span class="No-Break"><st c="35751">a distribution</st></span></li>
				<li><st c="35765">Random matrices are studied </st><span class="No-Break"><st c="35794">using RMT</st></span></li>
				<li><st c="35803">Large random matrices can display </st><span class="No-Break"><st c="35838">universal behavior</st></span></li>
				<li><st c="35856">A large-scale interacting system can be modeled as a large </st><span class="No-Break"><st c="35916">random matrix</st></span></li>
				<li><st c="35929">The Wigner </st><span class="No-Break"><st c="35941">semicircle law</st></span></li>
				<li><st c="35955">The GOE, GUE, and GSE families </st><span class="No-Break"><st c="35987">of matrices</st></span></li>
				<li><st c="35998">The </st><span class="No-Break"><st c="36003">Marčenko-Pastur distribution</st></span></li>
				<li><st c="36031">The bulk of the eigenvalues of a sample covariance matrix follow the </st><span class="No-Break"><st c="36101">Marčenko-Pastur distribution</st></span></li>
				<li><st c="36129">The tools of RMT are applied to understand the behavior of weight matrices in large deep-learning </st><span class="No-Break"><st c="36228">neural networks.</st></span></li>
			</ul>
			<p><st c="36244">This has been our last chapter. </st><st c="36277">Throughout this book, we covered a lot of material. </st><st c="36329">However, there are a vast number of mathematical topics that we haven’t covered. </st><st c="36410">That is okay. </st><st c="36424">By taking you on a journey through just 15 major math concepts that occur in data science and unpacking their nuances, we have equipped you with the skills to tackle any data science algorithm or idea on your own. </st><st c="36638">Thank you for allowing me to be your guide for that math journey. </st><st c="36704">I hope that you have enjoyed the journey as much as </st><span class="No-Break"><st c="36756">I have.</st></span></p>
			<h1 id="_idParaDest-424"><a id="_idTextAnchor771"/><st c="36763">Exercises</st></h1>
			<p><st c="36773">The following is a series of exercises. </st><st c="36814">Answers to all the exercises are given in the </st><strong class="source-inline"><st c="36860">Answers_to_Exercises_Chap15.ipynb</st></strong><st c="36893"> Jupyter notebook in the </st><span class="No-Break"><st c="36918">GitHub repository.</st></span></p>
			<ol>
				<li><st c="36936">Create a </st><img src="image/5005.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.919em"/><st c="36946"/><st c="36947"> symmetric matrix </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.875em"/><st c="36965"/><st c="36979"> using the </st><span class="No-Break"><st c="36989">following relationship:</st></span></li>
			</ol>
			<p><img src="image/5007.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;munder&gt;&lt;munder&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mo stretchy=&quot;true&quot;&gt;_&lt;/mo&gt;&lt;/munder&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;⊤&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.437em;height:1.401em;width:5.707em"/><st c="37012"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37025">Eq.13</st></p>
			<p class="list-inset"><st c="37030">The </st><img src="image/578.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.863em;width:0.685em"/><st c="37035"/><st c="37036"> matrix should have its matrix elements drawn from the standard normal distribution with a probability of 0.5, and from the mean-zero unit-variance Laplace distribution in </st><em class="italic"><st c="37208">Eq.4</st></em><st c="37212">, with a probability of 0.5. </st><st c="37241">Calculate the eigenvalues, </st><img src="image/826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.484em"/><st c="37268"/><st c="37269">, of </st><img src="image/89.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.877em"/><st c="37274"/><st c="37288"> and compute the empirical density of scaled eigenvalues </st><img src="image/4832.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:2.233em"/><st c="37344"/><st c="37345">. Compare this empirical density to the semicircle law </st><span class="No-Break"><st c="37400">in </st></span><span class="No-Break"><em class="italic"><st c="37403">Eq.2</st></em></span><span class="No-Break"><st c="37407">.</st></span></p>
			<p class="callout-heading"><st c="37408">Tip</st></p>
			<p class="callout"><st c="37412">You can draw a value </st><img src="image/5012.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.466em"/><st c="37434"/><st c="37435"> from the mean-zero unit-variance Laplace distribution by first drawing a value </st><img src="image/5013.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.532em"/><st c="37515"/><st c="37516"> from the uniform distribution, </st><img src="image/5014.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;u&lt;/mi&gt;&lt;mtext&gt;niform&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.167em;height:0.878em;width:7.471em"/><st c="37548"/><st c="37567">, then calculating </st><img src="image/5012.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.472em"/><st c="37586"/> <span class="No-Break"><st c="37587">as follows:</st></span></p>
			<p class="callout"><img src="image/5016.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msqrt&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msqrt&gt;&lt;/mfrac&gt;&lt;mtext&gt;sign&lt;/mtext&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;/mfenced&gt;&lt;mi&gt;ln&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-0.530em;height:1.465em;width:10.862em"/><st c="37598"/></p>
			<p class="callout"><span class="No-Break"><st c="37623">Eq.14</st></span></p>
			<p class="list-inset"><st c="37628">Alternatively, you can use the </st><strong class="source-inline"><st c="37660">numpy.random.laplace</st></strong><st c="37680"> NumPy function to sample the </st><span class="No-Break"><st c="37710">values directly.</st></span></p>
			<p><st c="37726">2.	</st><st c="37730">From the definition of the GUE in </st><em class="italic"><st c="37764">Eq.7</st></em><st c="37768">, generate a </st><img src="image/5005.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;2000&lt;/mml:mn&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.646em;width:4.919em"/><st c="37781"/><st c="37782"> GUE matrix and compute its eigenvalues </st><img src="image/3464.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.504em"/><st c="37822"/><st c="37823">. Compute the empirical probability density of scaled eigenvalues </st><img src="image/5019.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msqrt&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:msqrt&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.048em;height:0.866em;width:2.818em"/><st c="37889"/><st c="37890"> and compare it to the semicircle law </st><span class="No-Break"><st c="37928">in </st></span><span class="No-Break"><em class="italic"><st c="37931">Eq.2</st></em></span><span class="No-Break"><st c="37935">.</st></span></p>
			<p><st c="37936">3.	</st><st c="37940">Assume that all the eigenvalues </st><img src="image/826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.483em"/><st c="37972"/><st c="37973"> of a sample covariance matrix </st><img src="image/4945.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;" style="vertical-align:-0.216em;height:1.142em;width:0.641em"/><st c="38004"/><st c="38005"> are distributed according to the Marčenko-Pastur distribution given in </st><em class="italic"><st c="38077">Eq.11</st></em><st c="38082">. The sample covariance matrix has been calculated from a mean-centered data matrix </st><img src="image/1054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.647em"/><st c="38166"/><st c="38167">. The singular values </st><img src="image/5023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.672em"/><st c="38189"/><st c="38190"> of </st><img src="image/1054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:munder underaccent=&quot;false&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;X&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;/mml:munder&gt;&lt;/mml:math&gt;" style="vertical-align:-0.201em;height:0.848em;width:0.647em"/><st c="38194"/><st c="38195"> are related to the eigenvalues </st><img src="image/826.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.723em;width:0.483em"/><st c="38227"/><st c="38228"> via </st><img src="image/5026.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;λ&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" style="vertical-align:-0.058em;height:0.769em;width:6.367em"/><st c="38233"/><st c="38234">. Use this relationship to derive the probability density of the singular </st><span class="No-Break"><st c="38308">values </st></span><span class="No-Break"><img src="image/5023.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:math&gt;" style="vertical-align:-0.012em;height:0.460em;width:0.669em"/><st c="38315"/></span><span class="No-Break"><st c="38316">.</st></span></p>
			<h1 id="_idParaDest-425"><a id="_idTextAnchor772"/><st c="38317">Notes and further reading</st></h1>
			<ol>
				<li value="1"><st c="38343">If you want to learn more about the mathematical details behind RMT, the book </st><em class="italic"><st c="38422">Introduction to Random Matrices: Theory and Practice</st></em><st c="38474"> by G. </st><st c="38481">Livan, M. </st><st c="38491">Novaes, and P. </st><st c="38506">Vivo (ISBN: 978-3319708836, Springer, 2018), is a good start. </st><st c="38568">You can find a copy of the material on the arXiv archive at </st><a href="https://arxiv.org/pdf/1712.07903.pdf"><st c="38628">https://arxiv.org/pdf/1712.07903.pdf</st></a><st c="38664">. Be aware that the material can get </st><span class="No-Break"><st c="38701">mathematically advanced.</st></span></li>
				<li><st c="38725">For a readable and short introduction to quaternions, I recommend </st><em class="italic"><st c="38792">Introducing the Quaternions</st></em><st c="38819"> by J. </st><st c="38826">Huerta, which you can find </st><span class="No-Break"><st c="38853">at </st></span><a href="https://math.ucr.edu/~huerta/introquaternions.pdf"><span class="No-Break"><st c="38856">https://math.ucr.edu/~huerta/introquaternions.pdf</st></span></a><span class="No-Break"><st c="38905">.</st></span></li>
				<li><st c="38906">A good recent paper on the application of RMT to studying neural network weight matrices is C.H. </st><st c="39004">Martin and M.W. </st><st c="39020">Mahoney’s </st><em class="italic"><st c="39030">Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning</st></em><st c="39148"> from the Journal of Machine Learning Research, </st><span class="No-Break"><st c="39196">22:1-73, 2021.</st></span></li>
				<li><st c="39210">The recent book, </st><em class="italic"><st c="39228">Random Matrix Methods for Machine Learning</st></em><st c="39270"> by R. </st><st c="39277">Couillet and Z. </st><st c="39293">Liao (ISBN: 978-1009123235, Cambridge University Press, 2022), also has a chapter on RMT and large neural networks, as well as on other areas of machine learning including some of the topics we have covered in earlier chapters in this book, such as kernel methods and community detection. </st><st c="39582">You can find a copy of the material at one of the authors’ GitHub sites </st><span class="No-Break"><st c="39654">at </st></span><a href="https://zhenyu-liao.github.io/pdf/RMT4ML.pdf"><span class="No-Break"><st c="39657">https://zhenyu-liao.github.io/pdf/RMT4ML.pdf</st></span></a><span class="No-Break"><st c="39701">.</st></span></li>
			</ol>
		</div>
	<div id="charCountTotal" value="39702"/></body></html>