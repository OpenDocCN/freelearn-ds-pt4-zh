- en: <st c="0">1</st><st c="2">5</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="3">Random Matrices</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="18">This is our final chapter.</st> <st c="46">It is about random matrices.</st>
    <st c="75">That name may sound esoteric or even abstract.</st> <st c="122">It
    suggests that random matrices may not be a very useful thing to learn about.</st>
    <st c="202">However, by now, you’ll be very used to the idea that randomness is
    everywhere in data science.</st> <st c="298">Dealing with matrices is a core part
    of data science as well, so maybe a random matrix is not so esoteric after all.</st>
    <st c="415">This chapter will emphasize the idea that random matrices can be found
    everywhere in data science and are a useful way of representing large-scale interacting
    systems.</st> <st c="583">That means that we must become familiar with the tools
    used to study random matrices.</st> <st c="669">We will only very briefly introduce
    the main results and concepts connected to random matrices, so this will be a
    short chapter.</st> <st c="798">In it, we will cover the</st> <st c="823">following
    topics:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="840">What is a random matrix</st>*<st c="864">: In this section, we
    introduce the basic idea of what a random matrix is and why they are common in</st>
    <st c="966">data science</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<st c="978">Using random matrices to represent interactions in large-scale
    systems</st>*<st c="1049">: In this section, we introduce the idea that large
    random matrices are a natural way to represent and model large-scale</st> <st
    c="1171">interacting systems</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<st c="1190">Universal behavior of large random matrices</st>*<st c="1234">:
    In this section, we show how large random matrices start to behave in a similar
    way to</st> <st c="1324">each other</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<st c="1334">Random matrices and high-dimensional covariance matrices</st>*<st
    c="1391">: In this section, we show how universal behavior is also seen in covariance
    matrices, which are a core part of statistical and machine learning models, and
    where we also learn how random matrix theory is used to understand the behavior
    of large</st> <st c="1638">neural networks</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1653">Technical requirements</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1676">There are no code examples in this chapter, but Jupyter notebook-based
    answers to the exercises at the end of the chapter can be found at</st> [<st c="1815">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter15</st>](https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter15)<st
    c="1919">. To run the Jupyter notebook, you will need a full Python installation,
    including the</st> <st c="2006">following packages:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="2025">numpy</st>` <st c="2031">(>=</st> <st c="2036">1.24.3)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<st c="2043">matplotlib</st>` <st c="2054">(>=3.7.2)</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2064">What is a random matrix?</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2089">A random matrix</st> <st c="2105">sounds like it is some esoteric
    mathematical object – the sort of thing that is studied by mathematicians for
    fun but is of no practical use.</st> <st c="2248">Why should you care about random
    matrices as a</st> <st c="2295">data scientist?</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2310">As a data scientist, you have already been working with matrices.</st>
    <st c="2377">You know that they are useful.</st> <st c="2408">You know that a
    matrix is made up of matrix elements and that those elements are often formed
    from data.</st> <st c="2513">By now, you’re also most likely used to the idea
    that data has a random component, so a matrix formed from data must also have
    random matrix elements.</st> <st c="2664">This is what a random matrix is.</st>
    <st c="2697">A random matrix is just a matrix whose elements are drawn from a
    distribution.</st> **<st c="2776">Random Matrix Theory</st>** <st c="2796">(</st>**<st
    c="2798">RMT</st>**<st c="2801">) is the</st> <st c="2810">study of the properties
    of</st> <st c="2838">random matrices.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2854">Usually, in RMT, the matrix elements are</st> <st c="2895">taken
    to be</st> **<st c="2908">independent and identically distributed random variables</st>**
    <st c="2964">(</st>**<st c="2966">iid</st>**<st c="2969">), but recent research
    in the RMT field has extended this to looking at more structured randomness.</st>
    <st c="3070">Also, early work in the RMT field looked at square, that is,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:math>](img/726.png)<st
    c="3131"><st c="3147">, matrices.</st> <st c="3159">In doing so, RMT discovered
    that as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/1872.png)<st
    c="3195"><st c="3196">, these square random matrices develop some</st> <st c="3240">interesting
    properties.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3263">Again, these RMT discoveries may sound esoteric.</st> <st c="3313">However,
    as data scientists, we often work with big data, so we often work with large matrices
    with a random component.</st> <st c="3433">This means that results from the RMT
    field can be particularly relevant to</st> <st c="3508">data science.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3521">We have motivated this section by highlighting that as data scientists,
    we naturally work with large random matrices.</st> <st c="3640">However, the original
    motivation for RMT was to understand large-scale interacting systems.</st> <st
    c="3732">Since interacting systems are also often what we are tasked with analyzing
    as data scientists, it is instructive to understand this original motivation for
    RMT.</st> <st c="3893">This is what we will do in the next section, but for now,
    we’ll recap what we have learned</st> <st c="3984">so far.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3991">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="4007">In this section, we learned</st> <st c="4036">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4050">A random matrix</st> <st c="4066">is a matrix whose matrix elements
    are drawn from</st> <st c="4116">a distribution.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4131">Since data contains a random element, a matrix formed from data
    can be thought of as a</st> <st c="4219">random matrix.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4233">RMT is</st> <st c="4240">the mathematical field that studies</st>
    <st c="4277">random matrices.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4293">When random matrices become large in terms of the number of matrix
    elements that they contain, they develop</st> <st c="4402">interesting properties.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4425">Having thus learned what a random matrix is at a very basic level,
    in the next section, we’ll see how they can be used to represent large-scale</st>
    <st c="4570">interacting systems.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4590">Using random matrices to represent interactions in large-scale
    systems</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="4661">In</st> [*<st c="4665">Chapter 10</st>*](B19496_10.xhtml#_idTextAnchor501)<st
    c="4675">, we</st> <st c="4680">encountered the adjacency matrix method for representing
    a network.</st> <st c="4748">A network also represents a set of components, the
    nodes, and the network edges can be used to represent the pairwise interactions
    between the nodes.</st> *<st c="4898">Figure 15</st>**<st c="4907">.1</st>* <st
    c="4909">gives an example of a network and its adjacency</st> <st c="4958">matrix
    representatio</st><st c="4978">n.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.1: Network interactions represented as a matrix](img/B19496_15_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="5085">Figure 15.1: Network interactions represented as a matrix</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5142">It is</st> <st c="5148">natural to use a matrix to represent pairwise
    interactions between elements of any interacting system and not just between nodes
    in a network.</st> <st c="5292">Some of these systems may be physical, such as
    particles interacting via some force.</st> <st c="5377">They may also be non-physical,
    where the components of the system do not directly exert forces on each other
    but may influence each other, such as correlations between the share prices of
    different companies listed on a</st> <st c="5597">stock market.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5610">Many of the systems that we study can be large, particularly real
    physical systems.</st> <st c="5695">Therefore, the interactions can be represented
    by a large matrix.</st> <st c="5761">The matrix elements that we use encode the
    strengths of the pairwise interactions between the components of the system.</st>
    <st c="5881">They can differ in strength, but aside from this, we believe that
    the interactions are all of the same qualitative type.</st> <st c="6002">Consequently,
    we can consider the interaction strengths as being values sampled from the same
    distribution.</st> <st c="6110">Therefore, the interaction matrix is a large random
    matrix, and we are using the large random matrix as a way of representing our
    real system.</st> <st c="6253">To study these systems, we need tools that study
    large random matrices, that is, RMT.</st> <st c="6339">Unsurprisingly, RMT has
    been applied to many different interacting systems in many different fields, including</st>
    <st c="6450">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="6464">Energy levels of large atomic nuclei</st>**<st c="6501">: This
    was the original application of RMT and stimulated the early development of RMT
    as an area of mathematical research.</st> <st c="6626">Most of the ideas that
    we will introduce in the next section were discovered because of this RMT work
    on</st> <st c="6731">heavy nuclei.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="6744">Neuroscience</st>**<st c="6757">: Large-scale neuronal networks
    are modeled as pairwise connections, and hence dynamic interactions, between neurons
    in</st> <st c="6878">the brain.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="6888">Finance</st>**<st c="6896">: Correlations between the daily
    stock market movements of different stocks are modeled using a large</st> <st
    c="6999">random matrix.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="7013">Even if a system consists of more than pairwise interactions, it
    is not uncommon to model it with just pairwise interactions, as a pairwise interacting
    system is the simplest model of an interacting system we can have.</st> <st c="7233">The
    model interaction strengths in these cases represent effective interactions –
    they encapsulate the combined effects of the real pairwise interaction, as well
    as the real 3</st><st c="7408">rd</st><st c="7411">-order interactions, the real
    4</st><st c="7443">th</st><st c="7446">-order interactions, and so on.</st> <st
    c="7479">Again, this means that we can understand a lot about the behavior of
    these real systems by looking at the behavior of their random</st> <st c="7610">matrix
    models.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7624">Using</st> <st c="7631">RMT to study large-scale interacting systems
    is particularly insightful, as we find that large random matrices follow universal
    laws.</st> <st c="7765">It is RMT that uncovers those laws.</st> <st c="7801">We
    will introduce this universal behavior in the next section, so for now, let’s
    recap what we</st> <st c="7896">have learned.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7909">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="7925">In this section, we learned</st> <st c="7954">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7968">A system with pairwise interactions can be represented as</st>
    <st c="8027">a matrix.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8036">A large-scale interacting system can be modeled as a large</st>
    <st c="8096">random matrix.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8110">We can use the tools of RMT to study the behavior of large-scale</st>
    <st c="8176">interacting systems.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8196">Having learned that many large-scale interacting systems can be
    modeled as large random matrices and studied using the tools of RMT, in the next
    section, we will learn about some of the universal laws that large random</st>
    <st c="8416">matrices follow.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8432">Universal behavior of large random matrices</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="8476">We have already mentioned that when</st> <st c="8513">random matrices
    become large, they begin to display some interesting behaviors.</st> <st c="8593">However,
    what do we mean by this and why is it useful to us as</st> <st c="8656">data scientists?</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8672">The interesting behavior that we see is that the statistical properties
    of their eigen-decompositions or singular-value decompositions become</st> **<st
    c="8815">universal</st>**<st c="8824">. By universal, we mean that the same behavior
    is seen across many different matrices.</st> <st c="8911">In the case that we’re
    going to illustrate, it means that the statistical characteristics of the eigen-decomposition
    of any large square random matrix are</st> <st c="9066">the same.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9075">It is worth recalling from</st> [*<st c="9103">Chapter 3</st>*](B19496_03.xhtml#_idTextAnchor141)
    <st c="9112">that eigen-decompositions of square matrices are an important and
    flexible way of representing any square matrix.</st> <st c="9227">So, universality
    in parts of the eigen-decomposition of large random matrices also means that calculations
    and algorithms involving the matrices will have universal aspects to them.</st>
    <st c="9409">It won’t matter which matrix</st> <st c="9438">we have, we will get
    the same result for certain aspects of</st> <st c="9498">the calculation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9514">By now, you’re probably curious to see what this universal behavior
    in the eigen-decomposition of large random matrices is in more detail, so we’ll
    illustrate it with a numerical example.</st> <st c="9703">We’ll illustrate what
    is known as the</st> **<st c="9741">Wigner</st>** **<st c="9748">semicircle law</st>**<st
    c="9762">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9763">The Wigner semicircle law</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="9789">Matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4799.png)
    <st c="9797"><st c="9800">is a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4800.png)
    <st c="9805"><st c="9806">symmetric</st> <st c="9816">random matrix that I have
    generated.</st> <st c="9854">It has been created from matrix</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4801.png)
    <st c="9886"><st c="9888">using the</st> <st c="9898">following equation:</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfenced
    separators=""><mml:mrow><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:math>](img/4802.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="9919">Eq.1</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9923">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4803.png)
    <st c="9928"><st c="9930">matrix is a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4804.png)
    <st c="9942"><st c="9943">random matrix.</st> <st c="9959">All of its matrix elements
    are i.i.d.</st> <st c="9997">and drawn from the standard normal distribution,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced></mml:math>](img/4805.png)<st
    c="10046"><st c="10047">. The calculation in</st> *<st c="10068">Eq.1</st>* <st
    c="10072">ensures that the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4806.png)
    <st c="10090"><st c="10092">matrix is symmetric, even though</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4801.png)
    <st c="10125"><st c="10127">isn’t.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10133">Matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4808.png)
    <st c="10141"><st c="10144">is also a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4809.png)
    <st c="10154"><st c="10155">symmetric random matrix.</st> <st c="10181">I have
    generated it in a similar way to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4810.png)
    <st c="10221"><st c="10224">but using a matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4811.png)
    <st c="10243"><st c="10245">in</st> *<st c="10248">Eq.1</st>* <st c="10252">instead
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4803.png)<st
    c="10264"><st c="10266">. Like matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4803.png)<st
    c="10280"><st c="10282">, the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4811.png)
    <st c="10288"><st c="10290">matrix is a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4804.png)
    <st c="10302"><st c="10303">random matrix and all its matrix elements are i.i.d.</st>
    <st c="10357">and drawn</st> <st c="10367">from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced></mml:math>](img/4816.png)<st
    c="10372"><st c="10373">.</st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10374">Although the two matrices,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4817.png)
    <st c="10402"><st c="10404">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4818.png)<st
    c="10408"><st c="10409">, are generated in the same way, they are two different
    matrices.</st> <st c="10475">They have different matrix elements that are generated
    independently from each other.</st> <st c="10561">Each matrix has</st> ![<math
    xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mn>2000</mn><mo>×</mo><mn>2000</mn><mo>=</mo><mn>4</mn><msup><mrow><mo>×</mo><mn>10</mn></mrow><mn>6</mn></msup></mrow></mrow></math>](img/4819.png)
    <st c="10577"><st c="10578">matrix elements.</st> <st c="10596">There are a lot
    of ways in which matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4820.png)
    <st c="10636"><st c="10638">can be different from matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4821.png)<st
    c="10667"><st c="10668">.</st> *<st c="10670">Figure 15</st>**<st c="10679">.2</st>*
    <st c="10681">shows histograms of the scaled eigenvalues of each matrix – the
    left-hand panel shows the histogram for matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4822.png)<st
    c="10793"><st c="10796">, while the right-hand panel shows the histogram for matrix</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4823.png)<st
    c="10856"><st c="10859">.</st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_15_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="10955">Figure 15.2: Histograms of scaled eigenvalues for two large symmetric
    random matrices with Gaussian matrix elements</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11070">The</st> *<st c="11075">x</st>* <st c="11076">axis in</st> <st
    c="11084">both plots shows the</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>λ</mi><mo>/</mo><msqrt><mi>N</mi></msqrt><mi
    mathvariant="normal">s</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">a</mi><mi
    mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi><mi
    mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">g</mi><mi
    mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">v</mi><mi
    mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">u</mi><mi
    mathvariant="normal">e</mi></mrow></mrow></math>](img/4824.png)<st c="11106"><st
    c="11129">, with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4825.png)
    <st c="11136"><st c="11137">in this case.</st> <st c="11152">So, for each matrix,
    we have taken its eigenvalues</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/4826.png)
    <st c="11203"><st c="11219">and divided them by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:math>](img/4827.png)<st
    c="11239"><st c="11240">. The histograms are an estimate of the probability density
    of the</st> <st c="11307">scaled eigenvalues.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11326">What is remarkable is how similar the two histograms are, despite
    the matrices having a huge number of differences between them in terms of their
    individual matrix elements.</st> <st c="11501">The presence of the red line in</st>
    *<st c="11533">Figure 15</st>**<st c="11542">.2</st>*<st c="11544">, which follows
    the shape of the two histograms, suggests that I expected the histograms to have</st>
    <st c="11641">this shape.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11652">The red line is known as the semicircle law.</st> <st c="11698">Sometimes,
    you will see it referred to as the</st> **<st c="11744">Wigner semicircle distribution</st>**<st
    c="11774">, after</st> <st c="11781">Eugene Wigner, the famous theoretical physicist
    who used random matrices to study the properties of atomic nuclei.</st> <st c="11897">The
    semicircle law says that in the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/1873.png)
    <st c="11933"><st c="11934">limit, the probability density of the scaled eigenvalues
    tends to the density given</st> <st c="12019">by</st> *<st c="12022">Eq.2</st>*<st
    c="12026">.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>p</mml:mi><mml:mfenced separators=""><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:msqrt><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo>−</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo>≤</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo> </mml:mo></mml:math>](img/4829.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="12029">Eq.2</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12033">The red line in</st> *<st c="12050">Figure 15</st>**<st c="12059">.2</st>*
    <st c="12061">is the equation in</st> *<st c="12081">Eq.2</st>* <st c="12085">with</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4830.png)<st
    c="12091"><st c="12092">. The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:math>](img/4831.png)
    <st c="12098"><st c="12104">mathematical form in</st> *<st c="12125">Eq.2</st>*
    <st c="12129">tells us that this function will have a shape related to a semicircle,
    hence the origin of the name</st> *<st c="12230">semicircle law</st>* <st c="12244">(or</st>
    <st c="12249">semicircle distribution).</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12274">There are a few things we should point out about the result</st>
    <st c="12335">in</st> *<st c="12338">Eq.2</st>*<st c="12342">:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12344">It is an asymptotic result.</st> <st c="12372">We have said that
    it is the probability density of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4832.png)
    <st c="12423"><st c="12424">that we get in the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/1870.png)
    <st c="12444"><st c="12445">limit.</st> <st c="12453">This may not seem like a
    very useful result, as no real-world matrix is of infinite size.</st> <st c="12543">However,
    it means that for large but finite values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)<st
    c="12597"><st c="12598">, the density in</st> *<st c="12615">Eq.2</st>* <st c="12619">will
    still be a very good approximation for the probability density of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4832.png)<st
    c="12691"><st c="12692">. At large but finite values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)<st
    c="12724"><st c="12725">, we will see some deviations from the semicircle law.</st>
    <st c="12780">However, they will be small, and they will get smaller as</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="12838"><st c="12839">increases.</st> <st c="12851">As we can see from</st>
    *<st c="12870">Figure 15</st>**<st c="12879">.2</st>*<st c="12881">, at</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4838.png)<st
    c="12886"><st c="12887">, the semicircle law is a very good approximation for
    the density of scaled eigenvalues.</st> <st c="12976">I have even seen the semicircle
    law being used as a reasonable approximation for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>50</mml:mn><mml:mo>×</mml:mo><mml:mn>50</mml:mn></mml:math>](img/4839.png)
    <st c="13057"><st c="13058">matrices.</st></st></st></st></st></st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="13067">You’ll also notice the finite support of the semicircular law
    in</st> *<st c="13133">Eq.2</st>*<st c="13137">. We can only get values between</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>-</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:math>](img/4840.png)
    <st c="13170"><st c="13171">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:math>](img/4841.png)
    <st c="13176"><st c="13177">for the</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>λ</mi><mo>/</mo><msqrt><mi>N</mi></msqrt><mi
    mathvariant="normal">s</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">a</mi><mi
    mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi><mi
    mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">g</mi><mi
    mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">v</mi><mi
    mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">u</mi><mi
    mathvariant="normal">e</mi></mrow></mrow></math>](img/4842.png)<st c="13186"><st
    c="13209">. So, there is a minimum and maximum possible value for the scaled eigenvalue.</st>
    <st c="13288">Again, this is an asymptotic result.</st> <st c="13325">At finite</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>,</mml:mo></mml:math>](img/4843.png)
    <st c="13335"><st c="13336">we will see some departure from this rule, but at
    large values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>,</mml:mo></mml:math>](img/4844.png)
    <st c="13403"><st c="13404">the departures will be small, that is,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>±</mml:mo><mml:msqrt><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:msqrt></mml:math>](img/4845.png)
    <st c="13444"><st c="13445">will be a good approximation to the range of eigenvalues
    that we would see from matrices generated in the way that matrix</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4846.png)
    <st c="13568"><st c="13571">and matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4823.png)
    <st c="13582"><st c="13585">were.</st></st></st></st></st></st></st></st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="13590">The semicircle</st> <st c="13605">law of</st> *<st c="13613">Eq.2</st>*
    <st c="13617">is an example of what we mean by universal behavior or universality.</st>
    <st c="13687">Irrespective of the individual matrix, we will get the same statistical
    behavior.</st> <st c="13769">In this case, we get the same statistical behavior
    of the eigenvalue distribution of</st> <st c="13854">the matrix.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13865">The semicircle law is the most well-known result from RMT.</st>
    <st c="13925">Deriving the shape of the eigenvalue distribution as</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4848.png)
    <st c="13978"><st c="13979">is the sort of task that RMT focuses on.</st> <st
    c="14021">We won’t go into the methods used to derive the semicircle law or other
    RMT results, as they can be complex, but we will discuss more of these universal
    RMT results in the</st> <st c="14193">next section.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14206">What does RMT study?</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="14227">When we study ordinary random variables using the rules of probability,
    the mathematical results that we obtain are about expectation values, that is,
    statements about the average behavior of the random variable.</st> <st c="14441">It
    is the same when we use RMT to study random matrices.</st> <st c="14498">We</st>
    <st c="14500">can only derive formulae and laws about the expected behavior of
    random matrices.</st> <st c="14583">The semicircle law in</st> *<st c="14605">Eq.2</st>*
    <st c="14609">is actually a statement about what happens to the eigenvalue distribution
    on average as we go to the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/1873.png)
    <st c="14711"><st c="14712">limit.</st> <st c="14720">This means that if we were
    to generate lots of different matrices</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="14786"><st c="14800">using the process described in</st> *<st c="14831">Eq.1</st>*<st
    c="14835">, and we were to calculate their scaled eigenvalues and take the average
    of their empirical distributions, we would get something close to the semicircle
    law.</st> <st c="14994">As we made</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/629.png)
    <st c="15005"><st c="15006">larger and larger, this average scaled eigenvalue
    distribution would get closer and closer to the</st> <st c="15105">semicircle
    law.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15120">However, this raises an interesting question.</st> <st c="15167">If
    the semicircle law is the average scaled eigenvalue distribution we’d get after
    averaging across all matrices</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="15280"><st c="15294">generated using</st> *<st c="15310">Eq.1</st>* <st
    c="15314">(and taking the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4853.png)
    <st c="15331"><st c="15332">limit), how is the semicircle law such a good approximation
    to the eigenvalue distributions for the single</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4854.png)
    <st c="15440"><st c="15442">and</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mn>2</mn></msub><mi
    mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">s</mi><mi
    mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi
    mathvariant="normal">c</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">s</mi></mrow></mrow></math>](img/4855.png)<st
    c="15446"><st c="15459">? It’s like we had drawn two values from a random variable</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>X</mml:mi></mml:math>](img/2035.png)
    <st c="15518"><st c="15519">and both just happened to be almost exactly the same
    as the</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>exp</mo><mi
    mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi
    mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi
    mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">v</mi><mi
    mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">u</mi><mi
    mathvariant="normal">e</mi><mi mathvariant="double-struck">E</mi><mfenced open="("
    close=")"><mi>X</mi></mfenced></mrow></mrow></math>](img/4857.png)<st c="15580"><st
    c="15602">. Why did we not see any sampling variation (deviations) around the
    semicircle law when we generated</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4846.png)
    <st c="15703"><st c="15706">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4823.png)<st
    c="15710"><st c="15713">? Were we just extraordinarily lucky?</st> <st c="15751">The
    answer is no, and the reason why has to do with the fact that</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)
    <st c="15817"><st c="15818">is large.</st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15827">Self-averaging</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="15842">For a single matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="15863"><st c="15877">generated using the</st> <st c="15897">process in</st>
    *<st c="15908">Eq.1</st>*<st c="15912">, we’ll use</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:math>](img/4862.png)
    <st c="15924"><st c="15925">to denote a scaled eigenvalue, so</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4863.png)<st
    c="15960"><st c="15961">, and we’ll use</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder><mml:mo>)</mml:mo></mml:math>](img/4864.png)
    <st c="15977"><st c="15978">to denote the empirical density of scaled eigenvalues
    from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)<st
    c="16038"><st c="16052">. RMT says that the average of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder><mml:mo>)</mml:mo></mml:math>](img/4866.png)
    <st c="16083"><st c="16084">over all matrices</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="16103"><st c="16117">tends to the semicircle law in</st> *<st c="16148">Eq.2</st>*
    <st c="16152">as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4868.png)<st
    c="16156"><st c="16157">. In mathematical language, we would say this</st> <st
    c="16203">as follows:</st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><mi>lim</mi><mrow><mi>N</mi><mo>→</mo><mi
    mathvariant="normal">∞</mi></mrow></munder><msub><mi mathvariant="double-struck">E</mi><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder></msub><mfenced
    open="(" close=")"><mrow><mover><mi>p</mi><mo stretchy="true">ˆ</mo></mover><mo>(</mo><mover><mi>λ</mi><mo
    stretchy="true">~</mo></mover><mo>|</mo><munder><munder><mi>M</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>)</mo></mrow></mfenced><mo>=</mo><mfrac><mn>1</mn><mi>π</mi></mfrac><msqrt><mrow><mn>2</mn><mo>−</mo><msup><mover><mi>λ</mi><mo
    stretchy="true">~</mo></mover><mn>2</mn></msup></mrow></msqrt></mrow></mrow></math>](img/4869.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="16216">Eq.3</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16220">However, what we will also find is that the variance of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder><mml:mo>)</mml:mo></mml:math>](img/4870.png)
    <st c="16277"><st c="16278">around its expectation decreases to zero as</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4848.png)<st
    c="16323"><st c="16324">. As</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4848.png)<st
    c="16329"><st c="16330">, the empirical distribution of any single matrix</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="16380"><st c="16394">becomes the same as the average across all matrices
    of the same type as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)<st
    c="16466"><st c="16480">. In physics, we refer to this as</st> **<st c="16514">self-averaging</st>**<st
    c="16528">. The eigenvalue distribution of a matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="16570"><st c="16584">generated from</st> *<st c="16599">Eq.1</st>* <st
    c="16603">is a self-averaging quantity.</st> <st c="16634">What we get from a
    single random instance is very close to the average across multiple instances
    and vice versa.</st> <st c="16747">It is this self-averaging behavior that makes
    the semicircle law a useful approximation even for single instances of a</st>
    <st c="16866">random</st> <st c="16872">matrix.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16880">Ultimately, it is also this self-averaging behavior that makes
    it possible for RMT to derive formulae such as the semicircle law.</st> <st c="17011">Therefore,
    it is ultimately by considering</st> **<st c="17054">large</st>** <st c="17059">random
    matrices (that is, taking</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)
    <st c="17093"><st c="17094">to be large) that we can make progress in RMT.</st>
    <st c="17142">However, that is not to say that RMT doesn’t also consider random
    matrices of small or intermediate finite size.</st> <st c="17255">It is just that
    deriving simple closed-form laws for such matrices can be considerably</st> <st
    c="17342">more challenging.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17359">Universal is universal</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '<st c="17382">You may be</st> <st c="17393">thinking that although matrices</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4877.png)
    <st c="17426"><st c="17428">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>](img/4878.png)
    <st c="17432"><st c="17433">in</st> *<st c="17437">Figure 15</st>**<st c="17446">.2</st>*
    <st c="17448">are different matrices, they were generated according to the same
    process.</st> <st c="17524">How often are we going to be dealing with real-world
    matrices whose matrix elements are Gaussian distributed?</st> <st c="17634">Is
    the behavior illustrated in</st> *<st c="17665">Figure 15</st>**<st c="17674">.2</st>*
    <st c="17676">really that universal?</st> <st c="17700">Here’s the thing: universal
    behavior typically arises for reasons that are not related to the microscopic
    details of how a system is specified.</st> <st c="17844">This means that we can
    often change the microscopic details, such as which precise distribution the matrix
    elements are drawn from, and still get the same universal behavior.</st> <st c="18019">Let’s
    try it.</st> <st c="18033">Let’s take our matrix elements from another distribution,
    but still with mean zero and unit variance, and see</st> <st c="18143">what happens.</st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: '*<st c="18156">Figure 15</st>**<st c="18166">.3</st>* <st c="18168">shows the
    scaled eigenvalue histograms for two</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4879.png)
    <st c="18216"><st c="18217">symmetric random matrices,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math>](img/4880.png)
    <st c="18245"><st c="18248">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math>](img/4881.png)<st
    c="18252"><st c="18255">, generated using</st> *<st c="18273">Eq.1</st>* <st c="18277">but
    using matrices</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math>](img/4882.png)
    <st c="18297"><st c="18299">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math>](img/4883.png)
    <st c="18303"><st c="18306">instead, respectively.</st> <st c="18329">The</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math>](img/4884.png)
    <st c="18333"><st c="18334">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math>](img/4885.png)
    <st c="18339"><st c="18341">matrices are</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4886.png)
    <st c="18354"><st c="18355">random matrices whose matrix elements have been drawn
    from a Laplace distribution that has zero mean and</st> <st c="18461">un</st><st
    c="18463">it variance.</st></st></st></st></st></st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_15_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="18569">Figure 15.3: Histograms of scaled eigenvalues for two large symmetric
    random matrices with matrix elements drawn from a Laplace distribution</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18709">The zero mean unit</st> <st c="18729">variance Laplace distribution
    has a probability density of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math>](img/4887.png)
    <st c="18788"><st c="18794">which is given by the</st> <st c="18816">following
    equation:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>p</mi><mfenced
    open="(" close=")"><mi>x</mi></mfenced><mo>=</mo><mfrac><mn>1</mn><msqrt><mn>2</mn></msqrt></mfrac><mtext>exp</mtext><mfenced
    open="(" close=")"><mrow><mo>−</mo><msqrt><mn>2</mn></msqrt><mfenced open="|"
    close="|"><mi>x</mi></mfenced></mrow></mfenced></mrow></mrow></math>](img/4888.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="18859">Eq.4</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18863">The density function of the Laplace distribution is different
    from the Gaussian distribution.</st> <st c="18958">It decays more slowly than
    the Gaussian distribution.</st> <st c="19012">Despite these big differences, the
    histograms in</st> *<st c="19061">Figure 15</st>**<st c="19070">.3</st>* <st c="19072">are
    almost identical to those in</st> *<st c="19106">Figure 15</st>**<st c="19115">.2</st>*<st
    c="19117">. Again, the red lines in</st> *<st c="19143">Figure 15</st>**<st c="19152">.3</st>*
    <st c="19154">are the semicircle law from</st> *<st c="19183">Eq.2</st>*<st c="19187">.
    You can see that the semicircle law accurately describes the density of scaled
    eigenvalues for this Laplace distribution case.</st> <st c="19316">It turns out
    that the conditions on the distribution from which we can draw our matrix elements
    are very broad.</st> <st c="19428">Typically, for a real symmetric</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:math>](img/651.png)
    <st c="19460"><st c="19461">matrix, as long as we have a zero mean unit variance
    distribution whose low-order moments are finite, then the resulting distribution
    of scaled eigenvalues will follow the semicircle law in the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4890.png)
    <st c="19656"><st c="19657">limit.</st> <st c="19665">The universality of the
    semicircle law is indeed universal.</st> <st c="19725">You can even mix the distributions
    from which we draw our matrix elements and still get the semicircle law – this
    is one of the exercise questions at the end of</st> <st c="19886">this chapter.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19899">The classical Gaussian matrix ensembles</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="19939">The Gaussian matrices, which we defined via</st> *<st c="19984">Eq.1</st>*
    <st c="19988">and whose eigenvalue distributions we plotted in</st> *<st c="20038">Figure
    15</st>**<st c="20047">.2</st>*<st c="20049">, are part of a wider family of random
    matrices.</st> <st c="20098">It is time to meet</st> <st c="20117">that family.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20129">You’ll recall that we restricted our matrices in</st> *<st c="20179">Figure
    15</st>**<st c="20188">.2</st>* <st c="20190">to being real, square, symmetric,
    and generated according to</st> *<st c="20252">Eq.1</st>*<st c="20256">, with
    matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/4801.png)
    <st c="20270"><st c="20272">having all of its matrix elements drawn from the standard
    normal distribution.</st> <st c="20351">This</st> <st c="20356">group, or</st>
    **<st c="20366">ensemble</st>**<st c="20374">, of matrices is called</st> <st
    c="20397">the</st> **<st c="20402">Gaussian Orthogonal Ensemble</st>** <st c="20430">(</st>**<st
    c="20432">GOE</st>**<st c="20435">).</st> <st c="20439">So, overall, the GOE is
    defined by</st> <st c="20474">the following</st><st c="20487">:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>∈</mo><mtext>GOE</mtext><mtext>if</mtext><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mfenced
    open="(" close=")"><mrow><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup></mrow></mfenced><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>~</mo><mi>N</mi><mfenced
    open="(" close=")"><mn>0,1</mn></mfenced></mrow></mrow></math>](img/4892.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="20527">Eq.5</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20531">It is clear from</st> *<st c="20549">Eq.5</st>* <st c="20553">that</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="20559"><st c="20573">is symmetric and real.</st> <st c="20596">Consequently,
    its eigenvalues will be real.</st> <st c="20640">However, there are other ways
    in which we can construct a matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="20705"><st c="20719">, similar to how it is defined in</st> *<st c="20753">Eq.5</st>*
    <st c="20757">and such that it still has real eigenvalues.</st> <st c="20803">For
    example, if we make the matrix elements of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/564.png)
    <st c="20850"><st c="20851">be complex numbers and draw the real and imaginary
    parts of the matrix elements from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo>)</mml:mo></mml:math>](img/4896.png)<st
    c="20937"><st c="20938">, then we can define</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="20959"><st c="20973">via the</st> <st c="20981">following equation:</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mfenced
    open="(" close=")"><mrow><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">H</mi></msup></mrow></mfenced></mrow></mrow></math>](img/4898.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="21013">Eq.6</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mtext>H</mml:mtext></mml:mrow></mml:msup></mml:math>](img/4899.png)
    <st c="21017"><st c="21020">means the Hermitian conjugate of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/564.png)<st
    c="21053"><st c="21054">. We encountered this operation in</st> [*<st c="21089">Chapter
    3</st>*](B19496_03.xhtml#_idTextAnchor141)<st c="21098">, where we used the symbol</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mo>†</mml:mo></mml:math>](img/4901.png)
    <st c="21125"><st c="21126">for the Hermitian conjugate.</st> <st c="21156">It
    means taking the conjugate transpose of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/607.png)
    <st c="21199"><st c="21200">and ensures that the matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="21229"><st c="21243">is Hermitian and so has real eigenvalues.</st> <st
    c="21285">Matrices defined via</st> *<st c="21306">Eq.6</st>* <st c="21310">form</st>
    <st c="21315">the</st> **<st c="21320">Gaussian Unitary Ensemble</st>** <st c="21345">(</st>**<st
    c="21347">GUE</st>**<st c="21350">).</st> <st c="21354">So, overall, the GUE is
    defined by</st> <st c="21389">the following</st><st c="21402">:</st></st></st></st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>∈</mo><mtext>GUE</mtext><mtext>if</mtext><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mfenced
    open="(" close=")"><mrow><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">H</mi></msup></mrow></mfenced><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>a</mi><mo>+</mo><mtext>i</mtext><mi>b</mi><mi>a</mi><mo>,</mo><mi>b</mi><mo>~</mo><mi>N</mi><mfenced
    open="(" close=")"><mn>0,1</mn></mfenced></mrow></mrow></math>](img/4904.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="21447">Eq.7</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21451">The matrix elements of a GUE matrix have a different number of
    components compared to the matrix elements of a GOE matrix.</st> <st c="21575">The
    matrix elements of GOE matrices are real numbers and so are defined by a single
    real number.</st> <st c="21672">Matrix elements of GUE matrices are complex numbers
    and so are defined by two real numbers – their real and imaginary parts.</st>
    <st c="21797">We can extend this pattern further to define numbers with four real
    components.</st> <st c="21877">These numbers are</st> <st c="21894">called</st>
    **<st c="21902">quaternions</st>**<st c="21913">. We won’t go into quaternions
    any further here, but just like you can loosely think of complex numbers as being
    two-dimensional numbers because they live in a two-dimensional space called the</st>
    **<st c="22106">complex plane</st>**<st c="22119">, you can</st> <st c="22128">also
    think of quaternions as being four-dimensional numbers that live in a four-dimensional
    space.</st> <st c="22228">If we allow the matrix elements of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/607.png)
    <st c="22263"><st c="22264">to be quaternions, then we can define a new ensemble
    of random matrices called</st> <st c="22343">the</st> **<st c="22348">Gaussian
    Symplectic Ensemble</st>** <st c="22376">(</st>**<st c="22378">GSE</st>**<st c="22381">).</st>
    <st c="22385">So, overall, the GSE is defined by</st> <st c="22420">the follow</st><st
    c="22430">ing:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>∈</mo><mtext>GSE</mtext><mtext>if</mtext><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mfenced
    open="(" close=")"><mrow><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">D</mi></msup></mrow></mfenced><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mtext>Quaternion</mtext><mfenced
    open="(" close=")"><mrow><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>d</mi></mrow></mfenced><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>d</mi><mo>~</mo><mi>N</mi><mfenced
    open="(" close=")"><mn>0,1</mn></mfenced></mrow></mrow></math>](img/4906.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="22500">Eq.8</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22504">In</st> *<st c="22508">Eq.8</st>*<st c="22512">, the</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mtext>D</mml:mtext></mml:mrow></mml:msup></mml:math>](img/4907.png)
    <st c="22518"><st c="22520">notation means taking the dual transpose of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/607.png)
    <st c="22564"><st c="22565">and ensures that the matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="22594"><st c="22608">is self-dual and so has real eigenvalues.</st> <st
    c="22650">Since a quaternion itself can be represented as a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:math>](img/4910.png)
    <st c="22700"><st c="22701">matrix of complex numbers, an</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:math>](img/819.png)
    <st c="22732"><st c="22733">GSE matrix can be represented as a</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:math>](img/4912.png)
    <st c="22769"><st c="22770">matrix of complex numbers.</st> <st c="22798">This
    way of representing GSE matrices gives us a more practical way of</st> <st c="22869">generating
    them.</st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22885">Generating matrices from the Gaussian Symplectic Ensemble</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22943">1\.</st> <st c="22947">Generate two random complex</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:math>](img/4913.png)
    <st c="22975"><st c="22976">matrices,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4914.png)
    <st c="22987"><st c="22988">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4915.png)<st
    c="22993"><st c="22994">, whose matrix elements have their real and imaginary
    parts independently drawn</st> <st c="23074">from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo>)</mml:mo></mml:math>](img/4916.png)<st
    c="23079"><st c="23080">.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23081">2\.</st> <st c="23085">Construct the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:math>](img/4917.png)
    <st c="23099"><st c="23100">matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4918.png)
    <st c="23108"><st c="23109">defined in block form</st> <st c="23132">as follows:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>A</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>=</mo><mfenced
    open="[" close="]"><mtable columnspacing="0.8000em" columnwidth="auto auto" columnalign="center
    center" rowspacing="1.0000ex" rowalign="baseline baseline"><mtr><mtd><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder></mtd><mtd><munder><munder><mi>Y</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder></mtd></mtr><mtr><mtd><mrow><mo>−</mo><msup><munder><munder><mi>Y</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msup></mrow></mtd><mtd><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">*</mi></msup></mtd></mtr></mtable></mfenced></mrow></mrow></math>](img/4919.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="23145">3\.</st> <st c="23148">Calculate the GSE matrix</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4920.png)
    <st c="23173"><st c="23174">as</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>=</mo><mstyle
    scriptlevel="+1"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mfenced open="("
    close=")"><mrow><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi>H</mi></msup></mrow></mfenced></mrow></mrow></math>](img/4921.png)<st
    c="23177"><st c="23178">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23179">The GOE, GUE, and GSE</st> <st c="23201">differ in terms of the
    number of real</st> <st c="23240">numbers used to specify each matrix element.</st>
    <st c="23285">Traditionally, we</st> <st c="23302">use the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/4922.png)
    <st c="23311"><st c="23312">symbol to denote this number of real numbers.</st>
    <st c="23359">The GOE corresponds to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/4923.png)<st
    c="23382"><st c="23383">, the GUE corresponds to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math>](img/4924.png)<st
    c="23408"><st c="23409">, and the GSE corresponds to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math>](img/4925.png)<st
    c="23438"><st c="23439">. Overall, these three ensembles form the</st> **<st c="23481">classical</st>**
    <st c="23490">ensembles</st> <st c="23501">of RMT.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23508">Matrices from the GOE, GUE, or GSE all have real eigenvalues</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4926.png)<st
    c="23570"><st c="23571">. For all three ensembles, if we calculate scaled eigenvalues
    as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>β</mml:mi><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4927.png)
    <st c="23636"><st c="23643">, then the distribution of scaled eigenvalues tends
    to the semicircle law of</st> *<st c="23720">Eq.2</st>* <st c="23724">in the</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/1914.png)
    <st c="23732"><st c="23733">limit.</st> <st c="23741">The semicircle law is universal
    across all three of these classical random</st> <st c="23816">matrix ensembles.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23833">It is not uncommon to see</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4929.png)
    <st c="23860"><st c="23869">used to define the scaled eigenvalues from any of
    the classical RMT ensembles.</st> <st c="23948">In this case, the limiting scaled
    eigenvalue distribution becomes</st> <st c="24014">the fol</st><st c="24021">lowing:</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>p</mi><mfenced
    open="(" close=")"><mover><mi>λ</mi><mo stretchy="true">~</mo></mover></mfenced><mo>=</mo><mfrac><mn>1</mn><mrow><mi>β</mi><mi>π</mi></mrow></mfrac><msqrt><mrow><mn>2</mn><mi>β</mi><mo>−</mo><msup><mover><mi>λ</mi><mo
    stretchy="true">~</mo></mover><mn>2</mn></msup></mrow></msqrt><mtext>for</mtext><mover><mi>λ</mi><mo
    stretchy="true">~</mo></mover><mo>∈</mo><mfenced open="[" close="]"><mrow><mo>−</mo><msqrt><mrow><mn>2</mn><mi>β</mi></mrow></msqrt><mo>,</mo><msqrt><mrow><mn>2</mn><mi>β</mi></mrow></msqrt></mrow></mfenced></mrow></mrow></math>](img/4930.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="24066">Eq.9</st>
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="24070">Whichever classical ensemble, and hence value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/4931.png)<st
    c="24120"><st c="24121">, we are working with, all the different variants of</st>
    *<st c="24174">Eq.9</st>* <st c="24178">tend to get referred to as the semicircle
    law, which can be confusing when you first see the different variants.</st> <st
    c="24292">This is why I prefer to absorb the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mi>β</mml:mi></mml:msqrt></mml:math>](img/4932.png)
    <st c="24327"><st c="24328">factor into the definition of the scaled eigenvalue
    rather than its probability density.</st> <st c="24418">That way, you get only
    one semicircle law for all three classical RMT ensembles: the one</st> <st c="24507">in</st>
    *<st c="24510">Eq.2</st>*<st c="24514">.</st></st></st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24515">However, some authors also absorb the factor of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4933.png)
    <st c="24564"><st c="24570">into the definition of the ensemble, that is, into
    the definition of how the matrix is constructed.</st> <st c="24670">You may also
    see differences in pre-factors of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:math>](img/4934.png)
    <st c="24717"><st c="24718">between different authors when defining the classical
    ensembles.</st> <st c="24784">Again, these differences only lead to trivial variants
    of</st> *<st c="24842">Eq.9</st>* <st c="24846">for the form of the scaled eigenvalue
    density.</st> <st c="24894">However, it does require you to keep your eyes open
    and be aware of these differences when looking at different textbooks or</st>
    <st c="25019">research papers.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25035">For much of the early history of RMT, the three classical ensembles
    were the focus of study, mainly because of their relevance to physics and quantum
    mechanics.</st> <st c="25197">As RMT progressed, researchers realized that the
    ideas and concepts of RMT could be applied to other research areas and other ensembles
    of matrices, including large data matrices of the kind that we encounter when
    building statistical and machine learning models.</st> <st c="25461">The matrices
    may be different (for example, a data matrix is not usually square), but they
    are still large and random.</st> <st c="25580">Unsurprisingly, we also find universal
    behavior in the statistical properties of these new</st> <st c="25671">matrix
    ensembles.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25688">In the next section, we will look at ensembles of large random
    matrices that we encounter as data scientists, namely large covariance matrices
    and large weight matrices from neural networks.</st> <st c="25880">In both cases,
    we will highlight how RMT is used to study the properties of those classes of
    matrices.</st> <st c="25983">For now though, we’ll wrap up this section by summarizing
    what we</st> <st c="26049">have covered.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26062">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="26078">In this section, we have learned about</st> <st c="26118">the
    following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26132">How the distribution of scaled eigenvalues of large symmetric
    random matrices can follow a</st> <st c="26224">universal pattern</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="26241">The Wigner</st> <st c="26253">semicircle law</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="26267">The</st> <st c="26272">GOE,</st> <st c="26277">GUE, and GSE</st>
    <st c="26290">families</st> <st c="26299">of matrices</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="26310">How the semicircle law is the distribution of scaled eigenvalues
    for the GOE, GUE, and GSE in the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/1914.png)
    <st c="26409"><st c="26410">limit</st></st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="26415">How the semicircle law can apply to large square random matrices
    that are not drawn from the classical Gaussian random</st> <st c="26535">matrix
    ensembles</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="26551">Having learned about the semicircle law, in the next section,
    we will extend it by looking at large covariance matrices that arise in statistics
    and</st> <st c="26701">machine learning.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26718">Random matrices and high-dimensional covariance matrices</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="26775">The examples of large random matrices in the previous section
    were all square matrices.</st> <st c="26864">However, in real-world data science,
    not all matrices are square.</st> <st c="26930">Take the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="26939"><st c="26940">data matrix that we</st> <st c="26961">encountered
    in</st> [*<st c="26976">Chapter 3</st>*](B19496_03.xhtml#_idTextAnchor141) <st
    c="26985">when doing</st> `<st c="27241">0</st>`<st c="27242">.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27243">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="27248"><st c="27249">matrix is what we use to do PCA.</st> <st c="27283">It
    is also the design matrix that we use when building statistical models.</st> <st
    c="27358">So, the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="27366"><st c="27367">matrix is non-square (unless</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math>](img/4943.png)<st
    c="27397"><st c="27398">. However, in practice, we usually derive a square matrix
    from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)<st
    c="27461"><st c="27462">. For example, when doing PCA, we would calculate the
    sample covariance matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4945.png)<st
    c="27541"><st c="27542">, which is defined</st> <st c="27561">as follows:</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><munder><munder><mi>C</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo stretchy="true">ˆ</mo></mover><mo>=</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></mfrac><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder></mrow></mrow></math>](img/4946.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="27577">Eq.10</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27582">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4947.png)
    <st c="27587"><st c="27588">matrix in</st> *<st c="27599">Eq.10</st>* <st c="27604">is</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:math>](img/4948.png)
    <st c="27608"><st c="27609">and symmetric.</st> <st c="27625">If we had many features,
    it would be a large matrix.</st> <st c="27678">Since</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><munder><munder><mi>C</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo stretchy="true">ˆ</mo></mover></mrow></math>](img/4949.png)<st
    c="27684"><st c="27688">is derived from our data, which contains a random component,
    then</st>![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><munder><munder><mi>C</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo stretchy="true">ˆ</mo></mover></mrow></math>](img/4950.png)<st
    c="27753"><st c="27757">is a large</st> <st c="27768">random matrix.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27782">The eigenvalues of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4951.png)
    <st c="27802"><st c="27803">tell us about the principal components in our dataset.</st>
    <st c="27859">So, what would its eigenvalues look like?</st> <st c="27901">Given
    that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4952.png)
    <st c="27912"><st c="27913">is a large random matrix, should we expect some universal
    behavior in the distribution of eigenvalues from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4945.png)<st
    c="28021"><st c="28022">? Let’s do a numerical experiment to</st> <st c="28059">find
    out.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28068">For illustration purposes, we’ll use the simplest possible data
    matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="28140"><st c="28141">, where we first draw the matrix elements</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/4955.png)
    <st c="28183"><st c="28184">from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo>)</mml:mo></mml:math>](img/4956.png)
    <st c="28190"><st c="28191">and then mean-center the columns.</st> <st c="28226">The
    histogram in</st> *<st c="28243">Figure 15</st>**<st c="28252">.4</st>* <st c="28254">shows
    the approximate density of eigenvalues of a single sample covariance matrix generated
    in the way we have just described, with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/4957.png)
    <st c="28387"><st c="28388">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math>](img/4958.png)<st
    c="28392"><st c="28393">.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_15_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="28448">Figure 15.4: The distribution of sample covariance matrix eigenvalues</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28517">The red line in</st> *<st c="28534">Figure 15</st>**<st c="28543">.4</st>*
    <st c="28545">is the</st> **<st c="28553">Marčenko-Pastur</st>** <st c="28568">distribution.</st>
    <st c="28583">It is the equivalent of the semicircle law but for</st> <st c="28634">covariance
    matrices formed from large random data matrices like</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)<st
    c="28698"><st c="28699">. The Marčenko-Pastur formula for the density of eigenvalues,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/4960.png)<st
    c="28761"><st c="28765">, is give</st><st c="28774">n</st> <st c="28777">by</st>
    *<st c="28780">Eq.11</st>*<st c="28785">.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>p</mi><mfenced
    open="(" close=")"><mi>λ</mi></mfenced><mo>=</mo><mfenced open="{" close=""><mtable
    columnwidth="auto" columnalign="center" rowspacing="1.0000ex" rowalign="baseline
    baseline"><mtr><mtd><mrow><mfrac><mi>α</mi><mrow><mn>2</mn><mi>π</mi><mi>λ</mi></mrow></mfrac><msqrt><mrow><mfenced
    open="(" close=")"><mrow><msub><mi>λ</mi><mo>+</mo></msub><mo>−</mo><mi>λ</mi></mrow></mfenced><mfenced
    open="(" close=")"><mrow><mi>λ</mi><mo>−</mo><msub><mi>λ</mi><mo>−</mo></msub></mrow></mfenced></mrow></msqrt><mtext>for</mtext><mi>λ</mi><mo>∈</mo><mfenced
    open="[" close="]"><mrow><msub><mi>λ</mi><mo>−</mo></msub><mo>,</mo><msub><mi>λ</mi><mo>+</mo></msub></mrow></mfenced></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mtext>otherwise</mtext></mrow></mtd></mtr></mtable></mfenced></mrow></mrow></math>](img/4961.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="28832">Eq.11</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28837">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="28842"><st c="28843">value is the ratio of data to features.</st> <st c="28884">That
    is,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math>](img/4963.png)
    <st c="28893"><st c="28894">, so</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi></mml:math>](img/2470.png)
    <st c="28899"><st c="28900">measures how non-square our matrix</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1054.png)
    <st c="28936"><st c="28937">is.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28940">Like the semicircle law, the Marčenko-Pastur distribution has
    finite support.</st> <st c="29019">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:math>](img/4966.png)
    <st c="29023"><st c="29024">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math>](img/4967.png)
    <st c="29029"><st c="29030">values are the lower and upper ends of that support
    and are given by</st> <st c="29100">the</st> <st c="29103">following:</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>λ</mi><mo>−</mo></msub><mo>=</mo><msup><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><msqrt><mi>α</mi></msqrt></mfrac></mrow></mfenced><mn>2</mn></msup><msub><mi>λ</mi><mo>+</mo></msub><mo>=</mo><msup><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>+</mo><mfrac><mn>1</mn><msqrt><mi>α</mi></msqrt></mfrac></mrow></mfenced><mn>2</mn></msup></mrow></mrow></math>](img/4968.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="29116">Eq.12</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29121">Strictly speaking, the Marčenko-Pastur formula in</st> *<st c="29172">Eq.11</st>*
    <st c="29177">is an asymptotic result.</st> <st c="29203">It is the distribution
    of eigenvalues that we would get in the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/4969.png)
    <st c="29266"><st c="29267">limit, while also ensuring that</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>N</mi><mo>/</mo><mi>d</mi><mo>→</mo><mi>α</mi></mrow></mrow></math>](img/4970.png)<st
    c="29300"><st c="29308">. However, just like the semicircle law, it means we can
    also use the density in</st> *<st c="29389">Eq.11</st>* <st c="29394">as a very
    good approximation at finite</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/115.png)
    <st c="29434"><st c="29435">and where we set</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math>](img/4972.png)<st
    c="29453"><st c="29454">. Also, just like the semicircle law, the Marčenko-Pastur
    formula in</st> *<st c="29523">Eq.11</st>* <st c="29528">is the average eigenvalue
    distribution that we would get in the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:math>](img/1870.png)
    <st c="29593"><st c="29594">limit.</st> <st c="29602">The reason why it is such
    a good approximation to the single instance of a sample covariance matrix shown
    in</st> *<st c="29711">Figure 15</st>**<st c="29720">.4</st>* <st c="29722">is
    that the eigenvalue distribution of a large sample covariance matrix of the type
    generated in</st> *<st c="29820">Figure 15</st>**<st c="29829">.4</st>* <st c="29831">is
    self-averaging.</st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29850">The Marčenko-Pastur distribution is a bulk distribution</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="29906">Okay, so the Marčenko-Pastur distribution</st> <st c="29948">is
    a universal law for large sample covariance matrices, but how universal is it
    exactly?</st> <st c="30039">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="30043"><st c="30044">data matrix generated in our numerical example contained
    only values drawn from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo>)</mml:mo></mml:math>](img/4896.png)<st
    c="30125"><st c="30126">. These would seem like just noise values, and so the
    result is not a very realistic</st> <st c="30211">data matrix.</st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30223">Actually, it is realistic.</st> <st c="30251">In many real-world
    datasets and problems, we have lots of feature values.</st> <st c="30325">Typically,
    many of these features are uninformative or have limited signal in them.</st>
    <st c="30409">This means that in real-world datasets, the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="30453"><st c="30454">data matrix can be overwhelmingly made up of noise.</st>
    <st c="30507">Consequently, most of the eigenvalues of the resulting sample covariance
    matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4945.png)
    <st c="30587"><st c="30588">still follow the Marčenko-Pastur distribution.</st>
    <st c="30636">The Marčenko-Pastur distribution describes the</st> *<st c="30683">bulk</st>*
    <st c="30687">of the eigenvalues of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4978.png)<st
    c="30710"><st c="30711">, even for real-world data</st> <st c="30738">matrices</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1054.png)<st
    c="30747"><st c="30748">.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30749">Universality in the singular values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi
    mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/4980.png)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="30792">We have already encountered the definition of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4945.png)
    <st c="30838"><st c="30839">in</st> *<st c="30843">Eq.10</st>*<st c="30848">.
    We also came across it in</st> [*<st c="30876">Chapter 3</st>*](B19496_03.xhtml#_idTextAnchor141)<st
    c="30885">, where we learned about the link between singular values from the SVD
    of the data matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="30975"><st c="30976">and eigenvalues of the sample covariance matrix</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4978.png)
    <st c="31025"><st c="31026">calculated from</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)<st
    c="31043"><st c="31044">. From this link, we know that if</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4985.png)
    <st c="31078"><st c="31079">is an eigenvalue of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4952.png)
    <st c="31100"><st c="31101">, then</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msqrt><mml:mo>(</mml:mo><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:math>](img/4987.png)
    <st c="31108"><st c="31117">is a singular value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)<st
    c="31140"><st c="31141">. It immediately follows that if all or most of the eigenvalues
    of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4945.png)
    <st c="31208"><st c="31209">follow a universal distribution when the number of
    features</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>d</mml:mi></mml:math>](img/471.png)
    <st c="31270"><st c="31271">is large, then the singular values of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1279.png)
    <st c="31310"><st c="31311">must also follow a universal distribution.</st> <st
    c="31355">See whether you can derive what this universal distribution should be
    using the relationship between the eigenvalues of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4952.png)
    <st c="31475"><st c="31476">and the singular values of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1054.png)
    <st c="31504"><st c="31505">and the rules for transforming probability densities
    that we learned about in</st> [*<st c="31584">Chapter 2</st>*](B19496_02.xhtml#_idTextAnchor061)<st
    c="31593">.</st></st></st></st></st></st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31594">Overall, this means that we can also see universal behavior in
    the singular values of some large non-square matrices, not just square ones.</st>
    <st c="31735">This has become particularly useful in the field of deep learning
    neural networks, as we shall learn</st> <st c="31836">about next.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31847">The Marčenko-Pastur distribution and neural networks</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="31900">One of the</st> <st c="31912">most interesting areas of RMT research
    that has emerged over the last decade or so, and that is of relevance to the field
    of data science, is the role that the Marčenko-Pastur distribution plays in characterizing
    the properties of weight matrices in large</st> <st c="32168">neural networks.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32184">You’re probably familiar with the idea that feed-forward neural
    networks consist of layers of nodes that are connected via weights.</st> <st c="32317">The
    weights, along with the output values from the preceding layer in the network,
    feed into a transfer function to compute the output values of the current layer.</st>
    <st c="32481">The schematic in</st> *<st c="32498">Figure 15</st>**<st c="32507">.5</st>*
    <st c="32509">shows such a</st> <st c="32522">neural</st> <st c="32530">network
    structure.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19496_15_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<st c="32659">Figure 15.5: The schematic of a feed-forward neural network</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32718">The number of nodes in the initial input layer can be very large
    due to the large number of features that are input into the network.</st> <st
    c="32853">This is particularly true for modern deep learning neural networks,
    where large data volumes mean it is realistic to try and learn the relationship
    between high-dimensional feature vectors and the target variable.</st> <st c="33067">Therefore,
    the number of nodes,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math>](img/4994.png)
    <st c="33099"><st c="33100">in the input layer will typically be large.</st> <st
    c="33145">As a consequence, for subsequent layers</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>l</mml:mi><mml:mo>></mml:mo><mml:mn>1</mml:mn></mml:math>](img/4995.png)<st
    c="33185"><st c="33189">, the number of nodes</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math>](img/4996.png)
    <st c="33211"><st c="33212">will also</st> <st c="33223">be large.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33232">The number of nodes in a layer is usually less than the number
    of nodes in the preceding layer, as each layer is forced to learn an efficient
    representation of the information coming from the preceding layer.</st> <st c="33442">This
    means that we will also have</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>N</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo><</mo><msub><mi>N</mi><mi>l</mi></msub></mrow></mrow></math>](img/4997.png)<st
    c="33476"><st c="33477">. Consequently, the weight matrix,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math>](img/4998.png)<st
    c="33512"><st c="33516">, connecting layer</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>l</mml:mi></mml:math>](img/2620.png)
    <st c="33535"><st c="33536">to layer</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math>](img/5000.png)
    <st c="33546"><st c="33547">will be a large</st> <st c="33564">non-square matrix.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33582">Since the weight matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math>](img/5001.png)
    <st c="33607"><st c="33612">represents the interactions between nodes in layer</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>l</mml:mi></mml:math>](img/2620.png)
    <st c="33663"><st c="33664">and nodes in layer</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math>](img/5003.png)<st
    c="33684"><st c="33685">, you will not be surprised to find that the distribution
    of its singular values can be studied using the tools of RMT.</st> <st c="33805">In
    fact, it is usual to find that the distribution of the singular values of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math>](img/5004.png)
    <st c="33882"><st c="33886">can be described using the Marčenko-Pastur distribution.</st>
    <st c="33943">Again, the details are too extensive to go into in this short introduction
    – see, for example, the third point in the</st> *<st c="34061">Notes and further
    reading</st>* <st c="34086">section at the end of this</st> <st c="34114">chapter.</st>
    <st c="34123">However, it does illustrate once more that RMT is not an esoteric
    branch of mathematics, but a math concept of genuine relevance to data science
    and data</st> <st c="34277">science algorithms.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34296">This has been a whirlwind tour of the Marčenko-Pastur distribution
    and its applications, so it’s time to recap what we have learned in this section
    and wrap up the chapter as</st> <st c="34472">a whole.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34480">What we learned</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="34496">In this section, we have learned about</st> <st c="34536">the
    following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34550">The distribution of all or most of the eigenvalues of the sample
    covariance matrix calculated from a large data matrix displays a</st> <st c="34681">universal
    behavior</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="34699">The Marčenko-Pastur distribution and how it is the equivalent
    of the semicircle law for sample</st> <st c="34795">covariance matrices</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="34814">How large non-square matrices can display universal behavior in
    the distribution of their singular values and how this distribution can be derived
    from the</st> <st c="34971">Marčenko-Pastur distribution</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="34999">The tools of RMT are applied to understand the behavior of weight
    matrices in large deep-learning</st> <st c="35098">neural networks</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35113">Summary</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="35121">This chapter was about random matrices.</st> <st c="35162">What
    started out sounding like an esoteric plaything of mathematicians turned out to
    be a commonly occurring concept in data science with many applications.</st> <st
    c="35319">The tools to study random matrices come from RMT.</st> <st c="35369">These
    tools can be very mathematically advanced, so we have only given an overview of
    the main results of RMT and what the implications of those results are.</st> <st
    c="35527">We did not attempt to go into the derivations of those results.</st>
    <st c="35591">However, we had to learn about several new concepts.</st> <st c="35644">Those
    new concepts include</st> <st c="35671">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35685">A random matrix is a matrix whose matrix elements are drawn from</st>
    <st c="35751">a distribution</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35765">Random matrices are studied</st> <st c="35794">using RMT</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35803">Large random matrices can display</st> <st c="35838">universal
    behavior</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35856">A large-scale interacting system can be modeled as a large</st>
    <st c="35916">random matrix</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35929">The Wigner</st> <st c="35941">semicircle law</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35955">The GOE, GUE, and GSE families</st> <st c="35987">of matrices</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="35998">The</st> <st c="36003">Marčenko-Pastur distribution</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="36031">The bulk of the eigenvalues of a sample covariance matrix follow
    the</st> <st c="36101">Marčenko-Pastur distribution</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="36129">The tools of RMT are applied to understand the behavior of weight
    matrices in large deep-learning</st> <st c="36228">neural networks.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="36244">This has been our last chapter.</st> <st c="36277">Throughout
    this book, we covered a lot of material.</st> <st c="36329">However, there are
    a vast number of mathematical topics that we haven’t covered.</st> <st c="36410">That
    is okay.</st> <st c="36424">By taking you on a journey through just 15 major math
    concepts that occur in data science and unpacking their nuances, we have equipped
    you with the skills to tackle any data science algorithm or idea on your own.</st>
    <st c="36638">Thank you for allowing me to be your guide for that math journey.</st>
    <st c="36704">I hope that you have enjoyed the journey as much as</st> <st c="36756">I
    have.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36763">Exercises</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="36773">The following is a series of exercises.</st> <st c="36814">Answers
    to all the exercises are given in the</st> `<st c="36860">Answers_to_Exercises_Chap15.ipynb</st>`
    <st c="36893">Jupyter notebook in the</st> <st c="36918">GitHub repository.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36936">Create a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/5005.png)
    <st c="36946"><st c="36947">symmetric matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="36965"><st c="36979">using the</st> <st c="36989">following relationship:</st></st></st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>M</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mfenced
    open="(" close=")"><mrow><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mo>+</mo><msup><munder><munder><mi>A</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup></mrow></mfenced></mrow></mrow></math>](img/5007.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="37025">Eq.13</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37030">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/578.png)
    <st c="37035"><st c="37036">matrix should have its matrix elements drawn from
    the standard normal distribution with a probability of 0.5, and from the mean-zero
    unit-variance Laplace distribution in</st> *<st c="37208">Eq.4</st>*<st c="37212">,
    with a probability of 0.5\.</st> <st c="37241">Calculate the eigenvalues,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>λ</mml:mi></mml:math>](img/826.png)<st
    c="37268"><st c="37269">, of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/89.png)
    <st c="37274"><st c="37288">and compute the empirical density of scaled eigenvalues</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/4832.png)<st
    c="37344"><st c="37345">. Compare this empirical density to the semicircle law</st>
    <st c="37400">in</st> *<st c="37403">Eq.2</st>*<st c="37407">.</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37408">Tip</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37412">You can draw a value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/5012.png)
    <st c="37434"><st c="37435">from the mean-zero unit-variance Laplace distribution
    by first drawing a value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>u</mml:mi></mml:math>](img/5013.png)
    <st c="37515"><st c="37516">from the uniform distribution,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi
    mathvariant="normal">u</mi><mtext>niform</mtext><mfenced open="(" close=")"><mrow><mo>−</mo><mn>0.5</mn><mo>,</mo><mn>0.5</mn></mrow></mfenced></mrow></mrow></math>](img/5014.png)<st
    c="37548"><st c="37567">, then calculating</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/5012.png)
    <st c="37586"><st c="37587">as follows:</st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>x</mi><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><msqrt><mn>2</mn></msqrt></mfrac><mtext>sign</mtext><mfenced
    open="(" close=")"><mi>u</mi></mfenced><mi>ln</mi><mfenced open="(" close=")"><mrow><mn>1</mn><mo>−</mo><mn>2</mn><mfenced
    open="|" close="|"><mi>u</mi></mfenced></mrow></mfenced></mrow></mrow></math>](img/5016.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="37623">Eq.14</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37628">Alternatively, you can use the</st> `<st c="37660">numpy.random.laplace</st>`
    <st c="37680">NumPy function to sample the</st> <st c="37710">values directly.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37726">2.</st> <st c="37730">From the definition of the GUE in</st> *<st
    c="37764">Eq.7</st>*<st c="37768">, generate a</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mn>2000</mml:mn><mml:mo>×</mml:mo><mml:mn>2000</mml:mn></mml:math>](img/5005.png)
    <st c="37781"><st c="37782">GUE matrix and compute its eigenvalues</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>λ</mml:mi></mml:math>](img/3464.png)<st
    c="37822"><st c="37823">. Compute the empirical probability density of scaled
    eigenvalues</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math>](img/5019.png)
    <st c="37889"><st c="37890">and compare it to the semicircle law</st> <st c="37928">in</st>
    *<st c="37931">Eq.2</st>*<st c="37935">.</st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37936">3.</st> <st c="37940">Assume that all the eigenvalues</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>λ</mml:mi></mml:math>](img/826.png)
    <st c="37972"><st c="37973">of a sample covariance matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/4945.png)
    <st c="38004"><st c="38005">are distributed according to the Marčenko-Pastur distribution
    given in</st> *<st c="38077">Eq.11</st>*<st c="38082">. The sample covariance
    matrix has been calculated from a mean-centered data matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1054.png)<st
    c="38166"><st c="38167">. The singular values</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>w</mml:mi></mml:math>](img/5023.png)
    <st c="38189"><st c="38190">of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:munder underaccent="false"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1054.png)
    <st c="38194"><st c="38195">are related to the eigenvalues</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>λ</mml:mi></mml:math>](img/826.png)
    <st c="38227"><st c="38228">via</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/5026.png)<st
    c="38233"><st c="38234">. Use this relationship to derive the probability density
    of the singular</st> <st c="38308">values</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>w</mml:mi></mml:math>](img/5023.png)<st
    c="38315"><st c="38316">.</st></st></st></st></st></st></st></st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38317">Notes and further reading</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '<st c="38343">If you want to learn more about the mathematical details behind
    RMT, the book</st> *<st c="38422">Introduction to Random Matrices: Theory and
    Practice</st>* <st c="38474">by G.</st> <st c="38481">Livan, M.</st> <st c="38491">Novaes,
    and P.</st> <st c="38506">Vivo (ISBN: 978-3319708836, Springer, 2018), is a good
    start.</st> <st c="38568">You can find a copy of the material on the arXiv archive
    at</st> [<st c="38628">https://arxiv.org/pdf/1712.07903.pdf</st>](https://arxiv.org/pdf/1712.07903.pdf)<st
    c="38664">. Be aware that the material can get</st> <st c="38701">mathematically
    advanced.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="38725">For a readable and short introduction to quaternions, I recommend</st>
    *<st c="38792">Introducing the Quaternions</st>* <st c="38819">by J.</st> <st
    c="38826">Huerta, which you can find</st> <st c="38853">at</st> [<st c="38856">https://math.ucr.edu/~huerta/introquaternions.pdf</st>](https://math.ucr.edu/~huerta/introquaternions.pdf)<st
    c="38905">.</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '<st c="38906">A good recent paper on the application of RMT to studying neural
    network weight matrices is C.H.</st> <st c="39004">Martin and M.W.</st> <st c="39020">Mahoney’s</st>
    *<st c="39030">Implicit Self-Regularization in Deep Neural Networks: Evidence
    from Random Matrix Theory and Implications for Learning</st>* <st c="39148">from
    the Journal of Machine Learning Research,</st> <st c="39196">22:1-73, 2021.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '<st c="39210">The recent book,</st> *<st c="39228">Random Matrix Methods for
    Machine Learning</st>* <st c="39270">by R.</st> <st c="39277">Couillet and Z.</st>
    <st c="39293">Liao (ISBN: 978-1009123235, Cambridge University Press, 2022), also
    has a chapter on RMT and large neural networks, as well as on other areas of machine
    learning including some of the topics we have covered in earlier chapters in this
    book, such as kernel methods and community detection.</st> <st c="39582">You can
    find a copy of the material at one of the authors’ GitHub sites</st> <st c="39654">at</st>
    [<st c="39657">https://zhenyu-liao.github.io/pdf/RMT4ML.pdf</st>](https://zhenyu-liao.github.io/pdf/RMT4ML.pdf)<st
    c="39701">.</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
