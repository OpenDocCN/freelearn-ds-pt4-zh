<html><head></head><body>
  <div id="_idContainer219" class="Basic-Text-Frame">
    <h1 class="chapterNumber">7</h1>
    <h1 id="_idParaDest-233" class="chapterTitle">Traditional Supervised Learning Algorithms</h1>
    <blockquote class="packt_quote">
      <p class="quote">Artificial intelligence is the new electricity.</p>
      <p class="cite">—Andrew Ng</p>
    </blockquote>
    <p class="normal">In <em class="chapterRef">Chapter 7</em>, we will turn our attention to supervised machine learning algorithms. These algorithms, characterized by their reliance on labeled data for model training, are multifaceted and <a id="_idIndexMarker583"/>versatile in nature. Let’s consider some instances such as decision trees, <strong class="keyWord">Support Vector Machines</strong> (<strong class="keyWord">SVMs</strong>), and linear regression, to name a few, which all fall under the umbrella of supervised learning.</p>
    <p class="normal">As we delve deeper into this field, it’s important to note that this chapter doesn’t cover neural networks, a significant category within supervised machine learning. Given their complexity and the rapid advancements occurring in the field, neural networks merit an in-depth exploration, which we will embark on in the following three chapters. The vast expanse of neural networks necessitates more than a single chapter to fully discuss their complexities and potential.</p>
    <p class="normal">In this chapter, we will delve into the essentials of supervised machine learning, featuring classifiers and regressors. We will explore their capabilities using real-world problems as case studies. Six distinct classification algorithms will be presented, followed by three regression techniques. Lastly, we’ll compare their results to encapsulate the key takeaways from this discussion.</p>
    <p class="normal">The overall objective of this chapter is for you to understand the different types of supervised machine learning techniques, and to know what the best supervised machine learning techniques are for certain classes of problems.</p>
    <p class="normal">The following concepts are discussed in this chapter:</p>
    <ul>
      <li class="bulletList">Understanding supervised machine learning</li>
      <li class="bulletList">Understanding classification algorithms</li>
      <li class="bulletList">The methods to evaluate the performance of classifiers</li>
      <li class="bulletList">Understanding regression algorithms</li>
      <li class="bulletList">The methods to evaluate the performance of regression algorithms</li>
    </ul>
    <p class="normal">Let’s start by looking at the basic concepts behind supervised machine learning.</p>
    <h1 id="_idParaDest-234" class="heading-1">Understanding supervised machine learning</h1>
    <p class="normal">Machine learning focuses on using data-driven approaches to create autonomous systems that can help us to make decisions with or without human supervision. In order to create these <a id="_idIndexMarker584"/>autonomous systems, machine learning uses a group of algorithms and methodologies to discover and formulate repeatable patterns in data. One of the most popular and powerful methodologies used in machine learning is the supervised machine learning approach. In supervised machine learning, an algorithm is given a set of inputs, called <strong class="keyWord">features</strong>, and their corresponding outputs, called <strong class="keyWord">labels</strong>. These features often comprise structured data like user profiles, historical sales figures, or sensor measurements, while the labels usually represent specific outcomes we want to predict, such as customer purchasing habits or product quality ratings. Using a given dataset, a supervised machine learning algorithm is used to train a model that captures the complex relationship between the features and labels represented by a mathematical formula. This trained model is the basic vehicle that is used for predictions.</p>
    <div class="note">
      <p class="normal">The ability to learn from existing data in supervised learning is similar to the ability of the human brain to learn from experience. This learning ability in supervised learning uses one of the attributes of the human brain and is a fundamental way of opening the gates to bring decision-making power and intelligence to machines.</p>
    </div>
    <p class="normal">Let’s consider an example where we want to use supervised machine learning techniques to train a model that can categorize a set of emails into legitimate ones (called <strong class="keyWord">legit</strong>) and unwanted ones (called <strong class="keyWord">spam</strong>). In order to get started, we need examples from the past so that the machine can learn what sort of content of emails should be classified as spam. </p>
    <p class="normal">This content-based learning task using text data is a complex process and is <a id="_idIndexMarker585"/>achieved through one of the supervised machine learning algorithms. Some examples of supervised machine learning algorithms that can be used to train the model in this example include decision trees and Naive Bayes classifiers, which we will discuss later in this chapter.</p>
    <p class="normal">For now, we will focus on how we can formulate supervised machine learning problems.</p>
    <h1 id="_idParaDest-235" class="heading-1">Formulating supervised machine learning problems</h1>
    <p class="normal">Before going deeper into the details of supervised machine learning algorithms, let’s define some <a id="_idIndexMarker586"/>of the basic supervised machine learning terminology:</p>
    <table id="table001-6" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Terminology</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Explanation</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Label</p>
          </td>
          <td class="table-cell">
            <p class="normal">A label is the variable that our model is tasked with predicting. There can be only one label in a supervised machine learning model.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Features</p>
          </td>
          <td class="table-cell">
            <p class="normal">The set of input variables used to predict the label is called the features.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Feature engineering</p>
          </td>
          <td class="table-cell">
            <p class="normal">Transforming features to prepare them for the chosen supervised machine learning algorithm is called feature engineering.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Feature vector</p>
          </td>
          <td class="table-cell">
            <p class="normal">Before providing an input to a supervised machine learning algorithm, all the features are combined in to a data structure called a feature vector.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Historical data</p>
          </td>
          <td class="table-cell">
            <p class="normal">The data from the past that is used to formulate the relationship between the label and the features is called historical data. Historical data comes with examples.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Training/testing data</p>
          </td>
          <td class="table-cell">
            <p class="normal">Historical data with examples is divided into two parts—a larger dataset called the training data and a smaller dataset called the testing data.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Model</p>
          </td>
          <td class="table-cell">
            <p class="normal">A mathematical formulation of the patterns that best capture the relationship between the label and the features.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Training</p>
          </td>
          <td class="table-cell">
            <p class="normal">Creating a model using training data.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Testing</p>
          </td>
          <td class="table-cell">
            <p class="normal">Evaluating the quality of the trained model using testing data.</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Prediction</p>
          </td>
          <td class="table-cell">
            <p class="normal">The act of utilizing our trained model to estimate the label. In this context, “prediction” is the definitive output of the model, specifying a precise outcome. It’s crucial to distinguish this from “prediction probability,” which rather than providing a concrete result gives a statistical likelihood of each potential outcome.</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">A trained supervised machine learning model is capable of making predictions by estimating the label based on the features.</p>
    <p class="normal">Let’s introduce <a id="_idIndexMarker587"/>the notation that we will use in this chapter to discuss the machine learning techniques:</p>
    <table id="table002-4" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Variable</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Meaning</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">y</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Actual label</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">ý</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Predicted label</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">d</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Total number of examples</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">b</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Number of training examples</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">c</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Number of testing examples</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">X_train</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Training feature vector</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">Note that in this context, an “example” refers to a single instance in our dataset. Each example comprises a set of features (input data) and a corresponding label (the outcome we’re predicting)</p>
    <p class="normal">Let’s delve into some practical applications of the terms we’ve introduced. Consider a feature vector, essentially a data structure encompassing all the features.</p>
    <p class="normal">For instance, if we have “n” features and “b” training examples, we represent this training feature vector as <code class="inlineCode">X_train</code>. Hence, if our training dataset consists of five examples and five variables or features, <code class="inlineCode">X_train</code> will have five rows—one for each example, and a total of 25 elements (5 examples x 5 features).</p>
    <p class="normal">In this context, <code class="inlineCode">X_train</code> is a specific term representing our training dataset. Each example in this dataset is a combination of features and its associated label. We use superscripts to denote a specific example’s row number. Thus, a single example in our dataset is given as (<em class="italic">X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup>, <em class="italic">y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup>) where <em class="italic">X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup> refers to the features of the first example and<em class="italic"> y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup> is its corresponding label.</p>
    <p class="normal">Our complete labeled dataset, <em class="italic">D</em>, can therefore be expressed as <em class="italic">D = {( X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">), (y</em><sup class="superscript-italic" style="font-style: italic;"> (2)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">), ….. , (X</em><sup class="superscript-italic" style="font-style: italic;">(d)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(d)</sup><em class="italic">)}</em>, where <em class="italic">D</em> signifies the total number of examples.</p>
    <p class="normal">We partition <em class="italic">D</em> into two subsets - the training set <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">train</sub> and the testing set <em class="italic">D</em><sub class="subscript">test</sub>. The training set, <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">train</sub>, can be depicted as <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">train</sub><em class="italic"> = {( X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">), (X</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">), ….. , (X</em><sup class="superscript-italic" style="font-style: italic;">(b)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(b)</sup><em class="italic">)}</em>, where ‘<em class="italic">b</em>’ is the number of training examples.</p>
    <p class="normal">The primary <a id="_idIndexMarker588"/>goal of training a model is to ensure that the predicted target value <code class="inlineCode">('ý')</code> for any <em class="italic">i</em><sup class="superscript">th</sup> example in the training set aligns as closely as possible with the actual label <code class="inlineCode">('y')</code>. This ensures that the model’s predictions reflect the true outcomes presented in the examples.</p>
    <p class="normal">Now, let’s see how some of these terminologies are formulated practically.</p>
    <p class="normal">As we discussed, a feature vector is defined as a data structure that has all the features stored in it.</p>
    <p class="normal">If the number of features is <em class="italic">n</em> and the number of training examples is <em class="italic">b</em>, then <code class="inlineCode">X_train</code> represents the training feature vector.</p>
    <p class="normal">For the training dataset, the feature vector is represented by <code class="inlineCode">X_train</code>. If there are <em class="italic">b</em> examples in the training dataset, then <code class="inlineCode">X_train</code> will have <em class="italic">b</em> rows. If there are <em class="italic">n</em> variables, then the training dataset will have a dimension of <em class="italic">n</em> x <em class="italic">b</em>.</p>
    <p class="normal">We will use superscript to represent the row number of a training example.</p>
    <p class="normal">This particular example in our labeled dataset is represented by <em class="italic">(Features</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,label</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">) = (X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">, y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">).</em></p>
    <p class="normal">So, our labeled dataset is represented by <em class="italic">D = {(X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">), (X</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">), ….. , (X</em><sup class="superscript-italic" style="font-style: italic;">(d)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(d)</sup><em class="italic">)}</em>.</p>
    <p class="normal">We divide that into two parts—<em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">train</sub> and <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">test</sub>.</p>
    <p class="normal">So, our training set can be represented by <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">train</sub><em class="italic"> = {(X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">), (X</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">), ….. , (X</em><sup class="superscript-italic" style="font-style: italic;">(b)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(b)</sup><em class="italic">)}</em>.</p>
    <p class="normal">The objective of training a model is that for any <em class="italic">i</em><sup class="superscript">th</sup> example in the training set, the predicted value of the target value should be as close to the actual value in the examples as possible. In other words:</p>
    <p class="center"><img src="../Images/B18046_07_001.png" alt="" role="presentation"/></p>
    <p class="normal">So, our testing set can be represented by <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">test</sub><em class="italic"> = {X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">), (X</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">), ..... , (X</em><sup class="superscript-italic" style="font-style: italic;">(c)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(c)</sup><em class="italic">)}</em>.</p>
    <p class="normal">The values of the label are represented by a vector, <em class="italic">Y</em>:</p>
    <p class="center"><em class="italic">Y ={y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">, y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">, ....., y</em><sup class="superscript-italic" style="font-style: italic;">(m)</sup><em class="italic">}</em></p>
    <p class="normal">Let’s illustrate the concepts with an example.</p>
    <p class="normal">Let’s imagine <a id="_idIndexMarker589"/>we’re working on a project to predict house prices based on various features, like the number of bedrooms, the size of the house in square feet, and its age. Here’s how we’d apply our machine learning terminology to this real-world scenario.</p>
    <p class="normal">In this context, our “features” would be the number of bedrooms, house size, and age. Let’s say we have 50 examples (i.e., 50 different houses for which we have these details and the corresponding price). We can represent these in a training feature vector called <code class="inlineCode">X_train</code>.</p>
    <p class="normal"><code class="inlineCode">X_train</code> becomes a table with 50 rows (one for each house) and 3 columns (one for each feature: bedrooms, size, and age). It’s a 50 x 3 matrix holding all our feature data.</p>
    <p class="normal">An individual house’s feature set and price might be represented as <em class="italic">((X</em><sup class="superscript-italic" style="font-style: italic;">(i)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(i)</sup><em class="italic">))</em>, where <em class="italic">X</em><sup class="superscript-italic" style="font-style: italic;">(i)</sup> contains the features of the <em class="italic">i</em><sup class="superscript">th</sup> house and <em class="italic">y</em><sup class="superscript-italic" style="font-style: italic;">(i)</sup> is its actual price.</p>
    <p class="normal">Our entire dataset <em class="italic">D</em> can then be viewed as <em class="italic">D =</em> <em class="italic">{(X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">), (X</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">)), ... , ((X</em><sup class="superscript-italic" style="font-style: italic;">(50)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(50)</sup><em class="italic">))}</em>.</p>
    <p class="normal">Suppose we use 40 houses for training and the remaining 10 for testing. Our training set <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">train</sub> would be the first 40 examples: <em class="italic">{(X</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">), (X</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">)), ... , ((X</em><sup class="superscript-italic" style="font-style: italic;">(40)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(40)</sup><em class="italic">))}</em>.</p>
    <p class="normal">After training our model, the goal is to predict house prices <img src="../Images/B18046_07_002.png" alt="" role="presentation"/> that closely match the actual prices <img src="../Images/B18046_07_003.png" alt="" role="presentation"/> for all houses in our training set.</p>
    <p class="normal">Our testing set <em class="italic">D</em><sub class="subscript-italic" style="font-style: italic;">test</sub> consists of the remaining 10 examples: <em class="italic">{(X</em><sup class="superscript-italic" style="font-style: italic;">(41)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(41)</sup><em class="italic">), (X</em><sup class="superscript-italic" style="font-style: italic;">(42)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(42)</sup><em class="italic">), ... , (X</em><sup class="superscript-italic" style="font-style: italic;">(50)</sup><em class="italic">,y</em><sup class="superscript-italic" style="font-style: italic;">(50)</sup><em class="italic">))}</em>.</p>
    <p class="normal">Lastly, we have the <em class="italic">Y</em> vector, comprising all our actual house prices: <em class="italic">Y ={ y</em><sup class="superscript-italic" style="font-style: italic;">(1)</sup><em class="italic">, y</em><sup class="superscript-italic" style="font-style: italic;">(2)</sup><em class="italic">, ....., y</em><sup class="superscript-italic" style="font-style: italic;">(50)</sup><em class="italic">}</em>.</p>
    <p class="normal">With this <a id="_idIndexMarker590"/>concrete example, we can see how these concepts and equations translate into practice when predicting house prices with supervised machine learning.</p>
    <h2 id="_idParaDest-236" class="heading-2">Understanding enabling conditions</h2>
    <p class="normal">A supervised machine learning algorithm needs certain enabling conditions to be met in order to <a id="_idIndexMarker591"/>perform. Enabling conditions are certain prerequisites that ensure the efficacy of a supervised machine learning algorithm. These enabling conditions are as follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Enough examples</strong>: Supervised machine learning algorithms need enough examples to train a model. We say that we have enough examples when we have conclusive evidence that the pattern of interest is fully represented in our dataset.</li>
      <li class="bulletList"><strong class="keyWord">Patterns in historical data</strong>: The examples used to train a model need to have patterns in them. The likelihood of the occurrence of our event of interest should be dependent on a combination of patterns, trends, and events. The label mathematically represents the event of interest in our model. Without these, we are dealing with random data that cannot be used to train a model.</li>
      <li class="bulletList"><strong class="keyWord">Valid assumptions</strong>: When we train a supervised machine learning model using examples, we expect that the assumptions that apply to the examples will also be valid in the future. Let’s look at an actual example. If we want to train a machine learning model for the government that can predict the likelihood of whether a visa will be granted to a student, the understanding is that the laws and policies will not change when the model is used for predictions. If new policies or laws are enforced after training the model, the model may need to be retrained to incorporate this new information.</li>
    </ul>
    <p class="normal">Let us look into how we can differentiate between a classifier and a regressor.</p>
    <h2 id="_idParaDest-237" class="heading-2">Differentiating between classifiers and regressors</h2>
    <p class="normal">In a machine learning model, the label can be a category variable or a continuous variable. Continuous variables are numeric variables that can have an infinite number of values <a id="_idIndexMarker592"/>between two values, while <a id="_idIndexMarker593"/>categorical variables are qualitative variables <a id="_idIndexMarker594"/>that are classified into distinct categories. The type of label determines what type of supervised machine learning model we have. Fundamentally, we have two types of supervised machine learning models:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Classifiers</strong>: If the <a id="_idIndexMarker595"/>label is a category variable, the machine learning model is called a classifier. Classifiers can be used to answer the following type of business questions:<ul>
          <li class="bulletList">Is this abnormal tissue growth a malignant tumor?</li>
          <li class="bulletList">Based on the current weather conditions, will it rain tomorrow?</li>
          <li class="bulletList">Based on the profile of a particular applicant, should their mortgage application be approved?</li>
        </ul>
      </li>
      <li class="bulletList"><strong class="keyWord">Regressors</strong>: If the <a id="_idIndexMarker596"/>label is a continuous variable, we train a regressor. Regressors can be used to answer the following types of business questions:<ul>
          <li class="bulletList">Based on the current weather condition, how much will it rain tomorrow?</li>
          <li class="bulletList">What will the price of a particular home be with given characteristics?</li>
        </ul>
      </li>
    </ul>
    <p class="normal">Let’s look at both classifiers and regressors in more detail.</p>
    <h1 id="_idParaDest-238" class="heading-1">Understanding classification algorithms</h1>
    <p class="normal">In supervised <a id="_idIndexMarker597"/>machine learning, if the label is a category variable, the model is categorized as a classifier. Recall that the model is essentially a mathematical representation learned from the training data:</p>
    <ul>
      <li class="bulletList">The historical <a id="_idIndexMarker598"/>data is called <strong class="keyWord">labeled data</strong>.</li>
      <li class="bulletList">The production <a id="_idIndexMarker599"/>data, which the label needs to be predicted for, is called <strong class="keyWord">unlabeled data</strong>.</li>
    </ul>
    <div class="note">
      <p class="normal">The ability to accurately label unlabeled data using a trained model is the real power of classification algorithms. Classifiers predict labels for unlabeled data to answer a particular business question.</p>
    </div>
    <p class="normal">Before we present the details of classification algorithms, let’s first present a business problem that <a id="_idIndexMarker600"/>we will use as a challenge for classifiers. We will then use six different algorithms to answer the same challenge, which will help us compare their methodology, approach, and performance.</p>
    <h2 id="_idParaDest-239" class="heading-2">Presenting the classifiers challenge</h2>
    <p class="normal">We will first present a common problem, which we will use as a challenge to test six different <a id="_idIndexMarker601"/>classification algorithms. This common problem is referred to as the classifier challenge in this chapter. Using all six classifiers to solve the same problem will help us in two ways:</p>
    <ul>
      <li class="bulletList">All the input variables need to be processed and assembled as a complex data structure, called a feature vector. Using the same feature vector helps us avoid repeating data preparation for all six algorithms.</li>
      <li class="bulletList">We can accurately compare the performance of various algorithms as we use the same feature vector for input.</li>
    </ul>
    <p class="normal">The classifiers challenge is about predicting the likelihood of a person making a purchase. In the retail industry, one of the things that can help maximize sales is understanding better the behavior of the customers. This can be done by analyzing the patterns found in historical data. Let’s state the problem, first.</p>
    <h3 id="_idParaDest-240" class="heading-3">The problem statement</h3>
    <p class="normal">Given the <a id="_idIndexMarker602"/>historical data, can we train a binary classifier that can predict whether a particular user will eventually buy a product based on their profile?</p>
    <p class="normal">First, let’s explore the labeled dataset available to solve this problem:</p>
    <p class="center"><img src="../Images/B18046_07_004.png" alt="" role="presentation"/></p>
    <p class="normal">Note that <em class="italic">x</em> is a member of a set of real numbers. <img src="../Images/B18046_07_005.png" alt="" role="presentation"/> indicates that it is a vector with <em class="italic">b</em> real-time features. <img src="../Images/B18046_07_006.png" alt="" role="presentation"/> implies that is a binary variable, as we are dealing with a binary classification problem. The output can be <code class="inlineCode">0</code> or <code class="inlineCode">1</code>, where each number represents a different class.</p>
    <p class="normal">For this particular example, when <code class="inlineCode">y = 1</code>, we call it a positive class, and when <code class="inlineCode">y = 0</code>, we call it a negative class. To make it more tangible, when <code class="inlineCode">y</code> equals <code class="inlineCode">1</code>, we’re dealing with a positive class, meaning the user is likely to make a purchase. Conversely, when <code class="inlineCode">y</code> equals <code class="inlineCode">0</code>, it represents <a id="_idIndexMarker603"/>the negative class, suggesting the user isn’t likely to buy anything. This model will allow us to predict future user behavior based on their historical actions.</p>
    <div class="note">
      <p class="normal">Although the level of the positive and negative classes can be chosen arbitrarily, it is a good practice to define the positive class as the event of interest. If we try to flag the fraudulent transaction for a bank, then the positive class (that is, <code class="inlineCode">y = 1</code>) should be the fraudulent transaction, not the other way around.</p>
    </div>
    <p class="normal">Now, let’s look at the following:</p>
    <ul>
      <li class="bulletList">The actual label, denoted by <em class="italic">y</em></li>
      <li class="bulletList">The predicted label, denoted by <em class="italic">ý</em></li>
    </ul>
    <p class="normal">Note that for our classifiers challenge, the actual value of the label found in this example is represented by <em class="italic">y</em>. If, in our example, someone has purchased an item, we say <em class="italic">y =1</em>. The predicted values are represented by <em class="italic">ý</em>. The input feature vector, <em class="italic">x</em>, will have a dimension equal to the number of input variables. We want to determine what the probability is that a user will make a purchase, given a particular input.</p>
    <p class="normal">So, we want to determine the probability that <em class="italic">y = 1</em>, given a particular value of feature vector <em class="italic">x</em>. Mathematically, we can represent this as follows:</p>
    <p class="center"><img src="../Images/B18046_07_007.png" alt="" role="presentation"/></p>
    <p class="normal">Note that the expression <em class="italic">P</em>(<em class="italic">y</em> = <em class="italic">1</em>|<em class="italic">x</em>) represents the conditional probability of the event <em class="italic">y</em> being equal to 1, given the occurrence of event <em class="italic">x</em>. In other words, it represents the probability of the outcome y being true or positive, given the knowledge or presence of a specific condition <em class="italic">x</em>.</p>
    <p class="normal">Now, let’s look <a id="_idIndexMarker604"/>at how we can process and assemble different input variables in the feature vector, <em class="italic">x</em>. The methodology for assembling different parts of <em class="italic">x</em> using the processing pipeline is discussed in more detail in the following section.</p>
    <h3 id="_idParaDest-241" class="heading-3">Feature engineering using a data processing pipeline</h3>
    <p class="normal">Preparing data for <a id="_idIndexMarker605"/>a chosen machine learning algorithm is called <strong class="keyWord">feature engineering</strong> and is a crucial part of the machine learning life cycle. Feature <a id="_idIndexMarker606"/>engineering is done in different stages or phases. The multi-stage processing code used to process data is collectively <a id="_idIndexMarker607"/>known as a <strong class="keyWord">data pipeline</strong>. Making a data pipeline using standard processing steps, wherever possible, makes it reusable and decreases the effort needed to train the models. By using more well-tested software modules, the quality of the code is also enhanced.</p>
    <p class="normal">In addition <a id="_idIndexMarker608"/>to feature engineering, it’s important to note that data cleaning is a crucial part of this process as well. This involves addressing issues like outlier detection and missing value treatment. For instance, outlier detection allows you to identify and handle anomalous data points that could negatively impact your model’s performance. Similarly, missing value treatment is a technique used to fill in or handle missing data points in your dataset, ensuring your model has a complete picture of the data. These are important steps to be included in the data pipeline, helping to improve the reliability and accuracy of your machine learning models.</p>
    <p class="normal">Let’s design a reusable processing pipeline for the classifiers challenge. As mentioned, we will prepare data once and then use it for all the classifiers.</p>
    <h4 class="heading-4">Importing data</h4>
    <p class="normal">Let us <a id="_idIndexMarker609"/>start by importing the necessary libraries:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> sklearn,sklearn.tree
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> sklearn.metrics <span class="hljs-keyword">as</span> metrics
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder, StandardScaler
</code></pre>
    <p class="normal">Note that we will use the <code class="inlineCode">pandas</code> library in Python, which is a powerful open-source data manipulation and analysis tool that provides high-performance data structures and data analysis tools. We will also use <code class="inlineCode">sklearn</code>, which provides a comprehensive suite of tools and algorithms for various machine learning tasks.</p>
    <h4 class="heading-4">Importing data</h4>
    <p class="normal">The <a id="_idIndexMarker610"/>labeled data for this problem containing the examples is stored in a file called <code class="inlineCode">Social_Network_Ads.csv</code> in the <code class="inlineCode">CSV</code> format. Let us start by reading this file:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Importing the dataset</span>
dataset = pd.read_csv(<span class="hljs-string">'https://storage.googleapis.com/neurals/data/Social_Network_Ads.csv'</span>)
</code></pre>
    <p class="normal">This file can be downloaded from <a href="https://storage.googleapis.com/neurals/data/Social_Network_Ads.csv"><span class="url">https://storage.googleapis.com/neurals/data/Social_Network_Ads.csv</span></a>.</p>
    <h4 class="heading-4">Feature selection</h4>
    <p class="normal">The process of selecting features that are relevant to the context of the problem that we want <a id="_idIndexMarker611"/>to solve is called <strong class="keyWord">feature selection</strong>. It is an essential part of feature engineering.</p>
    <p class="normal">Once the <a id="_idIndexMarker612"/>file is imported, we drop the <code class="inlineCode">User ID</code> column, which is used to identify a person and should be excluded when training a model. Generally, <code class="inlineCode">User ID</code> is an identifying field that uniquely represents each person but holds no meaningful contribution to the patterns or trends we try to model. </p>
    <p class="normal">For this reason, it’s a common practice to drop such columns before training a machine learning model:</p>
    <pre class="programlisting code"><code class="hljs-code">dataset = dataset.drop(columns=[<span class="hljs-string">'User ID'</span>])
</code></pre>
    <p class="normal">Now, let’s preview the dataset using the <code class="inlineCode">head</code> command, which will print the first five rows of this dataset:</p>
    <pre class="programlisting code"><code class="hljs-code">dataset.head(<span class="hljs-number">5</span>)
</code></pre>
    <p class="normal">The dataset looks like this:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_01.png" alt="A table with numbers and text  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.1: Example dataset</p>
    <p class="normal">Now, let’s look <a id="_idIndexMarker613"/>at how <a id="_idIndexMarker614"/>we can further process the input dataset.</p>
    <h4 class="heading-4">One-hot encoding</h4>
    <p class="normal">Several machine learning models operate best when all features are expressed as continuous variables. This stipulation implies that we need an approach to transforming categorical <a id="_idIndexMarker615"/>features into continuous ones. One common technique to achieve this is ‘one-hot encoding.’</p>
    <p class="normal">In our context, the <code class="inlineCode">Gender</code> feature is categorical, and we aim to convert it into a continuous variable using one-hot encoding. But what is one-hot encoding, exactly?</p>
    <p class="normal">One-hot encoding is a process that transforms a categorical variable into a format that machine learning algorithms can understand better. It does so by creating new binary features for each category in the original feature. For example, if we apply one-hot encoding to ‘<code class="inlineCode">Gender</code>, ‘ it would result in two new features: <code class="inlineCode">Male</code> and <code class="inlineCode">Female</code>. If the gender is <code class="inlineCode">Male</code>, the ‘<code class="inlineCode">Male</code>' feature would be 1 (indicating true), and ‘<code class="inlineCode">Female</code>' would be 0 (indicating false), and vice versa.</p>
    <p class="normal">Let’s now apply this one-hot encoding process to our ‘<code class="inlineCode">Gender</code>' feature and continue our model preparation process:</p>
    <pre class="programlisting code"><code class="hljs-code">enc = sklearn.preprocessing.OneHotEncoder()
</code></pre>
    <p class="normal">The <code class="inlineCode">drop='first'</code> parameter indicates that the first category in the ‘<code class="inlineCode">Gender</code>' feature should be dropped.</p>
    <p class="normal">First, let us perform one-hot encoding on ‘<code class="inlineCode">Gender</code>':</p>
    <pre class="programlisting code"><code class="hljs-code">enc.fit(dataset.iloc[:,[<span class="hljs-number">0</span>]])
onehotlabels = enc.transform(dataset.iloc[:,[<span class="hljs-number">0</span>]]).toarray()
</code></pre>
    <p class="normal">Here, we use the <code class="inlineCode">fit_transform</code> method to apply one-hot encoding to the ‘<code class="inlineCode">Gender</code>' column. The <code class="inlineCode">reshape(-1, 1)</code> function is used to ensure that the data is in the correct 2D format expected by the encoder. The <code class="inlineCode">toarray()</code> function is used to convert the output, which is a sparse matrix, into a dense <code class="inlineCode">numpy</code> array for easier manipulation later on.</p>
    <p class="normal">Next, let us add the encoded <code class="inlineCode">Gender</code> back to the dataframe:</p>
    <pre class="programlisting code"><code class="hljs-code">genders = pd.DataFrame({<span class="hljs-string">'Female'</span>: onehotlabels[:, <span class="hljs-number">0</span>], <span class="hljs-string">'Male'</span>: onehotlabels[:, <span class="hljs-number">1</span>]})
</code></pre>
    <p class="normal">Note <a id="_idIndexMarker616"/>that this line of code adds the encoded ‘<code class="inlineCode">Gender</code>' data back to the DataFrame. Since we’ve set <code class="inlineCode">drop='first'</code>, and assuming that the ‘<code class="inlineCode">Male</code>' category is considered the first category, our new column, ‘<code class="inlineCode">Female</code>,’ will have a value of <code class="inlineCode">1</code> if the gender is female, and <code class="inlineCode">0</code> if it is male.</p>
    <p class="normal">Then, we drop the original <code class="inlineCode">Gender</code> column from the DataFrame, as it has now been replaced with our new <code class="inlineCode">Female</code> column:</p>
    <pre class="programlisting code"><code class="hljs-code">result = pd.concat([genders,dataset.iloc[:,<span class="hljs-number">1</span>:]], axis=<span class="hljs-number">1</span>, sort=<span class="hljs-title">False</span>)
</code></pre>
    <p class="normal">Once it’s converted, let’s look at the dataset again:</p>
    <pre class="programlisting code"><code class="hljs-code">result.head(<span class="hljs-number">5</span>)
</code></pre>
    <figure class="mediaobject"><img src="../Images/B18046_07_02.png" alt="Table  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.2: Add a caption here….</p>
    <p class="normal">Notice that in order to convert a variable from a category variable into a continuous variable, one-hot encoding has converted <code class="inlineCode">Gender</code> into two separate columns—<code class="inlineCode">Male</code> and <code class="inlineCode">Female</code>.</p>
    <p class="normal">Let us look into how we can specify the features and labels.</p>
    <h4 class="heading-4">Specifying the features and label</h4>
    <p class="normal">Let’s <a id="_idIndexMarker617"/>specify the features and labels. We will use <code class="inlineCode">y</code> through out this book to represent the label and <code class="inlineCode">X</code> to represent the feature set:</p>
    <pre class="programlisting code"><code class="hljs-code">y=result[<span class="hljs-string">'Purchased'</span>]
X=result.drop(columns=[<span class="hljs-string">'Purchased'</span>])
</code></pre>
    <p class="normal"><code class="inlineCode">X</code> represents the feature vector and contains all the input variables that we need to use to train the model.</p>
    <h4 class="heading-4">Dividing the dataset into testing and training portions</h4>
    <p class="normal">Next, we will partition our dataset into two parts: 70% for training and 30% for testing. The <a id="_idIndexMarker618"/>rationale behind this particular division is that, as a rule of thumb in machine learning practice, we want a sizable portion of the dataset to train our model so that it can <a id="_idIndexMarker619"/>learn effectively from various examples. This is where the larger 70% comes into play. However, we also need to ensure that our model generalizes well to unseen data and doesn’t just memorize the training set. To evaluate this, we will set aside 30% of the data for testing. This data is not used during the training process and acts as a benchmark for gauging the trained model’s performance and its ability to make predictions on new, unseen data:</p>
    <pre class="programlisting code"><code class="hljs-code">X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = <span class="hljs-number">0.25</span>, random_state = <span class="hljs-number">0</span>)
</code></pre>
    <p class="normal">This has created the following four data structures:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">X_train</code>: A data structure containing the features of the training data</li>
      <li class="bulletList"><code class="inlineCode">X_test</code>: A data structure containing the features of the training test</li>
      <li class="bulletList"><code class="inlineCode">y_train</code>: A vector containing the values of the label in the training dataset</li>
      <li class="bulletList"><code class="inlineCode">y_test</code>: A vector containing the values of the label in the testing dataset</li>
    </ul>
    <p class="normal">Let us now apply feature normalization to the dataset.</p>
    <h3 id="_idParaDest-242" class="heading-3">Scaling the features</h3>
    <p class="normal">As we proceed with the preparation of our dataset for our machine learning model, an important <a id="_idIndexMarker620"/>step is <strong class="keyWord">feature normalization</strong>, also known as scaling. In many <a id="_idIndexMarker621"/>machine learning algorithms, scaling the variables to a uniform range, typically from 0 to 1, can enhance the model’s performance by ensuring that <a id="_idIndexMarker622"/>no individual feature can dominate others due to its scale. </p>
    <p class="normal">This process can also help the algorithm converge more quickly to the solution. Now, let’s apply this transformation to our dataset for optimal results.</p>
    <p class="normal">First, we initialize an instance of the <code class="inlineCode">StandardScaler</code> class, which will be used to conduct the scaling operation:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Feature Scaling</span>
sc = StandardScaler()
</code></pre>
    <p class="normal">Then, we use the <code class="inlineCode">fit_transform</code> method. This transformation scales the features such that they have a mean of <code class="inlineCode">0</code> and a standard deviation of <code class="inlineCode">1</code>, which is the essence of standard scaling. The transformed data is stored in the <code class="inlineCode">X_train_scaled</code> variable:</p>
    <pre class="programlisting code"><code class="hljs-code">X_train = sc.fit_transform(X_train)
</code></pre>
    <p class="normal">Next, we will apply the <code class="inlineCode">transform</code> method, which applies the same transformation (as in the prior code) to the test dataset<code class="inlineCode"> X_test</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">X_test = sc.transform(X_test)
</code></pre>
    <p class="normal">After we scale the data, it is ready to be used as input to the different classifiers that we will present in the subsequent sections.</p>
    <h3 id="_idParaDest-243" class="heading-3">Evaluating the classifiers</h3>
    <p class="normal">Once the <a id="_idIndexMarker623"/>model is trained, we need to evaluate its performance. To do that, we will use the following process:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">We will divide the labeling dataset into two parts—a training partition and a testing partition. We will use the testing partition to evaluate the trained model.</li>
      <li class="numberedList">We will use the features of our testing partition to generate labels for each row. This is our set of predicted labels.</li>
      <li class="numberedList">We will compare the set of predicted labels with the actual labels to evaluate the model.</li>
    </ol>
    <div class="note">
      <p class="normal">Unless we try to solve something quite trivial, there will be some misclassifications when we evaluate the model. How we interpret these misclassifications to determine the quality of the model depends on which performance metrics we choose to use.</p>
    </div>
    <p class="normal">Once we have <a id="_idIndexMarker624"/>both the set of actual labels and the predicted labels, a bunch of performance metrics can be used to evaluate the models. </p>
    <p class="normal">The best metric for quantifying the model will depend on the requirements of the business problem that we want to solve, as well as the characteristics of the training dataset.</p>
    <p class="normal">Let us now look at the confusion matrix.</p>
    <h2 id="_idParaDest-244" class="heading-2">Confusion matrices</h2>
    <p class="normal">A confusion matrix is <a id="_idIndexMarker625"/>used to summarize the results of the evaluation of a classifier. The confusion matrix for a binary classifier looks as follows:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_03.png" alt="Diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.3: Confusion matrix</p>
    <div class="note">
      <p class="normal">If the label <a id="_idIndexMarker626"/>of the classifier we train has two levels, it is called a <strong class="keyWord">binary classifier</strong>. The first critical use case of supervised machine learning—specifically, a binary classifier—was during the First World War to differentiate between an aircraft and flying birds.</p>
    </div>
    <p class="normal">The classification can be divided into the following four categories:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">True Positives</strong> (<strong class="keyWord">TPs</strong>): The positive classifications that were correctly classified</li>
      <li class="bulletList"><strong class="keyWord">True Negatives</strong> (<strong class="keyWord">TNs</strong>): The negative classifications that were correctly classified</li>
      <li class="bulletList"><strong class="keyWord">False Positives</strong> (<strong class="keyWord">FPs</strong>): The positive classifications that were actually negative</li>
      <li class="bulletList"><strong class="keyWord">False Negatives</strong> (<strong class="keyWord">FNs</strong>): The negative classifications that were actually positive</li>
    </ul>
    <p class="normal">Let’s see how we can use these four categories to create various performance metrics.</p>
    <p class="normal">A confusion matrix provides a comprehensive snapshot of a model’s performance by detailing the number <a id="_idIndexMarker627"/>of correct and incorrect predictions. It enumerates TPs, TNs, FPs, and FNs. Among these, the correct classifications refer to the instances where our model correctly identified the class, i.e., TPs and TNs. The model’s accuracy, which signifies the proportion of these correct classifications (TPs and TNs) out of all the predictions made, can then be calculated directly from this confusion matrix. A confusion matrix gives you the number of correct classifications and misclassifications through a count of TPs, TNs, FPs, and FNs. The model accuracy is defined as the proportion of correct classifications among all predictions and can be easily seen from the confusion matrix as follows.</p>
    <p class="normal">When we have an approximately equal number of positive and negative examples in our data – a situation known as balanced classes – the accuracy metric can provide a valuable measure of our model’s performance. In other words, accuracy is the ratio of correct predictions made by the model to the total number of predictions. For example, if our model correctly identifies 90 out of 100 test instances, whether they are positive or negative, its accuracy will be 90%. This metric can give us a general understanding of how well our model performs across both classes. If our data has balanced classes (i.e., the total number of positive examples is roughly equal to the number of negative examples), than the accuracy will give us a good insight into the quality of our trained model. Accuracy is the proportion of correction classifications among all predictions.</p>
    <p class="normal">Mathematically:</p>
    <p class="center"><img src="../Images/B18046_07_008.png" alt="" role="presentation"/></p>
    <h3 id="_idParaDest-245" class="heading-3">Understanding recall and precision</h3>
    <p class="normal">While calculating accuracy, we do not differentiate between TPs and TNs. Evaluating a model through accuracy is straightforward, but when the data has imbalanced classes, it will not accurately <a id="_idIndexMarker628"/>quantify the quality of the trained model. When the data has imbalanced classes, two additional metrics will better quantify the <a id="_idIndexMarker629"/>quality of the trained model, recall and precision. We will use an example of a popular diamond mining process to explain the concepts of these two additional metrics.</p>
    <p class="normal">For centuries, alluvial diamond mining has been one of the most popular ways of extracting <a id="_idIndexMarker630"/>diamonds from the sand of riverbeds all over the world. Erosion over thousands of years is known to wash diamonds from their primary deposits to riverbeds in different parts of the world. To mine diamonds, people have collected sand from the banks <a id="_idIndexMarker631"/>of rivers in a large open pit. After going though extensive washing, a large number of rocks are left in the pit. </p>
    <p class="normal">A vast majority of these washed rocks are just ordinary stones. Identifying one of the rocks as a diamond is rare but a very important event. In our scenario, the owners of a mine are experimenting with the use of computer vision to identify which of the washed rocks are just ordinary rocks and which of the washed rocks are diamonds. They are using shape, color, and reflection to classify the washed rocks using computer vision.</p>
    <p class="normal">In the context of this example:</p>
    <table id="table003-4" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">TP</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">A washed rock correctly identified as a diamond</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">TN</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">A washed rock correctly identified as a stone</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">FP</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">A stone incorrectly identified as a diamond</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">FN</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">A diamond incorrectly identified as a stone</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">Let us explain recall and precision while keeping this diamond extraction process from the mine in mind:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Recall</strong>: This calculates the <em class="italic">hit rate</em>, which is the proportion of identified events of <a id="_idIndexMarker632"/>interest in a gigantic repository of events. In other words, this metric rates our ability to find or “hit” most of the events of interest and leaves as little as possible unidentified. In the context of identifying diamonds in a pit of a large number of washed stones, recall is about quantifying the success of the treasure hunt. For a certain pit filled up with washed stones, recall will be the ratio of the number of diamonds identified to the total number of diamonds in the pit:
    <p class="center"><img src="../Images/B18046_07_009.png" alt="" role="presentation"/></p>
    <p class="normal">Let us assume there were 10 diamonds in the pit, each valued at $1,000. Our machine learning algorithm was able to identify nine of them. So, the recall will be <em class="italic">9/10 = 0.90</em>.</p>
    <p class="normal">So, we are able to retrieve 90% of our treasure. In dollar cost, we were able to identify $9,000 of treasure out of a total value of $10,000.</p></li>
    </ul>
    <ul>
      <li class="bulletList"><strong class="keyWord">Precision</strong>: In precision, we only focus on the data points flagged by the trained model <a id="_idIndexMarker633"/>as positive and discard everything else. If we filter only the events flagged as positive by our trained model (i.e., TPs and FPs) and then calculate the accuracy, this is called precision.
    <p class="normal">Now, let us investigate precision in the context of the diamond mining example. Let us consider a scenario where we want to use computer vision to identify diamonds among a pit of washed rocks and send them to customers. </p>
    <p class="normal">The process is supposed to be automated. The worst-case scenario is the algorithm misclassifying a stone as a diamond, resulting in the end customer receiving it in the mail and getting charged for it. So, it should be obvious that for this process to be feasible, precision should be high. </p>
    <p class="normal">For the diamond mining example:</p>
    <p class="center"><img src="../Images/B18046_07_010.png" alt="" role="presentation"/></p></li>
    </ul>
    <h2 id="_idParaDest-246" class="heading-2">Understanding the recall and precision trade-off</h2>
    <p class="normal">Making decisions with a classifier involves a two-step process. Firstly, the classifier generates a <a id="_idIndexMarker634"/>decision score ranging from 0 to 1. Then, it applies a decision threshold to determine the class for each data point. Data points scoring above <a id="_idIndexMarker635"/>the threshold are assigned a positive class, while those scoring below are assigned a negative class. The two steps can be explained as follows:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">The classifier generates a decision score, which is a number from 0 to 1.</li>
      <li class="numberedList">The classifier uses the value of a parameter, called a decision threshold, to allocate one of the two classes to the current datapoint. Any decision (score &gt; decision) threshold is predicted to be positive, and any data point having a decision (score &lt; decision) threshold is predicted to be negative.</li>
    </ol>
    <p class="normal">Envision a scenario where you operate a diamond mine. Your task is to identify precious diamonds in a heap of ordinary rocks. To facilitate this process, you’ve developed a machine learning classifier. The classifier reviews each rock, assigns it a decision score ranging from 0 to 1, and finally, classifies the rock based on this score and a predefined decision threshold.</p>
    <p class="normal">The decision score essentially represents the classifier’s confidence that a given rock is indeed a diamond, with rocks closer to 1 highly likely to be diamonds. The decision threshold, on the other hand, is a predefined cut-off point that decides the ultimate classification of a rock. Rocks scoring above the threshold are classified as diamonds (the positive class), while those scoring below are discarded as ordinary rocks (the negative class).</p>
    <p class="normal">Now, imagine all the rocks are arranged in ascending order of their decision scores, as shown in <em class="italic">Figure 7.4</em>. The rocks on the far left have the lowest scores and are least likely to be diamonds, while those on the far right have the highest scores, making them most likely to be diamonds. In an ideal scenario, every rock to the right of the decision threshold would be a diamond, and every rock to the left would be an ordinary stone.</p>
    <p class="normal">Consider a situation, as depicted in <em class="italic">Figure 7.4</em>, where the decision threshold is at the center. On the right side of the decision boundary, we find three actual diamonds (TPs) and one ordinary rock wrongly flagged as a diamond (FPs). On the left, we have two ordinary rocks correctly identified (TNs) and two diamonds wrongly classified as ordinary rocks (FNs).</p>
    <p class="normal">Thus, on the left-hand side of the decision threshold, you will find two correct classifications <a id="_idIndexMarker636"/>and two misclassifications. They are 2TNs and 2FNs.</p>
    <p class="normal">Let us calculate <a id="_idIndexMarker637"/>the recall and precision for <em class="italic">Figure 7.4</em>:</p>
    <p class="center"><img src="../Images/B18046_07_011.png" alt="" role="presentation"/></p>
    <p class="center"><img src="../Images/B18046_07_012.png" alt="" role="presentation"/></p>
    <figure class="mediaobject"><img src="../Images/B18046_07_04.png" alt="A comparison of diamonds and stone  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.4: Precision/recall trade-off: rocks are ranked by their classifier score</p>
    <p class="normal">Those that are above the decision threshold are considered diamonds.</p>
    <p class="normal">Note that the higher the threshold, the higher the precision but the lower the recall.</p>
    <p class="normal">Adjusting the decision threshold influences the trade-off between precision and recall. If we move the threshold to the right (as shown in <em class="italic">Figure 7.5</em>), we increase the criteria for a rock to be classified as a diamond, increasing precision but decreasing recall:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_05.png" alt="A screenshot of a computer screen  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.5: Precision/recall trade-off: rocks are ranked by their classifier score</p>
    <p class="normal">Those that <a id="_idIndexMarker638"/>are above the decision threshold are considered diamonds. Note that the higher the threshold, the higher the precision but the lower the recall.</p>
    <p class="normal">In <em class="italic">Figure 7.6</em>, we have decreased the decision threshold. In other words, we have decreased our <a id="_idIndexMarker639"/>criteria for a rock to be classified as a diamond. So, FNs (the treasure misses) will decrease, but FPs (the false signal) will increase as well. Thus, if we decrease the threshold (as shown in <em class="italic">Figure 7.6</em>), we loosen the criteria for diamond classification, increasing recall but decreasing precision:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_06.png" alt="A screenshot of a computer screen  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.6: Precision/recall trade-off: rocks are ranked by their classifier score</p>
    <p class="normal">Those that are above the decision threshold are considered diamonds. Note that the higher the threshold, the higher the precision but the lower the recall.</p>
    <p class="normal">So, playing with the value of the decision boundary is about managing the trade-off between recall and precision. We increase the decision boundary to get better precision and can expect more recall, and we lower the decision boundary to get better recall and can expect less precision.</p>
    <p class="normal">Let us draw a graph between precision and recall to better understand the trade-off:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_07.png" alt="Chart, line chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.7: Precision vs. recall</p>
    <p class="normal">What is the right choice for recall and precision?</p>
    <p class="normal">Increasing recall is <a id="_idIndexMarker640"/>done by decreasing the criteria we use to identify a data <a id="_idIndexMarker641"/>point as positive. The precision is expected to decrease, but as shown in the figure above, it falls sharply at around 0.8. This is the point where we can choose the right value of recall and precision. In the above graph, if we choose 0.8 as the recall, the precision is 0.75. We can interpret it as being able to flag 80% of all the data points of interest. We flag these data points 75% accurately according to this level of precision. If there is no specific business requirement and it’s for a generic use case, this may be a reasonable compromise.</p>
    <p class="normal">Another way <a id="_idIndexMarker642"/>to show the inherent trade-off between precision and recall is by using the <strong class="keyWord">Receiving Operating Curve</strong> (<strong class="keyWord">ROC</strong>). To do that, let us define <a id="_idIndexMarker643"/>two terms: <strong class="keyWord">True Positive Rate</strong> (<strong class="keyWord">TPR</strong>) and <strong class="keyWord">False Positive Rate</strong> (<strong class="keyWord">FPR</strong>).</p>
    <p class="normal">Let us look <a id="_idIndexMarker644"/>into the ROC curve. To calculate the TPR and FPR, we need to look at the diamonds in the pit:</p>
    <p class="center"><img src="../Images/B18046_07_013.png" alt="" role="presentation"/></p>
    <p class="center"><img src="../Images/B18046_07_014.png" alt="" role="presentation"/></p>
    <p class="center"><img src="../Images/B18046_07_015.png" alt="" role="presentation"/></p>
    <p class="normal">Note that:</p>
    <ul>
      <li class="bulletList">TPR is equal to the recall or hit rate.</li>
      <li class="bulletList">TNR can be thought of as the recall or hit rate of the negative event. It determines our success in correctly identifying the negative event. It is also called <strong class="keyWord">specificity</strong>.</li>
      <li class="bulletList">FPR = 1 – TNR = 1 - Specificity.</li>
    </ul>
    <p class="normal">It should be <a id="_idIndexMarker645"/>obvious that TPR and FPR for these figures can be calculated as follows:</p>
    <table id="table004-3" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Figure number</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">TPR</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">FPR</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">7.4</p>
          </td>
          <td class="table-cell">
            <p class="normal">3/5=0.6</p>
          </td>
          <td class="table-cell">
            <p class="normal">1/3=0.33</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">7.5</p>
          </td>
          <td class="table-cell">
            <p class="normal">2/5=0.4</p>
          </td>
          <td class="table-cell">
            <p class="normal">0/3 = 0</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">7.6</p>
          </td>
          <td class="table-cell">
            <p class="normal">5/5 = 1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1/3 = 0.33</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">Note that TPR <a id="_idIndexMarker646"/>or recall will be increased by lowering our decision threshold. In an effort to get as many diamonds as possible from the mine, we will lower our criterion for a washed stone being classified as a diamond. The result is that more stones will be incorrectly classified as diamonds, increasing FPR.</p>
    <p class="normal">Note that a good-quality classification algorithm should be able to provide the decision score for each of the rocks in the pit, which roughly matches the likelihood of a rock being a diamond. The output of such an algorithm is shown in <em class="italic">Figure 7.8</em>. Diamonds are supposed to be on the right side and stones are supposed to be on the left side. In the figure, as we have decreased the decision threshold from <code class="inlineCode">0.8</code> to <code class="inlineCode">0.2</code>, we expect to have a much higher increase in TRP and then FPR. In fact, the steep increase in TRP with a slight increase in FPR is one of the best indications of the quality of a binary classifier, as the classification algorithm was able to generate decision scores that directly relate with the likelihood of a rock <a id="_idIndexMarker647"/>being a diamond. If the diamonds and stones are randomly <a id="_idIndexMarker648"/>located on the decision score axis, it is equally likely that lowering the decision threshold will flag stones or diamonds. This would be the worst possible binary classifier, also called a randomizer:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_08.png" alt="Chart, scatter chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.8: ROC curve</p>
    <h3 id="_idParaDest-247" class="heading-3">Understanding overfitting</h3>
    <p class="normal">If a machine learning model performs great in a development environment but degrades noticeably in a production environment, we say that the model is overfitted. This means the <a id="_idIndexMarker649"/>trained model too closely follows the training dataset. It is an indication there are too many details in the rules created by the model. The trade-off between model variance and bias best captures the idea.</p>
    <p class="normal">When developing a machine learning model, we often make certain simplifying assumptions about the real-world phenomena that the model is supposed to capture. These assumptions are essential to make the modeling process manageable and less complex. However, the simplicity of these assumptions introduces a certain level of ‘bias’ in to our model.</p>
    <p class="normal">Let’s break this down further. Bias is a term that quantifies how much, on average, our predictions deviate from true values. In simple terms, if we have high bias, it means our model’s predictions are far off from the actual values, which leads to a high error rate on our training data.</p>
    <p class="normal">For instance, consider linear regression models. They assume a linear relationship between input features and output variables. However, this may not always be the case in real-world scenarios where relationships can be non-linear or more complex. This linear assumption, while simplifying our model, can lead to a high bias, as it may not fully capture the actual relationships between variables.</p>
    <p class="normal">Now, let’s also talk about ‘variance.’ Variance, in the context of machine learning, refers to the amount by which our model’s predictions would change if we used a different training dataset. A model with high variance pays a lot of attention to training data and tends to learn from <a id="_idIndexMarker650"/>the noise and the details. As a result, it performs very well on training data but not so well on unseen or test data. This difference in performance is often referred to as overfitting.</p>
    <p class="normal">We can visualize bias and variance using a bullseye diagram, as shown in <em class="italic">Figure 7.9</em>. Note that the center of the target is a model that perfectly predicts the correct values. Shots that are far away from the bullseye indicate high bias, while shots that are dispersed widely indicate high variance. In a perfect scenario, we would like a low bias and low variance, where all shots hit right in the bullseye. However, in real-world scenarios, there is a trade-off. Lowering bias increases variance, and lowering variance increases bias. </p>
    <p class="normal">This is known as the bias-variance trade-off and is a fundamental aspect of machine learning model design:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_09.png" alt="A diagram of different types of bias  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.9: Graphical illustration of bias and variance</p>
    <p class="normal">Balancing the right amount of generalization in a machine learning model is a delicate process. This balance, or sometimes imbalance, is described by the bias-variance trade-off. Generalization in <a id="_idIndexMarker651"/>machine learning refers to the model’s ability to adapt properly to new, unseen data, drawn from the same distribution as the one used for training. In other words, a well-generalized model can effectively apply learned rules from training data to new, unseen data. A more generalized model is achieved using simpler assumptions. These simpler assumptions result in more broad rules, which in turn make the model less sensitive to fluctuations in the training data. This means that the model will have low variance, as it doesn’t change much with different training sets.</p>
    <p class="normal">However, there is a downside to this. Simpler assumptions mean the model might not fully capture all the complex relationships within the data. This results in a model that is consistently ‘off-target’ from the true output, leading to a higher bias.</p>
    <p class="normal">So, in this sense, more generalization equates to lower variance but higher bias. This is the essence of the bias-variance trade-off: a model with too much generalization (high bias) might oversimplify the problem and miss important patterns, while a model with too little generalization (high variance) might overfit to the training data, capturing noise along with the signal.</p>
    <p class="normal">Striking a balance between these two extremes is one of the central challenges in machine learning, and the ability to manage this trade-off can often make the difference between a good model and a great one. This trade-off between bias and variance is determined by the choice of algorithm, the characteristics of the data, and various hyperparameters. It is <a id="_idIndexMarker652"/>important to achieve the right compromise between bias and variance, based on the requirements of the specific problem you try to solve.</p>
    <p class="normal">Let us now look into how we can specify different phases of a classifier.</p>
    <h3 id="_idParaDest-248" class="heading-3">Specifying the phases of classifiers</h3>
    <p class="normal">Once the <a id="_idIndexMarker653"/>labeled data is prepared, the development of the classifiers involves training, evaluation, and deployment. These three phases of implementing <a id="_idIndexMarker654"/>a classifier are shown in the <strong class="keyWord">Cross-Industry Standard Process for Data Mining (CRISP-DM</strong>) life cycle in the following diagram (the CRISP-DM life cycle was explained in more detail in <em class="chapterRef">Chapter 5</em>, <em class="italic">Graph Algorithms</em>):</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_10.png" alt="Diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.10: CRISP DM life cycle</p>
    <p class="normal">When implementing a classifier model, there are several crucial phases to consider, starting with a thorough understanding of the business problem at hand. This involves identifying the data needed to solve this problem and understanding the real-world context of the data. After gathering the relevant labeled data, the next step is to split this dataset into two sections: a training set and a testing set. The training set, typically larger, is used to train the model to understand patterns and relationships within the data. The testing set, on the other hand, is used to evaluate the model’s performance on unseen data.</p>
    <p class="normal">To ensure <a id="_idIndexMarker655"/>both sets are representative of the overall data distribution, we will use a random sampling technique. This way, we can reasonably expect that patterns in the entire dataset will be reflected in both the training and testing partitions.</p>
    <p class="normal">Note that, as shown in <em class="italic">Figure 7.10</em>, there is first a training phase, where training data is used to train a model. Once the training phase is over, the trained model is evaluated using the testing data. Different performance matrices are used to quantify the performance of the trained model. Once the model is evaluated, we have the model deployment phase, where the trained model is deployed and used for inference to solve real-world problems by labeling unlabeled data.</p>
    <p class="normal">Now, let’s look at some classification algorithms.</p>
    <p class="normal">We will look at the following classification algorithms in the subsequent sections:</p>
    <ul>
      <li class="bulletList">The decision tree algorithm</li>
      <li class="bulletList">The XGBoost algorithm</li>
      <li class="bulletList">The Random Forest algorithm</li>
      <li class="bulletList">The logistic regression algorithm</li>
      <li class="bulletList">The <strong class="keyWord">SVM</strong> algorithm</li>
      <li class="bulletList">The Naive Bayes algorithm</li>
    </ul>
    <p class="normal">Let’s start with the decision tree algorithm.</p>
    <h1 id="_idParaDest-249" class="heading-1">Decision tree classification algorithm</h1>
    <p class="normal">A decision <a id="_idIndexMarker656"/>tree is based on a recursive partitioning approach (divide and conquer), which generates a set of rules that can be used to predict a label. It starts with a root node and splits it into multiple branches. Internal nodes represent a test on a certain attribute, and the result of the test is represented by a branch to the next level. The decision tree ends in leaf nodes, which contain the decisions. The process stops when partitioning no longer improves the outcome.</p>
    <p class="normal">Let us now look into the details of the decision tree algorithm.</p>
    <h2 id="_idParaDest-250" class="heading-2">Understanding the decision tree classification algorithm</h2>
    <p class="normal">The distinguishing feature of decision tree classification is the generation of a human-interpretable hierarchy of rules that is used to predict the label at runtime. This model’s transparency is a major advantage, as it allows us to understand the reasoning behind each prediction. This hierarchical structure is formed through a recursive algorithm, following a series of steps.</p>
    <p class="normal">First, let’s illustrate <a id="_idIndexMarker657"/>this with a simplified example. Consider a decision tree model predicting whether a person will enjoy a specific movie. The topmost decision or ‘rule’ in the tree might be, ‘Is the movie a comedy or not?’ If the answer is yes, the tree branches to the next rule, like, ‘Does the movie star the person’s favorite actor?’ If no, it branches to another rule. Each decision point creates further subdivisions, forming a tree-like structure of rules, until we reach a final prediction.</p>
    <p class="normal">With this process, a decision tree guides us through a series of understandable, logical steps to arrive at a prediction. This clarity is what sets decision tree classifiers apart from other machine learning models.</p>
    <p class="normal">The algorithm is recursive in nature. Creating this hierarchy of rules involves the following steps:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1"><strong class="keyWord">Find the most important feature</strong>: Out of all of the features, the algorithm identifies the feature that best differentiates between the data points in the training dataset with respect to the label. The calculation is based on metrics such as information gain or Gini impurity.</li>
      <li class="numberedList"><strong class="keyWord">Bifurcate</strong>: Using the most identified important feature, the algorithm creates a criterion that is used to divide the training dataset into two branches:<ul>
          <li class="bulletList">Data points that pass the criterion</li>
          <li class="bulletList">Data points that fail the criterion</li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord">Check for leaf nodes</strong>: If any resultant branch mostly contains labels of one class, the branch is made final, resulting in a leaf node.</li>
      <li class="numberedList"><strong class="keyWord">Check the stopping conditions and repeat</strong>: If the provided stopping conditions are not met, then the algorithm will go back to <em class="italic">step 1</em> for the next iteration. Otherwise, the model is marked as trained, and each node of the resultant decision tree at the lowest level is labeled as a leaf node. The stopping <a id="_idIndexMarker658"/>condition can be as simple as defining the number of iterations, or a default stopping condition can be used, where the algorithm stops as soon it reaches a certain homogeneity level for each of the leaf nodes.</li>
    </ol>
    <p class="normal">The decision tree algorithm can be explained by the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_11.png" alt="Diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.11: Decision Tree</p>
    <p class="normal">In the preceding diagram, the root contains a bunch of circles and crosses. They just represent two different categories of a particular feature. The algorithm creates a criterion that tries to separate the circles from the crosses. At each level, the decision tree creates partitions of the data, which are expected to be more and more homogeneous from level 1 upward. A perfect classifier has leaf nodes that only contain circles or crosses. Training perfect classifiers is usually difficult due to the inherent unpredictability and noise in real-world datasets. </p>
    <p class="normal">Note that the decision trees have key advantages that make them a preferred choice in many scenarios. The beauty of decision tree classifiers lies in their interpretability. Unlike many other models, they provide a clear and transparent set of ‘if-then’ rules, which makes the decision-making process understandable and auditable. This is particularly beneficial in fields like healthcare or finance, where comprehending the logic behind a prediction can be as important as the prediction itself.</p>
    <p class="normal">Additionally, decision trees are less sensitive to the scale of the data and can handle a mix of categorical and numerical variables. This makes them a versatile tool in the face of diverse data types.</p>
    <p class="normal">So, even though training a ‘perfect’ decision tree classifier might be difficult, the advantages they offer, including their simplicity, transparency, and flexibility, often outweigh this challenge.</p>
    <p class="normal">We are going to use the decision tree classification algorithm for the classifiers challenge.</p>
    <p class="normal">Now, let’s use the <a id="_idIndexMarker659"/>decision tree classification algorithm for the common problem that we previously defined to predict whether a customer ends up purchasing a product:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">First, let’s instantiate the decision tree classification algorithm and train a model using the training portion of the data that we prepared for our classifiers:
        <pre class="programlisting code"><code class="hljs-code">classifier = sklearn.tree.DecisionTreeClassifier(criterion = <span class="hljs-string">'entropy'</span>, random_state = <span class="hljs-number">100</span>, max_depth=<span class="hljs-number">2</span>)
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">DecisionTreeClassifier(criterion = 'entropy', random_state = 100, max_depth=2)
</code></pre>
      </li>
      <li class="numberedList">Now, let’s use our trained model to predict the labels for the testing portion of our labeled data. Let’s generate a confusion matrix that can summarize the performance of our trained model:
        <pre class="programlisting code"><code class="hljs-code">y_pred = classifier.predict(X_test)
cm = metrics.confusion_matrix(y_test, y_pred)
</code></pre>
      </li>
      <li class="numberedList">This gives the following output:
        <pre class="programlisting code"><code class="hljs-code">cm
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">array([[64, 4],
       [2, 30]])
</code></pre>
      </li>
      <li class="numberedList">Now, let’s calculate the <code class="inlineCode">accuracy</code>, <code class="inlineCode">recall</code>, and <code class="inlineCode">precision</code> values for the created classifier by using the decision tree classification algorithm:
        <pre class="programlisting code"><code class="hljs-code">accuracy= metrics.accuracy_score(y_test,y_pred)
recall = metrics.recall_score(y_test,y_pred)
precision = metrics.precision_score(y_test,y_pred)
<span class="hljs-built_in">print</span>(accuracy,recall,precision)
</code></pre>
      </li>
      <li class="numberedList">Running the preceding code will produce the following output:
        <pre class="programlisting con"><code class="hljs-con">0.94 0.9375 0.8823529411764706
</code></pre>
      </li>
    </ol>
    <p class="normal">The performance <a id="_idIndexMarker660"/>measures help us compare different training modeling techniques with each other.</p>
    <p class="normal">Let us now look into the strengths and weaknesses of decision tree classifiers.</p>
    <h2 id="_idParaDest-251" class="heading-2">The strengths and weaknesses of decision tree classifiers</h2>
    <p class="normal">In this section, let’s look at the strengths and weaknesses of using the decision tree classification algorithm.</p>
    <p class="normal">One of the <a id="_idIndexMarker661"/>most significant strengths of decision tree classifiers lies in their inherent transparency. The rules that govern their model formation are human-readable and interpretable, making them ideal for situations that demand a clear understanding of the decision-making process. This type of model, often referred to as a white-box model, is an essential component in scenarios where bias needs to be minimized and transparency maximized. This is particularly relevant in critical industries such as government and insurance, where accountability and traceability are paramount.</p>
    <p class="normal">In addition, decision tree classifiers are well equipped to handle categorical variables. Their design is inherently suited to extracting information from discrete problem spaces, which makes them an excellent choice for datasets where most features fall into specific categories.</p>
    <p class="normal">On the flip side, decision tree classifiers do exhibit certain limitations. Their biggest challenge is the tendency toward overfitting. When a decision tree delves too deep, it runs the risk of creating rules that capture an excessive amount of detail. This leads to models that overgeneralize from the training data and perform poorly on unseen data. Therefore, it’s critical to implement strategies such as pruning to prevent overfitting when using decision tree classifiers.</p>
    <p class="normal">Another limitation of decision tree classifiers is their struggle with non-linear relationships. Their rules are predominantly linear, and as such, they may not capture the nuances of relationships that aren’t straight-line in nature. Therefore, while decision trees bring some impressive strengths to the table, their weaknesses warrant careful consideration when choosing the appropriate model for your data.</p>
    <h2 id="_idParaDest-252" class="heading-2">Use cases</h2>
    <p class="normal">Decision trees <a id="_idIndexMarker662"/>classifiers can be used in the following use cases to classify data:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Mortgage applications</strong>: To train a binary classifier to determine whether an applicant is likely to default.</li>
      <li class="bulletList"><strong class="keyWord">Customer segmentation</strong>: To categorize customers into high-worth, medium-worth, and low-worth customers so that marketing strategies can be customized for each category.</li>
      <li class="bulletList"><strong class="keyWord">Medical diagnosis</strong>: To train a classifier that can categorize a benign or malignant growth.</li>
      <li class="bulletList"><strong class="keyWord">Treatment-effectiveness analysis</strong>: To train a classifier that can flag patients who have reacted positively to a particular treatment.</li>
      <li class="bulletList"><strong class="keyWord">Using a decision tree for feature selection</strong>: Another aspect worth discussing when examining decision tree classifiers is their feature selection capability. In the process of rule creation, decision trees tend to choose a subset of features from your dataset. This inherent trait of decision trees can be beneficial, especially when dealing with datasets that have a large number of features.</li>
    </ul>
    <p class="normal">Why is this feature selection important, you might ask? In machine learning, dealing with numerous features can be a challenge. An excess of features can lead to models that are complex, harder to interpret, and may even result in worse performance due to the ‘curse of dimensionality.’ </p>
    <p class="normal">By automatically selecting a subset of the most important features, decision trees can simplify a model and focus on the most relevant predictors.</p>
    <p class="normal">Notably, the feature selection process within decision trees isn’t confined to their own model development. The outcomes of this process can also serve as a form of preliminary feature selection for other machine learning models. This can provide an initial understanding of which features are most important and help streamline the development of other machine learning models.</p>
    <p class="normal">Next, let us look into the ensemble methods.</p>
    <h1 id="_idParaDest-253" class="heading-1">Understanding the ensemble methods</h1>
    <p class="normal">In the domain of machine learning, an ensemble refers to a technique where multiple models, each with <a id="_idIndexMarker663"/>slight variations, are created and combined to form a composite or aggregate model. The variations could arise from using different model parameters, subsets of the data, or even different machine learning algorithms.</p>
    <p class="normal">However, what does “slightly different” mean in this context? Here, each individual model in the ensemble is created to be unique, but not radically different. This can be achieved by tweaking the hyperparameters, training each model on a different subset of training data, or using diverse algorithms. The aim is to have each model capture different aspects or nuances of the data, which can help enhance the overall predictive power when they’re combined.</p>
    <p class="normal">So, how are these models combined? The ensemble technique involves a process of decision-making known as aggregation, where the predictions from individual models are consolidated. This could be a simple average, a majority vote, or a more complex approach, depending on the specific ensemble technique used.</p>
    <p class="normal">As for when and why ensemble methods are needed, they can be particularly useful when a single model isn’t sufficient to achieve a high level of accuracy. By combining multiple models, the ensemble can capture more complexity and often achieve better performance. This is because the ensemble can average out biases, reduce variance, and is less likely to overfit to the training data.</p>
    <p class="normal">Finally, assessing the effectiveness of an ensemble is similar to evaluating a single model. Metrics such as accuracy, precision, recall, or F1-score can be used, depending on the nature of the problem. The key difference is that these metrics are applied to the aggregated predictions of the ensemble rather than the predictions of a single model.</p>
    <p class="normal"> Let’s look at some ensemble algorithms, starting with XGBoost.</p>
    <h2 id="_idParaDest-254" class="heading-2">Implementing gradient boosting with the XGBoost algorithm</h2>
    <p class="normal">XGBoost, introduced <a id="_idIndexMarker664"/>in 2014, is an ensemble classification algorithm that’s gained widespread <a id="_idIndexMarker665"/>popularity, primarily <a id="_idIndexMarker666"/>due to its foundation on the principles of gradient boosting. But what does gradient boosting entail? Essentially, it’s a machine learning technique that involves building many models sequentially, with each new model attempting to correct the errors made by the previous ones. This progression continues until a significant reduction in error rate is achieved, or a pre-defined number of models has been added.</p>
    <p class="normal">In the context of XGBoost, it employs a collection of interrelated decision trees and optimizes their predictions using gradient descent, a popular optimization algorithm that aims to find the minimum of a function – in this case, the residual error. In simpler terms, gradient descent iteratively adjusts the model to minimize the difference between its predictions and the actual values.</p>
    <p class="normal">The design of XGBoost makes it well suited for distributed computing environments. This compatibility extends to Apache Spark – a platform for large-scale data processing, and cloud computing <a id="_idIndexMarker667"/>platforms like Google Cloud and <strong class="keyWord">Amazon Web Services</strong> (<strong class="keyWord">AWS</strong>). These platforms provide the computational resources needed to efficiently run XGBoost, especially on larger datasets.</p>
    <p class="normal">Now, we will walk through the process of implementing gradient boosting using the XGBoost <a id="_idIndexMarker668"/>algorithm. Our journey includes preparing the data, training the model, generating predictions, and evaluating the model’s performance. Firstly, data preparation <a id="_idIndexMarker669"/>is key to properly <a id="_idIndexMarker670"/>utilizing the XGBoost algorithm. Raw data often contains inconsistencies, missing values, or variable types that might not be suitable for the algorithm. Therefore, it’s imperative to preprocess and clean the data, normalizing numerical fields and encoding categorical ones as needed. Once our data is appropriately formatted, we can proceed with model training. An instance of the XGBClassifier has been created, which we’ll use to fit our model. Let us look at the steps:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">This process is trained using the <code class="inlineCode">X_train</code> and <code class="inlineCode">y_train</code> data subsets, representing our features and labels respectively:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> xgboost <span class="hljs-keyword">import</span> XGBClassifier
classifier = XGBClassifier()
classifier.fit(X_train, y_train)
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=None, num_parallel_tree=None,
              predictor=None, random_state=None, ...)
</code></pre>
      </li>
      <li class="numberedList">Then, we will generate predictions based on the newly trained model:
        <pre class="programlisting code"><code class="hljs-code">y_pred = classifier.predict(X_test)
cm = metrics.confusion_matrix(y_test, y_pred)
</code></pre>
      </li>
      <li class="numberedList">The produces the following output:
        <pre class="programlisting code"><code class="hljs-code">cm
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">array([[64, 4],
       [4, 28]])
</code></pre>
      </li>
      <li class="numberedList">Finally, we will quantify the performance of the model:
        <pre class="programlisting code"><code class="hljs-code">accuracy = metrics.accuracy_score(y_test,y_pred)
recall = metrics.recall_score(y_test,y_pred)
precision = metrics.precision_score(y_test,y_pred)
<span class="hljs-built_in">print</span>(accuracy,recall,precision)
</code></pre>
      </li>
      <li class="numberedList">This <a id="_idIndexMarker671"/>gives us <a id="_idIndexMarker672"/>the following output:
        <pre class="programlisting con"><code class="hljs-con">0.92 0.875 0.875
</code></pre>
      </li>
    </ol>
    <p class="normal">Now, let’s look at the Random Forest algorithm.</p>
    <p class="normal">The Random Forest algorithm is <a id="_idIndexMarker673"/>an ensemble learning method that achieves its effectiveness by combining the outputs of numerous decision trees, thereby reducing both bias and variance. Here, let’s dive deeper into how it’s trained and how it generates predictions. In training, the Random Forest algorithm leverages a technique known as bagging, or bootstrap-aggregating. It generates <code class="inlineCode">N</code> subsets from the training dataset, each created by randomly selecting some rows and columns from the input data. This selection process introduces randomness into the model, hence the name ‘Random Forest.’ Each subset of data is used to train an independent decision tree, resulting in a collection of trees denoted as C<sub class="subscript">1</sub> through C<sub class="subscript">m</sub>. These trees can be of any type, but typically, they’re binary trees where each node splits the data based on a single feature.</p>
    <p class="normal">In terms of predictions, the Random Forest model employs a democratic voting system. When a new instance of data is fed into the model for prediction, each decision tree in the forest generates its own label. The final prediction is determined by majority voting, meaning the label that received the most votes from all the trees becomes the overall prediction. </p>
    <p class="normal">It is shown in <em class="italic">Figure 7.12</em>:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_12.png" alt="Diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.12: Random Forest</p>
    <p class="normal">Note that in <em class="italic">Figure 7.12</em>, <em class="italic">m</em> trees are trained, which is represented by <em class="italic">C</em><sub class="subscript">1</sub> to <em class="italic">C</em><sub class="subscript">m</sub>—that is, <em class="italic">Trees = {C</em><sub class="subscript">1</sub><em class="italic">,..,C</em><sub class="subscript">m</sub><em class="italic">}</em>.</p>
    <p class="normal">Each of the trees <a id="_idIndexMarker674"/>generates a prediction, which is represented by a set:</p>
    <p class="normal"><em class="italic">Individual predictions = P= {P</em><sub class="subscript">1</sub><em class="italic">,..., P</em><sub class="subscript">m</sub><em class="italic">}</em></p>
    <p class="normal">The final prediction is represented by <code class="inlineCode">Pf</code>. It is determined by the majority of the individual predictions. The <code class="inlineCode">mode</code> function can be used to find the majority decision (<code class="inlineCode">mode</code> is the number that repeats most often and is in the majority). The individual prediction and the final prediction are linked, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">Pf = mode (P)
</code></pre>
    <p class="normal">This ensemble technique offers several benefits. Firstly, the randomness introduced into both data selection and decision tree construction reduces the risk of overfitting, increasing model robustness. Secondly, each tree in the forest operates independently, making Random Forest models highly parallelizable and, hence, suitable for large datasets. Lastly, Random Forest models are versatile, capable of handling both regression and classification tasks, and dealing effectively with missing or outlier data.</p>
    <p class="normal">However, keep in mind that the effectiveness of a Random Forest model heavily depends on the number of trees it contains. Having too few might lead to a weak model, while too many could result in unnecessary computation. It’s important to fine-tune this parameter based on the specific needs of your application.</p>
    <h2 id="_idParaDest-255" class="heading-2">Differentiating the Random Forest algorithm from ensemble boosting</h2>
    <p class="normal">Random Forest and ensemble boosting represent two distinct approaches to ensemble learning, a powerful <a id="_idIndexMarker675"/>method in machine <a id="_idIndexMarker676"/>learning that combines multiple models to create more robust and accurate predictions.</p>
    <p class="normal">In the Random Forest algorithm, each decision tree operates independently, uninfluenced by the performance or structure of the other trees in the forest. Each tree is built from a different subset of the data and uses a different subset of features for its decisions, adding to the overall diversity of the ensemble. The final output is determined by aggregating the predictions from all the trees, typically through a majority vote.</p>
    <p class="normal">Ensemble boosting, on the other hand, employs a sequential process where each model is aware of the mistakes made by its predecessors. Boosting techniques generate a sequence of models where each successive model aims to correct the errors of the previous one. This is achieved by assigning higher weights to the misclassified instances in the training set for the next model in the sequence. The final prediction is a weighted sum of the predictions made by all models in the ensemble, effectively giving more influence to more accurate models.</p>
    <p class="normal">In essence, while Random Forest leverages the power of independence and diversity, ensemble boosting focuses on correcting mistakes and improving from past errors. Each approach has its own strengths and can be more effective, depending on the nature and structure of the data being modeled.</p>
    <h2 id="_idParaDest-256" class="heading-2">Using the Random Forest algorithm for the classifiers challenge</h2>
    <p class="normal">Let’s <a id="_idIndexMarker677"/>instantiate the Random <a id="_idIndexMarker678"/>Forest algorithm and use it to train our model using the training data.</p>
    <p class="normal">There are two key hyperparameters that we’ll look at here:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">n_estimators</code></li>
      <li class="bulletList"><code class="inlineCode">max_depth</code></li>
    </ul>
    <p class="normal">The <code class="inlineCode">n_estimators</code> hyperparameter determines the number of individual decision trees that are constructed within the ensemble. Essentially, it dictates the size of the ‘forest.’ A larger number of trees generally leads to more robust predictions, as it increases the diversity of decision paths and a model’s ability to generalize. However, it’s important to note that adding more trees also increases the computational complexity, and beyond a certain point, the improvements in accuracy may become negligible.</p>
    <p class="normal">On the other hand, the <code class="inlineCode">max_depth</code> hyperparameter specifies the maximum depth that each individual tree can reach. In the context of a decision tree, ‘depth’ refers to the longest <a id="_idIndexMarker679"/>path from the root node (the starting point at the top of the tree) to a leaf node (the final decision outputs at the bottom). By limiting the maximum depth, we essentially control the complexity <a id="_idIndexMarker680"/>of the learned structures, balancing the trade-off between underfitting and overfitting. A tree that’s too shallow may miss important decision rules, while a tree that’s too deep may overfit to the training data, capturing noise and outliers.</p>
    <p class="normal">Fine-tuning these two hyperparameters plays a vital role in optimizing the performance of your decision-tree-based models, striking the right balance between predictive power and computational efficiency.</p>
    <p class="normal">To train a classifier using the Random Forest algorithm, we will do the following:</p>
    <pre class="programlisting code"><code class="hljs-code">classifier = RandomForestClassifier(n_estimators = <span class="hljs-number">10</span>, max_depth = <span class="hljs-number">4</span>,
criterion = <span class="hljs-string">'entropy'</span>, random_state = <span class="hljs-number">0</span>)
classifier.fit(X_train, y_train)
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">RandomForestClassifier(n_estimators = 10, max_depth = 4,criterion = 'entropy', random_state = 0)
</code></pre>
    <p class="normal">Once the Random Forest model is trained, let’s use it for predictions:</p>
    <pre class="programlisting code"><code class="hljs-code">y_pred = classifier.predict(X_test)
cm = metrics.confusion_matrix(y_test, y_pred)
cm
</code></pre>
    <p class="normal">Which gives the output as:</p>
    <pre class="programlisting con"><code class="hljs-con">array ([[64, 4],
        [3, 29]])
</code></pre>
    <p class="normal">Now, let’s quantify how good our model is:</p>
    <pre class="programlisting code"><code class="hljs-code">accuracy= metrics.accuracy_score(y_test,y_pred)
recall = metrics.recall_score(y_test,y_pred)
precision = metrics.precision_score(y_test,y_pred)
<span class="hljs-built_in">print</span>(accuracy,recall,precision)
</code></pre>
    <p class="normal">We will observe the following output:</p>
    <pre class="programlisting con"><code class="hljs-con">0.93 0.90625 0.8787878787878788
</code></pre>
    <p class="normal">Note <a id="_idIndexMarker681"/>that Random Forest is a popular and versatile machine learning method that can be used for both classification <a id="_idIndexMarker682"/>and regression tasks. It is renowned for its simplicity, robustness, and flexibility, making it applicable across a broad range of contexts.</p>
    <p class="normal">Next, let’s look into logistic regression.</p>
    <h1 id="_idParaDest-257" class="heading-1">Logistic regression</h1>
    <p class="normal">Logistic regression is a classification algorithm used for binary classification. It uses a logistic function <a id="_idIndexMarker683"/>to formulate the interaction between the input features and the label. It is one of the simplest classification techniques that is used to model a binary dependent variable.</p>
    <h2 id="_idParaDest-258" class="heading-2">Assumptions</h2>
    <p class="normal">Logistic <a id="_idIndexMarker684"/>regression assumes the following:</p>
    <ul>
      <li class="bulletList">The training dataset does not have a missing value.</li>
      <li class="bulletList">The label is a binary category variable.</li>
      <li class="bulletList">The label is ordinal—in other words, a categorical variable with ordered values.</li>
      <li class="bulletList">All features or input variables are independent of each other.</li>
    </ul>
    <h2 id="_idParaDest-259" class="heading-2">Establishing the relationship</h2>
    <p class="normal">For logistic <a id="_idIndexMarker685"/>regression, the predicted value is calculated as follows:</p>
    <p class="center"><em class="italic"><img src="../Images/B18046_07_035.png" alt="" role="presentation"/></em></p>
    <p class="normal">Let’s suppose that:</p>
    <p class="center"><em class="italic"><img src="../Images/B18046_07_036.png" alt="" role="presentation"/></em></p>
    <p class="normal">So now:</p>
    <p class="center"><img src="../Images/B18046_07_016.png" alt="" role="presentation"/></p>
    <p class="normal">The preceding <a id="_idIndexMarker686"/>relationship can be graphically shown as follows:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_13.png" alt="Chart, line chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.13: Plotting the sigmoid function</p>
    <p class="normal">Note that if <em class="italic">z</em> is large, <img src="../Images/B18046_07_017.png" alt="" role="presentation"/> (<em class="italic">z</em>) will equal <code class="inlineCode">1</code>. If <em class="italic">z</em> is very small or a large negative number, <img src="../Images/B18046_07_017.png" alt="" role="presentation"/> (<em class="italic">z</em>) will equal <code class="inlineCode">0</code>. Also, when <em class="italic">z</em> is 0, then <img src="../Images/B18046_07_017.png" alt="" role="presentation"/> (<em class="italic">z</em>)=0.5. Sigmoid is a natural function to use to represent probabilities, as it is strictly bounded between 0 and 1. By ‘natural,’ we mean it is well suited or particularly effective due to its inherent properties. In this case, the sigmoid function always outputs a value between 0 and 1, which aligns with the probability range. This makes it a great tool for modeling probabilities in logistic regression. The objective of training a logistic regression model is to find the correct values for <em class="italic">w</em> and <em class="italic">j</em>.</p>
    <div class="note">
      <p class="normal">Logistic regression <a id="_idIndexMarker687"/>is named after the function that is used to <a id="_idIndexMarker688"/>formulate it, called the <strong class="keyWord">logistic</strong> or <strong class="keyWord">sigmoid function</strong>.</p>
    </div>
    <h2 id="_idParaDest-260" class="heading-2">The loss and cost functions</h2>
    <p class="normal">The <code class="inlineCode">loss</code> function defines how we want to quantify an error for a particular example in our training data. The <code class="inlineCode">cost</code> function defines how we want to minimize an error in our entire training <a id="_idIndexMarker689"/>dataset. So, the <code class="inlineCode">loss</code> function is used for one <a id="_idIndexMarker690"/>of the examples in the training dataset and the <code class="inlineCode">cost</code> function is <a id="_idIndexMarker691"/>used for the overall cost that quantifies the overall deviation <a id="_idIndexMarker692"/>of the actual and predicted values. It is dependent on the choice of <em class="italic">w </em>and <em class="italic">h</em>.</p>
    <p class="normal">The <code class="inlineCode">loss</code> function used in logistic regression for a certain example <em class="italic">i</em> in the training set is as follows:</p>
    <p class="center"><em class="italic">Loss (ý</em><sup class="superscript">(i)</sup><em class="italic">, y</em><sup class="superscript">(i)</sup><em class="italic">) = - (y</em><sup class="superscript">(i)</sup><em class="italic"> log ý</em><sup class="superscript">(i)</sup><em class="italic"> + (1-y</em><sup class="superscript">(i)</sup><em class="italic"> ) log (1-ý</em><sup class="superscript">(i)</sup><em class="italic">)</em></p>
    <p class="normal">Note that when <em class="italic">y</em><sup class="superscript">(i)</sup><em class="italic"> = 1, Loss(ý</em><sup class="superscript">(i)</sup><em class="italic">, y</em><sup class="superscript">(i)</sup><em class="italic">) = - logý</em><sup class="superscript">(i)</sup>. Minimizing the loss will result in a large value of ý<sup class="superscript">(i)</sup>. Being a sigmoid function, the maximum value will be <em class="italic">1</em>.</p>
    <p class="normal">If <em class="italic">y</em><sup class="superscript">(i)</sup><em class="italic"> = 0, Loss (ý</em><sup class="superscript">(i)</sup><em class="italic">, y</em><sup class="superscript">(i)</sup><em class="italic">) = - log (1-ý</em><sup class="superscript">(i)</sup><em class="italic">)</em>.</p>
    <p class="normal">Minimizing the loss will result in <em class="italic">ý</em><sup class="superscript">(i)</sup> being as small as possible, which is <em class="italic">0</em>.</p>
    <p class="normal">The cost function of logistic regression is as follows:</p>
    <p class="center"><img src="../Images/B18046_07_020.png" alt="" role="presentation"/></p>
    <p class="normal">Let us now look into the details of logistic regression.</p>
    <h2 id="_idParaDest-261" class="heading-2">When to use logistic regression</h2>
    <p class="normal">Logistic regression <a id="_idIndexMarker693"/>works great for binary classifiers. To clarify, binary classification refers to the process of predicting one of two possible outcomes. For example, if we try to predict whether an email is spam or not, this is a binary classification problem because there are only two possible results – ‘spam’ or ‘not spam.’</p>
    <p class="normal">However, there are certain limitations to logistic regression. Particularly, it may struggle when dealing with large datasets of subpar quality. For instance, consider a dataset filled with numerous missing values, outliers, or irrelevant features. The logistic regression model might find it difficult to produce accurate predictions under these circumstances.</p>
    <p class="normal">Further, while logistic <a id="_idIndexMarker694"/>regression can handle linear relationships between features and the target variable effectively, it can fall short when dealing with complex, non-linear relationships. Picture a dataset where the relationship between the predictor variables and the target is not a straight line but a curve; a logistic regression model might struggle in such scenarios.</p>
    <p class="normal">Despite these limitations, logistic regression can often serve as a solid starting point for classification tasks. It provides a benchmark performance that can be used to compare the effectiveness of more complex models. Even if it doesn’t deliver the highest accuracy, it does offer interpretability and simplicity, which can be valuable in certain contexts.</p>
    <h2 id="_idParaDest-262" class="heading-2">Using the logistic regression algorithm for the classifiers challenge</h2>
    <p class="normal">In this section, we will <a id="_idIndexMarker695"/>see how we can use the <a id="_idIndexMarker696"/>logistic regression algorithm for the classifiers challenge:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">First, let’s instantiate a logistic regression model and train it using the training data:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
classifier = LogisticRegression(random_state = <span class="hljs-number">0</span>)
classifier.fit(X_train, y_train)
</code></pre>
      </li>
      <li class="numberedList">Let’s predict the values of the <code class="inlineCode">test</code> data and create a confusion matrix:
        <pre class="programlisting code"><code class="hljs-code">y_pred = classifier.predict(X_test)
cm = metrics.confusion_matrix(y_test, y_pred)
cm
</code></pre>
      </li>
      <li class="numberedList">We get the following output upon running the preceding code:
        <pre class="programlisting con"><code class="hljs-con">array ([[65, 3],
        [6, 26]])
</code></pre>
      </li>
      <li class="numberedList">Now, let’s <a id="_idIndexMarker697"/>look at the performance metrics:
        <pre class="programlisting code"><code class="hljs-code">accuracy= metrics.accuracy_score(y_test,y_pred)
recall = metrics.recall_score(y_test,y_pred)
precision = metrics.precision_score(y_test,y_pred)
<span class="hljs-built_in">print</span>(accuracy,recall,precision)
</code></pre>
      </li>
      <li class="numberedList">We get <a id="_idIndexMarker698"/>the following output upon running the preceding code:
        <pre class="programlisting con"><code class="hljs-con">0.91 0.8125 0.8996551724137931
</code></pre>
      </li>
    </ol>
    <p class="normal">Next, let’s look at <strong class="keyWord">SVMs</strong>.</p>
    <h1 id="_idParaDest-263" class="heading-1">The SVM algorithm</h1>
    <p class="normal">The <strong class="keyWord">SVM</strong> classifier is a robust tool in the machine learning arsenal, which functions by identifying an optimal <a id="_idIndexMarker699"/>decision boundary, or hyperplane, that distinctly segregates two classes. To further clarify, think of this ‘hyperplane’ as a line (in two dimensions), a surface (in three dimensions), or a manifold (in higher dimensions) that best separates the different classes in the feature space.</p>
    <p class="normal">The key characteristic that sets SVMs apart is their optimization goal – it aims to maximize the margin, which is the distance between the decision boundary and the closest data points from either class, known as the ‘support vectors.’ In simpler terms, the SVM algorithm doesn’t just find a line to separate the classes; it also tries to find the line that’s as far away as possible from the closest points of each class, thereby maximizing the separating gap.</p>
    <p class="normal">Consider a basic two-dimensional example where we try to separate circles from crosses. Our goal with SVMs is not just to find a line that divides these two types of shapes but also to find the line that maintains the greatest distance from the circles and crosses nearest to it.</p>
    <p class="normal">SVMs can be extremely useful when dealing with high-dimensional data, complex domains, or when the classes are not easily separable by a simple straight line. They can perform exceptionally well where logistic regression may falter, for instance, in situations with non-linearly separable data.</p>
    <p class="normal">The margin is defined as the distance between the separating hyperplane (the decision boundary) and the training samples that are closest to this hyperplane, called the <strong class="keyWord">support vectors</strong>. So, let’s start <a id="_idIndexMarker700"/>with a very basic example with only two dimensions, <em class="italic">X</em><sub class="subscript-italic" style="font-style: italic;">1</sub> and <em class="italic">X</em><sub class="subscript-italic" style="font-style: italic;">2</sub>. We want a line to separate the circles from the crosses. This is shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_14.png" alt="Chart, scatter chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.14: SVM algorithm</p>
    <p class="normal">We have drawn <a id="_idIndexMarker701"/>two lines, and both perfectly separate the crosses from the circles. However, there has to be an optimal line, or decision boundary, that gives us the best chance of correctly classifying most of the additional examples. A reasonable choice may be a line that is evenly spaced between these two classes to give a little bit of a buffer for each class, as shown here:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_15.png" alt="Diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.15: Concepts related to SVM</p>
    <p class="normal">Moreover, unlike logistic regression, SVMs are better equipped to handle smaller, cleaner datasets, and they excel at capturing complex relationships without needing a large amount of data. However, the trade-off here is interpretability – while logistic regression provides <a id="_idIndexMarker702"/>easily understandable insights into the model’s decision-making process, SVMs, being inherently more complex, are not as straightforward to interpret.</p>
    <p class="normal">Now, let’s see how we can use SVM to train a classifier for our challenge.</p>
    <h2 id="_idParaDest-264" class="heading-2">Using the SVM algorithm for the classifiers challenge</h2>
    <p class="normal">First, let’s instantiate the SVM classifier and then use the training portion of the labeled data to <a id="_idIndexMarker703"/>train it. The <code class="inlineCode">kernel</code> hyperparameter <a id="_idIndexMarker704"/>determines the type of transformation that is applied to the input data in order to make it linearly separable:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC
classifier = SVC(kernel = <span class="hljs-string">'linear'</span>, random_state = <span class="hljs-number">0</span>)
classifier.fit(X_train, y_train)
</code></pre>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Once trained, let’s generate some predictions and look at the confusion matrix:
        <pre class="programlisting code"><code class="hljs-code">y_pred = classifier.predict(X_test)
cm = metrics.confusion_matrix(y_test, y_pred)
cm
</code></pre>
      </li>
      <li class="numberedList">Observe the following output:
        <pre class="programlisting con"><code class="hljs-con">array ([[66, 2],
        [9, 23]])
</code></pre>
      </li>
      <li class="numberedList">Now, let’s look at the various performance metrics:
        <pre class="programlisting code"><code class="hljs-code">accuracy= metrics.accuracy_score(y_test,y_pred)
recall = metrics.recall_score(y_test,y_pred)
precision = metrics.precision_score(y_test,y_pred)
<span class="hljs-built_in">print</span>(accuracy,recall,precision)
</code></pre>
      </li>
    </ol>
    <p class="normal">After running the preceding code, we get the following values as our output:</p>
    <pre class="programlisting con"><code class="hljs-con">0.89 0.71875 0.92
</code></pre>
    <h2 id="_idParaDest-265" class="heading-2">Understanding the Naive Bayes algorithm</h2>
    <p class="normal">Based on probability theory, Naive Bayes is one of the simplest classification algorithms. If used <a id="_idIndexMarker705"/>properly, it can come up with accurate predictions. The Naive <a id="_idIndexMarker706"/>Bayes Algorithm is so-named for two reasons:</p>
    <ul>
      <li class="bulletList">It is based on a naive assumption that there is independence between the features and the input variable.</li>
      <li class="bulletList">It is based on Bayes’ theorem. Note that Bayes’ theorem is employed to calculate the probability of a particular class or outcome, given some observed features.</li>
    </ul>
    <p class="normal">This algorithm tries to classify instances based on the probabilities of the preceding attributes/instances, assuming complete attribute independence.</p>
    <p class="normal">There are three types of events:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Independent</strong> events do <a id="_idIndexMarker707"/>not affect the probability of another event occurring (for example, receiving an email offering you free entry to a tech event <em class="italic">and</em> a re-organization occurring in your company).</li>
      <li class="bulletList"><strong class="keyWord">Dependent </strong>events affect <a id="_idIndexMarker708"/>the probability of another event occurring; that is, they are linked in some way (for example, the probability of you getting to a conference on time could be affected by an airline staff strike or flights that may not run on time).</li>
      <li class="bulletList"><strong class="keyWord">Mutually exclusive</strong> events cannot occur simultaneously (for example, the probability of <a id="_idIndexMarker709"/>rolling a three and a six on a single dice roll is 0—these two outcomes are mutually exclusive).</li>
    </ul>
    <h1 id="_idParaDest-266" class="heading-1">Bayes’ theorem</h1>
    <p class="normal">Bayes’ theorem is <a id="_idIndexMarker710"/>used to calculate the conditional probability between two independent events, <em class="italic">A</em> and <em class="italic">B</em>. The probability of events <em class="italic">A</em> and <em class="italic">B </em>happening is represented by <em class="italic">P</em>(<em class="italic">A</em>) and <em class="italic">P</em>(<em class="italic">B</em>). The conditional probability is represented by <em class="italic">P</em>(<em class="italic">B</em>|<em class="italic">A</em>), which is the conditional probability that event <em class="italic">B</em> will happen given that event <em class="italic">A</em> has occurred:</p>
    <p class="center"><img src="../Images/B18046_07_021.png" alt="" role="presentation"/></p>
    <p class="normal">When it comes to applying Naive Bayes, the algorithm is particularly effective in scenarios where <a id="_idIndexMarker711"/>the dimensionality of the inputs (number of features) is high. This makes it well suited for text classification tasks such as spam detection or sentiment analysis. </p>
    <p class="normal">It can handle both continuous and discrete data, and it’s computationally efficient, making it useful for real-time predictions. Naive Bayes is also a good choice when you have limited computational resources and need a quick and easy implementation, but it’s worth noting that its “naive” assumption of feature independence can be a limitation in some cases.</p>
    <h2 id="_idParaDest-267" class="heading-2">Calculating probabilities</h2>
    <p class="normal">Naive Bayes is based on probability fundamentals. The probability of a single event occurring (the observational probability) is calculated by taking the number of times the event occurred <a id="_idIndexMarker712"/>and dividing it by the total number of processes that could have led to that event. For example, a call center receives over 100 support calls per day, which is 50 times over the course of a month. You want to know the probability that a call is responded to in under three minutes, based on the previous amount of time in which it was responded to. If the call center manages to match this time record on 27 occasions, then the observational probability of 100 calls being answered in under three minutes is as follows:</p>
    <p class="center"><em class="italic">P(100 support calls in under 3 mins) = (27 / 50) = 0.54 (54%)</em></p>
    <p class="normal">One hundred calls can be responded to in under three minutes in about half the time, based on the records of the 50 times it occurred in the past.</p>
    <p class="normal">Now, let us look into the multiplication rules for <code class="inlineCode">AND</code> events.</p>
    <h2 id="_idParaDest-268" class="heading-2">Multiplication rules for AND events</h2>
    <p class="normal">To calculate the probability of two or more events occurring simultaneously, consider whether <a id="_idIndexMarker713"/>events are independent or dependent. If they are independent, the simple multiplication rule is used:</p>
    <p class="center"><em class="italic">P(outcome 1 AND outcome 2) = P(outcome 1) * P(outcome 2)</em></p>
    <p class="normal">For example, to calculate the probability of receiving an email with free entry to a tech event <em class="italic">and</em> re-organization occurring in your workplace, this simple multiplication rule would be used. The two events are independent, as the occurrence of one does not affect the chance of the other occurring.</p>
    <p class="normal">If receiving the tech event email has a probability of 31% and the probability of staff re-organization is 82%, then the probability of both occurring is calculated as follows:</p>
    <p class="center"><em class="italic">P(email AND re-organization) = P(email) * P(re-organization) = (0.31) * (0.82) = 0.2542 (25%)</em></p>
    <h2 id="_idParaDest-269" class="heading-2">The general multiplication rule</h2>
    <p class="normal">If two or more events are dependent, the general multiplication rule is used. This formula is <a id="_idIndexMarker714"/>actually valid in both cases of independent and dependent events:</p>
    <p class="center"><em class="italic">P(outcome 1 AND outcome 2)=P(outcome 1)*P(outcome 2 | outcome 1)</em></p>
    <p class="normal">Note that <em class="italic">P(outcome 2 | outcome 1)</em> refers to the conditional probability of <code class="inlineCode">outcome 2</code> occurring given that <code class="inlineCode">outcome 1</code> has already occurred. The formula incorporates the dependence between the events. If the events are independent, then the conditional probability is irrelevant as one outcome does not influence the chance of the other occurring, and <em class="italic">P(outcome 2 | outcome 1)</em> is simply <em class="italic">P(outcome 2)</em>. Note that the formula in this case just becomes the simple multiplication rule.</p>
    <p class="normal">Let’s illustrate this with a simple example. Suppose you’re drawing two cards from a deck, and you want to know the probability of drawing an ace first and then a king. The first event (drawing an ace) modifies the conditions for the second event (drawing a king) since we’re not replacing the ace in the deck. According to the general multiplication rule, we can calculate this as <em class="italic">P(ace) * P(king | ace)</em>, where <em class="italic">P(king | ace)</em> is the probability of drawing a King given that we’ve already drawn an ace.</p>
    <h2 id="_idParaDest-270" class="heading-2">Addition rules for OR events</h2>
    <p class="normal">When calculating the probability of either one event or the other occurring (mutually exclusive), the following simple addition rule is used:</p>
    <p class="center"><em class="italic">P(outcome 1 OR outcome 2) = P(outcome 1) + P(outcome 2)</em></p>
    <p class="normal">For example, what is the probability of rolling a 6 or a 3? To answer this question, first, note that <a id="_idIndexMarker715"/>both outcomes cannot occur simultaneously. The probability of rolling a 6 is (1 / 6) and the same can be said for rolling a 3:</p>
    <p class="center"><em class="italic">P(6 OR 3) = (1 / 6) + (1 / 6) = 0.33 (33%)</em></p>
    <p class="normal">If the events are not mutually exclusive and can occur simultaneously, use the following general addition formula, which is always valid in both cases of mutual exclusiveness and non-mutual exclusiveness:</p>
    <p class="center"><em class="italic">P(outcome 1 OR outcome 2) = P(outcome 1) + P(outcome 2) P(outcome 1 AND outcome 2)</em></p>
    <h2 id="_idParaDest-271" class="heading-2">Using the Naive Bayes algorithm for the classifiers challenge</h2>
    <p class="normal">Now, let’s <a id="_idIndexMarker716"/>use the Naive Bayes algorithm <a id="_idIndexMarker717"/>to solve the classifiers challenge:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">First, we will import the <code class="inlineCode">GaussianNB()</code> function and use it to train the model:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Fitting Decision Tree Classification to the Training set</span>
<span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">GaussianNB()
</code></pre>
      </li>
      <li class="numberedList">Now, let’s use the trained model to predict the results. We will use it to predict the labels for our test partition, which is <code class="inlineCode">X_test</code>:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Predicting the Test set</span><span class="hljs-comment"> results</span>
y_pred = classifier.predict(X_test)
cm = metrics.confusion_matrix(y_test, y_pred)
</code></pre>
      </li>
      <li class="numberedList">Now, let’s print the confusion matrix:
        <pre class="programlisting code"><code class="hljs-code">cm
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">array([[66, 2],
[6, 26]])
</code></pre>
      </li>
      <li class="numberedList">Now, let’s <a id="_idIndexMarker718"/>print the performance <a id="_idIndexMarker719"/>matrices to quantify the quality of our trained model:
        <pre class="programlisting code"><code class="hljs-code">accuracy= metrics.accuracy_score(y_test,y_pred)
recall = metrics.recall_score(y_test,y_pred)
precision = metrics.precision_score(y_test,y_pred)
<span class="hljs-built_in">print</span>(accuracy,recall,precision)
</code></pre>
      </li>
    </ol>
    <p class="normal">Which gives the output as:</p>
    <pre class="programlisting con"><code class="hljs-con">0.92 0.8125 0.9285714285714286
</code></pre>
    <h1 id="_idParaDest-272" class="heading-1">For classification algorithms, the winner is...</h1>
    <p class="normal">Let’s take a moment to compare the performance metrics of the various algorithms we’ve discussed. However, keep in mind that these metrics are highly dependent on the data we’ve used <a id="_idIndexMarker720"/>in these examples, and they can significantly vary for different datasets. </p>
    <p class="normal">The performance of a model can be influenced by factors such as the nature of the data, the quality of the data, and how well the assumptions of the model align with the data.</p>
    <p class="normal">Here’s a summary of our observations:</p>
    <table id="table005-1" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Algorithm</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Accuracy</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Recall</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Precision</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Decision tree</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.94</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.93</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.88</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">XGBoost</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">0.93</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.90</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.87</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">Random Forest</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">0.93</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.90</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.87</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">Logistic regression</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">0.91</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.81</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.89</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">SVM</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">0.89</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.71</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.92</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">Naive Bayes</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">0.92</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.81</p>
          </td>
          <td class="table-cell">
            <p class="normal">0.92</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">From the table above, the decision tree classifier exhibits the highest performance in terms of both accuracy and recall in this particular context. For precision, we see a tie between the SVM and Naive Bayes algorithms.</p>
    <p class="normal">However, remember that these results are data-dependent. For instance, SVM might excel in scenarios where data is linearly separable or can be made so through kernel transformations. Naive Bayes, on the other hand, performs well when the features are independent. Decision trees and Random Forests might be preferred when we have complex non-linear relationships. Logistic regression is a solid choice for binary classification tasks <a id="_idIndexMarker721"/>and can serve as a good benchmark model. Lastly, XGBoost, being an ensemble technique, is powerful when dealing with a wide range of data types and often leads in terms of model performance across various tasks.</p>
    <p class="normal">So, it’s critical to understand your data and the requirements of your task before choosing a model. These results are merely a starting point, and deeper exploration and validation should be performed for each specific use case.</p>
    <h2 id="_idParaDest-273" class="heading-2">Understanding regression algorithms</h2>
    <p class="normal">A supervised machine learning model uses one of the regression algorithms if the label is a <a id="_idIndexMarker722"/>continuous variable. In this case, the machine learning model is called a regressor.</p>
    <p class="normal">To provide a <a id="_idIndexMarker723"/>more concrete understanding, let’s take a couple of examples. Suppose we want to predict the temperature for the next week based on historical data, or we aim to forecast sales for a retail store in the coming months. </p>
    <p class="normal">Both temperatures and sales figures are continuous variables, which means they can take on any value within a specified range, as opposed to categorical variables, which have a fixed number of distinct categories. In such scenarios, we would use a regressor rather than a classifier.</p>
    <p class="normal">In this section, we will present various algorithms that can be used to train a supervised machine learning regression model—or, put simply, a regressor. Before we go into the details of the algorithms, let’s first create a challenge for these algorithms to test their performance, abilities, and effectiveness.</p>
    <h2 id="_idParaDest-274" class="heading-2">Presenting the regressors challenge</h2>
    <p class="normal">Similar to the approach that we used with the classification algorithms, we will first present a <a id="_idIndexMarker724"/>problem to be solved as a challenge for all <a id="_idIndexMarker725"/>regression algorithms. We will call this common problem the regressors challenge. Then, we will use three different regression algorithms to address the challenge. This approach of using a common challenge for different regression algorithms has two benefits:</p>
    <ul>
      <li class="bulletList">We can prepare the data once and use the prepared data on all three regression algorithms.</li>
      <li class="bulletList">We can compare the performance of three regression algorithms in a meaningful way, as we will use them to solve the same problem.</li>
    </ul>
    <p class="normal">Let’s look at the problem statement of the challenge.</p>
    <h2 id="_idParaDest-275" class="heading-2">The problem statement of the regressors challenge</h2>
    <p class="normal">Predicting the mileage of different vehicles is important these days. An efficient vehicle is good <a id="_idIndexMarker726"/>for the environment and is also cost-effective. The mileage can be estimated from the power of the engine <a id="_idIndexMarker727"/>and the characteristics of the vehicle. Let’s create a challenge for regressors to train a model that can predict the <strong class="keyWord">Miles per Gallon</strong> (<strong class="keyWord">MPG</strong>) of a vehicle <a id="_idIndexMarker728"/>based on its characteristics.</p>
    <p class="normal">Let’s look at the historical dataset that we will use to train the regressors.</p>
    <h2 id="_idParaDest-276" class="heading-2">Exploring the historical dataset</h2>
    <p class="normal">The following <a id="_idIndexMarker729"/>are the features <a id="_idIndexMarker730"/>of the historical dataset data that we have:</p>
    <table id="table006-1" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Name</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Type</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Description</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">NAME</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Category</p>
          </td>
          <td class="table-cell">
            <p class="normal">Identifies a particular vehicle</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">CYLINDERS</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Continuous</p>
          </td>
          <td class="table-cell">
            <p class="normal">The number of cylinders (between four and eight)</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">DISPLACEMENT</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Continuous</p>
          </td>
          <td class="table-cell">
            <p class="normal">The displacement of the engine in cubic inches</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">HORSEPOWER</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Continuous</p>
          </td>
          <td class="table-cell">
            <p class="normal">The horsepower of the engine</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">ACCELERATION</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Continuous</p>
          </td>
          <td class="table-cell">
            <p class="normal">The time it takes to accelerate from 0 to 60 mph (in seconds)</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">The label <a id="_idIndexMarker731"/>for this problem is a continuous <a id="_idIndexMarker732"/>variable, <code class="inlineCode">MPG</code>, that specifies the MPG for each of the vehicles.</p>
    <p class="normal">Let’s first design the data processing pipeline for this problem.</p>
    <h2 id="_idParaDest-277" class="heading-2">Feature engineering using a data processing pipeline</h2>
    <p class="normal">Let’s <a id="_idIndexMarker733"/>see how we <a id="_idIndexMarker734"/>can design a reusable <a id="_idIndexMarker735"/>processing pipeline to address the regressors challenge. As mentioned, we will prepare the data once and then use it in all the regression algorithms. Let’s follow these steps:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">We will start by importing the dataset, as follows:
        <pre class="programlisting code"><code class="hljs-code">dataset = pd.read_csv(<span class="hljs-string">'https://storage.googleapis.com/neurals/data/data/auto.csv'</span>)
</code></pre>
      </li>
      <li class="numberedList">Let’s now preview the dataset:
        <pre class="programlisting code"><code class="hljs-code">dataset.head(<span class="hljs-number">5</span>)
</code></pre>
      </li>
      <li class="numberedList">This is how the dataset will look:</li>
    </ol>
    <figure class="mediaobject"><img src="../Images/B18046_07_16.png" alt="Table  Description automatically generated with medium confidence"/> </figure>
    <p class="packt_figref">Figure 7.16: Please add a caption here</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="4">Now, let’s proceed on to feature selection. Let’s drop the <code class="inlineCode">NAME</code> column, as it is only an identifier that is needed for cars. Columns that are used to identify the rows in our dataset are not relevant to training the model. Let’s drop this column.</li>
      <li class="numberedList">Let’s convert all of the input variables and impute all the <code class="inlineCode">null</code> values:
        <pre class="programlisting code"><code class="hljs-code">dataset=dataset.drop(columns=[<span class="hljs-string">'NAME'</span>])
dataset.head(<span class="hljs-number">5</span>)
dataset= dataset.apply(pd.to_numeric, errors=<span class="hljs-string">'coerce'</span>)
dataset.fillna(<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
      
    <p class="normal">Imputation improves the quality of the data and prepares it to be used to train the model. Now, let’s see the final step.</p></li>
    </ol>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="6">Let’s <a id="_idIndexMarker736"/>divide the data into testing and training partitions:
        <pre class="programlisting code"><code class="hljs-code">y=dataset[<span class="hljs-string">'MPG'</span>]
X=dataset.drop(columns=[<span class="hljs-string">'MPG'</span>])
<span class="hljs-comment"># Splitting the dataset into the Training set and Test set</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.cross_validation <span class="hljs-keyword">import</span> train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.25</span>, random_state = <span class="hljs-number">0</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal">This <a id="_idIndexMarker737"/>has created the following four data structures:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">X_train</code>: A data structure containing the features of the training data</li>
      <li class="bulletList"><code class="inlineCode">X_test</code>: A data structure containing the features of the training test</li>
      <li class="bulletList"><code class="inlineCode">y_train</code>: A vector containing the values of the label in the training dataset</li>
      <li class="bulletList"><code class="inlineCode">y_test</code>: A vector containing the values of the label in the testing dataset</li>
    </ul>
    <p class="normal">Now, let’s <a id="_idIndexMarker738"/>use the prepared data on three different regressors so that we can compare their performance.</p>
    <h1 id="_idParaDest-278" class="heading-1">Linear regression</h1>
    <p class="normal">Among the <a id="_idIndexMarker739"/>assortment of supervised machine learning algorithms, linear regression is often seen as the most straightforward to grasp. Initially, we will explore simple linear regression and then gradually broaden our discussion to encompass multiple linear regression.</p>
    <p class="normal">It’s important to note, however, that while linear regression is accessible and easy to implement, it is not always the ‘best’ choice in every circumstance. Each machine learning algorithm, including the ones we’ve discussed so far, comes with its unique strengths and limitations, and their effectiveness varies depending on the type and structure of the data at hand.</p>
    <p class="normal">For instance, decision trees and Random Forests are excellent at handling categorical data and capturing complex non-linear relationships. SVMs can work well with high-dimensional <a id="_idIndexMarker740"/>data and are robust to outliers, while logistic regression is particularly effective for binary classification problems. </p>
    <p class="normal">On the other hand, linear regression models are well suited to predicting continuous outcomes and can provide interpretability, which can be valuable in understanding the impact of individual features.</p>
    <h2 id="_idParaDest-279" class="heading-2">Simple linear regression</h2>
    <p class="normal">At its most basic level, linear regression establishes a relationship between two variables, usually <a id="_idIndexMarker741"/>represented as a single independent variable and a single dependent variable. Linear regression is a technique that <a id="_idIndexMarker742"/>enables us to study how changes in the dependent variable (plotted on the <em class="italic">y</em>-axis) are influenced by changes in the independent variable (plotted on the <em class="italic">x</em>-axis). It can be represented as follows:</p>
    <p class="center"><img src="../Images/B18046_07_022.png" alt="" role="presentation"/></p>
    <p class="normal">This formula can be explained as follows:</p>
    <ul>
      <li class="bulletList"><em class="italic">y</em> is the dependent variable.</li>
      <li class="bulletList"><em class="italic">X</em> is the independent variable.</li>
      <li class="bulletList"><img src="../Images/B18046_07_023.png" alt="" role="presentation"/> is the slope that indicates how much the line rises for each increase in <em class="italic">X</em>.</li>
      <li class="bulletList"><em class="italic">α</em> is the intercept that indicates the value of <em class="italic">y</em> when <em class="italic">X</em> = 0.</li>
    </ul>
    <p class="normal">Linear regression operates under these assumptions:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Linearity</strong>: The relationship between independent and dependent variables is linear.</li>
      <li class="bulletList"><strong class="keyWord">Independence</strong>: The observations are independent of each other.</li>
      <li class="bulletList"><strong class="keyWord">No multicollinearity</strong>: The independent variables are not too highly correlated with each other.</li>
    </ul>
    <p class="normal">Some examples of relationships between a single continuous dependent variable and a single continuous independent variable are as follows:</p>
    <ul>
      <li class="bulletList">A person’s weight and their calorie intake</li>
      <li class="bulletList">The price of a house and its area in square feet in a particular neighborhood</li>
      <li class="bulletList">The humidity in the air and the likelihood of rain</li>
    </ul>
    <p class="normal">For linear regression, both the input (independent) variable and the target (dependent) variable must be numeric. The best relationship is found by minimizing the sum of the squares of the <a id="_idIndexMarker743"/>vertical distances of each point, from a line drawn through all the points. It is assumed that the relationship is linear between the predictor <a id="_idIndexMarker744"/>variable and the label. For example, the more money invested in research and development, the higher the sales.</p>
    <p class="normal">Let’s look at a specific example. Let’s try to formulate the relationship between marketing expenditures and sales for a particular product. They are found to be directly relational to each other. The marketing expenditures and sales are drawn on a two-dimensional graph and are shown as blue diamonds. The relationship can best be approximated by drawing a straight line, as shown in the following graph:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_17.png" alt="Chart, scatter chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.17: Linear regression</p>
    <p class="normal">Once the linear line is drawn, we can see the mathematical relationship between marketing expenditure and sales.</p>
    <h2 id="_idParaDest-280" class="heading-2">Evaluating the regressors</h2>
    <p class="normal">The linear line that we drew is an approximation of the relationship between the dependent <a id="_idIndexMarker745"/>and independent variables. Even the <a id="_idIndexMarker746"/>best line will have some deviation from the actual values, as shown here:</p>
    <figure class="mediaobject"><img src="../Images/B18046_07_18.png" alt="Chart, scatter chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.18: Evaluating regressors</p>
    <p class="normal">A typical <a id="_idIndexMarker747"/>way of quantifying the performance of linear regression models is by using <strong class="keyWord">Root Mean Square Error</strong> (<strong class="keyWord">RMSE</strong>). This calculates the standard deviation of the errors made by the trained model mathematically. For example, in the training dataset, the <code class="inlineCode">loss</code> function is calculated as follows:</p>
    <p class="center"><em class="italic">Loss (ý</em><sup class="superscript">(i)</sup><em class="italic">, y</em><sup class="superscript">(i)</sup><em class="italic">) = 1/2(ý</em><sup class="superscript">(i)</sup><em class="italic">- y</em><sup class="superscript">(i)</sup><em class="italic">)2</em></p>
    <p class="normal">This leads to the following <code class="inlineCode">cost</code> function, which minimizes the loss of all of the examples in the training set:</p>
    <p class="center"><img src="../Images/B18046_07_024.png" alt="" role="presentation"/></p>
    <p class="normal">Let’s try to interpret RMSE. If RMSE is $50 for our example model that predicts the price of a product, this <a id="_idIndexMarker748"/>means that around 68.2% of the <a id="_idIndexMarker749"/>predictions will fall within $50 of the true value (that is, <img src="../Images/B18046_07_025.png" alt="" role="presentation"/>). It also means that 95% of the predictions will fall within $100 (that is, <img src="../Images/B18046_07_026.png" alt="" role="presentation"/>) of the actual value. Finally, 99.7% of the predictions will fall within $150 of the actual value.</p>
    <p class="normal">Let us look into multiple regression.</p>
    <h2 id="_idParaDest-281" class="heading-2">Multiple regression</h2>
    <p class="normal">The fact is that most real-world analyses have more than one independent variable. Multiple regression <a id="_idIndexMarker750"/>is an extension of simple linear regression. The key difference is that there are additional beta coefficients for the additional <a id="_idIndexMarker751"/>predictor variables. When training a model, the goal is to find the beta coefficients that minimize the errors of the linear equation. Let’s try to mathematically formulate the relationship between the dependent variable and the set of independent variables (features). </p>
    <p class="normal">For instance, in the housing market, the price of a house (the dependent variable) could depend on numerous factors such as its size, location, age, and more (the independent variables).</p>
    <p class="normal">Similar to a simple linear equation, the dependent variable, <em class="italic">y</em>, is quantified as the sum of an intercept term, plus the product of the <img src="../Images/B18046_07_027.png" alt="" role="presentation"/> coefficients multiplied by the <em class="italic">x</em> value for each of the <em class="italic">i</em> features:</p>
    <p class="center"><img src="../Images/B18046_07_028.png" alt="" role="presentation"/></p>
    <p class="normal">The error is represented by <img src="../Images/B18046_07_029.png" alt="" role="presentation"/> and indicates that the predictions are not perfect.</p>
    <p class="normal">The <img src="../Images/B18046_07_027.png" alt="" role="presentation"/> coefficients allow each feature to have a separate estimated effect on the value of <em class="italic">y</em> because <em class="italic">y</em> changes by an amount of <img src="../Images/B18046_07_031.png" alt="" role="presentation"/> for each unit increase in <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">i</sub>. Moreover, the intercept (<img src="../Images/B18046_07_032.png" alt="" role="presentation"/>) indicates the expected value of <em class="italic">y</em> when the independent variables are all 0.</p>
    <p class="normal">Note that all <a id="_idIndexMarker752"/>the variables in the preceding equation <a id="_idIndexMarker753"/>can be represented by a bunch of vectors. The target and predictor variables are now vectors with a row, and the regression coefficients, <img src="../Images/B18046_07_033.png" alt="" role="presentation"/>, and errors, <img src="../Images/B18046_07_029.png" alt="" role="presentation"/>, are also vectors.</p>
    <p class="normal">Next, let us look into how we can use linear regression for the regressors challenge.</p>
    <h2 id="_idParaDest-282" class="heading-2">Using the linear regression algorithm for the regressors challenge</h2>
    <p class="normal">Now, let’s <a id="_idIndexMarker754"/>train the model using the training <a id="_idIndexMarker755"/>portion of the dataset. Note that we will use the same data and data engineering logic that we discussed earlier:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Let’s start by importing the linear regression package:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression
</code></pre>
      </li>
      <li class="numberedList">Then, let’s instantiate the linear regression model and train it using the training dataset:
        <pre class="programlisting code"><code class="hljs-code">regressor = LinearRegression()
regressor.fit(X_train, y_train)
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">LinearRegression()
</code></pre>
      </li>
      <li class="numberedList">Now, let’s predict the results using the test portion of the dataset:
        <pre class="programlisting code"><code class="hljs-code">y_pred = regressor.predict(X_test)
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error
sqrt(mean_squared_error(y_test, y_pred))
</code></pre>
      </li>
      <li class="numberedList">The <a id="_idIndexMarker756"/>output generated by running the preceding code will generate the following:
        <pre class="programlisting con"><code class="hljs-con">19.02827669300187
</code></pre>
      </li>
    </ol>
    <p class="normal">As discussed <a id="_idIndexMarker757"/>in the preceding section, RMSE is the standard deviation of the error. It indicates that 68.2% of predictions will fall within <code class="inlineCode">4.36</code> of the value of the label.</p>
    <p class="normal">Let us look into when we can use linear regression.</p>
    <h2 id="_idParaDest-283" class="heading-2">When is linear regression used?</h2>
    <p class="normal">Linear regression <a id="_idIndexMarker758"/>is used to solve many real-world problems, including the following:</p>
    <ul>
      <li class="bulletList">Sales forecasting</li>
      <li class="bulletList">Predicting optimum product prices</li>
      <li class="bulletList">Quantifying the causal relationship between an event and the response, such as in clinical drug trials, engineering safety tests, or marketing research</li>
      <li class="bulletList">Identifying patterns that can be used to forecast future behavior, given known criteria—for example, predicting insurance claims, natural disaster damage, election results, and crime rates</li>
    </ul>
    <p class="normal">Let us next look into the weaknesses of linear regression.</p>
    <h2 id="_idParaDest-284" class="heading-2">The weaknesses of linear regression</h2>
    <p class="normal">The weaknesses <a id="_idIndexMarker759"/>of linear regression are as follows:</p>
    <ul>
      <li class="bulletList">It only works with numerical features.</li>
      <li class="bulletList">Categorical data needs to be pre-processed.</li>
      <li class="bulletList">It does not cope well with missing data.</li>
      <li class="bulletList">It makes assumptions about the data.</li>
    </ul>
    <h2 id="_idParaDest-285" class="heading-2">The regression tree algorithm</h2>
    <p class="normal">Similar to classification trees used for categorical outcomes, regression trees are another subset of decision trees, but they are employed when the target, or label, is a continuous <a id="_idIndexMarker760"/>variable instead of categorical. This distinction impacts how the tree algorithm processes and learns from the data.</p>
    <p class="normal">In the case <a id="_idIndexMarker761"/>of classification trees, the algorithm tries to identify the categories that the data points belong to. However, with regression trees, the goal is to predict a specific, continuous value. This might be something like the price of a house, a company’s future stock price, or the likely temperature tomorrow.</p>
    <p class="normal">These variations between classification and regression trees also lead to differences in the algorithms used. In a classification tree, we typically use metrics such as Gini impurity or <a id="_idIndexMarker762"/>entropy to find the best split. In contrast, regression trees utilize measures like <strong class="keyWord">Mean Squared Error</strong> (<strong class="keyWord">MSE</strong>) to minimize the distance between the actual and predicted continuous values.</p>
    <h2 id="_idParaDest-286" class="heading-2">Using the regression tree algorithm for the regressors challenge</h2>
    <p class="normal">In this <a id="_idIndexMarker763"/>section, we will see how <a id="_idIndexMarker764"/>a regression tree algorithm can be used for the regressors challenge:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">First, we train the model using a regression tree algorithm:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeRegressor
regressor = DecisionTreeRegressor(max_depth=<span class="hljs-number">3</span>)
regressor.fit(X_train, y_train)
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">DecisionTreeRegressor(max_depth=3)
</code></pre>
      </li>
      <li class="numberedList">Once the regression tree model is trained, we use the trained model to predict the values:
        <pre class="programlisting code"><code class="hljs-code">y_pred = regressor.predict(X_test)
</code></pre>
      </li>
      <li class="numberedList">Then, we calculate RMSE to quantify the performance of the model:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error
<span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> sqrt
sqrt(mean_squared_error(y_test, y_pred))
</code></pre>
      </li>
    </ol>
    <p class="normal">We <a id="_idIndexMarker765"/>get the <a id="_idIndexMarker766"/>following output:</p>
    <pre class="programlisting con"><code class="hljs-con">4.464255966462035
</code></pre>
    <h2 id="_idParaDest-287" class="heading-2">The gradient boost regression algorithm</h2>
    <p class="normal">Now, let’s shift our focus to the gradient boosting regression algorithm, which uses an ensemble <a id="_idIndexMarker767"/>of decision trees to formulate underlying patterns within a dataset.</p>
    <p class="normal">At its core, gradient <a id="_idIndexMarker768"/>boosting regression operates by creating a ‘team’ of decision trees, where each member progressively learns from the mistakes of its predecessors. In essence, each subsequent decision tree in the sequence attempts to correct the prediction errors made by the tree before it, leading to an ‘ensemble’ that makes a final prediction based on the collective wisdom of all the individual trees. What makes this algorithm truly unique is its capability to handle a broad spectrum of data and its resistance to overfitting. This versatility allows it to perform admirably across diverse datasets and problem scenarios.</p>
    <h2 id="_idParaDest-288" class="heading-2">Using the gradient boost regression algorithm for the regressors challenge</h2>
    <p class="normal">In this section, we will see how we can use the gradient boost regression algorithm for the <a id="_idIndexMarker769"/>regressors challenge, predicting a car’s MPG rating, which is a continuous variable and, therefore, a classic <a id="_idIndexMarker770"/>regression problem. Remember that our independent variables include features like ‘<code class="inlineCode">CYLINDERS</code>,’ ‘<code class="inlineCode">DISPLACEMENT</code>,’ ‘<code class="inlineCode">HORSEPOWER</code>,’ ‘<code class="inlineCode">WEIGHT</code>,’ and ‘<code class="inlineCode">ACCELERATION</code>.’</p>
    <p class="normal">Looking <a id="_idIndexMarker771"/>closely, MPG is not as straightforward as it may seem, considering the multifaceted relationships between the influencing factors. For example, while cars with higher displacement typically consume more fuel, leading to a lower MPG, this relationship could be offset by factors like weight and horsepower. It’s these nuanced interactions that may elude simpler models like linear regression or a single decision tree.</p>
    <p class="normal">This is where the gradient boosting regression algorithm may be useful. By building an ensemble of decision trees, each learning from the errors of its predecessor, the model will <a id="_idIndexMarker772"/>aim to discern <a id="_idIndexMarker773"/>these complex patterns in the data. Each tree contributes its understanding of the data, refining the predictions to be more accurate and reliable.</p>
    <p class="normal">For <a id="_idIndexMarker774"/>example, one decision tree might learn that cars with larger ‘<code class="inlineCode">DISPLACEMENT</code>' values tend to have lower <code class="inlineCode">MPG</code>. The next tree might then pick up on the subtlety that lighter cars (‘<code class="inlineCode">WEIGHT</code>') with the same ‘<code class="inlineCode">DISPLACEMENT</code>' can sometimes achieve higher <code class="inlineCode">MPG</code>. Through this iterative learning process, the model unveils the intricate layers of relationships between the variables:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">The first step in our Python script is to import the necessary library:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> ensemble
</code></pre>
      </li>
      <li class="numberedList">Here, we import the <code class="inlineCode">ensemble</code> module from the <code class="inlineCode">sklearn</code> library:
        <pre class="programlisting code"><code class="hljs-code">params = {<span class="hljs-string">'n_estimators'</span>: <span class="hljs-number">500</span>, <span class="hljs-string">'max_depth'</span>: <span class="hljs-number">4</span>,          <span class="hljs-string">'min_samples_split'</span>: <span class="hljs-number">2</span>, <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.01</span>,          <span class="hljs-string">'loss'</span>: <span class="hljs-string">'squared_error'</span>}
regressor = ensemble.GradientBoostingRegressor(**params)
regressor.fit(X_train, y_train)
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=500)
</code></pre>
        <pre class="programlisting code"><code class="hljs-code">y_pred = regressor.predict(X_test)
</code></pre>
      </li>
      <li class="numberedList">Finally, we calculate RMSE to quantify the performance of the model:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error
<span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> sqrt
sqrt(mean_squared_error(y_test, y_pred))
</code></pre>
      </li>
      <li class="numberedList">Running this will give us the output value, as follows:
        <pre class="programlisting con"><code class="hljs-con">4.039759805419003
</code></pre>
      </li>
    </ol>
    <h1 id="_idParaDest-289" class="heading-1">For regression algorithms, the winner is...</h1>
    <p class="normal">Let’s look <a id="_idIndexMarker775"/>at the performance of the three regression algorithms that we used on the same data and exactly the same use case:</p>
    <table id="table007" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Algorithm</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">RMSE</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Linear regression</p>
          </td>
          <td class="table-cell">
            <p class="normal">4.36214129677179</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Regression tree</p>
          </td>
          <td class="table-cell">
            <p class="normal">5.2771702288377</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Gradient boost regression</p>
          </td>
          <td class="table-cell">
            <p class="normal">4.034836373089085</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">Looking at the <a id="_idIndexMarker776"/>performance of all the regression algorithms, it is obvious that the performance of gradient boost regression is the best, as it has the lowest RMSE. This is followed by linear regression. The regression tree algorithm performed the worst for this problem.</p>
    <h1 id="_idParaDest-290" class="heading-1">Practical example – how to predict the weather</h1>
    <p class="normal">Now, we’ll transition from theory to application, employing the concepts we’ve discussed in <a id="_idIndexMarker777"/>this chapter to predict tomorrow’s rainfall, based on a year’s worth of weather data from a specific city. This real-world scenario aims to reinforce the principles of supervised learning.</p>
    <p class="normal">There are numerous algorithms capable of this task, but selecting the most suitable one hinges on the specific characteristics of our problem and data. Each algorithm has unique advantages and excels in specific contexts. For example, while linear regression can be ideal when there’s a discernible numerical correlation, decision trees might be more effective when dealing with categorical variables or non-linear relationships.</p>
    <p class="normal">For this prediction challenge, we have chosen logistic regression. This choice is driven by the binary nature of our prediction target (i.e., will it rain tomorrow or not?), a situation where Logistic Regression often excels. This algorithm provides a probability score between 0 and 1, allowing us to make clear yes-or-no predictions, ideal for our rainfall forecast scenario.</p>
    <p class="normal">Remember, this practical example differs from previous ones. It’s crafted to help you grasp how we select and apply a particular algorithm to specific real-world problems, offering a deeper understanding of the thought process behind algorithm selection.</p>
    <p class="normal">The data available to train this model is in the CSV file called <code class="inlineCode">weather.csv</code>:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Let’s import the data as a pandas DataFrame:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
df = pd.read_csv(<span class="hljs-string">"weather.csv"</span>)
</code></pre>
      </li>
      <li class="numberedList">Let’s look at the columns of the DataFrame:
        <pre class="programlisting code"><code class="hljs-code">df.columns
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">Index(['Date', 'MinTemp', 'MaxTemp', 'Rainfall', 
       'Evaporation', 'Sunshine', 'WindGustDir', 
       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 
       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 
       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 
       'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 
       'RainToday', 'RISK_MM', 'RainTomorrow'],
      dtype='object')
</code></pre>
      </li>
      <li class="numberedList">Now, let’s look <a id="_idIndexMarker778"/>at the header of the first 13 columns of the <code class="inlineCode">weather.csv</code> data that show the typical weather of a city:
        <pre class="programlisting code"><code class="hljs-code">df.iloc[:,<span class="hljs-number">0</span>:<span class="hljs-number">12</span>].head()
</code></pre>
      </li>
    </ol>
    <figure class="mediaobject"><img src="../Images/B18046_07_19.png" alt="A screenshot of a computer  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.19: Data showing typical weather of a city</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="4">Now, let’s look at the last 10 columns of the <code class="inlineCode">weather.csv</code> data:
        <pre class="programlisting code"><code class="hljs-code">df.iloc[:,<span class="hljs-number">12</span>:<span class="hljs-number">25</span>].head()
</code></pre>
      </li>
    </ol>
    <figure class="mediaobject"><img src="../Images/B18046_07_20.png" alt="A picture containing application  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 7.20: Last 10 columns of the weather.csv data</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="5">Let’s use <code class="inlineCode">x</code> to represent the input features. We will drop the <code class="inlineCode">Date</code> field for the feature list, as it is not useful in the context of predictions. We will also drop the <code class="inlineCode">RainTomorrow</code> label:
        <pre class="programlisting code"><code class="hljs-code">x = df.drop([<span class="hljs-string">'Date'</span>,<span class="hljs-string">'</span><span class="hljs-string">RainTomorrow'</span>],axis=<span class="hljs-number">1</span>)
</code></pre>
      </li>
      <li class="numberedList">Let’s use <code class="inlineCode">y</code> to represent the label:
        <pre class="programlisting code"><code class="hljs-code">y = df[<span class="hljs-string">'RainTomorrow'</span>]
</code></pre>
      </li>
      <li class="numberedList">Now, let’s divide the data into <code class="inlineCode">train_test_split</code>:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
train_x , train_y ,test_x , test_y = train_test_split(x,y,
test_size = <span class="hljs-number">0.2</span>,random_state = <span class="hljs-number">2</span>)
</code></pre>
      </li>
      <li class="numberedList">As the label <a id="_idIndexMarker779"/>is a binary variable, we will train a classifier. So, logistic regression will be a good choice here. First, let’s instantiate the logistic regression model:
        <pre class="programlisting code"><code class="hljs-code">model = LogisticRegression()
</code></pre>
      </li>
      <li class="numberedList">Now, we can use <code class="inlineCode">train_x</code> and <code class="inlineCode">test_x</code> to train the model:
        <pre class="programlisting code"><code class="hljs-code">model.fit(train_x , test_x)
</code></pre>
      </li>
      <li class="numberedList">Once the model is trained, let’s use it for predictions:
        <pre class="programlisting code"><code class="hljs-code">predict = model.predict(train_y)
</code></pre>
      </li>
      <li class="numberedList">Now, let’s find the accuracy of our trained model:
        <pre class="programlisting code"><code class="hljs-code">predict = model.predict(train_y)
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score
accuracy_score(predict , test_y)
</code></pre>
        <pre class="programlisting con"><code class="hljs-con">0.9696969696969697
</code></pre>
      </li>
    </ol>
    <p class="normal">Now, this binary <a id="_idIndexMarker780"/>classifier can be used to predict whether it will rain tomorrow.</p>
    <h1 id="_idParaDest-291" class="heading-1">Summary</h1>
    <p class="normal">Wrapping up, this chapter served as a comprehensive expedition into the multifaceted landscape of supervised machine learning. We spotlighted the primary components of classification and regression algorithms, dissecting their mechanics and applications.</p>
    <p class="normal">The chapter demonstrated a broad spectrum of algorithms through practical examples, providing an opportunity to understand the functionality of these tools in real-world contexts. This journey underscored the adaptability of supervised learning techniques and their ability to tackle varied problems.</p>
    <p class="normal">By juxtaposing the performance of different algorithms, we emphasized the crucial role of context when selecting an optimal machine learning strategy. Factors such as data size, feature complexity, and prediction requirements play significant roles in this selection process.</p>
    <p class="normal">As we transition to the upcoming chapters, the knowledge gleaned from this exploration serves as a robust foundation. This understanding of how to apply supervised learning techniques in practical scenarios is a critical skill set in the vast realm of machine learning. Keep these insights at your fingertips as we journey further into the compelling world of AI, preparing for an even deeper dive into the complex universe of neural networks.</p>
    <h1 id="_idParaDest-292" class="heading-1">Learn more on Discord</h1>
    <p class="normal">To join the Discord community for this book – where you can share feedback, ask questions to the author, and learn about new releases – follow the QR code below:</p>
    <p class="normal"><a href="https://packt.link/WHLel"><span class="url">https://packt.link/WHLel</span></a></p>
    <p class="normal"><img src="../Images/QR_Code1955211820597889031.png" alt="" role="presentation"/></p>
  </div>
</body></html>