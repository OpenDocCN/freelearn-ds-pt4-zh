<html><head></head><body>
  <div id="_idContainer454" class="Basic-Text-Frame">
    <h1 class="chapterNumber">12</h1>
    <h1 id="_idParaDest-439" class="chapterTitle">Recommendation Engines</h1>
    <blockquote class="packt_quote">
      <p class="quote"> The best recommendation I can have is my own talents, and the fruits of my own labors, and what others will not do for me, I will try and do for myself.</p>
      <p class="cite">—18–19th-century scientist John James Audubon</p>
    </blockquote>
    <p class="normal">Recommendation engines harness the power of available data on user preferences and item details to offer tailored suggestions. At their core, these engines aim to identify commonalities among various items and understand the dynamics of user-item interactions. Rather than just focusing on products, recommendation systems cast a wider net, considering any type of item – be it a song, a news article, or a product – and tailoring their suggestions accordingly.</p>
    <p class="normal">This chapter starts by presenting the basics of recommendation engines. Then, it discusses various types of recommendation engines. In the subsequent sections of this chapter, we’ll explore the inner workings of recommendation systems. These systems are adept at suggesting tailored items or products to users, but they’re not without their challenges. We’ll discuss both their strengths and the limitations they present. Finally, we will learn to use recommendation engines to solve a real-world problem.</p>
    <p class="normal">In this chapter, we’ll cover:</p>
    <ul>
      <li class="bulletList">An overview of recommendation engines</li>
      <li class="bulletList">Different categories of recommendation systems</li>
      <li class="bulletList">Recognizing the constraints of recommendation approaches</li>
      <li class="bulletList">Areas of practical application</li>
      <li class="bulletList">A practical example</li>
    </ul>
    <p class="normal">By the end of this chapter, you should be able to understand how to use recommendation engines to suggest various items based on some preference criteria.</p>
    <p class="normal">Let’s start by looking into the background concepts of recommendation engines.</p>
    <h1 id="_idParaDest-440" class="heading-1">Introducing recommendation systems</h1>
    <p class="normal">Recommendation systems are powerful tools, initially crafted by researchers but now widely adopted in <a id="_idIndexMarker1250"/>commercial settings, that predict items a user might find appealing. Their ability to deliver personalized item suggestions makes them an invaluable asset, especially in the digital shopping landscape.</p>
    <p class="normal">When used in e-commerce applications, recommendation engines use sophisticated algorithms to improve the shopping experience for shoppers, allowing service providers to customize products according to the preferences of the users.</p>
    <p class="normal">A classic example of the significance of these systems is the Netflix Prize challenge in 2009. Netflix, aiming to refine its recommendation algorithm, offered a whopping $1 million prize for any team that could enhance its current recommendation system, Cinematch, by 10%. This challenge saw participation from researchers globally, with BellKor’s Pragmatic Chaos team emerging as the winner. Their achievement underlines the essential role and potential of recommendation systems in the commercial domain. More about this fascinating challenge can be explored in this chapter.</p>
    <h1 id="_idParaDest-441" class="heading-1">Types of recommendation engines</h1>
    <p class="normal">We can broadly <a id="_idIndexMarker1251"/>classify recommendation engines into three main categories:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Content-based recommendation engines</strong>: They focus on item attributes, matching <a id="_idIndexMarker1252"/>the features of one product to another.</li>
      <li class="bulletList"><strong class="keyWord">Collaborative filtering engines</strong>: They <a id="_idIndexMarker1253"/>predict preferences based on user behaviors. </li>
      <li class="bulletList"><strong class="keyWord">Hybrid recommendation engines</strong>: A blend of both worlds, these engines integrate <a id="_idIndexMarker1254"/>the strengths of content-based and collaborative filtering methods to refine their suggestions.</li>
    </ul>
    <p class="normal">Having established the categories, let’s start by diving into the details of these three types of recommendation engines one by one:</p>
    <h2 id="_idParaDest-442" class="heading-2">Content-based recommendation engines</h2>
    <p class="normal"><strong class="keyWord">Content-based recommendation engines</strong> operate on a straightforward principle: they recommend <a id="_idIndexMarker1255"/>items that are like ones the user <a id="_idIndexMarker1256"/>has previously engaged with. The crux of these systems lies in accurately measuring the likeness between items.</p>
    <p class="normal">To illustrate, imagine the scenario depicted in <em class="italic">Figure 12.1</em>:</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_01.png" alt="Diagram, schematic  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.1: Content-based recommendation system</p>
    <p class="normal">Let’s say that <em class="italic">User1</em> has read <em class="italic">Doc1</em>. Due to the similarities between the documents, we could then recommend <em class="italic">Doc2</em> to <em class="italic">User1</em>.</p>
    <p class="normal">This method would only be effective if we could identify and quantify these similarities. Thus, identifying similarities between items is pivotal for recommendations. Let’s delve into how to quantify these similarities.</p>
    <h3 id="_idParaDest-443" class="heading-3">Determining similarities in unstructured documents</h3>
    <p class="normal">One way of determining the similarities between different documents is by using the co-occurrence <a id="_idIndexMarker1257"/>matrix, which works on the premise that items frequently bought together likely share similarities or belong to complementary categories.</p>
    <p class="normal">For instance, someone buying a razor might also need shaving gel. Let’s decode this with data from four users’ buying habits:</p>
    <table id="table001-8" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Razor</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Apple</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Shaving cream</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Bike</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Hummus</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Mike</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Taylor</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Elena</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Amine</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">To <a id="_idIndexMarker1258"/>construct the co-occurrence matrix, follow these steps:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Initialize an <em class="italic">NxN</em> matrix, where <em class="italic">N</em> is the number of items. This matrix will store the co-occurrence counts.</li>
      <li class="numberedList">For each user in the user-item matrix, update the co-occurrence matrix by incrementing the cell values for pairs of items that the user has interacted with.</li>
      <li class="numberedList">The final matrix showcases the associations between items based on user interactions.</li>
    </ol>
    <p class="normal">The occurrence matrix of the above table will be as follows:</p>
    <table id="table002-5" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Razor</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Apple</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Shaving cream</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Bike</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Hummus</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Razor</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">-</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">3</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">2</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Apple</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">-</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Shaving cream</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">3</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">-</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">2</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Bike</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">-</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Hummus</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">2</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">2</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">-</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">This matrix, in essence, showcases the likelihood of two items being bought together. It’s a valuable tool for recommendation.</p>
    <h2 id="_idParaDest-444" class="heading-2">Collaborative filtering recommendation engines</h2>
    <p class="normal">The recommendations from <strong class="keyWord">collaborative filtering</strong> are based on the analysis of the historical <a id="_idIndexMarker1259"/>buying patterns of <a id="_idIndexMarker1260"/>users. The basic assumption is that if two users show interest in mostly the same items, we can classify both users as similar. In other words, we can assume the following:</p>
    <ul>
      <li class="bulletList">If the overlap in the buying history of two users exceeds a threshold, we can classify them as similar users.</li>
      <li class="bulletList">Looking at the history of similar users, the items that do not overlap in the buying history become the basis of future recommendations through collaborative filtering.</li>
    </ul>
    <p class="normal">For example, let’s look at a specific example. We have two users, <em class="italic">User1</em> and <em class="italic">User2</em>, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_02.png" alt="A diagram of a couple of people  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.2: Collaborative filtering recommendation engine</p>
    <p class="normal">Note the following:</p>
    <ul>
      <li class="bulletList">Both <em class="italic">User1</em> and <em class="italic">User2</em> have shown interest in exactly the same documents, <em class="italic">Doc1</em> and <em class="italic">Doc2</em>.</li>
      <li class="bulletList">Based on their similar historical patterns, we can classify both of them as similar users.</li>
      <li class="bulletList">If <em class="italic">User1</em> now reads <em class="italic">Doc3</em>, then we can suggest <em class="italic">Doc3</em> to <em class="italic">User2</em> as well.</li>
    </ul>
    <p class="normal">This strategy of suggesting items to users based on their history will not always work. Let us look into the issues related to collaborative filtering in more detail.</p>
    <h3 id="_idParaDest-445" class="heading-3">Issues related to collaborative filtering</h3>
    <p class="normal">There are <a id="_idIndexMarker1261"/>three potential issues related to collaborative filtering: </p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Inaccuracies due to a limited sample size</li>
      <li class="numberedList">A vulnerability to <strong class="keyWord">isolated analysis</strong></li>
      <li class="numberedList">Over-reliance on history</li>
    </ol>
    <p class="normal">Let us look into the limitations in more detail.</p>
    <h4 class="heading-4">Inaccuracies due to a limited sample size</h4>
    <p class="normal">The accuracy and efficacy of a collaborative filtering system also hinge on the sample size. For instance, if only three documents are analyzed, the potential for accurate recommendations is limited. </p>
    <p class="normal">However, if a system has data on hundreds or thousands of documents and interactions, its predictive capabilities become significantly more reliable. It’s akin to the difference between making predictions based on a handful of data points versus having a comprehensive dataset to draw insights from.</p>
    <p class="normal">Even when equipped with vast amounts of data, collaborative filtering isn’t foolproof. The reason is that it relies purely on the historical interactions between users and items, without accounting for any external factors.</p>
    <h4 class="heading-4">Vulnerable to isolated analysis</h4>
    <p class="normal">Collaborative filtering zeroes in on patterns formed by user behaviors and their interactions with items. This means it often misses out on external influences that might dictate a user’s choice. For instance, a user might opt for a particular book not because of personal interest but because of academic needs or a friend’s recommendation. The collaborative filtering model won’t recognize these nuances.</p>
    <h4 class="heading-4">Over-reliance on history</h4>
    <p class="normal">Because the system hinges on historical data, it can sometimes end up reinforcing stereotypes or not catching up with a user’s evolving tastes. Imagine if a user once had a phase where they loved sci-fi movies but has since transitioned to enjoying romantic films. If they watched numerous sci-fi movies in the past, the system might still primarily recommend them, missing out on their current preferences.</p>
    <p class="normal">In essence, while collaborative filtering is powerful, especially with more data, it’s essential to understand its inherent limitations stemming from its isolated method of operation.</p>
    <p class="normal">Next, let’s look at hybrid recommendation engines.</p>
    <h2 id="_idParaDest-446" class="heading-2">Hybrid recommendation engines</h2>
    <p class="normal">So far, we have <a id="_idIndexMarker1262"/>discussed content-based and collaborative-filtering-based recommendation engines. Both types of recommendation engines <a id="_idIndexMarker1263"/>can be combined to create a <strong class="keyWord">hybrid recommendation engine</strong>. To do so, we follow these steps:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Generate a similarity matrix of the items.</li>
      <li class="numberedList">Generate preference matrices of the users.</li>
      <li class="numberedList">Generate recommendations.</li>
    </ol>
    <p class="normal">Let’s look into these steps one by one.</p>
    <h3 id="_idParaDest-447" class="heading-3">Generating a similarity matrix of the items</h3>
    <p class="normal">In hybrid recommendations, we start by creating a similarity matrix of items using content-based recommendations. This can be done by using the co-occurrence matrix or any <a id="_idIndexMarker1264"/>distance measure to quantify the similarities between items.</p>
    <p class="normal">Let’s assume that we currently have five items. Using content-based recommendations, we generate a matrix that captures the similarities between items, as shown in <em class="italic">Figure 12.3</em>:</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_03.png" alt="Calendar  Description automatically generated with low confidence"/></figure>
    <p class="packt_figref">Figure 12.3: Similarity matrix</p>
    <p class="normal">Let’s see how we can combine this similarity matrix with a preference matrix to generate recommendations.</p>
    <h3 id="_idParaDest-448" class="heading-3">Generating reference vectors of the users</h3>
    <p class="normal">Based on the history of each of the users of the system, we will produce a preference vector that captures those users’ interests.</p>
    <p class="normal">Let’s assume <a id="_idIndexMarker1265"/>that we want to generate recommendations for an online store named <em class="italic">KentStreetOnline</em>, which sells 100 unique items. <em class="italic">KentStreetOnline</em> is popular and has 1 million active subscribers. It is important to note that we need to generate only one similarity matrix with dimensions of 100 by 100. We also need to generate a preference vector for each of the users; this means that we need to generate 1 million preference vectors for each of the 1 million users.</p>
    <p class="normal">Each entry of the performance vector represents a preference for an item. The value of the first row means that the preference weight for <em class="italic">Item 1 </em>is <em class="italic">4</em>. The preference score isn’t a direct reflection of purchase counts. Instead, it’s a weighted metric, potentially considering factors like browsing history, past purchases, item ratings, and more. </p>
    <p class="normal">A score of <em class="italic">4</em> could represent a combination of interest and past interactions with <em class="italic">Item 1</em>, suggesting a strong likelihood that the user would appreciate that item.</p>
    <p class="normal">This is graphically shown in <em class="italic">Figure 12.4</em>:</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_04.png" alt="Table  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.4: User preference matrix</p>
    <p class="normal">Now, let’s look into how we can generate recommendations based on the similarity matrix, <em class="italic">S</em>, and the user preference matrix, <em class="italic">U</em>.</p>
    <h3 id="_idParaDest-449" class="heading-3">Generating recommendations</h3>
    <p class="normal">To make recommendations, we can multiply the matrices. Users are more likely to be interested <a id="_idIndexMarker1266"/>in an item that co-occurs frequently with an item that they gave a high rating to:</p>
    <p class="center"><em class="italic">Matrix</em>[<em class="italic">S</em>] ×<em class="italic"> Matrix</em>[<em class="italic">U</em>] =<em class="italic"> Matrix</em>[<em class="italic">R</em>]</p>
    <p class="normal">This calculation is shown graphically in <em class="italic">Figure 12.5</em>:</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_05.png" alt="Table  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.5: Generation of a recommendation matrix</p>
    <p class="normal">A separate resultant matrix is generated for each of the users. The numbers in the recommendation matrix, <em class="italic">Matrix[R]</em>, quantify the predicted interest of a user in each of the items. For example, in the resultant matrix, the fourth item has the highest number, 58. So this item is highly recommended for this particular user.</p>
    <h3 id="_idParaDest-450" class="heading-3">Evolving the recommendation system</h3>
    <p class="normal">Recommendation <a id="_idIndexMarker1267"/>systems aren’t static; they thrive on constant refinement. How does this evolution occur? By juxtaposing the recommended items (predictions) with the user’s actual choices. By analyzing discrepancies, the system identifies areas to improve. Over time, by recalibrating based on user feedback and observed behaviors, the system enhances its recommendation accuracy, ensuring users always receive the most relevant suggestions.</p>
    <p class="normal">Now, let’s look into the limitations of different recommendation systems.</p>
    <h1 id="_idParaDest-451" class="heading-1">Understanding the limitations of recommendation systems</h1>
    <p class="normal">Recommendation <a id="_idIndexMarker1268"/>engines use predictive algorithms to suggest recommendations to a bunch of users. It is a powerful technology, but we should be aware of its limitations. Let’s look into the various limitations of recommendation systems.</p>
    <h2 id="_idParaDest-452" class="heading-2">The cold start problem</h2>
    <p class="normal">At the core of collaborative filtering lies a crucial dependency: historical user data. Without a track <a id="_idIndexMarker1269"/>record of user preferences, generating accurate suggestions becomes a challenge. For a new entrant into the system, the absence of data means our algorithms largely operate on assumptive grounds, which can lead to imprecise recommendations. Similarly, in content-based recommendation systems, fresh items might lack comprehensive details, making the suggestion process less reliable. This data dependency – the need for established user and item data to produce sound recommendations – is what’s termed <strong class="keyWord">the cold start problem</strong>.</p>
    <p class="normal">There are several strategies to counterbalance the cold start challenge:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1"><strong class="keyWord">Hybrid systems</strong>: Merging collaborative and content-based filtering can offset the limitations of one system using the strengths of the other.</li>
      <li class="numberedList"><strong class="keyWord">Knowledge-based recommendations</strong>: If historical data is scant, leaning on explicit knowledge about users and items can help bridge the gap.</li>
      <li class="numberedList"><strong class="keyWord">Onboarding questionnaires</strong>: For new users, a brief questionnaire about preferences can seed the system with initial data, guiding early recommendations.</li>
    </ol>
    <p class="normal">Understanding and countering these challenges ensures that recommendation systems remain an effective and reliable tool in user engagement strategies.</p>
    <h2 id="_idParaDest-453" class="heading-2">Metadata requirements</h2>
    <p class="normal">While content-based recommendation systems can function without metadata, incorporating <a id="_idIndexMarker1270"/>such details can enhance their precision. It’s important to note that metadata isn’t confined to just textual descriptions. In our multifaceted digital ecosystem, items span various media types like images, audio, or movies. For such media, the “content” can be derived from their inherent properties. For instance, image-based metadata might be pulled from visual patterns; audio metadata from elements like waveforms or spectral features; and for movies, aspects like genre, cast, or scene structure can be considered.</p>
    <p class="normal">Integrating these diverse content dimensions allows recommendation systems to be more adaptable, offering refined suggestions across a wide range of items.</p>
    <h2 id="_idParaDest-454" class="heading-2">The data sparsity problem</h2>
    <p class="normal">Across an enormous number of items, a user will have rated only a few items, resulting in a very <a id="_idIndexMarker1271"/>sparse user/item rating matrix.</p>
    <div class="note">
      <p class="normal">Amazon has around a billion users and a billion items. Amazon’s recommendation engine is said to have the sparsest data for any recommendation engine in the world.</p>
    </div>
    <p class="normal">To tackle such <a id="_idIndexMarker1272"/>sparsity, various techniques are deployed. <strong class="keyWord">Matrix factorization methods</strong>, for example, can predict potential ratings in these sparse <a id="_idIndexMarker1273"/>areas, providing a more complete user-item interaction landscape. Additionally, <strong class="keyWord">hybrid recommendation systems</strong>, which combine elements of content-based and collaborative filtering, can generate meaningful recommendations even when user-item interactions are limited. By integrating these and other approaches, recommendation systems can effectively navigate and mitigate the challenges posed by sparse datasets.</p>
    <h2 id="_idParaDest-455" class="heading-2">The double-edged sword of social influence in recommendation systems</h2>
    <p class="normal">Recommendation <a id="_idIndexMarker1274"/>systems can be significantly influenced by social dynamics. Indeed, our social circles often have a marked impact on our preferences and choices. For instance, friends tend to make similar purchases and rate products or services in similar ways.</p>
    <p class="normal">On the positive side, leveraging social connections can boost recommendation relevance. If a system observes that individuals within a particular social group enjoyed a certain movie or product, it might make sense to recommend that same item to other members of the group. This could lead to increased user satisfaction and, potentially, higher conversion rates.</p>
    <p class="normal">However, there’s a downside. Relying too heavily on social influence can introduce bias into the recommendations. It might inadvertently create echo chambers where users are only exposed to items their immediate social circle appreciate, limiting diversity and <a id="_idIndexMarker1275"/>potentially missing out on products or services that could be more individually suited. Furthermore, this could lead to a self-reinforcing feedback loop, where the same items keep getting recommended, overshadowing other potentially valuable items.</p>
    <p class="normal">Thus, while social influence is a powerful tool in shaping user preferences, it’s essential for recommendation systems to balance it with individual user behavior and broader trends to ensure a diverse and personalized user experience.</p>
    <h1 id="_idParaDest-456" class="heading-1">Areas of practical applications</h1>
    <p class="normal">Recommendation systems play a pivotal role in our daily digital interactions. To truly understand <a id="_idIndexMarker1276"/>their significance, let’s delve into their applications across various industries.</p>
    <p class="normal">Based on the comprehensive details provided about Netflix’s use of data science and its recommendation system, let’s look at the restructured statement addressing the points mentioned.</p>
    <h2 id="_idParaDest-457" class="heading-2">Netflix’s mastery of data-driven recommendations</h2>
    <p class="normal">Netflix, a leader <a id="_idIndexMarker1277"/>in streaming, has harnessed data analytics to fine-tune content recommendations, with 800 engineers in Silicon Valley advancing this effort. Their emphasis on data-driven strategies is evident in the Netflix Prize challenge. The winning team, BellKor’s Pragmatic Chaos, used 107 diverse algorithms, from matrix factorization to restricted Boltzman machines, investing 2,000 hours in its development.</p>
    <p class="normal">The results were a significant 10.06% improvement in their “Cinematch” system. This translated to more streaming hours, fewer subscription cancellations, and substantial savings for Netflix. Interestingly, recommendations now influence about 75% of what users watch. Töscher et al. (2009) highlighted a curious “one-day effect” suggesting shared accounts or user mood variations.</p>
    <p class="normal">While the challenge showcased Netflix’s commitment to data, it also hinted at the potential of ensemble techniques in striking a balance between recommendation diversity <a id="_idIndexMarker1278"/>and accuracy. </p>
    <p class="normal">Today, elements of the winning model remain core to Netflix’s recommendation engine, but with ever-evolving technology, there’s potential for further refinements, like integrating reinforcement algorithms and improved A/B testing.</p>
    <p class="normal">Here’s the source for the Netflix statistic: <a href="https://towardsdatascience.com/netflix-recommender-system-a-big-data-case-study-19cfa6d56ff5"><span class="url">https://towardsdatascience.com/netflix-recommender-system-a-big-data-case-study-19cfa6d56ff5</span></a>.</p>
    <h2 id="_idParaDest-458" class="heading-2">The evolution of Amazon’s recommendation system</h2>
    <p class="normal">In the early 2000s, Amazon transformed its recommendation engine by shifting from user-based collaborative filtering to item-to-item collaborative filtering, as detailed in a seminal <a id="_idIndexMarker1279"/>2003 paper by Linden, Smith, and York. The strategy switched from recommending products based on similar users to suggesting products linked to individual product purchases.</p>
    <p class="normal">The essence of this “relatedness” was deciphered from observed customer purchasing patterns. If Harry Potter book buyers often bought a Harry Potter bookmark, the items were considered related. Yet, the initial system had flaws. For high-volume buyers, the recommendations weren’t as refined, leading Smith and his team to make necessary algorithmic tweaks.</p>
    <p class="normal">Fast-forward a few years – during a 2019 re:MARS conference, Amazon highlighted its significant advancements in movie recommendations for Prime Video customers, achieving a twofold improvement.</p>
    <p class="normal">The technique utilized for this was inspired by a matrix completion problem. This method involves representing Prime Video customers and movies in a grid and predicting the probability of a customer watching a particular movie. Amazon then applied deep neural networks to this matrix problem, leading to more accurate and personalized movie recommendations.</p>
    <p class="normal">The future holds even more potential. With continued research and advancements, the Amazon team aims to further refine and revolutionize their recommendation algorithms, always striving to enhance the customer experience.</p>
    <p class="normal">You can find the Amazon statistic here: <a href="https://www.amazon.science/the-history-of-amazons-recommendation-algorithm"><span class="url">https://www.amazon.science/the-history-of-amazons-recommendation-algorithm</span></a>.</p>
    <p class="normal">Now, let’s try to use a recommendation engine to solve a real-world problem.</p>
    <h1 id="_idParaDest-459" class="heading-1">Practical example – creating a recommendation engine</h1>
    <p class="normal">Let’s build a <a id="_idIndexMarker1280"/>recommendation engine that can recommend movies to a bunch of users. We will use data put together by the GroupLens Research group at the University of Minnesota.</p>
    <h2 id="_idParaDest-460" class="heading-2">1. Setting up the framework</h2>
    <p class="normal">Our first task <a id="_idIndexMarker1281"/>is to ensure we have the right tools for the job. In the world of Python, this means importing necessary libraries:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
</code></pre>
    <h2 id="_idParaDest-461" class="heading-2">2. Data loading: ingesting reviews and titles</h2>
    <p class="normal">Now, let’s <a id="_idIndexMarker1282"/>import the <code class="inlineCode">df_reviews</code> and <code class="inlineCode">df_movie_titles</code> datasets:</p>
    <pre class="programlisting code"><code class="hljs-code">df_reviews = pd.read_csv(<span class="hljs-string">'https://storage.googleapis.com/neurals/data/data/reviews.csv'</span>)
df_reviews.head()
</code></pre>
    <p class="normal">The <code class="inlineCode">reviews.csv</code> dataset encompasses a rich collection of user reviews. Each entry features a user’s ID, a movie ID they’ve reviewed, their rating, and a timestamp of when the review was made.</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_06.png" alt="A table with numbers and text  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.6: Contents of the reviews.csv dataset</p>
    <p class="normal">The <code class="inlineCode">movies.csv</code> dataset is a compilation of movie titles and their details. Each record usually <a id="_idIndexMarker1283"/>contains a unique movie ID, the movie’s title, and its associated genre or genres.</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_07.png" alt="A screenshot of a computer  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.7: Contents of the movies.csv dataset</p>
    <h2 id="_idParaDest-462" class="heading-2">3. Merging data: crafting a comprehensive view</h2>
    <p class="normal">For a holistic perspective, we need to merge these datasets. The <code class="inlineCode">'movieId'</code> serves as our bridge between them:</p>
    <pre class="programlisting code"><code class="hljs-code">df = pd.merge(df_reviews, df_movie_titles, on=<span class="hljs-string">'movieId'</span>)
df.head()
</code></pre>
    <p class="normal">The merged <a id="_idIndexMarker1284"/>datasets should contain the following information:</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_08.png" alt="A table with numbers and words  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.8: Merged movie data</p>
    <p class="normal">Here’s a <a id="_idIndexMarker1285"/>brief on each column:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">userId</code>: A unique identifier for each user.</li>
      <li class="bulletList"><code class="inlineCode">movieId</code>: A unique identifier for each movie.</li>
      <li class="bulletList"><code class="inlineCode">rating</code>: Represents the rating assigned by a user to a movie, ranging from 1 to 5.</li>
      <li class="bulletList"><code class="inlineCode">timestamp</code>: Denotes when a particular movie was rated.</li>
      <li class="bulletList"><code class="inlineCode">title</code>: The movie’s title.</li>
      <li class="bulletList"><code class="inlineCode">genres</code>: The genre(s) associated with the movie.</li>
    </ul>
    <h2 id="_idParaDest-463" class="heading-2">4. Descriptive analysis: gleaning insights from ratings</h2>
    <p class="normal">Let’s dive into the heart of our data: the ratings. A good starting point is to compute the average <a id="_idIndexMarker1286"/>rating for each movie. Alongside, understanding the number of users who rated a movie can provide insights into its popularity:</p>
    <pre class="programlisting code"><code class="hljs-code">df_ratings = pd.DataFrame(df.groupby(<span class="hljs-string">'title'</span>)[<span class="hljs-string">'rating'</span>].mean())
df_ratings[<span class="hljs-string">'number_of_ratings'</span>] = df.groupby(<span class="hljs-string">'title'</span>)[<span class="hljs-string">'rating'</span>].count()
df_ratings.head()
</code></pre>
    <p class="normal">The <code class="inlineCode">mean</code> rating for each movie should be the following:</p>
    <figure class="mediaobject"><img src="../Images/B18046_12_09.png" alt="A screenshot of a computer  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.9: Calculating the mean rating</p>
    <p class="normal">With these aggregated metrics, we can discern popular movies with high average ratings, potential blockbusters with numerous ratings, or hidden gems that might have fewer reviews but high averages.</p>
    <p class="normal">This foundation will pave the way for the subsequent steps, where we’ll delve into building the actual recommendation engine. As we progress, our understanding of user preferences will refine, enabling us to suggest movies that resonate with individual tastes.</p>
    <h2 id="_idParaDest-464" class="heading-2">5. Structuring for recommendations: crafting the matrix</h2>
    <p class="normal">The next <a id="_idIndexMarker1287"/>logical step is to convert our dataset into a structure optimized for recommendations. Visualize this structure as a matrix:</p>
    <ul>
      <li class="bulletList">Rows represent our users (indexed by <code class="inlineCode">userId</code>)</li>
      <li class="bulletList">Columns signify movie titles</li>
      <li class="bulletList">Cells within the matrix are populated with ratings, revealing what a user thought of a specific movie</li>
    </ul>
    <p class="normal">The <code class="inlineCode">pivot_table</code> function in Pandas is a versatile tool that helps reshape or pivot data in a DataFrame to provide a summarized view. The function essentially creates a new derived table out of the original one:</p>
    <pre class="programlisting code"><code class="hljs-code">movie_matrix = df.pivot_table(index=<span class="hljs-string">'userId'</span>, columns=<span class="hljs-string">'title'</span>, values=<span class="hljs-string">'rating'</span>)
</code></pre>
    <p class="normal">Note that the preceding code will generate a very sparse matrix.</p>
    <h2 id="_idParaDest-465" class="heading-2">6. Putting the engine to test: recommending movies</h2>
    <p class="normal">Let’s see our engine in action. Suppose a user has just watched <em class="italic">Avatar </em>(2009). How can we find <a id="_idIndexMarker1288"/>other movies they might enjoy?</p>
    <p class="normal">Our first task is to isolate all users who’ve rated <em class="italic">Avatar </em>(2009):</p>
    <pre class="programlisting code"><code class="hljs-code">avatar_ratings = movie_matrix[<span class="hljs-string">'Avatar (2009)'</span>]
avatar_ratings = avatar_ratings.dropna()
<span class="hljs-built_in">print</span>(<span class="hljs-string">"\nRatings for 'Avatar (2009)':"</span>)
<span class="hljs-built_in">print</span>(avatar_ratings.head())
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">userId
10    2.5
15    3.0
18    4.0
21    4.0
22    3.5
Name: Avatar (2009), dtype: float64
</code></pre>
    <p class="normal">From the preceding code, note the following: </p>
    <ul>
      <li class="bulletList"><strong class="keyWord">userId</strong>: This represents the unique identifier for each user in our dataset. The <code class="inlineCode">userId</code> list contains <code class="inlineCode">10</code>, <code class="inlineCode">15</code>, <code class="inlineCode">18</code>, <code class="inlineCode">21</code>, and <code class="inlineCode">22</code> – the first five users in our data snapshot who have rated <em class="italic">Avatar </em>(2009).</li>
      <li class="bulletList"><strong class="keyWord">Ratings</strong>: The numbers adjacent to each <code class="inlineCode">userId</code> (<code class="inlineCode">2.5</code>, <code class="inlineCode">3.0</code>, <code class="inlineCode">4.0</code>, <code class="inlineCode">4.0</code>, and <code class="inlineCode">3.5</code>) represent the ratings these users assigned to <em class="italic">Avatar </em>(2009). The ratings range between <code class="inlineCode">1</code> and <code class="inlineCode">5</code>, where a higher value indicates a more favorable opinion about the movie. For example, <em class="italic">User 10</em> rated <em class="italic">Avatar </em>(2009) a <code class="inlineCode">2.5</code>, suggesting they found the movie average or perhaps slightly below their expectations, and <em class="italic">User 22</em> rated it a <code class="inlineCode">3.5</code>, expressing a slightly above-average appreciation for the movie.</li>
    </ul>
    <p class="normal">Let’s build <a id="_idIndexMarker1289"/>a recommendation engine that can recommend movies to a bunch of users.</p>
    <h3 id="_idParaDest-466" class="heading-3">Finding movies correlating with Avatar (2009)</h3>
    <p class="normal">By determining how other movies correlate in rating patterns with <em class="italic">Avatar </em>(2009), we can suggest <a id="_idIndexMarker1290"/>movies that might appeal to fans of <em class="italic">Avatar</em>.</p>
    <p class="normal">To present our findings neatly:</p>
    <pre class="programlisting code"><code class="hljs-code">similar_to_Avatar=movie_matrix.corrwith(Avatar_user_rating)
corr_Avatar = pd.DataFrame(similar_to_Avatar, columns=[<span class="hljs-string">'correlation'</span>])
corr_Avatar.dropna(inplace=<span class="hljs-literal">True</span>)
corr_Avatar = corr_Avatar.join(df_ratings[<span class="hljs-string">'number_of_ratings'</span>])
corr_Avatar.head()
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">                                   correlation      number_of_ratings
title                                                                
'burbs, The (1989)                    0.353553                     17
(500) Days of Summer (2009)           0.131120                     42
*batteries not included (1987)        0.785714                      7
10 Things I Hate About You (1999)     0.265637                     54
</code></pre>
    <h3 id="_idParaDest-467" class="heading-3">10,000 BC (2008) -0.075431 Understanding correlation</h3>
    <p class="normal">A higher correlation (close to 1) means a movie’s rating pattern is similar to <em class="italic">Avatar </em>(2009). A negative value indicates the opposite.</p>
    <p class="normal">However, it’s crucial <a id="_idIndexMarker1291"/>to approach the recommendations with caution. For instance, <em class="italic">*batteries not included </em>(1987) emerged as a top recommendation for <em class="italic">Avatar </em>(2009) fans, which might not seem accurate. This could be due to the limitations of relying solely on user ratings without considering other factors, like genres or movie themes. Adjustments and refinements would be needed for a more precise recommendation system.</p>
    <p class="normal">The resulting table showcases movies that correlate in terms of user rating behavior with <em class="italic">Avatar</em>. The table produced at the end of our analysis lists movies in terms of their correlation to <em class="italic">Avatar </em>based on user ratings. But what does this mean in simpler terms?</p>
    <p class="normal">Correlation, in this context, refers to a statistical measure that explains how one set of data moves in relation to another set of data. Specifically, we used the Pearson correlation coefficient, which ranges from -1 to 1:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">1</strong>: Perfect positive correlation. This means if <em class="italic">Avatar </em>received a high rating from a user, the other movie also received a high rating from the same user.</li>
      <li class="bulletList"><strong class="keyWord">-1</strong>: Perfect negative correlation. If <em class="italic">Avatar </em>got a high rating from a user, the other movie got a low rating from the same user.</li>
      <li class="bulletList"><strong class="keyWord">0</strong>: No correlation. The ratings of <em class="italic">Avatar </em>and the other movie are independent of each other.</li>
    </ul>
    <p class="normal">In our movie recommendation context, movies with a higher positive correlation value (closer to 1) to <em class="italic">Avatar </em>are deemed to be more suitable recommendations for users who liked <em class="italic">Avatar</em>. This is because these movies have shown a pattern of receiving ratings similar to <em class="italic">Avatar </em>from the users.</p>
    <p class="normal">By inspecting the table, you can identify which movies have a rating behavior akin to <em class="italic">Avatar </em>and, thus, can be potential recommendations for its fans.</p>
    <p class="normal">This means that we can use these movies as recommendations for the user.</p>
    <h3 id="_idParaDest-468" class="heading-3">Evaluating the model</h3>
    <p class="normal">Testing and <a id="_idIndexMarker1292"/>evaluation are critical. One way to evaluate our model is by using methods like train-test split, where a portion of data is set aside for testing. The model’s recommendations for the test set are then compared to <a id="_idIndexMarker1293"/>actual user ratings. Metrics like <strong class="keyWord">Mean Absolute Error</strong> (<strong class="keyWord">MAE</strong>) or <strong class="keyWord">Root Mean Square Error</strong> (<strong class="keyWord">RMSE</strong>) can <a id="_idIndexMarker1294"/>quantify the differences.</p>
    <h3 id="_idParaDest-469" class="heading-3">Retraining over time: incorporating user feedback</h3>
    <p class="normal">User preferences evolve. Retraining the recommendation model periodically with fresh data ensures <a id="_idIndexMarker1295"/>its recommendations remain relevant. Incorporating a feedback loop where users can rate or review recommendations further refines the model’s accuracy.</p>
    <h1 id="_idParaDest-470" class="heading-1">Summary</h1>
    <p class="normal">In this chapter, we learned about recommendation engines. We studied the selection of the right recommendation engine based on the problem that we are trying to solve. We also looked into how we can prepare data for recommendation engines to create a similarity matrix. We also learned how recommendation engines can be used to solve practical problems, such as suggesting movies to users based on their past patterns.</p>
    <p class="normal">In the next chapter, we will focus on the algorithms that are used to understand and process data.</p>
    <h1 id="_idParaDest-471" class="heading-1">Learn more on Discord</h1>
    <p class="normal">To join the Discord community for this book – where you can share feedback, ask questions to the author, and learn about new releases – follow the QR code below:</p>
    <p class="normal"><a href="https://packt.link/WHLel"><span class="url">https://packt.link/WHLel</span></a></p>
    <p class="normal"><img src="../Images/QR_Code1955211820597889031.png" alt="" role="presentation"/></p>
  </div>
</body></html>