- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Grouping Users with Customer Segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To better understand consumer needs, we need to understand that our customers
    have distinct consumer patterns. Each mass of consumers of a given product or
    service can be divided into segments, described in terms of age, marital status,
    purchasing power, and so on. In this chapter, we will be performing an exploratory
    analysis of consumer data from a grocery store and then applying clustering techniques
    to separate them into segments with homogenous consumer patterns. This knowledge
    will enable us to better understand their needs, create unique offers, and target
    them more effectively. In this chapter, we will learn about the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding customer segmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring data about a customer’s database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying feature engineering to standardize variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating users’ segments with K-means clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describing the common characteristics of these clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us see the requirements to understand the steps and follow the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to follow the steps in this chapter, you will need to meet the following
    requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: A Jupyter notebook instance running Python 3.7 and above. You can also use the
    Google Colab notebook to run the steps if you have a Google Drive account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An understanding of basic math and statistical concepts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A Kaggle account—you must agree to the terms and conditions of the competition
    from where we will get the data, which you can find here: [https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis](https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding customer segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Customer segmentation is the practice of classifying customers into groups based
    on shared traits so that businesses may effectively and appropriately market to
    each group. In **business-to-business** (**B2B**) marketing, a firm may divide
    its clientele into several groups based on a variety of criteria, such as location,
    industry, the number of employees, and previous purchases of the company’s goods.
  prefs: []
  type: TYPE_NORMAL
- en: Businesses frequently divide their clientele into segments based on demographics
    such as age, gender, marital status, location (urban, suburban, or rural), and
    life stage (single, married, divorced, empty nester, retired). Customer segmentation
    calls for a business to collect data about its customers, evaluate it, and look
    for trends that may be utilized to establish segments.
  prefs: []
  type: TYPE_NORMAL
- en: Job title, location, and products purchased—for example—are some of the details
    that can be learned from purchasing data to help businesses to learn about their
    customers. Some of this information might be discovered by looking at the customer’s
    system entry. An online marketer using an opt-in email list may divide marketing
    communications into various categories based on the opt-in offer that drew the
    client, for instance. However, other data—for example, consumer demographics such
    as age and marital status—will have to be gathered through different methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other typical information-gathering methods in consumer goods include:'
  prefs: []
  type: TYPE_NORMAL
- en: Face-to-face interviews with customers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online surveys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online marketing and web traffic information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus groups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All organizations, regardless of size, industry, and whether they sell online
    or in person, can use customer segmentation. It starts with obtaining and evaluating
    data and concludes with taking suitable and efficient action on the information
    acquired.
  prefs: []
  type: TYPE_NORMAL
- en: We will execute an unsupervised clustering of data on the customer records from
    a grocery store’s database in this chapter. To maximize the value of each customer
    to the firm, we will segment our customer base to alter products in response to
    specific needs and consumer behavior. The ability to address the needs of various
    clientele also benefits the firm.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first stage to understanding customer segments is to understand the data
    that we will be using. The first stage is, then, an exploration of the data to
    check the variables we must work with, handle non-structured data, and adjust
    data types. We will be structuring the data for the clustering analysis and gaining
    knowledge about the data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the analysis we will use in the next example, the following Python modules
    are used:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pandas**: Python package for data analysis and data manipulation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NumPy**: This is a library that adds support for large, multi-dimensional
    arrays and matrices, along with an ample collection of high-level mathematical
    functions to operate on these arrays.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scipy` for statistical computations, including descriptive statistics and
    estimation and inference for statistical models. It provides classes and functions
    for the estimation of many different statistical models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Yellowbrick**: A Python package of visual analysis and diagnostic tools designed
    to facilitate **machine learning** (**ML**) with scikit-learn.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seaborn, mpl_toolkits, and Matplotlib**: Python packages for effective data
    visualization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We’ll now get started with the analysis, using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following block of code will load all the required packages mentioned earlier,
    including the functions that we will be using, such as `LabelEncoder`, `StandardScaler`,
    and `Kmeans`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For readability purposes, we will limit the maximum rows to be shown to 20,
    set the limit of maximum columns to 50, and show the floats with 2 digits of precision:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will load the data, which is stored in the local data folder. The
    file is in CSV format with a tab delimiter. We will read the data into a Pandas
    DataFrame and print the data shape as well as show the first rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: User data ](img/B19026_08_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: User data'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to get a full picture of the steps that we will be taking to clean
    the dataset, let us have a look at the statistical summary of the data with the
    `describe` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: Descriptive statistical summary ](img/B19026_08_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: Descriptive statistical summary'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get more information on features, we can use the `info` method to display
    the number of `null` values and data types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: Column data types and null values ](img/B19026_08_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: Column data types and null values'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the preceding output shown with the `describe` and `info` methods of Pandas
    DataFrames, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: There are 26 missing values in the `Income` column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The date variable named `Dt_Customer`, indicating the date a customer joined
    the database, is not parsed as `DateTime`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are categorical features in our DataFrame of the `dtype` object that we
    will need to encode into numerical features later to be able to apply the clustering
    method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To address the missing values, we will drop the rows that have missing income
    values, as it is an important variable to describe to customers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will parse the date column using the `pd.to_datetime` Pandas method. Take
    into account that the method will infer the format of the date, but we can otherwise
    specify it if it is necessary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After parsing the dates, we can look at the values of the newest and oldest
    recorded customer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the next step, we will create a feature out of `Dt_Customer` that indicates
    the number of days a customer is registered in the firm’s database, relative to
    the first user that was registered in the database, although we could use today’s
    date. We do this because we are analyzing historical records and not up-to-date
    data. The `Customer_For` feature is, then, the date of when the customer was registered
    minus the minimum value in the date column and can be interpreted as the number
    of days since customers started to shop in the store relative to the last recorded
    date:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will explore the unique values in the categorical features to get a
    clear idea of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.4: Marital status ](img/B19026_08_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.4: Marital status'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that there are several types of marital status, which may have
    been caused by free text entry during the data capturing. We will have to standardize
    these values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will look at the values in the `Education` feature using the `value_counts`
    method to create a bar chart using the Pandas `plot` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.5: Education values ](img/B19026_08_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5: Education values'
  prefs: []
  type: TYPE_NORMAL
- en: Again, we can see the effects of free text entry as there are several values
    that have the same underlying meaning; thus, we will need to standardize them
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will apply feature engineering to structure the data
    for better understanding and treatment of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to properly analyze the data as well as to model the clusters, we
    will need to clean and structure the data—a step that is commonly referred to
    as feature engineering—as we need to restructure some of the variables according
    to our plan of analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will be performing the next steps to clean and structure
    some of the dataset features, with the goal of simplifying the existing variables
    and creating features that are easier to understand and describe the data properly:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an `Age` variable for a customer by using the `Year_Birth` feature, indicating
    the birth year of the respective person.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `Living_With` feature to simplify the marital status, to describe the
    living situation of couples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `Children` feature to indicate the total number of children in a household—that
    is, kids and teenagers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Aggregate spending by product type to better capture consumer behaviors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Indicate parenthood status with a feature named `Is_Parent`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So, let’s apply the steps mentioned here to structure the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let us start with the age of the customer as of today, using the `pd.to_datetime`
    method to get the current year and the year of birth of the customers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will model the spending on distinct items by using the `sum` method
    on selected columns and summing along the column axis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the next step, we will map the marital status values into a different encoding
    to simplify terms with close meaning. For this, we define a mapping dictionary
    and use it to replace the values in the `marital_status` column to create a new
    feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a `Children` feature by summing up the total number of children
    living in the household plus teens living at home:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we model the total members in the household using the relationship and
    children data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we capture the parenthood status in a new variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will segment education levels into three groups for simplification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, to simplify, we rename columns into more understandable terms using a
    mapping dictionary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will drop some of the redundant features to focus on the clearest features,
    including the ones we just created. Finally, we will look at the statistical descriptive
    analysis using the `describe` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The stats show us that there are some discrepancies in the `Income` and `Age`
    features, which we will visualize to better understand these inconsistencies.
    We will start with a histogram of `Age`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.6: Age data ](img/B19026_08_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.6: Age data'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that there are some outliers, more than 120 years old, so we will
    be removing those.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we look at the income distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.7: Income data ](img/B19026_08_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.7: Income data'
  prefs: []
  type: TYPE_NORMAL
- en: Again, we can see that most incomes are below 20,000, so we will be limiting
    the spending level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we drop the outliers by setting a cap on `Age` to avoid data that doesn’t
    reflect reality, and the income to include 99% of the cases:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code prints the next output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can look back at the `Age` and `Spend` data distribution to better
    understand our customers. We start by creating a histogram plot of the `Age` feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.8: Age with no outliers ](img/B19026_08_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.8: Age with no outliers'
  prefs: []
  type: TYPE_NORMAL
- en: The age is centered on the 50s, with a skew to the right, meaning that the average
    age of our customers is above 45 years.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.9: Income with no outliers ](img/B19026_08_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.9: Income with no outliers'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the spend distribution, it has a normal distribution, centered on
    4,000 and slightly skewed to the left.
  prefs: []
  type: TYPE_NORMAL
- en: 'Up next, we will create a Seaborn pair plot to show the relationships between
    the different variables, with color labeling according to the parental status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.10: Relationship plot ](img/B19026_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.10: Relationship plot'
  prefs: []
  type: TYPE_NORMAL
- en: These graphics allow us to quickly observe relationships between the different
    variables, as well as their distribution. One of the clearest is the relationship
    between spend and income, in which we can see that the higher the income, the
    higher the expenditure, as well as observing that single parents spend more than
    people who are not. We can also see that the consumers with higher recency are
    parents, while single consumers have lower recency values. Next, let us look at
    the correlation among the features (excluding the categorical attributes at this
    point).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create a correlation matrix using the `corr` method, and show only
    the lower triangle of data using a `numpy` mask. Finally, we will use a Seaborn
    method to display the values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.11: Variable correlation ](img/B19026_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.11: Variable correlation'
  prefs: []
  type: TYPE_NORMAL
- en: The correlations allow us to explore the variable relationships in more detail.
    We can see negative correlations between children and expenditure in the mean,
    while there are positive relationships between children and recency. These correlations
    allow us to better understand consumption patterns.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will use the concept of clustering to segment the clients
    into groups that share common characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Creating client segments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Marketers can better target different audience subgroups with their marketing
    efforts by segmenting their audiences. Both product development and communications
    might be a part of those efforts. Segmentation benefits a business by allowing
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating targeted marketing communication on the right communication channel
    for each client or user segment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the right pricing options to the right clients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concentrating on the most lucrative clients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing better client service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Promoting and cross-promoting other goods and services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this section, we will be preprocessing the data to be able to apply clustering
    methods for customer segmentation. The steps that we will apply to preprocess
    the data are set out here:'
  prefs: []
  type: TYPE_NORMAL
- en: Encoding the categorical variables using a label encoder, which will transform
    them into numerical columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling features using the standard scaler to normalize the values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying **principal component analysis** (**PCA**) for dimensionality reduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, let’s follow the steps here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to list the categorical variables. Here, we will use the column
    names and check the column `dtype` to get only the object columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will encode the `dtypes` object using the `sklearn` `LabelEncoder`
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We subset the data and apply scaling to the numerical variables by dropping
    the features on deals accepted and promotions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can apply the scaling:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are numerous attributes in this dataset that describe the data. The more
    features there are, the more difficult it is to correctly analyze them in a business
    environment. Many of these characteristics are redundant since they are connected.
    Therefore, before running the features through a classifier, we will conduct dimensionality
    reduction on the chosen features.
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction is the process of reducing the number of random variables
    considered. To reduce the dimensionality of huge datasets, a technique known as
    PCA is frequently utilized. PCA works by condensing an ample collection of variables
    into a smaller set that still retains much of the data in the larger set.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy naturally suffers as a dataset’s variables are reduced, but the answer
    to dimensionality reduction is to trade a little accuracy for simplicity since
    ML algorithms can analyze data much more quickly and easily with smaller datasets
    because there are fewer unnecessary factors to process. In conclusion, the basic
    principle of PCA is to keep as much information as possible while reducing the
    number of variables in the data collected.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps that we will be applying in this section are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction with PCA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plotting the reduced DataFrame in a 3D plot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dimensionality reduction with PCA, again
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This will allow us to have a way to visualize the segments projected into three
    dimensions. In an ideal setup, we will use the weights of each component to understand
    what each component represents and make sense of the information we are visualizing
    in a better way. For reasons of simplicity, we will focus on the visualization
    of the components. Here are the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will initiate PCA to reduce dimensions or features to three in order
    to reduce complexity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The amount of variation in a dataset that can be attributed to each of the main
    components (eigenvectors) produced by a PCA is measured statistically as “explained
    variance”. This simply refers to how much of a dataset’s variability may be attributed
    to each unique primary component.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For this project, we will reduce the dimensions to three, which manages to
    explain the 54% total variance in the observed variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can project the data into a 3D plot to see the points’ distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code will show us the dimensions projected in three dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12: PCA variables in 3D ](img/B19026_08_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.12: PCA variables in 3D'
  prefs: []
  type: TYPE_NORMAL
- en: Since the attributes are now only three dimensions, agglomerative clustering
    will be used to perform the clustering. A hierarchical clustering technique is
    agglomerative clustering. Up until the appropriate number of clusters is reached,
    examples are merged.
  prefs: []
  type: TYPE_NORMAL
- en: The process of clustering involves grouping the population or data points into
    a number of groups so that the data points within each group are more like one
    another than the data points within other groups. Simply put, the goal is to sort
    into clusters any groups of people who share similar characteristics. Finding
    unique groups, or “clusters”, within a data collection is the aim of clustering.
    The tool uses an ML algorithm to construct groups, where members of a group would
    typically share similar traits.
  prefs: []
  type: TYPE_NORMAL
- en: Two methods of pattern recognition used in ML are classification and clustering.
    Although there are some parallels between the two processes, clustering discovers
    similarities between things and groups them according to those features that set
    them apart from other groups of objects, whereas classification employs predetermined
    classes to which objects are assigned. “Clusters” is the name for these collections.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps involved in clustering are set out here:'
  prefs: []
  type: TYPE_NORMAL
- en: Elbow method to determine the number of clusters to be formed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering via agglomerative clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examining the clusters formed via a scatter plot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In K-means clustering, the ideal number of clusters is established using the
    elbow approach. The number of clusters, or K, formed by various values of the
    cost function are plotted using the elbow approac:.
  prefs: []
  type: TYPE_NORMAL
- en: 'The elbow approach is a heuristic used in cluster analysis to estimate the
    number of clusters present in a dataset. Plotting the explained variation as a
    function of the number of clusters, the procedure entails choosing the elbow of
    the curve as the appropriate number of clusters, as illustrated in the following
    code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code will plot an elbow plot, which will be a good estimation of the required
    number of clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13: Elbow method ](img/B19026_08_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.13: Elbow method'
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the preceding cell, four clusters will be the best choice for
    this set of data. To obtain the final clusters, we will then fit the agglomerative
    clustering model, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we will add a `Clusters` feature to the original DataFrame for visualization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can visualize the clusters in three dimensions using the color codes
    of each cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code will show a three-dimensional visualization of the PCA components
    colored according to the clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14: PCA variables with cluster labeling ](img/B19026_08_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.14: PCA variables with cluster labeling'
  prefs: []
  type: TYPE_NORMAL
- en: From this, we can see that each cluster occupies a specific space in the visualization.
    We will now dive into a description of each cluster to better understand these
    segments.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding clusters as customer segments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To rigorously evaluate the output obtained, we need to evaluate the depicted
    clusters. This is because clustering is an unsupervised method and the patterns
    extracted should always reflect reality, otherwise; we might just as well be analyzing
    noise.
  prefs: []
  type: TYPE_NORMAL
- en: Common traits among consumer groups can help a business choose which items or
    services to advertise to which segments and how to market to each one.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do that, we will use **exploratory data analysis** (**EDA**) to look at
    the data in the context of clusters and make judgments. Here are the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us first examine the clustering group distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.15: Cluster count ](img/B19026_08_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.15: Cluster count'
  prefs: []
  type: TYPE_NORMAL
- en: The clusters are fairly distributed with a predominance of cluster 0\. It can
    be clearly seen that cluster 1 is our biggest set of customers, closely followed
    by cluster 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can explore what each cluster is spending on for the targeted marketing
    strategies using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.16: Income versus spending ](img/B19026_08_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.16: Income versus spending'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the income versus spending plot, we can see the next cluster patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster 0 is of high spending and average income
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster 1 is of high spending and high income
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster 2 is of low spending and low income
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster 3 is of high spending and low income
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we will see the detailed distribution of clusters of the expenditure
    per product in the data. Namely, we will explore expenditure patterns. The code
    is illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.17: Spend distribution per cluster ](img/B19026_08_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.17: Spend distribution per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: From *Figure 8**.17*, it can be seen how the spend is evenly distributed in
    cluster 0, cluster 1 is centered on high expenditure, and clusters 2 and 3 center
    on low expenditure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will use Seaborn to create Boxen plots of the clusters to find the
    spend distribution per cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.18:  Spend distribution per cluster (Boxen plot) ](img/B19026_08_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.18: Spend distribution per cluster (Boxen plot)'
  prefs: []
  type: TYPE_NORMAL
- en: We can visualize the patterns in a different way using a Boxen plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will create a feature to get a sum of accepted promotions so that
    we can model their relationships with the different clusters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will plot the count of total campaigns accepted in relation to the
    clusters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.19: Promotions applied per cluster ](img/B19026_08_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.19: Promotions applied per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that although there is no characteristic pattern in the promotions
    per cluster, we can see that cluster 0 and cluster 2 are the ones with the highest
    number of applied promotions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can visualize the number of deals purchased per type of cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.20: Purchased deals per cluster ](img/B19026_08_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.20: Purchased deals per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Promotional campaigns failed to be widespread, but the transactions were successful.
    The results from clusters 0 and 2 are the best. Cluster 1, one of our top clients,
    is not interested in the promotions, though. Nothing draws cluster 1 in a strong
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the clusters have been created and their purchasing patterns have been
    examined, let us look at everyone in these clusters. To determine who is our star
    customer and who requires further attention from the retail store’s marketing
    team, we will profile the clusters that have been developed.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the cluster characterization, we will graph some of the elements
    that are indicative of the customer’s personal traits. We will draw conclusions
    based on the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use a Seaborn joint plot to visualize both the relationships and distributions
    of different variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.21: Spend versus education distribution per cluster ](img/B19026_08_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.21: Spend versus education distribution per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster 0 is centered on medium education but with a peak in high education.
    Cluster 2 is the lowest in terms of education.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will look at family size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.22: Spend versus family size distribution per cluster ](img/B19026_08_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.22: Spend versus family size distribution per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster 1 represents small family sizes, and cluster 0 represents couples and
    families. Clusters 2 and 3 are evenly distributed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll now look at the spend versus customer cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.23: Spend versus customer distribution per cluster ](img/B19026_08_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.23: Spend versus customer distribution per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster 3 is the group with older clients. While it is interesting to see that
    although cluster 0 is the one with the highest spending, it is skewed to the left
    in terms of days since the user has been a customer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.24: Spend versus age distribution per cluster ](img/B19026_08_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.24: Spend versus age distribution per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster 0 is the one with older customers, and the one with the youngest clients
    is cluster 2.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have performed unsupervised clustering. After dimensionality
    reduction, agglomerative clustering was used. To better profile customers in clusters
    based on their family structures, income, and spending habits, we divided users
    into four clusters. This can be applied while creating more effective marketing
    plans.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive into the prediction of sales using time-series
    data to be able to determine revenue expectations given a set of historical sales,
    as well as understand their relationship with other variables.
  prefs: []
  type: TYPE_NORMAL
