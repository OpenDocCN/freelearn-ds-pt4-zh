- en: '*Chapter 5*: Letting the Machines Do the Model Training'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will create your first **Automated Machine Learning** (**Automated
    ML** or **AutoML**) experiment. AutoML refers to the process of trying multiple
    modeling techniques and selecting the model that produces the best predictions
    against the training dataset you specify. First, you will navigate through the
    AutoML wizard that is part of the Azure Machine Learning Studio web experience
    and understand the different options that need to be configured. You will then
    learn how to monitor the progress of an AutoML experiment and how to deploy the
    best-produced model as a web service hosted in an **Azure Container Instance**
    (**ACI**) to be able to make real-time inferences.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to go through this chapter is by sitting in front of a computer
    with this book by you. By using your Azure subscription and this book together,
    you can start your journey through AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring an AutoML experiment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring execution of an experiment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying best model as a web service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to have access to an Azure subscription. Within that subscription,
    you will need a `packt-azureml-rg`. You will need to have either a `Contributor`
    or `Owner` `packt-learning-mlw`, as described in [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026),
    *Deploying Azure Machine Learning Workspace Resources*.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring an AutoML experiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you were asked to train a model to make predictions against a dataset, you
    would need to do a couple of things, including normalizing the dataset, splitting
    it into train and validation data, running multiple experiments to understand
    which algorithm is performing best against the dataset, and then finetuning the
    best model. Automated machine learning shortens this process by fully automating
    the time-consuming, iterative tasks. It allows all users, from normal PC users
    to experienced data scientists, to build multiple machine learning models against
    a target dataset and select the model that performs the best, based on a metric
    you select.
  prefs: []
  type: TYPE_NORMAL
- en: 'This process consists of the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preparing the experiment**: Select the dataset you are going to use for training,
    select the column that you are trying to predict, and configure the experiment''s
    parameters. This is the configuration phase you will read about in this section.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data guardrails**: This is the first step of executing the experiment. It
    performs basic data guardrails on top of the provided training dataset. AutoML
    tries to identify potential issues with your data; for example, all the training
    data must have the same values in the column you are trying to predict.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Training multiple models**: Train multiple combinations of data normalization
    and algorithms to find the best model that optimizes (maximizes or minimizes)
    the desired metric. This process continues until one of the exit criteria is met,
    either a time constraint or a specified model performance target.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Creating an ensemble model**: Here, you train a model that combines the results
    of the best models trained so far and produces a potentially improved inference.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Selecting the best model**: The best model is selected based on the metric
    you specified.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure Machine Learning provides a web-based wizard that allows you to configure
    such an experiment. In [*Chapter 3*](B16777_03_Final_VK_ePub.xhtml#_idTextAnchor045),
    *Azure Machine Learning Studio Components*, you explored the **Azure Machine Learning
    Studio** \ web experience.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will create an AutoML classification model that will predict
    whether a customer will churn or not. This model will be able to predict whether
    a customer will continue being a loyal customer or whether they will terminate
    their active mobile phone contract. You will use a fabricated dataset from a fictional
    telecom company. The dataset shows, for each customer, information about how long
    they have been with the company and how much they are using their active subscription.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: To start the AutoML experiment, you will need to open a browser and navigate
    to the Azure Machine Learning Studio. You will land on the home page, as shown
    in the following screenshot:![Figure 5.1 – Azure Machine Learning Studio home
    screen
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_001.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.1 – Azure Machine Learning Studio home screen
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the Azure Machine Learning Studio home screen, navigate to the **Author**
    | **Automated ML** section by clicking the **Start now** button under **Automated
    ML**, as highlighted in the preceding screenshot. This will open the **Automated
    ML** home screen, as shown here:![Figure 5.2 – The Automated ML home screen
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_002.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.2 – The Automated ML home screen
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On this home screen, you can find the recently executed Automated ML experiments.
    Since this is the first time you are using this workspace, you shouldn't find
    any runs listed here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'By pressing the **New Automated ML Run** button, you will start the **Create
    a New Automated ML** wizard, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Starting the Automated ML wizard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_05_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Starting the Automated ML wizard
  prefs: []
  type: TYPE_NORMAL
- en: In this first step of the wizard, named **Select dataset**, you can either select
    an existing dataset or create a new one. From this list, you will be able to see
    the two datasets that you registered in [*Chapter 4*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053),
    *Configuring the Workspace*. You will not need those datasets. In the next section,
    you will learn how to create a new dataset to use for the Automated ML experiment
    you are about to perform.
  prefs: []
  type: TYPE_NORMAL
- en: Registering the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the **Select dataset** step of the **Automated ML** wizard, you can register
    a new dataset to be used for the AutoML experimentation. Follow these steps to
    register the fabricated churn dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Create dataset** on the top of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **From web files** from the drop-down menu that appears. This will start
    the **Create dataset from web files** wizard shown in the following screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the first page of the wizard (`churn-dataset`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: c) `Tabular`. This is an option that you cannot change since AutoML currently
    only supports tabular datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) `Dataset to train a model that predicts customer churn`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Basic info when creating a dataset from web files'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16777_05_004.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.4 – Basic info when creating a dataset from web files
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once you've filled everything in, press **Next**. It will take a while to download
    and parse the file. The wizard will move to the **Settings and preview** screen:![Figure
    5.5 – The Settings and preview screen of the Create dataset from web files wizard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_005.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.5 – The Settings and preview screen of the Create dataset from web
    files wizard
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The steps shown in the preceding screenshot provide important information for
    the demo dataset. The file format of the sample file is automatically detected
    to be the **Parquet** file format. You can modify the selection if needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The demo dataset consists of seven columns:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**ld** is a sequential record number that is not part of the original Parquet
    file. Auto ML generates this sequence number to let you validate the data you
    can see in the preview window. This column will not be part of the registered
    dataset.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**id** is a string that uniquely identifies each customer in the dataset.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**customer_tenure** is an integer value telling us how long each customer has
    been with the fictional telecom company. The value represents months.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**product_tenure** is an integer value that tells us how long a customer has
    owned the currently active subscription. It is measured in months.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**activity_last_6_month** tells us how many hours the customer has talked on
    the phone over the last 6 months.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**activity_last_12_month** tells us how many hours the customer has talked
    on the phone over the last 12 months.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**churned** is a flag that informs us whether the customer renewed the subscription
    or terminated the active contract. This is the column you will be trying to predict.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: From this fabricated dataset, the most relevant features for the classification
    model you are trying to build are **customer_tenure**, **product_tenure**, **activity_last_6_month**,
    and **activity_last_12_month**. The **churned** column is the **target** for the
    model you are trying to build. The **id** column allows you to link a model's
    prediction back to the actual customer who may churn.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Pressing `Date` as the type of a column, you will be able to select whether
    this column is a timestamp, something that will mark the dataset as a time series
    one. `Date` as the column's type. This allows you to define the date pattern that
    should be used to parse the specific column. For example, you can use `%Y-%m-%d`
    to specify that the date is stored in a year-month-day format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you've finished exploring the wizard's **Schema** screen, press **Next**.
    The wizard's **Confirm details** screen provides you with an overview of the new
    dataset you want to register in your workspace, as shown here:![Figure 5.7 – The
    Confirm details page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_007.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.7 – The Confirm details page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This screen summarizes the dataset information you read about in the *Working
    with datasets* section of [*Chapter 4*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053),
    *Configuring the Workspace*. If you select the **Profile this dataset after creation**
    checkbox, you can select a compute target to generate the profile of the newly
    created dataset. You do not need to generate the profile for this dataset since
    it only has 6,720 rows and Azure ML will automatically provide a full profile
    for you.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Create** button to complete the wizard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you have registered `churn-dataset`, you can continue with the AutoML
    wizard, where you will select the newly registered dataset, configure the experiment
    parameters, and kick off the AutoML process, something you will do in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to the AutoML wizard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that you have created `churn-dataset`, you can continue with the AutoML
    wizard. The wizard contains three steps, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – AutoML wizard steps'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_05_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.8 – AutoML wizard steps
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin with the steps!
  prefs: []
  type: TYPE_NORMAL
- en: As the first step, select `churn-dataset`, which you created in the previous
    section, *Registering the dataset*, and click **Next**, as shown here:![Figure
    5.9 – The Select dataset step of the Create a new Automated ML run wizard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_009.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.9 – The Select dataset step of the Create a new Automated ML run wizard
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the `churn-automl-experiment` for `churned` column. Based on the type of
    the target column, the wizard will automatically select the best task for this
    column, as you will see in the next wizard step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`gpu-cluster` here, which you created in the *Compute clusters* section of
    [*Chapter 4*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053), *Configuring the
    Workspace*. If you don''t have a cluster registered in your workspace, you can
    use a compute instance or you can start the dedicated wizard by clicking on the
    `gpu-cluster`. By default, free trial subscriptions do not allow you to provision
    GPU computes. For this experiment, you can select CPU-based clusters instead of
    GPU-based ones.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have configured the run details, click on the **Next** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next page of the wizard is the **Select task and settings** page, as shown
    here:![Figure 5.11 – The Create a new Automated ML run wizard – Select task type
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_011.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.11 – The Create a new Automated ML run wizard – Select task type
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this step, you can configure the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) **Select task type**: AutoML currently supports three types of tasks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Classification**: The produced model can predict the category a record belongs
    to. A category can be anything, such as a yes or no **Boolean** value or a blue,
    green, or yellow color value. In our case, you are trying to predict if the customer
    is going to churn, which can be answered with a yes or a no.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression**: Use regression models when you want to predict a numeric value,
    such as the price of an apartment or the diabetes disease level. We will look
    at this in [*Chapter 8*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117), *Experimenting
    with Python Code*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time series forecasting**: You usually use this type of model to predict
    time series values such as a stock''s price while considering the progress of
    the value over time. This type of model is a specialization on top of the regression
    models. This means that all regression models can be used, but there are also
    a couple of more specialized algorithms such as Facebook''s **Prophet** algorithm
    or the **Auto-Regressive Integrated Moving Average** (**ARIMA**) technique.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the target column you selected, the wizard will automatically guess
    the task you are trying to perform. In our case, it selected **Classification**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) **View additional configuration settings**: Depending on the task type you
    selected, you can configure various settings, including the target metric to be
    used to evaluate the models and the exit criteria that will terminate the search
    for the best model. Depending on the task''s type, the options on that wizard
    page change. You can see some of these options in the following diagram. You will
    visit this part of the wizard in *Step 5*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Configuration settings depending on the selected task type.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16777_05_012.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.12 – Configuration settings depending on the selected task type.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) **View featurization settings**: This allows you to configure various operations
    regarding the features that the model will use to make its prediction. In this
    section, you can exclude features such as row unique ID or irrelevant information
    to speed up the training process and reduce the size of the final model. You can
    also specify the type of each feature and the imputation function, which takes
    care of the missing values in the dataset. You will visit this section of the
    wizard in *Step 6*.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By clicking on `auto` in most cases unless you have a reason to modify it. By
    default, 10-folds cross-validation is used if you have fewer than 1,000 rows,
    3-folds is used if you have more than 1,000 and fewer than 20,000 rows, and if
    you have more than 20,000 rows, the dataset is split into 90% training data and
    10% validation data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`0.5`, which is half an hour or 30 minutes. You can leave the rest of the options
    as is, as shown in the preceding screenshot. Click **Save** and return to the
    **Select task type** page of the wizard you saw in *Step 4*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By clicking on **View featurization settings**, the **Featurization** screen
    will open, as shown here:![Figure 5.14 – The Featurization view on the create
    AutoML wizard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_014.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.14 – The Featurization view on the create AutoML wizard
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'On this screen, you can define actions that influence the data preparation
    phase for the training process. The following options can be configured:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Included**: You can exclude columns that should not be considered by the
    algorithm. The target column cannot be excluded.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature type**: By default, the **Auto** value is selected, which will automatically
    detect the type of each column you have in the dataset. It can be one of the following
    types: **Numeric**, **DateTime**, **Categorical**, **Categorical hash**, or **Text**.
    If you want, you can manually configure a column to be one of the available types.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Impute with**: If you have missing values in your dataset, this option will
    do in-place imputation based on the selected methodology. The options you can
    choose from are **Auto**, which is the default one, **Most frequent**, and **Fill
    with constant**. Especially for **Numeric** features, you can also use the **Mean**
    or the **Median** imputation strategy.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Imagine that you had a product ID feature that explicitly mentioned the subscription
    product each customer is registered for. This feature would have numeric values,
    such as 1,055 and 1,060\. This feature could accidentally be marked as a numeric
    feature, even though it is a categorical one. If you were missing values in the
    training dataset, the automatic approach may have imputed missing values with
    the average product ID, which doesn't make any sense. AutoML is smart enough to
    understand that if a numeric feature only has a few unique values repeating, this
    feature may be a categorical one, but you can explicitly assist the machine learning
    models by marking them as **Categorical** regarding **Feature type**.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: On this wizard page, you should exclude the **id** feature. The **id** feature
    provides information on who the actual customer is. It doesn't provide any relevant
    information to the classification problem, so it should be excluded to save on
    computational resources. Click **Save** to return to the **Select task type**
    page of the wizard you saw in *Step 4*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By clicking **Finish**, as shown in *Figure 5.11*, you can finalize the configuration
    of your AutoML experiment, and the run will automatically start. The browser will
    redirect you to the AutoML run execution page, which allows you to monitor the
    AutoML training process and review the training results. You are going to explore
    that page in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring the execution of the experiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, *Configuring an Automated ML experiment*, you submitted
    an AutoML experiment to execute on a remote compute cluster. Once you have submitted
    the job, your browser should redirect you to a page similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Running a new Automated ML run for the first time since the
    run finished'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_05_015.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.15 – Running a new Automated ML run for the first time since the run
    finished
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the page, the name of the run of the experiment is autogenerated.
    In the preceding screenshot, it is called `AutoML_05558d1d-c8ab-48a5-b652-4d47dc102d29`.
    By clicking the pencil icon, you can edit this name and make it something more
    memorable. Change the name to `my-first-experiment-run`. Right below the run''s
    name, you can click on one of the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Refresh**: This will refresh the information provided on the page. While
    running an experiment, you can get the latest and greatest information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generate notebook**: This will create a notebook with all the Python code
    that is needed to run the same experiment using the Azure ML SDK. You will learn
    more about the code needed to run an AutoML experiment through code in [*Chapter
    8*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117), *Experimenting with Python
    Code*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cancel**: This will cancel the current run. This option is only available
    if the experiment is still running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When you cancel a run, it may take a while until the run is canceled. By clicking
    on the **Refresh** button, you can check the progress of the cancelation process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Delete**: This deletes the selected run. It is only enabled if the run has
    been canceled or has finished executing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The run experiment page provides a lot of information regarding the entire
    process and is structured using tabs. By default, you start from the tab called
    **Details**. In this tab, you will find the following important information:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Properties** box, which is located on the left of the preceding screenshot,
    the most important information is located in the following fields:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a) **Status**, which describes the state of the current run. This can be running,
    canceled, errored, or completed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) **Compute target** is where the run is executed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) **Raw JSON** is a link that allows you to review all the configuration information
    of the current run in a machine-readable format.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the **Run summary** box on the right, you will find **Task type**, which
    is the type of model you are training. By clicking on **View configuration settings**,
    you can get a summary of the configuration parameters for the current experiment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Description** box allows you to document the hypothesis you are evaluating
    in the current experiment. By clicking the pencil icon, you can add a description
    of your experiment run, information that will allow you to recollect what you
    were looking for with this experiment and what the outcome was.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second tab of the run page is named **Data guardrails**. This tab provides
    you with detailed qualitative and quantitative information on the dataset you
    are using in your experiment. Depending on the task type, you will have different
    types of validation being performed. The status of each validation is **Passed**
    if everything was OK, **Failed** if your dataset has an issue that needs to be
    resolved, or **Done** if AutoML found an issue with your dataset and fixed it
    for you. In the **Done** cases, you will be able to see additional information
    on what was fixed in your dataset by clicking on the **+View additional details**
    button.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third tab is called **Model** and contains a list of all the models AutoML
    has trained so far, as seen in *Figure 5.16*. The model with the best metric score
    will be listed at the top. The table shows **Algorithm name**, the specific model''s
    explanation results (if they are available) (**Explained**), the model''s score
    (**Accuracy**, in this case), the percentage of the data used to train the model
    (**Sampling**), and information regarding when the model was trained and how long
    it took (the **Created** and **Duration** columns). If you select a model from
    the list, the following three commands will be enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deploy** initiates the deployment of the selected model, which you will learn
    about in the next section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model.pkl`, which includes the actual trained model and all supporting files
    needed to perform inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explain model** kicks off the **Explanations** wizard, where you need to
    select a **compute cluster** to calculate the model explanations for the specific
    model. By default, AutoML will explain the best model, but you may want to explain
    additional models to compare them. Once the explanations have been calculated,
    you can view them by clicking on **View explanation** in the **Explained** column.
    This will open the **Explanations** tab of the selected model, which has populated
    the report. You will learn more about model interpretability in [*Chapter 10*](B16777_10_Final_VK_ePub.xhtml#_idTextAnchor147),
    *Understanding Model Results*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fourth tab on the main page, called **Outputs + logs**, displays the outputs
    and log of the specific run in a simple files explorer. These logs are the ones
    of the overall AutoML process. If you want to view the logs of a specific model
    training process, you will need to select the model from the **Models** tab and
    then visit the **Outputs + logs** section of that child run. The files explorer
    that's available in this tab allows you to navigate through the folder structure
    on the left-hand side. If you select a file, its contents will be displayed on
    the right-hand side.
  prefs: []
  type: TYPE_NORMAL
- en: So far, you have managed to train a couple of models and see the best model
    to predict whether a customer will churn or not. In the next section, you will
    learn how to operationalize this model with only a couple of clicks.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the best model as a web service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, you navigated around the run experiment page while
    reviewing the information related to the run execution and the results of the
    exploration, which are the trained models. In this section, we will revisit the
    **Models** tabs and start deploying the best model as a web service to be able
    to make real-time inferences. Navigate to the run''s details page, as shown in
    *Figure 5.15*. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the **Models** tab. You should see a page similar to the one shown
    here:![Figure 5.16 – The Models tab as a starting point for deploying a model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_016.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.16 – The Models tab as a starting point for deploying a model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this list, you can select any model you want to deploy. Select the row with
    the best model, as shown in the preceding screenshot. Click the **Deploy** command
    at the top of the list. The **Deploy a model** dialog will appear, as shown here:![Figure
    5.17 – The Deploy a model dialogue
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_017.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.17 – The Deploy a model dialogue
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the `myfirstmlwebservice`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Compute type**: There are two types you can choose from:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Azure Kubernetes Cluster** (**AKS**): This option should be selected when
    you want to deploy your model for a production workload and are handling multiple
    requests in parallel. This option allows for both key-based and token based authentications
    if you want to protect the endpoint. It also supports using **Field Programmable
    Gate Arrays** (**FPGAs**) for even faster model inferences. In this case you would
    also need to specify the **Compute name** property of the AKS cluster where you
    want to deploy the model. The list should contain all inference clusters you may
    have registered in [*Chapter 4*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053),
    *Configuring the Workspace*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Container Instance**: If you plan to do functional testing or you want
    to deploy a model for the development environments, you can deploy the web service
    as a single Azure Container Instance. This compute type is cheaper, but it doesn''t
    scale and it only supports key-based authentication. For this book, you can select
    this type to deploy the model.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By pressing **Deploy**, you can start deploying the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the top-right corner of your browser, a popup window will appear, as shown
    in the following screenshot, letting you know that your model has started being
    deployed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Endpoint deployment window – deployment InProgress'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16777_05_018.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.18 – Endpoint deployment window – deployment InProgress
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The pop-up window will quickly disappear, but you can revisit it by clicking
    on the notification **bell** icon in the top-right corner, as shown here:![Figure
    5.19 – Azure Machine Learning Studio taskbar in the top-right corner
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_019.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.19 – Azure Machine Learning Studio taskbar in the top-right corner
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The model will take a couple of minutes to deploy. By looking at your notifications,
    you can check the progress of your deployment. If the notification turns green,
    as shown in the following screenshot, then the deployment is completed:![Figure
    5.20 – Endpoint deployment window – deployment Completed
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_020.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.20 – Endpoint deployment window – deployment Completed
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By clicking on the **Deploy details** link in the notification, your browser
    will redirect you to the endpoint page of the deployed model, as shown here:![Figure
    5.21 – Endpoint page of the deployed model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_021.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.21 – Endpoint page of the deployed model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There are multiple ways you can reach the endpoint page of your model. For example,
    you can see a list of all the published endpoints by going to the **Assets** |
    **Endpoints** menu in Azure ML Studio. To reach the same page, select the endpoint
    you want to inspect.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The endpoint page of the deployed model has a similar tab-based structure to
    the run experiment page. The first tab is called **Details** and provides information
    regarding the deployment of the model. Out of them, the most important ones are
    located in the **Attributes** box shown in the preceding screenshot. They are
    as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Service ID** is the name of the service you specified in *Step 3* of the
    deployment wizard.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment state** provides the state of the deployed or to-be-deployed model.
    There are five states the endpoint can be in. You can find more information regarding
    states and potential issues in the *Further reading* section of this chapter.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rest endpoint** is the link you can copy into an application''s code to call
    the deployed model via a REST API.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The second tab is called **Test** and allows you to test the deployed model.
    By default, you get the **Fields** mode, which is a form containing all the inputs
    your model is expecting, as shown here:![Figure 5.22 – The endpoint page of the
    deployed model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_022.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.22 – The endpoint page of the deployed model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you want to perform a mini-batch inference, meaning that you want to send
    multiple records at once, you can switch to **CSV** from the top-right corner.
    In that mode, you can copy the contents of a CSV file into the text box that will
    appear and hit the **Test** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In either mode, once you hit the **Test** button, the input data will be submitted
    to the REST API and results will be provided.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The third tab of the endpoint page is called `swagger.json`, which is automatically
    generated in the endpoint. This file describes the expected inputs and outputs
    of the REST APIs and is commonly used by web developers to provide documentation
    on the REST endpoints they produce.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the **Deployment logs** tab shows a detailed log of the deployment
    of the model. You can troubleshoot potential deployment issues using this tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Congratulations – you have successfully deployed your very own real-time endpoint
    that makes inferences on whether a customer will churn or not! In the next section,
    you will learn about the artifacts that are created when your model is deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the deployment of the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you deployed a model as a REST endpoint. In this section,
    you will understand what happened behind the scenes and discover the artifacts
    that were generated in the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'You started from the list of models that the AutoML process has trained. In
    that list, you selected a model and clicked on the **Deploy** command. By doing
    that, you registered the selected model in the Azure ML workspace and once that
    was done, the process continued with deploying the endpoint, as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23 – From AutoML model list to endpoint deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_05_023.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.23 – From AutoML model list to endpoint deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'Model registration creates a versioned record within the Azure ML workspace
    that allows you to keep track of what datasets were used to train the specific
    model and where the specific model was deployed. You will learn more about model
    registration in [*Chapter 12*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171),
    *Operationalizing Models with Code*. Let''s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: To see this model registration, in Azure ML Studio, navigate to **Assets** |
    **Models**. You will end up on the **Model List** page, as shown here:![Figure
    5.24 – The Model List page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_024.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.24 – The Model List page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The **Model List** page lists all registered models within the Azure ML workspace.
    These are the models that are being tracked by the workspace. Each model has a
    unique name. You can have multiple versions of the same model, something that
    automatically happens when you try to register a model with the same name. The
    model list allows you to select a model and perform various actions on it, such
    as deleting and deploying it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can only delete a registered model if it is not being used by any endpoint.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By clicking on the **Name** property of a model, you will end up on the details
    page of the selected registered model, as shown here:![Figure 5.25 – Registered
    model details page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_025.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.25 – Registered model details page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, you can get the general details regarding the model, such as which run
    trained the specific model, what framework was used, and the experiment name where
    this run is registered. Note that since this model was trained using AutoML, the
    framework is the generic AutoML one. In [*Chapter 12*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171),
    *Operationalizing Models with Code*, you will be able to register your own models
    and specify the framework you used to train the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the **Artifacts** tab, you will find the **model.pkl** file, which contains
    the trained model. In the **Explanations** and **Fairness** tabs, you can view
    the interpretability results, if they have been generated for the specific model.
    You will learn more about model interpretability in [*Chapter 10*](B16777_10_Final_VK_ePub.xhtml#_idTextAnchor147),
    *Understanding Model Results*. In the **Datasets** tab, you can see a reference
    to the specific version of the dataset that you used while configuring the AutoML
    experiment. This allows you to have lineage between the dataset that was used
    for training and the models you have deployed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the model has been registered, the deployment wizard creates an endpoint.
    Back in Azure ML Studio, click on the **Assets** | **Endpoint** menu item. This
    will bring you to the **Endpoints** page shown here:![Figure 5.26 – The Endpoints
    page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_026.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.26 – The Endpoints page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This list shows all real-time endpoints you have deployed from this Azure ML
    workspace. You will notice the **myfirstmlwebservice** endpoint, which you deployed
    in the previous section. By clicking on its name, you will end up on the endpoint's
    page, which you saw in *Figure 5.21*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Behind the scenes, this endpoint is a container instance that was deployed in
    the `packt-azureml-rg`, right next to your Azure ML workspace resource. Navigate
    to the Azure portal and open the `packt-azureml-rg`. You should have resources
    similar to the ones shown here:![Figure 5.27 – The resources in the packt-azureml-rg
    resource group of the Azure portal
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_05_027.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.27 – The resources in the packt-azureml-rg resource group of the Azure
    portal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, you will see that a **Container instance** has been deployed named **myfirstmllwebservice-<random
    id>**, which is the name of the endpoint you saw in *Figure 5.26*. This is the
    engine that is hosting the REST API you deployed in the previous section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Never delete Azure ML workspace artifacts directly from the resource group.
    This will leave orphan registrations in your workspace, such as an endpoint that
    points to a deleted container instance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this section, you saw what happens behind the scenes when you deploy a model
    from AutoML. In the next section, you are going to delete the endpoint you deployed
    to avoid spending money on a real-time endpoint you don't need.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up the model deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will clean up the deployed model. You should remove the
    deployments of the models that you are not planning to use. Otherwise, you will
    be paying for unused provisioned resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to Azure ML Studio. Click on the `myfirstmlwebservice` endpoint and
    click on the **Delete** command. Confirm your desire to delete the endpoint by
    clicking **Delete** in the pop-up window shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28 – Delete real-time endpoint pop-up window'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_05_028.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.28 – Delete real-time endpoint pop-up window
  prefs: []
  type: TYPE_NORMAL
- en: After the confirmation, the endpoint and the container instance you saw back
    in the Azure portal will get deleted. If you like, you can verify this by visiting
    the `packt-azureml-rg` **resource group**.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to configure an AutoML process to discover
    the best model that can predict whether a customer will churn or not. First, you
    used the AutoML wizard of the Azure Machine Learning Studio web experience to
    configure the experiment. Then, you monitored the execution of the run in the
    **Experiments** section of the studio interface. Once the training was completed,
    you reviewed the trained models and saw the information that had been stored regarding
    the best model. Then, you deployed that machine learning model in an Azure Container
    Instance and tested that the real-time endpoint performs the requested inferences.
    In the end, you deleted the deployment to avoid incurring costs in your Azure
    subscription.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will continue exploring the no-code/low code aspects
    of the Azure Machine Learning Studio experience by looking at the designer, which
    allows you to graphically design a training pipeline and operationalize the produced
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Question
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You need to train a classification model but only consider linear models during
    the AutoML process. Which of the following allows you to do that in the Azure
    Machine Learning Studio experience?
  prefs: []
  type: TYPE_NORMAL
- en: a) Add all algorithms other than linear ones to the blocked algorithms list.
  prefs: []
  type: TYPE_NORMAL
- en: b) Set the Exit criterion option to a metric score threshold.
  prefs: []
  type: TYPE_NORMAL
- en: c) Disable the automatic featurization option.
  prefs: []
  type: TYPE_NORMAL
- en: d) Disable the deep learning option on the classification task.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section offers additional content as useful web resources:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Basic concepts regarding AutoML:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://docs.microsoft.com/azure/machine-learning/concept-automated-ml](https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deep dive into how to use AutoML: [https://docs.microsoft.com/azure/machine-learning/how-to-use-automated-ml-for-ml-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-automated-ml-for-ml-models).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cross-validation in sklearn: [https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Understanding the service state of an endpoint: [https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#understanding-service-state](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#understanding-service-state).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generating client SDKs from `swagger.json` files: [https://swagger.io/tools/swagger-codegen/](https://swagger.io/tools/swagger-codegen/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
