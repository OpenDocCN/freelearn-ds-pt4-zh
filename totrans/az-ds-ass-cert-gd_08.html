<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer172">
			<h1 id="_idParaDest-84"><em class="italic"><a id="_idTextAnchor084"/>Chapter 6</em>: Visual Model Training and Publishing</h1>
			<p><strong class="bold">Azure Machine Learning</strong> (<strong class="bold">AzureML</strong>) Studio offers a designer experience when developing a model by allowing you to drag, drop, and configure training and inference pipelines. In this chapter, you will get an overview of the designer. You will then create a training process. Once you have seen the overall flow that's used with the designer, we will close this chapter by creating an inference pipeline and publishing the trained model artifact as a service endpoint.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Overview of the designer</li>
				<li>Designing a training process</li>
				<li>Creating a batch and real-time inference pipeline</li>
				<li>Deploying a real-time inference pipeline</li>
			</ul>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor085"/>Technical requirements</h1>
			<p>You will need to have access to an Azure subscription. Within that subscription, you will need a <strong class="bold">resource group</strong> named <strong class="source-inline">packt-azureml-rg</strong>. In addition, you will need to have either a <strong class="source-inline">Contributor</strong> or <strong class="source-inline">Owner</strong> <strong class="bold">access control</strong> (<strong class="bold">IAM</strong>) role at the resource group level. Within that resource group, you should have deployed a <strong class="bold">machine learning</strong> resource named <strong class="source-inline">packt-learning-mlw</strong>, as described in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>.</p>
			<p>You will also need to have registered <strong class="source-inline">churn-dataset</strong> within your workspace, which you created in <a href="B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072"><em class="italic">Chapter 5</em></a>, <em class="italic">Letting the Machines Do the Model Training</em>.</p>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor086"/>Overview of the designer</h1>
			<p>AzureML <a id="_idIndexMarker410"/>Studio <a id="_idIndexMarker411"/>offers a graphical designer that allows you to author pipelines visually. As per the definition, a pipeline is an independently <a id="_idIndexMarker412"/>executable flow of subtasks that describes a machine learning task. There<a id="_idIndexMarker413"/> are three types of pipelines that you can create within the designer:</p>
			<ul>
				<li><strong class="bold">Training pipelines</strong>: These<a id="_idIndexMarker414"/> pipelines are used for training models.</li>
				<li><strong class="bold">Batch inference pipelines</strong>: These <a id="_idIndexMarker415"/>pipelines are used to operationalize pre-trained models for batch prediction.</li>
				<li><strong class="bold">Real-time inference pipelines</strong>: These pipelines are used to expose a REST API that allows <a id="_idIndexMarker416"/>third-party applications to make real-time predictions using pre-trained models.</li>
			</ul>
			<p>To create a batch and a real-time pipeline, you need to author a training pipeline. In the following sections, you will learn how to create a training pipeline and then produce a batch and real-time pipeline on top of it. In <a href="B16777_11_Final_VK_ePub.xhtml#_idTextAnchor160"><em class="italic">Chapter 11</em></a>, <em class="italic">Working with Pipelines</em>, you will learn how to author similar pipelines through code. </p>
			<p>To start authoring pipelines, you will need to visit the <strong class="bold">Designer</strong> home page. Click on the <strong class="bold">Designer</strong> menu item to navigate to the home page, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer147" class="IMG---Figure">
					<img src="Images/B16777_06_001.jpg" alt="Figure 6.1 – Designer home page&#13;&#10;" width="449" height="481"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1 – Designer home page</p>
			<p>Next to the <strong class="bold">New pipeline +</strong> button, you will see several other buttons with different ready-to-use sample pipelines. Please<a id="_idIndexMarker417"/> familiarize yourself with these samples later. These samples regularly update to show the latest features of the designer, and it's a great resource to get started.</p>
			<p>In this chapter, we will create a new pipeline, starting from scratch. Clicking on the <strong class="bold">+</strong> button will lead you to the authoring screen/view, which we will explore in the next section.</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor087"/>The authoring screen/view</h2>
			<p>The <a id="_idIndexMarker418"/>main page for building a pipeline with the designer looks <a id="_idIndexMarker419"/>as follows:</p>
			<div>
				<div id="_idContainer148" class="IMG---Figure">
					<img src="Images/B16777_06_002.jpg" alt="Figure 6.2 – AzureML designer authoring view&#13;&#10;" width="1650" height="1086"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – AzureML designer authoring view</p>
			<p>We will describe the <a id="_idIndexMarker420"/>main page user interface here, and the preceding <a id="_idIndexMarker421"/>screenshot serves as a reference:</p>
			<ul>
				<li>By clicking on the hamburger icon (<img src="Images/1.png" alt="" width="46" height="33"/>) in the top-left corner, you can hide and unhide the AzureML main menu shown in the preceding screenshot as number <strong class="bold">1</strong>. From now on, we will assume this area is hidden.</li>
				<li>In the area labeled number <strong class="bold">2</strong>, you can find all the assets you can drop onto the canvas, referred to as number <strong class="bold">3</strong> in the preceding screenshot. By dropping different assets onto the canvas, you can build a pipeline. You will learn more about this area in the <em class="italic">Understanding the asset library</em> section of this chapter.</li>
				<li>On the right-hand area marked as <strong class="bold">4</strong>, you will find the settings. This area is also referred to as the details page. This view changes depending on what you have selected in the canvas. If you have not chosen any asset in the canvas area, you will see settings for the pipeline you are building, and you can choose a <strong class="bold">default compute target</strong> that will run each pipeline step. If you select an asset, you will find various configuration options for the specific asset.</li>
				<li>Area <strong class="bold">5</strong> provides a toolbar. You can switch <strong class="bold">Autosave</strong> on/off there. You can also change the autogenerated name of the pipeline you are designing. Rename the current pipeline to <strong class="source-inline">test-pipeline</strong>.</li>
				<li>In area <strong class="bold">5</strong>, you <a id="_idIndexMarker422"/>will also find the <strong class="bold">Settings</strong> button (<img src="Images/2.png" alt="" width="33" height="36"/>). With that button, you can hide/unhide the <strong class="bold">Settings</strong> area marked as <strong class="bold">4</strong> in the preceding screenshot. In the same area, you can find additional icons that allow you to save or delete the pipeline and <strong class="bold">undo, redo, and s</strong><strong class="bold">earch</strong> on the canvas. The <strong class="bold">Selection</strong> tool (<img src="Images/3.png" alt="" width="47" height="46"/>) is the standard cursor on the canvas. Later, when we work on our pipeline, we will switch to the <strong class="bold">Hand</strong> tool (<img src="Images/4.png" alt="" width="46" height="48"/>) to move selected parts on the canvas. Click on <strong class="bold">Settings</strong> to hide area <strong class="bold">4</strong> and increase the estate of the canvas.</li>
				<li>The last <a id="_idIndexMarker423"/>area, which is marked as <strong class="bold">6</strong> in the previous screenshot, provides you with the functionalities to <strong class="bold">submit, publish, and c</strong><strong class="bold">lone</strong> the pipeline, which we will discuss in the <em class="italic">Creating a batch and real-time inference pipeline</em> section.</li>
			</ul>
			<p>Before moving on to the next section, you will need to configure the <strong class="bold">default compute target</strong> property used by the pipeline to execute all the steps. Open the pipeline settings and select the compute cluster you used in <a href="B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072"><em class="italic">Chapter 5</em></a>, <em class="italic">Letting the Machines Do the Model Training</em>.</p>
			<p>In the next section, you will explore the area marked as <strong class="bold">2</strong>, also known as the <em class="italic">asset library</em>. </p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor088"/>Understanding the asset library</h2>
			<p>To build a <a id="_idIndexMarker424"/>pipeline, you will need to stitch together <a id="_idIndexMarker425"/>various assets. In this section, you will look at the different assets available within the asset library of the designer. In <em class="italic">Figure 6.2</em>, we had 96 of them available. This number depends on how many datasets you have registered in the AzureML workspace, and in a future release of AzureML, you may even be able to create your own coding assets. The following diagram shows the categories that are available in the asset library and a brief explanation of what type of assets (also referred to as modules) they contain:</p>
			<div>
				<div id="_idContainer153" class="IMG---Figure">
					<img src="Images/B16777_06_003.jpg" alt="Figure 6.3 – Categories in the AzureML designer asset library&#13;&#10;" width="1646" height="1073"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.3 – Categories in the AzureML designer asset library</p>
			<p>There are<a id="_idIndexMarker426"/> three<a id="_idIndexMarker427"/> types of assets in this library:</p>
			<ul>
				<li>Datasets and modules for manual input</li>
				<li>Untrained models</li>
				<li>Modules that perform certain operations on the data</li>
			</ul>
			<p>You will be dragging and dropping components from this asset library while building your first end-to-end machine learning training pipeline in the designer. In the next section, you will see what each asset looks like and how you can connect various assets between them.</p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor089"/>Exploring the asset's inputs and outputs</h2>
			<p>Each asset <a id="_idIndexMarker428"/>we drop from the asset library is a module of the pipeline we are building. A module looks similar to this sample<a id="_idIndexMarker429"/> module shown in the following screenshot:</p>
			<div>
				<div id="_idContainer154" class="IMG---Figure">
					<img src="Images/B16777_06_004.jpg" alt="Figure 6.4 – A sample module with two inputs and one output&#13;&#10;" width="438" height="179"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.4 – A sample module with two inputs and one output</p>
			<p>Let's describe this module from top to bottom:</p>
			<ul>
				<li>Zero, one, or more input ports at the top: The sample module in the preceding screenshot accepts two inputs. You can connect the output of another module to the input of the next one.</li>
				<li>In the middle of the module, the name describes the functionality of the module. Our example is a <strong class="bold">Train Model</strong> module, which trains an untrained model passed in the left input port with the data given in the right input port.</li>
				<li>If you select the module in the canvas, the module's detail page will appear in the area marked as <strong class="bold">4</strong> in <em class="italic">Figure 6.2</em>. This page is different for each module. You can configure various options, such as its short description or the compute target that will execute the specific module.</li>
				<li>Under the module name, you can read the description text of that module. You can edit this description by selecting the module and editing the text on the module's detail page. The module description in our example shows the text <strong class="bold">Sample Module</strong>.</li>
				<li>At the bottom of the module, there are one or more <strong class="bold">output ports</strong> that you can drag and connect to the next module.</li>
			</ul>
			<p>In this section, you <a id="_idIndexMarker430"/>explored the various aspects of AzureML Studio's designer. In the next section, you will start<a id="_idIndexMarker431"/> authoring your first training pipeline.</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor090"/>Building the pipeline with the designer</h1>
			<p>In this section, we <a id="_idIndexMarker432"/>will create a training pipeline to train <a id="_idIndexMarker433"/>a machine learning model against the <strong class="bold">churn</strong> dataset you used in the previous chapter. </p>
			<p>When you start designing a training pipeline, we recommend leveraging the <em class="italic">7 Steps of Machine Learning</em> approach shown in the following diagram, which contains all the steps needed to create a machine learning model:</p>
			<div>
				<div id="_idContainer155" class="IMG---Figure">
					<img src="Images/B16777_06_005.jpg" alt="Figure 6.5 – 7 Steps of Machine Learning&#13;&#10;" width="1035" height="579"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5 – 7 Steps of Machine Learning</p>
			<p>This 7-step journey is a valuable checklist for real-life end-to-end scenarios to ensure you are not missing anything. In this journey, you will need various components, transformations, and models, which you can find in the asset library. To keep things simple, we will skip a couple of steps in the pipeline that you are going to design. In this section, you will start with a dataset that you will prepare to train a model. You will then evaluate the model and store it. In the next section, you will use that model to create a batch and a <a id="_idIndexMarker434"/>real-time pipeline that utilize the model to <a id="_idIndexMarker435"/>make predictions.</p>
			<p>Let's start by acquiring the data that will be used to train the model, something you will do in the next section.</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor091"/>Acquiring the data</h2>
			<p>The first step<a id="_idIndexMarker436"/> is selecting the dataset that you will use to train the model:</p>
			<ol>
				<li>In the asset library, expand the <strong class="bold">Datasets</strong> category by clicking on the arrow next to its name. You should see <strong class="bold">churn-dataset</strong> there, which you created in <a href="B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072"><em class="italic">Chapter 5</em></a>, <em class="italic">Letting the Machines Do the Model Training</em>:<div id="_idContainer156" class="IMG---Figure"><img src="Images/B16777_06_006.jpg" alt="Figure 6.6 – churn-dataset under the Datasets category&#13;&#10;" width="443" height="144"/></div><p class="figure-caption">Figure 6.6 – churn-dataset under the Datasets category</p></li>
				<li>Drag <strong class="bold">churn-dataset</strong> onto the canvas:<div id="_idContainer157" class="IMG---Figure"><img src="Images/B16777_06_007.jpg" alt="Figure 6.7 – Canvas with churn-dataset&#13;&#10;" width="1296" height="1241"/></div><p class="figure-caption">Figure 6.7 – Canvas with churn-dataset</p><p>With that, you have just completed the <strong class="bold">Data collection</strong> step, which means you can move on to step number 2 of the <em class="italic">7 Steps of Machine Learning</em>.</p></li>
				<li>The <a id="_idIndexMarker437"/>next step is <strong class="bold">Data preparation</strong>. Add a processing step to the pipeline by dragging the <strong class="bold">Select Columns in Dataset</strong> module, which can be found under the <strong class="bold">Data Transformation</strong> category in the asset library, onto the canvas.</li>
				<li>You will now need to create a flow between the dataset and the module. You can do that by pulling from the dataset's <strong class="bold">output port</strong>, the small circle at the bottom of this <strong class="bold">dataset</strong>, to the dataset's <strong class="bold">input port</strong>, the small circle at the top of the <strong class="bold">Select Columns in Dataset</strong> module, as shown in the following screenshot:<div id="_idContainer158" class="IMG---Figure"><img src="Images/B16777_06_008.jpg" alt="Figure 6.8 – Creating a flow between the dataset and the processing module&#13;&#10;" width="1311" height="660"/></div><p class="figure-caption">Figure 6.8 – Creating a flow between the dataset and the processing module</p></li>
				<li>The <a id="_idIndexMarker438"/>next step is to configure the <strong class="bold">Select Columns in Dataset</strong> module. With the module selected in the canvas, click on the <strong class="bold">Edit column</strong> link on the details pane, which is on the right of the canvas, as shown in the preceding screenshot. The <strong class="bold">Select columns</strong> dialog will appear. See the following screenshot for the final configuration of this popup.</li>
				<li>In that popup, select <strong class="bold">All columns</strong> from the dropdown.</li>
				<li>Add a second line by clicking on the <strong class="bold">+</strong> button.</li>
				<li>Select <strong class="bold">Exclude</strong> from the dropdown.</li>
				<li>Choose <strong class="bold">Column names</strong> from the second dropdown.</li>
				<li>Select the <strong class="bold">id</strong> column from the last dropdown.<p>The dialog page should look as follows:</p><div id="_idContainer159" class="IMG---Figure"><img src="Images/B16777_06_009.jpg" alt="Figure 6.9 – Select columns dialog&#13;&#10;" width="1140" height="475"/></div><p class="figure-caption"> </p><p class="figure-caption">Figure 6.9 – Select columns dialog</p></li>
				<li>Click on <strong class="bold">Save</strong> to close the popup.</li>
			</ol>
			<p>So far, you<a id="_idIndexMarker439"/> have selected the dataset that you will use to train the model, and you have prepared the data by removing the <strong class="bold">id</strong> column, which you will not need for the training process. In the next section, you will finalize your training pipeline by adding the untrained model, the module that will train the model, and the module for scoring and evaluating the trained model.</p>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor092"/>Preparing the data and training the model</h2>
			<p>Now, you will <a id="_idIndexMarker440"/>choose the model that you will train. In <a href="B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072"><em class="italic">Chapter 5</em></a>, <em class="italic">Letting the Machines Do the Model Training</em>, you identified a <strong class="bold">voting ensemble</strong> as the best performing model for the given data. This type of model is a <a id="_idIndexMarker441"/>combination of different models, including <strong class="bold">Random Forest</strong>. To keep this example simple, you will use a <strong class="bold">Two-Class Decision Forest</strong> model, similar to <strong class="bold">Random Forest</strong>. Let's get started:</p>
			<ol>
				<li value="1">Navigate to the <strong class="bold">Machine Learning Algorithms</strong> category in the asset library. You will notice a couple of subcategories, including <strong class="bold">Classification</strong>. From that subcategory, drag and drop the <strong class="bold">Two-Class Decision Forest</strong> module onto the canvas.</li>
				<li>For the <a id="_idIndexMarker442"/>model training, you will need two additional modules: the <strong class="bold">Split Data</strong> module, which you can find in the asset library under the <strong class="bold">Data Transformation</strong> category, and the <strong class="bold">Train Model</strong> module, which<a id="_idIndexMarker443"/> can be found in the <strong class="bold">Model Training</strong> category. Drag and drop both modules onto the canvas.</li>
				<li>You will need to extend the data flow you created in the previous section to pass the data through the new modules. Pull an <strong class="bold">output port</strong> from the <strong class="bold">Select Columns in Dataset</strong> module to an <strong class="bold">input port</strong> of the <strong class="bold">Split Data</strong> module.</li>
				<li>You will need to configure the <strong class="bold">Split Data</strong> module on the module's details pane, as shown in the following screenshot. Set <strong class="bold">Fraction of rows in the first output dataset</strong> to <strong class="bold">0.7</strong>. By doing that, 70% of the data will be sent on the <strong class="bold">left output port</strong> area, which is used to train the model, and 30% will be sent to the <strong class="bold">right output port</strong> area, which is used for testing.</li>
				<li>The <strong class="bold">Train Model</strong> module accepts two inputs. On the <strong class="bold">left input port</strong> area, you need to pass an untrained model that will be trained with the data given on the <strong class="bold">right input port</strong> area. Pull an <strong class="bold">output port</strong> from the <strong class="bold">Two-Class Decision Forest</strong> module to the <strong class="bold">left input port</strong> area of the <strong class="bold">Train Model</strong> module. </li>
				<li>Drag the <strong class="bold">left output port</strong> area of the <strong class="bold">Split Data</strong> module to the <strong class="bold">right input port</strong> area of <strong class="bold">Train Model</strong>. Your canvas should look as follows:<div id="_idContainer160" class="IMG---Figure"><img src="Images/B16777_06_010.jpg" alt="Figure 6.10 – The Train Model module is missing some configuration&#13;&#10;" width="1440" height="1125"/></div><p class="figure-caption">Figure 6.10 – The Train Model module is missing some configuration</p></li>
				<li>In the <a id="_idIndexMarker444"/>preceding screenshot, there is an orange exclamation mark in the <strong class="bold">Train Model</strong> module. This mark indicates that something is misconfigured in that module. So far, you have configured <a id="_idIndexMarker445"/>which model to train and what data to use for the model's training. However, you have not defined which column the model should predict yet. This column is referred to as <strong class="bold">Label column</strong>. To configure <strong class="bold">Label column</strong>, select the module in the canvas and click on the <strong class="bold">Edit column</strong> link. This will open the <strong class="bold">Label column</strong> dialog shown in the following screenshot. Select the <strong class="bold">churned</strong> column from the drop-down list and click <strong class="bold">Save</strong>:<div id="_idContainer161" class="IMG---Figure"><img src="Images/B16777_06_011.jpg" alt="Figure 6.11 – Selecting the column that the model will predict&#13;&#10;" width="746" height="182"/></div><p class="figure-caption">Figure 6.11 – Selecting the column that the model will predict</p><p>So far, the training pipeline is performing the first four steps of the <em class="italic">7 Steps of Machine Learning</em>. The next step is to evaluate the model.</p></li>
				<li>Drag and <a id="_idIndexMarker446"/>drop the <strong class="bold">Score Model</strong> module <a id="_idIndexMarker447"/>onto the canvas, which can be found in the asset library under the <strong class="bold">Model Scoring &amp; Evaluation</strong> category. This module accepts a trained model in the <strong class="bold">left input port</strong> area and a dataset on the <strong class="bold">right input port</strong> area. The output of this module is a dataset that contains the inferences made by the model against the incoming dataset.</li>
				<li>Connect the <strong class="bold">right output port</strong> area of the <strong class="bold">Split Data</strong> module to the <strong class="bold">right input port</strong> area of the <strong class="bold">Score Model</strong> module. This will create a data flow that will bring the 30% part of the original data into the <strong class="bold">Score Model</strong> module.</li>
				<li>Connect the <strong class="bold">output port</strong> area of the <strong class="bold">Train Model</strong> module to the <strong class="bold">left input port</strong> area of the <strong class="bold">Score Model</strong> module. The <strong class="bold">Score Model</strong> module will use the trained model to perform inferences against the incoming data.</li>
				<li>Drag <a id="_idIndexMarker448"/>and drop the <strong class="bold">Evaluate Model</strong> module onto the canvas, which can be found in the asset library <a id="_idIndexMarker449"/>under the <strong class="bold">Model Scoring &amp; Evaluation</strong> category. This module will compare the predictions that the model made against the values stored in the <strong class="bold">churned</strong> column.</li>
				<li>Connect the <strong class="bold">output port</strong> area of the <strong class="bold">Score Model</strong> module to the <strong class="bold">left input port</strong> area of the <strong class="bold">Evaluate Model</strong> module.<p>If you have followed all the steps so far, your canvas should look as follows:</p><div id="_idContainer162" class="IMG---Figure"><img src="Images/B16777_06_012.jpg" alt="Figure 6.12 – The completed training pipeline&#13;&#10;" width="1535" height="1272"/></div></li>
			</ol>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 6.12 – The completed training pipeline</p>
			<p>So far, you have authored a training pipeline that performs the following actions:</p>
			<ul>
				<li>Removes the <strong class="bold">id</strong> column from the dataset.</li>
				<li>Splits the <a id="_idIndexMarker450"/>data into a training dataset and a validation one. The training dataset contains 70% of the original data. The validation dataset contains the remaining 30%.</li>
				<li>Trains <strong class="bold">Two-Class Decision Forest</strong> using the training dataset.</li>
				<li>Scores the<a id="_idIndexMarker451"/> validation dataset using the trained model.</li>
				<li>Evaluates the performance of the model by examining the results in the scored dataset. You will be able to review the metrics of the trained model in the <strong class="bold">Evaluate Model</strong> module.</li>
			</ul>
			<p>In the next section, you are going to execute this pipeline to train the model.</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor093"/>Executing the training pipeline</h2>
			<p>In the<a id="_idIndexMarker452"/> previous section, you created a complete training pipeline that you will now execute by creating a new pipeline run. Let's get started:</p>
			<ol>
				<li value="1">Click on the <strong class="bold">Submit</strong> button in the top-right corner. The <strong class="bold">Set up pipeline run</strong> dialog will open, as shown in the following screenshot. </li>
				<li>You will need to create a new experiment and name it <strong class="bold">test-pipeline</strong>. Select the <strong class="bold">Create new</strong> radio button and then type in this name.</li>
				<li>Notice that the pipeline will execute in the default <strong class="bold">compute target</strong> you selected in the<em class="italic"> The authoring screen/view</em> section. Click on the <strong class="bold">Submit</strong> button to start executing the training pipeline:</li>
			</ol>
			<div>
				<div id="_idContainer163" class="IMG---Figure">
					<img src="Images/B16777_06_013.jpg" alt="Figure 6.13 – Preparing to execute the training pipeline&#13;&#10;" width="682" height="664"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.13 – Preparing to execute the training pipeline</p>
			<p>Once the <a id="_idIndexMarker453"/>pipeline finishes executing, the designer will look similar to the following:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer164" class="IMG---Figure">
					<img src="Images/B16777_06_014.jpg" alt="Figure 6.14 – Successfully running the pipeline&#13;&#10;" width="1650" height="965"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.14 – Successfully running the pipeline</p>
			<p>With that, you <a id="_idIndexMarker454"/>have successfully finished developing and training your first pipeline. When the execution of the pipeline is completed, the <strong class="bold">Create inference pipeline</strong> button will appear. The following section describes the different options you have when it comes to creating an inference pipeline. </p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor094"/>Creating a batch and real-time inference pipeline</h1>
			<p>This<a id="_idIndexMarker455"/> section will discuss the two options of deploying an inference pipeline from the designer: <strong class="bold">batch</strong> and <strong class="bold">real time</strong>:</p>
			<ul>
				<li>With batch predictions, you asynchronously score large datasets.</li>
				<li>With real-time prediction, you score a small dataset or a single row in real time.</li>
			</ul>
			<p>When you create an <a id="_idIndexMarker456"/>inference pipeline, either batch or real time, AzureML takes care of the following things:</p>
			<ul>
				<li>AzureML stores the trained model and all the trained data processing modules as an asset in the asset library under the <strong class="bold">Datasets</strong> category.</li>
				<li>It removes unnecessary modules such as <strong class="bold">Train Model</strong> and <strong class="bold">Split Data</strong> automatically.</li>
				<li>It adds the trained model to the pipeline.</li>
			</ul>
			<p>Especially<a id="_idIndexMarker457"/> for real-time inference pipelines, AzureML will add a <strong class="bold">web service input</strong> and a <strong class="bold">web service output</strong> in the final pipeline.</p>
			<p>Let's start by creating a batch pipeline, something you will do in the next section.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor095"/>Creating a batch pipeline</h2>
			<p>In this <a id="_idIndexMarker458"/>section, you will create a batch inference pipeline. Let's get started:</p>
			<ol>
				<li value="1">Click on the <strong class="bold">Create inference pipeline</strong> dropdown next to the <strong class="bold">Submit</strong> button and select <strong class="bold">Batch inference pipeline</strong>. This action will create the <strong class="bold">Batch inference pipeline</strong> tab, as shown in the following screenshot:<div id="_idContainer165" class="IMG---Figure"><img src="Images/B16777_06_015.jpg" alt="Figure 6.15 – The Batch inference pipeline tab showing the default generated pipeline&#13;&#10;" width="1582" height="1087"/></div><p class="figure-caption">Figure 6.15 – The Batch inference pipeline tab showing the default generated pipeline</p></li>
				<li>By adding a pipeline parameter, you will be able to change the behavior of the pipeline at runtime. In our case, we want to parameterize which dataset to use to make predictions. To parameterize the input dataset, click on <strong class="bold">churn-dataset</strong> and select the <strong class="bold">Set as pipeline parameter</strong> checkbox in the details pane on the right.</li>
				<li>Change the <a id="_idIndexMarker459"/>default parameter name in the <strong class="bold">Parameter name</strong> text box to <strong class="bold">batchfile</strong>.</li>
				<li>Click on the <strong class="bold">Publish</strong> button to bring up the <strong class="bold">Set up published pipeline</strong> dialog shown in the following screenshot.</li>
				<li>Select the <strong class="bold">Create new</strong> radio button to define a new pipeline endpoint. This endpoint is used to trigger the pipeline that you are about to publish.</li>
				<li>Keep the default value of the <strong class="bold">New PipelineEndpoint name</strong> field as is. It should read <strong class="bold">test-pipeline-batch inference</strong>.</li>
				<li>You can add a description to your published endpoint by filling in the <strong class="bold">PipelineEndpoint description (optional)</strong> field. Write <strong class="bold">Test of a batch pipeline parameter name batchfile</strong> in that field.</li>
				<li>Keep all the other settings as is. The completed dialog page should look as follows:<div id="_idContainer166" class="IMG---Figure"><img src="Images/B16777_06_016.jpg" alt="Figure 6.16 – Published pipeline dialog page&#13;&#10;" width="444" height="503"/></div><p class="figure-caption">Figure 6.16 – Published pipeline dialog page</p></li>
				<li>Click on the <strong class="bold">Publish</strong> button.<p>Once the <a id="_idIndexMarker460"/>pipeline's endpoint has been successfully published, the message shown in the following screenshot will appear in the designer. The <strong class="bold">test-pipeline-batch inference</strong> link will direct you to the published pipeline:</p></li>
			</ol>
			<div>
				<div id="_idContainer167" class="IMG---Figure">
					<img src="Images/B16777_06_017.jpg" alt="" width="653" height="47"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.17 – Publish succeeded</p>
			<p>Now that you have published a batch inference pipeline, you can trigger it through the AzureML Studio interface. In <a href="B16777_11_Final_VK_ePub.xhtml#_idTextAnchor160"><em class="italic">Chapter 11</em></a>, <em class="italic">Working with Pipelines</em>, in the <em class="italic">Publishing a pipeline to expose it as an endpoint</em> section, you will learn more about these pipelines and how<a id="_idIndexMarker461"/> you can integrate them with third-party applications.</p>
			<p>In the next section, we will create a real-time pipeline based on the training pipeline.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor096"/>Creating a real-time pipeline</h2>
			<p>In this section, you <a id="_idIndexMarker462"/>will create a real-time inference pipeline. Let's get started:</p>
			<ol>
				<li value="1">Select the <strong class="bold">Training pipeline</strong> tab in the designer, which is visible on the top-left corner in <em class="italic">Figure 6.15</em>.</li>
				<li>Click on the <strong class="bold">Create inference pipeline</strong> dropdown next to the <strong class="bold">Submit</strong> button and select <strong class="bold">Real-time inference pipeline</strong>. This will generate the default <strong class="bold">r</strong><strong class="bold">eal-time inference pipeline</strong> shown in the following screenshot:<div id="_idContainer168" class="IMG---Figure"><img src="Images/B16777_06_018.jpg" alt="Figure 6.18 – The default real-time inference pipeline&#13;&#10;" width="1295" height="922"/></div><p class="figure-caption">Figure 6.18 – The default real-time inference pipeline</p><p>Before we deploy this pipeline, we will need to make a couple of changes.</p></li>
				<li>Click on the <strong class="bold">Select Columns in Dataset</strong> module and click on the <strong class="bold">Edit column</strong> link in the details pane on the right-hand side.</li>
				<li>Add a <a id="_idIndexMarker463"/>new row to the <strong class="bold">Select columns</strong> dialog by clicking on the plus (<strong class="bold">+</strong>) icon.</li>
				<li>Select <strong class="bold">Exclude</strong> and <strong class="bold">Column names</strong> from the corresponding dropdowns and enter <strong class="bold">churned</strong> as the column's name to exclude. The dialog page should look as follows:<div id="_idContainer169" class="IMG---Figure"><img src="Images/B16777_06_019.jpg" alt="Figure 6.19 – Excluding both the id and churned columns from the incoming dataset&#13;&#10;" width="1119" height="542"/></div><p class="figure-caption">Figure 6.19 – Excluding both the id and churned columns from the incoming dataset</p></li>
				<li>From the <strong class="bold">Data Transformation</strong> category in the asset library, drag the <strong class="bold">Apply SQL Transformation</strong> module onto the canvas. Place it above the <strong class="bold">Webservice Output</strong> module.</li>
				<li>Connect the <strong class="bold">output port</strong> area of the <strong class="bold">Score Model</strong> module to the <strong class="bold">left input port</strong> area of the <strong class="bold">Apply SQL Transformation</strong> module.</li>
				<li>Delete the connection between the <strong class="bold">Score Model</strong> module and the <strong class="bold">Web Service Output</strong> model. To do that, select the connection between those two modules by clicking on it. When highlighted, select the trash icon or press the <em class="italic">Delete</em> button on your keyboard. The connector should be removed.</li>
				<li>Delete <a id="_idIndexMarker464"/>the <strong class="bold">Evaluate Model</strong> module from the canvas.</li>
				<li>Connect the <strong class="bold">output port</strong> area of the <strong class="bold">Apply SQL Transformation</strong> module to the <strong class="bold">input port</strong> area of the <strong class="bold">Web Service Output</strong> module.</li>
				<li>Select the <strong class="bold">Apply SQL Transformation</strong> module.</li>
				<li>Click on the <strong class="bold">Edit code</strong> link in the <strong class="bold">Apply SQL Transformation</strong> detail pane and replace the default query with the following one:<p class="source-code">select [Scored Labels] from t1</p><p>This SQL transformation only selects the predicted value, which is stored in the <strong class="bold">Scored Labels</strong> column.</p></li>
				<li>Press the <strong class="bold">Save</strong> button. The changed pipeline should look like the one shown in the following screenshot.</li>
				<li>To ensure that the pipeline you have designed executes properly, you will need to run it once using the <strong class="bold">Submit</strong> button. The <strong class="bold">Set up published pipeline</strong> dialog will appear.</li>
				<li>You will need to execute the pipeline within an experiment. Select the <strong class="bold">Create new</strong> radio button.</li>
				<li>Use <strong class="bold">test-pipeline-real-time-inference</strong> as <strong class="bold">New experiment name</strong>.</li>
				<li>Keep the default values as is for the rest of the fields and press <strong class="bold">Submit</strong>.<p>Your pipeline should execute, and the canvas should look as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="Images/B16777_06_020.jpg" alt="Figure 6.20 – Modified real-time inference pipeline&#13;&#10;" width="1454" height="1127"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.20 – Modified real-time inference pipeline</p>
			<p>After <a id="_idIndexMarker465"/>verifying that the pipeline can execute without any issues, you can deploy it as a real-time endpoint. You have two options regarding the<a id="_idIndexMarker466"/> infrastructure that will host your real-time endpoint. You can deploy either in an <strong class="bold">Azure Container Instance</strong> (<strong class="bold">ACI</strong>) or <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>) cluster. The <strong class="bold">ACI</strong> infrastructure is useful for testing purposes, while the <strong class="bold">AKS</strong> infrastructure<a id="_idIndexMarker467"/> supports better production environments. In our case, we will deploy to <strong class="bold">ACI</strong>, something you will read about in the next section.</p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor097"/>Deploying a real-time inference pipeline</h1>
			<p>In this <a id="_idIndexMarker468"/>section, you will deploy the sample real-time inference pipeline you created in the <strong class="bold">Real-time inference pipeline</strong> designer tab. Let's get started:</p>
			<ol>
				<li value="1">Click on the <strong class="bold">Deploy</strong> button. This will bring up the <strong class="bold">Set up real-time endpoint</strong> popup shown in the following screenshot.</li>
				<li>On the <strong class="bold">Set up real-time endpoint</strong> popup, select the <strong class="bold">Deploy new real-time endpoint</strong> radio button option.</li>
				<li>In the <strong class="bold">Name</strong> text field, enter <strong class="bold">first-real-time-endpoint</strong>.</li>
				<li>In the <strong class="bold">Description</strong> text field, enter <strong class="bold">Container Deployment of the first real-time pipeline</strong>.</li>
				<li>Click on the <strong class="bold">Compute type</strong> drop-down list and select <strong class="bold">Azure Container Instance</strong>.</li>
				<li>You won't<a id="_idIndexMarker469"/> need to modify the <strong class="bold">Advanced</strong> settings. The completed popup should look as follows:<div id="_idContainer171" class="IMG---Figure"><img src="Images/B16777_06_021.jpg" alt="Figure 6.21 – Set up real-time endpoint popup&#13;&#10;" width="919" height="649"/></div><p class="figure-caption">Figure 6.21 – Set up real-time endpoint popup</p></li>
				<li>Click on the <strong class="bold">Deploy</strong> button to provision your real-time endpoint. This will take a couple of minutes.</li>
			</ol>
			<p>After<a id="_idIndexMarker470"/> successfully deploying the pipeline, you will find the newly deployed pipeline under <strong class="bold">Assets</strong> | <strong class="bold">Endpoints</strong> of AzureML Studio. The endpoint you just deployed is the same as the one you deployed in <a href="B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072"><em class="italic">Chapter 5</em></a>, <em class="italic">Letting the Machines Do the Model Training</em>. You can test it through the web interface. You will deep dive into how to use similar endpoints in <a href="B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171"><em class="italic">Chapter 12</em></a>, <em class="italic">Operationalizing Models with Code</em>. Before moving on, you should delete the real-time endpoint to avoid being charged. Follow the instructions in the <em class="italic">Cleaning up the model deployment</em> section of <a href="B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072"><em class="italic">Chapter 5</em></a>, <em class="italic">Letting the Machines Do the Model Training</em>, to delete the endpoint you just deployed. </p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor098"/>Summary</h1>
			<p>This chapter introduced the pipeline designer, which allows us to create AzureML pipelines via drag and drop. You built your first training pipeline based on the churn dataset and the <strong class="bold">Two-Class Decision Forest</strong> model. We discussed three pipeline types, authored the training pipeline, created a batch pipeline, and developed and deployed a real-time pipeline.</p>
			<p>This chapter concludes the no-code, low-code features that AzureML provides. In the next chapter, you will start working on the AzureML Python SDK. The AzureML Python SDK allows you to train models and create machine learning pipelines through code, which is critical for the DP-100 exam.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor099"/>Question</h1>
			<p>What are the options for deploying real-time pipelines?</p>
			<ul>
				<li><strong class="bold">Azure Container Instances</strong> only</li>
				<li><strong class="bold">Azure Container Instances</strong> and <strong class="bold">Azure Kubernetes Services</strong></li>
				<li><strong class="bold">Azure Container Instances</strong> and <strong class="bold">Azure Virtual Machines</strong></li>
				<li><strong class="bold">Azure Virtual Machines</strong> only</li>
			</ul>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor100"/>Further reading</h1>
			<p>This section offers a list of helpful web resources to help you augment your AzureML designer knowledge:</p>
			<ul>
				<li>Configuring data splits and cross-validation in automated machine learning: <a href="https://docs.microsoft.com/azure/machine-learning/how-to-configure-cross-validation-data-splits%0D">https://docs.microsoft.com/azure/machine-learning/how-to-configure-cross-validation-data-splits</a></li>
				<li>Running batch predictions using the AzureML designer: <a href="https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-run-batch-predictions-designer.md%0D">https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-run-batch-predictions-designer.md</a></li>
				<li>Tutorial: Designer – deploying a machine learning model: <a href="https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy%0D">https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy</a></li>
				<li>What is the AzureML designer? <a href="https://docs.microsoft.com/azure/machine-learning/concept-designer%0D">https://docs.microsoft.com/azure/machine-learning/concept-designer</a></li>
				<li>Tutorial: Designer – training a no-code regression model: <a href="https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-train-score%20">https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-train-score</a></li>
				<li>Tutorial: Designer – deploying a machine learning model: <a href="https://ttps://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy">ttps://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy</a></li>
			</ul>
		</div>
	</div></body></html>