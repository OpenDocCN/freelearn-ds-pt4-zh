- en: '*Chapter 6*: Visual Model Training and Publishing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Azure Machine Learning** (**AzureML**) Studio offers a designer experience
    when developing a model by allowing you to drag, drop, and configure training
    and inference pipelines. In this chapter, you will get an overview of the designer.
    You will then create a training process. Once you have seen the overall flow that''s
    used with the designer, we will close this chapter by creating an inference pipeline
    and publishing the trained model artifact as a service endpoint.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of the designer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing a training process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a batch and real-time inference pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a real-time inference pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to have access to an Azure subscription. Within that subscription,
    you will need a `packt-azureml-rg`. In addition, you will need to have either
    a `Contributor` or `Owner` `packt-learning-mlw`, as described in [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026),
    *Deploying Azure Machine Learning Workspace Resources*.
  prefs: []
  type: TYPE_NORMAL
- en: You will also need to have registered `churn-dataset` within your workspace,
    which you created in [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072),
    *Letting the Machines Do the Model Training*.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of the designer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AzureML Studio offers a graphical designer that allows you to author pipelines
    visually. As per the definition, a pipeline is an independently executable flow
    of subtasks that describes a machine learning task. There are three types of pipelines
    that you can create within the designer:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training pipelines**: These pipelines are used for training models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Batch inference pipelines**: These pipelines are used to operationalize pre-trained
    models for batch prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Real-time inference pipelines**: These pipelines are used to expose a REST
    API that allows third-party applications to make real-time predictions using pre-trained
    models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To create a batch and a real-time pipeline, you need to author a training pipeline.
    In the following sections, you will learn how to create a training pipeline and
    then produce a batch and real-time pipeline on top of it. In [*Chapter 11*](B16777_11_Final_VK_ePub.xhtml#_idTextAnchor160),
    *Working with Pipelines*, you will learn how to author similar pipelines through
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start authoring pipelines, you will need to visit the **Designer** home
    page. Click on the **Designer** menu item to navigate to the home page, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Designer home page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Designer home page
  prefs: []
  type: TYPE_NORMAL
- en: Next to the **New pipeline +** button, you will see several other buttons with
    different ready-to-use sample pipelines. Please familiarize yourself with these
    samples later. These samples regularly update to show the latest features of the
    designer, and it's a great resource to get started.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will create a new pipeline, starting from scratch. Clicking
    on the **+** button will lead you to the authoring screen/view, which we will
    explore in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The authoring screen/view
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main page for building a pipeline with the designer looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – AzureML designer authoring view'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 – AzureML designer authoring view
  prefs: []
  type: TYPE_NORMAL
- en: 'We will describe the main page user interface here, and the preceding screenshot
    serves as a reference:'
  prefs: []
  type: TYPE_NORMAL
- en: By clicking on the hamburger icon (![](img/1.png)) in the top-left corner, you
    can hide and unhide the AzureML main menu shown in the preceding screenshot as
    number **1**. From now on, we will assume this area is hidden.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the area labeled number **2**, you can find all the assets you can drop onto
    the canvas, referred to as number **3** in the preceding screenshot. By dropping
    different assets onto the canvas, you can build a pipeline. You will learn more
    about this area in the *Understanding the asset library* section of this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the right-hand area marked as **4**, you will find the settings. This area
    is also referred to as the details page. This view changes depending on what you
    have selected in the canvas. If you have not chosen any asset in the canvas area,
    you will see settings for the pipeline you are building, and you can choose a
    **default compute target** that will run each pipeline step. If you select an
    asset, you will find various configuration options for the specific asset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Area `test-pipeline`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In area **5**, you will also find the **Settings** button (![](img/2.png)).
    With that button, you can hide/unhide the **Settings** area marked as **4** in
    the preceding screenshot. In the same area, you can find additional icons that
    allow you to save or delete the pipeline and **undo, redo, and s****earch** on
    the canvas. The **Selection** tool (![](img/3.png)) is the standard cursor on
    the canvas. Later, when we work on our pipeline, we will switch to the **Hand**
    tool (![](img/4.png)) to move selected parts on the canvas. Click on **Settings**
    to hide area **4** and increase the estate of the canvas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last area, which is marked as **6** in the previous screenshot, provides
    you with the functionalities to **submit, publish, and c****lone** the pipeline,
    which we will discuss in the *Creating a batch and real-time inference pipeline*
    section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before moving on to the next section, you will need to configure the **default
    compute target** property used by the pipeline to execute all the steps. Open
    the pipeline settings and select the compute cluster you used in [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072),
    *Letting the Machines Do the Model Training*.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will explore the area marked as **2**, also known as
    the *asset library*.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the asset library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To build a pipeline, you will need to stitch together various assets. In this
    section, you will look at the different assets available within the asset library
    of the designer. In *Figure 6.2*, we had 96 of them available. This number depends
    on how many datasets you have registered in the AzureML workspace, and in a future
    release of AzureML, you may even be able to create your own coding assets. The
    following diagram shows the categories that are available in the asset library
    and a brief explanation of what type of assets (also referred to as modules) they
    contain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Categories in the AzureML designer asset library'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.3 – Categories in the AzureML designer asset library
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three types of assets in this library:'
  prefs: []
  type: TYPE_NORMAL
- en: Datasets and modules for manual input
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Untrained models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modules that perform certain operations on the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will be dragging and dropping components from this asset library while building
    your first end-to-end machine learning training pipeline in the designer. In the
    next section, you will see what each asset looks like and how you can connect
    various assets between them.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the asset's inputs and outputs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each asset we drop from the asset library is a module of the pipeline we are
    building. A module looks similar to this sample module shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – A sample module with two inputs and one output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.4 – A sample module with two inputs and one output
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s describe this module from top to bottom:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Zero, one, or more input ports at the top: The sample module in the preceding
    screenshot accepts two inputs. You can connect the output of another module to
    the input of the next one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the middle of the module, the name describes the functionality of the module.
    Our example is a **Train Model** module, which trains an untrained model passed
    in the left input port with the data given in the right input port.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you select the module in the canvas, the module's detail page will appear
    in the area marked as **4** in *Figure 6.2*. This page is different for each module.
    You can configure various options, such as its short description or the compute
    target that will execute the specific module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under the module name, you can read the description text of that module. You
    can edit this description by selecting the module and editing the text on the
    module's detail page. The module description in our example shows the text **Sample
    Module**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the bottom of the module, there are one or more **output ports** that you
    can drag and connect to the next module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, you explored the various aspects of AzureML Studio's designer.
    In the next section, you will start authoring your first training pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Building the pipeline with the designer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will create a training pipeline to train a machine learning
    model against the **churn** dataset you used in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you start designing a training pipeline, we recommend leveraging the *7
    Steps of Machine Learning* approach shown in the following diagram, which contains
    all the steps needed to create a machine learning model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – 7 Steps of Machine Learning'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.5 – 7 Steps of Machine Learning
  prefs: []
  type: TYPE_NORMAL
- en: This 7-step journey is a valuable checklist for real-life end-to-end scenarios
    to ensure you are not missing anything. In this journey, you will need various
    components, transformations, and models, which you can find in the asset library.
    To keep things simple, we will skip a couple of steps in the pipeline that you
    are going to design. In this section, you will start with a dataset that you will
    prepare to train a model. You will then evaluate the model and store it. In the
    next section, you will use that model to create a batch and a real-time pipeline
    that utilize the model to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by acquiring the data that will be used to train the model, something
    you will do in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Acquiring the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is selecting the dataset that you will use to train the model:'
  prefs: []
  type: TYPE_NORMAL
- en: In the asset library, expand the **Datasets** category by clicking on the arrow
    next to its name. You should see **churn-dataset** there, which you created in
    [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072), *Letting the Machines
    Do the Model Training*:![Figure 6.6 – churn-dataset under the Datasets category
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_006.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.6 – churn-dataset under the Datasets category
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Drag **churn-dataset** onto the canvas:![Figure 6.7 – Canvas with churn-dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_007.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.7 – Canvas with churn-dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With that, you have just completed the **Data collection** step, which means
    you can move on to step number 2 of the *7 Steps of Machine Learning*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next step is **Data preparation**. Add a processing step to the pipeline
    by dragging the **Select Columns in Dataset** module, which can be found under
    the **Data Transformation** category in the asset library, onto the canvas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will now need to create a flow between the dataset and the module. You can
    do that by pulling from the dataset's **output port**, the small circle at the
    bottom of this **dataset**, to the dataset's **input port**, the small circle
    at the top of the **Select Columns in Dataset** module, as shown in the following
    screenshot:![Figure 6.8 – Creating a flow between the dataset and the processing
    module
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_008.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.8 – Creating a flow between the dataset and the processing module
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next step is to configure the **Select Columns in Dataset** module. With
    the module selected in the canvas, click on the **Edit column** link on the details
    pane, which is on the right of the canvas, as shown in the preceding screenshot.
    The **Select columns** dialog will appear. See the following screenshot for the
    final configuration of this popup.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In that popup, select **All columns** from the dropdown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a second line by clicking on the **+** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Exclude** from the dropdown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Column names** from the second dropdown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **id** column from the last dropdown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The dialog page should look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Select columns dialog'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16777_06_009.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.9 – Select columns dialog
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on **Save** to close the popup.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So far, you have selected the dataset that you will use to train the model,
    and you have prepared the data by removing the **id** column, which you will not
    need for the training process. In the next section, you will finalize your training
    pipeline by adding the untrained model, the module that will train the model,
    and the module for scoring and evaluating the trained model.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data and training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, you will choose the model that you will train. In [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072),
    *Letting the Machines Do the Model Training*, you identified a **voting ensemble**
    as the best performing model for the given data. This type of model is a combination
    of different models, including **Random Forest**. To keep this example simple,
    you will use a **Two-Class Decision Forest** model, similar to **Random Forest**.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the **Machine Learning Algorithms** category in the asset library.
    You will notice a couple of subcategories, including **Classification**. From
    that subcategory, drag and drop the **Two-Class Decision Forest** module onto
    the canvas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the model training, you will need two additional modules: the **Split Data**
    module, which you can find in the asset library under the **Data Transformation**
    category, and the **Train Model** module, which can be found in the **Model Training**
    category. Drag and drop both modules onto the canvas.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will need to extend the data flow you created in the previous section to
    pass the data through the new modules. Pull an **output port** from the **Select
    Columns in Dataset** module to an **input port** of the **Split Data** module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will need to configure the **Split Data** module on the module's details
    pane, as shown in the following screenshot. Set **Fraction of rows in the first
    output dataset** to **0.7**. By doing that, 70% of the data will be sent on the
    **left output port** area, which is used to train the model, and 30% will be sent
    to the **right output port** area, which is used for testing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Train Model** module accepts two inputs. On the **left input port** area,
    you need to pass an untrained model that will be trained with the data given on
    the **right input port** area. Pull an **output port** from the **Two-Class Decision
    Forest** module to the **left input port** area of the **Train Model** module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the **left output port** area of the **Split Data** module to the **right
    input port** area of **Train Model**. Your canvas should look as follows:![Figure
    6.10 – The Train Model module is missing some configuration
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_010.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.10 – The Train Model module is missing some configuration
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the preceding screenshot, there is an orange exclamation mark in the **Train
    Model** module. This mark indicates that something is misconfigured in that module.
    So far, you have configured which model to train and what data to use for the
    model's training. However, you have not defined which column the model should
    predict yet. This column is referred to as **Label column**. To configure **Label
    column**, select the module in the canvas and click on the **Edit column** link.
    This will open the **Label column** dialog shown in the following screenshot.
    Select the **churned** column from the drop-down list and click **Save**:![Figure
    6.11 – Selecting the column that the model will predict
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_011.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.11 – Selecting the column that the model will predict
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So far, the training pipeline is performing the first four steps of the *7 Steps
    of Machine Learning*. The next step is to evaluate the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Drag and drop the **Score Model** module onto the canvas, which can be found
    in the asset library under the **Model Scoring & Evaluation** category. This module
    accepts a trained model in the **left input port** area and a dataset on the **right
    input port** area. The output of this module is a dataset that contains the inferences
    made by the model against the incoming dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the **right output port** area of the **Split Data** module to the **right
    input port** area of the **Score Model** module. This will create a data flow
    that will bring the 30% part of the original data into the **Score Model** module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the **output port** area of the **Train Model** module to the **left
    input port** area of the **Score Model** module. The **Score Model** module will
    use the trained model to perform inferences against the incoming data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag and drop the **Evaluate Model** module onto the canvas, which can be found
    in the asset library under the **Model Scoring & Evaluation** category. This module
    will compare the predictions that the model made against the values stored in
    the **churned** column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the **output port** area of the **Score Model** module to the **left
    input port** area of the **Evaluate Model** module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you have followed all the steps so far, your canvas should look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.12 – The completed training pipeline'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16777_06_012.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.12 – The completed training pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, you have authored a training pipeline that performs the following actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Removes the **id** column from the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splits the data into a training dataset and a validation one. The training dataset
    contains 70% of the original data. The validation dataset contains the remaining
    30%.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trains **Two-Class Decision Forest** using the training dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scores the validation dataset using the trained model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluates the performance of the model by examining the results in the scored
    dataset. You will be able to review the metrics of the trained model in the **Evaluate
    Model** module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, you are going to execute this pipeline to train the model.
  prefs: []
  type: TYPE_NORMAL
- en: Executing the training pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous section, you created a complete training pipeline that you
    will now execute by creating a new pipeline run. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the **Submit** button in the top-right corner. The **Set up pipeline
    run** dialog will open, as shown in the following screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will need to create a new experiment and name it **test-pipeline**. Select
    the **Create new** radio button and then type in this name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Notice that the pipeline will execute in the default **compute target** you
    selected in the *The authoring screen/view* section. Click on the **Submit** button
    to start executing the training pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Preparing to execute the training pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_013.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.13 – Preparing to execute the training pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the pipeline finishes executing, the designer will look similar to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Successfully running the pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.14 – Successfully running the pipeline
  prefs: []
  type: TYPE_NORMAL
- en: With that, you have successfully finished developing and training your first
    pipeline. When the execution of the pipeline is completed, the **Create inference
    pipeline** button will appear. The following section describes the different options
    you have when it comes to creating an inference pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a batch and real-time inference pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section will discuss the two options of deploying an inference pipeline
    from the designer: **batch** and **real time**:'
  prefs: []
  type: TYPE_NORMAL
- en: With batch predictions, you asynchronously score large datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With real-time prediction, you score a small dataset or a single row in real
    time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When you create an inference pipeline, either batch or real time, AzureML takes
    care of the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: AzureML stores the trained model and all the trained data processing modules
    as an asset in the asset library under the **Datasets** category.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It removes unnecessary modules such as **Train Model** and **Split Data** automatically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It adds the trained model to the pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Especially for real-time inference pipelines, AzureML will add a **web service
    input** and a **web service output** in the final pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by creating a batch pipeline, something you will do in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a batch pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will create a batch inference pipeline. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the **Create inference pipeline** dropdown next to the **Submit** button
    and select **Batch inference pipeline**. This action will create the **Batch inference
    pipeline** tab, as shown in the following screenshot:![Figure 6.15 – The Batch
    inference pipeline tab showing the default generated pipeline
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_015.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.15 – The Batch inference pipeline tab showing the default generated
    pipeline
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By adding a pipeline parameter, you will be able to change the behavior of the
    pipeline at runtime. In our case, we want to parameterize which dataset to use
    to make predictions. To parameterize the input dataset, click on **churn-dataset**
    and select the **Set as pipeline parameter** checkbox in the details pane on the
    right.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the default parameter name in the **Parameter name** text box to **batchfile**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Publish** button to bring up the **Set up published pipeline**
    dialog shown in the following screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Create new** radio button to define a new pipeline endpoint. This
    endpoint is used to trigger the pipeline that you are about to publish.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep the default value of the **New PipelineEndpoint name** field as is. It
    should read **test-pipeline-batch inference**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can add a description to your published endpoint by filling in the **PipelineEndpoint
    description (optional)** field. Write **Test of a batch pipeline parameter name
    batchfile** in that field.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep all the other settings as is. The completed dialog page should look as
    follows:![Figure 6.16 – Published pipeline dialog page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_016.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.16 – Published pipeline dialog page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Publish** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the pipeline''s endpoint has been successfully published, the message
    shown in the following screenshot will appear in the designer. The **test-pipeline-batch
    inference** link will direct you to the published pipeline:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B16777_06_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 – Publish succeeded
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have published a batch inference pipeline, you can trigger it through
    the AzureML Studio interface. In [*Chapter 11*](B16777_11_Final_VK_ePub.xhtml#_idTextAnchor160),
    *Working with Pipelines*, in the *Publishing a pipeline to expose it as an endpoint*
    section, you will learn more about these pipelines and how you can integrate them
    with third-party applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will create a real-time pipeline based on the training
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a real-time pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will create a real-time inference pipeline. Let''s get
    started:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the **Training pipeline** tab in the designer, which is visible on the
    top-left corner in *Figure 6.15*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Create inference pipeline** dropdown next to the **Submit** button
    and select **Real-time inference pipeline**. This will generate the default **r****eal-time
    inference pipeline** shown in the following screenshot:![Figure 6.18 – The default
    real-time inference pipeline
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_018.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.18 – The default real-time inference pipeline
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Before we deploy this pipeline, we will need to make a couple of changes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Select Columns in Dataset** module and click on the **Edit column**
    link in the details pane on the right-hand side.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new row to the **Select columns** dialog by clicking on the plus (**+**)
    icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Exclude** and **Column names** from the corresponding dropdowns and
    enter **churned** as the column's name to exclude. The dialog page should look
    as follows:![Figure 6.19 – Excluding both the id and churned columns from the
    incoming dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_019.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.19 – Excluding both the id and churned columns from the incoming dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the **Data Transformation** category in the asset library, drag the **Apply
    SQL Transformation** module onto the canvas. Place it above the **Webservice Output**
    module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the **output port** area of the **Score Model** module to the **left
    input port** area of the **Apply SQL Transformation** module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the connection between the **Score Model** module and the **Web Service
    Output** model. To do that, select the connection between those two modules by
    clicking on it. When highlighted, select the trash icon or press the *Delete*
    button on your keyboard. The connector should be removed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the **Evaluate Model** module from the canvas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the **output port** area of the **Apply SQL Transformation** module
    to the **input port** area of the **Web Service Output** module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Apply SQL Transformation** module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the **Edit code** link in the **Apply SQL Transformation** detail
    pane and replace the default query with the following one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This SQL transformation only selects the predicted value, which is stored in
    the **Scored Labels** column.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Press the **Save** button. The changed pipeline should look like the one shown
    in the following screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To ensure that the pipeline you have designed executes properly, you will need
    to run it once using the **Submit** button. The **Set up published pipeline**
    dialog will appear.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will need to execute the pipeline within an experiment. Select the **Create
    new** radio button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use **test-pipeline-real-time-inference** as **New experiment name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep the default values as is for the rest of the fields and press **Submit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your pipeline should execute, and the canvas should look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Modified real-time inference pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16777_06_020.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.20 – Modified real-time inference pipeline
  prefs: []
  type: TYPE_NORMAL
- en: After verifying that the pipeline can execute without any issues, you can deploy
    it as a real-time endpoint. You have two options regarding the infrastructure
    that will host your real-time endpoint. You can deploy either in an **Azure Container
    Instance** (**ACI**) or **Azure Kubernetes Service** (**AKS**) cluster. The **ACI**
    infrastructure is useful for testing purposes, while the **AKS** infrastructure
    supports better production environments. In our case, we will deploy to **ACI**,
    something you will read about in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a real-time inference pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will deploy the sample real-time inference pipeline you
    created in the **Real-time inference pipeline** designer tab. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the **Deploy** button. This will bring up the **Set up real-time endpoint**
    popup shown in the following screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the **Set up real-time endpoint** popup, select the **Deploy new real-time
    endpoint** radio button option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Name** text field, enter **first-real-time-endpoint**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Description** text field, enter **Container Deployment of the first
    real-time pipeline**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Compute type** drop-down list and select **Azure Container Instance**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You won't need to modify the **Advanced** settings. The completed popup should
    look as follows:![Figure 6.21 – Set up real-time endpoint popup
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16777_06_021.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.21 – Set up real-time endpoint popup
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Deploy** button to provision your real-time endpoint. This will
    take a couple of minutes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After successfully deploying the pipeline, you will find the newly deployed
    pipeline under **Assets** | **Endpoints** of AzureML Studio. The endpoint you
    just deployed is the same as the one you deployed in [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072),
    *Letting the Machines Do the Model Training*. You can test it through the web
    interface. You will deep dive into how to use similar endpoints in [*Chapter 12*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171),
    *Operationalizing Models with Code*. Before moving on, you should delete the real-time
    endpoint to avoid being charged. Follow the instructions in the *Cleaning up the
    model deployment* section of [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072),
    *Letting the Machines Do the Model Training*, to delete the endpoint you just
    deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduced the pipeline designer, which allows us to create AzureML
    pipelines via drag and drop. You built your first training pipeline based on the
    churn dataset and the **Two-Class Decision Forest** model. We discussed three
    pipeline types, authored the training pipeline, created a batch pipeline, and
    developed and deployed a real-time pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter concludes the no-code, low-code features that AzureML provides.
    In the next chapter, you will start working on the AzureML Python SDK. The AzureML
    Python SDK allows you to train models and create machine learning pipelines through
    code, which is critical for the DP-100 exam.
  prefs: []
  type: TYPE_NORMAL
- en: Question
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the options for deploying real-time pipelines?
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Container Instances** only'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Container Instances** and **Azure Kubernetes Services**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Container Instances** and **Azure Virtual Machines**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Virtual Machines** only'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section offers a list of helpful web resources to help you augment your
    AzureML designer knowledge:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuring data splits and cross-validation in automated machine learning:
    [https://docs.microsoft.com/azure/machine-learning/how-to-configure-cross-validation-data-splits](https://docs.microsoft.com/azure/machine-learning/how-to-configure-cross-validation-data-splits%0D)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Running batch predictions using the AzureML designer: [https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-run-batch-predictions-designer.md](https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-run-batch-predictions-designer.md%0D)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tutorial: Designer – deploying a machine learning model: [https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy](https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy%0D)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the AzureML designer? [https://docs.microsoft.com/azure/machine-learning/concept-designer](https://docs.microsoft.com/azure/machine-learning/concept-designer%0D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tutorial: Designer – training a no-code regression model: [https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-train-score](https://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-train-score%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tutorial: Designer – deploying a machine learning model: [ttps://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy](https://ttps://docs.microsoft.com/azure/machine-learning/tutorial-designer-automobile-price-deploy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
