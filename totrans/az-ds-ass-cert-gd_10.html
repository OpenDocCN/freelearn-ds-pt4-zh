<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer199">
			<h1 id="_idParaDest-102"><em class="italic"><a id="_idTextAnchor102"/>Chapter 7</em>: The AzureML Python SDK</h1>
			<p>In this chapter, you will understand how the AzureML Python <strong class="bold">Software Development Kit</strong> (<strong class="bold">SDK</strong>) is structured and how to work with it, something that is key for the DP-100 exam. You will learn how to work with the <strong class="bold">Notebooks</strong> experience that is built into the AzureML Studio web portal, a tool that boosts coding productivity. Using the notebook editor, you will write some Python code to gain a better understanding of how to manage the compute targets, datastores, and datasets that are registered in the workspace. Finally, you are going to revisit the Azure CLI we looked at in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>, to perform workspace management actions using the AzureML extension. This will allow you to script and automate your workspace management activities.</p>
			<p>In this chapter, we are going to cover the following main topics:</p>
			<ul>
				<li>Overview of the Python SDK</li>
				<li>Working with AzureML notebooks</li>
				<li>Basic coding with the AzureML SDK</li>
				<li>Working with the AzureML CLI extension</li>
			</ul>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor103"/>Technical requirements</h1>
			<p>You will need to have access to an Azure subscription. Within that subscription, you will need a <strong class="bold">resource group</strong> named <strong class="source-inline">packt-azureml-rg</strong>. You will need to have either a <strong class="source-inline">Contributor</strong> or <strong class="source-inline">Owner</strong> <strong class="bold">Access control</strong> (<strong class="bold">IAM</strong>) role at the resource group level. Within that resource group, you should have already deployed a <strong class="bold">machine learning</strong> resource named <strong class="source-inline">packt-learning-mlw</strong>, as described in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>.</p>
			<p>You will also need to have a basic understanding of the <strong class="bold">Python</strong> language. The code snippets in this chapter target Python version 3.6 or later. You should know the basics of how a Jupyter notebook works and how the variables that you defined in one cell exist in the execution context of others.</p>
			<p>You can find all the notebooks and code snippets for this chapter on GitHub at <a href="http://bit.ly/dp100-ch07">http://bit.ly/dp100-ch07</a>.</p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor104"/>Overview of the Python SDK</h1>
			<p>The AzureML <strong class="bold">SDK</strong> is a Python library that allows you to interact with the AzureML services. It also provides you with data science modules that will assist you in your machine learning journey. The AzureML SDK<a id="_idIndexMarker471"/> is available in the R programming language through a Python to R interoperability package.</p>
			<p>The SDK consists of several packages that group different types of modules you can import into your code base. All the Microsoft-supported modules are placed within packages that start with <strong class="source-inline">azureml</strong>, such as <strong class="source-inline">azureml.core</strong> and <strong class="source-inline">azureml.train.hyperdrive</strong>. The following diagram offers a broad overview of the AzureML SDK's most frequently used packages, as well as the key modules that you will see in this book and the exam:</p>
			<div>
				<div id="_idContainer174" class="IMG---Figure">
					<img src="Images/B16777_07_001.jpg" alt="Figure 7.1 – The AzureML SDK modules and important classes&#13;&#10;" width="1650" height="858"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – The AzureML SDK modules and important classes</p>
			<p>Note that all the key classes that exist in the <strong class="source-inline">azureml.core</strong> package can also be imported from the corresponding child module. For example, the <strong class="source-inline">Experiment</strong> class can be imported in either way, as follows:</p>
			<p class="source-code">from azureml.core import Experiment</p>
			<p class="source-code">from azureml.core.experiment import Experiment</p>
			<p>Both snippets will load the same class and you only need to use one of them. The<a id="_idIndexMarker472"/> first one loads the class from the <strong class="source-inline">azureml.core</strong> package, while the second one loads it from the <strong class="source-inline">experiment</strong> module (a file named <strong class="source-inline">experiment.py</strong>), which is part of the <strong class="source-inline">azureml.core</strong> package. Do not be surprised if you notice this type of difference in various code samples you may read through.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">For exam purposes, you will not need to memorize the packages, but you will have to select the appropriate one from a drop-down list. For example, you may be asked to complete some code that refers to <strong class="source-inline">AutoMLConfig</strong>, and you may have to select between the <strong class="source-inline">azureml.automl</strong> package and the <strong class="source-inline">azureml.pipeline</strong> one, a choice that will become even more obvious when you finish reading the next few chapters. The code samples throughout this book import all the required packages on top of the script to help you become familiar with the location of the classes.</p>
			<p>In this chapter, you will focus on the SDK classes that allow you to control the AzureML workspace, as well as the compute resources that are deployed in the workspace, the datastores, and the datasets that you can register in the workspace.</p>
			<p>In the next section, you will learn how to utilize the <strong class="bold">Notebooks</strong> experience that is built into AzureML Studio to write Python scripts.</p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor105"/>Working in AzureML notebooks</h1>
			<p>AzureML Studio<a id="_idIndexMarker473"/> offers integration with a couple of code editors that allow you to edit notebooks and Python scripts. These editors are powered by the <strong class="bold">compute instance</strong> you<a id="_idIndexMarker474"/> provisioned in <a href="B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Configuring the Workspace</em>. If you have stopped that compute instance to save on costs, navigate to <strong class="bold">Manage</strong> | <strong class="bold">Compute</strong> and start it. From this view, you can open all third-party coding editors AzureML Studio integrates with, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer175" class="IMG---Figure">
					<img src="Images/B16777_07_002.jpg" alt="Figure 7.2 – List of third-party code editor experiences Azure Studio integrates with&#13;&#10;" width="1199" height="522"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2 – List of third-party code editor experiences Azure Studio integrates with</p>
			<p>The most <a id="_idIndexMarker475"/>widely known open source data science editors are Jupyter Notebook and its newer sibling, JupyterLab. You can open those editing environments by clicking on the respective links shown in the preceding screenshot. This will open a new browser tab, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer176" class="IMG---Figure">
					<img src="Images/B16777_07_003.jpg" alt="Figure 7.3 – JupyterLab and Jupyter editing experiences provided by the compute instance&#13;&#10;" width="1132" height="1405"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3 – JupyterLab and Jupyter editing experiences provided by the compute instance</p>
			<p>Besides these <a id="_idIndexMarker476"/>third-party code editing experiences, AzureML Studio offers a built-in enhanced notebook editor that allows you to edit, share, and collaborate within the Studio interface, as shown in the following screenshot. This editor is created on top of the Jupyter Notebook service but offers a much more improved code editing experience, such as inline error highlighting, automatic code completion, popups with parameter information for the method you are about to invoke, and other features that are referred to<a id="_idIndexMarker477"/> as <strong class="bold">IntelliSense</strong>:</p>
			<div>
				<div id="_idContainer177" class="IMG---Figure">
					<img src="Images/B16777_07_004.jpg" alt="Figure 7.4 – The enhanced Notebooks experience built into AzureML Studio&#13;&#10;" width="1370" height="1167"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.4 – The enhanced Notebooks experience built into AzureML Studio</p>
			<p>The notebook <a id="_idIndexMarker478"/>editor comes with an embedded sample library that contains an up-to-date catalog of notebooks that demonstrate almost all the capabilities of the latest AzureML SDK. Once you have found a related notebook, you can review its contents and if you want to modify it, you can clone it in your workspace, an action that will copy both the Jupyter notebook and the accompanying scripts and data that relate to that notebook, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer178" class="IMG---Figure">
					<img src="Images/B16777_07_005.jpg" alt="Figure 7.5 – Sample notebooks to help you ramp up the AzureML SDK's capabilities&#13;&#10;" width="1218" height="379"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.5 – Sample notebooks to help you ramp up the AzureML SDK's capabilities</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">These notebooks are up to date with the latest version of the AzureML SDK. The code repository where these notebooks are hosted can be found on GitHub at <a href="https://github.com/Azure/MachineLearningNotebooks/">https://github.com/Azure/MachineLearningNotebooks/</a>. You can use GitHub to file an issue or search for a code snippet using GitHub's search experience.</p>
			<p>Every AzureML workspace comes with a storage account, as mentioned in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>. This storage account contains a <strong class="bold">file share</strong> prefixed with <strong class="bold">code-</strong> that hosts all the notebooks and scripts available within the workspace, as shown in the following screenshot. The files in that folder share location are the ones that you saw previously within the Studio experience, in the <strong class="bold">Files</strong> tab:</p>
			<div>
				<div id="_idContainer179" class="IMG---Figure">
					<img src="Images/B16777_07_006.jpg" alt="Figure 7.6 – The Azure portal view of the file share that hosts all &#13;&#10;the code files in the AzureML workspace&#13;&#10;" width="1184" height="528"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.6 – The Azure portal view of the file share that hosts all the code files in the AzureML workspace</p>
			<p>Each user gets a separate folder under the <strong class="bold">Users</strong> folder where they can organize their files. All the files can be accessed by all users that have access to the specific AzureML workspace. This makes sharing code very easy. You can point to someone who has access to the AzureML workspace to a file by opening the file in your browser; then, you can share the URL from the browser navigation bar.</p>
			<p>In this section, you will create a notebook where you will write and execute the code snippets in this chapter. To work with your files, navigate to the <strong class="bold">Files</strong> tab of the <strong class="bold">Notebooks</strong> section of<a id="_idIndexMarker479"/> AzureML Studio. To keep the code snippets organized by chapter, you must create a folder named <strong class="source-inline">chapter07</strong> and then create a notebook named <strong class="source-inline">chapter07.ipynb</strong>.</p>
			<p>Click on the three dots next to your username, as shown in the following screenshot. From there, you can create folder structures and upload files from your local computer. Click on the <strong class="bold">Create new folder</strong> option, as shown in the following screenshot: </p>
			<div>
				<div id="_idContainer180" class="IMG---Figure">
					<img src="Images/B16777_07_007.jpg" alt="Figure 7.7 – The Create new folder option in the Notebooks experience area of AzureML Studio&#13;&#10;" width="565" height="576"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.7 – The Create new folder option in the Notebooks experience area of AzureML Studio</p>
			<p>Fill in the pop-up dialog that appears to create a folder named <strong class="source-inline">chapter07</strong>. Select that folder and click on the three dots. Then, select the <strong class="bold">Create new file</strong> option shown in the following screenshot. In the popup that appears, under <strong class="bold">File location</strong>, you should see <strong class="source-inline">Users/&lt;username&gt;/chapter07</strong>, which means that this file will be placed in the newly created folder. Regarding <strong class="bold">File type</strong>, you can select from an ever-growing list of types such as notebooks, Python or R script files, text files, and other popular formats. If none of these options fit the file you want to create, you can just select <strong class="bold">Other</strong> from the drop-down menu. In the <strong class="bold">File name</strong> field, type <strong class="source-inline">chapter07.ipynb</strong> and click on the <strong class="bold">Create</strong> button, as <a id="_idIndexMarker480"/>shown in the following screenshot:</p>
			<div>
				<div id="_idContainer181" class="IMG---Figure">
					<img src="Images/B16777_07_008.jpg" alt="Figure 7.8 – Creating a notebook to write and execute this chapter's Python scripts&#13;&#10;" width="1504" height="1125"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.8 – Creating a notebook to write and execute this chapter's Python scripts</p>
			<p>This will create two files in your folder: the notebook file, which will open in the editor pane, and a <strong class="source-inline">.amlignore</strong> file, a file you will read about in <a href="B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117"><em class="italic">Chapter 8</em></a>, <em class="italic">Experimenting with Python Code</em>:</p>
			<div>
				<div id="_idContainer182" class="IMG---Figure">
					<img src="Images/B16777_07_009.jpg" alt="Figure 7.9 – Editing a notebook within AzureML Studio&#13;&#10;" width="1650" height="583"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.9 – Editing a notebook within AzureML Studio</p>
			<p>Starting from the left-hand side<a id="_idIndexMarker481"/> of the preceding screenshot, the Notebooks experience offers the following:</p>
			<ol>
				<li>The <strong class="bold">Files</strong> explorer, where you can create or upload new files and delete, download, rename, or move existing files you or your colleagues have created in this workspace.</li>
				<li>The name of the open file. Note that if you see an asterisk next to the name – for example, <strong class="bold">* chapter07.ipynb</strong> – this means that the file hasn't been saved yet. You can save the file by using the <em class="italic">Ctrl</em> + <em class="italic">S</em> shortcut for Windows and Linux or the <em class="italic">Cmd</em> + <em class="italic">S</em> shortcut for macOS. Alternatively, you can select the <strong class="bold">Save</strong> option from the <strong class="bold">File options</strong> menu, which you will read about next.</li>
				<li>The <strong class="bold">File options</strong> menu, where you have options such as the <strong class="bold">Save</strong> operation and <strong class="bold">Focus mode</strong>, which expands the editor pane to occupy most of the browser tab space. This is a dynamic menu that's based on the file type you are currently editing. In the preceding screenshot, a notebook is open, and the menu is offering additional operations such as clearing outputs, restarting the Python kernel, or examining the variables that are currently loaded in the Python kernel. You can also edit the same file in Jupyter or JupyterLab by clicking on the menu icon, which is the icon with the four vertical lines, and selecting the corresponding editor from the <strong class="bold">Editors</strong> option. Especially for VS Code, a very popular free cross-platform code editor, the <strong class="bold">Edit in VS Code</strong> option is available in the main bar.</li>
				<li>The ability to manage the compute instance where you are currently editing the specific file. From this section, you can quickly create a new compute instance or start/stop an existing one.</li>
				<li>The ability to select the environment to execute the notebook in. By default, the AzureML Python kernel is selected, which is the environment where the AzureML SDK is already installed. You can change the kernel to an R one if you are editing an R file, or you can create your own kernels if you want to customize the environment you are working in.</li>
				<li>The main editor pane. This is where you can modify the selected file.<p>In your case, the editor<a id="_idIndexMarker482"/> pane will be empty, and a single empty cell will be visible, as shown in the following screenshot. Each cell can either contain <strong class="bold">Markdown</strong>-formatted text<a id="_idIndexMarker483"/> or Python code. You can convert a cell into a code one by clicking on the pop-up menu and selecting the <strong class="bold">M</strong><strong class="bold">↓</strong> icon:</p><div id="_idContainer183" class="IMG---Figure"><img src="Images/B16777_07_010.jpg" alt="Figure 7.10 – An empty code cell&#13;&#10;" width="782" height="250"/></div><p class="figure-caption">Figure 7.10 – An empty code cell</p></li>
				<li>Click on the <strong class="bold">M</strong><strong class="bold">↓</strong> icon and then hit the <strong class="bold">edit</strong> icon to add the following Markdown text in the cell:<p class="source-code"># Chapter 07 code snippets</p><p class="source-code">This notebook contains all code snippets from chapter 7.</p></li>
				<li>Hit <em class="italic">Shift</em> + <em class="italic">Enter</em> on your keyboard to finish editing, execute the cell, which in this case will render the formatted text, and move the cursor to the next cell. By default, the next cell will be a code one. Add the following Python code inside the cell:<p class="source-code">print('Hello world')</p><p>Note that while you start typing, a popup will appear containing code suggestions that you can select using the arrow keys. You can confirm your selection by hitting the <em class="italic">Enter</em> button on your keyboard. The list is an intelligent one in that it shows classes that start with what you have typed. It also shows frequently used classes that you may have misspelled or forgot to type some letters in for. For example, the following screenshot shows the <strong class="source-inline">PermissionError</strong> class <a id="_idIndexMarker484"/>because you may have forgotten to type the <strong class="bold">e</strong> and <strong class="bold">m</strong> letters. Also, note that while the <strong class="source-inline">print</strong> statement is incomplete, a wavy underline will indicate a syntax error in that portion of the code. To execute a code cell, you can hit the <em class="italic">Shift</em> + <em class="italic">Enter</em> key combo, or you can click on the round button on the left-hand side of the cell:</p></li>
			</ol>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer184" class="IMG---Figure">
					<img src="Images/B16777_07_011.jpg" alt="Figure 7.11 – IntelliSense suggesting methods and classes that fit the current script's scope&#13;&#10;" width="490" height="184"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.11 – IntelliSense suggesting methods and classes that fit the current script's scope</p>
			<p>If an error occurs in the code cell you are executing, the error message will appear at the bottom of the cell and the Traceback will appear in the output section of the cell, as shown in the following screenshot. You can update the cell's content and rerun the cell to fix this error:</p>
			<div>
				<div id="_idContainer185" class="IMG---Figure">
					<img src="Images/B16777_07_012.jpg" alt="Figure 7.12 – Script error during notebook cell execution&#13;&#10;" width="1148" height="399"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.12 – Script error during notebook cell execution</p>
			<p>In this section, you learned how to use the built-in Notebooks experience to author Python scripts. In the next section, you will start writing code fragments that utilize the AzureML SDK.</p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor106"/>Basic coding with the AzureML SDK</h1>
			<p>The first class you will work with is the <a id="_idIndexMarker485"/>AzureML <strong class="source-inline">Workspace</strong>, a class that gives you access to <a id="_idIndexMarker486"/>all the resources within your workspace. To create a reference to your workspace, you will need the following information:</p>
			<ul>
				<li><strong class="bold">Subscription ID</strong>: The <a id="_idIndexMarker487"/>subscription where <a id="_idIndexMarker488"/>the workspace is located. This is a <strong class="bold">Globally Unique Identifier</strong> (<strong class="bold">GUID</strong>, also known as <a id="_idIndexMarker489"/>a <strong class="bold">UUID</strong>) that consists of 32 hexadecimal (0-F) digits; for example, <strong class="source-inline">ab05ab05-ab05-ab05-ab05-ab05ab05ab05</strong>. You can find this ID in the Azure portal in the <strong class="bold">Properties</strong> tab of the subscription you are using.</li>
				<li><strong class="bold">Resource group name</strong>: The resource group<a id="_idIndexMarker490"/> that contains the AzureML workspace components.</li>
				<li><strong class="bold">Workspace name</strong>: The name of the <a id="_idIndexMarker491"/>AzureML workspace.</li>
			</ul>
			<p>You can store this information in variables by running the following assignments:</p>
			<p class="source-code">subscription_id = '&lt;Subscription Id&gt;'</p>
			<p class="source-code">resource_group = 'packt-azureml-rg'</p>
			<p class="source-code">workspace_name = 'packt-learning-mlw'</p>
			<p>The first approach to creating the reference to the workspace is to instantiate the <strong class="source-inline">Workspace</strong> class, as shown in the following snippet:</p>
			<p class="source-code">from azureml.core import Workspace</p>
			<p class="source-code">ws = Workspace(subscription_id, resource_group, workspace_name)</p>
			<p>This is the code <a id="_idIndexMarker492"/>snippet that you saw in <a href="B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Configuring the Workspace</em>, when you<a id="_idIndexMarker493"/> created a dataset and explored the <strong class="bold">Consume</strong> tab of that dataset.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">This book assumes that you will be writing the code in the notebook you created in the previous section, and that you will be editing the notebook using the <strong class="bold">Notebook</strong> experience within Studio. When you open a notebook for the first time you will notice a banner asking you to authenticate. This is an once off process that you need to perform. If you are allowed to install software components on your local computer, you can execute the same scripts on your local machine on a local Jupyter server, so long as you install the <strong class="source-inline">azureml-sdk</strong> package by issuing the <strong class="source-inline">pip instal azureml-sdk</strong> command. In that case, you will be prompted to authenticate your device using an interactive authentication, something you will read about in the next section.</p>
			<p>Another approach to creating the reference to the AzureML workspace is to use the <strong class="source-inline">get()</strong> method of the <strong class="source-inline">Workspace</strong> class, as shown in the following snippet:</p>
			<p class="source-code">from azureml.core import Workspace</p>
			<p class="source-code">ws = Workspace.get(name=workspace_name,</p>
			<p class="source-code">                   subscription_id=subscription_id,</p>
			<p class="source-code">                   res<a id="_idTextAnchor107"/>ource_group=resource_group)</p>
			<p>Here, regarding the <strong class="source-inline">ws</strong> variable, you assigned a reference to the AzureML workspace that matches the <strong class="source-inline">name</strong>, <strong class="source-inline">subscription_id</strong>, and <strong class="source-inline">resource_group</strong> values that you specified in the <strong class="source-inline">workspace_name</strong>, <strong class="source-inline">subscription_id</strong>, and <strong class="source-inline">resource_group</strong> variables at the beginning of this section.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In Python, you can invoke functions by passing arguments either by name or by position. In the previous examples, we invoked <strong class="source-inline">Workspace.get()</strong>by passing arguments by name – that is, we explicitly specified that for the <strong class="source-inline">name</strong> argument, we are passing the <strong class="source-inline">workspace_name</strong> variable as its value. When using this approach, the order of the arguments is not important. In the example before that, we instantiated the <strong class="source-inline">Workspace</strong> class by passing arguments by position. You did not use the <strong class="source-inline">workspace_name=workspace_name</strong> assignment. This means that you assigned values to the parameters of the <strong class="source-inline">Workspace</strong> class's constructor based on the order they were declared in. In this book, as well as in the exam, you will see both ways of performing assignments.</p>
			<p>The previous <a id="_idIndexMarker494"/>two ways of getting the AzureML workspace reference <a id="_idIndexMarker495"/>are identical. The main issue with them, however, is that they hardcode the workspace where the script is connecting to. Imagine that you want to share a notebook with a friend, and you have hardcoded the subscription ID, resource name, and workspace name in that notebook. Your friend would have to manually go and edit that cell. This problem becomes even more obvious when you want to write a script that runs in multiple environments, such as the development environment, the quality assurance environment, and the production environment.</p>
			<p>The <strong class="source-inline">Workspace</strong> class offers the <strong class="source-inline">from_config()</strong> method to address this issue. This method searches the folder tree structure for the <strong class="source-inline">config.json</strong> file, which is in the following format and includes all the information that was mentioned at the beginning of this section:</p>
			<p class="source-code">{</p>
			<p class="source-code">  "subscription_id": "&lt;Subscription Id&gt;",</p>
			<p class="source-code">  "resource_group": "packt-azureml-rg",</p>
			<p class="source-code">  "workspace_name": "packt-learning-mlw"</p>
			<p class="source-code">}</p>
			<p>In the case of the compute instance, this file is located in the root folder (<strong class="source-inline">/config.json</strong>) and was automatically created there when you provisioned the compute instance within the AzureML workspace. If you want to run the same script from your local computer, you can create a similar file, place it next to the Python script you are editing, and write the following code to get a reference to the AzureML workspace:</p>
			<p class="source-code">from azureml.core import Workspace</p>
			<p class="source-code">ws = Workspace.from_config()</p>
			<p class="source-code">print(f"Connected to workspace {ws.name}")</p>
			<p>If you want to spin up a new AzureML workspace, you can provision one using the <strong class="source-inline">Workspace.create()</strong> method. The following code snippet creates an AzureML workspace in the West Europe region:</p>
			<p class="source-code">from azureml.core import Workspace</p>
			<p class="source-code">new_ws = Workspace.create(</p>
			<p class="source-code">                   name='packt-azureml-sdk-mlw',</p>
			<p class="source-code">                   subscription_id=subscription_id,</p>
			<p class="source-code">                   r<a id="_idTextAnchor108"/>esource_group='packt-azureml-sdk-rg',</p>
			<p class="source-code">                   create_resource_group=True,</p>
			<p class="source-code">                   location='westeurope')</p>
			<p>This snippet will <a id="_idIndexMarker496"/>create an AzureML workspace named <strong class="source-inline">packt-azureml-sdk-mlw</strong>, in the<a id="_idIndexMarker497"/> subscription with the ID specified by the <strong class="source-inline">subscription_id</strong> variable. This resource will be deployed in the <strong class="source-inline">packt-azureml-sdk-rg</strong> resource group, which will be created if it does not already exist.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">You will need to have the required permissions at the Azure subscription level to be able to create the resource group if it does not exist already. Otherwise, you will get an error stating <strong class="bold">Azure Error: AuthorizationFailed</strong>. This can be either a custom role, a <strong class="source-inline">Contributor</strong> role, or an <a id="_idIndexMarker498"/>even more privileged role such as <strong class="source-inline">Owner</strong>. To get past that<a id="_idIndexMarker499"/> error, you may try to deploy the new workspace within the <strong class="source-inline">packt-azureml-rg</strong> resource group instead of <strong class="source-inline">packt-azureml-sdk-rg</strong> by modifying the preceding code snippet. You will need to have at least a <strong class="source-inline">Contributor</strong> role at the resource group level to be able to deploy the AzureML workspace with the SDK.</p>
			<p>To delete <a id="_idIndexMarker500"/>the workspace you just deployed, you can use the following code <a id="_idIndexMarker501"/>snippet:</p>
			<p class="source-code">new_ws.delete(delete_dependent_resources=True)</p>
			<p>This code deletes the workspace being referenced by the <strong class="source-inline">new_ws</strong> variable and removes the dependent resources, which are the storage account, the key vault, and the Application Insights resources that were deployed with the AzureML workspace.</p>
			<p>In this section, you learned how to get a reference to and manipulate the workspace resource through Python code. This section assumed that you have been using the built-in notebook editor of the studio web UI, so you did not have to authenticate. If you wanted to run the same code on your computer, you would have to authenticate to be able to access the resources, which is something we will look at in the next section.</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor109"/>Authenticating from your device</h2>
			<p>In March<a id="_idIndexMarker502"/> 2020, the <strong class="bold">Notebooks</strong> experience in <a id="_idIndexMarker503"/>AzureML Studio requests you to authenticate to the compute instance. This is a process you have to do only once and it is as simple as clicking the <strong class="bold">Authenticate</strong> button that will be visible in the Notebooks experience. If you are running the same code from your local computer, or if you are trying to execute a Python script within a terminal in a compute instance for the very first time, you must run an AzureML SDK command. A prompt will ask you to authenticate, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer186" class="IMG---Figure">
					<img src="Images/B16777_07_013.jpg" alt="Figure 7.13 – Interactive authentication requested during the first command's execution&#13;&#10;" width="1292" height="297"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.13 – Interactive authentication requested during the first command's execution</p>
			<p>If you see this message, navigate to <a id="_idIndexMarker504"/>the link provided, where you will be asked to input the request code displayed in the prompt. In this case, this is <strong class="bold">MYRNDCODE</strong>. This code is a unique identifier for a request to log in using your identity from your computer's location. Select the account you are planning to use to access the various Azure resources, including the AzureML workspace. The following figure shows the overall interactive authentication flow:</p>
			<div>
				<div id="_idContainer187" class="IMG---Figure">
					<img src="Images/B16777_07_014.jpg" alt="Figure 7.14 – Using interactive login to authenticate in a compute instance&#13;&#10;" width="1650" height="613"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.14 – Using interactive login to authenticate in a compute instance</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The request code is a short-lived one and it expires in 15 minutes. If you fail to complete the process within that time frame, an error will occur, and you will have to start over.</p>
			<p>If your account has access to <a id="_idIndexMarker505"/>multiple <strong class="bold">Azure Active Directories</strong> (<strong class="bold">AADs</strong>), for example, your personal AAD from the trial subscription and your company's one, you may need to manually indicate which AAD tenant to authenticate to. This can be done by invoking the interactive authentication process manually using the following snippet:</p>
			<p class="source-code">from azureml.core.authentication import \ </p>
			<p class="source-code">                             InteractiveLoginAuthentication</p>
			<p class="source-code">InteractiveLoginAuthentication(tenant_id="&lt;AAD tenant id&gt;")</p>
			<p>This code initiates the device authentication flow shown in the preceding figure. <strong class="source-inline">&lt;AAD tenant id&gt;</strong> is a GUID that you can get from the Azure portal by visiting the AAD resource.</p>
			<p>In this section, you <a id="_idIndexMarker506"/>learned about interactive authentication, which allows you to access your AzureML workspace from any device. This authentication method should be used when you try to execute a script on a remote computer or if you are trying to execute an Azure CLI command. Once authenticated, a token is stored within the computer you are executing <strong class="source-inline">InteractiveLoginAuthentication</strong> on and you will not be prompted for another login until that token has expired.</p>
			<p>In the next section, you will start using the authenticated reference to your workspace to deploy compute targets you can use to execute scripts remotely.</p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor110"/>Working with compute targets</h2>
			<p>As we mentioned in <a href="B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Configuring the Workspace</em>, in the <em class="italic">Provisioning compute resources</em> section, compute resources<a id="_idIndexMarker507"/> are machines that allow you to execute scripts remotely. The AzureML SDK allows you to list the existing compute targets you may have in your workspace or provision new ones if needed.</p>
			<p>To enumerate the compute targets that you have provisioned or attached to your workspace, you can use the reference to the AzureML workspace that you assigned to the <strong class="source-inline">ws</strong> variable using <strong class="source-inline">ws = Workspace.from_config()</strong>. The workspace object has an attribute named <strong class="source-inline">compute_targets</strong>. This is a Python dictionary that has all the compute instance names as keys and a reference to that compute instance as a value. To enumerate and print out this list, you can use the following code:</p>
			<p class="source-code">for compute_name in ws.compute_targets:</p>
			<p class="source-code">    compute = ws.compute_targets[compute_name]</p>
			<p class="source-code">    print(f"Compute {compute.name} is a {type(compute)}")</p>
			<p>The output should list at least the <strong class="source-inline">ComputeInstance</strong> area where you are executing the script and potentially the <strong class="source-inline">AmlCompute</strong> cluster you created in <a href="B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Configuring the Workspace</em>. You will notice that all the compute types are defined within the modules of the <strong class="source-inline">azureml.core.compute</strong> package.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">This code assumes that you have initialized the <strong class="source-inline">ws</strong> variable, something you did earlier on the notebook by following the instructions in the <em class="italic">Basic coding with the AzureML SDK</em> section. If you close the compute instance, the kernel will stop, and all the variables you defined by executing the notebook cells will be lost. If you want to continue working on a notebook, the easiest approach is to rerun all the cells, which will ensure that you have initialized all the variables.</p>
			<p>Another way <a id="_idIndexMarker508"/>to get a reference to a compute target is to use the <strong class="source-inline">ComputeTarget</strong> constructor. You need to pass in the <strong class="source-inline">Workspace</strong> reference and the name of the compute target you are looking for. If the target does not exist, a <strong class="source-inline">ComputeTargetException</strong> exception will be raised that you have to handle in your code base, as shown in the following script:</p>
			<p class="source-code">from azureml.core import ComputeTarget</p>
			<p class="source-code">from azureml.exceptions import ComputeTargetException</p>
			<p class="source-code">compute_name = 'gpu-cluster'</p>
			<p class="source-code">compute = None</p>
			<p class="source-code">try:</p>
			<p class="source-code">    compute = ComputeTarget(workspace=ws, name=compute_name)</p>
			<p class="source-code">    print(f"Found {compute_name} which is {type(compute)}")</p>
			<p class="source-code">except ComputeTargetException as e:</p>
			<p class="source-code">    print(f"Failed to get compute {compute_name}. Error: {e}")</p>
			<p>The <strong class="source-inline">ComputeTarget</strong> class offers the <strong class="source-inline">create()</strong> method, which allows you to provision various compute targets, including compute instances (the <strong class="source-inline">ComputeInstance</strong> class), compute clusters (the <strong class="source-inline">AmlCompute</strong> class), and Azure Kubernetes Service (the <strong class="source-inline">AKSCompute</strong> class) targets.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Whenever you are deploying a compute instance or compute cluster from the AzureML Studio web UI, the Azure CLI, or the SDK, the compute target will be provisioned in the same resource group and the same Azure Region that your machine learning workspace is located.</p>
			<p>To provision a<a id="_idIndexMarker509"/> compute target, you will need to create a configuration object that inherits from the <strong class="source-inline">ComputeTargetProvisioningConfiguration</strong> abstract class. In the following example, the script is trying to locate a compute cluster named <strong class="source-inline">cpu-sm-cluster</strong>. If the cluster exists, it assigns a reference to the cluster to the <strong class="source-inline">cluster</strong> variable. If the cluster does not exist, the script creates an instance of the <strong class="source-inline">AmlComputeProvisioningConfiguration</strong> class, which is assigned to the <strong class="source-inline">config</strong> variable. This instance is created through the <strong class="source-inline">provisioning_configuration()</strong> method of the <strong class="source-inline">AmlCompute</strong> class. This <strong class="source-inline">config</strong> is used to create the cluster and wait for the registration in the workspace to complete, showing the creation logs:</p>
			<p class="source-code">from azureml.core.compute import ComputeTarget, AmlCompute</p>
			<p class="source-code">compute_name = 'cpu-sm-cluster'</p>
			<p class="source-code">cluster = None</p>
			<p class="source-code">if compute_name in ws.compute_targets:</p>
			<p class="source-code">    print('Getting reference to compute cluster')</p>
			<p class="source-code">    cluster = ws.compute_targets[compute_name]</p>
			<p class="source-code">else:</p>
			<p class="source-code">    print('Creating compute cluster')</p>
			<p class="source-code">    config = AmlCompute.provisioning_configuration(</p>
			<p class="source-code">                           vm_size='Standard_D1', </p>
			<p class="source-code">                           max_nodes=2)</p>
			<p class="source-code">    cluster = ComputeTarget.create(ws, compute_name, config)</p>
			<p class="source-code">    cluster.wait_for_completion(show_output=True)</p>
			<p class="source-code">print(f"Got reference to cluster {cluster.name}") </p>
			<p>This script specifies<a id="_idIndexMarker510"/> the virtual machine's size (the <strong class="source-inline">vm_size</strong> argument). The virtual machine is going to be <strong class="source-inline">Standard_D1</strong>, which is a <strong class="bold">D-Series</strong> one, also known as general-purpose compute. This means that it does not have any GPU capabilities. This is in contrast to <strong class="bold">N-Series</strong>, which are also known as GPU-enabled virtual machines. Examples of <strong class="bold">N-Series</strong> virtual machine sizes are <strong class="source-inline">Standard_NC6</strong>, <strong class="source-inline">Standard_NV24s_v3</strong>, and <strong class="source-inline">Standard_ND40rs_v2</strong>. Notice how all the sizes start with <strong class="bold">N</strong>.</p>
			<p>The script is only specifying the maximum nodes (the <strong class="source-inline">max_nodes</strong> argument) that the compute cluster will have. If you do not specify the minimum nodes (the <strong class="source-inline">min_nodes</strong> argument), the argument will be the default value of 0. This means that by default, the cluster will scale down to 0 nodes, inflicting no compute costs when no job is running. You can find all the default values for all the arguments of the <strong class="source-inline">provisioning_configuration()</strong> method on Microsoft's official Python SDK reference page, as shown in the following screenshot, or by using the Python <strong class="source-inline">help</strong> command by executing <strong class="source-inline">help(AmlCompute.provisioning_configuration)</strong>:</p>
			<div>
				<div id="_idContainer188" class="IMG---Figure">
					<img src="Images/B16777_07_015.jpg" alt="Figure 7.15 – Documentation for the provisioning_configuration method of the AmlCompute class&#13;&#10;" width="966" height="413"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.15 – Documentation for the provisioning_configuration method of the AmlCompute class</p>
			<p>One of the <a id="_idIndexMarker511"/>drawbacks of having 0 minimum nodes in a compute cluster is that you will have to wait for the compute nodes to be allocated before the job you submitted gets executed. To save this slack time, it is common to scale up the minimum and even the maximum nodes of the cluster during workdays, and then change those values after business hours to save on costs. To change the number of nodes of a compute cluster, you can use the AzureML Studio web UI or the Azure CLI, or even update the <strong class="source-inline">min_nodes</strong> attribute of the compute cluster using the following code:</p>
			<p class="source-code">from azureml.core.compute import AmlCompute</p>
			<p class="source-code">for ct_name, ct in ws.compute_targets.items():</p>
			<p class="source-code">    if (isinstance(ct, AmlCompute)):</p>
			<p class="source-code">        print(f"Scalling down cluster {ct.name}")</p>
			<p class="source-code">        ct.update(min_nodes=0)</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Changing the number of minimum and maximum nodes of a compute cluster can be done through the AzureML Studio web portal, the CLI, the SDK, and ARM templates. Before October 2020, you could also change the number of nodes through the Azure portal, a functionality that has been removed since.</p>
			<p>In this section, you learned how to create or get a reference to a compute target that you can use to execute scripts. In the next section, you will learn how to attach to various data sources through the SDK.</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor111"/>Defining datastores</h2>
			<p>As we mentioned in <a href="B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Configuring the Workspace</em>, in the <em class="italic">Connecting to datastores</em> section, datastores are the engines where your data resides and provide access to anyone<a id="_idIndexMarker512"/> authorized to do so. The AzureML SDK allows you to attach existing datastores to access the underlying data. </p>
			<p>In this section, you are going to attach the blob container of a storage account to your workspace. Imagine that you have a storage account named <strong class="bold">mydatastg</strong>. This storage account has a blob container named <strong class="bold">existing-container</strong> that contains the CSV files you want to analyze and then train models against, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer189" class="IMG---Figure">
					<img src="Images/B16777_07_016.jpg" alt="Figure 7.16 – The container in the mydatastg storage account, as seen in the Azure portal&#13;&#10;" width="1641" height="510"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.16 – The container in the mydatastg storage account, as seen in the Azure portal</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Provisioning new storage accounts and adding containers from the Azure portal is an easy task and is outside the scope of the exam. Note that storage accounts have unique names. This means that you will probably not be able to provision a storage account named <strong class="bold">mydatastg</strong> because it belongs to someone else. You can use the existing storage account that was provisioned with your AzureML workspace to follow these steps. You can add the <strong class="bold">existing-container</strong> container to that storage account through the Azure portal or you can use the <strong class="bold">azureml</strong> container that already exists.</p>
			<p>To register this <a id="_idIndexMarker513"/>container as a new datastore in your AzureML workspace, you will need to follow these steps:</p>
			<ol>
				<li value="1">Before going into your notebook, you will need the storage account name and the account key. This information is located in the Azure portal, in the <strong class="bold">Settings</strong> | <strong class="bold">Access keys</strong> tab of the storage account resource, as shown in the following screenshot:<div id="_idContainer190" class="IMG---Figure"><img src="Images/B16777_07_017.jpg" alt="Figure 7.17 – Storage account name and key required to connect to the storage account&#13;&#10;" width="1650" height="899"/></div><p class="figure-caption">Figure 7.17 – Storage account name and key required to connect to the storage account</p></li>
				<li>Go to your <strong class="source-inline">chapter07.ipynb</strong> notebook and in a new code cell, assign that information to the following Python variables:<p class="source-code">storage_name = 'mydatastg'</p><p class="source-code">storage_key = '&lt;storagekey&gt;'</p><p class="source-code">storage_container = 'existing-container'</p></li>
				<li>To register the blob container as a new datastore named <strong class="source-inline">my_data_store</strong>, you can use the <strong class="source-inline">register_azure_blob_container()</strong> method of the <strong class="source-inline">Datastore</strong> class, as shown in the following snippet:<p class="source-code">from azureml.core import Datastore</p><p class="source-code">dstore = Datastore.register_azure_blob_container(</p><p class="source-code">    workspace=ws,</p><p class="source-code">    datastore_name="my_data_store",</p><p class="source-code">    container_name=storage_container,</p><p class="source-code">    account_name=storage_name,</p><p class="source-code">    account_key=storage_key,</p><p class="source-code">    create_if_not_exists=False</p><p class="source-code">)</p><p>As expected, the<a id="_idIndexMarker514"/> method requires a reference to the <strong class="source-inline">Workspace</strong> area where the new datastore will be created as an argument. Also, note that the <strong class="source-inline">create_if_not_exists</strong> argument is set to <strong class="source-inline">False</strong>, something that will make the method raise an <strong class="source-inline">AzureMissingResourceHttpError</strong> exception with an error code of <strong class="source-inline">ContainerNotFound</strong> if that the blob container does not exist.</p><p>Similar to the blob container, you can register all supported data storage types through the AzureML SDK's <strong class="source-inline">Datastore</strong> class, as shown in the following screenshot. For example, you can use the <strong class="source-inline">register_azure_data_lake_gen2()</strong> method to connect to an Azure Data Lake Generation 2 datastore or the <strong class="source-inline">register_azure_sql_database()</strong> method to connect to an Azure SQL database:</p><div id="_idContainer191" class="IMG---Figure"><img src="Images/B16777_07_018.jpg" alt="Figure 7.18 – Supported data storage service types from the official documentation page&#13;&#10;" width="1431" height="1062"/></div><p class="figure-caption">Figure 7.18 – Supported data storage service types from the official documentation page</p></li>
				<li>To get a reference <a id="_idIndexMarker515"/>to the connected datastore, you can use the <strong class="source-inline">Datastore</strong> class constructor, as shown in the following snippet:<p class="source-code">from azureml.core import Datastore</p><p class="source-code">dstore = Datastore.get(ws,"my_data_store")</p></li>
				<li>In <a href="B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Configuring the Workspace</em>, in the list of datastores, you learn how to set one of the registered datastores to the default one for the AzureML workspace. The <strong class="source-inline">Workspace</strong> class offers a shortcut that gives a reference to that store using the <strong class="source-inline">get_default_datastore()</strong> method:<p class="source-code">dstore = ws.get_default_datastore()</p><p>In the rest of this book, you will be using the default datastore to store data.</p></li>
				<li>Datastores that refer to Azure blob containers (the <strong class="source-inline">AzureBlobDatastore</strong> class) or Azure file shares (the <strong class="source-inline">AzureFileDatastore</strong> class) can upload and download files through the SDK. The following snippet loads the <strong class="bold">scikit-learn</strong> diabetes dataset into a pandas <strong class="source-inline">DataFrame</strong>, which is then stored as a local CSV file. Once the file has been stored, the script gets a reference to the default datastore of the <strong class="source-inline">Workspace</strong> area, which<a id="_idIndexMarker516"/> is referenced in the <strong class="source-inline">ws</strong> variable, and uploads that file to <strong class="source-inline">/samples/diabetes/v1/rawdata.csv</strong> using the <strong class="source-inline">upload()</strong> method:<p class="source-code">from sklearn.datasets import load_diabetes</p><p class="source-code">import pandas as pd</p><p class="source-code">features, target = load_diabetes(return_X_y=True)</p><p class="source-code">diabetes_df = pd.DataFrame(features)</p><p class="source-code">diabetes_df['target']= target</p><p class="source-code">diabetes_df.to_csv('rawdata.csv', index=False)</p><p class="source-code">dstore = ws.get_default_datastore()</p><p class="source-code">dstore.upload_files(</p><p class="source-code">            files=['rawdata.csv'],</p><p class="source-code">            target_path="/samples/diabetes/v1", </p><p class="source-code">            overwrite=True,</p><p class="source-code">            show_progress=True)</p></li>
				<li>This file will appear in the storage account that was created with your AzureML workspace. You can find it in the Azure portal by navigating to the storage account, selecting the blob container with the name that starts with <strong class="bold">azureml-blobstore-</strong>, and navigating through the <strong class="bold">samples / diabetes / v1</strong> folders, as shown in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer192" class="IMG---Figure">
					<img src="Images/B16777_07_019.jpg" alt="Figure 7.19 – Uploaded data in the blob container that is registered as the default datastore&#13;&#10;" width="1650" height="702"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.19 – Uploaded data in the blob container that is registered as the default datastore</p>
			<p>In this section, you learned how to attach an existing Azure blob container to a new datastore within your AzureML workspace. You also learned how to easily get a reference to the workspace's default datastore, and then you uploaded a CSV file to that datastore. In the next section, you will learn how to define datasets, a construct that will help you work with your data independently from where it's stored.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor112"/>Working with datasets</h2>
			<p>As we mentioned in <a href="B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Configuring the Workspace</em>, in the <em class="italic">Working with datasets</em> section, datasets are <a id="_idIndexMarker517"/>an abstraction layer on top of the data that you use for training and inference. They contain references to the physical data's location and provide a series of metadata that helps you understand their shape and statistical properties. They <em class="italic">do not copy</em> the data that resides within the datastores. AzureML offers two types of datasets:</p>
			<ul>
				<li><strong class="source-inline">FileDataset</strong> allows <a id="_idIndexMarker518"/>you to reference a single file or multiple files in one or multiple datastores. A common example of <strong class="source-inline">FileDataset</strong> is images that are being used to train a computer vision model.</li>
				<li><strong class="source-inline">TabularDataset</strong> allows you<a id="_idIndexMarker519"/> to reference tabular structured data that can be stored in a single file or multiple files within datastores or may be stored directly in relational datastores such as SQL servers. The diabetes <strong class="bold">pandas</strong> <strong class="source-inline">DataFrame</strong> that you loaded in the previous section is a typical tabular dataset. You can create <strong class="source-inline">TabularDataset</strong> by parsing various files, including CSV, TSV, Parquet, and JSON files. If your data contains a column/feature that has a timestamp, or the files are stored in a folder structure that contains a date pattern such as <strong class="source-inline">/&lt;year&gt;/&lt;month&gt;/file.csv</strong>, you can enable the time series trait of <strong class="source-inline">TabularDataset</strong>, something that allows you to perform time-based filtering of the dataset.</li>
			</ul>
			<p>To get some hands-on<a id="_idIndexMarker520"/> experience with this, you can define a <strong class="source-inline">FileDataset</strong> that references the CSV file you uploaded in the default datastore in the previous section. Although CSV represents tabular data, it is also a file, something that <strong class="source-inline">FileDataset</strong> can referenc:. </p>
			<ol>
				<li value="1">In a new cell in your notebook, type the following code:<p class="source-code">from azureml.core import Dataset</p><p class="source-code">dstore = ws.get_default_datastore()</p><p class="source-code">file_paths = [</p><p class="source-code">    (dstore, "/samples/diabetes/v1")</p><p class="source-code">]</p><p class="source-code">file_ds = Dataset.File.from_files(</p><p class="source-code">    path = file_paths, validate=True</p><p class="source-code">)</p><p class="source-code">print("Files in FileDataset:")</p><p class="source-code">print(file_ds.to_path())</p><p>In this code snippet, there is a reference to the default datastore of the workstation. </p></li>
				<li>Now, you can create an array of tuples of <strong class="source-inline">Datastore</strong> and its relative paths. Each tuple references a file or a folder within a specific <strong class="source-inline">Datastore</strong>. In this case, you are referencing the <strong class="source-inline">samples/diabetes/v1</strong> folder within the default <strong class="source-inline">Datastore</strong>. You can use the wildcard character, <strong class="source-inline">*</strong>, to load multiple subfolders or partial filenames if you want. For example, the following array of tuples loads all the CSV files of all the months in 2021 of the weather data that's stored in <strong class="source-inline">/weather/&lt;year&gt;/&lt;month&gt;/&lt;day&gt;.csv</strong>:<p class="source-code">file_paths = [</p><p class="source-code">    (dstore, "/weather/2021/*/*.csv")</p><p class="source-code">]</p></li>
				<li>If you wanted to<a id="_idIndexMarker521"/> explicitly load the data for the first day (<strong class="source-inline">01.csv</strong>) of January (<strong class="source-inline">01</strong>), February (<strong class="source-inline">02</strong>), and March (<strong class="source-inline">03</strong>) only, then you would use the following array of tuples:<p class="source-code">file_paths = [</p><p class="source-code">    (dstore, "/weather/2021/01/01.csv"),</p><p class="source-code">    (dstore, "/weather/2021/02/01.csv"),</p><p class="source-code">    (dstore, "/weather/2021/03/01.csv")</p><p class="source-code">]</p><p>It is advised to keep the array's size to less than 100 data path references per dataset for performance reasons.</p></li>
				<li>Returning to the code snippet at the beginning of this section, you can now create an unregistered <strong class="source-inline">FileDataset</strong> using the <strong class="source-inline">from_files()</strong> method. Here, you must pass the array of data paths as an argument. You must also validate whether the data can be loaded or not via the method. If the folder did not exist or the datastore was protected with private endpoints and was not directly accessible from the compute that is executing the code, you will get <strong class="source-inline">DatasetValidationError</strong>. The default value of the <strong class="source-inline">validate</strong> argument is <strong class="source-inline">True</strong>, and you can disable that validation by passing <strong class="source-inline">False</strong> in that argument.</li>
				<li>Once you have created <strong class="source-inline">FileDataset</strong>, you can get a list of files that were referenced by invoking the <strong class="source-inline">to_path()</strong> method. The output of these two prints should look as follows:<p class="figure-caption"> </p><div id="_idContainer193" class="IMG---Figure"><img src="Images/B16777_07_020.jpg" alt="Figure 7.20 – Unregistered FileDataset referencing a single CSV file&#13;&#10;" width="984" height="874"/></div><p class="figure-caption">Figure 7.20 – Unregistered FileDataset referencing a single CSV file</p></li>
				<li>For the CSV files, a far better <a id="_idIndexMarker522"/>approach would be to define a <strong class="source-inline">TabularDataset</strong> that could parse the file and provide us with a pandas <strong class="source-inline">DataFrame</strong>. To do so, copy the following code in a new cell:<p class="source-code">tabular_dataset = Dataset.Tabular.from_delimited_files(</p><p class="source-code">    path=file_paths, validate=False)</p><p class="source-code">df = tabular_dataset.to_pandas_dataframe()</p><p class="source-code">print(len(df))</p><p>In this snippet, you are reusing the <strong class="source-inline">file_paths</strong> properties that you used while creating <strong class="source-inline">FileDataset</strong>. This time, you are creating an unregistered <strong class="source-inline">TabularDataset</strong> using the <strong class="source-inline">from_delimited_files()</strong> method. Also, note that you explicitly skip the validation so that the data can be loaded from the current compute (<strong class="source-inline">validate=False</strong>), speeding up the declaration process.</p><p><strong class="bold">Datasets</strong> do not load the data by default unless you are explicitly invoking a method that requires the actual data. In this case, your code will reach out to the datastore, load the data in memory as a pandas <strong class="source-inline">DataFrame</strong>, and assign it to the <strong class="source-inline">df</strong> variable when you invoke the <strong class="source-inline">to_pandas_dataframe()</strong> method. Upon calling the <strong class="source-inline">len()</strong> method, you get the number of rows that <strong class="source-inline">DataFrame</strong> has.</p></li>
				<li>So far, the datasets<a id="_idIndexMarker523"/> that you have created have been unregistered, meaning that they did not register within the AzureML workspace, nor were they listed in the <strong class="bold">Datasets</strong> section of the studio web portal. If you want to reuse a dataset in multiple experiments, you can register it in the workspace using the <strong class="source-inline">register()</strong> method: <p class="source-code">tabular_dataset.register(</p><p class="source-code">    workspace=ws,</p><p class="source-code">    name="diabetes",</p><p class="source-code">    description="The sklearn diabetes dataset")</p><p class="callout-heading">Important note</p><p class="callout">If you have already registered a dataset with the same name, you will not be able to rerun this cell. To register a new version of the dataset you must use the <strong class="source-inline">create_new_version</strong> argument as follows: <strong class="source-inline">tabular_dataset.register(workspace=ws, name="diabetes", create_new_version=True)</strong></p><p>This method requires you to specify the workspace where you want to register <strong class="source-inline">TabularDataset</strong> and the name of the registration. Optionally, you can pass a description, tags, and whether to create a new version of the dataset with the specific name that is already registered in the workspace. Once the dataset has been registered, you can review the registration information in the Studio web UI, as shown in the following screenshot:</p><div id="_idContainer194" class="IMG---Figure"><img src="Images/B16777_07_021.jpg" alt="Figure 7.21 – Registered tabular dataset in the workspace&#13;&#10;" width="836" height="815"/></div><p class="figure-caption">Figure 7.21 – Registered tabular dataset in the workspace</p></li>
				<li>If, instead of <strong class="source-inline">TabularDataset</strong>, you have a pandas <strong class="source-inline">DataFrame</strong> that you want to register, you can use the <strong class="source-inline">register_pandas_dataframe()</strong> method, as shown<a id="_idIndexMarker524"/> in the following code snippet:<p class="source-code">Dataset.Tabular.register_pandas_dataframe(</p><p class="source-code">    dataframe=df,</p><p class="source-code">    target=(dstore,"/samples/diabetes"),</p><p class="source-code">    name="diabetes",</p><p class="source-code">    description="The sklearn diabetes dataset")</p><p>Note that in this snippet, you are passing the <strong class="source-inline">df</strong> pandas <strong class="source-inline">DataFrame</strong> reference and that you are requesting to store that <strong class="source-inline">DataFrame</strong> in the default datastore that is referenced by the <strong class="source-inline">dstore</strong> variable, in the <strong class="source-inline">/samples/diabetes</strong> folder. This method will create a new folder with a GUID name and store the data in Parquet file format. Since the dataset has already been registered and points to a different path, the command will create a new version of the dataset. In the Studio experience, you will notice that <strong class="bold">Version 2</strong> of the dataset was registered. This version has a different <strong class="bold">relative path</strong>, as shown here:</p><div id="_idContainer195" class="IMG---Figure"><img src="Images/B16777_07_022.jpg" alt="Figure 7.22 – New version of the diabetes dataset, registered directly from a pandas DataFrame&#13;&#10;" width="839" height="833"/></div><p class="figure-caption">Figure 7.22 – New version of the diabetes dataset, registered directly from a pandas DataFrame</p><p>Note that the <a id="_idIndexMarker525"/>Parquet file format is a compressed one, which leads to smaller files compared to the CSV file you used for the first version of the dataset.</p></li>
				<li>Once you have registered a dataset, either <strong class="source-inline">FileDataset</strong> or <strong class="source-inline">TabularDataset</strong>, you can retrieve it using the <strong class="source-inline">get_by_name()</strong> method of the <strong class="source-inline">Dataset</strong> class using the following code snippet:<p class="source-code">from azureml.core import Dataset</p><p class="source-code">diabetes_dataset = Dataset.get_by_name(</p><p class="source-code">    workspace=ws,</p><p class="source-code">    name='diabetes')</p><p>Optionally, you can specify the <strong class="source-inline">version</strong> argument, which is <strong class="source-inline">latest</strong> by default.</p></li>
				<li>The preceding <a id="_idIndexMarker526"/>code snippet returns an instance of a <strong class="source-inline">TabularDataset</strong> class, but the data hasn't been loaded yet. You can load the dataset partially using various methods of the <strong class="source-inline">TabularDataset</strong> class, as shown in the following code snippet:<p class="source-code">partial_dataset = diabetes_dataset \</p><p class="source-code">        .skip(10) \</p><p class="source-code">        .take(2) \</p><p class="source-code">        .keep_columns(['0','target'])</p></li>
				<li><strong class="source-inline">partial_dataset</strong> is a <strong class="source-inline">TabularDataset</strong> instance that was created from <strong class="source-inline">diabetes_dataset</strong>. This dataset skips the first 10 rows of <strong class="source-inline">diabetes_dataset</strong>, keeps two rows, and then drops all the columns other than the columns named <strong class="source-inline">0</strong> and <strong class="source-inline">target</strong>. No data was loaded during the execution of this multiline statement. Having this unregistered <strong class="source-inline">partial_dataset</strong> dataset defined, you can load the data into a pandas <strong class="source-inline">DataFrame</strong> using the following code:<p class="source-code">df = partial_dataset.to_pandas_dataframe()</p><p class="source-code">df.head()</p><p>This will display a small table that consists of two rows and two columns, as shown in the following screenshot:</p></li>
			</ol>
			<div>
				<div id="_idContainer196" class="IMG---Figure">
					<img src="Images/B16777_07_023.jpg" alt="Figure 7.23 – Small DataFrame loaded from a sliced tabular dataset&#13;&#10;" width="320" height="171"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.23 – Small DataFrame loaded from a sliced tabular dataset</p>
			<p>This lazy<a id="_idIndexMarker527"/> loading capability of the AzureML dataset classes gives you the flexibility to slice and dice huge datasets without having to load them in memory.</p>
			<p>So far, you have learned how to work with the Python SDK to deploy compute targets, define datastores, and create datasets. In the next section, you will learn how to perform similar actions using the Azure CLI tool you saw in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>, in the <em class="italic">Using the Azure CLI</em> section.</p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor113"/>Working with the AzureML CLI extension</h1>
			<p>In <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>, you learned how to use the <a id="_idIndexMarker528"/>Azure CLI and how to install the <strong class="source-inline">azure-cli-ml</strong> extension. This extension uses the Python SDK you saw in this chapter to perform various operations. To work with the Azure CLI, you can do one of the following:</p>
			<ol>
				<li value="1">Open the cloud shell in the Azure portal, as you did in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>.</li>
				<li>Open a terminal in the compute instance you have been working on in this chapter.</li>
				<li>Use the shell assignment feature of Jupyter notebooks, which allows you to execute commands using the underlying shell by using an exclamation mark (<strong class="bold">!</strong>), also known<a id="_idIndexMarker529"/> as <strong class="bold">bang</strong>.</li>
			</ol>
			<p>In this section, you will use the notebook, something that will allow you to store the steps and repeat them if you need them in the future:</p>
			<ol>
				<li value="1">The first thing you will need to do is install the <strong class="source-inline">azure-cli-ml</strong> extension in the Azure CLI of the compute instance you are currently working on. Create a new code cell in the notebook you have been editing so far and add the following code:<p class="source-code">! az extension add -n azure-cli-ml</p><p>Note that in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>, you executed the same command, without the exclamation prefix. The output of this <a id="_idIndexMarker530"/>command should be similar to the following:</p><p class="figure-caption"> </p><div id="_idContainer197" class="IMG---Figure"><img src="Images/B16777_07_024.jpg" alt="Figure 7.24 – Installing the AzureML extension&#13;&#10;" width="1086" height="331"/></div><p class="figure-caption">Figure 7.24 – Installing the AzureML extension</p></li>
				<li>Then, you will need to log in using the <strong class="source-inline">az login</strong> command. This command will trigger a device authentication process, similar to the one you used at the beginning of this chapter when you first tried to connect to the workspace through the SDK. Run the following command:<p class="source-code">! az login</p></li>
				<li>If you have access to multiple Azure subscriptions, you will need to select the one you are targeting using the following code snippet:<p class="source-code">! az account set --subscription "&lt;subscription id&gt;"</p><p>From this point on, you can use the AzureML CLI to perform operations against the workspace.</p><p class="callout-heading">Important note</p><p class="callout">If you have multiple AzureML workspaces within your subscription, you will need to specify which workspace and in which resource group you are targeting each AzureML CLI command. To do that, you will need to use the <strong class="source-inline">-g</strong> and <strong class="source-inline">-w</strong> parameters, which we looked at in <a href="B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Azure Machine Learning Workspace Resources</em>.</p></li>
				<li>To list all the compute targets in your workspace, use the following code snippet:<p class="source-code">! az ml computetarget list -g packt-azureml-rg -w packt-learning-mlw -o table</p></li>
				<li>You can then update <strong class="source-inline">cpu-sm-cluster</strong> so that it has 0 minimum nodes using the following command:<p class="source-code">! az ml computetarget update amlcompute --name cpu-sm-cluster --min-nodes 0 -g packt-azureml-rg -w packt-learning-mlw</p></li>
				<li>To get the <a id="_idIndexMarker531"/>default datastore that is registered in the workspace, you can use the following command:<p class="source-code">! az ml datastore show-default -g packt-azureml-rg -w packt-learning-mlw</p></li>
				<li>Finally, you can list the datasets registered in the workspace using the following snippet:<p class="source-code">! az ml dataset list -g packt-azureml-rg -w packt-learning-mlw -o table</p><p>The results of this command should be similar to the following:</p></li>
			</ol>
			<div>
				<div id="_idContainer198" class="IMG---Figure">
					<img src="Images/B16777_07_025.jpg" alt="Figure 7.25 – Table-formatted output of the datasets listing within the AzureML CLI&#13;&#10;" width="975" height="254"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.25 – Table-formatted output of the datasets listing within the AzureML CLI</p>
			<p>The AzureML<a id="_idIndexMarker532"/> CLI offers full access to the SDK options, including the ability to create and detach compute targets, datastores, and even define datasets. For the exam, you won't need to memorize the commands, so long as you have understood that the CLI is using the SDK under the hood and that most of the things you can do with the SDK have an equivalent CLI command.</p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor114"/>Summary</h1>
			<p>In this chapter, you learned how the AzureML Python SDK is structured. You also discovered the AzureML notebook editor, which allows you to code Python scripts. You then worked with the SDK. You started your coding journey by managing the compute targets that are attached to the AzureML workspace. You then attached new datastores and got a reference to existing ones, including the default datastore for the workspace. Then, you worked with various files and tabular-based datasets and learned how to reuse them by registering them in the workspace.</p>
			<p>Finally, you worked with the AzureML CLI extension, which is a client that utilizes the Python SDK you explored in this chapter.</p>
			<p>In the next chapter, you will build on top of this knowledge and learn how to use the AzureML SDK during the data science experimentation phase. You will also learn how to track metrics on your data science experiments, as well as how to scale your training into bigger computes, by running scripts in compute clusters.</p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor115"/>Questions</h1>
			<p>Please answer the following questions to check your knowledge of the topics that were discussed in this chapter:</p>
			<ol>
				<li value="1">What is the default minimum number of nodes for an AzureML compute cluster?<p>a. 0</p><p>b. 1</p><p>c. Equal to the maximum number of nodes</p></li>
				<li>You upload a CSV file to the default datastore that contains credit card transaction details. Which of the following methods should you use to create a dataset reference? <p>a. <strong class="source-inline">Dataset.File.from_files()</strong></p><p>b. <strong class="source-inline">Dataset.Tabular.from_delimited_files()</strong></p><p>c. <strong class="source-inline">Workspace.from_csv_files()</strong></p><p>d. <strong class="source-inline">Datastore.from_csv_files()</strong></p></li>
				<li>How can you force the creation of a blob container during the registration process of an Azure blob-based datastore?<p>a. Pass the <strong class="source-inline">force_create=True</strong> parameter to the <strong class="source-inline">Datastore.register_azure_blob_container()</strong> method.</p><p>b. Pass the <strong class="source-inline">create_if_not_exists=True</strong> parameter to the <strong class="source-inline">Datastore.register_azure_blob_container()</strong> method.</p><p>c. Pass the <strong class="source-inline">force_create=True</strong> parameter to the <strong class="source-inline">Datastore.register_container()</strong> method.</p><p>b. Pass the <strong class="source-inline">create_if_not_exists=True</strong> parameter to the <strong class="source-inline">Datastore.register_container()</strong> method.</p></li>
			</ol>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor116"/>Further reading</h1>
			<p>This section offers a list of useful web resources that will help you augment your knowledge of the AzureML SDK and the various third-party libraries that were used in this chapter:</p>
			<ul>
				<li>Supported data storage service types in AzureML: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data#supported-data-storage-service-types">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data#supported-data-storage-service-types</a></li>
				<li>Reference to the <strong class="bold">pandas</strong> <strong class="source-inline">DataFrame</strong> API: <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a></li>
				<li>Reference to the diabetes dataset that was loaded from the scikit-learn library: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html">https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html</a></li>
				<li>AzureML SDK Python API browser, which lists all packages, classes, and methods: <a href="https://docs.microsoft.com/en-us/Python/api/?view=azure-ml-py">https://docs.microsoft.com/en-us/Python/api/?view=azure-ml-py</a></li>
				<li>Reference to the AzureML CLI extension: <a href="https://docs.microsoft.com/cli/azure/ml(v1)?view=azure-cli-latest">https://docs.microsoft.com/cli/azure/ml(v1)?view=azure-cli-latest</a></li>
				<li>Free e-book – Learn Python Programming – Second Edition: <a href="https://www.packtpub.com/free-ebook/learn-Python-programming-second-edition/9781788996662">https://www.packtpub.com/free-ebook/learn-Python-programming-second-edition/9781788996662</a></li>
			</ul>
		</div>
	</div></body></html>