["```py\n    from azureml.core import Workspace\n    ws = Workspace.from_config()\n    diabetes_ds = ws.datasets['diabetes']\n    training_data, validation_data =\\\n    diabetes_ds.random_split(percentage = 0.8)\n    X_train =\\\n    training_data.drop_columns('target').to_pandas_dataframe()\n    y_train =\\\n    training_data.keep_columns('target').to_pandas_dataframe()\n    X_validate =\\\n    validation_data.drop_columns('target').to_pandas_dataframe()\n    y_validate =\\\n    validation_data.keep_columns('target').to_pandas_dataframe()\n    ```", "```py\n        import os\n        import joblib\n        os.makedirs('./outputs', exist_ok=True)\n        model_file_name = f'model_{nrmse:.4f}_{alpha:.4f}.pkl'\n        joblib.dump(value=model,\n                filename=os.path.join('./outputs/',model_file_name))\n        ```", "```py\nfrom azureml.core import Workspace, Experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name=\"chapter08\")\n```", "```py\nrun = exp.start_logging()\nprint(run.get_details())\n```", "```py\nrun.log(\"nrmse\", 0.01)\nrun.log(name=\"nrmse\", value=0.015, description=\"2nd measure\")\n```", "```py\n    run.log_list(\"accuracies\", [0.5, 0.57, 0.62])\n    ```", "```py\n    run.log_table(\"table\", {\"x\":[1, 2], \"y\":[0.1, 0.2]})\n    run.log_row(\"table\", x=3, y=0.3)\n    ```", "```py\nchild_run = run.child_run()\nchild_run.log(\"child_metric\", 0.01)\nchild_run.parent.log(\"metric_from_child\", 0.02)\n```", "```py\nchild_run.cancel()\nrun.complete()\nprint(run.get_status())\n```", "```py\n    import shutil\n    try:\n      shutil.rmtree(\"./outputs\")\n    except FileNotFoundError: \n      pass\n    ```", "```py\n    from sklearn.linear_model import LassoLars\n    from sklearn.metrics import mean_squared_error\n    def train_and_evaluate(alpha, X_t, y_t, X_v, y_v):\n      model = LassoLars(alpha=alpha)\n      model.fit(X_t, y_t)\n      predictions = model.predict(X_v)\n      rmse = mean_squared_error(predictions, y_v, squared = False)\n      range_y_validate = y_v.to_numpy().ptp()\n      nrmse = rmse/range_y_validate\n      print(f\"NRMSE: {nrmse}\")\n      return model, nrmse\n    trained_model, model_nrmse = train_and_evaluate(0.1, \n                            X_train, y_train,\n                            X_validate, y_validate) \n    ```", "```py\n    def train_and_evaluate(log and log_row methods to log the NRMSE metric of the trained model.Important noteIf you cannot type the *α* letter shown in the preceding example, you can use the *a* character instead.\n    ```", "```py\n    from azureml.core import Workspace, Experiment\n    ws = Workspace.from_config()\n    exp = Experiment(workspace=ws, name=\"chapter08\")\n    with exp.start_logging() as run:\n        print(run.get_portal_url())\n        for a in [0.001, 0.01, 0.1, 0.25, 0.5]:\n            train_and_evaluate(run, a, \n                                X_train, y_train,\n                                X_validate, y_validate)\n    ```", "```py\nimport mlflow\ndef train_and_evaluate(alpha, X_t, y_t, X_v, y_v):\n  model = LassoLars(alpha=alpha)\n  model.fit(X_t, y_t)\n  predictions = model.predict(X_v)\n  rmse = mean_squared_error(predictions, y_v, squared = False)\n  range_y_validate = y_v.to_numpy().ptp()\n  nrmse = rmse/range_y_validate\n  mlflow.log_metric(\"nrmse\", nrmse)\n  return model, nrmse\nmlflow.set_experiment(\"chapter08-mlflow\")\nwith mlflow.start_run():\n    mlflow.sklearn.autolog()\n    trained_model, model_nrmse = train_and_evaluate(0.1, \n                                    X_train, y_train,\n                                    X_validate, y_validate)\n```", "```py\nimport mlflow\nfrom azureml.core import Workspace\nws = Workspace.from_config()\nmlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\nmlflow.set_experiment(\"chapter08-mlflow\")\nwith mlflow.start_run():\n    mlflow.sklearn.autolog()\n    trained_model, model_nrmse = train_and_evaluate(0.1, \n                                    X_train, y_train,\n                                    X_validate, y_validate)\n```", "```py\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument('--greet-name', type=str, \n                    dest='name', help='The name to greet')\nargs = parser.parse_args()\nname = args.name\nprint(f\"Hello {name}!\")\n```", "```py\npython greeter.py --greet-name packt\n```", "```py\nfrom azureml.core import Workspace, Experiment\nfrom azureml.core import ScriptRunConfig\nws = Workspace.from_config()\ntarget = ws.compute_targets['cpu-sm-cluster']\nscript = ScriptRunConfig(\n    source_directory='greeter-job',\n    script='greeter.py',\n    compute_target=target,\n    arguments=['--greet-name', 'packt']\n)\nexp = Experiment(ws, 'greet-packt')\nrun = exp.submit(script)\nprint(run.get_portal_url())\nrun.wait_for_completion(show_output=True)\n```", "```py\n*.amltmp\n.amlignore\n```", "```py\nfrom azureml.widgets import RunDetails\nrun = exp.submit(script)\nRunDetails(run).show()\n```", "```py\nrun.get_details_with_logs()\n```", "```py\n    from azureml.core import Environment\n    minimal_env =\\\n    Environment.get(ws, name=\"AzureML-Minimal\")\n    print(minimal_env.name, minimal_env.version)\n    print(minimal_env.Python.conda_dependencies.serialize_to_string())\n    ```", "```py\n    from azureml.core import Experiment, ScriptRunConfig\n    target = ws.compute_targets['cpu-sm-cluster']\n    script = ScriptRunConfig(\n        source_directory='greeter-job',\n        script='greeter.py',\n        environment argument in the ScriptRunConfig constructor.\n    ```", "```py\nStatus: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_<something>:latest\n```", "```py\n    import argparse\n    Banner method from the asciistuff open source Python package. This method is used in the last print. This will output a fancy os module, which allows you to read the environment variables using the os.environ.get() method. The code tries to read the environment variable named GREET_HEADER, and if it is not defined, the default value, Message:, is assigned to the greet_header variable, which is printed before the banner message.Important noteIf you try to execute the modified `greeter.py` in a terminal within your AzureML *compute instance*, it will fail because you don't have the `asciistuff` package installed. To install it in your compute instance, you can use the `pip install asciistuff` command.\n    ```", "```py\n    name: banner-env\n    dependencies:\n    - python=3.6.2\n    - pip:\n      - asciistuff==1.2.1 \n    ```", "```py\n    from azureml.core import Environment\n    banner_env = Environment.from_conda_specification(\n                     name = \"banner-env\",\n                     file_path = \"greeter-banner-job.yml\")\n    banner_env.environment_variables[\"GREET_HEADER\"] = \\\n                                     \"Env. var. header:\"\n    ```", "```py\n    script = ScriptRunConfig(\n        source_directory='ScriptRunConfig::*   The source directory has changed to point to the `greeter-banner-job` folder, which contains the updated script.*   The environment argument is specified, passing your very own defined `banner_env` environment. \n    ```", "```py\nfrom azureml.core.run import Run\nrun = Run.get_context()\n```", "```py\nws = run.experiment.workspace\n```", "```py\npython training.py --alpha 0.1\n```", "```py\nfrom azureml.core import Workspace\nfrom azureml.core.run import Run, _OfflineRun\nrun = Run.get_context()\nws = None\nif type(run) == _OfflineRun:\n    ws = Workspace.from_config()\nelse:\n    ws = run.experiment.workspace\n```", "```py\nfrom sklearn.linear_model import LassoLars\nfrom sklearn.metrics import mean_squared_error\nfrom azureml.core import Workspace\nfrom azureml.core.run import Run, _OfflineRun\nimport argparse\nimport os\nimport joblib\n```", "```py\nparser = argparse.ArgumentParser()\nparser.add_argument('--alpha', type=float, \n                  dest='alpha', help='The alpha parameter')\nargs = parser.parse_args()\n```", "```py\nrun = Run.get_context()\nws = None\nif type(run) == _OfflineRun:\n    ws = Workspace.from_config()\nelse:\n    ws = run.experiment.workspace\n```", "```py\ndiabetes_ds = ws.datasets['diabetes']\ntraining_data, validation_data = \\\n               diabetes_ds.random_split(\n                            percentage = 0.8, seed=1337)\nX_train = training_data.drop_columns('target') \\\n                       .to_pandas_dataframe()\ny_train = training_data.keep_columns('target') \\\n                       .to_pandas_dataframe()\nX_validate = validation_data.drop_columns('target') \\\n                            .to_pandas_dataframe()\ny_validate = validation_data.keep_columns('target') \\\n                            .to_pandas_dataframe()\n```", "```py\ndef train_and_evaluate(run, alpha, X_t, y_t, X_v, y_v):\n  model = LassoLars(alpha=alpha)\n  model.fit(X_t, y_t)\n  predictions = model.predict(X_v)\n  rmse = mean_squared_error(predictions,y_v,squared=False)\n  range_y_validate = y_v.to_numpy().ptp()\n  nrmse = rmse/range_y_validate\n  run.log(\"nrmse\", nrmse)\n  run.log_row(\"nrmse over α\", α=alpha, nrmse=nrmse)\n  return model, nrmse\n```", "```py\nmodel, nrmse = train_and_evaluate(run, args.alpha,\n                  X_train, y_train, X_validate, y_validate)\n```", "```py\nos.makedirs('./outputs', exist_ok=True)\nmodel_file_name = 'model.pkl'\njoblib.dump(value=model, filename=\n           os.path.join('./outputs/',model_file_name))\n```", "```py\n!pip show scikit-learn\n```", "```py\nimport sklearn\nprint(sklearn.__version__)\n```", "```py\nfrom azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies \nimport sklearn\ndiabetes_env = Environment(name=\"diabetes-training-env\")\ndiabetes_env.Python.conda_dependencies = CondaDependencies()\ndiabetes_env.Python.conda_dependencies.add_conda_package(\n                   f\"scikit-learn=={sklearn.__version__}\")\ndiabetes_env.python.conda_dependencies.add_pip_package(\"azureml-dataprep[pandas]\")\n```", "```py\ndiabetes_env.Python.conda_dependencies = \\\nCondaDependencies.create(\n      conda_packages=[\n                   f\"scikit-learn=={sklearn.__version__}\"],\n      pip_packages=[\"azureml-defaults\", \"azureml-dataprep[pandas]\"])\n```", "```py\nimport joblib\ndiabetes_env.Python.conda_dependencies.add_pip_package(f\"joblib=={joblib.__version__}\")\n```", "```py\nfrom azureml.core import Workspace, Experiment\nfrom azureml.core import ScriptRunConfig\nws = Workspace.from_config()\ntarget = ws.compute_targets['cpu-sm-cluster']\nscript = ScriptRunConfig(\n    source_directory='diabetes-training',\n    script='training.py',\n    environment=diabetes_env,\n    compute_target=target,\n    arguments=['--alpha', 0.01]\n)\nexp = Experiment(ws, 'chapter08-diabetes')\nrun = exp.submit(script)\nrun.wait_for_completion(show_output=True)\n```"]