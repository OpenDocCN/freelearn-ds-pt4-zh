["```py\nhd_config = HyperDriveConfig(\n             run_config=script,\n             primary_metric_name=\"nrmse\",\n             primary_metric_goal=PrimaryMetricGoal.MINIMIZE\n             ,…)\nexperiment = Experiment(ws, \"chapter09-hyperdrive\")\nhyperdrive_run = experiment.submit(hd_config)\n```", "```py\nchoice('selu','relu')\n```", "```py\nchoice(0.001, 0.01, 0.1, 0.25, 0.5)\n```", "```py\n    from azureml.train.hyperdrive import GridParameterSampling\n    from azureml.train.hyperdrive import choice\n    param_sampling = GridParameterSampling( {\n            \"a\": choice(0.01, 0.5),\n            \"b\": choice(10, 100)\n        }\n    )\n    ```", "```py\n    from azureml.core import (\n        Workspace, Environment\n    )\n    from azureml.core.conda_dependencies import \\\n         CondaDependencies \n    import sklearn\n    ws = Workspace.from_config()\n    diabetes_env = Environment(name=»diabetes-training-env»)\n    diabetes_env.python.conda_dependencies = \\\n         CondaDependencies.create(\n          conda_packages=[\n              f\"scikit-learn=={sklearn.__version__}\"],\n          pip_packages=[\"azureml-defaults\",\n                        \"azureml-dataprep[pandas]\"])\n    target = ws.compute_targets['cpu-sm-cluster'] \n    ```", "```py\n    from azureml.core import ScriptRunConfig\n    script = ScriptRunConfig(\n        source_directory='diabetes-training',\n        script='training.py',\n        environment=diabetes_env,\n        compute_target=target\n    )\n    ```", "```py\n    from azureml.train.hyperdrive import HyperDriveConfig\n    from azureml.train.hyperdrive import (\n       RandomParameterSampling, uniform, PrimaryMetricGoal\n    )\n    param_sampling = RandomParameterSampling({\n            'alpha': uniform(0.00001, 0.1),\n        }\n    )\n    hd_config = HyperDriveConfig(\n                   run_config=script,                          \n                   hyperparameter_sampling=param_sampling,\n                   primary_metric_name=\"nrmse\", \n                   primary_metric_goal=                   \n                              PrimaryMetricGoal.MINIMIZE,\n                   max_total_runs=20,\n                   max_concurrent_runs=4)\n    ```", "```py\n    from azureml.core import Experiment\n    experiment = Experiment(ws, \"chapter09-hyperdrive\")\n    hyperdrive_run = experiment.submit(hd_config)\n    hyperdrive_run.wait_for_completion(show_output=True)\n    ```", "```py\nfrom azureml.core.run import Run\nimport argparse\nimport time\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--a\", type=int, dest=\"a\", help=\"The alpha parameter\")\nparser.add_argument(\"--b\", type=int, dest=\"b\", help=\"The beta parameter\")\nargs = parser.parse_args()\nif (args.a > 2):\n    args.a = 0\nrun = Run.get_context()\ndef fake_train(run, a, b):\n    time.sleep(5)\n    metric = a + b\n    run.log(\"fake_metric\", metric)\nfor epoch in range(20):\n    fake_train(run, args.a * epoch, args.b)\n```", "```py\n    from azureml.train.hyperdrive import (\n        GridParameterSampling,    \n        choice,\n        MedianStoppingPolicy,\n        HyperDriveConfig,\n        PrimaryMetricGoal\n    )\n    param_sampling = GridParameterSampling(\n        {\n            \"a\": choice(1, 2, 3, 4),\n            \"b\": choice(1, 2, 3, 4),\n        }\n    )\n    early_termination_policy = MedianStoppingPolicy(\n        evaluation_interval=1, delay_evaluation=5\n    )\n    hd_config = HyperDriveConfig(\n        policy=early_termination_policy,\n        run_config=script,\n        hyperparameter_sampling=param_sampling,\n        primary_metric_name=\"fake_metric\",\n        primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n        max_total_runs=50,\n        max_concurrent_runs=4\n    )\n    ```", "```py\n    experiment = Experiment(ws, \"chapter09-hyperdrive\")\n    hyperdrive_run = experiment.submit(hd_config)\n    hyperdrive_run.wait_for_completion(show_output=True)\n    ```", "```py\nfrom azureml.core import Workspace, Dataset\nfrom azureml.train.automl import AutoMLConfig\nws = Workspace.from_config()\ncompute_target = ws.compute_targets[\"cpu-sm-cluster\"]\ndiabetes_dataset = Dataset.get_by_name(workspace=ws, name='diabetes')\ntrain_ds,validate_ds = diabetes_dataset.random_split(percentage=0.8, seed=1337)\nexperiment_config = AutoMLConfig(\n    task = \"regression\",\n    primary_metric = 'normalized_root_mean_squared_error',\n    training_data = train_ds,\n    label_column_name = \"target\",\n    validation_data = validate_ds,\n    compute_target = compute_target,\n    experiment_timeout_hours = 0.25,\n    iterations = 4\n)\n```", "```py\nfrom azureml.core.experiment import Experiment\nmy_experiment = Experiment(ws, 'chapter09-automl-experiment')\nrun = my_experiment.submit(experiment_config, \n                           show_output=True)\n```", "```py\nbest_run, best_model = run.get_output()\n```", "```py\nbest_run = run.get_output()[0]\nbest_model = run.get_output()[1]\n```", "```py\nbest_model.steps\n```", "```py\nprint(best_model.named_steps['datatransformer'] \\\n                 .get_featurization_summary())\nfeature_names=best_model.named_steps['datatransformer'] \\\n                 .get_engineered_feature_names()\nprint(\"Engineered feature names:\")\nprint(feature_names)\n```"]