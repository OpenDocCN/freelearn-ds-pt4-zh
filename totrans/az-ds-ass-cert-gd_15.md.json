["```py\n    from azureml.core import Workspace, Experiment\n    ws = Workspace.from_config()\n    loans_ds = ws.datasets['loans']\n    experiment = Experiment(ws, \"chapter-12-train\")\n    ```", "```py\n    training_data, validation_data = loans_ds.random_split(\n                           percentage = 0.8, seed=42)\n    X_train = training_data.drop_columns('approved_loan') \\\n                .to_pandas_dataframe()\n    y_train = training_data.keep_columns('approved_loan') \\\n                .to_pandas_dataframe().values.ravel()\n    X_validate = validation_data.drop_columns('approved_loan') \\\n                    .to_pandas_dataframe()\n    y_validate = validation_data.keep_columns('approved_loan') \\\n                    .to_pandas_dataframe().values.ravel()\n    ```", "```py\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import accuracy_score\n    run = experiment.start_logging()\n    sk_model = LogisticRegression()\n    sk_model.fit(X_train, y_train)\n    y_predicted = sk_model.predict(X_validate)\n    accuracy = accuracy_score(y_validate, y_predicted)\n    print(accuracy)\n    run.log(\"accuracy\", accuracy)\n    run.complete()\n    ```", "```py\n    import os\n    import joblib\n    os.makedirs('./model', exist_ok=True)\n    joblib.dump(value=sk_model,\n                filename=\n                  os.path.join('./model/','model.joblib'))\n    ```", "```py\n    from sklearn import __version__ as sk_version\n    from azureml.core import Model\n    run.upload_folder(\"model\", \"./model\")\n    model = run.register_model(\n            model_name=\"chapter12-loans\",\n            model_path=\"./model/\",\n            tags={ \"accuracy\": accuracy},\n            properties={ \"accuracy\": accuracy},\n            model_framework= Model.Framework.SCIKITLEARN,\n            model_framework_version= sk_version,\n            datasets=[(\"training\", loans_ds)]\n    )\n    ```", "```py\n    from azureml.core import Model\n    offline_model = Model.register(\n            ws,\n            model_name=\"chapter12-pre-trained-loans\",\n            model_path=\"./model/\",\n            properties={\"accuracy\": 0.828},\n            model_framework= \"ScikitLearn\",\n            model_framework_version= \"0.22.2.post1\"\n    ) \n    ```", "```py\n    from sklearn.linear_model import RidgeClassifier\n    new_model = RidgeClassifier(solver='svd')\n    new_model.fit(X_train, y_train)\n    y_predicted = new_model.predict(X_validate)\n    accuracy = accuracy_score(y_validate, y_predicted)\n    registered_model = Model(ws, name=\"chapter12-loans\")\n    r_version = registered_model.version\n    r_acc = float(registered_model.properties['accuracy'])\n    if accuracy > r_acc:\n        print(f\"New model has better accuracy {accuracy}\")\n    else:\n        print(f\"Registered model with version {r_version}\" \\\n               \" has better accuracy {r_acc}\")\n    ```", "```py\n    import shutil\n    shutil.rmtree('./model',ignore_errors=True)\n    ```", "```py\n    from azureml.core import Workspace, Model\n    ws = Workspace.from_config()\n    model = Model(ws, name=\"chapter12-loans\")\n    ```", "```py\n    no_code_service = Model.deploy(ws, \"no-code-loans\",\n                                   [model])\n    no_code_service.wait_for_deployment(show_output=True)\n    ```", "```py\n    print(no_code_service.scoring_uri)\n    ```", "```py\n    {\"data\": [[2000,2,45]]}\n    ```", "```py\n    import json\n    input_payload = json.dumps({\n        'data': [[2000, 2, 45], [2000, 9, 45]],\n        'method': 'predict'\n    })\n    output = no_code_service.run(input_payload)\n    print(output)\n    ```", "```py\n    {'predict': [0, 1]}\n    ```", "```py\n    {'predict_proba': [[0.998, 0.002], [0.173, 0.827]]}\n    ```", "```py\n    no_code_service.delete()\n    ```", "```py\n    from azureml.core import Environment\n    from azureml.core.conda_dependencies import CondaDependencies \n    import sklearn\n    myEnv= Environment(name=\"sklearn-inference\")\n    myEnv.Python.conda_dependencies = CondaDependencies()\n    myEnv.Python.conda_dependencies.add_conda_package(\n                   f\"scikit-learn=={sklearn.__version__}\")\n    myEnv.Python.conda_dependencies.add_pip_package(\n                   \"azureml-defaults>=1.0.45\")\n    ```", "```py\n    from azureml.core.model import InferenceConfig\n    inference_config = InferenceConfig(\n                          source_directory= \"./script\",\n                          entry_script='score.py', \n                          environment=myEnv)\n    ```", "```py\n    from azureml.core.webservice import AciWebservice\n    deployment_config = AciWebservice.deploy_configuration(\n                        cpu_cores=1, memory_gb=1)\n    service = Model.deploy(ws, \"aci-loans\", [model], \n                    inference_config, deployment_config)\n    service.wait_for_deployment(show_output=True)\n    ```", "```py\n    import json\n    input_payload = json.dumps({\n        'data': [[2000, 2, 45]]\n    })\n    output = service.run(input_payload)\n    print(output)\n    ```", "```py\n    service.delete()\n    ```", "```py\n    from azureml.core.webservice import LocalWebservice\n    deployment_config = LocalWebservice.deploy_configuration(port=1337)\n    service = Model.deploy(ws, \"local-loans\", [model], inference_config, deployment_config)\n    service.wait_for_deployment()\n    ```", "```py\n    loans_ds = ws.datasets['loans']\n    prof_df = loans_ds.drop_columns('approved_loan') \\\n                            .to_pandas_dataframe()\n    prof_df['sample_request'] = \\\n        \"{'data':[[\" + prof_df['income'].map(str) \\\n      + \",\"+ prof_df['credit_cards'].map(str) \\\n      + \",\" + prof_df['age'].map(str) + \"]]}\"\n    prof_df = prof_df[['sample_request']]\n    prof_df.head()\n    ```", "```py\n    {\"data\": [[2000,2,45]]}\n    ```", "```py\n    from azureml.core import Dataset\n    dstore = ws.get_default_datastore()\n    loan_req_ds = Dataset.Tabular.register_pandas_dataframe(\n        dataframe=prof_df,\n        target=(dstore,\"/samples/loans-requests\"),\n        name=\"loans-requests\",\n        description=\"Sample requests for the loans model\")\n    ```", "```py\n    profile = Model.profile(ws,\n                  'chapter12-loan',\n                  [model], inference_config,\n                  input_dataset=loan_req_ds,\n                  cpu=2, memory_in_gb=1)\n    profile.wait_for_completion(True)\n    print(profile.get_details())\n    ```", "```py\nfrom azureml.core.webservice import AciWebservice\ndeployment_config = AciWebservice.deploy_configuration(\n   cpu_cores=1, memory_gb=0.5, enable_app_insights= True)\nservice = Model.deploy(ws, \"aci-loans\", [model], inference_config, deployment_config)\nservice.wait_for_deployment(show_output=True) \n```", "```py\nservice.update(enable_app_insights=True)\n```", "```py\nimport json\ninput_payload = json.dumps({'data': [[2000, 2, 45], [2000, 9, 45]]})\nfor x in range(10):\n   print(service.run(input_payload))\n```", "```py\nservice.delete()\n```", "```py\n{\"data\":[{\"income\": 2000, \"credit_cards\": 2, \"age\": 45}]}\n```", "```py\nimport os\nimport joblib\nfrom inference_schema.schema_decorators import input_schema, output_schema\nimport pandas as pd\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\nimport numpy as np\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n```", "```py\ndef init():\n    global model\n    model_path = os.path.join(os.getenv(\\\n\"AZUREML_MODEL_DIR\"), \"model/model.joblib\")\n    model = joblib.load(model_path)\n```", "```py\ndata_sample = pd.DataFrame(\n    {\n        \"income\": pd.Series([2000.0], dtype=\"float64\"),\n        \"credit_cards\": pd.Series([1], dtype=\"int\"),\n        \"age\": pd.Series([25], dtype=\"int\")\n    }\n)\noutput_sample = np.array([0])\n```", "```py\n@input_schema(\"data\", PandasParameterType(data_sample))\n@output_schema(NumpyParameterType(output_sample))\ndef run(data):\n    try:\n        result = model.predict(data)\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n```", "```py\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.webservice import AciWebservice\nmyEnv.Python.conda_dependencies.add_pip_package(\"inference_schema[pandas-support]>=1.1.0\")\ninference_config = InferenceConfig(source_directory= \"./script\", entry_script='score_v2.py', environment=myEnv)\ndeployment_config = AciWebservice.deploy_configuration( cpu_cores=1, memory_gb=0.5)\nservice = Model.deploy(ws, \"aci-loans\", [model], inference_config, deployment_config)\nservice.wait_for_deployment(show_output=True)\n```", "```py\nimport json\nservice = ws.webservices['aci-loans']\ninput_payload = json.dumps({\"data\":[\n    {\"income\": 2000,\"credit_cards\": 2,\"age\": 45},\n    {\"income\": 2000, \"credit_cards\": 9,\"age\": 45}\n]})\nprint(service.run(input_payload))\ninput_payload = json.dumps({'data': [\n    [2000, 2, 45], [2000, 9, 45]\n]})\nprint(service.run(input_payload))\n```", "```py\nservice.delete()\n```", "```py\n    from azureml.core import Workspace\n    ws = Workspace.from_config()\n    loans_ds = ws.datasets['loans']\n    compute_target = ws.compute_targets['cpu-sm-cluster']\n    ```", "```py\n    from azureml.core import Dataset\n    loans_df = loans_ds.drop_columns('approved_loan') \\  \n                       .to_pandas_dataframe()\n    for x in range(10):\n        loans_df = loans_df.append(loans_df)\n    dstore = ws.get_default_datastore()\n    pending_loans_ds =\\\n    Dataset.Tabular.register_pandas_dataframe(\n        dataframe=loans_df,\n        target=(dstore,\"/samples/pending-loans\"),\n        name=\"pending-loans\",\n        description=\"Pending loans to be processed\")\n    ```", "```py\n    from azureml.core import Model\n    import joblib\n    def init():\n        global model\n        model_path = Model.get_model_path(\"chapter12-loans\")\n        model = joblib.load(model_path)\n    def run(mini_batch):\n        print(mini_batch.info())\n        mini_batch[\"approved\"] = model.predict(mini_batch)\n        return mini_batch.values.tolist()\n    ```", "```py\n    [7298, 2, 35, 1]\n    [4698, 7, 70, 0]\n    ```", "```py\n    def init():\n        print('Load model here')\n    def run(mini_batch):\n        output = []\n        for file_path in mini_batch:\n            output.append([file_path, 0])\n        return output\n    ```", "```py\n    ['/path/sample_cat.jpg', 0]\n    ['/path/sample_dog.jpg', 1]\n    ```", "```py\n    from azureml.core import Environment\n    from azureml.core.conda_dependencies import CondaDependencies \n    import sklearn\n    pEnv= Environment(name=\"sklearn-parallel\")\n    pEnv.Python.conda_dependencies = CondaDependencies()\n    pEnv.Python.conda_dependencies.add_conda_package(f\"scikit-learn=={sklearn.__version__}\")\n    pEnv.Python.conda_dependencies.add_pip_package(\"azureml-core\")\n    pEnv.Python.conda_dependencies.add_pip_package(\"azureml-dataset-runtime[pandas,fuse]\")\n    ```", "```py\n    from azureml.pipeline.steps import ParallelRunConfig\n    parallel_run_config = ParallelRunConfig(\n        source_directory='pipeline_step',\n        entry_script='tabular_batch.py',\n        mini_batch_size='100Kb',\n        error_threshold=-1,\n        output_action='append_row',\n        append_row_file_name=\"loans_outputs.txt\",\n        environment=pEnv,\n        compute_target=compute_target, \n        node_count=1,\n        process_count_per_node=2\n    )\n    ```", "```py\n    from azureml.data import OutputFileDatasetConfig\n    datastore = ws.get_default_datastore()\n    step_output = OutputFileDatasetConfig(\n        name= \"results_store\",\n        destination=(datastore, '/inferences/loans/'))\n    ```", "```py\n    from azureml.pipeline.steps import ParallelRunStep\n    parallel_step = ParallelRunStep(\n        name='chapter12-parallel-loans',\n        inputs=[pending_loans_ds.as_named_input('loans')],\n        output=step_output,\n        parallel_run_config=parallel_run_config,\n        allow_reuse=False\n    )\n    ```", "```py\n    from azureml.core import Experiment\n    from azureml.pipeline.core import Pipeline\n    pipeline = Pipeline(workspace=ws, steps=[parallel_step])\n    pipeline_run = Experiment(ws, 'chapter12-parallel-run').submit(pipeline)\n    ```", "```py\n    from azureml.widgets import RunDetails\n    RunDetails(pipeline_run).show()\n    ```", "```py\n    pipeline_run.wait_for_completion(show_output=True)\n    ```"]