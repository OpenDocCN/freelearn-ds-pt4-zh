<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer049">&#13;
			<h1 id="_idParaDest-158" class="chapter-number"><a id="_idTextAnchor694"/>10</h1>&#13;
			<h1 id="_idParaDest-159"><a id="_idTextAnchor695"/>Deploying a FastAPI Project</h1>&#13;
			<p>Building a good application is great, but it’s even better if customers can enjoy it. In this chapter, you’ll look at different techniques and the best practices for deploying your FastAPI application to make it available on the web. First, you’ll learn how to structure your project to make it ready for deployment by using environment variables to set the configuration options you need, as well as by managing your dependencies properly with <strong class="source-inline">pip</strong>. Once that’s done, we’ll show you three ways to deploy your application: with a serverless cloud platform, with a Docker container, and with a traditional <span class="No-Break">Linux server.</span></p>&#13;
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>&#13;
			<ul>&#13;
				<li>Setting and using <span class="No-Break">environment variables</span></li>&#13;
				<li>Managing <span class="No-Break">Python dependencies</span></li>&#13;
				<li>Deploying a FastAPI application on a <span class="No-Break">serverless platform</span></li>&#13;
				<li>Deploying a FastAPI application <span class="No-Break">with Docker</span></li>&#13;
				<li>Deploying a FastAPI application on a <span class="No-Break">traditional server</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-160"><a id="_idTextAnchor696"/>Technical requirements</h1>&#13;
			<p>For this chapter, you’ll require a Python virtual environment, just as we set up in <a href="B19528_01.xhtml#_idTextAnchor024"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Python Development </em><span class="No-Break"><em class="italic">Environment Setup</em></span><span class="No-Break">.</span></p>&#13;
			<p>You’ll find all the code examples for this chapter in the dedicated GitHub repository <span class="No-Break">at </span><span class="No-Break">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10</span><span class="No-Break">.</span></p>&#13;
			<h1 id="_idParaDest-161"><a id="_idTextAnchor697"/>Setting and using environment variables</h1>&#13;
			<p>Before<a id="_idIndexMarker708"/> dee<a id="_idTextAnchor698"/>p-divin<a id="_idTextAnchor699"/>g into the different deployment techniques, we<a id="_idIndexMarker709"/> need to structure our application to enable reliable, fast, and secure deployments. One of the key things in this process is handling configuration variables: a database URL, an external API token, a debug flag, and so on. When handling those variables, it’s necessary to handle them dynamically instead of hardcoding them into your source <span class="No-Break">code. Why?</span></p>&#13;
			<p>First of all, those variabl<a id="_idTextAnchor700"/>es wi<a id="_idTextAnchor701"/>ll likely be different in your local environment and in production. Typically, your database URL will point to a local database on your computer while developing but will point to a proper production database in production. This is even more pertinent if you want to have other environments such as a staging or pre-production environment. Furthermore, if we need to change one of the values, we’ll have to change the code, commit it, and deploy it again. Thus, we need a convenient mechanism to set <span class="No-Break">those values.</span></p>&#13;
			<p>Secondly, it’s unsafe to write those values in your code. Values such as database connection strings or API tokens are extremely sensitive. If they appear in your code, they’ll likely be committed to your repository: they can be read by anyone who has access to your repository, which causes obvious <span class="No-Break">security issues.</span></p>&#13;
			<p>To solve this, we usually <a id="_idIndexMarker710"/>use <strong class="bold">environment variables</strong>. Environment<a id="_idIndexMarker711"/> variables are values that aren’t set in the program itself but in the whole operating system. Most programming languages have the required functions to read those variables from the system. You can try this very easily in a Unix <span class="No-Break">command line:</span></p>&#13;
			<pre class="source-code">&#13;
$ export MY_ENVIRONMENT_VARIABLE="Hello" # Set a temporary variable on the system$ python&#13;
&gt;&gt;&gt; import os&#13;
&gt;&gt;&gt; os.getenv("MY_ENVIRONMENT_VARIABLE")  # Get it in Python&#13;
'Hello'</pre>&#13;
			<p>In the Python source code, we can get the value dynamically from the system. During deployment, we’ll only have to make sure that we set the correct environment variables on the server. This way, we can easily change a value without redeploying the code and have several deployments of our application containing different configurations sharing the same source code. However, bear in mind that sensitive values that have been set in environment variables can still leak if you don’t pay attention – for example, in log files or error <span class="No-Break">stack traces.</span></p>&#13;
			<p>To help us with this task, we’ll use a very convenient feature of Pydantic: settings management. This allows us to structure and use our configuration variables as we do for any other data model. It even takes care of automatically retrieving the values from <span class="No-Break">environment variables!</span></p>&#13;
			<p>For the <a id="_idTextAnchor702"/>res<a id="_idTextAnchor703"/>t of this chapter, we’ll work with an application that you can find in <strong class="source-inline">chapter10/project</strong> within our example repository. It’s a simple FastAPI application that uses SQLAlchemy, very similar to the one we reviewed in the <em class="italic">Communicating with a SQL database with the SQLAlchemy ORM</em> section of <a href="B19528_06.xhtml#_idTextAnchor346"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Databases and </em><span class="No-Break"><em class="italic">Asynchronous ORMs</em></span><span class="No-Break">.</span></p>&#13;
			<p class="callout-heading">Running the commands from the project directory</p>&#13;
			<p class="callout">If you cloned the example repository, be sure to run the commands shown in this chapter from the <strong class="source-inline">project</strong> directory. On the command line, simply type <span class="No-Break"><strong class="source-inline">cd chapter10/project</strong></span><span class="No-Break">.</span></p>&#13;
			<p>To structure a<a id="_idIndexMarker712"/> settings model, all you need to do is create a class that<a id="_idIndexMarker713"/> inherits from <strong class="source-inline">pydantic.BaseSettings</strong>. The following example shows a configuration class with a debug flag, an environment name, and a <span class="No-Break">database URL:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">settings.py</p>&#13;
			<pre class="source-code">&#13;
from pydantic import BaseSettingsclass Settings(BaseSettings):&#13;
    debug: bool = False&#13;
    environment: str&#13;
    database_url: str&#13;
    class Config:&#13;
        env_file = ".env"&#13;
settings = Settings()</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/settings.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/settings.py</a></p>&#13;
			<p>As you can see, creating this class is very similar to creating a standard Pydantic model. We can even define default values, as we did for <span class="No-Break"><strong class="source-inline">debug</strong></span><span class="No-Break"> here.</span></p>&#13;
			<p>To use it, w<a id="_idTextAnchor704"/>e<a id="_idIndexMarker714"/> on<a id="_idTextAnchor705"/>ly have to create an instance of this class. We<a id="_idIndexMarker715"/> can then import it wherever we need it in our project. For example, here is how to retrieve the database URL to create our <span class="No-Break">SQLAlchemy engine:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">database.py</p>&#13;
			<pre class="source-code">&#13;
from project.settings import settingsengine = create_async_engine(settings.database_url)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/database.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/database.py</a></p>&#13;
			<p>We also use the <strong class="source-inline">debug</strong> flag to print all the settings in the <strong class="source-inline">lifespan</strong> event <span class="No-Break">at startup:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">app.py</p>&#13;
			<pre class="source-code">&#13;
@contextlib.asynccontextmanagerasync def lifespan(app: FastAPI):&#13;
    if settings.debug:&#13;
        print(settings)&#13;
    yield</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/app.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/app.py</a></p>&#13;
			<p>Since our application is designed to work with SQLAlchemy, we also took care of initializing a database migration environment with Alembic, as we showed in <a href="B19528_06.xhtml#_idTextAnchor346"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Databases and Asynchronous ORMs</em>. The difference here is that we use our <strong class="source-inline">settings</strong> object to dynamically configure the database URL; instead of hardcoding it in <strong class="source-inline">alembic.ini</strong>, we can set it from our settings in <strong class="source-inline">env.py</strong>, as you can <span class="No-Break">see here:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">env.py</p>&#13;
			<pre class="source-code">&#13;
config.set_main_option(    "sqlalchemy.url", settings.database_url.replace("+aiosqlite", "")&#13;
)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/alembic/env.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/alembic/env.py</a></p>&#13;
			<p>Notice that we take care of manually removing the <strong class="source-inline">aiosqlite</strong> driver part of the URL. Indeed, as we mentioned previously, Alembic is designed to work synchronously, so we need to pass it a standard URL. Now, we can generate migrations from our development database and apply them in production without changing anything in our <span class="No-Break">Alembic configuration!</span></p>&#13;
			<p>The good thing <a id="_idIndexMarker716"/>with this <strong class="source-inline">Settings</strong> model is that it works just like <a id="_idIndexMarker717"/>any other Pydantic model: it automatically parses the values it finds in environment variables and raises an error if one value is missing in your environment. This way, you can ensure you don’t forget any values directly when the app starts. You can test this behavior by running <span class="No-Break">the application:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ uvicorn project.app:apppydantic.error_wrappers.ValidationError: 2 validation errors for Settings&#13;
environment&#13;
  field required (type=value_error.missing)&#13;
database_url&#13;
  field required (type=value_error.missing)</pre>&#13;
			<p>We have a clear list of the missing variables. Let’s set those variables in our environment and <span class="No-Break">try again:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ export DEBUG="true" ENVIRONMENT="development" DATABASE_URL="sqlite+aiosqlite:///chapter10_project.db"(venv) $ uvicorn project.app:app&#13;
INFO:     Started server process [34880]&#13;
INFO:     Waiting for application startup.&#13;
debug=True environment='development' database_url='sqlite+aiosqlite:///chapter10_project.db'&#13;
INFO:     Application startup complete.&#13;
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)</pre>&#13;
			<p>The<a id="_idIndexMarker718"/> <a id="_idTextAnchor706"/>application s<a id="_idTextAnchor707"/>tarted! You can even see that our lifespan<a id="_idIndexMarker719"/> handler printed our settings values. Notice that Pydantic is case-insensitive (by default) when retrieving environment variables. By convention, environment variables are usually set in all caps on <a id="_idTextAnchor708"/><span class="No-Break">the system.</span></p>&#13;
			<h2 id="_idParaDest-162">Using a .env f<a id="_idTextAnchor709"/>ile</h2>&#13;
			<p>In local development, it’s a <a id="_idIndexMarker720"/>bit annoying to set environment variables by hand, especially if you’re working on several projects at the same time on your machine. To solve this, Pydantic allows you to read the values from a <strong class="source-inline">.env</strong> file. This file contains a simple list of environment variables and their associated values. It’s usually easier to edit and manipulate <span class="No-Break">during development.</span></p>&#13;
			<p>To make this work, we’ll need a new library, <strong class="source-inline">python-dotenv</strong>, whose task is to parse those <strong class="source-inline">.env</strong> files. You can install it as usual with the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install python-dotenv</pre>			<p>To enable this feature, notice how we added the <strong class="source-inline">Config</strong> subclass with the <span class="No-Break"><strong class="source-inline">env_file</strong></span><span class="No-Break"> property:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">settings.py</p>&#13;
			<pre class="source-code">&#13;
class Settings(BaseSettings):    debug: bool = False&#13;
    environment: str&#13;
    database_url: str&#13;
    class Config:&#13;
        env_file = ".env"</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/settings.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/project/settings.py</a></p>&#13;
			<p>By doing this, we <a id="_idIndexMarker721"/>simply tell Pydantic to look for environment variables set in a file named <strong class="source-inline">.env</strong>, if <span class="No-Break">it’s available.</span></p>&#13;
			<p>Fi<a id="_idTextAnchor710"/>nally, you can create your <strong class="source-inline">.env</strong> file at the root of the project with the <span class="No-Break">following content:</span></p>&#13;
			<pre class="source-code">&#13;
DEBUG=trueENVIRONMENT=development&#13;
DATABASE_URL=sqlite+aiosqlite:///chapter10_project.db</pre>&#13;
			<p>And that’s it! The values will now be read from this <strong class="source-inline">.env</strong> file. If the file is missing, <strong class="source-inline">Settings</strong> will try to read them from the environment variables as usual. Of course, this is only for convenience while developing: this file <em class="italic">shouldn’t be committed</em> and you should rely on <em class="italic">properly set environment variables in production</em>. To ensure you don’t commit this file by accident, it’s usually recommended that you add it to your <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">gitignore</strong></span><span class="No-Break"> file.</span></p>&#13;
			<p class="callout-heading">Creating hidden files such as .env files</p>&#13;
			<p class="callout">In Unix <a id="_idTextAnchor711"/>systems, <a id="_idTextAnchor712"/>files starting with a dot, such as <strong class="source-inline">.env</strong>, are considered hidden files. If you try to create them from the operating system’s file explorer, it might show you warnings or even prevent you from doing so. Thus, it’s usually more convenient to create them from your IDE, such as Visual Studio Code, or from the command line by executing the following command: <span class="No-Break"><strong class="source-inline">touch .env</strong></span><span class="No-Break">.</span></p>&#13;
			<p>Great! Our <a id="_idIndexMarker722"/>application now supports dynamic configuration variables, which are now easy to set and change on our deployment platforms. Another important thing to take care of is dependencies: we’ve installed quite a lot of them at this point, but we must make sure they are installed properly <span class="No-Break">durin<a id="_idTextAnchor713"/>g deployments!</span></p>&#13;
			<h1 id="_idParaDest-163">Managing Python dependen<a id="_idTextAnchor714"/>cies</h1>&#13;
			<p>Throughout this book, we’ve<a id="_idIndexMarker723"/> installed libraries using <strong class="source-inline">pip</strong> to add some useful features to our application: FastAPI, of course, but also SQLAlchemy, pytest, and so on. When deploying a project to a new environment, such as a production server, we have to make sure all those dependencies are installed for our application to work properly. This is also true if you have colleagues that also need to work on the project: they need to know the dependencies they must install on <span class="No-Break">their machines.</span></p>&#13;
			<p>Fortunately, <strong class="source-inline">pip</strong> comes with a solution for this so that we don’t have to remember all this in our heads. Indeed, most Python projects define a <strong class="source-inline">requirements.txt</strong> file, which contains a list of all Python dependencies. It usually lives at the root of your project. <strong class="source-inline">pip</strong> has a special option for reading this file and installing all the <span class="No-Break">needed dependencies.</span></p>&#13;
			<p>When you already have a working environment, such as the one we’ve used since the beginning of this book, people usually recommend that you run the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip freezeaiosqlite==0.17.0&#13;
alembic==1.8.1&#13;
anyio==3.6.2&#13;
argon2-cffi==21.3.0&#13;
argon2-cffi-bindings==21.2.0&#13;
asgi-lifespan==2.0.0&#13;
asyncio-redis==0.16.0&#13;
attrs==22.1.0&#13;
...</pre>&#13;
			<p>The result of <strong class="source-inline">pip freeze</strong> is a list of <em class="italic">every Python package currently installed in your environment</em>, along with their corresponding versions. This list can be directly used in the <span class="No-Break"><strong class="source-inline">requirements.txt</strong></span><span class="No-Break"> file.</span></p>&#13;
			<p>The problem with this approach is that it lists every package, including the sub-dependencies of the libraries you install. Said another way, in this list, you<a id="_idTextAnchor715"/>’ll see packages that you don’t directly use but that are needed by the ones you installed. If, for some reason, you decide to not use a library anymore, you’ll be able to remove it, but it’ll be very hard to guess which sub-dependencies it has installed. In the long term, your <strong class="source-inline">requirements.txt</strong> file will grow larger and larger, with lots of dependencies that are useless in <span class="No-Break">your project.</span></p>&#13;
			<p>To solve this, some people recommend that you <em class="italic">manually maintain your </em><strong class="source-inline">requirements.txt</strong><em class="italic"> file</em>. With this approach, you have to list yourself all the libraries you use, along with their respective versions. During installation, <strong class="source-inline">pip</strong> will take care of installing the sub-dependencies, but they’ll never appear in <strong class="source-inline">requirements.txt</strong>. This way, when you remove<a id="_idIndexMarker724"/> one of your dependencies, you make sure any useless packages are <span class="No-Break">not kept.</span></p>&#13;
			<p>In the following example, you can see the <strong class="source-inline">requirements.txt</strong> file for the project we are working on in <span class="No-Break">this chapter:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">requirements.txt</p>&#13;
			<pre class="source-code">&#13;
aiosqlite==0.17.0alembic==1.8.1&#13;
fastapi==0.88.0&#13;
sqlalchemy[asyncio]==1.4.44&#13;
uvicorn[standard]==0.20.0&#13;
gunicorn==20.1.0</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/requirements.txt">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/requirements.txt</a></p>&#13;
			<p>As you can see, the list is much shorter! Now, whenever we install a new dependency, our responsibility is to add it manually <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">requirements.txt</strong></span><span class="No-Break">.</span></p>&#13;
			<p class="callout-heading">A word on alternate package managers such as Poetry, Pipenv, and Conda</p>&#13;
			<p class="callout">While exploring the Python community, you may hear about alternate<a id="_idTextAnchor716"/> pack<a id="_idTextAnchor717"/>age<a id="_idTextAnchor718"/> managers such as Poetry, Pipenv, and Conda. These managers were created to solve some issues posed by <strong class="source-inline">pip</strong>, especially related to sub-dependency management. While they are very good tools, lots of cloud platforms expect a traditional <strong class="source-inline">requirements.txt</strong> file to specify the dependencies, rather than those more modern tools. Therefore, they may not be the best choice for a <span class="No-Break">FastAPI application.</span></p>&#13;
			<p>The <strong class="source-inline">requirements.txt</strong> file should be <a id="_idIndexMarker725"/>committed along with your source code. When you need to install the dependencies on a new computer or server, you’ll simply need to run <span class="No-Break">this command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install -r requirements.t<a id="_idTextAnchor719"/>xt</pre>			<p>Of course, make sure that you’re working on proper virtual environments when doing this, as we described in <a href="B19528_01.xhtml#_idTextAnchor024"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Python Development </em><span class="No-Break"><em class="italic">Environment Setup</em></span><span class="No-Break">.</span></p>&#13;
			<p>You have probably noticed the <strong class="source-inline">gunicorn</strong> dependency in <strong class="source-inline">requirements.txt</strong>. Let’s look at what it is and<a id="_idTextAnchor720"/> why <span class="No-Break">it’s needed.</span></p>&#13;
			<h2 id="_idParaDest-164"><a id="_idTextAnchor721"/>Adding Gunicorn as a server process for deployment</h2>&#13;
			<p>In <a href="B19528_02.xhtml#_idTextAnchor032"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Python Programming<a id="_idTextAnchor722"/> Specificities</em>, we briefly introduced the WSGI and ASGI protocols. They define <a id="_idIndexMarker726"/>the norm and data structure for building web servers in Python. Traditional Python web frameworks, such as Django and Flask, rely on the WSGI protocol. ASGI appeared recently and is presented as the “spiritual successor” of WSGI, providing a protocol for developing web servers running asynchronously. This protocol is at the heart of FastAPI <span class="No-Break">and Starlette.</span></p>&#13;
			<p>As we mentioned in <a href="B19528_03.xhtml#_idTextAnchor058"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Developing RESTful APIs with FastAPI</em>, we use <em class="italic">Uvicorn</em> to run our FastAPI applications: its role is to accept HTTP requests, transform them according to the ASGI protocol, and pass them to the FastAPI application, which returns an ASGI-compliant response object. Then, Uvicorn can form a proper HTTP response from <span class="No-Break">this object.</span></p>&#13;
			<p>In the WSGI world, the most widely used server is <em class="italic">Gunicorn</em>. It has the same role in the context of a Django or Flask application. Why are we talking about it, then? Gunicorn has lots of refinements and features that make it more robust and reliable in production than Uvicorn. However, Gunicorn is designed to work for WSGI applications. So, what can <span class="No-Break">we do?</span></p>&#13;
			<p>Actually, we can use both: Gunicorn will be used as a robust process manager for our production server. However, we’ll specify a special worker class provided by Uvicorn, which will allow us to run ASGI applications such as FastAPI. This is the recommended way of doing deployments in t<a id="_idTextAnchor723"/>he official Uvicorn <a id="_idIndexMarker727"/><span class="No-Break">documentation: </span><a href="https://www.uvicorn.org/deployment/#using-a-process-manager"><span class="No-Break">https://www.uvicorn.org/deployment/#using-a-process-manager</span></a><span class="No-Break">.</span></p>&#13;
			<p>So, let’s install Gunicorn to our dependencies by using the following command (remember to add it to your <span class="No-Break"><strong class="source-inline">requirements.txt</strong></span><span class="No-Break"> file):</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install gunicorn</pre>			<p>If you wish, you can try to run our FastAPI project using Gunicorn by using the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ gunicorn -w 4 -k uvicorn.workers.UvicornWorker proje<a id="_idTextAnchor724"/>ct.app:app</pre>			<p>Its usage is quite similar to Uvicorn, except that we tell it to use a Uvicorn worker. Once again, this is necessary to make it work with an ASGI application. Also, notice the <strong class="source-inline">-w</strong> option. This allows us to set the number of workers to launch for our server. Here, we launch four instances of our application. Then, Gunicorn takes care of load-balancing the incoming requests between each worker. This is what makes Gunicorn more robust: if, for any reason, your application blocks the event loop with a synchronous operation, other workers will be <a id="_idIndexMarker728"/>able to process other requests while this <span class="No-Break">is happening.</span></p>&#13;
			<p>Now, we are ready to deploy our FastAPI application! In the next section, you’ll learn how to deploy one on a <a id="_idTextAnchor725"/><span class="No-Break">serverless platform.</span></p>&#13;
			<h1 id="_idParaDest-165"><a id="_idTextAnchor726"/>Deploying a FastAPI application on a serverless platform</h1>&#13;
			<p>In recent years,<a id="_idTextAnchor727"/> serv<a id="_idTextAnchor728"/>erless platforms <a id="_idIndexMarker729"/>have gained a lot of <a id="_idIndexMarker730"/>popularity and have become a very common way to deploy web applications. Those platforms completely hide the complexity of setting up and managing a server, giving you the tools to automatically build and deploy your application in minutes. Google App Engine, Heroku, and Azure App Service are among the most popular. Even though they have their own specificities, all these serverless platforms work on the same principles. This is why, in this section, we’ll outline the common steps you <span class="No-Break">should follow.</span></p>&#13;
			<p>Usually, serverless platforms<a id="_idIndexMarker731"/> expect you to provide the <a id="_idIndexMarker732"/>source code in the form of a GitHub repository, which you push directly to their servers or which they pull automatically from GitHub. Here, we’ll assume that you have a GitHub repository with the source code structured <span class="No-Break">like so:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer048" class="IMG---Figure">&#13;
					<img src="Images/B19528_10_01.jpg" alt="Figure 10.1 – Project structure for serverless deployment" width="471" height="722"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – Project structure for serverless deployment</p>&#13;
			<p>Here are the<a id="_idIndexMarker733"/> general steps you should follow to <a id="_idIndexMarker734"/>deploy your projects on this kind <span class="No-Break">of platform:</span></p>&#13;
			<ol>&#13;
				<li>Create an account on a cloud platform of your choice. You must do this before you can start any work. It’s worth noting that most cloud platforms offer free credits when you are getting started so that you can try their serv<a id="_idTextAnchor729"/>ices <span class="No-Break">for f<a id="_idTextAnchor730"/>ree.</span></li>&#13;
				<li>Install the necessary command-line tools. Most cloud providers supply a complete CLI for managing their services. Typically, this is required for deploying your application. Here are the <a id="_idIndexMarker735"/>relevant documentation pages for the most popu<a id="_idTextAnchor731"/>lar <span class="No-Break">cloud providers:</span><ul><li>Google <span class="No-Break">Cloud: </span><a href="https://cloud.google.com/sdk/gcloud"><span class="No-Break">https://cloud.google.com/sdk/gcloud</span></a></li><li>Microsoft <span class="No-Break">Azure: </span><a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli"><span class="No-Break">https://docs.microsoft.com/en-us/cli/azu<span id="_idTextAnchor732"/>re/install-azure-cli</span></a></li><li><span class="No-Break">Heroku: </span><span class="No-Break">https://devcenter.heroku.com<a id="_idTextAnchor733"/>/articles/heroku<a id="_idTextAnchor734"/>-cli</span></li></ul></li>&#13;
				<li>Set up the application configuration. Depending on the platform, you’ll either have to create a configuration file or use the CLI or the web interface to do this. Here are the <a id="_idIndexMarker736"/>relevant documentation pages for the most popular <span class="No-Break">cloud <a id="_idTextAnchor735"/>providers:</span><ul><li>Google App Engine (configuration <span class="No-Break">file): </span><a href="https://cloud.google.com/appengine/docs/standard/python3/configuring-your-app-with-app-yaml"><span class="No-Break">https://cloud.google.com/appengine/docs/standard/python3/configuring-<span id="_idTextAnchor736"/>your<span id="_idTextAnchor737"/>-app-with-app-yaml</span></a></li><li>Azure App Service (web interface and CLI): <a href="https://docs.microsoft.com/en-us/azure/app-service/quickstart-python">https://docs.microsoft.com/en-us/azure/app-service/quickstart-python</a> <span class="No-Break">and </span><a href="https://docs.microsoft.com/en-us/azure/app-service/configure-language-python"><span class="No-Break">https://docs.microsoft.com/en-us/azure/app-service/conf<span id="_idTextAnchor738"/>igure-language-python</span></a></li><li>Heroku (configuration <a id="_idIndexMarker737"/><span class="No-Break">file): </span><a href="https://devcenter.heroku.com/articles/getting-started-with-python#define-a-procfile"><span class="No-Break">https://devcenter.heroku.com/articles/getting-started-with-python#define-a-procfile</span></a></li></ul></li>&#13;
			</ol>&#13;
			<p>The key point in this step is to correctly <em class="italic">set the startup command</em>. As we saw in the previous section, it’s essential to set the Uvicorn worker class using the <strong class="source-inline">gunicorn</strong> command, as well as set the correct path to your application.</p>&#13;
			<ol>&#13;
				<li value="4">Set the environment variables. Depending on the cloud provider, you should be able to do so during configuration or deployment. Remember that they are key for your application to work. Here are the<a id="_idIndexMarker738"/> relevant documentation pages for the most popular <span class="No-Break">clou<a id="_idTextAnchor739"/>d providers:</span><ul><li>Google App Engine (configuration <span class="No-Break">file): </span><a href="https://cloud.google.com/appengine/docs/standard/python/config/appref"><span class="No-Break">https://cloud.google.com/appengine/docs/stand<span id="_idTextAnchor740"/>ard/python/config/appref</span></a></li><li>Azure App Service (web <span class="No-Break">interface): </span><a href="https://docs.microsoft.com/en-us/azure/app-service/configure-common#configure-app-settings"><span class="No-Break">https://docs.microsoft.com/en-us/azure/app-service/configure-common<span id="_idTextAnchor741"/>#configure-app-settings</span></a></li><li>Heroku (CLI or web <span class="No-Break">interface): </span><a href="https://devcenter.heroku.com/articles/config-vars"><span class="No-Break">https://devcenter.heroku.com/articles/config-vars</span></a></li></ul></li>&#13;
				<li>Deploy the <a id="_idIndexMarker739"/>application. Some<a id="_idIndexMarker740"/> platforms can automatically<a id="_idTextAnchor742"/> deploy when<a id="_idTextAnchor743"/> they detect changes on a hosted repository, such as GitHub. Others require that you start deployment from the command-line tools. Here are the relevant documentation pages for the most popular <span class="No-Break">cl<a id="_idTextAnchor744"/>oud </span><span class="No-Break"><a id="_idIndexMarker741"/></span><span class="No-Break">providers:</span><ul><li>Google App Engine (<span class="No-Break">CLI): </span><a href="https://cloud.google.com/appengine/docs/standard/python3/testing-and-deploying-your-app#deploying_your_application"><span class="No-Break">https://cloud.google.com/appengine/docs/standard/python3/testing-and-deploying-your-app#deploying_y<span id="_idTextAnchor745"/>our_application</span></a></li><li>Azure App Service (continuous deployment or manual Git deployment): <a href="https://docs.microsoft.com/en-us/azure/app-service/deploy-continuous-deployment?tabs=github">https://docs.microsoft.com/en-us/azure/app-service/deploy-continuous-deployment?tabs=github</a> <span class="No-Break">and </span><a href="https://docs.microsoft.com/en-us/azure/app-service/deploy-local-git?tabs=cli%0D"><span class="No-Break">https://docs.microsoft.com/en-us/azure/app-service<span id="_idTextAnchor746"/>/deploy-local-git?tabs=cli</span></a></li><li>Heroku<a id="_idIndexMarker742"/> (<span class="No-Break">CLI): </span><a href="https://devcenter.heroku.com/articles/getting-started-with-python#deploy-the-app"><span class="No-Break">https://devcenter.heroku.com/articles/getting-started-with-python#deploy-the-app</span></a></li></ul></li>&#13;
			</ol>&#13;
			<p>Your application should now be live on the platform. Under the hood, most cloud platforms actually automatically build and deploy Docker containers while following the configuration you provide.</p>&#13;
			<p>They will make your application available on a generic subdomain such as <strong class="source-inline">myapplication.herokuapp.com</strong>. Of course, they also provide mechanisms for binding it to your own domain or subdomain. Here are the relevant<a id="_idIndexMarker743"/> documentation pages <a id="_idIndexMarker744"/>for the most popular<a id="_idIndexMarker745"/> cloud providers:</p>&#13;
			<ul>&#13;
				<li>Google App <span class="No-Break">Engine: </span><a href="https://cloud.google.com/appengine/docs/standard/python3/mapping-custom-domains"><span class="No-Break">https://cloud.google.com/appengine/docs/standard/python3/mapping-custom-domains</span></a></li>&#13;
				<li>Azure App <span class="No-Break">Service: </span><a href="https://docs.microsoft.com/en-us/azure/app-service/manage-custom-dns-migrate-domain%0D"><span class="No-Break">https://docs.microsoft.com/en-us/azure/app-service/manage-custom-dns-migrate-domain</span></a></li>&#13;
				<li><span class="No-Break">Heroku: </span><a href="https://devcenter.heroku.com/articles/custom-domains"><span class="No-Break">https://devcente<span id="_idTextAnchor747"/>r.heroku.com/articles/custom<span id="_idTextAnchor748"/>-domains</span></a></li>&#13;
			</ul>&#13;
			<h2 id="_idParaDest-166"><a id="_idTextAnchor749"/>Adding database servers</h2>&#13;
			<p>Most of the time, your application will be <a id="_idIndexMarker746"/>backed by a database engine, such as PostgreSQL. Fortunately, cloud providers propose fully managed databases, billed according to the computing power, memory, and storage you need. Once created, you’ll have access to a connection string to connect to the database instance. All you have to do then is set it in the environment variables of your application. Here are the relevant documentation pages for getting started with managed databases with th<a id="_idTextAnchor750"/>e most popular <span class="No-Break">cloud providers:</span></p>&#13;
			<ul>&#13;
				<li>Google <a id="_idIndexMarker747"/>Cloud <span class="No-Break">SQL: </span><a href="https://cloud.google.com/sql/docs/postgres/create-instance"><span class="No-Break">https://cloud.google.com/sql/docs/<span id="_idTextAnchor751"/>postgres/create-instance</span></a></li>&#13;
				<li>Azure Database for<a id="_idIndexMarker748"/> <span class="No-Break">PostgreSQL: </span><a href="https://docs.microsoft.com/en-us/azure/postgresql/quickstart-create-server-database-portal"><span class="No-Break">https://docs.microsoft.com/en-us/azure/postgresql/quickst<span id="_idTextAnchor752"/>art-create-server-database-portal</span></a></li>&#13;
				<li>Amazon <a id="_idIndexMarker749"/><span class="No-Break">RDS: </span><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_GettingStarted.html"><span class="No-Break">https://docs.aws.amazon.com/AmazonRDS/latest/<span id="_idTextAnchor753"/>UserGuide/CHAP_GettingStarted.html</span></a></li>&#13;
				<li>Heroku <a id="_idIndexMarker750"/><span class="No-Break">Postgres: </span><a href="https://devcenter.heroku.com/articles/heroku-postgresql%0D"><span class="No-Break">https://devcenter.heroku.com/articles/heroku-postgresql</span></a></li>&#13;
			</ul>&#13;
			<p>As we’ve seen, serverless <a id="_idIndexMarker751"/>platforms are the quickest and easiest way to deploy a FastAPI application. However, in some situations, you may wish to have more control of how things are deployed, or you may need system packages that are not available on serverless platforms. In those cases, it ma<a id="_idTextAnchor754"/>y be worthwhile to use a <span class="No-Break">Docker container.</span></p>&#13;
			<h1 id="_idParaDest-167"><a id="_idTextAnchor755"/>Deploying a FastAPI application with Docker</h1>&#13;
			<p>Docker<a id="_idIndexMarker752"/> is a widely used tec<a id="_idTextAnchor756"/>hnology for containerization. <strong class="bold">Containers</strong> are small, self-contained systems running on a <a id="_idIndexMarker753"/>computer. Each container contains all the files and configurations necessary for running a single application: a web server, a database engine, a data processing application, and so on. The main goal is to be able to run those applications without worrying about the dependency and version conflicts that often happen when trying to install and <a id="_idTextAnchor757"/>configure t<a id="_idTextAnchor758"/>hem on <span class="No-Break">the system.</span></p>&#13;
			<p>Besides, Docker<a id="_idIndexMarker754"/> containers are designed to be <em class="italic">portable and reproducible</em>: to creat<a id="_idTextAnchor759"/>e a Docker container, you simply have to write a <strong class="bold">Dockerfile</strong> containing<a id="_idIndexMarker755"/> all the necessary instructions to build the small system, along with <a id="_idIndexMarker756"/>all the files and configuration you need. Those instructions<a id="_idTextAnchor760"/> are executed during a <strong class="bold">build</strong>, which results in a Docker <strong class="bold">image</strong>. This image is a package containing your small system, ready to use, wh<a id="_idTextAnchor761"/>ich you can easily share on the internet through <strong class="bold">registries</strong>. Any developer who has a working Docker installation can then download this image and run it on their system in <span class="No-Break">a container.</span></p>&#13;
			<p>Docker has been quickly adopted by developers as it greatly eases the setup of complex development environments, allowing them to have several projects with different system package versions, all without worrying about their installation on their <span class="No-Break">local machine.</span></p>&#13;
			<p>However, Docker is not only for local development: it’s also widely used for deploying applications to production. Since the builds are reproducible, we can ensure that the local and production environments remain the same, which limits any issues when moving <span class="No-Break">to production.</span></p>&#13;
			<p>In this section, we’ll learn how to write a Dockerfile for a FastAPI application, how to build an i<a id="_idTextAnchor762"/>mage, and how to deploy it on a <span class="No-Break">clou<a id="_idTextAnchor763"/>d platform.</span></p>&#13;
			<h2 id="_idParaDest-168"><a id="_idTextAnchor764"/>Writing a Dockerfile</h2>&#13;
			<p>As we mentioned <a id="_idIndexMarker757"/>in the introduction to this <a id="_idIndexMarker758"/>section, a Dockerfile is a set of instructions for building your Docker image, a self-contained system containing all the required components to run your applications. To begin with, all Dockerfiles derive from a base image; usually, this is a standard Linux installation, such as Debian or Ubuntu. From this base, we can copy files from our local machine into the image (usually, the source code of our application) and execute Unix commands – for example, to install packages or <span class="No-Break">execute scripts.</span></p>&#13;
			<p>In our case, the creator of FastAPI has created a base Docker image that contains all the necessary tools to run a FastAPI app! All we have to do is start from this image, copy our source files, and install our dependencies! Let’s learn how to <span class="No-Break">d<a id="_idTextAnchor765"/>o that!</span></p>&#13;
			<p>First of all, you’ll need a working Docker installation on your machine. Follow the official <em class="italic">Getting Started</em> tutorial, which should guide you in this <span class="No-Break">proces<a id="_idTextAnchor766"/>s: </span><a href="https://docs.docker.com/get-started/"><span class="No-Break">https://docs.docker.com/get-started/</span></a><span class="No-Break">.</span></p>&#13;
			<p>To create a Docker image, we simply have to create a file named <strong class="source-inline">Dockerfile</strong> at the root of our project. The following example shows the content of this file for our <span class="No-Break">current project:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>&#13;
			<pre class="source-code">&#13;
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.10ENV APP_MODULE project.app:app&#13;
COPY requirements.txt /app&#13;
RUN pip install --upgrade pip &amp;&amp; \&#13;
    pip install -r /app/requirements.txt&#13;
COPY ./ /app</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/Dockerfile">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/Dockerfile</a></p>&#13;
			<p>Let’s go through <a id="_idIndexMarker759"/>each instruction. The first instruction, <strong class="source-inline">FROM</strong>, is the base image we derive from. Here, we took the <strong class="source-inline">uvicorn-gunicorn-fastapi</strong> image, which was created by the creator of FastAPI. Docker images have tags, which can be used to pick a specific version of the image. Here, we chose Python version 3.10. Lots of variations exist for this image, including ones with other versions of Python. You can check them out in the official README <span class="No-Break">file: </span><a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker"><span class="No-Break">https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker</span></a><span class="No-Break">.</span></p>&#13;
			<p>Then, we set the <strong class="source-inline">APP_MODULE</strong> environment variable thanks to the <strong class="source-inline">ENV</strong> instruction. In a Docker image, environment variables can be set at build time, as we did here, or at runtime. <strong class="source-inline">APP_MODULE</strong> is an environment variable defined by the base image. It should point to the path of your FastAPI application: it’s the same argument that we set at the end of Uvicorn and Gunicorn commands to launch the application. You can find the list of all the accepted environment variables for t<a id="_idTextAnchor767"/>he base image in the official <span class="No-Break">README file.</span></p>&#13;
			<p>Next, we have our first <strong class="source-inline">COPY</strong> statement. As you may have guessed, this instruction will copy a file from your local system to the image. Here, we only copied our <strong class="source-inline">requirements.txt</strong> file. We’ll explain why shortly. Notice that we copied the file into the <strong class="source-inline">/app</strong> directory of the image; it’s the main working directory defined by the <span class="No-Break">base image.</span></p>&#13;
			<p>We then have a <strong class="source-inline">RUN</strong> statement. This<a id="_idIndexMarker760"/> instruction is used to execute Unix commands. In our case, we ran <strong class="source-inline">pip</strong> to install our dependencies, following the <strong class="source-inline">requirements.txt</strong> file we just copied. This is essential to make sure all our Python dependencies <span class="No-Break">are present.</span></p>&#13;
			<p>Finally, we copied the rest of our source code files into the <strong class="source-inline">/app</strong> directory. Now, let’s explain why we separately copied <strong class="source-inline">requirements.txt</strong>. The important thing to understand is that Docker images are built using layers: each instruction will create a new layer in the build system. To improve performance, Docker does its best to reuse layers it has already built. Therefore, if it detects no changes from the previous build, it’ll reuse the ones it has in memory without <span class="No-Break">rebuilding them.</span></p>&#13;
			<p>By copying the <strong class="source-inline">requirements.txt</strong> file alone and installing the Python dependencies before the rest of the source code, we allow Docker to reuse the layer where the dependencies have been installed. If we edit our source code but not <strong class="source-inline">requirements.txt</strong>, the Docker build will only execute the last <strong class="source-inline">COPY</strong> instruction, reusing all the previous layers. Thus, the image is built in a few seconds instead <span class="No-Break">of minutes.</span></p>&#13;
			<p>Most of the time, Dockerfiles<a id="_idIndexMarker761"/> end with a <strong class="source-inline">CMD</strong> instruction, which should be the <a id="_idIndexMarker762"/>command to execute when the container is started. In our case, we would have used the Gunicorn command we saw in the <em class="italic">Adding Gunicorn as a server</em> section. However, in our case, the base image already handles this <span class="No-Break">for us.</span></p>&#13;
			<h2 id="_idParaDest-169"><a id="_idTextAnchor768"/>Adding a prestart script</h2>&#13;
			<p>When deploying<a id="_idIndexMarker763"/> an application, it’s quite common to run several commands before the application starts. The most typical case is to execute database migrations so that our production database has the correct set of tables and columns. To help us with this, our base Docker image allows us to create a bash script named <strong class="source-inline">prestart.sh</strong>. If this file is present, it’ll be automatically run before the FastAPI application <span class="No-Break">is started.</span></p>&#13;
			<p>In our case, we just run the Alembic command to <span class="No-Break">execute migrations:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">prestart.sh</p>&#13;
			<pre class="source-code">&#13;
#! /usr/bin/env bash# Let the DB start&#13;
sleep 10;&#13;
# Run migrations&#13;
alembic upgrade head</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/prestart.sh">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter10/project/prestart.sh</a></p>&#13;
			<p>Bear in mind<a id="_idIndexMarker764"/> that this is a mechanism provided only for convenience by the <strong class="source-inline">tiangolo/uvicorn-gunicorn-fastapi</strong> image. If you start from a more basic image, you’ll have to c<a id="_idTextAnchor769"/>ome up with your own solution to run a <span class="No-Break">p<a id="_idTextAnchor770"/>restart script.</span></p>&#13;
			<h2 id="_idParaDest-170"><a id="_idTextAnchor771"/>Building a Docker image</h2>&#13;
			<p>We can now <a id="_idIndexMarker765"/>build our Docker image! From the<a id="_idIndexMarker766"/> root of your project, just run the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
$ docker build -t fastapi-app  .</pre>			<p>The dot (<strong class="source-inline">.</strong>) denotes the path of the root context to build your image – in this case, the current directory. The <strong class="source-inline">-t</strong> option is <a id="_idTextAnchor772"/>here to tag the image and give it a <span class="No-Break">practical name.</span></p>&#13;
			<p>Docker will then perform the build. You’ll see that it’ll download the base image and sequentially run your instructions. This should take a few minutes. If you run the command again, you’ll experience what we explained earlier about layers: if there is no change, <a id="_idTextAnchor773"/>layers are reused and the build takes only a <span class="No-Break">fe<a id="_idTextAnchor774"/>w seconds.</span></p>&#13;
			<h2 id="_idParaDest-171"><a id="_idTextAnchor775"/>Running a Docker image locally</h2>&#13;
			<p>Before deploying it to<a id="_idIndexMarker767"/> production, you<a id="_idIndexMarker768"/> can try to run your image locally. To do this, run the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
$ docker run -p 8000:80 -e ENVIRONMENT=production -e DATABASE_URL=sqlite+aiosqlite:///app.db fastapi-app</pre>			<p>Here, we used the <strong class="source-inline">run</strong> command with the name of the image we just built. There are, of course, a few <span class="No-Break">options here:</span></p>&#13;
			<ul>&#13;
				<li><strong class="source-inline">-p</strong> allows you to publish ports on your local machine. By default, Docker containers are not accessible on your local machine. If you publish ports, they will be available through <strong class="source-inline">localhost</strong>. On the container side, the FastAPI application is executed on port <strong class="source-inline">80</strong>. We publish it on port <strong class="source-inline">8000</strong> on our local machine – that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">8000:80</strong></span><span class="No-Break">.</span></li>&#13;
				<li><strong class="source-inline">-e</strong> is used to set environment variables. As we mentioned in the <em class="italic">Setting and using environment variables</em> section, we need those variables to configure our application. Docker allows us to set them easily and dynamically at runtime. Notice that we set a simple SQLite database for testing purposes. However, in production, it sh<a id="_idTextAnchor776"/>ould point to a <span class="No-Break">proper database.</span></li>&#13;
				<li>You can review the<a id="_idIndexMarker769"/> numerous options of this command in the official Docker <span class="No-Break">documentation: </span><a href="https://docs.docker.com/engine/reference/commandline/run/#options"><span class="No-Break">https://docs.docker.com/engine/reference/commandline/run/#options</span></a><span class="No-Break">.</span></li>&#13;
			</ul>&#13;
			<p>This command will run your application, which will be accessible through <strong class="source-inline">http://lo<a id="_idTextAnchor777"/>calhost:8000</strong>. Docker will show you the logs in <span class="No-Break">the t<a id="_idTextAnchor778"/>erminal.</span></p>&#13;
			<h2 id="_idParaDest-172"><a id="_idTextAnchor779"/>Deploying a Docker image</h2>&#13;
			<p>Now <a id="_idIndexMarker770"/>that you have a working <a id="_idIndexMarker771"/>Docker image, you can deploy it on virtually any machine that runs Docker. This can be your own server or a dedicated platform. Lots of serverless platforms have emerged to help you deploy container images automatically: Google Cloud Run, Amazon Elastic Container Service, and Microsoft Azure Container I<a id="_idTextAnchor780"/>nstances are just <span class="No-Break">a few.</span></p>&#13;
			<p>Usually, what you have to do is upload (<strong class="bold">push</strong>, in Docker jargon) your image to a registry. By default, Docker pulls and pushes images from Docker Hub, the official Docker registry, but lots of services and platforms propose their own registries. Usually, using the private cloud registry proposed by the cloud platform is necessary to deploy it on this platform. Here are the relevant documentation pages for getting started with p<a id="_idTextAnchor781"/>rivate registries with the most popular <span class="No-Break">cloud providers:</span></p>&#13;
			<ul>&#13;
				<li>Google <a id="_idIndexMarker772"/>Artifact <span class="No-Break">Registry: </span><a href="https://cloud.google.com/artifact-registry/docs/docker/store-docker-container-images"><span class="No-Break">https://cloud.google.com/artifact-registry/docs/docker/store-docker-container-images</span></a></li>&#13;
				<li>Amazon <a id="_idIndexMarker773"/><span class="No-Break">ECR: </span><a href="https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-console.html"><span class="No-Break">https://docs.aws.amazon.com/<span id="_idTextAnchor782"/>AmazonECR/latest/userguide/getting-started-console.html</span></a></li>&#13;
				<li>Microsoft Azure <a id="_idIndexMarker774"/>Container <span class="No-Break">Registry: </span><a href="https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-docker-cli?tabs=azure-cli"><span class="No-Break">https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-docker-cli?tabs=azure-cli</span></a></li>&#13;
			</ul>&#13;
			<p>If you followed the relevant instructions, you should have a private registry for storing Docker images. The instructions probably showed you how to authenticate your local Docker command line with it and how to push your first image. Basically, all you have to do is tag the image you built with the path to your <span class="No-Break">private registry:</span></p>&#13;
			<pre class="source-code">&#13;
$ docker tag fastapi-app aws_account_id.dkr.ecr.region.amazonaws.com/fastapi-app</pre>			<p>Then, you need to push it to <span class="No-Break">the registry:</span></p>&#13;
			<pre class="source-code">&#13;
$ docker push fastapi-app aws_account_id.dkr.ecr.region.amazonaws.com/fastapi-app</pre>			<p>Your image is now safely stored in the cloud platform registry. You can now use a serverless container platform to deploy it automatically. Here are the relevant documentation pages for getting started with priv<a id="_idTextAnchor783"/>ate registries with the most popular <span class="No-Break">cloud providers:</span></p>&#13;
			<ul>&#13;
				<li>Google<a id="_idIndexMarker775"/> Cloud <span class="No-Break">Run: </span><a href="https://cloud.google.com/run/docs/quickstarts/build-and-deploy/python"><span class="No-Break">https://c<span id="_idTextAnchor784"/>loud.google.com/run/docs/quickstarts/build-and-deploy/python</span></a></li>&#13;
				<li>Amazon Elastic <a id="_idIndexMarker776"/>Container <span class="No-Break">Service: </span><a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/getting-started-ecs-ec2.html"><span class="No-Break">https://docs.aws.amazon.com/Am<span id="_idTextAnchor785"/>azonECS/latest/developerguide/getting-started-ecs-ec2.html</span></a></li>&#13;
				<li>Microsoft Azure Container<a id="_idIndexMarker777"/> <span class="No-Break">Instances: </span><a href="https://docs.microsoft.com/en-us/azure/container-instances/container-instances-tutorial-deploy-app%0D"><span class="No-Break">https://docs.microsoft.com/en-us/azure/container-i<span id="_idTextAnchor786"/>nstances/container-instances-tutorial-deploy-app</span></a></li>&#13;
			</ul>&#13;
			<p>Of course, you’ll be able to set the environment variables just like you can for fully managed apps. Those environments also provide lots of options for tuning the scalability of your containers, both vertically (using more powerful instances) and horizontally (spawning <span class="No-Break">more instances).</span></p>&#13;
			<p>Once done, your application should be live on the web! The great thing about deploying Docker images compared to automated serverless platforms is that you are not limited to the features supported by the platform: you can deploy anything, even complex applications that require a lot of exotic packages, without worrying <span class="No-Break">about compatibility.</span></p>&#13;
			<p>At this point, we’ve seen the easiest and most efficient ways to deploy a FastAPI application. However, you may wish to deploy one the old-fashioned way and manually set up your serv<a id="_idTextAnchor787"/>er. In the next section, we’ll provide some guidelines for <span class="No-Break">doing so.</span></p>&#13;
			<h1 id="_idParaDest-173">Deploying <a id="_idTextAnchor788"/>a FastAP<a id="_idTextAnchor789"/>I application on a traditional server</h1>&#13;
			<p>In some <a id="_idIndexMarker778"/>situations, you may not have the <a id="_idIndexMarker779"/>chance to use a serverless platform to deploy your application. Some security or regulatory policies may force you to deploy on physical servers with specific configurations. In this case, it’s worth knowing some basic things so that you can deploy your application on <span class="No-Break">traditional servers.</span></p>&#13;
			<p>In this section, we’ll consider you are working on a <span class="No-Break">Linux server:</span></p>&#13;
			<ol>&#13;
				<li>First of all, make sure a <em class="italic">recent version of Python has been installed</em> on your server, ideally with the version matching the one you used in development. The easiest way to do this is to set up <strong class="source-inline">pyenv</strong>, as we saw in <a href="B19528_01.xhtml#_idTextAnchor024"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Python Development </em><span class="No-Break"><em class="italic">Environment Setup</em></span><span class="No-Break">.</span></li>&#13;
				<li>To retrieve your source code and keep it in sync with your latest developments, you can <em class="italic">clone your Git repository</em> on your server. This way, you only have to pull the changes and restart the server process to deploy a <span class="No-Break">new version.</span></li>&#13;
				<li>Set up a <em class="italic">Python virtual environment</em>, as we explained in <a href="B19528_01.xhtml#_idTextAnchor024"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Python Development Environment Setup</em>. You can install the dependencies with <strong class="source-inline">pip</strong> thanks to your <span class="No-Break"><strong class="source-inline">requirements.txt</strong></span><span class="No-Break"> file.</span></li>&#13;
				<li>At that point, you should be able to run Gunicorn and start serving your FastAPI application. Howeve<a id="_idTextAnchor790"/>r, some<a id="_idTextAnchor791"/> improvements are <span class="No-Break">strongly recommended.</span></li>&#13;
				<li><em class="italic">Use a process manager</em> to ensure your Gunicorn process is always running and restarted when the <a id="_idTextAnchor792"/>server is restarted. A good option for this is <em class="italic">Supervisor</em>. The Gunicorn documentation provides good guidelines for <span class="No-Break">this: </span><a href="https://docs.gunicorn.org/en/stable/deploy.html#supervisor"><span class="No-Break">https://docs.gunicorn.org/en/stable/deploy.html#supervisor</span></a><span class="No-Break">.</span></li>&#13;
				<li>It’s also recommended to <em class="italic">put Gunicorn behind an HTTP proxy</em> instead of directly putting it on the front line. Its role is to handle SSL connections, perform load balancing, and serve static files such as images or documents. The Gunicorn documentation recommends using nginx for this task and provides a basic <span class="No-Break">configuration: </span><a href="https://docs.gunicorn.org/en/stable/deploy.html#nginx-configuration"><span class="No-Break">https://docs.gunicorn.org/en/stable/deploy.html#nginx-configuration</span></a><span class="No-Break">.</span></li>&#13;
			</ol>&#13;
			<p>As you can see, in this<a id="_idIndexMarker780"/> context, there are quite <a id="_idIndexMarker781"/>a lot of configurations and decisions to make regarding your server configuration. Of course, you should also pay attention to security and make sure <a id="_idTextAnchor793"/>your server is well protected against the usual attacks. In the following DigitalOcean tutorial, you’ll find some guidelines for securing your <span class="No-Break">server: </span><a href="https://www.digitalocean.com/community/tutorials/recommended-security-measures-to-protect-your-servers"><span class="No-Break">https://www.digitalocean.com/community/tutorials/recommended-security-measures-to-protect-your-servers</span></a><span class="No-Break">.</span></p>&#13;
			<p>If you’re not an experienced system administrator, we recommend that you favor serverless platforms; professional teams handle security, system updates, and server scalability for you, lettin<a id="_idTextAnchor794"/>g you focus on what matters most to you: developing a <span class="No-Break">great application!</span></p>&#13;
			<h1 id="_idParaDest-174"><a id="_idTextAnchor795"/>Summary</h1>&#13;
			<p>Your application is now live on the web! In this chapter, we covered the best practices to apply before deploying your application to production: use environment variables to set configuration options, such as database URLs, and manage your Python dependencies with a <strong class="source-inline">requirements.txt</strong> file. Then, we showed you how to deploy your application to a serverless platform, which handles everything for you by retrieving your source code, packaging it with its dependencies, and serving it on the web. Next, you learned how to build a Docker image for FastAPI using the base image created by the creator of FastAPI. As you saw, it allows you to be flexible while configuring the system, but you can still deploy it in a few minutes with a serverless platform that’s compatible with containers. Finally, we provided you with some guidelines for manual deployment on a traditional <span class="No-Break">Linux server.</span></p>&#13;
			<p>This marks the end of the second part of this book. You should now be confident in writing efficient, reliable FastAPI applications and be able to deploy them on <span class="No-Break">the web.</span></p>&#13;
			<p>In the next chapter, we will begin some data science tasks and integrate them efficiently into a <span class="No-Break">FastAPI project.</span></p>&#13;
		</div>&#13;
	</div></body></html>