["```py\n\n# Make the pipelinemodel = make_pipeline(\n           TfidfVectorizer(),\n           MultinomialNB(),\n)\n# Train the model\nmodel.fit(newsgroups_training.data, newsgroups_training.target)\n# Serialize the model and the target names\nmodel_file = \"newsgroups_model.joblib\"\nmodel_targets_tuple = (model, newsgroups_training.target_names)\njoblib.dump(model_targets_tuple, model_file)\n```", "```py\n\n(venv) $ python chapter12/chapter12_dump_joblib.py$ ls -lh *.joblib\n-rw-r--r--    1 fvoron    staff       3,0M 10 jan 08:27 newsgroups_model.joblib\n```", "```py\n\nimport osimport joblib\nfrom sklearn.pipeline import Pipeline\n# Load the model\nmodel_file = os.path.join(os.path.dirname(__file__), \"newsgroups_model.joblib\")\nloaded_model: tuple[Pipeline, list[str]] = joblib.load(model_file)\nmodel, targets = loaded_model\n# Run a prediction\np = model.predict([\"computer cpu memory ram\"])\nprint(targets[p[0]])\n```", "```py\n\nclass PredictionInput(BaseModel):           text: str\nclass PredictionOutput(BaseModel):\n           category: str\nclass NewsgroupsModel:\n           model: Pipeline | None = None\n           targets: list[str] | None = None\n           def load_model(self) -> None:\n                         \"\"\"Loads the model\"\"\"\n                         model_file = os.path.join(os.path.dirname(__file__), \"newsgroups_model.joblib\")\n                         loaded_model: tuple[Pipeline, list[str]] = joblib.load(model_file)\n                         model, targets = loaded_model\n                         self.model = model\n                         self.targets = targets\n           async def predict(self, input: PredictionInput) -> PredictionOutput:\n                         \"\"\"Runs a prediction\"\"\"\n                         if not self.model or not self.targets:\n                                       raise RuntimeError(\"Model is not loaded\")\n                         prediction = self.model.predict([input.text])\n                         category = self.targets[prediction[0]]\n                         return PredictionOutput(category=category)\n```", "```py\n\nnewgroups_model = NewsgroupsModel()@contextlib.asynccontextmanager\nasync def lifespan(app: FastAPI):\n           newgroups_model.load_model()\n           yield\napp = FastAPI(lifespan=lifespan)\n@app.post(\"/prediction\")\nasync def prediction(\n           output: PredictionOutput = Depends(newgroups_model.predict),\n) -> PredictionOutput:\n           return output\n```", "```py\n\n(venv) $ uvicorn chapter12.chapter12_prediction_endpoint:app\n```", "```py\n\n$ http POST http://localhost:8000/prediction text=\"computer cpu memory ram\"HTTP/1.1 200 OK\ncontent-length: 36\ncontent-type: application/json\ndate: Tue, 10 Jan 2023 07:37:22 GMT\nserver: uvicorn\n{\n           \"category\": \"comp.sys.mac.hardware\"\n}\n```", "```py\n\nmemory = joblib.Memory(location=\"cache.joblib\")@memory.cache(ignore=[\"model\"])\ndef predict(model: Pipeline, text: str) -> int:\n           prediction = model.predict([text])\n           return prediction[0]\n```", "```py\n\nclass NewsgroupsModel:           model: Pipeline | None = None\n           targets: list[str] | None = None\n           def load_model(self) -> None:\n                         \"\"\"Loads the model\"\"\"\n                         model_file = os.path.join(os.path.dirname(__file__), \"newsgroups_model.joblib\")\n                         loaded_model: tuple[Pipeline, list[str]] = joblib.load(model_file)\n                         model, targets = loaded_model\n                         self.model = model\n                         self.targets = targets\n           def predict(self, input: PredictionInput) -> PredictionOutput:\n                         \"\"\"Runs a prediction\"\"\"\n                         if not self.model or not self.targets:\n                                       raise RuntimeError(\"Model is not loaded\")\n                         prediction = predict(self.model, input.text)\n                         category = self.targets[prediction]\n                         return PredictionOutput(category=category)\n```", "```py\n\n@app.post(\"/prediction\")def prediction(\n           output: PredictionOutput = Depends(newgroups_model.predict),\n) -> PredictionOutput:\n           return output\n@app.delete(\"/cache\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_cache():\n           memory.clear()\n```", "```py\n\nimport timefrom fastapi import FastAPI\napp = FastAPI()\n@app.get(\"/fast\")\nasync def fast():\n           return {\"endpoint\": \"fast\"}\n@app.get(\"/slow-async\")\nasync def slow_async():\n           \"\"\"Runs in the main process\"\"\"\n           time.sleep(10)    # Blocking sync operation\n           return {\"endpoint\": \"slow-async\"}\n@app.get(\"/slow-sync\")\ndef slow_sync():\n           \"\"\"Runs in a thread\"\"\"\n           time.sleep(10)    # Blocking sync operation\n           return {\"endpoint\": \"slow-sync\"}\n```", "```py\n\n(venv) $ uvicorn chapter12.chapter12_async_not_async:app\n```", "```py\n\n$ http GET http://localhost:8000/slow-async\n```", "```py\n\n$ http GET http://localhost:8000/fast\n```", "```py\n\n$ http GET http://localhost:8000/slow-sync\n```", "```py\n\n$ http GET http://localhost:8000/fast\n```"]