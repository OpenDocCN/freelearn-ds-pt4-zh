<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer070">&#13;
			<h1 id="_idParaDest-210" class="chapter-number"><a id="_idTextAnchor1041"/>14</h1>&#13;
			<h1 id="_idParaDest-211"><a id="_idTextAnchor1042"/>Creating a Distributed Text-to-Image AI System Using the Stable Diffusion Model</h1>&#13;
			<p>Until now, in this book, we’ve built APIs where all the operations were computed inside the request handling. Said another way, before they could get their response, the user had to wait for the server to do everything we had defined: request validation, database queries, ML predictions, and so on. However, this behavior is not always desired <span class="No-Break">or possible.</span></p>&#13;
			<p>A typical example is<a id="_idIndexMarker966"/> email notifications. It happens quite often in a web application that we need to send an email to the user because they just registered or they performed a specific action. To do this, the server needs to send a request to an email server so the email can be sent. This operation could take a few milliseconds. If we do this inside the request handling, the response will be delayed until we send the email. This is not a very good experience since the user doesn’t really care how and when the email is sent. This example is typical of what we usually call <strong class="bold">background operations</strong>: things <a id="_idIndexMarker967"/>that need to be done in our application but don’t require direct <span class="No-Break">user interaction.</span></p>&#13;
			<p>Another case is when the user requests an expensive operation that can’t be done in a reasonable time. It’s usually the case for complex data exports or heavy AI models. In this context, the user would like to get the result directly, but doing this in the request handler would block the server process until it’s done. If lots of users were requesting this kind of operation, it would quickly make our server unresponsive. Besides, some network infrastructure such as proxy or web clients, like browsers, have quite strict timeout settings, meaning they will usually cancel an operation if it takes too much time <span class="No-Break">to respond.</span></p>&#13;
			<p>To solve <a id="_idIndexMarker968"/>this, we’ll introduce a typical architecture for web applications: <strong class="bold">web-queue-worker</strong>. As we’ll see in this chapter, we’ll defer the most expensive, long operations to a background process, a <strong class="bold">worker</strong>. To show you this architecture in action, we’ll build our <a id="_idIndexMarker969"/>very own AI system to generate images from text prompts using <a id="_idIndexMarker970"/>the <strong class="bold">Stable </strong><span class="No-Break"><strong class="bold">Diffusion</strong></span><span class="No-Break"> model.</span></p>&#13;
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>&#13;
			<ul>&#13;
				<li>Using the Stable Diffusion model with Hugging Face Diffusers to generate images from <span class="No-Break">text prompts</span></li>&#13;
				<li>Implementing a worker process using Dramatiq and an <span class="No-Break">image-generation task</span></li>&#13;
				<li>Storing and serving files in <span class="No-Break">object storage</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-212"><a id="_idTextAnchor1043"/>Technical requirements</h1>&#13;
			<p>For this chapter, you’ll require a Python virtual environment, just as we set up in <a href="B19528_01.xhtml#_idTextAnchor024"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Python Development </em><span class="No-Break"><em class="italic">Environment Setup</em></span><span class="No-Break">.</span></p>&#13;
			<p>To run the Stable Diffusion model correctly, we recommend you have a recent computer equipped with at least 16 GB of RAM and, ideally, a dedicated GPU with 8 GB of VRAM. For Mac users, recent models equipped with the M1 Pro or M2 Pro chips are also a good fit. If you don’t have that kind of machine, don’t worry: we’ll show you ways to run the system anyway – the only drawback is that image generation will be slow and show <span class="No-Break">poor results.</span></p>&#13;
			<p>For running the worker, you’ll need a running <strong class="bold">Redis server</strong> on your local computer. The easiest way is to run it as a Docker container. If you’ve never used Docker before, we recommend you read the <em class="italic">Getting started</em> tutorial in the official documentation at <a href="https://docs.docker.com/get-started/">https://docs.docker.com/get-started/</a>. Once done, you’ll be able to run a Redis server with this <span class="No-Break">simple command:</span></p>&#13;
			<pre class="source-code">&#13;
$ docker run -d --name worker-redis -p 6379:6379 redis</pre>			<p>You’ll find all the code examples of this chapter in the dedicated GitHub repository <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14"><span class="No-Break">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14</span></a><span class="No-Break">.</span></p>&#13;
			<h1 id="_idParaDest-213"><a id="_idTextAnchor1044"/>Generating images from text prompts with Stable Diffusion</h1>&#13;
			<p>Recently, a new generation of AI tools has emerged and fascinated the whole world: image-generation models, such as<a id="_idIndexMarker971"/> DALL-E or Midjourney. Those models are trained on huge amounts of image data and are <a id="_idIndexMarker972"/>able to generate completely new images from a simple text prompt. These AI models are very good use cases for background workers: they take seconds or even minutes to process, and they need lots of resources in the CPU, RAM, and even <span class="No-Break">the GPU.</span></p>&#13;
			<p>To build our system, we’ll rely on Stable Diffusion, a very <a id="_idIndexMarker973"/>popular image-generation model that was released in 2022. This model is available publicly and can be run on a modern gaming computer. As we did in the previous chapter, we’ll rely on Hugging Face tools for both downloading the model and <span class="No-Break">running it.</span></p>&#13;
			<p>Let’s first install the <span class="No-Break">required tools:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install accelerate diffusers</pre>			<p>We’re now ready to use diffuser models thanks to <span class="No-Break">Hugging Face.</span></p>&#13;
			<h2 id="_idParaDest-214"><a id="_idTextAnchor1045"/>Implementing the model in a Python script</h2>&#13;
			<p>In the <a id="_idIndexMarker974"/>following example, we’ll show you the implementation of a class able to instantiate the model and run an image generation. Once again, we’ll apply our lazy loading pattern with separate <strong class="source-inline">load_model</strong> and <strong class="source-inline">generate</strong> methods. Let’s first focus <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">load_model</strong></span><span class="No-Break">:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">text_to_image.py</p>&#13;
			<pre class="source-code">&#13;
class TextToImage:    pipe: StableDiffusionPipeline | None = None&#13;
    def load_model(self) -&gt; None:&#13;
        # Enable CUDA GPU&#13;
        if torch.cuda.is_available():&#13;
            device = "cuda"&#13;
        # Enable Apple Silicon (M1) GPU&#13;
        elif torch.backends.mps.is_available():&#13;
            device = "mps"&#13;
        # Fallback to CPU&#13;
        else:&#13;
            device = "cpu"&#13;
        pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")&#13;
        pipe.to(device)&#13;
        self.pipe = pipe</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py</a></p>&#13;
			<p>The first part of this method aims to find the most efficient way to run the model given your computer. These diffusion models are faster when run on the GPU – that’s why we check first if there are CUDA (NVIDIA GPU) or MPS (Apple Silicon) devices available. If there are none, we fall back to <span class="No-Break">the CPU.</span></p>&#13;
			<p>Then, we simply have<a id="_idIndexMarker975"/> to create a <strong class="source-inline">StableDiffusionPipeline</strong> pipeline, as provided by Hugging Face. We simply have to set the model we want to download from the hub. For this example, we chose <strong class="source-inline">runwayml/stable-diffusion-v1-5</strong>. You can find its details on Hugging <span class="No-Break">Face: </span><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5"><span class="No-Break">https://huggingface.co/runwayml/stable-diffusion-v1-5</span></a><span class="No-Break">.</span></p>&#13;
			<p>We can now focus on the <span class="No-Break"><strong class="source-inline">generate</strong></span><span class="No-Break"> method:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">text_to_image.py</p>&#13;
			<pre class="source-code">&#13;
    def generate(        self,&#13;
        prompt: str,&#13;
        *,&#13;
        negative_prompt: str | None = None,&#13;
        num_steps: int = 50,&#13;
        callback: Callable[[int, int, torch.FloatTensor], None] | None = None,&#13;
    )    Image.Image:&#13;
        if not self.pipe:&#13;
            raise RuntimeError("Pipeline is not loaded")&#13;
        return self.pipe(&#13;
            prompt,&#13;
            negative_prompt=negative_prompt,&#13;
            num_inference_steps=num_steps,&#13;
            guidance_scale=9.0,&#13;
            callback=callback,&#13;
        ).images[0]</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py</a></p>&#13;
			<p>You can see it <a id="_idIndexMarker976"/>accepts <span class="No-Break">four parameters:</span></p>&#13;
			<ul>&#13;
				<li><strong class="source-inline">prompt</strong>, which is, of course, the text prompt describing the image we want <span class="No-Break">to generate.</span></li>&#13;
				<li><strong class="source-inline">negative_prompt</strong>, which is an optional prompt to tell the model what we absolutely <span class="No-Break">don’t want.</span></li>&#13;
				<li><strong class="source-inline">num_steps</strong>, which is the number of inference steps the model should run. More steps lead to a better image, but each iteration delays the inference. The default, <strong class="source-inline">50</strong>, should provide a good balance between speed <span class="No-Break">and quality.</span></li>&#13;
				<li><strong class="source-inline">callback</strong>, which is an optional function that will be called at each iteration step. This is helpful to be informed about the progress of the generation and possibly execute more logic, such as saving the progress in <span class="No-Break">a database.</span></li>&#13;
			</ul>&#13;
			<p class="callout-heading">What does the asterisk (*) in the method signature mean?</p>&#13;
			<p class="callout">You may have noticed the asterisk, <strong class="source-inline">*</strong>, in the method signature. It tells Python that the arguments coming after this symbol should only be treated as keyword-only arguments. Said another way, you can only call them like this: <strong class="source-inline">.generate("PROMPT", </strong><span class="No-Break"><strong class="source-inline">negative_prompt="NEGATIVE", num_steps=10)</strong></span><span class="No-Break">.</span></p>&#13;
			<p class="callout">While not necessary, it’s a way to keep your functions clear and self-explanatory. It’s especially true if you develop classes or functions that are meant to be used by <span class="No-Break">other developers.</span></p>&#13;
			<p class="callout">Another syntax also exists to force arguments to be positional-only, using a slash (<strong class="source-inline">/</strong>) symbol. You can read more about it <span class="No-Break">here: </span><a href="https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters"><span class="No-Break">https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters</span></a><span class="No-Break">.</span></p>&#13;
			<p>All we have to do then <a id="_idIndexMarker977"/>is to pass those parameters to <strong class="source-inline">pipe</strong>. There are a lot more parameters for you to tune if needed, but the default ones should give you quite good results. You can find the whole list of them in the Hugging Face documentation: <a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__">https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__</a>. This <strong class="source-inline">pipe</strong> object is able to generate several images per prompt, that’s why the result of this operation is a list of Pillow images. The default here is to generate only one image, so we directly return the <span class="No-Break">first one.</span></p>&#13;
			<p>And that’s about it! Once again, Hugging Face makes our lives really easy by allowing us to run cutting-edge models in dozens <span class="No-Break">of lines!</span></p>&#13;
			<h2 id="_idParaDest-215"><a id="_idTextAnchor1046"/>Executing the Python script</h2>&#13;
			<p>We bet that you’re eager to try it<a id="_idIndexMarker978"/> yourself – that’s why we added a small <strong class="source-inline">main</strong> script at the bottom of <span class="No-Break">our example:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">text_to_image.py</p>&#13;
			<pre class="source-code">&#13;
if __name__ == "__main__":    text_to_image = TextToImage()&#13;
    text_to_image.load_model()&#13;
    def callback(step: int, _timestep, _tensor):&#13;
        print(f"🚀 Step {step}")&#13;
    image = text_to_image.generate(&#13;
        "A Renaissance castle in the Loire Valley",&#13;
        negative_prompt="low quality, ugly",&#13;
        callback=callback,&#13;
    )&#13;
    image.save("output.png")</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py</a></p>&#13;
			<p>This small script instantiates our <strong class="source-inline">TextToImage</strong> class, loads the model, and generates an image before saving it to disk. We also define a dummy callback function so you can see how <span class="No-Break">it works.</span></p>&#13;
			<p>When you run this script for the first time, you’ll notice that Hugging Face downloads files of several gigabytes to your computer: that’s the Stable Diffusion model, and it’s indeed <span class="No-Break">quite big!</span></p>&#13;
			<p>Then, the <a id="_idIndexMarker979"/>inference will start. You’ll see a progress bar showing you how many inference steps are left, along with the <strong class="source-inline">print</strong> statement from our callback, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer064" class="IMG---Figure">&#13;
					<img src="Images/Figure_14.1_B19528.jpg" alt="Figure 14.1 – Stable Diffusion generating an image" width="1330" height="705"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – Stable Diffusion generating an image</p>&#13;
			<p class="callout-heading">How much time does it take to generate a single image?</p>&#13;
			<p class="callout">We’ve run several tests on different types of computers. With a modern NVIDIA GPU with 8 GB of RAM or a Mac with an M1 Pro chip, the model is able to generate an image with 50 inference steps in <em class="italic">around a minute</em>, with reasonable RAM usage. When run on a CPU, it takes around <em class="italic">5 to 10 minutes</em> and eats up to 16 GB <span class="No-Break">of RAM.</span></p>&#13;
			<p class="callout">If the inference is really too slow on your computer, you can try to reduce the <span class="No-Break"><strong class="source-inline">num_steps</strong></span><span class="No-Break"> parameter.</span></p>&#13;
			<p>When the<a id="_idIndexMarker980"/> inference is done, you’ll find your generated image on the disk along with your script. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.2</em> shows an example of such a result. Nice, <span class="No-Break">isn’t it?</span></p>&#13;
			<div>&#13;
				<div id="_idContainer065" class="IMG---Figure">&#13;
					<img src="Images/Figure_14.2_B19528.jpg" alt="Figure 14.2 – Result of a Stable Diffusion image generation" width="512" height="512"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Result of a Stable Diffusion image generation</p>&#13;
			<p>We now have the <a id="_idIndexMarker981"/>fundamental brick of our AI system. Now, we need to build an API so users can generate their own images. As we’ve just seen, generating a single image takes some time. As we said in the introduction, we’ll need to introduce a web-queue-worker architecture to make this system reliable <span class="No-Break">and scalable.</span></p>&#13;
			<h1 id="_idParaDest-216"><a id="_idTextAnchor1047"/>Creating a Dramatiq worker and defining an image-generation task</h1>&#13;
			<p>As we mentioned in the introduction of this chapter, it’s not conceivable to run our image-generation model directly on our REST API server. As we saw in the previous section, the operation can take several minutes and consumes a massive amount of memory. To solve this, we’ll define another process, apart from the server process, that’ll take care of this image-generation task: the <strong class="bold">worker</strong>. In essence, a worker can be any program whose role is to compute a task in <span class="No-Break">the</span><span class="No-Break"><a id="_idIndexMarker982"/></span><span class="No-Break"> background.</span></p>&#13;
			<p>In web development, this concept usually implies a bit more than this. A worker is a process running continuously in the background, waiting for incoming tasks. The tasks are usually sent by the web server, which asks for specific operations given the <span class="No-Break">user actions.</span></p>&#13;
			<p>Therefore, we see that we need a<a id="_idIndexMarker983"/> communication channel between the web server and the worker. That’s the role of the <strong class="bold">queue</strong>. It’ll accept and stack messages coming from the web server and make them available to read for the worker. That’s the web-queue-worker architecture. To better understand it, <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.4</em> shows you the schema of such<a id="_idIndexMarker984"/> <span class="No-Break">an architecture.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer066" class="IMG---Figure">&#13;
					<img src="Images/Figure_14.3_B19528.jpg" alt="Figure 14.3 – Schema of web-queue-worker architecture" width="1493" height="396"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 – Schema of web-queue-worker architecture</p>&#13;
			<p>Does it ring a bell? Yes, it’s very similar to what we saw in <a href="B19528_08.xhtml#_idTextAnchor551"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, in the <em class="italic">Handling multiple WebSocket connections and broadcasting messages</em> section. Actually, this is the same principle: we solve the problem of having separate processes by having a single central <span class="No-Break">data source.</span></p>&#13;
			<p>The great feature of this architecture is that it scales very easily. Imagine your application is a huge success and thousands of users want to generate images: a single worker wouldn’t be able to meet the demand. Actually, all we need to do is to start more worker processes. Since there is a single message broker in the architecture, each worker will pull messages as they come, allowing <a id="_idIndexMarker985"/>tasks to be processed in parallel. They don’t even need to be on the same physical machine. This is shown in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer067" class="IMG---Figure">&#13;
					<img src="Images/Figure_14.4_B19528.jpg" alt="Figure 14.4 – Web-queue-worker architecture with multiple workers" width="1014" height="1112"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Web-queue-worker architecture with multiple workers</p>&#13;
			<p>In Python, there are several libraries to help implement a worker. They provide the required tools to define tasks, schedule them in the queue, and run a process, pulling them and executing them. In this book, we’ll use Dramatiq, a lightweight but powerful and modern background task-processing library. As we did in <a href="B19528_08.xhtml#_idTextAnchor551"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, we’ll use Redis as a <span class="No-Break">message broker.</span></p>&#13;
			<h2 id="_idParaDest-217"><a id="_idTextAnchor1048"/>Implementing a worker</h2>&#13;
			<p>As usual, we’ll start by installing the <a id="_idIndexMarker986"/>required dependency. Run the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install "dramatiq[redis]"</pre>			<p>This will install Dramatiq with the required dependencies to talk with a <span class="No-Break">Redis broker.</span></p>&#13;
			<p>In a minimal example, setting up a Dramatiq worker involves <span class="No-Break">two things:</span></p>&#13;
			<ol>&#13;
				<li>Setting the broker type <span class="No-Break">and URL.</span></li>&#13;
				<li>Defining tasks by wrapping functions with the <strong class="source-inline">@</strong><span class="No-Break"><strong class="source-inline">dramatiq.actor</strong></span><span class="No-Break"> decorator.</span></li>&#13;
			</ol>&#13;
			<p>It works very well for the vast majority of tasks, such as sending emails or <span class="No-Break">generating exports.</span></p>&#13;
			<p>In our case, however, we need to load the heavy Stable Diffusion model. As we usually do in the FastAPI server with the <strong class="source-inline">startup</strong> event, we want to do this only when the process is actually started. To do this with Dramatiq, we implement a <em class="italic">middleware</em>. They allow us to plug custom logic at several key events in the lifetime of the worker, including when <span class="No-Break">it’s started.</span></p>&#13;
			<p>You can see the implementation of our custom middleware in the <span class="No-Break">following sample:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
class TextToImageMiddleware(Middleware):    def __init__(self) -&gt; None:&#13;
        super().__init__()&#13;
        self.text_to_image = TextToImage()&#13;
    def after_process_boot(self, broker):&#13;
        self.text_to_image.load_model()&#13;
        return super().after_process_boot(broker)&#13;
text_to_image_middleware = TextToImageMiddleware()&#13;
redis_broker = RedisBroker(host="localhost")&#13;
redis_broker.add_middleware(text_to_image_middleware)&#13;
dramatiq.set_broker(redis_broker)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py</a></p>&#13;
			<p>We define a <strong class="source-inline">TextToImageMiddleware</strong> class whose role is to bear an instance of <strong class="source-inline">TextToImage</strong>, the image generation service we defined in the previous section. It inherits from the <strong class="source-inline">Middleware</strong> class of Dramatiq. The key thing here is the <strong class="source-inline">after_process_boot</strong> method. It’s one of the event hooks exposed by Dramatiq, allowing us to plug our own logic. Here, we tell it to load the Stable Diffusion model when the worker process has booted up. You can see the full list of supported hooks in the official <span class="No-Break">documentation: </span><a href="https://dramatiq.io/reference.html#middleware"><span class="No-Break">https://dramatiq.io/reference.html#middleware</span></a><span class="No-Break">.</span></p>&#13;
			<p>The next lines allow us to <a id="_idIndexMarker987"/>configure our worker. We first instantiate an instance of our custom middleware. Then, we create a broker class corresponding to the technology we chose; in our case, Redis. We take care of adding our middleware to this broker before telling Dramatiq to use it. Our worker is now completely configured to connect to a Redis broker and load our model <span class="No-Break">at startup.</span></p>&#13;
			<p>Now, let’s see how we can define a task to <span class="No-Break">generate images:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
@dramatiq.actor()def text_to_image_task(&#13;
    prompt: str, *, negative_prompt: str | None = None, num_steps: int = 50&#13;
):&#13;
    image = text_to_image_middleware.text_to_image.generate(&#13;
        prompt, negative_prompt=negative_prompt, num_steps=num_steps&#13;
    )&#13;
    image.save(f"{uuid.uuid4()}.png")</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py</a></p>&#13;
			<p>The <a id="_idIndexMarker988"/>implementation is straightforward: Dramatiq tasks are actually plain functions that we decorated with <strong class="source-inline">@dramatiq.actor</strong>. We can define arguments as we would for any other function. However, there is an important pitfall to avoid here: when we schedule tasks from our server, the arguments will have to be stored in the queue storage. Thus, <em class="italic">Dramatiq will internally serialize the arguments to JSON</em>. It means your task arguments must be serializable data – you can’t have arbitrary Python objects, such as class instances <span class="No-Break">or functions.</span></p>&#13;
			<p>The function body calls our <strong class="source-inline">TextToImage</strong> instance loaded in <strong class="source-inline">text_to_image_middleware</strong>, before saving the image to the disk. To avoid file overrides, we choose here to generate a <strong class="bold">UUID</strong>, a <strong class="bold">Universally Unique IDentifier</strong>. It’s a big random string that’s guaranteed to be <a id="_idIndexMarker989"/>unique in each generation. Thanks to this, we can safely use it as a filename and be sure it won’t already exist on <span class="No-Break">our disk.</span></p>&#13;
			<p>That’s it for the <span class="No-Break">worker implementation.</span></p>&#13;
			<h3>Starting the worker</h3>&#13;
			<p>We don’t have the web server code to call it yet, but we can already try it manually. First, make sure you have a Redis server started, as explained in the <em class="italic">Technical requirements</em> section. Then, we can start the Dramatiq worker<a id="_idIndexMarker990"/> using the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ dramatiq -p 1 -t 1 chapter14.basic.worker</pre>			<p>Dramatiq comes with command-line tools to take care of starting the worker processes. The main positional argument is the dotted path of your worker module. It’s similar to what we do with Uvicorn. We also set two optional parameters, <strong class="source-inline">-p</strong> and <strong class="source-inline">-t</strong>. They control the number of processes and threads Dramatiq will start. By default, it starts 10 processes, each one with 8 threads. This means there will be 80 workers able to pull and execute tasks. While this default is good for common needs, it doesn’t work with our Stable Diffusion model for <span class="No-Break">two reasons:</span></p>&#13;
			<ul>&#13;
				<li>Each thread in a process shares the same memory space. This means that if two (or more) threads try to generate an image, they will read and write on the same objects in memory. For our model here, this causes concurrency problems. We say that it’s <em class="italic">not thread-safe</em>. Hence, each process should start only one thread: that’s the point of the <strong class="source-inline">-t </strong><span class="No-Break"><strong class="source-inline">1</strong></span><span class="No-Break"> option.</span></li>&#13;
				<li>Each process should load the model in memory. This means that if we start 8 processes, we’ll load the model 8 times. As we saw earlier, it takes quite a huge amount of memory, so doing this would probably blow up your computer’s memory. To be safe here, we start only one process thanks to the <strong class="source-inline">-p 1</strong> option. If you want to try parallelization and see that our worker is able to generate two images in parallel, you can try <strong class="source-inline">-p 2</strong> to spawn two processes. Make sure your computer can handle <span class="No-Break">it though!</span></li>&#13;
			</ul>&#13;
			<p>If you run the <a id="_idIndexMarker991"/>preceding command, you should see an output <span class="No-Break">like this:</span></p>&#13;
			<pre class="source-code">&#13;
[2023-02-02 08:52:11,479] [PID 44348] [MainThread] [dramatiq.MainProcess] [INFO] Dramatiq '1.13.0' is booting up.Fetching 19 files:   0%|          | 0/19 [00:00&lt;?, ?it/s]&#13;
Fetching 19 files: 100%|██████████| 19/19 [00:00&lt;00:00, 13990.83it/s]&#13;
[2023-02-02 08:52:11,477] [PID 44350] [MainThread] [dramatiq.WorkerProcess(0)] [INFO] Worker process is ready for action.&#13;
[2023-02-02 08:52:11,578] [PID 44355] [MainThread] [dramatiq.ForkProcess(0)] [INFO] Fork process 'dramatiq.middleware.prometheus:_run_exposition_server' is ready for action.</pre>&#13;
			<p>You can see the output of the Stable Diffusion pipeline checking whether the model files are downloaded before the worker is fully started. This means that it has been <span class="No-Break">correctly loaded.</span></p>&#13;
			<h3>Scheduling tasks in the worker</h3>&#13;
			<p>We can now try to <a id="_idIndexMarker992"/>schedule tasks in our worker. For this, we can start a Python interactive shell and import the <strong class="source-inline">task</strong> function. Open a new command line and run the following commands (make sure you enabled your Python <span class="No-Break">virtual environment):</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ python&gt;&gt;&gt; from chapter14.basic.worker import text_to_image_task&#13;
&gt;&gt;&gt; text_to_image_task.send("A Renaissance castle in the Loire Valley")&#13;
Message(queue_name='default', actor_name='text_to_image_task', args=('A Renaissance castle in the Loire Valley',), kwargs={}, options={'redis_message_id': '663df44a-cfc1-4f13-8457-05d8181290c1'}, message_id='bf57d112-6c20-49bc-a926-682ca43ea7ea', message_timestamp=1675324585644)</pre>&#13;
			<p>That’s it – we scheduled a task in the worker! Notice how we used the <strong class="source-inline">send</strong> method on our <strong class="source-inline">task</strong> function instead of calling it directly: this is how you tell Dramatiq to send it in <span class="No-Break">the queue.</span></p>&#13;
			<p>If you go back to your worker terminal, you’ll see the Stable Diffusion output generating the image. After a moment, you’ll have your image saved on disk. You can also try to send two tasks in a row in a short time. You’ll find that Dramatiq processes them one after <span class="No-Break">the other.</span></p>&#13;
			<p>Great job! We have our background process ready and are even able to schedule tasks in it. The next step now is to implement a REST API so the users can ask for image <span class="No-Break">generation themselves.</span></p>&#13;
			<h2 id="_idParaDest-218"><a id="_idTextAnchor1049"/>Implementing the REST API</h2>&#13;
			<p>To schedule tasks in our worker, we need a safe interface users can interact with. A REST API is a <a id="_idIndexMarker993"/>good choice for this, since it can be easily integrated into any software, such as a website or a mobile app. In this section, we’ll very quickly review a simple API endpoint<a id="_idIndexMarker994"/> we implemented to send image-generation tasks into our queue. Here’s <span class="No-Break">the implementation:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">api.py</p>&#13;
			<pre class="source-code">&#13;
class ImageGenerationInput(BaseModel):    prompt: str&#13;
    negative_prompt: str | None&#13;
    num_steps: int = Field(50, gt=0, le=50)&#13;
class ImageGenerationOutput(BaseModel):&#13;
    task_id: UUID4&#13;
app = FastAPI()&#13;
@app.post(&#13;
    "/image-generation",&#13;
    response_model=ImageGenerationOutput,&#13;
    status_code=status.HTTP_202_ACCEPTED,&#13;
)&#13;
async def post_image_generation(input: ImageGenerationInput) -&gt; ImageGenerationOutput:&#13;
    task: Message = text_to_image_task.send(&#13;
        input.prompt, negative_prompt=input.negative_prompt, num_steps=input.num_steps&#13;
    )&#13;
    return ImageGenerationOutput(task_id=task.message_id)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py</a></p>&#13;
			<p>If you have followed along since the beginning of this book, this shouldn’t surprise you. We took care of defining proper Pydantic models to structure and validate the endpoint payload. This data is then directly used to send a task to Dramatiq, as we saw in the <span class="No-Break">previous section.</span></p>&#13;
			<p>In this simple<a id="_idIndexMarker995"/> implementation, the output consists only of the message ID, which is automatically assigned to each task by Dramatiq. Notice that we set the HTTP status code to <strong class="source-inline">202</strong>, which means <em class="italic">Accepted</em>. Semantically, it means the server understood and accepted the request, but the processing has not yet finished or even started. It’s specifically designed for cases where the processing is done in the background, which is exactly our <span class="No-Break">case here.</span></p>&#13;
			<p>If you start both the worker and this API, you’ll be able to trigger image generations with an <span class="No-Break">HTTP call.</span></p>&#13;
			<p>You’re probably wondering here: <em class="italic">That’s nice… But how will the users retrieve the result? How will they know whether the task is done?</em>. You’re right – we didn’t talk at all about this problem! Actually, there are two aspects to solve here: how do we keep track of the pending tasks and their execution? How do we store and serve the resulting images? That’s the subject of the <span class="No-Break">next section.</span></p>&#13;
			<h1 id="_idParaDest-219"><a id="_idTextAnchor1050"/>Storing results in a database and object storage</h1>&#13;
			<p>In the previous section, we showed how to implement a background worker to do the heavy computation and an API to schedule tasks on this worker. However, we are still missing two important aspects: the user doesn’t have any way to know the progress of the task nor to retrieve the final result. Let’s <span class="No-Break">fix this!</span></p>&#13;
			<h2 id="_idParaDest-220"><a id="_idTextAnchor1051"/>Sharing data between the worker and the API</h2>&#13;
			<p>As we’ve seen, the<a id="_idIndexMarker996"/> worker is a program running in the background executing the computations the API has asked it to do. However, the worker doesn’t have any way to talk with the API server. That’s expected: since there could be any number of server processes, and since they could even run on different physical servers, processes cannot communicate directly. It’s always the same problem of having a central data source on which processes can write and <span class="No-Break">read data.</span></p>&#13;
			<p>Actually, the first approach to solve the lack of communication between the API and the worker could be to use the same broker we use to schedule tasks: the worker could write results in the broker, and the API could read from it. This is something possible with most background task libraries, including Dramatiq. However, this solution has some limitations, the principal one being the limited time we can retain the data. Brokers, such as Redis, are not really suited to storing data reliably for a long period. At some point, we’ll need to erase the most ancient data to limit <span class="No-Break">memory usage.</span></p>&#13;
			<p>Yet, we already know of something able to store structured data efficiently: a database, of course! That’s the approach we’ll show here. By having a central database where we’ll store our image generation requests and results, we’ll be able to share information between the worker and the API. For this, we’ll reuse a lot of techniques we showed in the <em class="italic">Communicating with a SQL database with SQLAlchemy ORM</em> section of <a href="B19528_06.xhtml#_idTextAnchor346"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>. <span class="No-Break">Let’s go!</span></p>&#13;
			<h3>Defining an SQLAlchemy model</h3>&#13;
			<p>The first step is defining an<a id="_idIndexMarker997"/> SQLAlchemy model to store a single image-generation task. You can see it <span class="No-Break">as follows:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">models.py</p>&#13;
			<pre class="source-code">&#13;
class GeneratedImage(Base):    __tablename__ = "generated_images"&#13;
    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)&#13;
    created_at: Mapped[datetime] = mapped_column(&#13;
        DateTime, nullable=False, default=datetime.now&#13;
    )&#13;
    progress: Mapped[int] = mapped_column(Integer, nullable=False, default=0)&#13;
    prompt: Mapped[str] = mapped_column(Text, nullable=False)&#13;
    negative_prompt: Mapped[str | None] = mapped_column(Text, nullable=True)&#13;
    num_steps: Mapped[int] = mapped_column(Integer, nullable=False)&#13;
    file_name: Mapped[str | None] = mapped_column(String(255), nullable=True)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py</a></p>&#13;
			<p>As usual, we define an auto-incremented ID as the primary key. We also add <strong class="source-inline">prompt</strong>, <strong class="source-inline">negative_prompt</strong>, and <strong class="source-inline">num_steps</strong> columns, which correspond to the arguments we give to the worker task. This way, we’ll be able to directly give the ID to the worker, and it’ll take the parameter directly from the object. Besides, it’ll allow us to store and remember the parameters we used for a <span class="No-Break">specific generation.</span></p>&#13;
			<p>The <strong class="source-inline">progress</strong> column is an integer where we’ll store the current progress of the <span class="No-Break">generation task.</span></p>&#13;
			<p>Finally, <strong class="source-inline">file_name</strong> will<a id="_idIndexMarker998"/> store the actual filename we’ll store on our system. We’ll see how we use it in the next section, about <span class="No-Break">object storage.</span></p>&#13;
			<h3>Adapting the API to save image-generation tasks in a database</h3>&#13;
			<p>With<a id="_idIndexMarker999"/> this model at hand, our approach to scheduling image generation in the API changes a bit. Instead of directly sending the task to the worker, we first create a row in our database and use the ID of this object as input for the worker task. The endpoint implementation is <span class="No-Break">shown here:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">api.py</p>&#13;
			<pre class="source-code">&#13;
@app.post(    "/generated-images",&#13;
    response_model=schemas.GeneratedImageRead,&#13;
    status_code=status.HTTP_201_CREATED,&#13;
)&#13;
async def create_generated_image(&#13;
    generated_image_create: schemas.GeneratedImageCreate,&#13;
    session: AsyncSession = Depends(get_async_session),&#13;
)    GeneratedImage:&#13;
    image = GeneratedImage(**generated_image_create.dict())&#13;
    session.add(image)&#13;
    await session.commit()&#13;
    text_to_image_task.send(image.id)&#13;
    return image</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py</a></p>&#13;
			<p>We won’t go into the details about how to create an object in a database with SQLAlchemy ORM. If you need a refresher, you can refer to the <em class="italic">Communicating with a SQL database with SQLAlchemy ORM</em> section of <a href="B19528_06.xhtml#_idTextAnchor346"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><span class="No-Break">.</span></p>&#13;
			<p>The main thing to notice in this snippet is that we pass the ID of the newly created object as an argument of <strong class="source-inline">text_to_image_task</strong>. As we’ll see right after, the worker will read it again from the database to retrieve the <span class="No-Break">generation parameters.</span></p>&#13;
			<p>The<a id="_idIndexMarker1000"/> response of this endpoint is simply a representation of our <strong class="source-inline">GeneratedImage</strong> model, using the Pydantic schema <strong class="source-inline">GeneratedImageRead</strong>. Thus, the user will get a response like this to <span class="No-Break">their request:</span></p>&#13;
			<pre class="source-code">&#13;
{    "created_at": "2023-02-07T10:17:50.992822",&#13;
    "file_name": null,&#13;
    "id": 6,&#13;
    "negative_prompt": null,&#13;
    "num_steps": 50,&#13;
    "progress": 0,&#13;
    "prompt": "a sunset over a beach"&#13;
}</pre>&#13;
			<p>It shows<a id="_idIndexMarker1001"/> the prompt we gave in our request and, most importantly, <em class="italic">it gives it an ID</em>. This means that the user will be able to query for this specific request again to retrieve the data and see whether it’s done. That’s the purpose of the <strong class="source-inline">get_generated_image</strong> endpoint defined below the previous snippet. We won’t show it here, but you can read it in the <span class="No-Break">examples repository.</span></p>&#13;
			<h3>Adapting the worker to read and update image-generation tasks from a database</h3>&#13;
			<p>You <a id="_idIndexMarker1002"/>probably have guessed that we need to change the implementation of our task so it can retrieve objects from the database instead of reading the parameters directly. Let’s go through this step <span class="No-Break">by step.</span></p>&#13;
			<p>The first thing we do is retrieve a <strong class="source-inline">GeneratedImage</strong> from the database using the ID we got in the <span class="No-Break">task argument.</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
@dramatiq.actor()def text_to_image_task(image_id: int):&#13;
    image = get_image(image_id)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>To achieve this, you see that we use a helper function called <strong class="source-inline">get_image</strong>. It’s defined right <a id="_idIndexMarker1003"/>above the task. Let’s <span class="No-Break">review it:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
def get_image(id: int) -&gt; GeneratedImage:    async def _get_image(id: int) -&gt; GeneratedImage:&#13;
        async with async_session_maker() as session:&#13;
            select_query = select(GeneratedImage).where(GeneratedImage.id == id)&#13;
            result = await session.execute(select_query)&#13;
            image = result.scalar_one_or_none()&#13;
            if image is None:&#13;
                raise Exception("Image does not exist")&#13;
            return image&#13;
    return asyncio.run(_get_image(id))</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>It may look <a id="_idIndexMarker1004"/>quite strange, but actually, you are already familiar with most of its logic. If you look closely, you’ll see that it defines a nested and private function where we define the actual logic to retrieve and save the object using SQLAlchemy ORM. Notice that it’s <em class="italic">async</em>, and that we make great use of async I/O patterns, as we’ve seen throughout <span class="No-Break">this book.</span></p>&#13;
			<p>That’s the exact reason why we need a helper function like this. Indeed, Dramatiq is not designed to run async functions natively, so we need to manually schedule their execution using <strong class="source-inline">asyncio.run</strong>. We already saw this function in <a href="B19528_02.xhtml#_idTextAnchor032"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, where we presented async I/O. Its role is to run an async function and return its result. That’s how we can call the wrapping function synchronously in our task without <span class="No-Break">any issues.</span></p>&#13;
			<p class="callout-heading">Other approaches could work to tackle the async I/O problem</p>&#13;
			<p class="callout">The approach we show here is the most straightforward and robust one to tackle the problem of <span class="No-Break">asynchronous workers.</span></p>&#13;
			<p class="callout">Another approach could be to set up a decorator or middleware for Dramatiq so it could natively run async functions, but this is complex and subject <span class="No-Break">to bugs.</span></p>&#13;
			<p class="callout">We could also consider having another SQLAlchemy engine and session maker that works synchronously. However, this would require us to have a lot of duplicated things in our code. Besides, this wouldn’t help if we had async functions other <span class="No-Break">than SQLAlchemy.</span></p>&#13;
			<p>Now, let’s get back to the implementation <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">text_to_image_task</strong></span><span class="No-Break">:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
@dramatiq.actor()def text_to_image_task(image_id: int):&#13;
    image = get_image(image_id)&#13;
    def callback(step: int, _timestep, _tensor):&#13;
        update_progress(image, step)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>We define a <strong class="source-inline">callback</strong> function for the Stable Diffusion pipeline. Its role is to save the current progress in a database for the current <strong class="source-inline">GeneratedImage</strong>. For this, we once again use a helper<a id="_idIndexMarker1005"/> <span class="No-Break">function, </span><span class="No-Break"><strong class="source-inline">update_progress</strong></span><span class="No-Break">:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
def update_progress(image: GeneratedImage, step: int):    async def _update_progress(image: GeneratedImage, step: int):&#13;
        async with async_session_maker() as session:&#13;
            image.progress = int((step / image.num_steps) * 100)&#13;
            session.add(image)&#13;
            await session.commit()&#13;
    asyncio.run(_update_progress(image, step))</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>We use the same approach we explained for <strong class="source-inline">get_image</strong>, so we can wrap the <span class="No-Break">async function.</span></p>&#13;
			<p>Going back to <strong class="source-inline">text_to_image_task</strong>, we can now call our <strong class="source-inline">TextToImage</strong> model to generate an image. It’s exactly the same call we showed in the previous section. The only difference is that we take the parameters from the <strong class="source-inline">image</strong> object. We also generate a <a id="_idIndexMarker1006"/>random filename using <span class="No-Break">a UUID:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
    image_output = text_to_image_middleware.text_to_image.generate(        image.prompt,&#13;
        negative_prompt=image.negative_prompt,&#13;
        num_steps=image.num_steps,&#13;
        callback=callback,&#13;
    )&#13;
    file_name = f"{uuid.uuid4()}.png"</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>The following part is designed to upload the image to object storage. We’ll explain this in more detail in the <span class="No-Break">next section:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
    storage = Storage()    storage.upload_image(image_output, file_name, settings.storage_bucket)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>Finally, we call another helper function, <strong class="source-inline">update_file_name</strong>, to save the random filename in the database. It’ll allow us to retrieve the file for <span class="No-Break">the user:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
    update_file_name(image, file_name)</pre>			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>As you can see, the main point of attention throughout this implementation is that we read and write information about <strong class="source-inline">GeneratedImage</strong> from and to the database. This is how we can <em class="italic">synchronize</em> between the API server and the worker. That’s it for the worker! With this logic, we are able to schedule an image-generation task from the API, and the worker is able to regularly update the task progress before setting the resulting filename. Thus, from <a id="_idIndexMarker1007"/>the API, a simple <strong class="source-inline">GET</strong> request allows us to see the status of <span class="No-Break">our task.</span></p>&#13;
			<h2 id="_idParaDest-221"><a id="_idTextAnchor1052"/>Storing and serving files in object storage</h2>&#13;
			<p>The last challenge <a id="_idIndexMarker1008"/>we have to tackle concerns the storage of our resulting images. We need a way to store them reliably while letting users retrieve them easily from <span class="No-Break">the internet.</span></p>&#13;
			<p>Traditionally, web applications handled this quite simply. They stored the files directly on the server hard disk, in a defined directory, and configured their web server to serve those files when accessed under a certain URL. This is actually what we did in <a href="B19528_13.xhtml#_idTextAnchor1005"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, in the WebSocket example: we used the <strong class="source-inline">StaticFiles</strong> middleware to statically serve the JavaScript script we had <span class="No-Break">on disk.</span></p>&#13;
			<p>While this works well for static files, such as JavaScript or CSS files, for which each server has its own copy, it is not suitable for dynamic files uploaded by the user or generated by the backend, in particular for complex architectures where several processes are run on different physical machines. Once again, this is the problem of having a central source of data that the different processes read from. In the previous sections, we saw that message brokers and databases could solve this issue in several contexts. In the case of arbitrary binary files, whether they are images, videos, or simple text files, we need something else. Let’s<a id="_idIndexMarker1009"/> introduce <span class="No-Break"><strong class="bold">object storage</strong></span><span class="No-Break">.</span></p>&#13;
			<p>Object storage is a bit different from the standard file storage we use daily in computers, where the disk is organized in a hierarchy of directories and files. Instead, object storage will store each file as an object, which includes the actual data and all its metadata, such as its name, size, type, and a unique ID. The main benefit of such conceptualization is that it’s easier to spread those files across multiple physical machines: <em class="italic">we can store billions of files on the same object storage</em>. From the user’s point of view, we just ask for a specific file, and the storage will take care of loading the file from the actual <span class="No-Break">physical disk.</span></p>&#13;
			<p>In the cloud era, this approach has obviously <a id="_idIndexMarker1010"/>gained a lot of popularity. In 2006, <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) launched Amazon S3, its own implementation <a id="_idIndexMarker1011"/>of object storage. It gave developers access to virtually unlimited disk space to store files using a simple API, all at a very cheap price. Amazon S3 gained so much popularity its API became the de facto standard in the industry. Nowadays, most cloud object storage, including storage from competitors such as Microsoft Azure or Google Cloud, is compatible with the S3 API. Open source implementations have also emerged, such as MinIO. The main benefit of this common S3 API is that you can use the same code and libraries in your project to talk with any object storage provider and easily switch <span class="No-Break">if needed.</span></p>&#13;
			<p>To sum up, object storage is a very convenient way to store and serve files at scale, no matter the number of processes that need to access this data. At the end of this section, the global architecture of our project will look like the one shown in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer068" class="IMG---Figure">&#13;
					<img src="Images/Figure_14.5_B19528.jpg" alt="Figure 14.5 – Web-queue-worker architecture and object storage" width="1394" height="956"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – Web-queue-worker architecture and object storage</p>&#13;
			<p>It’s worth<a id="_idIndexMarker1012"/> noting that the <em class="italic">object storage will serve the file directly to the user</em>. There won’t be an endpoint where the server would act as a proxy by downloading the file from the object storage before sending it to the user. There isn’t much benefit in doing it that way, even in terms of authentication. We’ll see that S3-compatible storage has built-in mechanisms to protect files from <span class="No-Break">unauthorized access.</span></p>&#13;
			<h3>Implementing an object storage helper</h3>&#13;
			<p>Let’s get to the <a id="_idIndexMarker1013"/>code then! We’ll use the MinIO client for Python, a library to interact with any S3-compatible storage. Let’s <span class="No-Break">install it:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install minio</pre>			<p>We can now implement a class to have all the operations we need at hand. Let’s first go with <span class="No-Break">the initializer:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">storage.py</p>&#13;
			<pre class="source-code">&#13;
class Storage:    def __init__(self) -&gt; None:&#13;
        self.client = Minio(&#13;
            settings.storage_endpoint,&#13;
            access_key=settings.storage_access_key,&#13;
            secret_key=settings.storage_secret_key,&#13;
        )</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py</a></p>&#13;
			<p>In the initializer of this class, we create a <strong class="source-inline">Minio</strong> client instance. You’ll see that we use a <strong class="source-inline">settings</strong> object to pull the storage URL and credentials. Thus, it’s very easy to switch them by using <span class="No-Break">environment variables.</span></p>&#13;
			<p>We’ll then<a id="_idIndexMarker1014"/> implement several methods that’ll help us work with object storage. The first one <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">ensure_bucket</strong></span><span class="No-Break">:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">storage.py</p>&#13;
			<pre class="source-code">&#13;
    def ensure_bucket(self, bucket_name: str):        bucket_exists = self.client.bucket_exists(bucket_name)&#13;
        if not bucket_exists:&#13;
            self.client.make_bucket(bucket_name)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py</a></p>&#13;
			<p>The<a id="_idIndexMarker1015"/> role of this method is to make sure the right bucket is created in our object storage. In S3 implementations, a <strong class="bold">bucket</strong> is like a folder<a id="_idIndexMarker1016"/> that you own and in which you can store your files. Each file you upload has to be put into an <span class="No-Break">existing bucket.</span></p>&#13;
			<p>Then, we <span class="No-Break">define </span><span class="No-Break"><strong class="source-inline">upload_image</strong></span><span class="No-Break">:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">storage.py</p>&#13;
			<pre class="source-code">&#13;
    def upload_image(self, image: Image, object_name: str, bucket_name: str):        self.ensure_bucket(bucket_name)&#13;
        image_data = io.BytesIO()&#13;
        image.save(image_data, format="PNG")&#13;
        image_data.seek(0)&#13;
        image_data_length = len(image_data.getvalue())&#13;
        self.client.put_object(&#13;
            bucket_name,&#13;
            object_name,&#13;
            image_data,&#13;
            length=image_data_length,&#13;
            content_type="image/png",&#13;
        )</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py</a></p>&#13;
			<p>This is for <a id="_idIndexMarker1017"/>uploading an image to the storage. To simplify things, this method accepts a Pillow <strong class="source-inline">Image</strong>, as it’s the result we get at the end of the Stable Diffusion pipeline. We implemented some logic to convert this <strong class="source-inline">Image</strong> object into a raw stream of bytes suitable for the S3 upload. This method also expects <strong class="source-inline">object_name</strong>, which will be the actual name of the file in the storage, along with <strong class="source-inline">bucket_name</strong>. Notice that we first ensure the bucket is correctly created before trying to upload <span class="No-Break">the file.</span></p>&#13;
			<p>Finally, we <a id="_idIndexMarker1018"/>add the <span class="No-Break"><strong class="source-inline">get_presigned_url</strong></span><span class="No-Break"> method:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">storage.py</p>&#13;
			<pre class="source-code">&#13;
    def get_presigned_url(        self,&#13;
        object_name: str,&#13;
        bucket_name: str,&#13;
        *,&#13;
        expires: timedelta = timedelta(days=7)&#13;
    )    str:&#13;
        return self.client.presigned_get_object(&#13;
            bucket_name, object_name, expires=expires&#13;
        )</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py</a></p>&#13;
			<p>This method will help us to serve the file securely to the user. By default, for security reasons, files in S3 storage are not accessible by any user on the internet. To give access to a file, we can do either of <span class="No-Break">the following:</span></p>&#13;
			<ul>&#13;
				<li>Set the file as public so anybody with the URL can access it. This is suitable for public files but certainly not for private <span class="No-Break">user files.</span></li>&#13;
				<li>Generate a URL with a temporary access key. Thus, we can give access to the file to the user, knowing that even if the URL is stolen, the access will be revoked after a certain time. The huge benefit of this is that this URL generation happens on our API server using the S3 client. Therefore, we could check whether the user is correctly authenticated and has the rights to this specific file following our own logic before generating the file URL. This is the approach we adopt here, and this method generates the pre-signed URL on a specific file in a specific bucket for a certain amount <span class="No-Break">of time.</span></li>&#13;
			</ul>&#13;
			<p>As you can see, our<a id="_idIndexMarker1019"/> class is just a thin wrapper around the MinIO client. All we have to do now is to use it to upload the images and get a pre-signed URL from <span class="No-Break">the API.</span></p>&#13;
			<h3>Using the object storage helper in the worker</h3>&#13;
			<p>In the <a id="_idIndexMarker1020"/>previous section, we showed the following lines in our <span class="No-Break">task implementation:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">worker.py</p>&#13;
			<pre class="source-code">&#13;
    storage = Storage()    storage.upload_image(image_output, file_name, settings.storage_bucket)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py</a></p>&#13;
			<p>Now that we’ve talked about the <strong class="source-inline">Storage</strong> class, you should guess what we’re doing here: we take the generated image and its random name and upload it to a bucket defined in <strong class="source-inline">settings</strong>. And… <span class="No-Break">That’s it!</span></p>&#13;
			<h3>Generating a pre-signed URL on the server</h3>&#13;
			<p>On the<a id="_idIndexMarker1021"/> API’s side, we implement a new endpoint whose role is to return a pre-signed URL for a <span class="No-Break">given </span><span class="No-Break"><strong class="source-inline">GeneratedImage</strong></span><span class="No-Break">:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">server.py</p>&#13;
			<pre class="source-code">&#13;
@app.get("/generated-images/{id}/url")async def get_generated_image_url(&#13;
    image: GeneratedImage = Depends(get_generated_image_or_404),&#13;
    storage: Storage = Depends(get_storage),&#13;
)    schemas.GeneratedImageURL:&#13;
    if image.file_name is None:&#13;
        raise HTTPException(&#13;
            status_code=status.HTTP_400_BAD_REQUEST,&#13;
            detail="Image is not available yet. Please try again later.",&#13;
        )&#13;
    url = storage.get_presigned_url(image.file_name, settings.storage_bucket)&#13;
    return schemas.GeneratedImageURL(url=url)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py</a></p>&#13;
			<p>Before generating the URL, we first check whether the <strong class="source-inline">file_name</strong> property is set on the <strong class="source-inline">GeneratedImage</strong> object. If it’s not, it means the worker has not completed the task yet. If it is, we can proceed with the call to the <strong class="source-inline">get_presigned_url</strong> method of our <span class="No-Break"><strong class="source-inline">Storage</strong></span><span class="No-Break"> class.</span></p>&#13;
			<p>Notice that <a id="_idIndexMarker1022"/>we took care of defining a dependency injection to get our <strong class="source-inline">Storage</strong> instance. As we’ve seen throughout this book, using dependencies in FastAPI is a very good practice when dealing with <span class="No-Break">external services.</span></p>&#13;
			<p>Well, it seems that we’re all set! Let’s see it <span class="No-Break">in action.</span></p>&#13;
			<h3>Running the image-generation system</h3>&#13;
			<p>First of all, we need <a id="_idIndexMarker1023"/>to populate the <a id="_idIndexMarker1024"/>environment variables for our project with, in particular, a database URL and S3 credentials. To keep things simple, we’ll use a simple SQLite database and the MinIO playground for the S3 storage. It’s a free and open instance of MinIO object storage that’s perfect for examples and toy projects. When going into production, you’ll be able to easily switch to any S3-compatible provider. Let’s create a <strong class="source-inline">.env</strong> file at the root of <span class="No-Break">the project:</span></p>&#13;
			<pre class="source-code">&#13;
DATABASE_URL=sqlite+aiosqlite:///chapter14.dbSTORAGE_ENDPOINT=play.min.io&#13;
STORAGE_ACCESS_KEY=Q3AM3UQ867SPQQA43P2F&#13;
STORAGE_SECRET_KEY=zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG&#13;
STORAGE_BUCKET=fastapi-book-text-to-image</pre>&#13;
			<p>The storage endpoint, access key, and secret key are the parameters for the MinIO playground. Make sure to check their official documentation to see whether they have changed since we wrote this <span class="No-Break">book: </span><a href="https://min.io/docs/minio/linux/developers/python/minio-py.html#id5"><span class="No-Break">https://min.io/docs/minio/linux/developers/python/minio-py.html#id5</span></a><span class="No-Break">.</span></p>&#13;
			<p>Our <strong class="source-inline">Settings</strong> class will automatically load this file to populate the settings we use throughout the code. Make sure to check the <em class="italic">Setting and using environment variables</em> section of <a href="B19528_10.xhtml#_idTextAnchor694"><span class="No-Break"><em class="italic">Chapter 10</em></span></a> if you need a refresher on <span class="No-Break">this concept.</span></p>&#13;
			<p>We can now run our system. Make sure your<a id="_idIndexMarker1025"/> Redis server is still running, as explained <a id="_idIndexMarker1026"/>in the <em class="italic">Technical requirements</em> section. First of all, let’s run the <span class="No-Break">FastAPI server:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ uvicorn chapter14.complete.api:app</pre>			<p>Then, start <span class="No-Break">the worker:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ dramatiq -p 1 -t 1 chapter14.complete.worker</pre>			<p>The stack is now ready to generate images. Let’s make a request with HTTPie to start a <span class="No-Break">new task:</span></p>&#13;
			<pre class="source-code">&#13;
$ http POST http://localhost:8000/generated-images prompt="a sunset over a beach"HTTP/1.1 201 Created&#13;
content-length: 151&#13;
content-type: application/json&#13;
date: Mon, 13 Feb 2023 07:24:44 GMT&#13;
server: uvicorn&#13;
{&#13;
    "created_at": "2023-02-13T08:24:45.954240",&#13;
    "file_name": null,&#13;
    "id": 1,&#13;
    "negative_prompt": null,&#13;
    "num_steps": 50,&#13;
    "progress": 0,&#13;
    "prompt": "a sunset over a beach"&#13;
}</pre>&#13;
			<p>A new <strong class="source-inline">GeneratedImage</strong> has been created in the database with the assigned ID <strong class="source-inline">1</strong>. The progress<a id="_idIndexMarker1027"/> is at <em class="italic">0%</em>; the processing has<a id="_idIndexMarker1028"/> not started yet. Let’s try to query it with <span class="No-Break">our API:</span></p>&#13;
			<pre class="source-code">&#13;
http GET http://localhost:8000/generated-images/1HTTP/1.1 200 OK&#13;
content-length: 152&#13;
content-type: application/json&#13;
date: Mon, 13 Feb 2023 07:25:04 GMT&#13;
server: uvicorn&#13;
{&#13;
    "created_at": "2023-02-13T08:24:45.954240",&#13;
    "file_name": null,&#13;
    "id": 1,&#13;
    "negative_prompt": null,&#13;
    "num_steps": 50,&#13;
    "progress": 36,&#13;
    "prompt": "a sunset over a beach"&#13;
}</pre>&#13;
			<p>The<a id="_idIndexMarker1029"/> API returns <a id="_idIndexMarker1030"/>the same object with all its properties. Notice that the progress has been updated and that it’s now at <em class="italic">36%</em>. After a while, we can try the same <span class="No-Break">request again:</span></p>&#13;
			<pre class="source-code">&#13;
$ http GET http://localhost:8000/generated-images/1HTTP/1.1 200 OK&#13;
content-length: 191&#13;
content-type: application/json&#13;
date: Mon, 13 Feb 2023 07:25:34 GMT&#13;
server: uvicorn&#13;
{&#13;
    "created_at": "2023-02-13T08:24:45.954240",&#13;
    "file_name": "affeec65-5d9b-480e-ac08-000c74e22dc9.png",&#13;
    "id": 1,&#13;
    "negative_prompt": null,&#13;
    "num_steps": 50,&#13;
    "progress": 100,&#13;
    "prompt": "a sunset over a beach"&#13;
}</pre>&#13;
			<p>This<a id="_idIndexMarker1031"/> time, the <a id="_idIndexMarker1032"/>progress is at <em class="italic">100%</em> and the filename has been filled. The image is ready! We can now ask our API to generate a pre-signed URL for <span class="No-Break">this image:</span></p>&#13;
			<pre class="source-code">&#13;
$ http GET http://localhost:8000/generated-images/1/urlHTTP/1.1 200 OK&#13;
content-length: 366&#13;
content-type: application/json&#13;
date: Mon, 13 Feb 2023 07:29:53 GMT&#13;
server: uvicorn&#13;
{&#13;
    "url": "https://play.min.io/fastapi-book-text-to-image/affeec65-5d9b-480e-ac08-000c74e22dc9.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=Q3AM3UQ867SPQQA43P2F%2F20230213%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20230213T072954Z&amp;X-Amz-Expires=604800&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=6ffddb81702bed6aac50786578eb75af3c1f6a3db28e4990467c973cb3b457a9"&#13;
}</pre>&#13;
			<p>We get a very long URL on the MinIO server. If you open it in your browser, you’ll see the image that has just been generated by our system, as you can see in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer069" class="IMG---Figure">&#13;
					<img src="Images/Figure_14.6_B19528.jpg" alt="Figure 14.6 – Generated image hosted on object storage" width="1650" height="650"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.6 – Generated image hosted on object storage</p>&#13;
			<p>Quite nice, isn’t it? We now have a fully featured system where the user is able to do <span class="No-Break">the following:</span></p>&#13;
			<ul>&#13;
				<li>Request to generate images following their own prompt <span class="No-Break">and parameters</span></li>&#13;
				<li>Get information about the progress of <span class="No-Break">the request</span></li>&#13;
				<li>Get the resulting image from <span class="No-Break">reliable storage</span></li>&#13;
			</ul>&#13;
			<p>The architecture<a id="_idIndexMarker1033"/> we see<a id="_idIndexMarker1034"/> here is already deployable in a cloud environment with multiple machines. Typically, we may have a standard, cheap server to serve the API and a more expensive one with a dedicated GPU and a good amount of RAM to run the worker. The code doesn’t have to change to handle this kind of deployment since the communication between processes is handled by the central elements – the message broker, the database, and the <span class="No-Break">object storage.</span></p>&#13;
			<h1 id="_idParaDest-222"><a id="_idTextAnchor1053"/>Summary</h1>&#13;
			<p>Awesome! You may not have realized it yet, but in this chapter, you learned how to architect and implement a very complex machine learning system that could rival existing image-generation services you see out there. The concepts we showed here are essential and are at the heart of all the distributed systems you could imagine, whether they are designed to run machine learning models, extraction pipelines, or math computations. By using modern tools such as FastAPI and Dramatiq, you’ll be able to implement this kind of architecture in a short time with a minimum amount of code, leading to a very quick and <span class="No-Break">robust result.</span></p>&#13;
			<p>We’re near the end of our journey. Before letting you live your own adventures with FastAPI, we’ll study one last important aspect when building data science applications: logging <span class="No-Break">and monitoring.</span></p>&#13;
		</div>&#13;
	</div></body></html>