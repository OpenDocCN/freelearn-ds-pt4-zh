- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Creating a Distributed Text-to-Image AI System Using the Stable Diffusion Model
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 模型创建分布式文本到图像 AI 系统
- en: 'Until now, in this book, we’ve built APIs where all the operations were computed
    inside the request handling. Said another way, before they could get their response,
    the user had to wait for the server to do everything we had defined: request validation,
    database queries, ML predictions, and so on. However, this behavior is not always
    desired or possible.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在这本书中，我们构建的 API 中所有操作都是在请求处理内部计算的。换句话说，用户必须等待服务器完成我们定义的所有操作（如请求验证、数据库查询、ML
    预测等），才能收到他们的响应。然而，并非总是希望或可能要求这种行为。
- en: 'A typical example is email notifications. It happens quite often in a web application
    that we need to send an email to the user because they just registered or they
    performed a specific action. To do this, the server needs to send a request to
    an email server so the email can be sent. This operation could take a few milliseconds.
    If we do this inside the request handling, the response will be delayed until
    we send the email. This is not a very good experience since the user doesn’t really
    care how and when the email is sent. This example is typical of what we usually
    call **background operations**: things that need to be done in our application
    but don’t require direct user interaction.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 典型例子是电子邮件通知。在 Web 应用程序中，我们经常需要向用户发送电子邮件，因为他们刚刚注册或执行了特定操作。为了做到这一点，服务器需要向电子邮件服务器发送请求，以便发送电子邮件。此操作可能需要几毫秒时间。如果我们在请求处理中执行此操作，响应将延迟直到我们发送电子邮件。这不是一个很好的体验，因为用户并不真正关心电子邮件是如何何时发送的。这个例子是我们通常所说的**后台操作**的典型例子：需要在我们的应用程序中完成的事情，但不需要直接用户交互。
- en: Another case is when the user requests an expensive operation that can’t be
    done in a reasonable time. It’s usually the case for complex data exports or heavy
    AI models. In this context, the user would like to get the result directly, but
    doing this in the request handler would block the server process until it’s done.
    If lots of users were requesting this kind of operation, it would quickly make
    our server unresponsive. Besides, some network infrastructure such as proxy or
    web clients, like browsers, have quite strict timeout settings, meaning they will
    usually cancel an operation if it takes too much time to respond.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种情况是当用户请求一个耗时的操作，在合理的时间内无法完成。这通常是复杂数据导出或重型 AI 模型的情况。在这种情况下，用户希望直接获取结果，但如果在请求处理程序中执行此操作，将会阻塞服务器进程，直到完成。如果大量用户请求这种操作，会迅速使我们的服务器无响应。此外，某些网络基础设施，如代理或
    Web 客户端（如浏览器），具有非常严格的超时设置，这意味着如果响应时间过长，它们通常会取消操作。
- en: 'To solve this, we’ll introduce a typical architecture for web applications:
    **web-queue-worker**. As we’ll see in this chapter, we’ll defer the most expensive,
    long operations to a background process, a **worker**. To show you this architecture
    in action, we’ll build our very own AI system to generate images from text prompts
    using the **Stable** **Diffusion** model.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们将引入一个典型的 Web 应用程序架构：**web-queue-worker**。正如我们将在本章中看到的，我们将把最昂贵、耗时最长的操作推迟到后台进程，即**worker**。为了展示这种架构的运行方式，我们将建立我们自己的
    AI 系统，使用**Stable Diffusion**模型根据文本提示生成图像。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将涵盖以下主要话题：
- en: Using the Stable Diffusion model with Hugging Face Diffusers to generate images
    from text prompts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 模型与 Hugging Face Diffusers 生成图像的文本提示
- en: Implementing a worker process using Dramatiq and an image-generation task
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Dramatiq 实现工作进程和图像生成任务
- en: Storing and serving files in object storage
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储和服务于对象存储中的文件
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you’ll require a Python virtual environment, just as we set
    up in [*Chapter 1*](B19528_01.xhtml#_idTextAnchor024), *Python Development* *Environment
    Setup*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您将需要一个 Python 虚拟环境，就像我们在[*第 1 章*](B19528_01.xhtml#_idTextAnchor024)中设置的那样，*Python
    开发环境设置*。
- en: 'To run the Stable Diffusion model correctly, we recommend you have a recent
    computer equipped with at least 16 GB of RAM and, ideally, a dedicated GPU with
    8 GB of VRAM. For Mac users, recent models equipped with the M1 Pro or M2 Pro
    chips are also a good fit. If you don’t have that kind of machine, don’t worry:
    we’ll show you ways to run the system anyway – the only drawback is that image
    generation will be slow and show poor results.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确运行 Stable Diffusion 模型，我们建议你使用配备至少 16 GB RAM 的最新计算机，理想情况下还应配备 8 GB VRAM
    的专用 GPU。对于 Mac 用户，配备 M1 Pro 或 M2 Pro 芯片的最新型号也非常适合。如果你没有这种机器，也不用担心：我们会告诉你如何以其他方式运行系统——唯一的缺点是图像生成会变慢并且效果较差。
- en: 'For running the worker, you’ll need a running **Redis server** on your local
    computer. The easiest way is to run it as a Docker container. If you’ve never
    used Docker before, we recommend you read the *Getting started* tutorial in the
    official documentation at [https://docs.docker.com/get-started/](https://docs.docker.com/get-started/).
    Once done, you’ll be able to run a Redis server with this simple command:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行工作程序，你需要在本地计算机上运行**Redis 服务器**。最简单的方法是将其作为 Docker 容器运行。如果你以前从未使用过 Docker，我们建议你阅读官方文档中的*入门教程*，网址为[https://docs.docker.com/get-started/](https://docs.docker.com/get-started/)。完成后，你将能够通过以下简单命令运行
    Redis 服务器：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You’ll find all the code examples of this chapter in the dedicated GitHub repository
    at [https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在专用的 GitHub 仓库中找到本章的所有代码示例，地址为[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14)。
- en: Generating images from text prompts with Stable Diffusion
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 从文本提示生成图像
- en: 'Recently, a new generation of AI tools has emerged and fascinated the whole
    world: image-generation models, such as DALL-E or Midjourney. Those models are
    trained on huge amounts of image data and are able to generate completely new
    images from a simple text prompt. These AI models are very good use cases for
    background workers: they take seconds or even minutes to process, and they need
    lots of resources in the CPU, RAM, and even the GPU.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一种新一代的 AI 工具引起了全世界的关注：图像生成模型，例如 DALL-E 或 Midjourney。这些模型是在大量图像数据上进行训练的，能够从简单的文本提示中生成全新的图像。这些
    AI 模型非常适合作为后台工作程序：它们的处理时间为几秒钟甚至几分钟，并且需要大量的 CPU、RAM 甚至 GPU 资源。
- en: To build our system, we’ll rely on Stable Diffusion, a very popular image-generation
    model that was released in 2022\. This model is available publicly and can be
    run on a modern gaming computer. As we did in the previous chapter, we’ll rely
    on Hugging Face tools for both downloading the model and running it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们的系统，我们将依赖于 Stable Diffusion，这是一种非常流行的图像生成模型，发布于 2022 年。该模型是公开的，可以在现代游戏计算机上运行。正如我们在上一章中所做的，我们将依赖
    Hugging Face 工具来下载和运行该模型。
- en: 'Let’s first install the required tools:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们安装所需的工具：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We’re now ready to use diffuser models thanks to Hugging Face.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好通过 Hugging Face 使用扩散模型了。
- en: Implementing the model in a Python script
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Python 脚本中实现模型
- en: 'In the following example, we’ll show you the implementation of a class able
    to instantiate the model and run an image generation. Once again, we’ll apply
    our lazy loading pattern with separate `load_model` and `generate` methods. Let’s
    first focus on `load_model`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将展示一个能够实例化模型并运行图像生成的类的实现。再次提醒，我们将应用懒加载模式，使用单独的 `load_model` 和 `generate`
    方法。首先，让我们专注于 `load_model`：
- en: text_to_image.py
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: text_to_image.py
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
- en: The first part of this method aims to find the most efficient way to run the
    model given your computer. These diffusion models are faster when run on the GPU
    – that’s why we check first if there are CUDA (NVIDIA GPU) or MPS (Apple Silicon)
    devices available. If there are none, we fall back to the CPU.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的第一部分旨在根据你的计算机找到最有效的运行模型的方式。当在GPU上运行时，这些扩散模型的速度更快——这就是为什么我们首先检查是否有CUDA（NVIDIA
    GPU）或MPS（Apple Silicon）设备可用。如果没有，我们将退回到CPU。
- en: 'Then, we simply have to create a `StableDiffusionPipeline` pipeline, as provided
    by Hugging Face. We simply have to set the model we want to download from the
    hub. For this example, we chose `runwayml/stable-diffusion-v1-5`. You can find
    its details on Hugging Face: [https://huggingface.co/runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只需创建一个由Hugging Face提供的`StableDiffusionPipeline`管道。我们只需要设置我们想要从Hub下载的模型。对于这个例子，我们选择了`runwayml/stable-diffusion-v1-5`。你可以在Hugging
    Face上找到它的详细信息：[https://huggingface.co/runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)。
- en: 'We can now focus on the `generate` method:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以专注于`generate`方法：
- en: text_to_image.py
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: text_to_image.py
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
- en: 'You can see it accepts four parameters:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到它接受四个参数：
- en: '`prompt`, which is, of course, the text prompt describing the image we want
    to generate.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`，当然，这是描述我们想要生成的图像的文本提示。'
- en: '`negative_prompt`, which is an optional prompt to tell the model what we absolutely
    don’t want.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`，这是一个可选的提示，用于告诉模型我们绝对不希望出现的内容。'
- en: '`num_steps`, which is the number of inference steps the model should run. More
    steps lead to a better image, but each iteration delays the inference. The default,
    `50`, should provide a good balance between speed and quality.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_steps`，即模型应执行的推理步骤数。更多步骤会导致更好的图像，但每次迭代都会延迟推理。默认值`50`应该在速度和质量之间提供良好的平衡。'
- en: '`callback`, which is an optional function that will be called at each iteration
    step. This is helpful to be informed about the progress of the generation and
    possibly execute more logic, such as saving the progress in a database.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback`，这是一个可选的函数，它将在每次迭代步骤中被调用。这对于了解生成进度并可能执行更多逻辑（如将进度保存到数据库中）非常有用。'
- en: What does the asterisk (*) in the method signature mean?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 方法签名中的星号（*）是什么意思？
- en: 'You may have noticed the asterisk, `*`, in the method signature. It tells Python
    that the arguments coming after this symbol should only be treated as keyword-only
    arguments. Said another way, you can only call them like this: `.generate("PROMPT",`
    `negative_prompt="NEGATIVE", num_steps=10)`.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到方法签名中的星号（`*`）。它告诉Python，星号后面的参数应该仅作为关键字参数处理。换句话说，你只能像这样调用它们：`.generate("PROMPT",`
    `negative_prompt="NEGATIVE", num_steps=10)`。
- en: While not necessary, it’s a way to keep your functions clear and self-explanatory.
    It’s especially true if you develop classes or functions that are meant to be
    used by other developers.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不是必须的，但这是一种保持函数清晰且自解释的方式。如果你开发的是供其他开发者使用的类或函数，这尤其重要。
- en: 'Another syntax also exists to force arguments to be positional-only, using
    a slash (`/`) symbol. You can read more about it here: [https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters](https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种语法可以强制参数仅作为位置参数传递，方法是使用斜杠（`/`）符号。你可以在这里阅读更多相关内容：[https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters](https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters)。
- en: 'All we have to do then is to pass those parameters to `pipe`. There are a lot
    more parameters for you to tune if needed, but the default ones should give you
    quite good results. You can find the whole list of them in the Hugging Face documentation:
    [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__).
    This `pipe` object is able to generate several images per prompt, that’s why the
    result of this operation is a list of Pillow images. The default here is to generate
    only one image, so we directly return the first one.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只需要将这些参数传递给`pipe`。如果需要的话，还有更多的参数可以调节，但默认的参数应该会给你不错的结果。你可以在 Hugging Face
    文档中找到完整的参数列表：[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__)。这个`pipe`对象能够为每个提示生成多张图像，因此该操作的结果是一个Pillow图像列表。这里的默认行为是生成一张图像，所以我们直接返回第一张。
- en: And that’s about it! Once again, Hugging Face makes our lives really easy by
    allowing us to run cutting-edge models in dozens of lines!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些！再次感谢 Hugging Face，通过允许我们在几十行代码内运行最前沿的模型，真的是让我们的生活变得更轻松！
- en: Executing the Python script
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行 Python 脚本
- en: 'We bet that you’re eager to try it yourself – that’s why we added a small `main`
    script at the bottom of our example:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们敢打赌你急于自己试一试——所以我们在示例的底部添加了一个小的`main`脚本：
- en: text_to_image.py
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: text_to_image.py
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
- en: This small script instantiates our `TextToImage` class, loads the model, and
    generates an image before saving it to disk. We also define a dummy callback function
    so you can see how it works.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小脚本实例化了我们的`TextToImage`类，加载了模型，并在保存到磁盘之前生成了图像。我们还定义了一个虚拟回调函数，让你能看到它是如何工作的。
- en: 'When you run this script for the first time, you’ll notice that Hugging Face
    downloads files of several gigabytes to your computer: that’s the Stable Diffusion
    model, and it’s indeed quite big!'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当你第一次运行这个脚本时，你会注意到 Hugging Face 会将几个 GB 的文件下载到你的计算机上：那就是稳定扩散模型，确实相当庞大！
- en: Then, the inference will start. You’ll see a progress bar showing you how many
    inference steps are left, along with the `print` statement from our callback,
    as shown in *Figure 14**.1*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，推理开始了。你会看到一个进度条，显示剩余的推理步骤数，并显示我们回调函数中的`print`语句，如*图 14.1*所示。
- en: '![Figure 14.1 – Stable Diffusion generating an image](img/Figure_14.1_B19528.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.1 – 稳定扩散生成图像](img/Figure_14.1_B19528.jpg)'
- en: Figure 14.1 – Stable Diffusion generating an image
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 – 稳定扩散生成图像
- en: How much time does it take to generate a single image?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一张图像需要多长时间？
- en: We’ve run several tests on different types of computers. With a modern NVIDIA
    GPU with 8 GB of RAM or a Mac with an M1 Pro chip, the model is able to generate
    an image with 50 inference steps in *around a minute*, with reasonable RAM usage.
    When run on a CPU, it takes around *5 to 10 minutes* and eats up to 16 GB of RAM.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在不同类型的计算机上进行了多次测试。在配备8 GB RAM的现代NVIDIA GPU或M1 Pro芯片的Mac上，模型能够在*大约一分钟*内生成一张图像，并且内存使用合理。而在CPU上运行时，大约需要*5到10分钟*，并且会占用多达16
    GB的内存。
- en: If the inference is really too slow on your computer, you can try to reduce
    the `num_steps` parameter.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的计算机上推理速度确实太慢，你可以尝试减少`num_steps`参数。
- en: When the inference is done, you’ll find your generated image on the disk along
    with your script. *Figure 14**.2* shows an example of such a result. Nice, isn’t
    it?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当推理完成后，你会在磁盘上找到生成的图像和你的脚本。*图 14.2*展示了这种结果的一个例子。不错吧？
- en: '![Figure 14.2 – Result of a Stable Diffusion image generation](img/Figure_14.2_B19528.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.2 – 稳定扩散图像生成结果](img/Figure_14.2_B19528.jpg)'
- en: Figure 14.2 – Result of a Stable Diffusion image generation
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 – 稳定扩散图像生成结果
- en: We now have the fundamental brick of our AI system. Now, we need to build an
    API so users can generate their own images. As we’ve just seen, generating a single
    image takes some time. As we said in the introduction, we’ll need to introduce
    a web-queue-worker architecture to make this system reliable and scalable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经拥有了我们 AI 系统的基础构件。接下来，我们需要构建一个 API，供用户生成自己的图像。正如我们刚刚看到的，生成一张图像需要一些时间。正如我们在介绍中所说的，我们需要引入一个
    Web 队列工作进程架构，使得这个系统既可靠又具有可扩展性。
- en: Creating a Dramatiq worker and defining an image-generation task
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 Dramatiq 工作进程并定义图像生成任务
- en: 'As we mentioned in the introduction of this chapter, it’s not conceivable to
    run our image-generation model directly on our REST API server. As we saw in the
    previous section, the operation can take several minutes and consumes a massive
    amount of memory. To solve this, we’ll define another process, apart from the
    server process, that’ll take care of this image-generation task: the **worker**.
    In essence, a worker can be any program whose role is to compute a task in the
    background.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章的介绍中提到的，直接在我们的 REST API 服务器上运行图像生成模型是不可行的。正如我们在上一节所见，这一操作可能需要几分钟，并消耗大量内存。为了解决这个问题，我们将定义一个独立于服务器进程的其他进程来处理图像生成任务：**工作进程**。本质上，工作进程可以是任何一个在后台执行任务的程序。
- en: In web development, this concept usually implies a bit more than this. A worker
    is a process running continuously in the background, waiting for incoming tasks.
    The tasks are usually sent by the web server, which asks for specific operations
    given the user actions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Web 开发中，这个概念通常意味着比这更多的内容。工作进程是一个持续运行在后台的进程，等待接收任务。这些任务通常由 Web 服务器发送，服务器会根据用户的操作请求执行特定的操作。
- en: Therefore, we see that we need a communication channel between the web server
    and the worker. That’s the role of the **queue**. It’ll accept and stack messages
    coming from the web server and make them available to read for the worker. That’s
    the web-queue-worker architecture. To better understand it, *Figure 14**.4* shows
    you the schema of such an architecture.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到，我们需要一个通信通道来连接 Web 服务器和工作进程。这就是**队列**的作用。队列会接收并堆积来自 Web 服务器的消息，然后将这些消息提供给工作进程读取。这就是
    Web 队列工作进程架构。为了更好地理解这一点，*图 14.4* 展示了这种架构的示意图。
- en: '![Figure 14.3 – Schema of web-queue-worker architecture](img/Figure_14.3_B19528.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.3 – Web 队列工作进程架构示意图](img/Figure_14.3_B19528.jpg)'
- en: Figure 14.3 – Schema of web-queue-worker architecture
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.3 – Web 队列工作进程架构示意图
- en: 'Does it ring a bell? Yes, it’s very similar to what we saw in [*Chapter 8*](B19528_08.xhtml#_idTextAnchor551),
    in the *Handling multiple WebSocket connections and broadcasting messages* section.
    Actually, this is the same principle: we solve the problem of having separate
    processes by having a single central data source.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这是不是让你想起了什么？是的，这与我们在[*第 8 章*](B19528_08.xhtml#_idTextAnchor551)中看到的非常相似，在*处理多个
    WebSocket 连接并广播消息*这一节。实际上，这是同一个原理：我们通过一个中央数据源来解决有多个进程的问题。
- en: 'The great feature of this architecture is that it scales very easily. Imagine
    your application is a huge success and thousands of users want to generate images:
    a single worker wouldn’t be able to meet the demand. Actually, all we need to
    do is to start more worker processes. Since there is a single message broker in
    the architecture, each worker will pull messages as they come, allowing tasks
    to be processed in parallel. They don’t even need to be on the same physical machine.
    This is shown in *Figure 14**.4*.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构的一个伟大特性是它非常容易扩展。试想你的应用程序取得了巨大成功，成千上万的用户想要生成图像：单个工作进程根本无法满足这种需求。事实上，我们所需要做的就是启动更多的工作进程。由于架构中有一个单独的消息代理，每个工作进程会在收到消息时进行拉取，从而实现任务的并行处理。它们甚至不需要位于同一台物理机器上。*图
    14.4* 展示了这一点。
- en: '![Figure 14.4 – Web-queue-worker architecture with multiple workers](img/Figure_14.4_B19528.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.4 – 带有多个工作进程的 Web 队列工作进程架构](img/Figure_14.4_B19528.jpg)'
- en: Figure 14.4 – Web-queue-worker architecture with multiple workers
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.4 – 带有多个工作进程的 Web 队列工作进程架构
- en: In Python, there are several libraries to help implement a worker. They provide
    the required tools to define tasks, schedule them in the queue, and run a process,
    pulling them and executing them. In this book, we’ll use Dramatiq, a lightweight
    but powerful and modern background task-processing library. As we did in [*Chapter
    8*](B19528_08.xhtml#_idTextAnchor551), we’ll use Redis as a message broker.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a worker
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As usual, we’ll start by installing the required dependency. Run the following
    command:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This will install Dramatiq with the required dependencies to talk with a Redis
    broker.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'In a minimal example, setting up a Dramatiq worker involves two things:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Setting the broker type and URL.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining tasks by wrapping functions with the `@``dramatiq.actor` decorator.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It works very well for the vast majority of tasks, such as sending emails or
    generating exports.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: In our case, however, we need to load the heavy Stable Diffusion model. As we
    usually do in the FastAPI server with the `startup` event, we want to do this
    only when the process is actually started. To do this with Dramatiq, we implement
    a *middleware*. They allow us to plug custom logic at several key events in the
    lifetime of the worker, including when it’s started.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see the implementation of our custom middleware in the following sample:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: worker.py
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'We define a `TextToImageMiddleware` class whose role is to bear an instance
    of `TextToImage`, the image generation service we defined in the previous section.
    It inherits from the `Middleware` class of Dramatiq. The key thing here is the
    `after_process_boot` method. It’s one of the event hooks exposed by Dramatiq,
    allowing us to plug our own logic. Here, we tell it to load the Stable Diffusion
    model when the worker process has booted up. You can see the full list of supported
    hooks in the official documentation: [https://dramatiq.io/reference.html#middleware](https://dramatiq.io/reference.html#middleware).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: The next lines allow us to configure our worker. We first instantiate an instance
    of our custom middleware. Then, we create a broker class corresponding to the
    technology we chose; in our case, Redis. We take care of adding our middleware
    to this broker before telling Dramatiq to use it. Our worker is now completely
    configured to connect to a Redis broker and load our model at startup.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see how we can define a task to generate images:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: worker.py
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation is straightforward: Dramatiq tasks are actually plain functions
    that we decorated with `@dramatiq.actor`. We can define arguments as we would
    for any other function. However, there is an important pitfall to avoid here:
    when we schedule tasks from our server, the arguments will have to be stored in
    the queue storage. Thus, *Dramatiq will internally serialize the arguments to
    JSON*. It means your task arguments must be serializable data – you can’t have
    arbitrary Python objects, such as class instances or functions.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 实现是直接的：Dramatiq 任务实际上是我们用 `@dramatiq.actor` 装饰的普通函数。我们可以像定义其他函数一样定义参数。然而，这里有一个重要的陷阱需要避免：当我们从服务器调度任务时，参数将必须存储在队列存储中。因此，*Dramatiq
    会将参数内部序列化为 JSON*。这意味着你的任务参数必须是可序列化的数据——你不能有任意的 Python 对象，比如类实例或函数。
- en: The function body calls our `TextToImage` instance loaded in `text_to_image_middleware`,
    before saving the image to the disk. To avoid file overrides, we choose here to
    generate a **UUID**, a **Universally Unique IDentifier**. It’s a big random string
    that’s guaranteed to be unique in each generation. Thanks to this, we can safely
    use it as a filename and be sure it won’t already exist on our disk.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 函数体在将图像保存到磁盘之前，会调用我们在 `text_to_image_middleware` 中加载的 `TextToImage` 实例。为了避免文件覆盖，我们选择在这里生成一个**UUID**，即**通用唯一标识符**。它是一个大的随机字符串，保证每次生成时都是唯一的。凭借这个，我们可以安全地将其作为文件名，并确保它不会在磁盘上已存在。
- en: That’s it for the worker implementation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 worker 实现的内容。
- en: Starting the worker
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动 worker
- en: 'We don’t have the web server code to call it yet, but we can already try it
    manually. First, make sure you have a Redis server started, as explained in the
    *Technical requirements* section. Then, we can start the Dramatiq worker using
    the following command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有代码来调用它，但我们可以手动尝试。首先，确保你已经启动了一个 Redis 服务器，正如在*技术要求*部分中所解释的那样。然后，我们可以使用以下命令启动
    Dramatiq worker：
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Dramatiq comes with command-line tools to take care of starting the worker
    processes. The main positional argument is the dotted path of your worker module.
    It’s similar to what we do with Uvicorn. We also set two optional parameters,
    `-p` and `-t`. They control the number of processes and threads Dramatiq will
    start. By default, it starts 10 processes, each one with 8 threads. This means
    there will be 80 workers able to pull and execute tasks. While this default is
    good for common needs, it doesn’t work with our Stable Diffusion model for two
    reasons:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Dramatiq 提供了命令行工具来启动 worker 进程。主要的位置参数是 worker 模块的点路径。这类似于我们在使用 Uvicorn 时的操作。我们还设置了两个可选参数，`-p`
    和 `-t`。它们控制 Dramatiq 启动的进程和线程的数量。默认情况下，它启动 10 个进程，每个进程有 8 个线程。这意味着将会有 80 个 worker
    来拉取并执行任务。虽然这个默认配置适合常见需求，但由于两个原因，它不适用于我们的 Stable Diffusion 模型：
- en: 'Each thread in a process shares the same memory space. This means that if two
    (or more) threads try to generate an image, they will read and write on the same
    objects in memory. For our model here, this causes concurrency problems. We say
    that it’s *not thread-safe*. Hence, each process should start only one thread:
    that’s the point of the `-t` `1` option.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程中的每个线程共享相同的内存空间。这意味着，如果两个（或更多）线程尝试生成图像，它们将对内存中的同一对象进行读写操作。对于我们的模型来说，这会导致并发问题。我们说它是*非线程安全的*。因此，每个进程应该仅启动一个线程：这就是`-t`
    `1`选项的意义所在。
- en: Each process should load the model in memory. This means that if we start 8
    processes, we’ll load the model 8 times. As we saw earlier, it takes quite a huge
    amount of memory, so doing this would probably blow up your computer’s memory.
    To be safe here, we start only one process thanks to the `-p 1` option. If you
    want to try parallelization and see that our worker is able to generate two images
    in parallel, you can try `-p 2` to spawn two processes. Make sure your computer
    can handle it though!
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个进程都应该将模型加载到内存中。这意味着，如果我们启动 8 个进程，我们将加载 8 次模型。正如我们之前所看到的，它需要相当大的内存，所以这样做可能会使你的计算机内存爆炸。为了安全起见，我们仅启动一个进程，使用`-p
    1`选项。如果你想尝试并行化并查看我们的 worker 能否并行生成两张图像，你可以尝试`-p 2`来启动两个进程。但要确保你的计算机能够处理！
- en: 'If you run the preceding command, you should see an output like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行前面的命令，你应该会看到类似这样的输出：
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can see the output of the Stable Diffusion pipeline checking whether the
    model files are downloaded before the worker is fully started. This means that
    it has been correctly loaded.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过查看 Stable Diffusion 流水线的输出，检查模型文件是否已经下载，直到 worker 完全启动。这意味着它已经正确加载。
- en: Scheduling tasks in the worker
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 worker 中调度任务
- en: 'We can now try to schedule tasks in our worker. For this, we can start a Python
    interactive shell and import the `task` function. Open a new command line and
    run the following commands (make sure you enabled your Python virtual environment):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以尝试在工作线程中调度任务了。为此，我们可以启动一个Python交互式Shell并导入`task`函数。打开一个新的命令行并运行以下命令（确保你已启用Python虚拟环境）：
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'That’s it – we scheduled a task in the worker! Notice how we used the `send`
    method on our `task` function instead of calling it directly: this is how you
    tell Dramatiq to send it in the queue.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样——我们在工作线程中安排了一个任务！注意我们在`task`函数上使用了`send`方法，而不是直接调用它：这是告诉Dramatiq将其发送到队列中的方式。
- en: If you go back to your worker terminal, you’ll see the Stable Diffusion output
    generating the image. After a moment, you’ll have your image saved on disk. You
    can also try to send two tasks in a row in a short time. You’ll find that Dramatiq
    processes them one after the other.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回到工作线程终端，你会看到Stable Diffusion正在生成图像。过一会儿，你的图像将保存在磁盘上。你还可以尝试在短时间内连续发送两个任务。你会发现Dramatiq会一个接一个地处理它们。
- en: Great job! We have our background process ready and are even able to schedule
    tasks in it. The next step now is to implement a REST API so the users can ask
    for image generation themselves.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！我们的后台进程已经准备好，甚至能够在其中调度任务。下一步就是实现REST API，以便用户可以自己请求图像生成。
- en: Implementing the REST API
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现REST API
- en: 'To schedule tasks in our worker, we need a safe interface users can interact
    with. A REST API is a good choice for this, since it can be easily integrated
    into any software, such as a website or a mobile app. In this section, we’ll very
    quickly review a simple API endpoint we implemented to send image-generation tasks
    into our queue. Here’s the implementation:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要在工作线程中调度任务，我们需要一个用户可以交互的安全接口。REST API是一个不错的选择，因为它可以轻松集成到任何软件中，如网站或移动应用。在这一节中，我们将快速回顾一下我们实现的简单API端点，用于将图像生成任务发送到队列中。以下是实现代码：
- en: api.py
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: api.py
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py)'
- en: If you have followed along since the beginning of this book, this shouldn’t
    surprise you. We took care of defining proper Pydantic models to structure and
    validate the endpoint payload. This data is then directly used to send a task
    to Dramatiq, as we saw in the previous section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从这本书的开头一直跟到现在，这不应该让你感到惊讶。我们已经妥善地定义了合适的Pydantic模型来构建和验证端点负载。然后，这些数据会直接用于发送任务到Dramatiq，正如我们在前一节看到的那样。
- en: In this simple implementation, the output consists only of the message ID, which
    is automatically assigned to each task by Dramatiq. Notice that we set the HTTP
    status code to `202`, which means *Accepted*. Semantically, it means the server
    understood and accepted the request, but the processing has not yet finished or
    even started. It’s specifically designed for cases where the processing is done
    in the background, which is exactly our case here.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的实现中，输出仅包含消息ID，Dramatiq会自动为每个任务分配这个ID。注意我们将HTTP状态码设置为`202`，表示*已接受*。从语义上讲，这意味着服务器已理解并接受了请求，但处理尚未完成，甚至可能还没有开始。它专门用于处理在后台进行的情况，这正是我们在这里的情况。
- en: If you start both the worker and this API, you’ll be able to trigger image generations
    with an HTTP call.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你同时启动工作线程和这个API，你将能够通过HTTP调用触发图像生成。
- en: 'You’re probably wondering here: *That’s nice… But how will the users retrieve
    the result? How will they know whether the task is done?*. You’re right – we didn’t
    talk at all about this problem! Actually, there are two aspects to solve here:
    how do we keep track of the pending tasks and their execution? How do we store
    and serve the resulting images? That’s the subject of the next section.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能在想：*这不错……但是用户怎么才能获取结果呢？他们怎么知道任务是否完成？* 你说得对——我们完全没有讨论这个问题！实际上，这里有两个方面需要解决：我们如何跟踪待处理任务及其执行情况？我们如何存储并提供生成的图像？这就是下一节的内容。
- en: Storing results in a database and object storage
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将结果存储在数据库和对象存储中
- en: 'In the previous section, we showed how to implement a background worker to
    do the heavy computation and an API to schedule tasks on this worker. However,
    we are still missing two important aspects: the user doesn’t have any way to know
    the progress of the task nor to retrieve the final result. Let’s fix this!'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Sharing data between the worker and the API
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we’ve seen, the worker is a program running in the background executing
    the computations the API has asked it to do. However, the worker doesn’t have
    any way to talk with the API server. That’s expected: since there could be any
    number of server processes, and since they could even run on different physical
    servers, processes cannot communicate directly. It’s always the same problem of
    having a central data source on which processes can write and read data.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Actually, the first approach to solve the lack of communication between the
    API and the worker could be to use the same broker we use to schedule tasks: the
    worker could write results in the broker, and the API could read from it. This
    is something possible with most background task libraries, including Dramatiq.
    However, this solution has some limitations, the principal one being the limited
    time we can retain the data. Brokers, such as Redis, are not really suited to
    storing data reliably for a long period. At some point, we’ll need to erase the
    most ancient data to limit memory usage.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'Yet, we already know of something able to store structured data efficiently:
    a database, of course! That’s the approach we’ll show here. By having a central
    database where we’ll store our image generation requests and results, we’ll be
    able to share information between the worker and the API. For this, we’ll reuse
    a lot of techniques we showed in the *Communicating with a SQL database with SQLAlchemy
    ORM* section of [*Chapter 6*](B19528_06.xhtml#_idTextAnchor346). Let’s go!'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Defining an SQLAlchemy model
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step is defining an SQLAlchemy model to store a single image-generation
    task. You can see it as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: models.py
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: As usual, we define an auto-incremented ID as the primary key. We also add `prompt`,
    `negative_prompt`, and `num_steps` columns, which correspond to the arguments
    we give to the worker task. This way, we’ll be able to directly give the ID to
    the worker, and it’ll take the parameter directly from the object. Besides, it’ll
    allow us to store and remember the parameters we used for a specific generation.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: The `progress` column is an integer where we’ll store the current progress of
    the generation task.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `file_name` will store the actual filename we’ll store on our system.
    We’ll see how we use it in the next section, about object storage.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Adapting the API to save image-generation tasks in a database
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With this model at hand, our approach to scheduling image generation in the
    API changes a bit. Instead of directly sending the task to the worker, we first
    create a row in our database and use the ID of this object as input for the worker
    task. The endpoint implementation is shown here:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: api.py
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: We won’t go into the details about how to create an object in a database with
    SQLAlchemy ORM. If you need a refresher, you can refer to the *Communicating with
    a SQL database with SQLAlchemy ORM* section of [*Chapter 6*](B19528_06.xhtml#_idTextAnchor346).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: The main thing to notice in this snippet is that we pass the ID of the newly
    created object as an argument of `text_to_image_task`. As we’ll see right after,
    the worker will read it again from the database to retrieve the generation parameters.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'The response of this endpoint is simply a representation of our `GeneratedImage`
    model, using the Pydantic schema `GeneratedImageRead`. Thus, the user will get
    a response like this to their request:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It shows the prompt we gave in our request and, most importantly, *it gives
    it an ID*. This means that the user will be able to query for this specific request
    again to retrieve the data and see whether it’s done. That’s the purpose of the
    `get_generated_image` endpoint defined below the previous snippet. We won’t show
    it here, but you can read it in the examples repository.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Adapting the worker to read and update image-generation tasks from a database
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You probably have guessed that we need to change the implementation of our task
    so it can retrieve objects from the database instead of reading the parameters
    directly. Let’s go through this step by step.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we do is retrieve a `GeneratedImage` from the database using
    the ID we got in the task argument.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: worker.py
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve this, you see that we use a helper function called `get_image`.
    It’s defined right above the task. Let’s review it:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: worker.py
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: It may look quite strange, but actually, you are already familiar with most
    of its logic. If you look closely, you’ll see that it defines a nested and private
    function where we define the actual logic to retrieve and save the object using
    SQLAlchemy ORM. Notice that it’s *async*, and that we make great use of async
    I/O patterns, as we’ve seen throughout this book.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来可能有些奇怪，但实际上，你已经对其大部分逻辑非常熟悉了。如果你仔细观察，你会发现它定义了一个嵌套的私有函数，在其中我们定义了实际的逻辑来使用SQLAlchemy
    ORM获取和保存对象。请注意，它是*异步的*，并且我们在其中大量使用了异步I/O模式，正如本书中所展示的那样。
- en: That’s the exact reason why we need a helper function like this. Indeed, Dramatiq
    is not designed to run async functions natively, so we need to manually schedule
    their execution using `asyncio.run`. We already saw this function in [*Chapter
    2*](B19528_02.xhtml#_idTextAnchor032), where we presented async I/O. Its role
    is to run an async function and return its result. That’s how we can call the
    wrapping function synchronously in our task without any issues.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们需要像这样的辅助函数的原因。事实上，Dramatiq并未原生设计为运行异步函数，因此我们需要手动使用`asyncio.run`来调度其执行。我们已经在[*第二章*](B19528_02.xhtml#_idTextAnchor032)中看到过这个函数，那里介绍了异步I/O。它的作用是运行异步函数并返回其结果。这就是我们如何在任务中同步调用包装函数而不出现任何问题。
- en: Other approaches could work to tackle the async I/O problem
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法也可以解决异步I/O问题。
- en: The approach we show here is the most straightforward and robust one to tackle
    the problem of asynchronous workers.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里展示的方法是解决异步工作者问题最直接且稳健的方法。
- en: Another approach could be to set up a decorator or middleware for Dramatiq so
    it could natively run async functions, but this is complex and subject to bugs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法可能是为Dramatiq设置装饰器或中间件，使其能够原生支持运行异步函数，但这种方法复杂且容易出现BUG。
- en: We could also consider having another SQLAlchemy engine and session maker that
    works synchronously. However, this would require us to have a lot of duplicated
    things in our code. Besides, this wouldn’t help if we had async functions other
    than SQLAlchemy.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以考虑拥有另一个同步工作的SQLAlchemy引擎和会话生成器。然而，这会导致代码中出现大量重复的内容。而且，如果我们有除了SQLAlchemy之外的其他异步函数，这也无法提供帮助。
- en: 'Now, let’s get back to the implementation of `text_to_image_task`:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到`text_to_image_task`的实现：
- en: worker.py
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: 'We define a `callback` function for the Stable Diffusion pipeline. Its role
    is to save the current progress in a database for the current `GeneratedImage`.
    For this, we once again use a helper function, `update_progress`:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为Stable Diffusion管道定义了一个`callback`函数。它的作用是将当前的进度保存到数据库中，针对当前的`GeneratedImage`。为此，我们再次使用了一个辅助函数`update_progress`：
- en: worker.py
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE18]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: We use the same approach we explained for `get_image`, so we can wrap the async
    function.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用与`get_image`相同的方法来包装异步函数。
- en: 'Going back to `text_to_image_task`, we can now call our `TextToImage` model
    to generate an image. It’s exactly the same call we showed in the previous section.
    The only difference is that we take the parameters from the `image` object. We
    also generate a random filename using a UUID:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 回到`text_to_image_task`，我们现在可以调用我们的`TextToImage`模型来生成图像。这与前一节中展示的调用完全相同。唯一的区别是，我们从`image`对象中获取参数。我们还使用UUID生成一个随机的文件名：
- en: worker.py
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: 'The following part is designed to upload the image to object storage. We’ll
    explain this in more detail in the next section:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: worker.py
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we call another helper function, `update_file_name`, to save the random
    filename in the database. It’ll allow us to retrieve the file for the user:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: worker.py
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the main point of attention throughout this implementation is
    that we read and write information about `GeneratedImage` from and to the database.
    This is how we can *synchronize* between the API server and the worker. That’s
    it for the worker! With this logic, we are able to schedule an image-generation
    task from the API, and the worker is able to regularly update the task progress
    before setting the resulting filename. Thus, from the API, a simple `GET` request
    allows us to see the status of our task.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Storing and serving files in object storage
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last challenge we have to tackle concerns the storage of our resulting images.
    We need a way to store them reliably while letting users retrieve them easily
    from the internet.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, web applications handled this quite simply. They stored the
    files directly on the server hard disk, in a defined directory, and configured
    their web server to serve those files when accessed under a certain URL. This
    is actually what we did in [*Chapter 13*](B19528_13.xhtml#_idTextAnchor1005),
    in the WebSocket example: we used the `StaticFiles` middleware to statically serve
    the JavaScript script we had on disk.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: While this works well for static files, such as JavaScript or CSS files, for
    which each server has its own copy, it is not suitable for dynamic files uploaded
    by the user or generated by the backend, in particular for complex architectures
    where several processes are run on different physical machines. Once again, this
    is the problem of having a central source of data that the different processes
    read from. In the previous sections, we saw that message brokers and databases
    could solve this issue in several contexts. In the case of arbitrary binary files,
    whether they are images, videos, or simple text files, we need something else.
    Let’s introduce **object storage**.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'Object storage is a bit different from the standard file storage we use daily
    in computers, where the disk is organized in a hierarchy of directories and files.
    Instead, object storage will store each file as an object, which includes the
    actual data and all its metadata, such as its name, size, type, and a unique ID.
    The main benefit of such conceptualization is that it’s easier to spread those
    files across multiple physical machines: *we can store billions of files on the
    same object storage*. From the user’s point of view, we just ask for a specific
    file, and the storage will take care of loading the file from the actual physical
    disk.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: In the cloud era, this approach has obviously gained a lot of popularity. In
    2006, **Amazon Web Services** (**AWS**) launched Amazon S3, its own implementation
    of object storage. It gave developers access to virtually unlimited disk space
    to store files using a simple API, all at a very cheap price. Amazon S3 gained
    so much popularity its API became the de facto standard in the industry. Nowadays,
    most cloud object storage, including storage from competitors such as Microsoft
    Azure or Google Cloud, is compatible with the S3 API. Open source implementations
    have also emerged, such as MinIO. The main benefit of this common S3 API is that
    you can use the same code and libraries in your project to talk with any object
    storage provider and easily switch if needed.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: To sum up, object storage is a very convenient way to store and serve files
    at scale, no matter the number of processes that need to access this data. At
    the end of this section, the global architecture of our project will look like
    the one shown in *Figure 14**.5*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.5 – Web-queue-worker architecture and object storage](img/Figure_14.5_B19528.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Web-queue-worker architecture and object storage
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting that the *object storage will serve the file directly to the
    user*. There won’t be an endpoint where the server would act as a proxy by downloading
    the file from the object storage before sending it to the user. There isn’t much
    benefit in doing it that way, even in terms of authentication. We’ll see that
    S3-compatible storage has built-in mechanisms to protect files from unauthorized
    access.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Implementing an object storage helper
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s get to the code then! We’ll use the MinIO client for Python, a library
    to interact with any S3-compatible storage. Let’s install it:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We can now implement a class to have all the operations we need at hand. Let’s
    first go with the initializer:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: storage.py
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: In the initializer of this class, we create a `Minio` client instance. You’ll
    see that we use a `settings` object to pull the storage URL and credentials. Thus,
    it’s very easy to switch them by using environment variables.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll then implement several methods that’ll help us work with object storage.
    The first one is `ensure_bucket`:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: storage.py
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: The role of this method is to make sure the right bucket is created in our object
    storage. In S3 implementations, a **bucket** is like a folder that you own and
    in which you can store your files. Each file you upload has to be put into an
    existing bucket.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we define `upload_image`:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: storage.py
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: This is for uploading an image to the storage. To simplify things, this method
    accepts a Pillow `Image`, as it’s the result we get at the end of the Stable Diffusion
    pipeline. We implemented some logic to convert this `Image` object into a raw
    stream of bytes suitable for the S3 upload. This method also expects `object_name`,
    which will be the actual name of the file in the storage, along with `bucket_name`.
    Notice that we first ensure the bucket is correctly created before trying to upload
    the file.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we add the `get_presigned_url` method:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: storage.py
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'This method will help us to serve the file securely to the user. By default,
    for security reasons, files in S3 storage are not accessible by any user on the
    internet. To give access to a file, we can do either of the following:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Set the file as public so anybody with the URL can access it. This is suitable
    for public files but certainly not for private user files.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate a URL with a temporary access key. Thus, we can give access to the
    file to the user, knowing that even if the URL is stolen, the access will be revoked
    after a certain time. The huge benefit of this is that this URL generation happens
    on our API server using the S3 client. Therefore, we could check whether the user
    is correctly authenticated and has the rights to this specific file following
    our own logic before generating the file URL. This is the approach we adopt here,
    and this method generates the pre-signed URL on a specific file in a specific
    bucket for a certain amount of time.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, our class is just a thin wrapper around the MinIO client. All
    we have to do now is to use it to upload the images and get a pre-signed URL from
    the API.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Using the object storage helper in the worker
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous section, we showed the following lines in our task implementation:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: worker.py
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve talked about the `Storage` class, you should guess what we’re
    doing here: we take the generated image and its random name and upload it to a
    bucket defined in `settings`. And… That’s it!'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Generating a pre-signed URL on the server
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'On the API’s side, we implement a new endpoint whose role is to return a pre-signed
    URL for a given `GeneratedImage`:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: server.py
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Before generating the URL, we first check whether the `file_name` property is
    set on the `GeneratedImage` object. If it’s not, it means the worker has not completed
    the task yet. If it is, we can proceed with the call to the `get_presigned_url`
    method of our `Storage` class.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we took care of defining a dependency injection to get our `Storage`
    instance. As we’ve seen throughout this book, using dependencies in FastAPI is
    a very good practice when dealing with external services.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Well, it seems that we’re all set! Let’s see it in action.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Running the image-generation system
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First of all, we need to populate the environment variables for our project
    with, in particular, a database URL and S3 credentials. To keep things simple,
    we’ll use a simple SQLite database and the MinIO playground for the S3 storage.
    It’s a free and open instance of MinIO object storage that’s perfect for examples
    and toy projects. When going into production, you’ll be able to easily switch
    to any S3-compatible provider. Let’s create a `.env` file at the root of the project:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The storage endpoint, access key, and secret key are the parameters for the
    MinIO playground. Make sure to check their official documentation to see whether
    they have changed since we wrote this book: [https://min.io/docs/minio/linux/developers/python/minio-py.html#id5](https://min.io/docs/minio/linux/developers/python/minio-py.html#id5).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Our `Settings` class will automatically load this file to populate the settings
    we use throughout the code. Make sure to check the *Setting and using environment
    variables* section of [*Chapter 10*](B19528_10.xhtml#_idTextAnchor694) if you
    need a refresher on this concept.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now run our system. Make sure your Redis server is still running, as
    explained in the *Technical requirements* section. First of all, let’s run the
    FastAPI server:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, start the worker:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The stack is now ready to generate images. Let’s make a request with HTTPie
    to start a new task:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'A new `GeneratedImage` has been created in the database with the assigned ID
    `1`. The progress is at *0%*; the processing has not started yet. Let’s try to
    query it with our API:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The API returns the same object with all its properties. Notice that the progress
    has been updated and that it’s now at *36%*. After a while, we can try the same
    request again:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This time, the progress is at *100%* and the filename has been filled. The
    image is ready! We can now ask our API to generate a pre-signed URL for this image:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We get a very long URL on the MinIO server. If you open it in your browser,
    you’ll see the image that has just been generated by our system, as you can see
    in *Figure 14**.6*.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.6 – Generated image hosted on object storage](img/Figure_14.6_B19528.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
- en: Figure 14.6 – Generated image hosted on object storage
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Quite nice, isn’t it? We now have a fully featured system where the user is
    able to do the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Request to generate images following their own prompt and parameters
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get information about the progress of the request
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get the resulting image from reliable storage
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The architecture we see here is already deployable in a cloud environment with
    multiple machines. Typically, we may have a standard, cheap server to serve the
    API and a more expensive one with a dedicated GPU and a good amount of RAM to
    run the worker. The code doesn’t have to change to handle this kind of deployment
    since the communication between processes is handled by the central elements –
    the message broker, the database, and the object storage.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Awesome! You may not have realized it yet, but in this chapter, you learned
    how to architect and implement a very complex machine learning system that could
    rival existing image-generation services you see out there. The concepts we showed
    here are essential and are at the heart of all the distributed systems you could
    imagine, whether they are designed to run machine learning models, extraction
    pipelines, or math computations. By using modern tools such as FastAPI and Dramatiq,
    you’ll be able to implement this kind of architecture in a short time with a minimum
    amount of code, leading to a very quick and robust result.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re near the end of our journey. Before letting you live your own adventures
    with FastAPI, we’ll study one last important aspect when building data science
    applications: logging and monitoring.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
