<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer088">&#13;
			<h1 id="_idParaDest-223" class="chapter-number"><a id="_idTextAnchor1054"/>15</h1>&#13;
			<h1 id="_idParaDest-224"><a id="_idTextAnchor1055"/>Monitoring the Health and Performance of a Data Science System</h1>&#13;
			<p>In this chapter, we will cover the extra mile so you are able to build robust, production-ready systems. One of the most important aspects to achieve this is to have all the data we need to ensure the system is operating correctly and detect as soon as possible when something goes wrong so we can take corrective actions. In this chapter, we’ll see how to set up a proper logging facility and how we can monitor the performance and health of our software in <span class="No-Break">real time.</span></p>&#13;
			<p>We’re near the end of our journey into FastAPI for data science. Until now, we’ve mainly focused on the functionality of the programs we implemented. However, there is another aspect that is often overlooked by developers but is actually very important: <em class="italic">assessing whether the system is functioning correctly and reliably in production</em> and being warned as soon as possible when that’s not <span class="No-Break">the case.</span></p>&#13;
			<p>For this, lot of tools and techniques exist so we can gather the maximum amount of data about how our program is performing. That’s what we’ll review in <span class="No-Break">this chapter.</span></p>&#13;
			<p>We’re going to cover the following <span class="No-Break">main topics:</span></p>&#13;
			<ul>&#13;
				<li>Configuring and using a logging facility <span class="No-Break">with Loguru</span></li>&#13;
				<li>Configuring Prometheus metrics and monitoring them <span class="No-Break">in Grafana</span></li>&#13;
				<li>Configuring Sentry for <span class="No-Break">reporting errors</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-225"><a id="_idTextAnchor1056"/>Technical requirements</h1>&#13;
			<p>For this chapter, you’ll require a Python virtual environment, just as we set up in <a href="B19528_01.xhtml#_idTextAnchor024"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Python Development </em><span class="No-Break"><em class="italic">Environment Setup</em></span><span class="No-Break">.</span></p>&#13;
			<p>To run a Dramatiq worker, you’ll need a running Redis server on your local computer. The easiest way is to run it as a Docker container. If you’ve never used Docker before, we recommend you read the <em class="italic">Getting started</em> tutorial in the official documentation at <a href="https://docs.docker.com/get-started/">https://docs.docker.com/get-started/</a>. Once done, you’ll be able to run a Redis server with this <span class="No-Break">simple command:</span></p>&#13;
			<pre class="source-code">&#13;
$ docker run -d --name worker-redis -p 6379:6379 redis</pre>			<p>You’ll find all the code examples of this chapter in the dedicated GitHub repository <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15"><span class="No-Break">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15</span></a><span class="No-Break">.</span></p>&#13;
			<p class="callout-heading">A note about the screenshots</p>&#13;
			<p class="callout">In the course of this chapter, we’ll present several screenshots, in particular of the Grafana interface. Their goal is to show you the general layout of the UI to help you identify its different parts. Don’t worry if you struggle to read the actual content: the explanations around them will explain where to look at and what to <span class="No-Break">interact with.</span></p>&#13;
			<h1 id="_idParaDest-226"><a id="_idTextAnchor1057"/>Configuring and using a logging facility with Loguru</h1>&#13;
			<p>In software development, logs<a id="_idIndexMarker1035"/> are probably the simplest but most powerful way to control the behavior of a system. They usually consist of lines of plain text that are printed at specific points of a program. By reading them chronologically, we are able to trace the behavior of the program and check that everything goes well. Actually, we’ve already seen log lines in this book. When you run a FastAPI app with Uvicorn and make some requests, you’ll see these lines in the <span class="No-Break">console output:</span></p>&#13;
			<pre class="source-code">&#13;
INFO:     Started server process [94918]INFO:     Waiting for application startup.&#13;
INFO:     Application startup complete.&#13;
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)&#13;
INFO:     127.0.0.1:60736 - "POST /generated-images HTTP/1.1" 201 Created</pre>&#13;
			<p>Those are the<a id="_idIndexMarker1036"/> logs generated by Uvicorn, which tell us when it has started and when it has handled a request. As you can see, logs can help us to know what happened in our program and what actions it performed. They can also tell us when something goes wrong, which could be a bug that needs to <span class="No-Break">be solved.</span></p>&#13;
			<h2 id="_idParaDest-227"><a id="_idTextAnchor1058"/>Understanding log levels</h2>&#13;
			<p>Notice that before each log line, we<a id="_idIndexMarker1037"/> have the <strong class="source-inline">INFO</strong> keyword. This is what we call the <strong class="bold">log level</strong>. It’s a way to classify the importance of this log. In general, the following levels <span class="No-Break">are defined:</span></p>&#13;
			<ul>&#13;
				<li><span class="No-Break"><strong class="source-inline">DEBUG</strong></span></li>&#13;
				<li><span class="No-Break"><strong class="source-inline">INFO</strong></span></li>&#13;
				<li><span class="No-Break"><strong class="source-inline">WARNING</strong></span></li>&#13;
				<li><span class="No-Break"><strong class="source-inline">ERROR</strong></span></li>&#13;
			</ul>&#13;
			<p>You can consider this the <em class="italic">level of importance</em>: <strong class="source-inline">DEBUG</strong> is really specific information about what the program does, which could help you to debug the code, while <strong class="source-inline">ERROR</strong> means that something bad happened in your program, which probably requires action on your part. The good thing about those levels is that we can <em class="italic">configure the minimum level</em> that should be output by the logger. The actual call to the log function is still there in the code, but it’s ignored by the logger if it doesn’t match the <span class="No-Break">minimum level.</span></p>&#13;
			<p>Typically, we can set the <strong class="source-inline">DEBUG</strong> level in local development so we have all the information to help us develop and fix our program. On the other hand, we can set the level to <strong class="source-inline">INFO</strong> or <strong class="source-inline">WARNING</strong> in <a id="_idIndexMarker1038"/>production so we have only the most <span class="No-Break">important messages.</span></p>&#13;
			<h2 id="_idParaDest-228"><a id="_idTextAnchor1059"/>Adding logs with Loguru</h2>&#13;
			<p>Adding your own logs to a <a id="_idIndexMarker1039"/>Python program can be fairly easy using the <strong class="source-inline">logging</strong> module <a id="_idIndexMarker1040"/>available in the standard library. You could do something <span class="No-Break">like this:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; import logging&gt;&gt;&gt; logging.warning("This is my log")&#13;
WARNING:root:This is my log</pre>&#13;
			<p>As you can see, it’s just a function call with a string in the argument. Typically, logging modules expose the different levels as methods, as you see here <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">warning</strong></span><span class="No-Break">.</span></p>&#13;
			<p>The <a id="_idIndexMarker1041"/>standard <strong class="source-inline">logging</strong> module<a id="_idIndexMarker1042"/> is really powerful and allows you to finely <a id="_idIndexMarker1043"/>customize how your logs are handled, printed, and formatted. If you go through the logging tutorials in the official documentation, <a href="https://docs.python.org/3/howto/logging.html">https://docs.python.org/3/howto/logging.html</a>, you’ll see it can quickly <a id="_idIndexMarker1044"/>become really complex, even for <span class="No-Break">simple cases.</span></p>&#13;
			<p>That’s why Python developers usually<a id="_idIndexMarker1045"/> use libraries wrapping the <strong class="source-inline">logging</strong> module and exposing much more friendly functions and interfaces. In this chapter, we’ll review how to use and configure <strong class="bold">Loguru</strong>, a modern <a id="_idIndexMarker1046"/>yet simple approach <span class="No-Break">to logging.</span></p>&#13;
			<p>As always, the first thing to do is to install it in our <span class="No-Break">Python environment:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install loguru</pre>			<p>We can try it right away in a <span class="No-Break">Python shell:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; from loguru import logger&gt;&gt;&gt; logger.debug("This is my log!")&#13;
2023-02-21 08:44:00.168 | DEBUG    | __main__:&lt;module&gt;:1 - This is my log!</pre>&#13;
			<p>You may think that’s not very different from what we did with the standard <strong class="source-inline">logging</strong> module. However, notice the resulting log already includes the timestamp, the level, and the position of the function call in the code. That’s one of the main benefits of Loguru: it comes with sensible defaults working out of <span class="No-Break">the box.</span></p>&#13;
			<p>Let’s see it in action in a more complete script. We’ll define a simple function to check whether an integer, <strong class="source-inline">n</strong>, is odd or not. We’ll add a debug line to let us know the function starts its logic. Then, before computing the result, we’ll first check whether <strong class="source-inline">n</strong> truly is an integer and log an error if not. The implementation of this function looks <span class="No-Break">like this:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_logs_01.py</p>&#13;
			<pre class="source-code">&#13;
from loguru import loggerdef is_even(n) -&gt; bool:&#13;
    logger.debug("Check if {n} is even", n=n)&#13;
    if not isinstance(n, int):&#13;
        logger.error("{n} is not an integer", n=n)&#13;
        raise TypeError()&#13;
    return n % 2 == 0&#13;
if __name__ == "__main__":&#13;
    is_even(2)&#13;
    is_even("hello")</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_01.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_01.py</a></p>&#13;
			<p>As you can see, it’s<a id="_idIndexMarker1047"/> really simple to use: we just have to import <strong class="source-inline">logger</strong> and call it <a id="_idIndexMarker1048"/>wherever we need to log something. Notice also how we can add variables to format our string: we just need to add a placeholder around curly braces inside the string and then map each placeholder to its value with keyword arguments. This syntax is actually similar to the standard <strong class="source-inline">str.format</strong> method. You can read more about it in the official Python <span class="No-Break">documentation: </span><a href="https://docs.python.org/fr/3/library/stdtypes.html#str.format"><span class="No-Break">https://docs.python.org/fr/3/library/stdtypes.html#str.format</span></a><span class="No-Break">.</span></p>&#13;
			<p>If we run this simple script, we’ll see our log lines in the <span class="No-Break">console output:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ python chapter15/chapter15_logs_01.py2023-03-03 08:16:40.145 | DEBUG    | __main__:is_even:5 - Check if 2 is even&#13;
2023-03-03 08:16:40.145 | DEBUG    | __main__:is_even:5 - Check if hello is even&#13;
2023-03-03 08:16:40.145 | ERROR    | __main__:is_even:7 - hello is not an integer&#13;
Traceback (most recent call last):&#13;
  File "/Users/fvoron/Development/Building-Data-Science-Applications-with-FastAPI-Second-Edition/chapter15/chapter15_logs_01.py", line 14, in &lt;module&gt;&#13;
    is_even("hello")&#13;
  File "/Users/fvoron/Development/Building-Data-Science-Applications-with-FastAPI-Second-Edition/chapter15/chapter15_logs_01.py", line 8, in is_even&#13;
    raise TypeError()&#13;
TypeError</pre>&#13;
			<p>Our log lines are <a id="_idIndexMarker1049"/>correctly added to the output before the actual exception is<a id="_idIndexMarker1050"/> raised. Notice how Loguru is able to precisely tell us where the log call comes from in the code: we have the function’s name <span class="No-Break">and line.</span></p>&#13;
			<h2 id="_idParaDest-229"><a id="_idTextAnchor1060"/>Understanding and configuring sinks</h2>&#13;
			<p>We’ve seen that, by default, logs are added to the console output. By default, Loguru defines a <strong class="bold">sink</strong> targeted at<a id="_idIndexMarker1051"/> a standard error. A sink is a concept introduced by Loguru to define how log lines should be handled by the logger. We’re not limited to console output: we can also save them to a file, or a database, or even send them to a <span class="No-Break">web service!</span></p>&#13;
			<p>The good thing is that you’re not limited to only one sink; you can have as many as you need! Then, each log call will be processed through each sink accordingly. You can see a schematic representation of this approach in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer071" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.01_B19528.jpg" alt="Figure 15.1 – Schema of Loguru sinks" width="892" height="642"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.1 – Schema of Loguru sinks</p>&#13;
			<p>Each <em class="italic">sink is associated </em><em class="italic">with</em><em class="italic"> a log level</em>. This <a id="_idIndexMarker1052"/>means that we could have different log levels depending on the sink. For example, we could choose to output all logs to a file and keep only the most important warning and error logs in the console. Let’s again take our previous example and configure Loguru with <span class="No-Break">this approach:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_logs_02.py</p>&#13;
			<pre class="source-code">&#13;
logger.remove()logger.add(sys.stdout, level="WARNING")&#13;
logger.add("file.log", level="DEBUG", rotation="1 day")</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_02.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_02.py</a></p>&#13;
			<p>The <strong class="source-inline">remove</strong> method of <strong class="source-inline">logger</strong> is helpful for removing a previously defined sink. When calling it like this with no parameter, all the defined sinks are removed. By doing this, we start fresh without the <span class="No-Break">default sink.</span></p>&#13;
			<p>Then, we call <strong class="source-inline">add</strong> to define new sinks. The first parameter, like <strong class="source-inline">sys.stdout</strong> or <strong class="source-inline">file.log</strong> here, defines how the log calls should be handled. This parameter can be many things, such as a callable function, but Loguru allows us, for convenience, to directly pass file-like objects, such as <strong class="source-inline">sys.stdout</strong>, or strings, which will be interpreted as filenames. Several arguments are accepted to customize all the aspects of the sink and, in particular, <span class="No-Break">the level.</span></p>&#13;
			<p>As we said, the standard output sink will only log messages with at least a <strong class="source-inline">WARNING</strong> level, while the file sink will log <span class="No-Break">all messages.</span></p>&#13;
			<p>Notice also that we<a id="_idIndexMarker1053"/> added a <strong class="source-inline">rotation</strong> parameter for the file sink. Since logs will continuously be appended to a file, it can quickly grow in size during the lifetime of your application. That’s why we have access to a couple <span class="No-Break">of options:</span></p>&#13;
			<ul>&#13;
				<li><strong class="bold">“Rotate” the file</strong>: This means that the current file will be renamed, and new logs will be added to a new file. This operation can be configured so it happens after a certain amount of time (for example, every day, as in our example) or when it reaches a <span class="No-Break">certain size.</span></li>&#13;
				<li><strong class="bold">Remove older files</strong>: After a certain amount of time, it’s probably not very useful to keep older logs that take up unnecessary space on <span class="No-Break">your disk.</span></li>&#13;
			</ul>&#13;
			<p>You can read all the<a id="_idIndexMarker1054"/> details about these features in the official documentation for <span class="No-Break">Loguru: </span><a href="https://loguru.readthedocs.io/en/stable/api/logger.html#file"><span class="No-Break">https://loguru.readthedocs.io/en/stable/api/logger.html#file</span></a><span class="No-Break">.</span></p>&#13;
			<p>Now, if we run this example, we’ll see this in the <span class="No-Break">console output:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ python chapter15/chapter15_logs_02.py2023-03-03 08:15:16.804 | ERROR    | __main__:is_even:12 - hello is not an integer&#13;
Traceback (most recent call last):&#13;
  File "/Users/fvoron/Development/Building-Data-Science-Applications-with-FastAPI-Second-Edition/chapter15/chapter15_logs_02.py", line 19, in &lt;module&gt;&#13;
    is_even("hello")&#13;
  File "/Users/fvoron/Development/Building-Data-Science-Applications-with-FastAPI-Second-Edition/chapter15/chapter15_logs_02.py", line 13, in is_even&#13;
    raise TypeError()&#13;
TypeError</pre>&#13;
			<p>The <strong class="source-inline">DEBUG</strong> logs don’t <a id="_idIndexMarker1055"/>appear anymore. However, if we read the <strong class="source-inline">file.log</strong> file, we’ll <span class="No-Break">have both:</span></p>&#13;
			<pre class="source-code">&#13;
$ cat file.log2023-03-03 08:15:16.803 | DEBUG    | __main__:is_even:10 - Check if 2 is even&#13;
2023-03-03 08:15:16.804 | DEBUG    | __main__:is_even:10 - Check if hello is even&#13;
2023-03-03 08:15:16.804 | ERROR    | __main__:is_even:12 - hello is not an integer</pre>&#13;
			<p>That’s it! Sinks are really useful for routing our logs to different places depending on their nature <span class="No-Break">or importance.</span></p>&#13;
			<h2 id="_idParaDest-230"><a id="_idTextAnchor1061"/>Structuring logs and adding context</h2>&#13;
			<p>In their simplest form, logs<a id="_idIndexMarker1056"/> consist of free-form text. While convenient, we’ve seen that we usually need to log variable values to better understand what’s going on. With only strings, this usually ends up in a messy string consisting of multiple <span class="No-Break">concatenated values.</span></p>&#13;
			<p>A better approach to handle this is to<a id="_idIndexMarker1057"/> adopt <strong class="bold">structured logging</strong>. The goal is to have a clear and proper structure for each log line, so we can embed all the information we need without sacrificing readability. Loguru supports this approach natively, thanks to contexts. The next example shows you how to <span class="No-Break">use it:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_logs_03.py</p>&#13;
			<pre class="source-code">&#13;
def is_even(n) -&gt; bool:    logger_context = logger.bind(n=n)&#13;
    logger_context.debug("Check if even")&#13;
    if not isinstance(n, int):&#13;
        logger_context.error("Not an integer")&#13;
        raise TypeError()&#13;
    return n % 2 == 0</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_03.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_03.py</a></p>&#13;
			<p>We once again took the same example as before. As you can see, we use the <strong class="source-inline">bind</strong> method of logger to retain extra information. Here, we set the <strong class="source-inline">n</strong> variable. This method returns a new instance of our logger with those attributes attached. Then, we can use this instance normally to log things. We don’t need to add <strong class="source-inline">n</strong> in the formatted <span class="No-Break">string anymore.</span></p>&#13;
			<p>However, if you try this example directly, you won’t <a id="_idIndexMarker1058"/>see the value of <strong class="source-inline">n</strong> in the logs. That’s normal: by default, Loguru doesn’t add context information to the formatted log line. We need to customize it! Let’s <span class="No-Break">see how:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_logs_04.py</p>&#13;
			<pre class="source-code">&#13;
logger.add(    sys.stdout,&#13;
    level="DEBUG",&#13;
    format="&lt;green&gt;{time:YYYY-MM-DD HH:mm:ss.SSS}&lt;/green&gt; | "&#13;
    "&lt;level&gt;{level: &lt;8}&lt;/level&gt; | "&#13;
    "&lt;cyan&gt;{name}&lt;/cyan&gt;:&lt;cyan&gt;{function}&lt;/cyan&gt;:&lt;cyan&gt;{line}&lt;/cyan&gt; - &lt;level&gt;{message}&lt;/level&gt;"&#13;
    " - {extra}",&#13;
)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_04.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_04.py</a></p>&#13;
			<p>To format log output, we have to use the <strong class="source-inline">format</strong> parameter when configuring a sink. It expects a template string. Here, we copied and pasted the default Loguru format and added a part with the <strong class="source-inline">extra</strong> variable. <strong class="source-inline">extra</strong> is a dictionary where Loguru stores all the values you added in context. Here, we just output it directly so we can see <span class="No-Break">all variables.</span></p>&#13;
			<p class="callout-heading">Format syntax and available variables</p>&#13;
			<p class="callout">You can find all the available variables you can output in the format string, such as <strong class="source-inline">extra</strong> or <strong class="source-inline">level</strong>, in the Loguru <span class="No-Break">documentation: </span><a href="https://loguru.readthedocs.io/en/stable/api/logger.html#record"><span class="No-Break">https://loguru.readthedocs.io/en/stable/api/logger.html#record</span></a><span class="No-Break">.</span></p>&#13;
			<p class="callout">The format string supports standard formatting directives, which are useful for retrieving values, format numbers, pad strings, and so on. You can read more about it in the Python <span class="No-Break">documentation: </span><a href="https://docs.python.org/3/library/string.html#format-string-syntax"><span class="No-Break">https://docs.python.org/3/library/string.html#format-string-syntax</span></a><span class="No-Break">.</span></p>&#13;
			<p class="callout">Also, Loguru adds special markup so you can color the output. You can read more about it <span class="No-Break">here: </span><a href="https://loguru.readthedocs.io/en/stable/api/logger.html#color"><span class="No-Break">https://loguru.readthedocs.io/en/stable/api/logger.html#color</span></a><span class="No-Break">.</span></p>&#13;
			<p>This<a id="_idIndexMarker1059"/> time, if you <a id="_idIndexMarker1060"/>run this example, you’ll see the extra context added to the <span class="No-Break">log lines:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ python chapter15/chapter15_logs_04.py2023-03-03 08:30:10.905 | DEBUG    | __main__:is_even:18 - Check if even - {'n': 2}&#13;
2023-03-03 08:30:10.905 | DEBUG    | __main__:is_even:18 - Check if even - {'n': 'hello'}&#13;
2023-03-03 08:30:10.905 | ERROR    | __main__:is_even:20 - Not an integer - {'n': 'hello'}</pre>&#13;
			<p>This approach is very convenient and powerful: if you want to keep track of a value you care about across logs, you just have to add <span class="No-Break">it once.</span></p>&#13;
			<p class="callout-heading">Logs as JSON objects</p>&#13;
			<p class="callout">Another approach to <a id="_idIndexMarker1061"/>structured logging is to serialize all the data of a log into a JSON object. This can be enabled easily with Loguru by setting <strong class="source-inline">serialize=True</strong> when configuring the sink. This approach can be interesting if you plan to use a log ingestion service such as Logstash or Datadog: they will be able to parse the JSON data and make it available <span class="No-Break">for querying.</span></p>&#13;
			<p>You now have the basics of adding and configuring logs with Loguru. Let’s now see how we can leverage them in a <span class="No-Break">FastAPI application.</span></p>&#13;
			<h2 id="_idParaDest-231"><a id="_idTextAnchor1062"/>Configuring Loguru as the central logger</h2>&#13;
			<p>Adding logs to your <a id="_idIndexMarker1062"/>FastAPI application can be really useful to <a id="_idIndexMarker1063"/>know what’s happening in your different routes <span class="No-Break">and dependencies.</span></p>&#13;
			<p>Let’s take an example from <a href="B19528_05.xhtml#_idTextAnchor285"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, where we added a global dependency to check for a secret value that should be set in the header. In this new version, we’ll add a debug log to trace when the <strong class="source-inline">secret_header</strong> dependency is called and a warning log to inform us when this secret is missing <span class="No-Break">or invalid:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_logs_05.py</p>&#13;
			<pre class="source-code">&#13;
from loguru import loggerdef secret_header(secret_header: str | None = Header(None)) -&gt; None:&#13;
    logger.debug("Check secret header")&#13;
    if not secret_header or secret_header != "SECRET_VALUE":&#13;
        logger.warning("Invalid or missing secret header")&#13;
        raise HTTPException(status.HTTP_403_FORBIDDEN)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_05.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_logs_05.py</a></p>&#13;
			<p>That’s nothing really surprising if you have followed us so far! Now, let’s run this application with Uvicorn and make a request with an <span class="No-Break">invalid header:</span></p>&#13;
			<pre class="source-code">&#13;
INFO:     Started server process [47073]INFO:     Waiting for application startup.&#13;
INFO:     Application startup complete.&#13;
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)&#13;
2023-03-03 09:00:47.324 | DEBUG    | chapter15.chapter15_logs_05:secret_header:6 - Check secret header&#13;
2023-03-03 09:00:47.324 | WARNING  | chapter15.chapter15_logs_05:secret_header:8 - Invalid or missing secret header&#13;
INFO:     127.0.0.1:58190 - "GET /route1 HTTP/1.1" 403 Forbidden</pre>&#13;
			<p>Our own logs are here, but there is a problem: Uvicorn also adds its own logs, but it doesn’t follow our format! Actually, that’s expected: other libraries, such as Uvicorn, may have their own logs with their own settings. As such, they won’t follow what we defined with Loguru. It’s a bit annoying because if we have a complex, well-thought-out setup, we would like every log to follow it. Fortunately, there are ways to <span class="No-Break">configure this</span><span class="No-Break">.</span></p>&#13;
			<p>First of all, we’ll create a<a id="_idIndexMarker1064"/> module named <strong class="source-inline">logger.py</strong>, where we’ll<a id="_idIndexMarker1065"/> put all our logger configurations. It’s a good practice in your project to have this module so your configuration is centralized in one place. The first thing we do in this file is to <span class="No-Break">configure Loguru:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">logger.py</p>&#13;
			<pre class="source-code">&#13;
LOG_LEVEL = "DEBUG"logger.remove()&#13;
logger.add(&#13;
    sys.stdout,&#13;
    level=LOG_LEVEL,&#13;
    format="&lt;green&gt;{time:YYYY-MM-DD HH:mm:ss.SSS}&lt;/green&gt; | "&#13;
    "&lt;level&gt;{level: &lt;8}&lt;/level&gt; | "&#13;
    "&lt;cyan&gt;{name}&lt;/cyan&gt;:&lt;cyan&gt;{function}&lt;/cyan&gt;:&lt;cyan&gt;{line}&lt;/cyan&gt; - &lt;level&gt;{message}&lt;/level&gt;"&#13;
    " - {extra}",&#13;
)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py</a></p>&#13;
			<p>As we did in the previous<a id="_idIndexMarker1066"/> section, we removed the default handler<a id="_idIndexMarker1067"/> and defined our own. Notice that we set the level thanks to a constant named <strong class="source-inline">LOG_LEVEL</strong>. We hardcoded it here, but a better way would be to take the value from a <strong class="source-inline">Settings</strong> object, as we showed in <a href="B19528_10.xhtml#_idTextAnchor694"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>. This way, we could directly set the level from <span class="No-Break">environment variables!</span></p>&#13;
			<p>After that, we have a quite complex piece of code in the class named <strong class="source-inline">InterceptHandler</strong>. It’s a custom handler for the standard logging module that will forward every standard log call to Loguru. This code is directly taken from the Loguru documentation. We won’t go into much detail about its functioning but just know that it’ll retrieve the log level and go through the call stack to retrieve the original caller and forward this information <span class="No-Break">to Loguru.</span></p>&#13;
			<p>The most important part, however, is how we use this class. Let’s see <span class="No-Break">this here:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">logger.py</p>&#13;
			<pre class="source-code">&#13;
logging.basicConfig(handlers=[InterceptHandler()], level=0, force=True)for uvicorn_logger_name in ["uvicorn.error", "uvicorn.access"]:&#13;
    uvicorn_logger = logging.getLogger(uvicorn_logger_name)&#13;
    uvicorn_logger.propagate = False&#13;
    uvicorn_logger.handlers = [InterceptHandler()]</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py</a></p>&#13;
			<p>The trick here is to<a id="_idIndexMarker1068"/> call the <strong class="source-inline">basicConfig</strong> method from the standard<a id="_idIndexMarker1069"/> logging module to set our custom interception handler. This way, every log call made with the root logger, even ones from external libraries, will go through it and be handled <span class="No-Break">by Loguru.</span></p>&#13;
			<p>In some cases, however, this configuration is not sufficient. Some libraries define their own loggers with their own handlers, so they won’t use the root configuration. That’s the case for Uvicorn, which defines two main loggers: <strong class="source-inline">uvicorn.error</strong> and <strong class="source-inline">uvicorn.access</strong>. By retrieving those loggers and changing their handler, we force them to go through Loguru <span class="No-Break">as well.</span></p>&#13;
			<p>If you use other libraries that define their own loggers like Uvicorn does, you’ll probably need to apply the same technique. All you need to determine is the name of their logger, which should be quite easy to find in the library’s <span class="No-Break">source code.</span></p>&#13;
			<p class="callout-heading">It works out of the box with Dramatiq</p>&#13;
			<p class="callout">If you implement a worker with Dramatiq, as we showed in <a href="B19528_14.xhtml#_idTextAnchor1041"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, you’ll see that, if you use the <strong class="source-inline">logger</strong> module, the default logs of Dramatiq will be correctly handled <span class="No-Break">by Loguru.</span></p>&#13;
			<p>Finally, we take care of setting the <strong class="source-inline">__all__</strong> variable at the end of <span class="No-Break">the module:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">logger.py</p>&#13;
			<pre class="source-code">&#13;
__all__ = ["logger"]</pre>			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py</a></p>&#13;
			<p><strong class="source-inline">__all__</strong> is a special variable telling Python which variables should be made publicly available when importing this module. Here, we’ll expose <strong class="source-inline">logger</strong> from Loguru, so we can easily import it everywhere we need in <span class="No-Break">our project.</span></p>&#13;
			<p>Bear in mind that it’s not strictly necessary to use <strong class="source-inline">__all__</strong>: we could very well import <strong class="source-inline">logger</strong> without it, but it’s a clean way to hide other things we want to keep private, such as <strong class="source-inline">InterceptHandler</strong>, <span class="No-Break">for example.</span></p>&#13;
			<p>Finally, we can use it as <a id="_idIndexMarker1070"/>we<a id="_idIndexMarker1071"/> saw previously in <span class="No-Break">our code:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">logger.py</p>&#13;
			<pre class="source-code">&#13;
from chapter15.logger import loggerdef secret_header(secret_header: str | None = Header(None))    None:&#13;
    logger.debug("Check secret header")&#13;
    if not secret_header or secret_header != "SECRET_VALUE":&#13;
        logger.warning("Invalid or missing secret header")&#13;
        raise HTTPException(status.HTTP_403_FORBIDDEN)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/logger.py</a></p>&#13;
			<p>If we run it with Uvicorn, you’ll now see that all our logs are formatted the <span class="No-Break">same way:</span></p>&#13;
			<pre class="source-code">&#13;
2023-03-03 09:06:16.196 | INFO     | uvicorn.server:serve:75 - Started server process [47534] - {}2023-03-03 09:06:16.196 | INFO     | uvicorn.lifespan.on:startup:47 - Waiting for application startup. - {}&#13;
2023-03-03 09:06:16.196 | INFO     | uvicorn.lifespan.on:startup:61 - Application startup complete. - {}&#13;
2023-03-03 09:06:16.196 | INFO     | uvicorn.server:_log_started_message:209 - Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit) - {}&#13;
2023-03-03 09:06:18.500 | DEBUG    | chapter15.chapter15_logs_06:secret_header:7 - Check secret header - {}&#13;
2023-03-03 09:06:18.500 | WARNING  | chapter15.chapter15_logs_06:secret_header:9 - Invalid or missing secret header - {}&#13;
2023-03-03 09:06:18.500 | INFO     | uvicorn.protocols.http.httptools_impl:send:489 - 127.0.0.1:59542 - "GET /route1 HTTP/1.1" 403 - {}</pre>&#13;
			<p>Great! Now, whenever <a id="_idIndexMarker1072"/>you need to add logs in your app, all you need <a id="_idIndexMarker1073"/>to do is to import <strong class="source-inline">logger</strong> from your <span class="No-Break"><strong class="source-inline">logger</strong></span><span class="No-Break"> module.</span></p>&#13;
			<p>You now have the basics to add logs to your application, with plenty of options to fine-tune how and where you output them. Logs are very useful for monitoring what your application is doing at a micro-level, operation per operation. Another important aspect of monitoring is to have information at a more general level in order to have big figures and quickly detect if something goes wrong. That’s what we’ll see now <span class="No-Break">with metrics.</span></p>&#13;
			<h1 id="_idParaDest-232"><a id="_idTextAnchor1063"/>Adding Prometheus metrics</h1>&#13;
			<p>In the previous section, we saw how <a id="_idIndexMarker1074"/>logs can help us understand what our program is doing by finely tracing the operations it does over time. However, most of the time, you can’t afford to keep an eye on the logs all day: they are useful for understanding and debugging a particular situation but way less useful for getting global insights to alert you when something <span class="No-Break">goes wrong.</span></p>&#13;
			<p>To solve this, we’ll see in this section <a id="_idIndexMarker1075"/>how to add <strong class="bold">metrics</strong> to our application. Their role is to measure things that matter in the execution of our program: the number of requests made, the time taken to give a response, the number of pending tasks in the worker queue, the accuracy of our ML predictions… Anything that we could easily monitor over time – usually, with charts and graphs – so we can easily monitor the health of our system. We say<a id="_idIndexMarker1076"/> that we <strong class="bold">instrument</strong> <span class="No-Break">our application.</span></p>&#13;
			<p>To achieve this task, we’ll use two widely used technologies in the industry: Prometheus <span class="No-Break">and Grafana.</span></p>&#13;
			<h2 id="_idParaDest-233"><a id="_idTextAnchor1064"/>Understanding Prometheus and the different metrics</h2>&#13;
			<p>Prometheus is a<a id="_idIndexMarker1077"/> technology to help you instrument your application. It consists of <span class="No-Break">three things:</span></p>&#13;
			<ul>&#13;
				<li>Libraries for a wide range of programming languages, including Python, to add metrics to <span class="No-Break">an application</span></li>&#13;
				<li>A server to aggregate and store those metrics <span class="No-Break">over time</span></li>&#13;
				<li>A query language, PromQL, so we can pull data from those metrics into <span class="No-Break">visualization tools</span></li>&#13;
			</ul>&#13;
			<p>Prometheus has very precise guidelines and conventions about how to define metrics. Actually, it defines four different types <span class="No-Break">of metrics.</span></p>&#13;
			<h3>The counter metric</h3>&#13;
			<p>The counter metric<a id="_idIndexMarker1078"/> is a way to measure a <em class="italic">value that goes up over time</em>. For example, this could be<a id="_idIndexMarker1079"/> the number of requests answered or the number of predictions done. This will not be used for values that can go down. For that, there is the <span class="No-Break">gauge metric.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer072" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.02_B19528.jpg" alt="Figure 15.2 – Possible representation of a counter" width="341" height="402"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.2 – Possible representation of a counter</p>&#13;
			<h3>The gauge metric</h3>&#13;
			<p>The gauge metric<a id="_idIndexMarker1080"/> is a way to <a id="_idIndexMarker1081"/>measure a <em class="italic">value that can go up or down over time</em>. For example, this could be the current memory usage or the number of pending tasks in a <span class="No-Break">worker queue.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer073" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.03_B19528.jpg" alt="Figure 15.3 – Possible representation of a gauge" width="520" height="425"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.3 – Possible representation of a gauge</p>&#13;
			<h3>The histogram metric</h3>&#13;
			<p>Contrary to counters and gauges, a <a id="_idIndexMarker1082"/>histogram will <em class="italic">measure values and count them in buckets</em>. Typically, if we<a id="_idIndexMarker1083"/> want to measure the response time of our API, we can count the number of requests that have been processed in less than 10 milliseconds, less than 100 milliseconds, and less than 1 second. Doing this is much more insightful than getting a simple average or median, <span class="No-Break">for example.</span></p>&#13;
			<p>When using a <a id="_idIndexMarker1084"/>histogram, it’s our<a id="_idIndexMarker1085"/> responsibility to define the buckets we want with their <span class="No-Break">value threshold.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer074" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.04_B19528.jpg" alt="Figure 15.4 – Possible representation of a histogram" width="1612" height="596"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.4 – Possible representation of a histogram</p>&#13;
			<p>Prometheus defines a fourth type of metric, a summary. It’s quite similar to the histogram metric, but it works with sliding quantiles instead of defined buckets. We won’t go through it since it has quite limited support in Python. Besides, we’ll see in the Grafana section of this chapter that we’ll be able to compute quantiles with the <span class="No-Break">histogram metric.</span></p>&#13;
			<p>You can read more details about those <a id="_idIndexMarker1086"/>metrics in the official <span class="No-Break">Prometheus documentation:</span></p>&#13;
			<p><a href="https://prometheus.io/docs/concepts/metric_types/"><span class="No-Break">https://prometheus.io/docs/concepts/metric_types/</span></a></p>&#13;
			<h2 id="_idParaDest-234"><a id="_idTextAnchor1065"/>Measuring and exposing metrics</h2>&#13;
			<p>Once the metrics <a id="_idIndexMarker1087"/>have been defined, we can start to measure things during the lifetime of our program. Similar to what we do with logs, metrics expose methods so we can store values during the execution of the application. Prometheus will then retain those values in memory to build <span class="No-Break">the metrics.</span></p>&#13;
			<p>But then, how can we <a id="_idIndexMarker1088"/>access those metrics so we can actually analyze and monitor them? Quite simply, apps using Prometheus usually expose an HTTP endpoint called <strong class="source-inline">/metrics</strong>, which will return the current values of all metrics in a specific format. You can see what it looks like in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer075" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.05_B19528.jpg" alt="Figure 15.5 – Output of a Prometheus metrics endpoint" width="1650" height="954"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.5 – Output of a Prometheus metrics endpoint</p>&#13;
			<p>This endpoint can then be polled at regular intervals by a Prometheus server, which will store those metrics over time and make them available <span class="No-Break">through PromQL.</span></p>&#13;
			<p class="callout-heading">Metrics are reset when your application restarts</p>&#13;
			<p class="callout">It’s worth noting that every time you restart your application, like your FastAPI server, metric values are lost, and you start from zero. It may be a bit surprising, but it’s key to understand that metric values are only stored in memory in your app. The responsibility for properly storing them permanently belongs to the <span class="No-Break">Prometheus server.</span></p>&#13;
			<p>Now that we have a good idea of how they work, let’s see how to add metrics to FastAPI and <span class="No-Break">Dramatiq applications.</span></p>&#13;
			<h2 id="_idParaDest-235"><a id="_idTextAnchor1066"/>Adding Prometheus metrics to FastAPI</h2>&#13;
			<p>As we said, Prometheus <a id="_idIndexMarker1089"/>maintains official libraries for various languages, <span class="No-Break">including Python.</span></p>&#13;
			<p>We could very well use it on its own and manually define various metrics to monitor our FastAPI app. We would also need to come up with some logic to hook into a FastAPI request handler so we could measure things such as the requests count, response time, payload size, and <span class="No-Break">so on.</span></p>&#13;
			<p>While definitely doable, we’ll take a shortcut and rely once again on the open source community, which proposes a ready-to-use library for integrating <a id="_idIndexMarker1090"/>Prometheus into a FastAPI project: <strong class="bold">Prometheus FastAPI Instrumentator</strong>. It comes with useful metrics by default, such as the total number of requests or the response size in bytes. It also takes care of exposing the <strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">metrics</strong></span><span class="No-Break"> endpoint.</span></p>&#13;
			<p>The first thing is, of course, to install it with <strong class="source-inline">pip</strong>. Run the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ pip install prometheus_fastapi_instrumentator</pre>			<p>In the following example, we’ve implemented a very simple FastAPI app and enabled <span class="No-Break">the instrumentator:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_metrics_01.py</p>&#13;
			<pre class="source-code">&#13;
from fastapi import FastAPIfrom prometheus_fastapi_instrumentator import Instrumentator, metrics&#13;
app = FastAPI()&#13;
@app.get("/")&#13;
async def hello():&#13;
    return {"hello": "world"}&#13;
instrumentator = Instrumentator()&#13;
instrumentator.add(metrics.default())&#13;
instrumentator.instrument(app).expose(app)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_01.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_01.py</a></p>&#13;
			<p>Enabling the instrumentator consists of <span class="No-Break">three lines:</span></p>&#13;
			<ol>&#13;
				<li>Instantiate the <span class="No-Break"><strong class="source-inline">Instrumentator</strong></span><span class="No-Break"> class.</span></li>&#13;
				<li>Enable the default metrics proposed by <span class="No-Break">the library.</span></li>&#13;
				<li>Wire it to our FastAPI <strong class="source-inline">app</strong> and expose the <strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">metrics</strong></span><span class="No-Break"> endpoint.</span></li>&#13;
			</ol>&#13;
			<p>That’s it! FastAPI is instrumented <span class="No-Break">with Prometheus!</span></p>&#13;
			<p>Let’s run this app <a id="_idIndexMarker1091"/>with Uvicorn and access the <strong class="source-inline">hello</strong> endpoint. Internally, Prometheus will measure things about this request. Let’s now access <strong class="source-inline">/metrics</strong> to see the result. If you scroll down this big list of metrics, you should come across <span class="No-Break">these lines:</span></p>&#13;
			<pre class="source-code">&#13;
# HELP http_requests_total Total number of requests by method, status and handler.# TYPE http_requests_total counter&#13;
http_requests_total{handler="/",method="GET",status="2xx"} 1.0</pre>&#13;
			<p>This is the metrics counting the number of requests. We see that we have one request in total, which corresponds to our call to <strong class="source-inline">hello</strong>. Notice that the instrumentator is smart enough to label the metrics by path, method, and even status code. This is very convenient, as it’ll enable us to pull interesting figures depending on the characteristics of <span class="No-Break">the request.</span></p>&#13;
			<h3>Adding custom metrics</h3>&#13;
			<p>The built-in metrics are a good <a id="_idIndexMarker1092"/>start, but we’ll likely need to come up with our own to measure things specific to <span class="No-Break">our application.</span></p>&#13;
			<p>Let’s say we want to implement a function that rolls a dice with six faces and exposes it via a REST API. We want to define a metric allowing us to count the number of times each face has appeared. For this task, a counter is a good match. Let’s see how to declare it in <span class="No-Break">the code:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_metrics_02.py</p>&#13;
			<pre class="source-code">&#13;
DICE_COUNTER = Counter(    "app_dice_rolls_total",&#13;
    "Total number of dice rolls labelled per face",&#13;
    labelnames=["face"],&#13;
)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_02.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_02.py</a></p>&#13;
			<p>We have to instantiate a <strong class="source-inline">Counter</strong> object. The two first arguments are, respectively, the name and description of the metric. The name will be used by Prometheus to uniquely <a id="_idIndexMarker1093"/>identify this metric. Since we want to count the rolls per face, we also add a single label named <strong class="source-inline">face</strong>. Every time we count a roll of the dice, we’ll have to set this label to the corresponding <span class="No-Break">result face.</span></p>&#13;
			<p class="callout-heading">Conventions for metric names</p>&#13;
			<p class="callout">Prometheus defines very precise <a id="_idIndexMarker1094"/>conventions for naming your metrics. In particular, it should start with the domain the metrics belong to, such as <strong class="source-inline">http_</strong> or <strong class="source-inline">app_</strong>, and should end with the unit, such as <strong class="source-inline">_seconds</strong>, <strong class="source-inline">_bytes</strong>, or <strong class="source-inline">_total</strong> if this is just a value count. We strongly recommend you read the Prometheus <span class="No-Break">guidelines: </span><a href="https://prometheus.io/docs/practices/naming/"><span class="No-Break">https://prometheus.io/docs/practices/naming/</span></a><span class="No-Break">.</span></p>&#13;
			<p>We can now use this metric in our code. In the following snippet, you’ll see the implementation of the <span class="No-Break"><strong class="source-inline">roll_dice</strong></span><span class="No-Break"> function:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_metrics_02.py</p>&#13;
			<pre class="source-code">&#13;
def roll_dice() -&gt; int:    result = random.randint(1, 6)&#13;
    DICE_COUNTER.labels(result).inc()&#13;
    return result</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_02.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_02.py</a></p>&#13;
			<p>You can see that we directly use the metrics instance, <strong class="source-inline">DICE_COUNTER</strong>, and first call the <strong class="source-inline">labels</strong> method to set the face, and then <strong class="source-inline">inc</strong> to actually increment <span class="No-Break">the counter.</span></p>&#13;
			<p>That’s all we need to <a id="_idIndexMarker1095"/>do: our metric is automatically registered in the Prometheus client and will start to be exposed by the <strong class="source-inline">/metrics</strong> endpoint. In <span class="No-Break"><em class="italic">Figure 15</em></span><em class="italic">.6</em>, you can see a possible visualization of this metric <span class="No-Break">in Grafana.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer076" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.06_B19528.jpg" alt="Figure 15.6 – Representation of the dice roll metric in Grafana" width="1650" height="904"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.6 – Representation of the dice roll metric in Grafana</p>&#13;
			<p>As you can see, declaring and using a new metric is quite straightforward: we can just call it directly in the code we want <span class="No-Break">to monitor.</span></p>&#13;
			<h3>Handling multiple processes</h3>&#13;
			<p>In <a href="B19528_10.xhtml#_idTextAnchor694"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, we <a id="_idIndexMarker1096"/>mentioned in the <em class="italic">Adding Gunicorn as a server process for deployment</em> section that, in a production deployment, FastAPI apps are usually run with several workers. Basically, it spawns several processes of the same application and balances the incoming requests between them. This allows us to serve more requests concurrently and avoid blocks if one of the operations is blocking <span class="No-Break">the process.</span></p>&#13;
			<p class="callout-heading">Do not confuse Gunicorn workers and Dramatiq workers</p>&#13;
			<p class="callout">When we talk about workers in the context of a Gunicorn deployment for FastAPI, we are referring to the fact that we are spawning multiple processes that’ll be able to serve our API requests concurrently. We are not talking about workers in the context of Dramatiq that are processing tasks in <span class="No-Break">the background.</span></p>&#13;
			<p>Having multiple processes for the same application is a bit problematic for Prometheus metrics. Indeed, as we mentioned before, those metrics are only stored in memory and exposed through a <strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">metrics</strong></span><span class="No-Break"> endpoint.</span></p>&#13;
			<p>If we have several processes answering requests, each one will have its own set of metrics values. Then, when the Prometheus server asks for <strong class="source-inline">/metrics</strong>, we’ll get the values of the process that answered our request but not the ones of the others. And it may change in the next poll! Obviously, this will totally defeat our <span class="No-Break">initial goal.</span></p>&#13;
			<p>To circumvent this, the Prometheus client has a special multiprocess mode. Basically, instead of storing the values in memory, it’ll store them in files in a dedicated folder. When calling <strong class="source-inline">/metrics</strong>, it’ll take care of loading all the files and reconciling the values of all <span class="No-Break">processes together.</span></p>&#13;
			<p>Enabling this mode requires us to set the environment variable called <strong class="source-inline">PROMETHEUS_MULTIPROC_DIR</strong>. It should point to a valid folder in your filesystem where the metrics files will be stored. Here is a command example of how to set this variable and start Gunicorn with <span class="No-Break">four workers:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ PROMETHEUS_MULTIPROC_DIR=./prometheus-tmp gunicorn -w 4 -k uvicorn.workers.UvicornWorker chapter15.chapter15_metrics_01:app</pre>			<p>Of course, in a production deployment, you would set the environment variable globally on your platform, as we explained in <a href="B19528_10.xhtml#_idTextAnchor694"><span class="No-Break"><em class="italic">Chapter 10</em></span></a><span class="No-Break">.</span></p>&#13;
			<p>If you try this command, you’ll see that Prometheus will start to store some <strong class="source-inline">.db</strong> files inside the folder, each one corresponding to a metric and a process. The side effect is that <em class="italic">metrics won’t be cleared when restarting the process</em>. It can lead to unexpected behaviors if you change your metrics definition or if you run a completely different application. Make sure to choose a dedicated folder for each of your apps and clean it up when you run a <span class="No-Break">new version.</span></p>&#13;
			<p>We are now able<a id="_idIndexMarker1097"/> to precisely instrument a FastAPI app. However, we saw in the previous chapter that data science applications can be constituted of a separate worker process, where a lot of logic and intelligence is run. Thus, it’s also crucial to instrument this part of <span class="No-Break">the application.</span></p>&#13;
			<h2 id="_idParaDest-236"><a id="_idTextAnchor1067"/>Adding Prometheus metrics to Dramatiq</h2>&#13;
			<p>In <a href="B19528_14.xhtml#_idTextAnchor1041"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, we implemented a <a id="_idIndexMarker1098"/>complex application with a distinct worker process that was in charge of loading and executing the Stable Diffusion model to generate images. Hence, this part of the architecture is critical and needs to be monitored to be sure everything is <span class="No-Break">going well.</span></p>&#13;
			<p>In this section, we’ll see how to add Prometheus metrics to a Dramatiq worker. The good news is that Dramatiq already comes with built-in metrics and exposes the <strong class="source-inline">/metrics</strong> endpoint by default. Really, there is nothing much <span class="No-Break">to do!</span></p>&#13;
			<p>Let’s take a very basic example of a Dramatiq worker with a <span class="No-Break">dummy task:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_metrics_03.py</p>&#13;
			<pre class="source-code">&#13;
import timeimport dramatiq&#13;
from dramatiq.brokers.redis import RedisBroker&#13;
redis_broker = RedisBroker(host="localhost")&#13;
dramatiq.set_broker(redis_broker)&#13;
@dramatiq.actor()&#13;
def addition_task(a: int, b: int):&#13;
    time.sleep(2)&#13;
    print(a + b)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_03.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_03.py</a></p>&#13;
			<p>As you probably understand by now, Dramatiq is by nature a multiprocessing program: it spawns several workers to handle tasks concurrently. As such, we need to make sure Prometheus is in multiprocessing mode, as we mentioned in the <em class="italic">Handling multiple processes</em> section. Thus, we’ll need to set the <strong class="source-inline">PROMETHEUS_MULTIPROC_DIR</strong> environment variable, as we explained earlier, but also <strong class="source-inline">dramatiq_prom_db</strong>. Indeed, Dramatiq implements its own mechanism to enable Prometheus’s multiprocessing mode, which should work out of the box, but it turns out, in our experience, that it’s better to be explicit <span class="No-Break">about it.</span></p>&#13;
			<p>The following command <a id="_idIndexMarker1099"/>shows you how to start our worker with <strong class="source-inline">PROMETHEUS_MULTIPROC_DIR</strong> and <span class="No-Break"><strong class="source-inline">dramatiq_prom_db</strong></span><span class="No-Break"> set:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ PROMETHEUS_MULTIPROC_DIR=./prometheus-tmp-dramatiq dramatiq_prom_db=./prometheus-tmp-dramatiq dramatiq chapter15.chapter15_metrics_03</pre>			<p>To allow you to schedule a task easily in this worker, we’ve added a small <strong class="source-inline">__name__ == "__main__"</strong> instruction. In another terminal, run the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
(venv) $ python -m chapter15.chapter15_metrics_03</pre>			<p>It’ll schedule a task in the worker. You’ll probably see it being executed in the <span class="No-Break">worker logs.</span></p>&#13;
			<p>Now, try to open the following URL in your browser: <strong class="source-inline">http://localhost:9191/metrics</strong>. You’ll see a result similar to what we show in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer077" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.07_B19528.jpg" alt="Figure 15.7 – Output of a Dramatiq Prometheus metrics endpoint" width="1650" height="920"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.7 – Output of a Dramatiq Prometheus metrics endpoint</p>&#13;
			<p>We already see <a id="_idIndexMarker1100"/>several metrics, including a counter for the total number of messages processed by Dramatiq, a histogram to measure the execution time of our tasks, and a gauge to measure the number of tasks currently in progress. You can review the complete list of metrics included by Dramatiq in its official <span class="No-Break">documentation: </span><a href="https://dramatiq.io/advanced.html#prometheus-metrics"><span class="No-Break">https://dramatiq.io/advanced.html#prometheus-metrics</span></a><span class="No-Break">.</span></p>&#13;
			<h3>Adding custom metrics</h3>&#13;
			<p>Of course, as for FastAPI, we would probably <a id="_idIndexMarker1101"/>like to add our own metrics to the Dramatiq worker. Actually, this is very similar to what we saw in the previous section. Let’s again take the dice <span class="No-Break">roll example:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">chapter15_metrics_04.py</p>&#13;
			<pre class="source-code">&#13;
DICE_COUNTER = Counter(    "worker_dice_rolls_total",&#13;
    "Total number of dice rolls labelled per face",&#13;
    labelnames=["face"],&#13;
)&#13;
@dramatiq.actor()&#13;
def roll_dice_task():&#13;
    result = random.randint(1, 6)&#13;
    time.sleep(2)&#13;
    DICE_COUNTER.labels(result).inc()&#13;
    print(result)</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_04.py">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/chapter15_metrics_04.py</a></p>&#13;
			<p>All we needed to do <a id="_idIndexMarker1102"/>was to create our <strong class="source-inline">Counter</strong> object, as we did before, and use it in our task. If you try to run the worker and request the <strong class="source-inline">/metrics</strong> endpoint, you’ll see this new <span class="No-Break">metric appear.</span></p>&#13;
			<p>We are now able to instrument our FastAPI and Dramatiq apps. As we have already mentioned several times, we now need to aggregate those metrics in a Prometheus server and visualize them in Grafana. That’s what we’ll look at in the <span class="No-Break">next section.</span></p>&#13;
			<h1 id="_idParaDest-237"><a id="_idTextAnchor1068"/>Monitoring metrics in Grafana</h1>&#13;
			<p>Having metrics is<a id="_idIndexMarker1103"/> nice, but being able to visualize them is better! In this <a id="_idIndexMarker1104"/>section, we’ll see how we can collect Prometheus metrics, send them to Grafana, and create dashboards to <span class="No-Break">monitor them.</span></p>&#13;
			<p>Grafana<a id="_idIndexMarker1105"/> is an open source web application for data visualization and analytics. It’s able to connect to various data sources, such as timeseries databases and, of course, Prometheus. Its powerful query and graph builder allows us to create detailed dashboards where we can monitor our data in <span class="No-Break">real time.</span></p>&#13;
			<h2 id="_idParaDest-238"><a id="_idTextAnchor1069"/>Configuring Grafana to collect metrics</h2>&#13;
			<p>Since it’s open source, you <a id="_idIndexMarker1106"/>can run it from your own machine or server. Detailed instructions are available in the official documentation: <a href="https://grafana.com/docs/grafana/latest/setup-grafana/installation/">https://grafana.com/docs/grafana/latest/setup-grafana/installation/</a>. However, to speed things up and get you started quickly, we’ll rely here on Grafana Cloud, an official hosting platform. It offers a free plan, which should be enough for you to get started. You can create your account here: <a href="https://grafana.com/auth/sign-up/create-user">https://grafana.com/auth/sign-up/create-user</a>. Once done, you’ll be asked to create your own instance, a “Grafana Stack,” by choosing a subdomain and a data center region, as you can see in <span class="No-Break"><em class="italic">Figure 15</em></span><em class="italic">.8</em>. Choose a region close to your <span class="No-Break">geographic location.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer078" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.08_B19528.jpg" alt="Figure 15.8 – Instance creation on Grafana Cloud" width="1650" height="659"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.8 – Instance creation on Grafana Cloud</p>&#13;
			<p>You’ll then be presented with a set of common actions to get started with Grafana. The first thing we’ll do is add Prometheus metrics. Click on <strong class="bold">Scale and centralize existing data</strong>, then <strong class="bold">Hosted Prometheus metrics</strong>. You’ll be taken to a page to configure a Prometheus metrics collection. Click on the tab named <strong class="bold">Configuration Details</strong> at the top. The page will look like the one shown in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.9</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer079" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.09_B19528.jpg" alt="Figure 15.9 – Hosted Prometheus metrics configuration on Grafana" width="1650" height="1098"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.9 – Hosted Prometheus metrics configuration on Grafana</p>&#13;
			<p>You see that we have two ways to forward metrics: via Grafana Agent or via a <span class="No-Break">Prometheus server.</span></p>&#13;
			<p>As we mentioned earlier, a <a id="_idIndexMarker1107"/>Prometheus server is responsible for collecting metrics for all our apps and storing the data in a database. It’s the standard way to do it. You can find instructions on how to install it in the official documentation: <a href="https://prometheus.io/docs/prometheus/latest/installation/">https://prometheus.io/docs/prometheus/latest/installation/</a>. Bear in mind, though, that it’s a dedicated application server that’ll need proper backups, as it’ll store all your <span class="No-Break">metrics data.</span></p>&#13;
			<p>The most straightforward way is to use Grafana Agent. It consists of a small command-line program with a single configuration file. When it runs, it’ll poll the metrics of each of your apps and send the data to Grafana Cloud. All the data is stored on Grafana Cloud, so nothing is lost, even if you stop or delete the agent. This is what we’ll <span class="No-Break">use here.</span></p>&#13;
			<p>Grafana shows you commands on the page to download, unzip, and execute the Grafana Agent program. Execute those commands so you have it at the root of <span class="No-Break">your project.</span></p>&#13;
			<p>Then, in the last step, you’ll <a id="_idIndexMarker1108"/>have to create an API token so Grafana Agent can send data to your instance. Give it a name and click on <strong class="bold">Create API Token</strong>. A new text area will appear with a new command to create the agent’s configuration file, as you can see in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer080" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.10_B19528.jpg" alt="Figure 15.10 – Command to create Grafana Agent configuration" width="1650" height="1150"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.10 – Command to create Grafana Agent configuration</p>&#13;
			<p>Execute the <strong class="source-inline">./grafana-agent-linux-amd64 –config.file=agent-config.yaml</strong> command. A file named <strong class="source-inline">agent-config.yaml</strong> will be created in your project. We now have to edit it so we can configure our actual FastAPI and Dramatiq applications. You can see the result in the <span class="No-Break">following snippet:</span></p>&#13;
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">agent-config.yaml</p>&#13;
			<pre class="source-code">&#13;
metrics:  global:&#13;
    scrape_interval: 60s&#13;
  configs:&#13;
  - name: hosted-prometheus&#13;
    scrape_configs:&#13;
      - job_name: app&#13;
        static_configs:&#13;
        - targets: ['localhost:8000']&#13;
      - job_name: worker&#13;
        static_configs:&#13;
        - targets: ['localhost:9191']&#13;
    remote_write:&#13;
      - url: https://prometheus-prod-01-eu-west-0.grafana.net/api/prom/push&#13;
        basic_auth:&#13;
          username: 811873&#13;
          password: __YOUR_API_TOKEN__</pre>&#13;
			<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/agent-config.yaml">https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter15/agent-config.yaml</a></p>&#13;
			<p>It’s a YAML configuration file where we can set the various options for Grafana Agent. The most important part is the <strong class="source-inline">scrape_configs</strong> key. As you can see, we can define the list of all the apps we want to gather the metrics for and specify their hostname, the “target”: <strong class="source-inline">localhost:8000</strong> for the FastAPI app and <strong class="source-inline">localhost:9191</strong> for the Dramatiq worker. Of course, this configuration is valid for local development, but you’ll have to adapt it with the proper hostnames of your apps in a <span class="No-Break">production deployment.</span></p>&#13;
			<p>We are now ready to start<a id="_idIndexMarker1109"/> Grafana Agent and collect the metrics! Make sure your FastAPI and Dramatiq apps are running, and then run Grafana Agent. Depending on your system, the name of the executable will vary, but it’ll look similar <span class="No-Break">to this:</span></p>&#13;
			<pre class="source-code">&#13;
$ ./grafana-agent-linux-amd64 --config.file=agent-config.yaml</pre>			<p>Grafana Agent will start and will collect the metrics at regular intervals before sending them to Grafana. We’re now ready to plot <span class="No-Break">some data!</span></p>&#13;
			<h2 id="_idParaDest-239"><a id="_idTextAnchor1070"/>Visualizing metrics in Grafana</h2>&#13;
			<p>Our metrics data is<a id="_idIndexMarker1110"/> now sent to Grafana. We’re ready to query it and build <a id="_idIndexMarker1111"/>some graphs. The first step is to create a new <strong class="bold">dashboard</strong>, a place <a id="_idIndexMarker1112"/>where you’ll be able to create and organize multiple graphs. Click on the plus button at the top right and then <span class="No-Break"><strong class="bold">New dashboard</strong></span><span class="No-Break">.</span></p>&#13;
			<p>A new blank dashboard will appear, as you can see in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.11</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer081" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.11_B19528.jpg" alt="Figure 15.11 – Create a new dashboard in Grafana" width="1650" height="575"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.11 – Create a new dashboard in Grafana</p>&#13;
			<p>Click on <strong class="bold">Add a new panel</strong>. The interface to build a new graph will appear. There are three <span class="No-Break">main parts:</span></p>&#13;
			<ul>&#13;
				<li>The graph preview at the top left. When starting, <span class="No-Break">it’s empty.</span></li>&#13;
				<li>The query builder at the bottom left. This is where we’ll query the <span class="No-Break">metrics data.</span></li>&#13;
				<li>The graph settings on the right. This is where we’ll choose the type of graph and finely configure its look and feel, similar to what we have in <span class="No-Break">spreadsheet software.</span></li>&#13;
			</ul>&#13;
			<p>Let’s try to create a graph for the duration of HTTP requests in our FastAPI app. In the select menu called <strong class="bold">Metric</strong>, you’ll have access to all the Prometheus metrics that have been reported by our apps. Select <strong class="bold">http_request_duration_seconds_bucket</strong>. This is the histogram metric defined by default by Prometheus FastAPI Instrumentator to measure the response time of <span class="No-Break">our endpoints.</span></p>&#13;
			<p>Then, click on <strong class="bold">Run queries</strong>. Under the hood, Grafana will build and execute PromQL queries to retrieve <span class="No-Break">the data.</span></p>&#13;
			<p>At the top right of the <a id="_idIndexMarker1113"/>graph, let’s select a shorter time span, such as <strong class="bold">Last 15 minutes</strong>. Since <a id="_idIndexMarker1114"/>we do not have much data yet, we’ll have a clearer view if we look at only a few minutes of data instead of hours. You should see a graph similar to the one in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer082" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.12_B19528.jpg" alt="Figure 15.12 – Basic plot of a histogram metric in Grafana" width="1650" height="962"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.12 – Basic plot of a histogram metric in Grafana</p>&#13;
			<p>Grafana has plotted several series: for each <strong class="source-inline">handler</strong> (which corresponds to the endpoint pattern), we have several buckets, <strong class="source-inline">le</strong>. Each line roughly represents <em class="italic">the number of times we answered “handler” in less than “</em><span class="No-Break"><em class="italic">le” seconds</em></span><span class="No-Break">.</span></p>&#13;
			<p>This is the raw representation of the metric. However, you probably see that it’s not very convenient to read and analyze. It would be better if we could look at this data another way, in terms of response time, arranged <span class="No-Break">by quantiles.</span></p>&#13;
			<p>Fortunately, PromQL includes some math operations so we can arrange the raw data. The part below the <strong class="bold">Metric</strong> menu allows us to add those operations. We can even see that Grafana suggests we use <strong class="bold">add histogram_quantile</strong>. If you click on this blue button, Grafana will automatically add three operations: a <em class="italic">Rate</em>, a <em class="italic">Sum by le</em>, and finally, a <em class="italic">Histogram quantile</em>, set by default <span class="No-Break">to </span><span class="No-Break"><em class="italic">0.95</em></span><span class="No-Break">.</span></p>&#13;
			<p>By doing this, we’ll now have a view of the evolution of our response time: 95% of the time, we answer in less than <span class="No-Break"><em class="italic">x</em></span><span class="No-Break"> seconds.</span></p>&#13;
			<p>The default <em class="italic">y</em> axis unit is<a id="_idIndexMarker1115"/> not very convenient. Since we know we work with <a id="_idIndexMarker1116"/>seconds, let’s select this unit in the graph options. On the right, look for the <strong class="bold">Standard options</strong> part and, in the <strong class="bold">Unit</strong> menu, look for <strong class="bold">seconds (s)</strong> under the <strong class="bold">Time</strong> group. Your graph will now look like <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.13</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer083" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.13_B19528.jpg" alt="Figure 15.13 – Quantile representation of a histogram metric in Grafana" width="1650" height="956"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.13 – Quantile representation of a histogram metric in Grafana</p>&#13;
			<p>Now it’s much more insightful: we can see that we answer nearly all our requests (95%) in under 100 milliseconds. If our server starts to slow down, we’ll immediately see an increase in our graph, which could alert us that something has <span class="No-Break">gone wrong.</span></p>&#13;
			<p>If we want to have other <a id="_idIndexMarker1117"/>quantiles on the same graph, we can duplicate this <a id="_idIndexMarker1118"/>query by clicking on the <strong class="bold">Duplicate</strong> button right above <strong class="bold">Run queries</strong>. Then, all we have to do is to select another quantile. We show the result with quantiles <em class="italic">0.95</em>, <em class="italic">0.90</em>, and <em class="italic">0.50</em> in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.14</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer084" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.14_B19528.jpg" alt="Figure 15.14 – Several quantiles on the same graph in Grafana" width="1650" height="932"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.14 – Several quantiles on the same graph in Grafana</p>&#13;
			<p class="callout-heading">The legend can be customized</p>&#13;
			<p class="callout">Notice that the name of the series in the legend can be customized. Under the <strong class="bold">Options</strong> part of each query, you can customize it at will. You can even include dynamic values coming from the query, such as <span class="No-Break">metrics labels.</span></p>&#13;
			<p>Finally, we can give a name to our graph by setting <strong class="bold">Panel title</strong>, in the right column. Now that we’re happy with our graph, we can click on <strong class="bold">Apply</strong> at the top right to add it to our dashboard, as we see in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.15</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer085" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.15_B19528.jpg" alt="Figure 15.15 – Grafana dashboard" width="1383" height="636"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.15 – Grafana dashboard</p>&#13;
			<p>That’s it! We can start to monitor our application. You can resize and position each panel at will. You can set the query time span you want to look at and even enable auto-refresh so the data gets updated in real time! Don’t forget to click on the <strong class="bold">Save</strong> button to save <span class="No-Break">your dashboard.</span></p>&#13;
			<p>We can build a <a id="_idIndexMarker1119"/>similar graph with the exact same configuration to monitor<a id="_idIndexMarker1120"/> the time needed to execute tasks in Dramatiq, thanks to the metric named <strong class="source-inline">dramatiq_message_duration_milliseconds_bucket</strong>. Notice that this one is expressed in milliseconds instead of seconds, so you should be careful when selecting the unit of your graph. We see here one of the benefits of the Prometheus naming convention <span class="No-Break">for metrics!</span></p>&#13;
			<h3>Adding a bar chart graph</h3>&#13;
			<p>There are a lot <a id="_idIndexMarker1121"/>of different types of graphs available in Grafana. For example, we could plot our dice roll metric in the form of a bar chart, where each bar represents the number of times a face has been seen. Let’s try it: add a new panel and select the <strong class="source-inline">app_dice_rolls_total</strong> metric. You’ll see something similar to what is shown in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer086" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.16_B19528.jpg" alt="Figure 15.16 – Default representation of a counter metric with a bar chart in Grafana" width="1650" height="961"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.16 – Default representation of a counter metric with a bar chart in Grafana</p>&#13;
			<p>We do have a bar for each face, but there is something strange: there are bars for each point in time. That’s a key thing to understand with Prometheus metrics and PromQL: all metrics are stored as <em class="italic">time series</em>. This allows us to go back in time and see the evolution of the metrics <span class="No-Break">over time.</span></p>&#13;
			<p>However, for some representations, like the one shown here, it’s not really insightful. For this case, it would be better to show us the latest values for the time span we selected. We can do this by setting <strong class="bold">Type</strong> to <strong class="bold">Instant</strong> under the <strong class="bold">Options</strong> part of the metric panel. We’ll see that we now have a single graph with a single point in time, as you can see in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.17</em></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer087" class="IMG---Figure">&#13;
					<img src="Images/Figure_15.17_B19528.jpg" alt="Figure 15.17 – Counter metric configured as Instant in Grafana" width="1650" height="965"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.17 – Counter metric configured as Instant in Grafana</p>&#13;
			<p>It’s better, but we can go further. Typically, we would like the <em class="italic">x</em> axis to show the face labels instead of the point in time. First, let’s customize the legend with a <strong class="bold">Custom</strong> label and type <strong class="source-inline">{{face}}</strong>. The legend will now only show the <span class="No-Break"><strong class="source-inline">face</strong></span><span class="No-Break"> label.</span></p>&#13;
			<p>Now, we’ll transform the <a id="_idIndexMarker1122"/>data so the <em class="italic">x</em> axis is the <strong class="source-inline">face</strong> label. Click on the <strong class="bold">Transform</strong> tab. You’ll see a list of functions that can be applied by Grafana to your data before visualizing it. For our case here, we’ll choose <strong class="bold">Reduce</strong>. The effect of this function is to take each series, take a specific value from it, and plot it on the <em class="italic">x</em> axis. By default, Grafana will take the maximum value, <strong class="bold">Max</strong>, but there are other choices, such as <strong class="bold">Last</strong>, <strong class="bold">Mean</strong>, or <strong class="bold">StdDev</strong>. In this context, they won’t make a difference since we already queried the <span class="No-Break">instant value.</span></p>&#13;
			<p>That’s it! Our graph now shows the number of times we’ve seen a face. This is the one we showed in <span class="No-Break"><em class="italic">Figure 15</em></span><em class="italic">.6</em> earlier in <span class="No-Break">the chapter.</span></p>&#13;
			<h1 id="_idParaDest-240"><a id="_idTextAnchor1071"/>Summary</h1>&#13;
			<p>Congratulations! You are now able to report metrics and build your own dashboards in Grafana to monitor your data science applications. Over time, don’t hesitate to add new metrics or complete your dashboards if you notice some blind spots: the goal is to be able to watch over every important part at a glance so you can quickly take corrective actions. Those metrics can also be used to drive the evolution of your work: by monitoring the performance and accuracy of your ML models, you can track the effects of your changes and see whether you are going in the <span class="No-Break">right direction.</span></p>&#13;
			<p>This is the end of this book and our FastAPI journey. We sincerely hope that you liked it and that you learned a lot along the way. We’ve covered many subjects, sometimes just by scratching the surface, but you should now be ready to build your own projects with FastAPI and serve smart data science algorithms. Be sure to check all the external resources we proposed along the way, as they will give you all the insights you need to <span class="No-Break">master them.</span></p>&#13;
			<p>In recent years, Python has gained a lot of popularity, especially in data science communities, and the FastAPI framework, even though still very young, is already a game-changer and has seen an unprecedented adoption rate. It’ll likely be at the heart of many data science systems in the coming years... And as you read this book, you’ll probably be one of the developers behind <span class="No-Break">them. Cheers!</span></p>&#13;
		</div>&#13;
	</div></body></html>