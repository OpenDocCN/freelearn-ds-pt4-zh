<html><head></head><body>
  <div id="_idContainer069">
   <h1 class="chapter-number" id="_idParaDest-119">
    <a id="_idTextAnchor148">
    </a>
    <span class="koboSpan" id="kobo.1.1">
     6
    </span>
   </h1>
   <h1 id="_idParaDest-120">
    <a id="_idTextAnchor149">
    </a>
    <span class="koboSpan" id="kobo.2.1">
     Managing Data Locations in Unity Catalog
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.3.1">
     In this chapter, we’ll explore how to effectively manage data storage locations using securable objects
    </span>
    <a id="_idIndexMarker327">
    </a>
    <span class="koboSpan" id="kobo.4.1">
     in
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.5.1">
      Unity Catalog
     </span>
    </strong>
    <span class="koboSpan" id="kobo.6.1">
     – objects that allow administrators to grant fine-grained permissions to users, groups, and service principals .
    </span>
    <span class="koboSpan" id="kobo.6.2">
     We’ll cover six types of securable objects for storing data in Unity Catalog: catalogs, schemas, tables, volumes, external locations, and connections.
    </span>
    <span class="koboSpan" id="kobo.6.3">
     We’ll also look at how you can effectively govern storage access across various roles and departments within your organization, ensuring data security and auditability within the Databricks Data Intelligence Platform.
    </span>
    <span class="koboSpan" id="kobo.6.4">
     Lastly, we’ll outline how to organize and structure data across different storage locations within
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.7.1">
      Unity Catalog.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.8.1">
     In this chapter, we’re going to cover the following
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.9.1">
      main topics:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.10.1">
      Creating and managing data catalogs in
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.11.1">
       Unity Catalog
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.12.1">
      Setting default storage locations for data within
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.13.1">
       Unity Catalog
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.14.1">
      Creating and managing external storage locations in
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.15.1">
       Unity Catalog
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.16.1">
      Hands-on lab – extracting document text for a generative
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.17.1">
       AI pipeline
      </span>
     </span>
    </li>
   </ul>
   <h1 id="_idParaDest-121">
    <a id="_idTextAnchor150">
    </a>
    <span class="koboSpan" id="kobo.18.1">
     Technical requirements
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.19.1">
     To follow along with the examples provided in this chapter, you’ll need Databricks workspace permissions to create and start an all-purpose cluster so that you can import and execute the chapter’s accompanying notebooks.
    </span>
    <span class="koboSpan" id="kobo.19.2">
     All code samples can be downloaded from this chapter’s GitHub repository located at
    </span>
    <a href="https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter06">
     <span class="koboSpan" id="kobo.20.1">
      https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter06
     </span>
    </a>
    <span class="koboSpan" id="kobo.21.1">
     .
    </span>
    <span class="koboSpan" id="kobo.21.2">
     It’s also recommended that your Databricks user be elevated to a metastore admin (covered in
    </span>
    <a href="B22011_05.xhtml#_idTextAnchor126">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.22.1">
        Chapter 5
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.23.1">
     ) so that you can add and remove external locations, security credentials, foreign connections, and bind catalogs to a Databricks workspace.
    </span>
    <span class="koboSpan" id="kobo.23.2">
     This chapter will create and run several new notebooks, estimated to consume around 5-10
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.24.1">
      Databricks
     </span>
    </strong>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.25.1">
       Units
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.26.1">
      (
     </span>
    </span>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.27.1">
       DBUs
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.28.1">
      ).
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-122">
    <a id="_idTextAnchor151">
    </a>
    <span class="koboSpan" id="kobo.29.1">
     Creating and managing data catalogs in Unity Catalog
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.30.1">
     A
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.31.1">
      catalog
     </span>
    </strong>
    <span class="koboSpan" id="kobo.32.1">
     is the
    </span>
    <a id="_idIndexMarker328">
    </a>
    <span class="koboSpan" id="kobo.33.1">
     topmost container
    </span>
    <a id="_idIndexMarker329">
    </a>
    <span class="koboSpan" id="kobo.34.1">
     in the Unity Catalog object model hierarchy for storing data assets.
    </span>
    <span class="koboSpan" id="kobo.34.2">
     A catalog will contain one or more schemas (or databases), which can contain one or many tables, views, models, functions,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.35.1">
      or volumes.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer061">
     <span class="koboSpan" id="kobo.36.1">
      <img alt="Figure 6.1 – Data is isolated in Unity Catalog using catalogs" src="image/B22011_06_1.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.37.1">
     Figure 6.1 – Data is isolated in Unity Catalog using catalogs
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.38.1">
     A common question is “How many catalogs should my workspace have?”
    </span>
    <span class="koboSpan" id="kobo.38.2">
     While there is no right or wrong answer to the exact number of catalogs one should create for their workspace, a good rule of thumb would be to break your workspace catalogs up by natural dividing factors such as lines of business, logical work environments, teams, or use cases, for example.
    </span>
    <span class="koboSpan" id="kobo.38.3">
     Furthermore, you should consider the subset of groups and users who will have permission to use the data assets as a factor in deciding how to create your
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.39.1">
      catalog isolation.
     </span>
    </span>
   </p>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.40.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.41.1">
     It is a best practice to not have too few catalogs where you cannot logically divide datasets from one another.
    </span>
    <span class="koboSpan" id="kobo.41.2">
     Similarly, it’s also a best practice to not have too many catalogs within a workspace as it makes it difficult for users to navigate and discover datasets.
    </span>
    <span class="koboSpan" id="kobo.41.3">
     You should aim to find somewhere
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.42.1">
      in between.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.43.1">
     Metastore administrators, or privileged users within Unity Catalog, can grant other users the entitlement to create additional catalogs within a metastore.
    </span>
    <span class="koboSpan" id="kobo.43.2">
     For example, the following grant statement executed by a metastore administrator will grant the Databricks user,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.44.1">
      jane.smith@example.com
     </span>
    </strong>
    <span class="koboSpan" id="kobo.45.1">
     , permission to create new catalogs within the metastore attached to their
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.46.1">
      Databricks workspace:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.47.1">
GRANT CREATE CATALOG ON METASTORE TO `jane.smith@example.com`;</span></pre>
   <p>
    <span class="koboSpan" id="kobo.48.1">
     Furthermore, for
    </span>
    <a id="_idIndexMarker330">
    </a>
    <span class="koboSpan" id="kobo.49.1">
     Databricks workspaces created after November 8th, 2023, a default workspace catalog is created within the Unity Catalog metastore,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.50.1">
      &lt;workspace_name&gt;_catalog
     </span>
    </strong>
    <span class="koboSpan" id="kobo.51.1">
     .
    </span>
    <span class="koboSpan" id="kobo.51.2">
     By default, all users in the workspace will have access to this catalog and can create
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.52.1">
      data assets.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-123">
    <a id="_idTextAnchor152">
    </a>
    <span class="koboSpan" id="kobo.53.1">
     Managed data versus external data
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.54.1">
     When you deploy
    </span>
    <a id="_idIndexMarker331">
    </a>
    <span class="koboSpan" id="kobo.55.1">
     a Unity
    </span>
    <a id="_idIndexMarker332">
    </a>
    <span class="koboSpan" id="kobo.56.1">
     Catalog metastore, part of the deployment
    </span>
    <a id="_idIndexMarker333">
    </a>
    <span class="koboSpan" id="kobo.57.1">
     process includes setting up a new, default cloud storage container at the metastore level.
    </span>
    <span class="koboSpan" id="kobo.57.2">
     This cloud storage container serves as the
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.58.1">
      default
     </span>
    </em>
    <span class="koboSpan" id="kobo.59.1">
     location for all data assets created on the Databricks Data Intelligence Platform.
    </span>
    <span class="koboSpan" id="kobo.59.2">
     For example, when a user creates a new table and they do not specify a
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.60.1">
      LOCATION
     </span>
    </strong>
    <span class="koboSpan" id="kobo.61.1">
     attribute
    </span>
    <a id="_idIndexMarker334">
    </a>
    <span class="koboSpan" id="kobo.62.1">
     in the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.63.1">
      data definition language
     </span>
    </strong>
    <span class="koboSpan" id="kobo.64.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.65.1">
      DDL
     </span>
    </strong>
    <span class="koboSpan" id="kobo.66.1">
     ) statement, then the Databricks Data Intelligence Platform will store the table data in the default storage container.
    </span>
    <span class="koboSpan" id="kobo.66.2">
     As a result, the platform will take care of managing the life cycle of this table, including the data files, metadata, and even characteristics of the table, such as tuning the table layout and file sizes.
    </span>
    <span class="koboSpan" id="kobo.66.3">
     This type of data asset is referred to as a
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.67.1">
      managed
     </span>
    </em>
    <span class="koboSpan" id="kobo.68.1">
     table because the Databricks Data Intelligence Platform will manage the life cycle.
    </span>
    <span class="koboSpan" id="kobo.68.2">
     Furthermore, if the table is dropped, the platform will take care of removing all the table metadata and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.69.1">
      data files.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.70.1">
     However, if the user provides a
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.71.1">
      LOCATION
     </span>
    </strong>
    <span class="koboSpan" id="kobo.72.1">
     attribute in the DDL statement, they will override the default behavior.
    </span>
    <span class="koboSpan" id="kobo.72.2">
     Instead, the user is explicitly directing the Databricks Data Intelligence Platform to store the data in a location external to the default storage container for Unity Catalog.
    </span>
    <span class="koboSpan" id="kobo.72.3">
     As a result, this type of data asset is referred to as an
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.73.1">
      external
     </span>
    </em>
    <span class="koboSpan" id="kobo.74.1">
     table.
    </span>
    <span class="koboSpan" id="kobo.74.2">
     Databricks will not manage the performance characteristics of the table, such as the size of the files or the layout of the files.
    </span>
    <span class="koboSpan" id="kobo.74.3">
     Unlike managed tables, if an external table is dropped, only the entry of the table is removed from Unity Catalog and none of the table metadata and data files will be removed from their external location.
    </span>
    <span class="koboSpan" id="kobo.74.4">
     Instead, the table owner will need to take care of deleting the table files from the cloud location, since they’ve taken over managing the table
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.75.1">
      life cycle.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.76.1">
     Generally speaking,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.77.1">
      managed
     </span>
    </em>
    <span class="koboSpan" id="kobo.78.1">
     refers to the Databricks platform managing the life cycle and data will be stored in the default storage container, while on the other hand,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.79.1">
      external
     </span>
    </em>
    <span class="koboSpan" id="kobo.80.1">
     means that the object owner is taking control of the object life cycle and the data should be stored in an external
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.81.1">
      storage location.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.82.1">
     In fact, there may be good reasons when you wish to create data assets in a different storage location than metastore default location.
    </span>
    <span class="koboSpan" id="kobo.82.2">
     For example, for privileged datasets containing sensitive data, such
    </span>
    <a id="_idIndexMarker335">
    </a>
    <span class="koboSpan" id="kobo.83.1">
     as
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.84.1">
      personally identifiable information
     </span>
    </strong>
    <span class="koboSpan" id="kobo.85.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.86.1">
      PII
     </span>
    </strong>
    <span class="koboSpan" id="kobo.87.1">
     ) /
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.88.1">
      protected health information
     </span>
    </strong>
    <span class="koboSpan" id="kobo.89.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.90.1">
      PHI
     </span>
    </strong>
    <span class="koboSpan" id="kobo.91.1">
     ) data, you may
    </span>
    <a id="_idIndexMarker336">
    </a>
    <span class="koboSpan" id="kobo.92.1">
     wish to store these datasets in a separate storage account.
    </span>
    <span class="koboSpan" id="kobo.92.2">
     Or perhaps you have a contractual obligation that requires data to be stored separately in an isolated storage account.
    </span>
    <span class="koboSpan" id="kobo.92.3">
     In any event, it’s quite common to have requirements for data isolation.
    </span>
    <span class="koboSpan" id="kobo.92.4">
     In the next section, let’s look at another securable
    </span>
    <a id="_idIndexMarker337">
    </a>
    <span class="koboSpan" id="kobo.93.1">
     object in
    </span>
    <a id="_idIndexMarker338">
    </a>
    <span class="koboSpan" id="kobo.94.1">
     Unity
    </span>
    <a id="_idIndexMarker339">
    </a>
    <span class="koboSpan" id="kobo.95.1">
     Catalog that allows data admins to securely store arbitrary types of data while maintaining strong isolation from traditional tables
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.96.1">
      and views.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-124">
    <a id="_idTextAnchor153">
    </a>
    <span class="koboSpan" id="kobo.97.1">
     Saving data to storage volumes in Unity Catalog
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.98.1">
     A
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.99.1">
      volume
     </span>
    </strong>
    <span class="koboSpan" id="kobo.100.1">
     , short
    </span>
    <a id="_idIndexMarker340">
    </a>
    <span class="koboSpan" id="kobo.101.1">
     for a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.102.1">
      storage volume
     </span>
    </strong>
    <span class="koboSpan" id="kobo.103.1">
     , can be
    </span>
    <a id="_idIndexMarker341">
    </a>
    <span class="koboSpan" id="kobo.104.1">
     used to
    </span>
    <a id="_idIndexMarker342">
    </a>
    <span class="koboSpan" id="kobo.105.1">
     store files of various
    </span>
    <a id="_idIndexMarker343">
    </a>
    <span class="koboSpan" id="kobo.106.1">
     format types.
    </span>
    <span class="koboSpan" id="kobo.106.2">
     Furthermore, volumes can be stored alongside tables and views in a schema in Unity Catalog.
    </span>
    <span class="koboSpan" id="kobo.106.3">
     While tables and views are used to store structured data, volumes can be used to store structured, semi-structured, or
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.107.1">
      unstructured data.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer062">
     <span class="koboSpan" id="kobo.108.1">
      <img alt="Figure 6.2 – Storage volumes are stored alongside tables and views within a schema in Unity Catalog" src="image/B22011_06_2.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.109.1">
     Figure 6.2 – Storage volumes are stored alongside tables and views within a schema in Unity Catalog
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.110.1">
     Volumes can be managed by the Databricks Data Intelligence Platform, where, once dropped, the storage container, including the entire contents of the storage container, is removed entirely.
    </span>
    <span class="koboSpan" id="kobo.110.2">
     On the other hand, volumes can be external volumes, meaning the volume owner manages the storage location of the storage volume, and once dropped, the contents of the storage container are
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.111.1">
      not removed.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.112.1">
     Storage volumes simplify the storage of files in Unity Catalog by removing the overhead of creating and managing external storage locations and storage credential objects within Unity Catalog.
    </span>
    <span class="koboSpan" id="kobo.112.2">
     Whereas, external locations would need to be created with an accompanying storage credential, making provisioning and deprovisioning slightly
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.113.1">
      more complex.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.114.1">
     Storage volumes
    </span>
    <a id="_idIndexMarker344">
    </a>
    <span class="koboSpan" id="kobo.115.1">
     provide users of
    </span>
    <a id="_idIndexMarker345">
    </a>
    <span class="koboSpan" id="kobo.116.1">
     a particular schema the flexibility of storing arbitrary files in a safe and secure storage location that is managed by the Databricks Data Intelligence Platform.
    </span>
    <span class="koboSpan" id="kobo.116.2">
     By default, storage volumes will persist data in the default storage location of the parent schema.
    </span>
    <span class="koboSpan" id="kobo.116.3">
     For example, if there was no storage location provided at the time of the schema creation, then the data in a storage volume will be stored in the default storage account for the Unity Catalog metastore.
    </span>
    <span class="koboSpan" id="kobo.116.4">
     Whereas if the schemas were created with an explicit storage location, then by default the storage volume will store its contents in this
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.117.1">
      cloud location.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.118.1">
     A metastore administrator or a privileged user with explicit permission to create a volume within a catalog can create or drop a volume.
    </span>
    <span class="koboSpan" id="kobo.118.2">
     The following example grants explicit permission for a Databricks user to create volumes on the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.119.1">
      development catalog:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.120.1">
GRANT CREATE VOLUME
    ON CATALOG development_catalog
    TO `jane.smith@example.com`;</span></pre>
   <p>
    <span class="koboSpan" id="kobo.121.1">
     A fully qualified volume path is constructed using
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.122.1">
      /Volumes/
     </span>
    </strong>
    <span class="koboSpan" id="kobo.123.1">
     followed by the catalog, schema, and volume names.
    </span>
    <span class="koboSpan" id="kobo.123.2">
     For example, an arbitrary text file can be referenced using the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.124.1">
      following path:
     </span>
    </span>
   </p>
   <p>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.125.1">
      /
     </span>
    </strong>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.126.1">
       Volumes/catalog_name/schema_name/volume_name/subdirectory_name/arbitrary_file.txt
      </span>
     </strong>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.127.1">
     In the previous examples, we’ve let the Databricks Data Intelligence Platform decide how data is stored using schemas, tables, views, and volumes.
    </span>
    <span class="koboSpan" id="kobo.127.2">
     However, we can
    </span>
    <a id="_idIndexMarker346">
    </a>
    <span class="koboSpan" id="kobo.128.1">
     set a
    </span>
    <a id="_idIndexMarker347">
    </a>
    <span class="koboSpan" id="kobo.129.1">
     prescribed cloud location for certain securable objects as well.
    </span>
    <span class="koboSpan" id="kobo.129.2">
     Let’s look at how we can control the storage location using several techniques in
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.130.1">
      Unity Catalog.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-125">
    <a id="_idTextAnchor154">
    </a>
    <span class="koboSpan" id="kobo.131.1">
     Setting default locations for data within Unity Catalog
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.132.1">
     You can control the
    </span>
    <a id="_idIndexMarker348">
    </a>
    <span class="koboSpan" id="kobo.133.1">
     storage location
    </span>
    <a id="_idIndexMarker349">
    </a>
    <span class="koboSpan" id="kobo.134.1">
     of data using several techniques in
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.135.1">
      Unity Catalog:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.136.1">
       Default location at the catalog level:
      </span>
     </strong>
     <span class="koboSpan" id="kobo.137.1">
      When creating a new catalog, data administrators can prescribe a storage location.
     </span>
     <span class="koboSpan" id="kobo.137.2">
      When creating a data asset, such as a table, and no location is specified, then the data will be stored in the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.138.1">
       catalog location.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.139.1">
       Default location at the schema level
      </span>
     </strong>
     <span class="koboSpan" id="kobo.140.1">
      : Similarly, you can specify a default location at the schema level.
     </span>
     <span class="koboSpan" id="kobo.140.2">
      The schema location will override any default location specified at the catalog level.
     </span>
     <span class="koboSpan" id="kobo.140.3">
      When creating a data asset, such as a table, and no location is specified, then the data will be stored in the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.141.1">
       schema location.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.142.1">
       An external location at the table level
      </span>
     </strong>
     <span class="koboSpan" id="kobo.143.1">
      : This is the finest-grained control data stewards have over their datasets.
     </span>
     <span class="koboSpan" id="kobo.143.2">
      The table location will override any default location specified at either the catalog or the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.144.1">
       schema level.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.145.1">
       Volume location
      </span>
     </strong>
     <span class="koboSpan" id="kobo.146.1">
      : Closely related to external locations (covered in the
     </span>
     <em class="italic">
      <span class="koboSpan" id="kobo.147.1">
       Creating and managing external storage locations in Unity Catalog
      </span>
     </em>
     <span class="koboSpan" id="kobo.148.1">
      section), volumes allow control over where the
     </span>
     <a id="_idIndexMarker350">
     </a>
     <span class="koboSpan" id="kobo.149.1">
      table
     </span>
     <a id="_idIndexMarker351">
     </a>
     <span class="koboSpan" id="kobo.150.1">
      data gets stored in your cloud
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.151.1">
       storage location.
      </span>
     </span>
    </li>
   </ul>
   <h1 id="_idParaDest-126">
    <a id="_idTextAnchor155">
    </a>
    <span class="koboSpan" id="kobo.152.1">
     Isolating catalogs to specific workspaces
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.153.1">
     By default, when
    </span>
    <a id="_idIndexMarker352">
    </a>
    <span class="koboSpan" id="kobo.154.1">
     you create a catalog in Unity Catalog, the catalog will be available for metastore admins to grant permissions for users to access across
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.155.1">
      all
     </span>
    </em>
    <span class="koboSpan" id="kobo.156.1">
     Databricks workspaces using that metastore.
    </span>
    <span class="koboSpan" id="kobo.156.2">
     However, in certain scenarios, you may want to override this behavior and enforce stronger isolation of datasets residing within a particular catalog.
    </span>
    <span class="koboSpan" id="kobo.156.3">
     For example, sensitive datasets may only be available for data pipeline processing in a production workspace but should not be available in lower environments such as a development workspace.
    </span>
    <span class="koboSpan" id="kobo.156.4">
     A feature of Unity Catalog
    </span>
    <a id="_idIndexMarker353">
    </a>
    <span class="koboSpan" id="kobo.157.1">
     called
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.158.1">
      catalog binding
     </span>
    </strong>
    <span class="koboSpan" id="kobo.159.1">
     helps address this type of scenario.
    </span>
    <span class="koboSpan" id="kobo.159.2">
     With catalog binding, catalog administrators, such as a metastore administrator or a catalog owner, can control which workspaces have access to a particular catalog.
    </span>
    <span class="koboSpan" id="kobo.159.3">
     For Databricks workspaces that are not bound to a particular catalog, the catalog will not appear in the search results of the Catalog
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.160.1">
      Explorer UI.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer063">
     <span class="koboSpan" id="kobo.161.1">
      <img alt="Figure 6.3 – Catalog binding allows data administrators to control data isolation and isolation levels per workspace" src="image/B22011_06_3.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.162.1">
     Figure 6.3 – Catalog binding allows data administrators to control data isolation and isolation levels per workspace
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.163.1">
     Furthermore, data administrators can prescribe the type of actions that are available to datasets bound to a particular workspace.
    </span>
    <span class="koboSpan" id="kobo.163.2">
     For example, say that you want to limit the access to read-only
    </span>
    <a id="_idIndexMarker354">
    </a>
    <span class="koboSpan" id="kobo.164.1">
     for datasets residing within a catalog for a testing environment.
    </span>
    <span class="koboSpan" id="kobo.164.2">
     Data administrators can change the binding settings of a catalog either from the UI, using the Catalog Explorer in the Databricks Data Intelligence Platform, or using automated tools such as Terraform or the REST API.
    </span>
    <span class="koboSpan" id="kobo.164.3">
     Let’s look at an example of how we could leverage the Databricks REST API to bind our testing catalog, which contains PII data to our
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.165.1">
      production workspace.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.166.1">
     First, let’s start off by updating the default settings of our catalog so that the catalog is not accessible from all workspaces that use our Unity Catalog metastore.
    </span>
    <span class="koboSpan" id="kobo.166.2">
     By default, this attribute is set to
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.167.1">
      OPEN
     </span>
    </strong>
    <span class="koboSpan" id="kobo.168.1">
     , and we would like to isolate our catalog to a prescribed
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.169.1">
      workspace only:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.170.1">
import requests
catalog = "testing_catalog"
response = requests.patch(
    f"https://{workspace_name}/api/2.1/unity-catalog/catalogs/{catalog}",
    headers = {"Authorization": f"Bearer {api_token}"},
    json = {"isolation_mode": "ISOLATED"}
)
print(response.json())</span></pre>
   <p>
    <span class="koboSpan" id="kobo.171.1">
     We can also use the Catalog Explorer to verify that the isolation mode of our catalog has been updated with our previous request.
    </span>
    <span class="koboSpan" id="kobo.171.2">
     From the Databricks workspace, navigate to the Catalog Explorer
    </span>
    <a id="_idIndexMarker355">
    </a>
    <span class="koboSpan" id="kobo.172.1">
     from the left sidebar menu.
    </span>
    <span class="koboSpan" id="kobo.172.2">
     Next, type in the name of your catalog in the search box to filter the catalogs and click on the name of your catalog.
    </span>
    <span class="koboSpan" id="kobo.172.3">
     From the Catalog Explorer UI, verify in the details that the checkbox titled
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.173.1">
      All workspaces have access
     </span>
    </strong>
    <span class="koboSpan" id="kobo.174.1">
     is no
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.175.1">
      longer checked.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer064">
     <span class="koboSpan" id="kobo.176.1">
      <img alt="Figure 6.4 – Catalog binding information can be configured from the Databricks UI" src="image/B22011_06_4.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.177.1">
     Figure 6.4 – Catalog binding information can be configured from the Databricks UI
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.178.1">
     Now that our catalog is no longer open for metastore administrators to grant access from all workspaces that use our Unity Catalog metastore, we want to bind the catalog to only the workspaces that we’d like users to have
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.179.1">
      access to.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.180.1">
     In the next example, we’ll again use the Databricks REST API to allow data administrators in the production workspace to assign read-only access to the datasets in
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.181.1">
      our catalog:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.182.1">
response = requests.patch(
    f"https://{workspace_name}/api/2.1/unity-catalog/bindings/catalog/{catalog}",
    headers = {"Authorization": f"Bearer {api_token}"},
    json = {"add": [{
        "workspace_id": &lt;production_workspace_id&gt;,
        "binding_type": "</span><strong class="bold"><span class="koboSpan" id="kobo.183.1">BINDING_TYPE_READ_ONLY</span></strong><span class="koboSpan" id="kobo.184.1">"}]
    }
)
print(response.json())</span></pre>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.185.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.186.1">
     In the preceding example, we provide the workspace identifier in the payload request for binding a catalog to a workspace in Unity Catalog.
    </span>
    <span class="koboSpan" id="kobo.186.2">
     If you aren’t sure what your workspace identifier is, you can quickly find it by inspecting the URL of your Databricks workspace.
    </span>
    <span class="koboSpan" id="kobo.186.3">
     The workspace identifier can be found in the first URI segment of the URL to your Databricks workspace and follows the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.187.1">
      https://&lt;workspace_name&gt;.cloud.databricks.com/o=&lt;workspace_id&gt;
     </span>
    </strong>
    <span class="koboSpan" id="kobo.188.1">
     pattern.
    </span>
    <span class="koboSpan" id="kobo.188.2">
     The workspace identifier will be the numerical value immediately following the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.189.1">
      o=
     </span>
    </strong>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.190.1">
      URL parameter.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.191.1">
     By now, you should
    </span>
    <a id="_idIndexMarker356">
    </a>
    <span class="koboSpan" id="kobo.192.1">
     understand the impact that catalog binding has in allowing data administrators the ability to control how our data is accessible and further isolate datasets in the Databricks Data Intelligence Platform.
    </span>
    <span class="koboSpan" id="kobo.192.2">
     However, there may be certain scenarios in which data administrators need to control the cloud storage location, such as meeting contractual obligations of no co-location of datasets during pipeline processing.
    </span>
    <span class="koboSpan" id="kobo.192.3">
     In the next section, let’s look at how data administrators can assign specific cloud locations
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.193.1">
      for datasets.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-127">
    <a id="_idTextAnchor156">
    </a>
    <span class="koboSpan" id="kobo.194.1">
     Creating and managing external storage locations in Unity Catalog
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.195.1">
     One of the strong
    </span>
    <a id="_idIndexMarker357">
    </a>
    <span class="koboSpan" id="kobo.196.1">
     suits of
    </span>
    <a id="_idIndexMarker358">
    </a>
    <span class="koboSpan" id="kobo.197.1">
     Databricks is the openness of data, meaning users can connect to data stored in a variety of cloud-native storage systems.
    </span>
    <span class="koboSpan" id="kobo.197.2">
     For example, users can connect to data stored in Amazon’s S3 service and join that data with another dataset stored in an
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.198.1">
      Azure Data Lake Storage
     </span>
    </strong>
    <span class="koboSpan" id="kobo.199.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.200.1">
      ADLS
     </span>
    </strong>
    <span class="koboSpan" id="kobo.201.1">
     )
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.202.1">
      Gen2
     </span>
    </strong>
    <span class="koboSpan" id="kobo.203.1">
     storage container.
    </span>
    <span class="koboSpan" id="kobo.203.2">
     However, one of the
    </span>
    <a id="_idIndexMarker359">
    </a>
    <span class="koboSpan" id="kobo.204.1">
     downsides is
    </span>
    <a id="_idIndexMarker360">
    </a>
    <span class="koboSpan" id="kobo.205.1">
     that integration with these cloud-native storage services needs complex configuration settings to be set typically at the beginning of a notebook execution, or perhaps in an initialization script when a cluster starts up.
    </span>
    <span class="koboSpan" id="kobo.205.2">
     These configuration settings are complex, and at the very minimum need to be stored in a Databricks secret, and authentication tokens would need to be rotated by cloud admins – a very complex maintenance life cycle for an otherwise simple task – loading remote data using Spark’s
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.206.1">
      DataFrameReader
     </span>
    </strong>
    <span class="koboSpan" id="kobo.207.1">
     .
    </span>
    <span class="koboSpan" id="kobo.207.2">
     One of the key benefits that Unity Catalog brings is a securable object called a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.208.1">
      storage credential
     </span>
    </strong>
    <span class="koboSpan" id="kobo.209.1">
     , which aims to simplify this maintenance task, while also allowing end users the ability to store and connect to datasets that are external to the Databricks Data Intelligence Platform.
    </span>
    <span class="koboSpan" id="kobo.209.2">
     Cloud admins or metastore admins can store cloud service authentication details in a single place and save end users, who may not be technical, from having to configure complex details of cloud authentication, such as an IAM role identifier.
    </span>
    <span class="koboSpan" id="kobo.209.3">
     As an example of how complex these configuration details can be, the following code snippet can be used to configure authentication to an ADLS Gen2 container using the configuration that gets set during the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.210.1">
      code execution:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.211.1">
# Connect to data stored in an ADLS Gen2 container
account_name = "some_storage_account"
spark.conf.set(f"fs.azure.account.auth.type.{account_name}.dfs.core.windows.net", "SAS")
spark.conf.set(f"fs.azure.sas.token.provider.type.{account_name}.dfs.core.windows.net", "org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider")
# Use a Databricks Secret to safely store and retrieve a SAS key for authenticating with ADLS service
spark.conf.set(
    f"fs.azure.sas.fixed.token.{account_name}.dfs.core.windows.net",
    dbutils.secrets.get(scope="sas_token_scope", 
    key="sas_ token_key"))</span></pre>
   <h2 id="_idParaDest-128">
    <a id="_idTextAnchor157">
    </a>
    <span class="koboSpan" id="kobo.212.1">
     Storing cloud service authentication using storage credentials
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.213.1">
     A
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.214.1">
      storage credential
     </span>
    </strong>
    <span class="koboSpan" id="kobo.215.1">
     is
    </span>
    <a id="_idIndexMarker361">
    </a>
    <span class="koboSpan" id="kobo.216.1">
     a securable
    </span>
    <a id="_idIndexMarker362">
    </a>
    <span class="koboSpan" id="kobo.217.1">
     object within Unity Catalog that abstracts
    </span>
    <a id="_idIndexMarker363">
    </a>
    <span class="koboSpan" id="kobo.218.1">
     away a cloud-native credential for access to a cloud storage account.
    </span>
    <span class="koboSpan" id="kobo.218.2">
     For example, a storage credential may
    </span>
    <a id="_idIndexMarker364">
    </a>
    <span class="koboSpan" id="kobo.219.1">
     represent an
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.220.1">
      Identity and Access Management
     </span>
    </strong>
    <span class="koboSpan" id="kobo.221.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.222.1">
      IAM
     </span>
    </strong>
    <span class="koboSpan" id="kobo.223.1">
     ) role on the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.224.1">
      Amazon Web Services
     </span>
    </strong>
    <span class="koboSpan" id="kobo.225.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.226.1">
      AWS
     </span>
    </strong>
    <span class="koboSpan" id="kobo.227.1">
     ) cloud.
    </span>
    <span class="koboSpan" id="kobo.227.2">
     A
    </span>
    <a id="_idIndexMarker365">
    </a>
    <span class="koboSpan" id="kobo.228.1">
     storage credential may also represent a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.229.1">
      managed identity
     </span>
    </strong>
    <span class="koboSpan" id="kobo.230.1">
     or
    </span>
    <a id="_idIndexMarker366">
    </a>
    <span class="koboSpan" id="kobo.231.1">
     service principal in the Azure cloud.
    </span>
    <span class="koboSpan" id="kobo.231.2">
     Once a storage credential has been created, access to the storage credential can be granted to users and groups in Unity Catalog using an explicit grant statement.
    </span>
    <span class="koboSpan" id="kobo.231.3">
     Like other securable objects in Unity Catalog, there are various methods for creating a new security credential on the Databricks Data Intelligence Platform.
    </span>
    <span class="koboSpan" id="kobo.231.4">
     For example, a metastore admin may choose to use
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.232.1">
      American National Standards Institute Structured Query Language
     </span>
    </strong>
    <span class="koboSpan" id="kobo.233.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.234.1">
      ANSI SQL
     </span>
    </strong>
    <span class="koboSpan" id="kobo.235.1">
     ) to
    </span>
    <a id="_idIndexMarker367">
    </a>
    <span class="koboSpan" id="kobo.236.1">
     create the storage credential, or they might use the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.237.1">
      Databricks UI.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer065">
     <span class="koboSpan" id="kobo.238.1">
      <img alt="Figure 6.5 – Storage credentials can be created using Databricks UI" src="image/B22011_06_5.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.239.1">
     Figure 6.5 – Storage credentials can be created using Databricks UI
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.240.1">
     Storage credentials are
    </span>
    <a id="_idIndexMarker368">
    </a>
    <span class="koboSpan" id="kobo.241.1">
     paired with another securable object in Unity
    </span>
    <a id="_idIndexMarker369">
    </a>
    <span class="koboSpan" id="kobo.242.1">
     Catalog
    </span>
    <a id="_idIndexMarker370">
    </a>
    <span class="koboSpan" id="kobo.243.1">
     called an
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.244.1">
      external location
     </span>
    </strong>
    <span class="koboSpan" id="kobo.245.1">
     , and the
    </span>
    <a id="_idIndexMarker371">
    </a>
    <span class="koboSpan" id="kobo.246.1">
     combination is used to store and access data in a specific cloud
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.247.1">
      storage account.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer066">
     <span class="koboSpan" id="kobo.248.1">
      <img alt="Figure 6.6 – A storage credential encapsulates a cloud identity and is used by Unity Catalog to access an external storage location" src="image/B22011_06_6.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.249.1">
     Figure 6.6 – A storage credential encapsulates a cloud identity and is used by Unity Catalog to access an external storage location
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.250.1">
     You must be either a Databricks account administrator or a metastore administrator for a Unity Catalog metastore, which will include the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.251.1">
      CREATE STORAGE CREDENTIAL
     </span>
    </strong>
    <span class="koboSpan" id="kobo.252.1">
     entitlement.
    </span>
    <span class="koboSpan" id="kobo.252.2">
     The following example uses the Databricks
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.253.1">
      command-line interface
     </span>
    </strong>
    <span class="koboSpan" id="kobo.254.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.255.1">
      CLI
     </span>
    </strong>
    <span class="koboSpan" id="kobo.256.1">
     ) tool to
    </span>
    <a id="_idIndexMarker372">
    </a>
    <span class="koboSpan" id="kobo.257.1">
     create a new storage credential in Unity Catalog using an IAM role
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.258.1">
      in AWS:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.259.1">
databricks storage-credentials create \
  --json '{"name": "my_storage_cred", ' \
  '"aws_iam_role": {"role_arn": ' \
  '"arn:aws:iam::&lt;role_identifier&gt;:role/&lt;account_name&gt;"}}'</span></pre>
   <p>
    <span class="koboSpan" id="kobo.260.1">
     Let’s use the SQL API this time to grant permission to the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.261.1">
      data-science
     </span>
    </strong>
    <span class="koboSpan" id="kobo.262.1">
     group to use the credential for accessing
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.263.1">
      cloud storage:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.264.1">
-- Grant access to create an external location using the storage cred
GRANT CREATE EXTERNAL LOCATION
    ON STORAGE CREDENTIAL my_s3_bucket_cred
    TO `data-science`;</span></pre>
   <p>
    <span class="koboSpan" id="kobo.265.1">
     However, storage containers external to the Databricks Data Intelligence Platform may not be the only source of data that you wish to connect to from your lakehouse.
    </span>
    <span class="koboSpan" id="kobo.265.2">
     For instance, there may be scenarios in which you may need to connect to an external system, such as an
    </span>
    <a id="_idIndexMarker373">
    </a>
    <span class="koboSpan" id="kobo.266.1">
     existing data warehouse or a relational database, to
    </span>
    <a id="_idIndexMarker374">
    </a>
    <span class="koboSpan" id="kobo.267.1">
     cross-reference
    </span>
    <a id="_idIndexMarker375">
    </a>
    <span class="koboSpan" id="kobo.268.1">
     data.
    </span>
    <span class="koboSpan" id="kobo.268.2">
     Let’s turn our attention to
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.269.1">
      Lakehouse Federation
     </span>
    </strong>
    <span class="koboSpan" id="kobo.270.1">
     , which allows lakehouse users to query datasets outside of the Databricks Data
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.271.1">
      Intelligence Platform.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-129">
    <a id="_idTextAnchor158">
    </a>
    <span class="koboSpan" id="kobo.272.1">
     Querying external systems using Lakehouse Federation
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.273.1">
     Lakehouse
    </span>
    <a id="_idIndexMarker376">
    </a>
    <span class="koboSpan" id="kobo.274.1">
     Federation is a
    </span>
    <a id="_idIndexMarker377">
    </a>
    <span class="koboSpan" id="kobo.275.1">
     feature
    </span>
    <a id="_idIndexMarker378">
    </a>
    <span class="koboSpan" id="kobo.276.1">
     in the Databricks Data Intelligence Platform that permits users to execute queries on storage systems external to Databricks without needing to migrate the data to the lakehouse.
    </span>
    <span class="koboSpan" id="kobo.276.2">
     Another securable object in Unity
    </span>
    <a id="_idIndexMarker379">
    </a>
    <span class="koboSpan" id="kobo.277.1">
     Catalog, called a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.278.1">
      connection
     </span>
    </strong>
    <span class="koboSpan" id="kobo.279.1">
     , can be used to federate queries to external systems.
    </span>
    <span class="koboSpan" id="kobo.279.2">
     A connection represents a
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.280.1">
      read-only
     </span>
    </em>
    <span class="koboSpan" id="kobo.281.1">
     connection to an external system, such as a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.282.1">
      relational database management system
     </span>
    </strong>
    <span class="koboSpan" id="kobo.283.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.284.1">
      RDBMS
     </span>
    </strong>
    <span class="koboSpan" id="kobo.285.1">
     ), such as
    </span>
    <a id="_idIndexMarker380">
    </a>
    <span class="koboSpan" id="kobo.286.1">
     Postgres or MySQL, or a cloud data warehouse such as Amazon Redshift.
    </span>
    <span class="koboSpan" id="kobo.286.2">
     This is a great way to query external data to quickly prototype new pipelines in your lakehouse.
    </span>
    <span class="koboSpan" id="kobo.286.3">
     Perhaps, even, you need to cross-reference an external dataset and don’t want to go through the lengthy process of creating
    </span>
    <a id="_idIndexMarker381">
    </a>
    <span class="koboSpan" id="kobo.287.1">
     another
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.288.1">
      extract, transform, and load
     </span>
    </strong>
    <span class="koboSpan" id="kobo.289.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.290.1">
      ETL
     </span>
    </strong>
    <span class="koboSpan" id="kobo.291.1">
     ) pipeline to ingest a new data source
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.292.1">
      just yet.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.293.1">
     A list of all connections can be easily viewed in the Databricks Data Intelligence Platform by navigating to the Catalog Explorer, expanding the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.294.1">
      Connections
     </span>
    </strong>
    <span class="koboSpan" id="kobo.295.1">
     pane, and clicking a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.296.1">
      Foreign Connection
     </span>
    </strong>
    <span class="koboSpan" id="kobo.297.1">
     to view the details about a previously
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.298.1">
      created connection.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.299.1">
     Let’s look at an example of how we can use the SQL connection API in Databricks to create a new foreign connection to the MySQL database.
    </span>
    <span class="koboSpan" id="kobo.299.2">
     Databricks recommends that all credential information be stored in a Databricks secret, which can be easily retrieved from SQL using
    </span>
    <a id="_idIndexMarker382">
    </a>
    <span class="koboSpan" id="kobo.300.1">
     the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.301.1">
      secret()
     </span>
    </strong>
    <span class="koboSpan" id="kobo.302.1">
     SQL function and providing the secret scope and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.303.1">
      secret key:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.304.1">
CREATE CONNECTION my_mysql_connection TYPE mysql
OPTIONS (
    host '&lt;fully_qualified_hostname&gt;',
    port '3306',
    user secret('mysql_scope', 'mysql_username'),
    password secret('mysql_scope', 'mysql_password')
)</span></pre>
   <p>
    <span class="koboSpan" id="kobo.305.1">
     Next, navigate to the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.306.1">
      Connections
     </span>
    </strong>
    <span class="koboSpan" id="kobo.307.1">
     UI by clicking on the Catalog Explorer in the left-hand side navigation bar, expanding the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.308.1">
      External Data
     </span>
    </strong>
    <span class="koboSpan" id="kobo.309.1">
     pane, and clicking on the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.310.1">
      Connections
     </span>
    </strong>
    <span class="koboSpan" id="kobo.311.1">
     menu item.
    </span>
    <span class="koboSpan" id="kobo.311.2">
     You should now see the newly created connection to the MySQL database and clicking on it will reveal details about
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.312.1">
      the connection.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer067">
     <span class="koboSpan" id="kobo.313.1">
      <img alt="Figure 6.7 – Connections to foreign storage systems can be viewed from the Catalog Explorer" src="image/B22011_06_7.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.314.1">
     Figure 6.7 – Connections to foreign storage systems can be viewed from the Catalog Explorer
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.315.1">
     Let’s connect
    </span>
    <a id="_idIndexMarker383">
    </a>
    <span class="koboSpan" id="kobo.316.1">
     everything
    </span>
    <a id="_idIndexMarker384">
    </a>
    <span class="koboSpan" id="kobo.317.1">
     we’ve
    </span>
    <a id="_idIndexMarker385">
    </a>
    <span class="koboSpan" id="kobo.318.1">
     learned in the previous sections to build a modern data pipeline capable of powering generative AI
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.319.1">
      use cases.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-130">
    <a id="_idTextAnchor159">
    </a>
    <span class="koboSpan" id="kobo.320.1">
     Hands-on lab – extracting document text for a generative AI pipeline
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.321.1">
     In this example, we’ll
    </span>
    <a id="_idIndexMarker386">
    </a>
    <span class="koboSpan" id="kobo.322.1">
     look at a typical pipeline used to extract text from documents for the purposes of generative AI.
    </span>
    <span class="koboSpan" id="kobo.322.2">
     This is a very common architectural pattern, especially for real-world use cases such as training a chatbot over a text corpus.
    </span>
    <span class="koboSpan" id="kobo.322.3">
     Along the way, we’ll see how storage volumes on the Databricks Data Intelligence Platform are a great fit for processing arbitrary files from an external cloud storage location.
    </span>
    <span class="koboSpan" id="kobo.322.4">
     All code samples can be downloaded from this chapter’s GitHub repository located
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.323.1">
      at
     </span>
    </span>
    <a href="https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter06">
     <span class="No-Break">
      <span class="koboSpan" id="kobo.324.1">
       https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter06
      </span>
     </span>
    </a>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.325.1">
      .
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-131">
    <a id="_idTextAnchor160">
    </a>
    <span class="koboSpan" id="kobo.326.1">
     Generating mock documents
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.327.1">
     The first step in a
    </span>
    <a id="_idIndexMarker387">
    </a>
    <span class="koboSpan" id="kobo.328.1">
     data pipeline
    </span>
    <a id="_idIndexMarker388">
    </a>
    <span class="koboSpan" id="kobo.329.1">
     will be a process for generating arbitrary text files to extract text from.
    </span>
    <span class="koboSpan" id="kobo.329.2">
     Let’s begin by creating a new notebook in our Databricks workspace which will be used to train our organization’s chatbot.
    </span>
    <span class="koboSpan" id="kobo.329.3">
     The following code example uses the popular
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.330.1">
      faker
     </span>
    </strong>
    <span class="koboSpan" id="kobo.331.1">
     Python library, to randomly generate the content within our documents, and the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.332.1">
      reportlab
     </span>
    </strong>
    <span class="koboSpan" id="kobo.333.1">
     Python library, for generating
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.334.1">
      PDF files.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.335.1">
     Begin by installing the library dependencies in the first notebook cell using the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.336.1">
      %pip
     </span>
    </strong>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.337.1">
      magic command:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.338.1">
%pip install faker reportlab</span></pre>
   <h2 id="_idParaDest-132">
    <a id="_idTextAnchor161">
    </a>
    <span class="koboSpan" id="kobo.339.1">
     Defining helper functions
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.340.1">
     Let’s define a few
    </span>
    <a id="_idIndexMarker389">
    </a>
    <span class="koboSpan" id="kobo.341.1">
     helper
    </span>
    <a id="_idIndexMarker390">
    </a>
    <span class="koboSpan" id="kobo.342.1">
     functions that will take a randomly generated paragraph of text and save the text as a document.
    </span>
    <span class="koboSpan" id="kobo.342.2">
     We’ll define three helper functions – one helper function for each document
    </span>
    <a id="_idIndexMarker391">
    </a>
    <span class="koboSpan" id="kobo.343.1">
     format type – plain
    </span>
    <a id="_idIndexMarker392">
    </a>
    <span class="koboSpan" id="kobo.344.1">
     text,
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.345.1">
      Portable Document Format
     </span>
    </strong>
    <span class="koboSpan" id="kobo.346.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.347.1">
      PDF
     </span>
    </strong>
    <span class="koboSpan" id="kobo.348.1">
     ), and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.349.1">
      comma-separated
     </span>
    </strong>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.350.1">
       values
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.351.1">
      (
     </span>
    </span>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.352.1">
       CSV
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.353.1">
      ):
     </span>
    </span>
   </p>
   <ol>
    <li>
     <span class="koboSpan" id="kobo.354.1">
      Let’s define the helper function for a plain
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.355.1">
       text file:
      </span>
     </span>
     <pre class="source-code"><span class="koboSpan" id="kobo.356.1">
from shutil import copyfile
def save_doc_as_text(file_name, save_path, paragraph):
    """Helper function that saves a paragraph of text as a text file"""
    tmp_path = f"/local_disk0/tmp/{file_name}"
    volume_path = f"{save_path}/{file_name}"
    print(f"Saving text file at : {tmp_path}")
    txtfile = open(tmp_path, "a")
    txtfile.write(paragraph)
    txtfile.close()
    copyfile(tmp_path, volume_path)</span></pre>
    </li>
    <li>
     <span class="koboSpan" id="kobo.357.1">
      Next, we define the helper function for a
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.358.1">
       PDF file:
      </span>
     </span>
     <pre class="source-code"><span class="koboSpan" id="kobo.359.1">
def save_doc_as_pdf(file_name, save_path, paragraph):
    """Helper function that saves a paragraph of text as a PDF file"""
    from reportlab.pdfgen.canvas import Canvas
    from reportlab.lib.pagesizes import letter
    from reportlab.lib.units import cm
    tmp_path = f"/local_disk0/tmp/{file_name}"
    volume_path = f"{save_path}/{file_name}"
    canvas = Canvas(tmp_path, pagesize=letter)
    lines = paragraph.split(".")
    textobject = canvas.beginText(5*cm, 25*cm)
    for line in lines:
        textobject.textLine(line)
        canvas.drawText(textobject)
    canvas.save()
    print(f"Saving PDF file at : {tmp_path}")
    copyfile(tmp_path, volume_path)</span></pre>
    </li>
    <li>
     <span class="koboSpan" id="kobo.360.1">
      Lastly, we
     </span>
     <a id="_idIndexMarker393">
     </a>
     <span class="koboSpan" id="kobo.361.1">
      define
     </span>
     <a id="_idIndexMarker394">
     </a>
     <span class="koboSpan" id="kobo.362.1">
      the helper function for a
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.363.1">
       CSV file:
      </span>
     </span>
     <pre class="source-code"><span class="koboSpan" id="kobo.364.1">
def save_doc_as_csv(file_name, save_path, paragraph):
    """Helper function that saves a paragraph of text as a CSV file"""
    import csv
    tmp_path = f"/local_disk0/tmp/{file_name}"
    volume_path = f"{save_path}/{file_name}"
    print(f"Saving CSV file at : {tmp_path}")
    with open(tmp_path, 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Id", "Sentence"])
        i = 1
        for line in paragraph.split("."):
            writer.writerow([i, line])
            i = i + 1
    copyfile(tmp_path, volume_path)</span></pre>
    </li>
   </ol>
   <p>
    <span class="koboSpan" id="kobo.365.1">
     This is a great
    </span>
    <a id="_idIndexMarker395">
    </a>
    <span class="koboSpan" id="kobo.366.1">
     way to simulate
    </span>
    <a id="_idIndexMarker396">
    </a>
    <span class="koboSpan" id="kobo.367.1">
     a variety of documents you might expect your organization to accumulate
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.368.1">
      over time.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-133">
    <a id="_idTextAnchor162">
    </a>
    <span class="koboSpan" id="kobo.369.1">
     Choosing a file format randomly
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.370.1">
     Next, we will need to
    </span>
    <a id="_idIndexMarker397">
    </a>
    <span class="koboSpan" id="kobo.371.1">
     randomly
    </span>
    <a id="_idIndexMarker398">
    </a>
    <span class="koboSpan" id="kobo.372.1">
     choose the file format to save the generated documents.
    </span>
    <span class="koboSpan" id="kobo.372.2">
     Let’s begin by importing the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.373.1">
      faker
     </span>
    </strong>
    <span class="koboSpan" id="kobo.374.1">
     library and a few Python utility libraries that we’ll use to create unpredictable behavior.
    </span>
    <span class="koboSpan" id="kobo.374.2">
     We’ll also define a few global variables that will be used to determine the characteristics of our randomly generated documents, such as the number of documents to generate, the number of sentences to generate per document, and the types of file formats to store the documents in.
    </span>
    <span class="koboSpan" id="kobo.374.3">
     Add the following code snippet to
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.375.1">
      the notebook:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.376.1">
from faker import Faker
import time
import random
Faker.seed(631)
fake = Faker()
# Randomly generate documents
num_docs = 5
num_sentences_per_doc = 100
doc_types = ["txt", "pdf", "csv"]
volume_path = f"/Volumes/{catalog_name}/{schema_name}/{volume_name}"</span></pre>
   <p>
    <span class="koboSpan" id="kobo.377.1">
     Next, let’s create a simple
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.378.1">
      for
     </span>
    </strong>
    <span class="koboSpan" id="kobo.379.1">
     loop that will serve as the backbone for our random document generator.
    </span>
    <span class="koboSpan" id="kobo.379.2">
     Within the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.380.1">
      for
     </span>
    </strong>
    <span class="koboSpan" id="kobo.381.1">
     loop, we’ll use the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.382.1">
      faker
     </span>
    </strong>
    <span class="koboSpan" id="kobo.383.1">
     library to create a paragraph of random text having the number of sentences equal to the number set by our
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.384.1">
      num_sentences_per_doc
     </span>
    </strong>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.385.1">
      global variable:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.386.1">
for _ in range(num_docs):
    paragraph = fake.paragraph(nb_sentences=num_sentences_per_doc)</span></pre>
   <p>
    <span class="koboSpan" id="kobo.387.1">
     After the paragraph of random text has been generated, it’s time to choose what file format to store the
    </span>
    <a id="_idIndexMarker399">
    </a>
    <span class="koboSpan" id="kobo.388.1">
     text in.
    </span>
    <span class="koboSpan" id="kobo.388.2">
     We’ll
    </span>
    <a id="_idIndexMarker400">
    </a>
    <span class="koboSpan" id="kobo.389.1">
     leverage the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.390.1">
      random
     </span>
    </strong>
    <span class="koboSpan" id="kobo.391.1">
     Python library to randomly select a file format type from the list of file formats defined in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.392.1">
      doc_types
     </span>
    </strong>
    <span class="koboSpan" id="kobo.393.1">
     global variable.
    </span>
    <span class="koboSpan" id="kobo.393.2">
     Add the following code snippet to the body of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.394.1">
      the for-loop:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.395.1">
    # Randomly choose a document format type
    doc_type = doc_types[random.randrange(2)]
    print(doc_type)
    if doc_type == "txt":
        doc_name = f"{fake.pystr()}.txt"
        save_doc_as_text(doc_name, volume_path, paragraph)
    elif doc_type == "pdf":
        doc_name = f"{fake.pystr()}.pdf"
        save_doc_as_pdf(doc_name, volume_path, paragraph)
    elif doc_type == "csv":
        doc_name = f"{fake.pystr()}.csv"
        save_doc_as_csv(doc_name, volume_path, paragraph)</span></pre>
   <p>
    <span class="koboSpan" id="kobo.396.1">
     Lastly, we’ll add a sleep timer to simulate unpredictable peaks and lulls in the generation of text documents – something that you could expect in a typical production environment.
    </span>
    <span class="koboSpan" id="kobo.396.2">
     Add the following code snippet to the bottom of the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.397.1">
      for-loop body:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.398.1">
    # Sleep for a random interval
    sleep_time = random.randint(3, 30)
    print(f"Sleeping for {sleep_time} seconds...\n\n")
    time.sleep(sleep_time)</span></pre>
   <p>
    <span class="koboSpan" id="kobo.399.1">
     You’ll also notice in the global variables section of the notebook, we’ve defined a volume path for our process to save the randomly
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.400.1">
      generated documents:
     </span>
    </span>
   </p>
   <p>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.401.1">
      volume_path =
     </span>
    </strong>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.402.1">
       f"/Volumes/{catalog_name}/{schema_name}/{volume_name}"
      </span>
     </strong>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.403.1">
     This is a convenient way to reference a cloud storage location as though it were a local storage path.
    </span>
    <span class="koboSpan" id="kobo.403.2">
     Plus, we have all the benefits of strong data governance that come with a storage volume in Unity Catalog.
    </span>
    <span class="koboSpan" id="kobo.403.3">
     For example, all the data is secured by default, and other users or processes cannot read these documents until we have permission to access the data in the storage volume.
    </span>
    <span class="koboSpan" id="kobo.403.4">
     Finally, let’s attach the new notebook to a running all-purpose cluster in the Databricks Data Intelligence Platform and click the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.404.1">
      Run all
     </span>
    </strong>
    <span class="koboSpan" id="kobo.405.1">
     button at
    </span>
    <a id="_idIndexMarker401">
    </a>
    <span class="koboSpan" id="kobo.406.1">
     the top
    </span>
    <a id="_idIndexMarker402">
    </a>
    <span class="koboSpan" id="kobo.407.1">
     of the notebook to begin generating and saving new documents to our storage
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.408.1">
      volume location.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-134">
    <a id="_idTextAnchor163">
    </a>
    <span class="koboSpan" id="kobo.409.1">
     Creating/assembling the DLT pipeline
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.410.1">
     Now that we’ve
    </span>
    <a id="_idIndexMarker403">
    </a>
    <span class="koboSpan" id="kobo.411.1">
     generated
    </span>
    <a id="_idIndexMarker404">
    </a>
    <span class="koboSpan" id="kobo.412.1">
     some text documents, let’s go ahead a create a new DLT pipeline that will stream the randomly generated documents and perform a simple text extraction.
    </span>
    <span class="koboSpan" id="kobo.412.2">
     Import the notebook titled
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.413.1">
      Preprocess Text Documents.py
     </span>
    </strong>
    <span class="koboSpan" id="kobo.414.1">
     from the chapter’s GitHub repository into your Databricks workspace.
    </span>
    <span class="koboSpan" id="kobo.414.2">
     You’ll notice that we define three new streaming tables, all of which are responsible for ingesting the randomly generated text, PDF, and CSV documents.
    </span>
    <span class="koboSpan" id="kobo.414.3">
     After doing minimal preprocessing, the text field from each of these data sources is extracted and joined in a fourth table,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.415.1">
      text_docs_silver
     </span>
    </strong>
    <span class="koboSpan" id="kobo.416.1">
     .
    </span>
    <span class="koboSpan" id="kobo.416.2">
     This fourth table will serve as the input into our
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.417.1">
      chatbot training:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.418.1">
@dlt.table(
    name="text_docs_silver",
    comment="Combined textual documents for Generative AI pipeline."
</span><span class="koboSpan" id="kobo.418.2">)
def text_docs_silver():
    text_docs_df = dlt.read("text_docs_raw").withColumn(
        "type", F.lit("text"))
    csv_docs_df = dlt.read("csv_docs_raw").withColumn(
        "type", F.lit("csv"))
    pdf_docs_df = dlt.read("pdf_docs_raw").withColumn(
        "type", F.lit("pdf"))
    combined_df = text_docs_df.union(csv_docs_df).union(
        pdf_docs_df)
    return combined_df</span></pre>
   <p>
    <span class="koboSpan" id="kobo.419.1">
     After attaching
    </span>
    <a id="_idIndexMarker405">
    </a>
    <span class="koboSpan" id="kobo.420.1">
     the notebook
    </span>
    <a id="_idIndexMarker406">
    </a>
    <span class="koboSpan" id="kobo.421.1">
     to a running cluster, you will be prompted to create a new DLT pipeline.
    </span>
    <span class="koboSpan" id="kobo.421.2">
     Go ahead and create a brand new DLT pipeline (covered in
    </span>
    <a href="B22011_02.xhtml#_idTextAnchor052">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.422.1">
        Chapter 2
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.423.1">
     ), titling the pipeline with a meaningful name, such as
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.424.1">
      doc_ingestion_pipeline
     </span>
    </strong>
    <span class="koboSpan" id="kobo.425.1">
     .
    </span>
    <span class="koboSpan" id="kobo.425.2">
     Select
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.426.1">
      Triggered
     </span>
    </strong>
    <span class="koboSpan" id="kobo.427.1">
     for the processing mode and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.428.1">
      Core
     </span>
    </strong>
    <span class="koboSpan" id="kobo.429.1">
     for the product edition, and accept the remaining defaults.
    </span>
    <span class="koboSpan" id="kobo.429.2">
     Finally, click
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.430.1">
      Start
     </span>
    </strong>
    <span class="koboSpan" id="kobo.431.1">
     to begin an update execution of the newly created
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.432.1">
      DLT pipeline.
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer068">
     <span class="koboSpan" id="kobo.433.1">
      <img alt="Figure 6.8 – An overview of a DLT pipeline extracting text from arbitrary documents saved to a volume location in Unity Catalog" src="image/B22011_06_8_new.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.434.1">
     Figure 6.8 – An overview of a DLT pipeline extracting text from arbitrary documents saved to a volume location in Unity Catalog
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.435.1">
     You should see the DLT pipeline incrementally processing the randomly generated text documents, extracting the text from each of the different file types, and merging them into a consolidated
    </span>
    <a id="_idIndexMarker407">
    </a>
    <span class="koboSpan" id="kobo.436.1">
     dataset
    </span>
    <a id="_idIndexMarker408">
    </a>
    <span class="koboSpan" id="kobo.437.1">
     downstream.
    </span>
    <span class="koboSpan" id="kobo.437.2">
     This is a simple, yet powerful example of how DLT can be combined with a storage volume in Unity Catalog to process arbitrary file formats in a real-world
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.438.1">
      use case.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-135">
    <a id="_idTextAnchor164">
    </a>
    <span class="koboSpan" id="kobo.439.1">
     Summary
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.440.1">
     In this chapter, we covered a variety of methods for storing data while also maintaining fine-grained access control using different securable objects in Unity Catalog.
    </span>
    <span class="koboSpan" id="kobo.440.2">
     We covered how data could be stored using catalogs, schemas, tables, views, volumes, and external locations in Unity Catalog.
    </span>
    <span class="koboSpan" id="kobo.440.3">
     We also saw how organizations could bind catalogs to individual Databricks workspaces to isolate datasets and even set the level of access to read-only.
    </span>
    <span class="koboSpan" id="kobo.440.4">
     We covered the differences between managed datasets in the Databricks Data Intelligence Platform, as well as how we could set prescribed storage locations for storing data using catalogs, schemas, tables, volumes, and external locations.
    </span>
    <span class="koboSpan" id="kobo.440.5">
     We covered how external data sources, such as data warehouses, could be queried in place without having to migrate the data using Lakehouse Federation.
    </span>
    <span class="koboSpan" id="kobo.440.6">
     Lastly, we concluded with a hands-on exercise implementing the start of a generative AI pipeline for extracting text from documents using volumes in
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.441.1">
      Unity Catalog.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.442.1">
     Now that we have a solid foundation for storing our data and other assets, in the next chapter, we’ll be covering tracking lineage across various objects in the Databricks Data
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.443.1">
      Intelligence Platform.
     </span>
    </span>
   </p>
  </div>
 </body></html>