["```py\nimport requests\n```", "```py\nresponse = requests.get(\n    f\"https://{WORKSPACE_NAME}.cloud.databricks.com/api/2.0/lineage-tracking/table-lineage\",\n    headers={\n        \"Authorization\": f\"Bearer {API_TOKEN}\"\n    },\n    json={\n        \"table_name\": FULLY_QUALIFIED_TABLE_NAME,\n        \"include_entity_lineage\": \"true\"\n    }\n)\nprint(response.json())\n```", "```py\ndef print_table_info(conn_type, table_info_json):\n    info = table_info_json[\"tableInfo\"]\n    print(f\"\"\"\n        +---------------------------------------------+\n        | {conn_type.upper()} Table Connection Info\n        |---------------------------------------------|\n        | Table name: {info['name']}\n        |---------------------------------------------|\n        | Catalog name: {info['catalog_name']}\n        |---------------------------------------------|\n        | Table type: {info['table_type']}\n        |---------------------------------------------|\n        | Lineage timestamp: {info['lineage_timestamp']}\n        +---------------------------------------------+\n    \"\"\")\n    if conn_type.upper() == \"UPSTREAMS\":\n        print(f\"\"\"\n                                |\n                               \\|/\n        \"\"\")\ndef print_notebook_info(conn_type, notebook_info):\n    print(f\"\"\"\n        +---------------------------------------------+\n        | {conn_type.upper()} Notebook Connection Info:\n        |---------------------------------------------|\n        | Workspace id: {str(notebook_info['workspace_id'])}\n        |---------------------------------------------|\n        | Notebook id: {str(notebook_info['notebook_id'])}\n        |---------------------------------------------|\n        | Timestamp: {notebook_info['lineage_timestamp']}\n        +---------------------------------------------+\n    \"\"\")\n```", "```py\nif response.status_code == 200:\n    connection_flows = [\"upstreams\", \"downstreams\"]\n    for flow in connection_flows:\n        if flow in response.json():\n            connections = response.json()[flow]\n            for conn in connections:\n                if \"tableInfo\" in conn:\n                    print_table_info(flow, conn)\n                elif \"notebookInfos\" in conn:\n                    for notebook_info in conn[\"notebookInfos\"]:\n                        print_notebook_info(flow, notebook_info)\n```", "```py\ndef print_column_info(conn_type, column_info):\n    print(f\"\"\"\n        Connection flow: {conn_type.upper()}\n        Column name: {column_info['name']}\n        Catalog name: {column_info['catalog_name']}\n        Schema name: {column_info['schema_name']}\n        Table name: {column_info['table_name']}\n        Table type: {column_info['table_type']}\n        Lineage timestamp: {column_info['lineage_timestamp']}\n    \"\"\")\ncolumn_name = \"description\"\nresponse = requests.get(\n    f\"https://{WORKSPACE_NAME}.cloud.databricks.com/api/2.0/lineage-tracking/column-lineage\",\n    headers={\n        \"Authorization\": f\"Bearer {API_TOKEN}\"\n    },\n    json={\n        \"table_name\": FULLY_QUALIFIED_TABLE_NAME,\n        \"column_name\": column_name\n    }\n)\nif response.status_code == 200:\n    if \"upstream_cols\" in response.json():\n        print(\"| Upstream cols:\")\n        for column_info in response.json()['upstream_cols']:\n            print_column_info(\"Upstream\", column_info)\n    if \"downstream_cols\" in response.json():\n        print(\"| Downstream cols:\")\n        for column_info in response.json()['downstream_cols']:\n            print_column_info(\"Downstream\", column_info)\n```", "```py\nimport dlt\n@dlt.table(\n    name=\"commercial_airliner_flights_bronze\",\n    comment=\"The commercial airliner flight data dataset located in `/databricks-datasets/`\"\n)\ndef commercial_airliner_flights_bronze():\n    path = \"/databricks-datasets/airlines/\"\n    return (spark.readStream\n            .format(\"csv\")\n            .schema(schema)\n            .option(\"header\", True)\n            .load(path))\n```", "```py\ncommercial_airliners = [\n    (\"Airbus A220\", \"Canada\", 2, 2013, 2016, 287, 287, 5790),\n    (\"Airbus A330neo\", \"Multinational\", 2, 2017, 2018, 123,\n     123, 36744 ),\n    (\"Airbus A350 XWB\", \"Multinational\", 2, 2013, 2014, 557,\n     556, 44000),\n    (\"Antonov An-148/An-158\", \"Ukraine\", 2, 2004, 2009, 37,\n     8, 98567 ),\n    (\"Boeing 737\", \"United States\", 2, 1967, 1968, 11513, 7649,\n     6875),\n    (\"Boeing 767\", \"United States\", 2, 1981, 1982, 1283, 764,\n     23980),\n    (\"Boeing 777\", \"United States\", 2, 1994, 1995, 1713, 1483,\n     47890),\n    (\"Boeing 787 Dreamliner\", \"United States\", 2, 2009, 2011,\n     1072, 1069, 33340),\n    (\"Embraer E-Jet family\", \"Brazil\", 2, 2002, 2004, 1671,\n     1443, 3071),\n    (\"Embraer E-Jet E2 family\", \"Brazil\", 2, 2016, 2018, 81,\n     23, 3071)\n]\ncommercial_airliners_schema = \"jet_model string, Country_of_Origin string, Engines int, First_Flight int, Airline_Service_Entry int, Number_Built int, Currently_In_Service int, Fuel_Capacity int\"\nairliners_df = spark.createDataFrame(\n    data=commercial_airpliners,\n    schema=commercial_airliners_schema\n)\n```", "```py\nairliners_table_name = f\"{catalog_name}.{schema_name}.{table_name}\"\n(airliners_df.write\n    .format(\"delta\")\n    .mode(\"overwrite\")\n    .option(\"mergeSchema\", True)\n    .saveAsTable(airliners_table_name))\n```", "```py\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.functions import udf\n@udf(returnType=StringType())\ndef generate_jet_model():\n    import random\n    commercial_jets = [\n        \"Airbus A220\",\n        \"Airbus A320\",\n        \"Airbus A330\",\n        \"Airbus A330neo\",\n        \"Airbus A350 XWB\",\n        \"Antonov An-148/An-158\",\n        \"Boeing 737\",\n        \"Boeing 767\",\n        \"Boeing 777\",\n        \"Boeing 787 Dreamliner\",\n        \"Comac ARJ21 Xiangfeng\",\n        \"Comac C919\",\n        \"Embraer E-Jet family\",\n        \"Embraer E-Jet E2 family\",\n        \"Ilyushin Il-96\",\n        \"Sukhoi Superjet SSJ100\",\n        \"Tupolev Tu-204/Tu-214\"\n    ]\n    random_index = random.randint(0, 16)\n    return commercial_jets[random_index]\n```", "```py\n@dlt.table(\n    name=\"commercial_airliner_flights_silver\",\n    comment=\"The commercial airliner flight data augmented with randomly generated jet model and used fuel amount.\"\n)\ndef commercial_airliner_flights_silver():\n    return (dlt.read_stream(\n            \"commercial_airliner_flights_bronze\")\n            .withColumn(\"jet_model\", generate_jet_model())\n            .join(spark.table(airliners_table_name),\n                  [\"jet_model\"], \"left\"))\n```", "```py\n# 3.1kg of CO2 is created for every 1kg of fuel used.\n# So we multiply the fuel mass above by 3.1 to estimate the CO2 emitted\n# Source: https://ecotree.green/en/calculate-flight-co2\n# 1 gallon of jet fuel weighs approximately 3.03907 kilograms\ndef calc_carbon_footprint(fuel_consumed_gallons):\n    return (fuel_consumed_gallons * 3.03907) * 3.1\n```", "```py\nSELECT *\n  FROM system.access.table_lineage\n  WHERE source_table_name LIKE '%commercial_airliners_silver%';\n```"]