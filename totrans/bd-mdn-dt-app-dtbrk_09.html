<html><head></head><body>
  <div id="_idContainer098">
   <h1 class="chapter-number" id="_idParaDest-176">
    <a id="_idTextAnchor222">
    </a>
    <span class="koboSpan" id="kobo.1.1">
     9
    </span>
   </h1>
   <h1 id="_idParaDest-177">
    <a id="_idTextAnchor223">
    </a>
    <span class="koboSpan" id="kobo.2.1">
     Leveraging Databricks Asset Bundles to Streamline Data Pipeline Deployment
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.3.1">
     This chapter explores a relatively new
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.4.1">
      continuous integration and continuous deployment
     </span>
    </strong>
    <span class="koboSpan" id="kobo.5.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.6.1">
      CI/CD
     </span>
    </strong>
    <span class="koboSpan" id="kobo.7.1">
     ) tool
    </span>
    <a id="_idIndexMarker523">
    </a>
    <span class="koboSpan" id="kobo.8.1">
     called
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.9.1">
      Databricks Asset Bundles
     </span>
    </strong>
    <span class="koboSpan" id="kobo.10.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.11.1">
      DABs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.12.1">
     ), which can be leveraged to
    </span>
    <a id="_idIndexMarker524">
    </a>
    <span class="koboSpan" id="kobo.13.1">
     streamline the development and deployment of data analytical projects across various Databricks workspaces.
    </span>
    <span class="koboSpan" id="kobo.13.2">
     In this chapter, we’ll dive into the core concept of
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.14.1">
      DABs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.15.1">
     .
    </span>
    <span class="koboSpan" id="kobo.15.2">
     We’ll demonstrate the practical use of DABs through several hands-on exercises so that you feel comfortable developing your next data analytics projects as a DAB.
    </span>
    <span class="koboSpan" id="kobo.15.3">
     Lastly, we’ll cover how DABs can be used to increase cross-team collaboration
    </span>
    <a id="_idIndexMarker525">
    </a>
    <span class="koboSpan" id="kobo.16.1">
     through version control systems such as GitHub, and how DABs can be used to simplify even the most complex data
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.17.1">
      analytical deployments.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.18.1">
     In this chapter, we’re going to cover the following
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.19.1">
      main topics:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.20.1">
      Introduction to Databricks
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.21.1">
       Asset Bundles
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.22.1">
      Databricks Asset Bundles
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.23.1">
       in action
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.24.1">
      Simplifying
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.25.1">
       cross-team collaboration
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.26.1">
      Versioning
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.27.1">
       and maintenance
      </span>
     </span>
    </li>
   </ul>
   <h1 id="_idParaDest-178">
    <a id="_idTextAnchor224">
    </a>
    <span class="koboSpan" id="kobo.28.1">
     Technical requirements
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.29.1">
     To follow the examples in this chapter, it’s recommended that you have Databricks workspace administrative privileges so that you can deploy DABs to target workspaces.
    </span>
    <span class="koboSpan" id="kobo.29.2">
     You’ll also need to download and install version 0.218.0 or higher of the Databricks CLI.
    </span>
    <span class="koboSpan" id="kobo.29.3">
     All the code samples can be downloaded from this chapter’s GitHub repository at
    </span>
    <a href="https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter09">
     <span class="koboSpan" id="kobo.30.1">
      https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter09
     </span>
    </a>
    <span class="koboSpan" id="kobo.31.1">
     .
    </span>
    <span class="koboSpan" id="kobo.31.2">
     In this chapter, we will deploy several new workflows, DLT pipelines, notebooks, and clusters.
    </span>
    <span class="koboSpan" id="kobo.31.3">
     It’s estimated that this will consume around 5-10
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.32.1">
      Databricks
     </span>
    </strong>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.33.1">
       Units
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.34.1">
      (
     </span>
    </span>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.35.1">
       DBUs
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.36.1">
      ).
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-179">
    <a id="_idTextAnchor225">
    </a>
    <span class="koboSpan" id="kobo.37.1">
     Introduction to Databricks Asset Bundles
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.38.1">
     DABs provide an easy
    </span>
    <a id="_idIndexMarker526">
    </a>
    <span class="koboSpan" id="kobo.39.1">
     and convenient way to develop your
    </span>
    <a id="_idIndexMarker527">
    </a>
    <span class="koboSpan" id="kobo.40.1">
     data and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.41.1">
      artificial intelligence
     </span>
    </strong>
    <span class="koboSpan" id="kobo.42.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.43.1">
      AI
     </span>
    </strong>
    <span class="koboSpan" id="kobo.44.1">
     ) projects together with YAML metadata for declaring the infrastructure that goes along with it – just like a bundle.
    </span>
    <span class="koboSpan" id="kobo.44.2">
     DABs provide data engineers with a way to programmatically validate, deploy, and test Databricks resources in target workspaces.
    </span>
    <span class="koboSpan" id="kobo.44.3">
     This may include deploying workspace assets such
    </span>
    <a id="_idIndexMarker528">
    </a>
    <span class="koboSpan" id="kobo.45.1">
     as
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.46.1">
      Delta Live Tables
     </span>
    </strong>
    <span class="koboSpan" id="kobo.47.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.48.1">
      DLT
     </span>
    </strong>
    <span class="koboSpan" id="kobo.49.1">
     ) pipelines, workflows, notebooks, and more.
    </span>
    <span class="koboSpan" id="kobo.49.2">
     DABs also provide a convenient way to develop, package, and deploy machine learning workloads using reusable templates (we’ll cover DAB templates later in the
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.50.1">
      Initializing an asset bundle using templates
     </span>
    </em>
    <span class="koboSpan" id="kobo.51.1">
     section), called
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.52.1">
      MLOps Stacks.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.53.1">
     DABs were designed around the principles
    </span>
    <a id="_idIndexMarker529">
    </a>
    <span class="koboSpan" id="kobo.54.1">
     of expressing
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.55.1">
      Infrastructure as Code
     </span>
    </strong>
    <span class="koboSpan" id="kobo.56.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.57.1">
      IaC
     </span>
    </strong>
    <span class="koboSpan" id="kobo.58.1">
     ) and benefit from using configuration to drive the deployment of architectural components of your data applications.
    </span>
    <span class="koboSpan" id="kobo.58.2">
     DABs provide a way to check in IaC configuration along with data assets such as Python files, Notebooks, and other dependencies.
    </span>
    <span class="koboSpan" id="kobo.58.3">
     DABs can also be an alternative if you feel Terraform (covered in
    </span>
    <a href="B22011_08.xhtml#_idTextAnchor185">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.59.1">
        Chapter 8
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.60.1">
     ) is too advanced for your organization’s needs within the context of the Databricks Data
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.61.1">
      Intelligence Platform.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.62.1">
     DABs share some similarities with Terraform in that both are IaC tools that give users the ability to define cloud resources and deploy those resources in a cloud-agnostic manner.
    </span>
    <span class="koboSpan" id="kobo.62.2">
     However, there are many differences as well.
    </span>
    <span class="koboSpan" id="kobo.62.3">
     Let’s compare a few of the similarities and differences between DABs and Terraform to get a better feeling of when to choose which tool over the other for your
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.63.1">
      organization’s needs:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer092">
     <span class="koboSpan" id="kobo.64.1">
      <img alt="Figure 9.1 – DABs and Terraform are both IaC tools, but they meet very different needs" src="image/B22011_09_001.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.65.1">
     Figure 9.1 – DABs and Terraform are both IaC tools, but they meet very different needs
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.66.1">
     Before we start
    </span>
    <a id="_idIndexMarker530">
    </a>
    <span class="koboSpan" id="kobo.67.1">
     writing our very first DAB, let’s spend some time getting to know the major building blocks of what makes up a DAB
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.68.1">
      configuration file.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-180">
    <a id="_idTextAnchor226">
    </a>
    <span class="koboSpan" id="kobo.69.1">
     Elements of a DAB configuration file
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.70.1">
     At the center of
    </span>
    <a id="_idIndexMarker531">
    </a>
    <span class="koboSpan" id="kobo.71.1">
     a DAB is a YAML configuration file, named
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.72.1">
      databricks.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.73.1">
     .
    </span>
    <span class="koboSpan" id="kobo.73.2">
     This configuration file provides engineers with an entry point for configuring the deployment of their project’s resources.
    </span>
    <span class="koboSpan" id="kobo.73.3">
     The file consists of many composable building blocks that tell the Databricks
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.74.1">
      command-line interface
     </span>
    </strong>
    <span class="koboSpan" id="kobo.75.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.76.1">
      CLI
     </span>
    </strong>
    <span class="koboSpan" id="kobo.77.1">
     ) what to
    </span>
    <a id="_idIndexMarker532">
    </a>
    <span class="koboSpan" id="kobo.78.1">
     deploy to a target Databricks workspace and how to configure each resource.
    </span>
    <span class="koboSpan" id="kobo.78.2">
     Each building block accepts different parameters for configuring
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.79.1">
      that component.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.80.1">
     Later in this chapter, we’ll cover how to decompose the configuration file into many YAML files, but for simplicity’s sake, we’ll start with a single YAML file.
    </span>
    <span class="koboSpan" id="kobo.80.2">
     Within this YAML configuration file, we’ll declare our Databricks resources, as well as other metadata.
    </span>
    <span class="koboSpan" id="kobo.80.3">
     These building blocks, or
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.81.1">
      mappings
     </span>
    </strong>
    <span class="koboSpan" id="kobo.82.1">
     , tell
    </span>
    <a id="_idIndexMarker533">
    </a>
    <span class="koboSpan" id="kobo.83.1">
     the DAB tool what Databricks resource to create, and more importantly, what Databricks REST API to manipulate to create and configure a Databricks
    </span>
    <a id="_idIndexMarker534">
    </a>
    <span class="koboSpan" id="kobo.84.1">
     resource.
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.85.1">
     These mappings can be a variety of Databricks resources.
    </span>
    <span class="koboSpan" id="kobo.85.2">
     For example, a DAB configuration file can contain any combination of the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.86.1">
      following mappings:
     </span>
    </span>
   </p>
   <table class="No-Table-Style _idGenTablePara-1" id="table001-6">
    <colgroup>
     <col/>
     <col/>
     <col/>
    </colgroup>
    <tbody>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="bold">
          <span class="koboSpan" id="kobo.87.1">
           Mapping Name
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="bold">
          <span class="koboSpan" id="kobo.88.1">
           Required?
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="bold">
          <span class="koboSpan" id="kobo.89.1">
           Description
          </span>
         </strong>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.90.1">
           bundle
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.91.1">
          Yes
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.92.1">
         Contains top-level information about the current asset bundle, including the Databricks CLI version, existing cluster identifier, and
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.93.1">
          git settings.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.94.1">
           variables
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.95.1">
          No
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.96.1">
         Contains global variables that will be dynamically populated during the execution of a
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.97.1">
          DAB deployment.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.98.1">
           workspace
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.99.1">
          No
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.100.1">
         Used to specify non-default workspace locations, such as the root storage, artifact storage, and
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.101.1">
          file paths.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.102.1">
           permissions
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.103.1">
          No
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.104.1">
         Contains information about what permissions to grant to the
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.105.1">
          deployed resources.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.106.1">
           resources
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.107.1">
          Yes
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.108.1">
         Specifies what Databricks resources to deploy and how to
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.109.1">
          configure them.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.110.1">
           artifacts
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.111.1">
          No
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.112.1">
         Specifies deployment artifacts, such as Python
        </span>
        <strong class="source-inline">
         <span class="koboSpan" id="kobo.113.1">
          .whl
         </span>
        </strong>
        <span class="koboSpan" id="kobo.114.1">
         files, that will be generated during the
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.115.1">
          deployment process.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.116.1">
           include
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.117.1">
          No
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.118.1">
         Specifies a list of relative file path globs to additional configuration files.
        </span>
        <span class="koboSpan" id="kobo.118.2">
         This is a great way to separate a DAB configuration file into several child
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.119.1">
          configuration files.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.120.1">
           sync
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.121.1">
          No
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.122.1">
         Specifies a list of relative file path globs to include or exclude in the
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.123.1">
          deployment process.
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="source-inline">
          <span class="koboSpan" id="kobo.124.1">
           targets
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.125.1">
          Yes
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.126.1">
         Specifies information about the context in addition to the Databricks workspace and details about the workflow, pipeline,
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.127.1">
          and artifacts.
         </span>
        </span>
       </p>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.128.1">
     Table 9.1 – Mappings in a databricks.yml file
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.129.1">
     Let’s look at a simple DAB configuration file so that we’re familiar with some of the basics.
    </span>
    <span class="koboSpan" id="kobo.129.2">
     The following
    </span>
    <a id="_idIndexMarker535">
    </a>
    <span class="koboSpan" id="kobo.130.1">
     example will create a new Databricks workflow called
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.131.1">
      Hello, World!
     </span>
    </strong>
    <span class="koboSpan" id="kobo.132.1">
     that will run a notebook that prints the simple yet popular expression
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.133.1">
       Hello, World!
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.134.1">
      :
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.135.1">
bundle:
  name: hello_dab_world
resources:
  jobs:
    hello_dab_world_job:
      name: hello_dab_world_job
      tasks:
        - task_key: notebook_task
          existing_cluster_id: &lt;cluster_id&gt;
          notebook_task:
            notebook_path: ./src/hello_dab_world.py
targets:
  dev:
    default: true
    workspace:
      host: https://&lt;workspace_name&gt;.cloud.databricks.com</span></pre>
   <p>
    <span class="koboSpan" id="kobo.136.1">
     In this simple example, our DAB configuration file consists of three
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.137.1">
      main sections:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.138.1">
       bundle
      </span>
     </strong>
     <span class="koboSpan" id="kobo.139.1">
      : This section contains high-level information about the current DAB – in this case,
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.140.1">
       its name.
      </span>
     </span>
    </li>
    <li>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.141.1">
       resources
      </span>
     </strong>
     <span class="koboSpan" id="kobo.142.1">
      : This defines a new Databricks workflow with a single notebook task that should be run on an
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.143.1">
       existing cluster.
      </span>
     </span>
    </li>
    <li>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.144.1">
       targets
      </span>
     </strong>
     <span class="koboSpan" id="kobo.145.1">
      : This specifies information about the target Databricks workspace the workflow and notebook should be
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.146.1">
       deployed to.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.147.1">
     Now that we have a
    </span>
    <a id="_idIndexMarker536">
    </a>
    <span class="koboSpan" id="kobo.148.1">
     strong understanding of the basics of a DAB configuration file, let’s look at how we can deploy our Databricks resources under different
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.149.1">
      deployment scenarios.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-181">
    <a id="_idTextAnchor227">
    </a>
    <span class="koboSpan" id="kobo.150.1">
     Specifying a deployment mode
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.151.1">
     One attribute that’s
    </span>
    <a id="_idIndexMarker537">
    </a>
    <span class="koboSpan" id="kobo.152.1">
     available
    </span>
    <a id="_idIndexMarker538">
    </a>
    <span class="koboSpan" id="kobo.153.1">
     from within a DAB configuration file is a deployment mode, which allows us to specify an operating mode when we’re deploying resources.
    </span>
    <span class="koboSpan" id="kobo.153.2">
     There are two types of deployment modes available: development
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.154.1">
      and production.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.155.1">
     In
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.156.1">
      development
     </span>
    </em>
    <span class="koboSpan" id="kobo.157.1">
     mode, all resources are marked with a special prefix,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.158.1">
      [dev &lt;username&gt;]
     </span>
    </strong>
    <span class="koboSpan" id="kobo.159.1">
     , to indicate that the resources are in development.
    </span>
    <span class="koboSpan" id="kobo.159.2">
     Furthermore, all resources, when available, are deployed with the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.160.1">
      dev
     </span>
    </strong>
    <span class="koboSpan" id="kobo.161.1">
     metadata tag, to also indicate that the resources are in development.
    </span>
    <span class="koboSpan" id="kobo.161.2">
     As you may recall from
    </span>
    <a href="B22011_02.xhtml#_idTextAnchor052">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.162.1">
        Chapter 2
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.163.1">
     , DLT also has a development mode available.
    </span>
    <span class="koboSpan" id="kobo.163.2">
     When DLT pipelines are deployed using DABs in development mode, all deployed DLT pipelines will be deployed to the target workspace with this development
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.164.1">
      mode enabled.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.165.1">
     During the development life cycle, it’s also expected that engineers will want to experiment with changes and quickly iterate on design changes.
    </span>
    <span class="koboSpan" id="kobo.165.2">
     As a result, development mode will also pause all Databricks workflow schedules and enable concurrent runs of the same workflow, allowing engineers to run the workflow in an ad hoc fashion directly from the Databricks CLI.
    </span>
    <span class="koboSpan" id="kobo.165.3">
     Similarly, development mode gives you the option to specify an existing all-purpose cluster to use for the deployment process, either by specifying the cluster ID as an argument from the Databricks CLI via
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.166.1">
      --
     </span>
    </strong>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.167.1">
      compute-id &lt;cluster_id&gt;
     </span>
    </strong>
    <span class="koboSpan" id="kobo.168.1">
     or by adding the cluster ID to the top-level
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.169.1">
      bundle
     </span>
    </strong>
    <span class="koboSpan" id="kobo.170.1">
     mapping of the YAML
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.171.1">
      configuration file.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.172.1">
     Let’s look at how we might be able to specify a target workspace so that it can be used as a development environment and override all clusters with a default, existing
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.173.1">
      all-purpose cluster:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.174.1">
targets:
  dev:
    default: true
    mode: development
    compute_id: &lt;cluster_id&gt;
    workspace:
      host: https://&lt;workspace_name&gt;.cloud.databricks.com</span></pre>
   <p>
    <span class="koboSpan" id="kobo.175.1">
     Conversely, you can also specify a production mode.
    </span>
    <span class="koboSpan" id="kobo.175.2">
     In
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.176.1">
      production
     </span>
    </em>
    <span class="koboSpan" id="kobo.177.1">
     mode, resources won’t be prepended with a special naming prefix and no tags will be applied.
    </span>
    <span class="koboSpan" id="kobo.177.2">
     However, production mode will validate the resources before they’re deployed to the target workspace.
    </span>
    <span class="koboSpan" id="kobo.177.3">
     For example, it will be ensured that all DLT pipelines have been set to production mode and resources that specify cloud storage locations or workspace paths don’t point
    </span>
    <a id="_idIndexMarker539">
    </a>
    <span class="koboSpan" id="kobo.178.1">
     to
    </span>
    <a id="_idIndexMarker540">
    </a>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.179.1">
      user-specific locations.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.180.1">
     In the next section, we’ll roll up our sleeves and dive into using the Databricks CLI to experiment with asset bundles and see them
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.181.1">
      in action.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-182">
    <a id="_idTextAnchor228">
    </a>
    <span class="koboSpan" id="kobo.182.1">
     Databricks Asset Bundles in action
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.183.1">
     DABs depend entirely
    </span>
    <a id="_idIndexMarker541">
    </a>
    <span class="koboSpan" id="kobo.184.1">
     on the Databricks CLI tool (see
    </span>
    <a href="B22011_08.xhtml#_idTextAnchor185">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.185.1">
        Chapter 8
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.186.1">
     for installation instructions) to create new bundles from templates, deploy bundles to target workspaces, and even remove previously deployed resource bundles from workspaces.
    </span>
    <span class="koboSpan" id="kobo.186.2">
     For this section, you’ll need version 0.218.0 or higher of the Databricks CLI.
    </span>
    <span class="koboSpan" id="kobo.186.3">
     You can quickly check the version of your local Databricks CLI by passing the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.187.1">
      --
     </span>
    </strong>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.188.1">
       version
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.189.1">
      argument:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.190.1">
databricks –-version</span></pre>
   <p>
    <span class="koboSpan" id="kobo.191.1">
     You should get a similar output as shown in the following
    </span>
    <span class="No-Break">
     <em class="italic">
      <span class="koboSpan" id="kobo.192.1">
       Figure 9
      </span>
     </em>
    </span>
    <span class="No-Break">
     <em class="italic">
      <span class="koboSpan" id="kobo.193.1">
       .2
      </span>
     </em>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.194.1">
      :
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer093">
     <span class="koboSpan" id="kobo.195.1">
      <img alt="Figure 9.﻿2 - Checking the version of a previously installed Databricks CLI" src="image/B22011_09_002.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.196.1">
     Figure 9.2 - Checking the version of a previously installed Databricks CLI
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.197.1">
     Once you’ve successfully installed the recommended version of the Databricks CLI, you can test that the installation was successful by displaying the manual page for the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.198.1">
      bundle
     </span>
    </strong>
    <span class="koboSpan" id="kobo.199.1">
     command.
    </span>
    <span class="koboSpan" id="kobo.199.2">
     Enter the following command to display the available arguments and descriptions from
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.200.1">
      the CLI:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.201.1">
$ databricks bundle --help</span></pre>
   <p>
    <span class="koboSpan" id="kobo.202.1">
     We’ll get the following
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.203.1">
      manual page:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer094">
     <span class="koboSpan" id="kobo.204.1">
      <img alt="Figure 9.﻿3 – The manual page for the bundle command in the Databricks CLI" src="image/B22011_09_003.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.205.1">
     Figure 9.3 – The manual page for the bundle command in the Databricks CLI
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.206.1">
     Before we can begin authoring DABs and deploying resources to Databricks workspaces, we will nee
    </span>
    <a id="_idTextAnchor229">
    </a>
    <span class="koboSpan" id="kobo.207.1">
     d
    </span>
    <a id="_idTextAnchor230">
    </a>
    <span class="koboSpan" id="kobo.208.1">
     to authenticate with the target Databricks workspaces so that we can deploy resources.
    </span>
    <span class="koboSpan" id="kobo.208.2">
     DABs
    </span>
    <a id="_idIndexMarker542">
    </a>
    <span class="koboSpan" id="kobo.209.1">
     leverage OAuth toke
    </span>
    <a id="_idTextAnchor231">
    </a>
    <span class="koboSpan" id="kobo.210.1">
     ns to authenticate with Databricks workspaces.
    </span>
    <span class="koboSpan" id="kobo.210.2">
     Two types of OAuth authentication can be used with DABs –
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.211.1">
      user-to-machine
     </span>
    </strong>
    <span class="koboSpan" id="kobo.212.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.213.1">
      U2M
     </span>
    </strong>
    <span class="koboSpan" id="kobo.214.1">
     ) authentication and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.215.1">
      machine-to-machine
     </span>
    </strong>
    <span class="koboSpan" id="kobo.216.1">
     (
    </span>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.217.1">
       M2M
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.218.1">
      ) authentication.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-183">
    <a id="_idTextAnchor232">
    </a>
    <span class="koboSpan" id="kobo.219.1">
     User-to-machine authentication
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.220.1">
     U2M authentication
    </span>
    <a id="_idIndexMarker543">
    </a>
    <span class="koboSpan" id="kobo.221.1">
     involves
    </span>
    <a id="_idIndexMarker544">
    </a>
    <span class="koboSpan" id="kobo.222.1">
     a human in the loop generating an OAuth token that can be used when you’re deploying new resources to a target workspace.
    </span>
    <span class="koboSpan" id="kobo.222.2">
     This type of authentication involves a user who will log in via a web browser when prompted by the CLI tool.
    </span>
    <span class="koboSpan" id="kobo.222.3">
     This type of authentication is good for development scenarios where users want to experiment with DABs and deploy resources in non-critical
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.223.1">
      development workspaces.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.224.1">
     U2M is the easiest way to authenticate with your Databricks workspace and can be done directly from the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.225.1">
      Databricks CLI:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.226.1">
$ databricks auth login --host &lt;workspace-url&gt;</span></pre>
   <p>
    <span class="koboSpan" id="kobo.227.1">
     Workspace information such as the workspace’s URL, nickname, and authentication details are stored in a hidden file under your user directory on your local machine.
    </span>
    <span class="koboSpan" id="kobo.227.2">
     For example, on Mac and Linux systems, this information will be written to a local
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.228.1">
      ~/.databrickscfg
     </span>
    </strong>
    <span class="koboSpan" id="kobo.229.1">
     file under the user’s
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.230.1">
      home directory:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer095">
     <span class="koboSpan" id="kobo.231.1">
      <img alt="Figure 9.﻿4 – Example of multiple Databricks profiles saved to a local configuration file" src="image/B22011_09_004.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.232.1">
     Figure 9.4 – Example of multiple Databricks profiles saved to a local configuration file
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.233.1">
     You can quickly switch
    </span>
    <a id="_idIndexMarker545">
    </a>
    <span class="koboSpan" id="kobo.234.1">
     between
    </span>
    <a id="_idIndexMarker546">
    </a>
    <span class="koboSpan" id="kobo.235.1">
     different Databricks workspaces by passing the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.236.1">
      --profile &lt;profile_nickname&gt;
     </span>
    </strong>
    <span class="koboSpan" id="kobo.237.1">
     argument using CLI commands.
    </span>
    <span class="koboSpan" id="kobo.237.2">
     For example, the following command will apply a DAB to a workspace saved under the
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.238.1">
       TEST_ENV
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.239.1">
      profile:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.240.1">
$ databricks bundle deploy –-profile TEST_ENV</span></pre>
   <p>
    <span class="koboSpan" id="kobo.241.1">
     U2M authentication was designed strictly for development purposes.
    </span>
    <span class="koboSpan" id="kobo.241.2">
     For production scenarios, this type of authentication is not recommended as it can’t be automated and doesn’t restrict access to the least set of privileges necessary.
    </span>
    <span class="koboSpan" id="kobo.241.3">
     In these cases, M2M authentication
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.242.1">
      is recommended.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.243.1">
     Let’s take a look at this alternative authentication type for when you’re automating your DAB deployment
    </span>
    <a id="_idIndexMarker547">
    </a>
    <span class="koboSpan" id="kobo.244.1">
     in
    </span>
    <a id="_idIndexMarker548">
    </a>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.245.1">
      production scenarios.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-184">
    <a id="_idTextAnchor233">
    </a>
    <span class="koboSpan" id="kobo.246.1">
     Machine-to-machine authentication
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.247.1">
     M2M authentication
    </span>
    <a id="_idIndexMarker549">
    </a>
    <span class="koboSpan" id="kobo.248.1">
     doesn’t
    </span>
    <a id="_idIndexMarker550">
    </a>
    <span class="koboSpan" id="kobo.249.1">
     involve a human, per se.
    </span>
    <span class="koboSpan" id="kobo.249.2">
     This type of authentication was designed for fully automated CI/CD workflows.
    </span>
    <span class="koboSpan" id="kobo.249.3">
     Furthermore, this type of authentication pairs well with version control systems such as GitHub, Bitbucket, and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.250.1">
      Azure DevOps.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.251.1">
     M2M requires the us
    </span>
    <a id="_idTextAnchor234">
    </a>
    <span class="koboSpan" id="kobo.252.1">
     e of service principals to abstract the generation of OAuth tokens.
    </span>
    <span class="koboSpan" id="kobo.252.2">
     Furthermore, service principals give automated tools and scripts API-only access to Databricks resources, providing greater security than using users or groups.
    </span>
    <span class="koboSpan" id="kobo.252.3">
     For this reason, service principals are an ideal scenario for
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.253.1">
      production environments.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.254.1">
     M2M requires a Databricks account admin to crea
    </span>
    <a id="_idTextAnchor235">
    </a>
    <span class="koboSpan" id="kobo.255.1">
     te a service principal and generate an OAuth token from the Databricks account console.
    </span>
    <span class="koboSpan" id="kobo.255.2">
     Once an OAuth token has been generated under the service principal’s identity, the token can be used to populate environment variables such as
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.256.1">
      DATABRICKS_HOST
     </span>
    </strong>
    <span class="koboSpan" id="kobo.257.1">
     ,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.258.1">
      DATABRICKS_CLIENT_ID
     </span>
    </strong>
    <span class="koboSpan" id="kobo.259.1">
     , and
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.260.1">
      DATABRICKS_CLIENT_SECRET
     </span>
    </strong>
    <span class="koboSpan" id="kobo.261.1">
     , which are used in automated build and deployment tools such as GitHub Actions or
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.262.1">
      Azure DevOps.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-185">
    <a id="_idTextAnchor236">
    </a>
    <span class="koboSpan" id="kobo.263.1">
     Initializing an asset bundle using templates
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.264.1">
     DABs also come with
    </span>
    <a id="_idIndexMarker551">
    </a>
    <span class="koboSpan" id="kobo.265.1">
     project
    </span>
    <a id="_idIndexMarker552">
    </a>
    <span class="koboSpan" id="kobo.266.1">
     templates, which allow developers to quickly create a new bundle using predefined settings.
    </span>
    <span class="koboSpan" id="kobo.266.2">
     DAB templates contain predefined artifacts and settings for commonly deployed Databricks projects.
    </span>
    <span class="koboSpan" id="kobo.266.3">
     For example, the following command will initialize a local
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.267.1">
      DAB project:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.268.1">
$ databricks bundle init</span></pre>
   <p>
    <span class="koboSpan" id="kobo.269.1">
     From the CLI, the user is prompted to choose a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.270.1">
      DAB template:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer096">
     <span class="koboSpan" id="kobo.271.1">
      <img alt="Figure 9.﻿5 – Initializing a new DAB project using templates from the Databricks CLI" src="image/B22011_09_005.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.272.1">
     Figure 9.5 – Initializing a new DAB project using templates from the Databricks CLI
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.273.1">
     At the time of writing, DABs come with four templates to choose from:
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.274.1">
      default-python
     </span>
    </strong>
    <span class="koboSpan" id="kobo.275.1">
     ,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.276.1">
      default-sql
     </span>
    </strong>
    <span class="koboSpan" id="kobo.277.1">
     ,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.278.1">
      dbt-sql
     </span>
    </strong>
    <span class="koboSpan" id="kobo.279.1">
     , and
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.280.1">
      mlops-stacks
     </span>
    </strong>
    <span class="koboSpan" id="kobo.281.1">
     (
    </span>
    <a href="https://docs.databricks.com/en/dev-tools/bundles/templates.html">
     <span class="koboSpan" id="kobo.282.1">
      https://docs.databricks.com/en/dev-tools/bundles/templates.html
     </span>
    </a>
    <span class="koboSpan" id="kobo.283.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.283.2">
     However, you also have the option to create organization templates and generate artifacts as a reusable
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.284.1">
      project bundle.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.285.1">
     Now that we have
    </span>
    <a id="_idIndexMarker553">
    </a>
    <span class="koboSpan" id="kobo.286.1">
     a good
    </span>
    <a id="_idIndexMarker554">
    </a>
    <span class="koboSpan" id="kobo.287.1">
     understanding of the basics of DABs, let’s put together everything that we’ve learned so far and deploy a few resources to a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.288.1">
      Databricks workspace.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-186">
    <a id="_idTextAnchor237">
    </a>
    <span class="koboSpan" id="kobo.289.1">
     Hands-on exercise – deploying your first DAB
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.290.1">
     In this hands-on
    </span>
    <a id="_idIndexMarker555">
    </a>
    <span class="koboSpan" id="kobo.291.1">
     exercise, we’re going to create a Python-based asset bundle and deploy a simple Databricks workflow that runs a DLT pipeline in a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.292.1">
      target workspace.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.293.1">
     Let’s begin by creating a local directory that we’ll be using to create the project scaffolding for our DAB.
    </span>
    <span class="koboSpan" id="kobo.293.2">
     For example, the following command will create a new directory under the user’s
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.294.1">
      home directory:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.295.1">
$ mkdir –p ~/chapter9/dabs/</span></pre>
   <p>
    <span class="koboSpan" id="kobo.296.1">
     Next, navigate to the newly created
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.297.1">
      project directory:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.298.1">
$ cd ~/chapter9/dabs</span></pre>
   <p>
    <span class="koboSpan" id="kobo.299.1">
     Generate a new OAuth token using U2M authentication by entering the following command and completing
    </span>
    <a id="_idIndexMarker556">
    </a>
    <span class="koboSpan" id="kobo.300.1">
     the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.301.1">
      single sign-on
     </span>
    </strong>
    <span class="koboSpan" id="kobo.302.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.303.1">
      SSO
     </span>
    </strong>
    <span class="koboSpan" id="kobo.304.1">
     ) login when you’re redirected to a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.305.1">
      browser window:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.306.1">
$ databricks auth login</span></pre>
   <p>
    <span class="koboSpan" id="kobo.307.1">
     Now that our directory has been created and we’ve authenticated with our target workspace, let’s use the Databricks CLI to initialize an empty DAB project.
    </span>
    <span class="koboSpan" id="kobo.307.2">
     Enter the following command to bring up the prompt for choosing a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.308.1">
      DAB template:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.309.1">
$ databricks bundle init</span></pre>
   <p>
    <span class="koboSpan" id="kobo.310.1">
     Next, choose
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.311.1">
      default-python
     </span>
    </strong>
    <span class="koboSpan" id="kobo.312.1">
     from the template chooser prompt.
    </span>
    <span class="koboSpan" id="kobo.312.2">
     Enter a meaningful name for your project, such as
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.313.1">
      my_first_dab
     </span>
    </strong>
    <span class="koboSpan" id="kobo.314.1">
     .
    </span>
    <span class="koboSpan" id="kobo.314.2">
     When prompted to select a notebook stub, select
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.315.1">
      No
     </span>
    </strong>
    <span class="koboSpan" id="kobo.316.1">
     .
    </span>
    <span class="koboSpan" id="kobo.316.2">
     Select
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.317.1">
      Yes
     </span>
    </strong>
    <span class="koboSpan" id="kobo.318.1">
     when you’re prompted to include a sample DLT pipeline.
    </span>
    <span class="koboSpan" id="kobo.318.2">
     Finally, select
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.319.1">
      No
     </span>
    </strong>
    <span class="koboSpan" id="kobo.320.1">
     when you’re prompted to add a sample Python library.
    </span>
    <span class="koboSpan" id="kobo.320.2">
     The project scaffolding will be created, at which point you can list the directory’s contents so that you can have
    </span>
    <a id="_idIndexMarker557">
    </a>
    <span class="koboSpan" id="kobo.321.1">
     a glance at the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.322.1">
      gene
     </span>
     <a id="_idTextAnchor238">
     </a>
     <span class="koboSpan" id="kobo.323.1">
      rated artifacts:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.324.1">
$ cd ./my_first_dab  # a new dir will be created
$ ls -la             # list the project artifacts</span></pre>
   <p>
    <span class="koboSpan" id="kobo.325.1">
     To navigate to the newly created project files more easily, open the project directory using your favorite code editor, such as
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.326.1">
      VS Code:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer097">
     <span class="koboSpan" id="kobo.327.1">
      <img alt="Figure 9.6 – Generated DAB project scaffolding using the default-python template, viewed from VS Code" src="image/B22011_09_006.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.328.1">
     Figure 9.6 – Generated DAB project scaffolding using the default-python template, viewed from VS Code
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.329.1">
     Go ahead and explore the subdirectories of the generated DAB project for yourself.
    </span>
    <span class="koboSpan" id="kobo.329.2">
     You should notice a couple of important directories
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.330.1">
      and files:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.331.1">
       src
      </span>
     </strong>
     <span class="koboSpan" id="kobo.332.1">
      : This directory contains the DLT pipeline definition as a
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.333.1">
       notebook file.
      </span>
     </span>
    </li>
    <li>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.334.1">
       resources
      </span>
     </strong>
     <span class="koboSpan" id="kobo.335.1">
      : DABs can be decomposed into multiple YAML files that pertain to a single resource or a subset of resources.
     </span>
     <span class="koboSpan" id="kobo.335.2">
      This directory contains the resource definitions for a DLT pipeline and a workflow definition for running the pipeline, including the schedule, notebook task definition, and job
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.336.1">
       cluster attributes.
      </span>
     </span>
    </li>
    <li>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.337.1">
       databricks.yml
      </span>
     </strong>
     <span class="koboSpan" id="kobo.338.1">
      : This is the main entry point and definition of our DAB.
     </span>
     <span class="koboSpan" id="kobo.338.2">
      This tells the Databricks CLI what resources to deploy and how to deploy them, and specifies target
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.339.1">
       workspace information.
      </span>
     </span>
    </li>
    <li>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.340.1">
       README.md
      </span>
     </strong>
     <span class="koboSpan" id="kobo.341.1">
      : This is the project README file and contains helpful information on the different sections of the project, as well as instructions on how to deploy or undeploy
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.342.1">
       the resources.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.343.1">
     Open the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.344.1">
      dlt_pipeline.ipynb
     </span>
    </strong>
    <span class="koboSpan" id="kobo.345.1">
     notebook contained under the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.346.1">
      src
     </span>
    </strong>
    <span class="koboSpan" id="kobo.347.1">
     directory.
    </span>
    <span class="koboSpan" id="kobo.347.2">
     Notice that the
    </span>
    <a id="_idIndexMarker558">
    </a>
    <span class="koboSpan" id="kobo.348.1">
     notebook defines two datasets – a view that reads raw, unprocessed JSON files from the NYC Taxi dataset and a table that filters the view based on rows with a
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.349.1">
      fare_amount
     </span>
    </strong>
    <span class="koboSpan" id="kobo.350.1">
     value of less
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.351.1">
      than 30.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.352.1">
     Next, open the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.353.1">
      databricks.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.354.1">
     file.
    </span>
    <span class="koboSpan" id="kobo.354.2">
     You’ll notice that this file has three main sections:
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.355.1">
      bundle
     </span>
    </strong>
    <span class="koboSpan" id="kobo.356.1">
     ,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.357.1">
      include
     </span>
    </strong>
    <span class="koboSpan" id="kobo.358.1">
     ,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.359.1">
      and
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.360.1">
       targets
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.361.1">
      .
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.362.1">
     For simplicity’s sake, under the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.363.1">
      targets
     </span>
    </strong>
    <span class="koboSpan" id="kobo.364.1">
     mapping, remove all sections except for the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.365.1">
      dev
     </span>
    </strong>
    <span class="koboSpan" id="kobo.366.1">
     section.
    </span>
    <span class="koboSpan" id="kobo.366.2">
     We’ll only be deploying to a development environment for
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.367.1">
      this exercise.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.368.1">
     Finally, ensure that the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.369.1">
      dev
     </span>
    </strong>
    <span class="koboSpan" id="kobo.370.1">
     target is pointing to the correct development workspace.
    </span>
    <span class="koboSpan" id="kobo.370.2">
     Your
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.371.1">
      databricks.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.372.1">
     file should look similar
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.373.1">
      to this:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.374.1">
bundle:
  name: my_first_dab
include:
  -resources/*.yml
targets:
  mode: development
  default: true
  workspace:
    host: http</span><a id="_idTextAnchor239"/><span class="koboSpan" id="kobo.375.1">s://&lt;workspace_name&gt;.cloud.databricks.com</span></pre>
   <p>
    <span class="koboSpan" id="kobo.376.1">
     Save the changes to the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.377.1">
      databricks.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.378.1">
     file and return to your Terminal window.
    </span>
    <span class="koboSpan" id="kobo.378.2">
     Let’s validate the changes to our DAB project by executing the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.379.1">
      validate
     </span>
    </strong>
    <span class="koboSpan" id="kobo.380.1">
     command from the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.381.1">
      Databricks CLI:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.382.1">
$ databricks bundle validate</span></pre>
   <p>
    <span class="koboSpan" id="kobo.383.1">
     Now that our project has been modified to our liking, it’s time to deploy the bundle to our development workspace.
    </span>
    <span class="koboSpan" id="kobo.383.2">
     Execute the following command from your
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.384.1">
      Databricks CLI:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.385.1">
$ databricks bundle deploy </span></pre>
   <p>
    <span class="koboSpan" id="kobo.386.1">
     The Databricks CLI will parse our DAB definition and deploy the resources to our development target.
    </span>
    <span class="koboSpan" id="kobo.386.2">
     Log in to the development workspace and verify that a new workflow titled
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.387.1">
      [dev &lt;username&gt;] my_first_dab_job
     </span>
    </strong>
    <span class="koboSpan" id="kobo.388.1">
     has been created and your Databricks user is listed as
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.389.1">
      the owner.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.390.1">
     Congratulations!
    </span>
    <span class="koboSpan" id="kobo.390.2">
     You’ve just created your first DAB and deployed it to a development workspace.
    </span>
    <span class="koboSpan" id="kobo.390.3">
     You’re well on your way to automating the deployment of data pipelines and other
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.391.1">
      Databricks resources.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.392.1">
     Let’s test that the
    </span>
    <a id="_idIndexMarker559">
    </a>
    <span class="koboSpan" id="kobo.393.1">
     deployment was successful by executing a new run of the deployed workflow.
    </span>
    <span class="koboSpan" id="kobo.393.2">
     From the same Databricks CLI, enter the following command.
    </span>
    <span class="koboSpan" id="kobo.393.3">
     This will start an execution run of the newly created workflow and trigger an update of the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.394.1">
      DLT pipeline:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.395.1">
$ databricks bundle run</span></pre>
   <p>
    <span class="koboSpan" id="kobo.396.1">
     You may be prompted to select which resource to run.
    </span>
    <span class="koboSpan" id="kobo.396.2">
     For this, select
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.397.1">
      my_first_dab_job
     </span>
    </strong>
    <span class="koboSpan" id="kobo.398.1">
     .
    </span>
    <span class="koboSpan" id="kobo.398.2">
     If success
    </span>
    <a id="_idTextAnchor240">
    </a>
    <span class="koboSpan" id="kobo.399.1">
     ful, you should see a confirmation message from the CLI that the workflow is currently running.
    </span>
    <span class="koboSpan" id="kobo.399.2">
     Return to your Databricks workspace and verify that an execution run has indeed
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.400.1">
      been started.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.401.1">
     There may be certain scenarios where you need to undeploy resources from a target workspace.
    </span>
    <span class="koboSpan" id="kobo.401.2">
     To undeploy the workflow and DLT pipeline definitions that were created earlier, we can use the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.402.1">
      destroy
     </span>
    </strong>
    <span class="koboSpan" id="kobo.403.1">
     command in the Databricks CLI.
    </span>
    <span class="koboSpan" id="kobo.403.2">
     Enter the following command to revert all changes that were created in this hands-on exercise.
    </span>
    <span class="koboSpan" id="kobo.403.3">
     You’ll need to confirm that you would like to permanently delete
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.404.1">
      all resources:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.405.1">
$ databricks bundle destroy</span></pre>
   <p>
    <span class="koboSpan" id="kobo.406.1">
     So far, we’ve created a simple workflow and DLT pipeline defined in a source notebook in a target Databricks workspace.
    </span>
    <span class="koboSpan" id="kobo.406.2">
     We’ve used a local code editor to author the DAB project and deployed the changes from our local machine.
    </span>
    <span class="koboSpan" id="kobo.406.3">
     However, in production scenarios, you’ll be collaborating with teams within your organization to author data pipelines and other Databricks resources that all work together to generate data products for
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.407.1">
      your organization.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.408.1">
     In the next section, we’ll look at how we expand upon this simple exercise and work with team
    </span>
    <a id="_idIndexMarker560">
    </a>
    <span class="koboSpan" id="kobo.409.1">
     members to deploy Databricks resources such as workflows, notebooks, or DLT pipelines using
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.410.1">
      automation tools.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-187">
    <a id="_idTextAnchor241">
    </a>
    <span class="koboSpan" id="kobo.411.1">
     Hands-on exercise – simplifying cross-team collaboration with GitHub Actions
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.412.1">
     Often, you’ll be
    </span>
    <a id="_idIndexMarker561">
    </a>
    <span class="koboSpan" id="kobo.413.1">
     working across a team of data engineers working to deploy Databricks assets such as DLT pipelines, all-purpose clusters, or workflows, to name a few.
    </span>
    <span class="koboSpan" id="kobo.413.2">
     In these scenarios, you’ll likely be using a version control system such as GitHub, Bitbucket, or Azure DevOps to collaborate with members of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.414.1">
      a team.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.415.1">
     DABs can be easily incorporated into your CI/CD pipelines.
    </span>
    <span class="koboSpan" id="kobo.415.2">
     Let’s look at how we can use GitHub Actions to automatically deploy changes made to our main branch of the code repository and automatically deploy the resource changes to our production
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.416.1">
      Databricks workspace.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.417.1">
     GitHub Actions is a feature in GitHub that allows users to implement a CI/CD workflow directly from a GitHub repository, making it simple to declare a workflow of actions to perform based on some triggering event, such as merging a feature branch into a master branch.
    </span>
    <span class="koboSpan" id="kobo.417.2">
     Together with DABs, we can implement a robust, fully automated CI/CD pipeline that deploys changes that have been made to our Databricks code base.
    </span>
    <span class="koboSpan" id="kobo.417.3">
     This enables our teams to be more agile, deploying changes as soon as they are available, allowing them to speed up the iterative development life cycle and quickly
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.418.1">
      test changes.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-188">
    <a id="_idTextAnchor242">
    </a>
    <span class="koboSpan" id="kobo.419.1">
     Setting up the environment
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.420.1">
     In this hands-on
    </span>
    <a id="_idIndexMarker562">
    </a>
    <span class="koboSpan" id="kobo.421.1">
     exercise, we’ll be creating a GitHub Action to automatically deploy changes to our Databricks workspace as soon as a branch is merged in our GitHub repository.
    </span>
    <span class="koboSpan" id="kobo.421.2">
     Let’s return to the example from earlier in this chapter.
    </span>
    <span class="koboSpan" id="kobo.421.3">
     If you haven’t already done so, you can clone the example from this chapter’s GitHub
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.422.1">
      repository:
     </span>
    </span>
    <a href="https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter09">
     <span class="No-Break">
      <span class="koboSpan" id="kobo.423.1">
       https://github.com/PacktPublishing/Building-Modern-Data-Applications-Using-Databricks-Lakehouse/tree/main/chapter09
      </span>
     </span>
    </a>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.424.1">
      .
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.425.1">
     First, let’s create a new private folder in the root of our repository – that is,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.426.1">
      .github
     </span>
    </strong>
    <span class="koboSpan" id="kobo.427.1">
     .
    </span>
    <span class="koboSpan" id="kobo.427.2">
     Within this folder, let’s create another child folder called
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.428.1">
      workflows
     </span>
    </strong>
    <span class="koboSpan" id="kobo.429.1">
     .
    </span>
    <span class="koboSpan" id="kobo.429.2">
     This nested directory structure is a special pattern whose presence will be automatically picked up by the GitHub repository and parsed as a GitHub Actions workflow.
    </span>
    <span class="koboSpan" id="kobo.429.3">
     Within this folder, we’ll define our GitHub Actions workflow, which also uses a YAML configuration file to declare a CI/CD workflow.
    </span>
    <span class="koboSpan" id="kobo.429.4">
     Create a new YAML file called
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.430.1">
      dab_deployment_workflow.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.431.1">
     within the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.432.1">
      .
     </span>
    </strong>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.433.1">
       github/workflows
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.434.1">
      folder.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.435.1">
     Next, we’ll open
    </span>
    <a id="_idIndexMarker563">
    </a>
    <span class="koboSpan" id="kobo.436.1">
     the workflow file in our favorite code editor so that it’s easier
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.437.1">
      to manipulate.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-189">
    <a id="_idTextAnchor243">
    </a>
    <span class="koboSpan" id="kobo.438.1">
     Configuring the GitHub Action
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.439.1">
     Let’s begin by
    </span>
    <a id="_idIndexMarker564">
    </a>
    <span class="koboSpan" id="kobo.440.1">
     adding the basic structure to our GitHub Actions workflow file.
    </span>
    <span class="koboSpan" id="kobo.440.2">
     Within the YAML file, we’ll give the GitHub Actions workflow a user-friendly name, such as
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.441.1">
      DABs in Action
     </span>
    </strong>
    <span class="koboSpan" id="kobo.442.1">
     .
    </span>
    <span class="koboSpan" id="kobo.442.2">
     Within this file, we’ll also specify that whenever an approved pull request is merged into the main branch of our code repository, our CI/CD pipeline should be run.
    </span>
    <span class="koboSpan" id="kobo.442.3">
     Copy and paste the following contents into the newly created
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.443.1">
      file,
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.444.1">
       dab_deployment_workflow
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.445.1">
       .yml
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.446.1">
      :
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.447.1">
name: "DABs in Action"
on:
  push:
    branches:
         - main</span></pre>
   <p>
    <span class="koboSpan" id="kobo.448.1">
     Next, let’s define a job within our GitHub Actions YAML file that will clone the GitHub repository, download the Databricks CLI, and deploy our DAB to our target Databricks workspace.
    </span>
    <span class="koboSpan" id="kobo.448.2">
     Add the following job definition to the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.449.1">
      workflow file:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.450.1">
jobs:
  bundle-and-deploy:
    name: "DAB Deployment Job"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: databricks/setup-cli@main
      - run: databricks bundle deploy --target prod
        working-directory: ./dabs
        env:
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_SERVICE_PRINCIPAL_TOKEN }}</span></pre>
   <p>
    <span class="koboSpan" id="kobo.451.1">
     You’ll also notice that we’ve used the same Databricks CLI
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.452.1">
      bundle
     </span>
    </strong>
    <span class="koboSpan" id="kobo.453.1">
     command to deploy our Databricks resources as we did in the earlier example, using our local installation to deploy resources.
    </span>
    <span class="koboSpan" id="kobo.453.2">
     Furthermore, under the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.454.1">
      working-directory
     </span>
    </strong>
    <span class="koboSpan" id="kobo.455.1">
     parameter, we’ve specified that our DAB configuration file will be found at the root of our GitHub repository under the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.456.1">
      dabs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.457.1">
     folder.
    </span>
    <span class="koboSpan" id="kobo.457.2">
     We’ve also leveraged GitHub Secrets (
    </span>
    <a href="https://docs.github.com/en/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository">
     <span class="koboSpan" id="kobo.458.1">
      https://docs.github.com/en/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository
     </span>
    </a>
    <span class="koboSpan" id="kobo.459.1">
     ) to securely store the API token for authenticating with our target Databricks workspace, as well as followed the best practice of using a service principal (see the
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.460.1">
      User-to-machine authentication
     </span>
    </em>
    <span class="koboSpan" id="kobo.461.1">
     section) to automate the deployment of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.462.1">
      our resources.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.463.1">
     You’ll recall that service principals are restricted to a subset of API calls and follow the best practice of
    </span>
    <a id="_idIndexMarker565">
    </a>
    <span class="koboSpan" id="kobo.464.1">
     least privilege, whereas a user account would provide more privileges than are necessary.
    </span>
    <span class="koboSpan" id="kobo.464.2">
     Furthermore, our users can come and go from our organization, making maintenance activities such as user deprovisioning
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.465.1">
      a headache.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-190">
    <a id="_idTextAnchor244">
    </a>
    <span class="koboSpan" id="kobo.466.1">
     Testing the workflow
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.467.1">
     Now that we’ve
    </span>
    <a id="_idIndexMarker566">
    </a>
    <span class="koboSpan" id="kobo.468.1">
     defined when our CI/CD pipeline should be triggered and the workflow job responsible for deploying our DAB to our target workspace, we can test the GitHub
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.469.1">
      Actions workflow.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.470.1">
     Let’s add a section to our existing GitHub Actions workflow file that will trigger the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.471.1">
      my_first_dab_job
     </span>
    </strong>
    <span class="koboSpan" id="kobo.472.1">
     Databricks workflow that we created in the previous example.
    </span>
    <span class="koboSpan" id="kobo.472.2">
     You’ll also notice that, under the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.473.1">
      needs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.474.1">
     parameter, we declare a dependency on
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.475.1">
      DAB Deployment Job
     </span>
    </strong>
    <span class="koboSpan" id="kobo.476.1">
     , which must be completed before we can execute a run of the Databricks workflow.
    </span>
    <span class="koboSpan" id="kobo.476.2">
     In other words, we can’t test the changes without deploying them first.
    </span>
    <span class="koboSpan" id="kobo.476.3">
     Add the following job definition below the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.477.1">
      bundle-and-deploy
     </span>
    </strong>
    <span class="koboSpan" id="kobo.478.1">
     job in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.479.1">
      workflow file:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.480.1">
run-workflow:
  name: "Test the deployed pipeline workflow"
  runs-on: ubuntu-latest
  needs:
    - bundle-and-deploy
  steps:
    - uses: actions/checkout@v3
    - uses: databricks/setup-cli@main
    - run: databricks bundle run my_first_dab_job
      working-directory: ./dabs
      env:
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_SERVICE_PRINCIPAL_TOKEN }}</span></pre>
   <p>
    <span class="koboSpan" id="kobo.481.1">
     Save the GitHub Actions
    </span>
    <a id="_idIndexMarker567">
    </a>
    <span class="koboSpan" id="kobo.482.1">
     workflow file.
    </span>
    <span class="koboSpan" id="kobo.482.2">
     Now, let’s test the changes by opening a new pull request on our GitHub repository and merging the pull request into the main branch of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.483.1">
      the repository.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.484.1">
     First, create a new feature branch
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.485.1">
      using
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.486.1">
       git
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.487.1">
      :
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.488.1">
$ git checkout –b increaseAutoScaling</span></pre>
   <p>
    <span class="koboSpan" id="kobo.489.1">
     Next, open the DAB configuration file for the Databricks workflow in a code editor.
    </span>
    <span class="koboSpan" id="kobo.489.2">
     Update the autoscaling size of our job cluster from four worker nodes to five.
    </span>
    <span class="koboSpan" id="kobo.489.3">
     Save the file and commit the changes to the branch.
    </span>
    <span class="koboSpan" id="kobo.489.4">
     Finally, push the changes to the remote repository.
    </span>
    <span class="koboSpan" id="kobo.489.5">
     Using a web browser, navigate to the GitHub repository and create a new pull request in GitHub.
    </span>
    <span class="koboSpan" id="kobo.489.6">
     Approve the changes and merge the branch into the main branch.
    </span>
    <span class="koboSpan" id="kobo.489.7">
     Ensure that the GitHub Actions workflow is triggered and that the code changes have been deployed to the target Databricks workspac
    </span>
    <a id="_idTextAnchor245">
    </a>
    <span class="koboSpan" id="kobo.490.1">
     e.
    </span>
    <span class="koboSpan" id="kobo.490.2">
     You should also see that a new run of the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.491.1">
      my_first_dab_job
     </span>
    </strong>
    <span class="koboSpan" id="kobo.492.1">
     Databricks workflow has been executed by the GitHub
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.493.1">
      Actions workflow.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.494.1">
     Now that we’ve
    </span>
    <a id="_idIndexMarker568">
    </a>
    <span class="koboSpan" id="kobo.495.1">
     seen how easy it is to incorporate our DABs into a CI/CD pipeline, let’s expand on this example to see how DABs can assist us when we want to deploy different versions of our code base to a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.496.1">
      Databricks workspace.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-191">
    <a id="_idTextAnchor246">
    </a>
    <span class="koboSpan" id="kobo.497.1">
     Versioning and maintenance
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.498.1">
     DABs make it simple to
    </span>
    <a id="_idIndexMarker569">
    </a>
    <span class="koboSpan" id="kobo.499.1">
     deploy changes to different environments iteratively.
    </span>
    <span class="koboSpan" id="kobo.499.2">
     There may be scenarios where you might want to experiment with different changes and document that those changes come from a particular version of your repository.
    </span>
    <span class="koboSpan" id="kobo.499.3">
     The top-level
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.500.1">
      bundle
     </span>
    </strong>
    <span class="koboSpan" id="kobo.501.1">
     mapping permits users to specify a repository URL and branch name to annotate different versions of your code base that are deployed to target Databricks workspaces.
    </span>
    <span class="koboSpan" id="kobo.501.2">
     This is a great way to document that a bundle deployment comes from a particular repository and feature branch.
    </span>
    <span class="koboSpan" id="kobo.501.3">
     For example, the following code annotates that an asset bundle uses an experimental feature branch as the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.502.1">
      project source:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.503.1">
bundle:
  name: new-feature-dab
  git:
    origin_url: https://github.com/&lt;username&gt;/&lt;repo_name&gt;
    branch: my_experimental_feature_br</span></pre>
   <p>
    <span class="koboSpan" id="kobo.504.1">
     As another example, DABs make it simple to automate and document regular maintenance activities such as upgrading Databricks runtimes to the latest release.
    </span>
    <span class="koboSpan" id="kobo.504.2">
     This is a great way to experiment with beta versions of the runtime and test compatibility with existing Databricks workflows.
    </span>
    <span class="koboSpan" id="kobo.504.3">
     DABs can be used to automate the manual deployment and
    </span>
    <a id="_idIndexMarker570">
    </a>
    <span class="koboSpan" id="kobo.505.1">
     testing process, and even roll back changes if workflows begin to fail,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.506.1">
      for example.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-192">
    <a id="_idTextAnchor247">
    </a>
    <span class="koboSpan" id="kobo.507.1">
     Summary
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.508.1">
     In this chapter, we covered how to automate the deployment of your Databricks resources u
    </span>
    <a id="_idTextAnchor248">
    </a>
    <span class="koboSpan" id="kobo.509.1">
     sing DABs.
    </span>
    <span class="koboSpan" id="kobo.509.2">
     We saw how integral the Databricks CLI was in creating new bundles from preconfigured templates, authenticating the CLI tool with target Databricks workspaces, triggering Databricks workflow runs, and managing the end-to-end bundle life cycle.
    </span>
    <span class="koboSpan" id="kobo.509.3">
     We also saw how we can quickly iterate on design and testing by using a development mode inside of our DAB
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.510.1">
      configuration file.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.511.1">
     In the next chapter, we’ll conclude with the skills necessary to monitor your data applications in a production environment.
    </span>
    <span class="koboSpan" id="kobo.511.2">
     We’ll touch on key features in the Databricks Data Intelligence Platform, including alerting, viewing the pipeline event log, and measuring statistical metrics using
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.512.1">
      L
     </span>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.513.1">
      akehouse
     </span>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.514.1">
      M
     </span>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.515.1">
      onitoring.
     </span>
    </span>
   </p>
  </div>
 </body></html>