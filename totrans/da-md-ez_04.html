<html><head></head><body>
		<div id="_idContainer154">
			<h1 class="chapterNumber">4</h1>
			<h1 id="_idParaDest-65" class="chapterTitle" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor066"/>What is Machine Learning?</h1>
			<p class="normal">Autonomous self-driving cars, ultraprecise robot surgeons, impeccable virtual assistants, fully automated financial traders: some of the most promising AI applications seem more like sci-fi material than prospects to an imminent reality. We could fill entire books by just collecting and presenting sensational stories of algorithmic wonders. If we manage—instead—to keep both feet firmly on the present ground and recognize how intelligent algorithms can <em class="italic">already</em> support our everyday work needs, then we start unlocking tangible value for us and our business. This is what this chapter is all about: stripping away the myth from reality by meeting in person the main machine learning algorithms and techniques. The end objective is to start counting on them as everyday companions rather than out-of-reach, futuristic possibilities.</p>
			<p class="normal">In this chapter, we will find answers to the following questions:</p>
			<ul>
				<li class="bullet">What are AI and machine learning? </li>
				<li class="bullet">What is the "machine learning way" to solve business problems? What's the difference between this approach and the traditional approach?</li>
				<li class="bullet">How can machines learn? Which algorithms are available out there for making this happen? How do they work?</li>
				<li class="bullet">What tradeoffs do I need to consider when selecting the right model for my business need?</li>
				<li class="bullet">How can I assess the performance of a machine learning solution? </li>
			</ul>
			<p class="normal">Although this chapter is the most "analytical" one of the book, you will find only a handful of math formulas involved. The point is to give you an intuitive understanding of how machine learning works versus providing the whole theoretical background behind it.</p>
			<p class="normal">Think about it: you don't need to be a mathematician to use math, and you don't have to become a computer scientist or an expert coder to use a computer! Similarly, the next few pages will not make you able to recreate from scratch full modeling procedures: it will, instead, show you how to utilize the ones that—spoiler alert—are already conveniently implemented in software platforms like KNIME. In this chapter, we will learn the unmissable foundations needed to make you a user of machine learning, while in the next one, we will put them into practice using KNIME nodes through full tutorials. You might be impatient to jump into the practice, but I strongly recommend you go through this chapter first and feel confident about it before moving on. Buckle up: let's talk AI!</p>
			<h1 id="_idParaDest-66" class="title"><a id="_idTextAnchor067"/>Introducing artificial intelligence and machine learning</h1>
			<p class="normal"><em class="italic">Can machines think?</em> This is what English polymath and wartime codebreaker Alan Turing asked himself in his seminal 1950 paper that would lay the groundwork for AI. Although Turing does not use the term "artificial intelligence" (it would be introduced as a research discipline only six years later), he was convinced that machines would eventually compete with human beings in <em class="italic">all purely intellectual fields</em>.</p>
			<p class="normal">Using technology devices to extend and partially replace human intellect was not a new quest. Back in the 17th century, French mathematician and philosopher Blaise Pascal invented <a id="_idIndexMarker306"/>the <strong class="keyword">Pascaline </strong>(<em class="italic">Figure 4.1</em>), a fully working mechanical computer that could do addition and subtraction of numbers entered by rotating its dials.</p>
			<figure class="mediaobject"><img src="image/B17125_04_01.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.1: Pascal's arithmetic machine, a.k.a. the Pascaline. From the top left, clockwise: an original device built in 1652; a view of the underlying system of gears; the detailed plan of the sautoir, the ingenious mechanism enabling the carryover in additions. The photograph is by Rama, Wikimedia Commons, Cc-by-sa-2.0-fr.</p>
			<p class="normal">Calculating mathematical operations is a very specific intellectual task. Still, the Pascaline was early proof that technology can replicate and amplify people's capacity to do brain work, not just physical activities. This is what AI is all about: <strong class="keyword">Artificial Intelligence </strong>(<strong class="keyword">AI</strong>) is defined <a id="_idIndexMarker307"/>as the ability of machines to perform actions that display <em class="italic">some</em> form of human intelligence, such as solving logical problems, using language to communicate, recognizing visual and auditory patterns, making sense of the environment, or coordinating physical movements. Within the broader field of AI, <strong class="keyword">Machine Learning</strong> (<strong class="keyword">ML</strong>) focuses<a id="_idIndexMarker308"/> on the artificial replication of a <em class="italic">specific</em> aspect of human intelligence: the ability to learn.</p>
			<p class="normal">The faculty of learning has immense potential value when applied to any business. If a machine can autonomously learn from data for us, we can use it to consistently grow our knowledge on customers, competitors, and our own operations. We can reduce costs, simplify processes, grow revenue thanks to better decisions, proactively prepare for the future, and even improve the experience—and so the loyalty—of our customers. ML algorithms are tireless partners in growing our business: they can extend our team's overall intelligence, leveraging the extensive computational capacity of digital technology (which gets increasingly cheaper over time) and the massive amount of data that would be otherwise largely lying unused in a corporate database. The strong potential of autonomous learning explains why, in the last few years, ML has grown so much in popularity to unseat its conceptual parent, AI, as the trendiest technology phenomenon on everyone's lips. Today, AI and ML are often used as synonyms, and in the rest of the book, we will primarily refer to the latter. To avoid confusion in your further readings, just remember: AI looks at the full scope of human intelligence, ML concentrates on the autonomous learning bit.</p>
			<div>
				<div id="_idContainer130" class="note">
					<p class="Information-Box--PACKT-">An <strong class="keyword">Algorithm</strong><strong class="keyword"><a id="_idIndexMarker309"/></strong> is a problem-solving procedure or, in other words, a series of pre-defined steps that can be followed to solve a specific task. The steps required by a machine to multiply two numbers or to make a prediction based on previous values are both examples of algorithms. Computers are often able to solve complex problems, provided that a human equips them with the right algorithm to follow.</p>
				</div>
			</div>
			<p class="normal">One important clarification is needed on the nature of the tasks that we can solve with AI and the classification that derives from it. In fact, researchers postulate the existence of two types of AI: strong and weak:</p>
			<ul>
				<li class="bullet"><strong class="keyword">Strong AI</strong> (or <strong class="keyword">AGI</strong>, <strong class="keyword">Artificial General Intelligence</strong>) is the <a id="_idIndexMarker310"/>hypothetical aptitude of machines to <a id="_idIndexMarker311"/>potentially understand and execute <em class="italic">any</em> intellectual task. A strong AI would autonomously "understand what's needed" and then "go for it," even displaying those features that make us human, such as consciousness, self-awareness, creativity, intentionality, and sentience. However fascinating (and scary) the concept of strong AI appears, today it still mainly falls into the realm of theoretical speculation or fictional exploration. Many researchers argue that AGI is decades away, while some believe it will never become a reality. In any case, we are not going to investigate it further in this book: here we will focus, instead, on the other type of AI, which is undoubtedly more in reach.</li>
				<li class="bullet"><strong class="keyword">Weak AI</strong> refers to<a id="_idIndexMarker312"/> machines' ability to solve <em class="italic">pre-determined</em> and specific tasks, like predicting future sales, anticipating the behavior of a user in a given situation, or unveiling ways to optimize a particular business process. To make weak AI happen, there is always a fundamental role for human operators to play when setting things up: algorithms will need to be guided to the problem to solve and initially tweaked for operating at their best. In the upcoming part of the book, we will learn how to do precisely that: to make AI drive value in our everyday work, by setting up the right algorithms in the right way, so as to make them operate at best for our advantage.</li>
			</ul>
			<p class="normal">Since strong AI is nowhere close to us and weak AI is clearly dependent on the people that set it up correctly, one thing is clear: humans and machines are not in conflict with each other, fighting for supremacy in the workforce arena and protecting their jobs. Actually, it is quite the opposite: the magic happens when humans collaborate with machines by "coaching" them properly in their learning endeavors. When this happens, intelligent machines show their full value, ultimately benefitting their human companions. Having this in mind, let's start to learn how to coach the AI properly, by recognizing the business situations where the right algorithm can make the difference.</p>
			<h1 id="_idParaDest-67" class="title"><a id="_idTextAnchor068"/>The machine learning way</h1>
			<p class="normal">Ironically, one of the<a id="_idIndexMarker313"/> foremost barriers preventing the exploitation of ML in a business is neither the implementation of the algorithm nor the retrieval of the data (the <em class="italic">how</em>): the toughest part is to recognize the right occasion to use it (the <em class="italic">why</em>)! We need to identify within the complex map of business processes (the operating model of the company) the specific steps where algorithms can bring real value if adopted. If we develop our sensitivity to recognize such leverage points, then we will be able to find in our work the first opportunities to put ML into practice.</p>
			<p class="normal">There is a machine learning way (we can call it the <strong class="keyword">ML way</strong>) to operate business processes. Let's go through three sample scenarios to distinguish between the traditional and the ML ways to create value with data.</p>
			<h2 id="_idParaDest-68" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor069"/>Scenario #1: Predicting market prices</h2>
			<p class="normal">You work for a car<a id="_idIndexMarker314"/> dealership, specializing in multibrand, used vehicles. You notice that some cars take much longer to sell because their initial listing price was too high versus customers' expectations. To improve this situation, you want to implement a technical solution to guide the price-setting process in a data-based manner: the objective is to anticipate the actual market price of each car to keep inventory under control while maximizing revenues.</p>
			<p class="normal">Here are two possible approaches to solve this:</p>
			<ul>
				<li class="bullet">The traditional way is to codify a set of rules that define how the car's features impact the market price and build a "calculator" that implements these rules. The calculator will leverage a mix of available data points (like the starting price of new cars by brand and model, or the cost of accessories) and some thumb-rules defined thanks to common sense and to the expertise of those who have been for some time in the business. For example, some rules can be: <em class="italic">the car depreciates by 20% during its first year and then by an additional 15% every further year of age</em>, or <em class="italic">cars that run for more than 10,000 miles/year are high-mileage and their value is reduced by a further 15%</em>, and so on. To build this calculator, you will need to implement these if-then rules using a programming language, which means that you also need a programmer to develop and maintain the code over time.</li>
				<li class="bullet">The ML way is to get an algorithm to analyze all the data related to previous sales and autonomously "learn" the rules that connect the car features (like mileage, age, make, model, accessories, and so on) with the actual price at which the car sold. The algorithm can identify some recurrent patterns, which are partly confirming the rules we already had in mind (maybe adding a further level of precision to those approximate thumb rules), and partly identify new and unexpected connections, which humans failed to recognize and summarize in a simple rule (like, for instance, <em class="italic">model X depreciates 37% more slowly when equipped with this rare optional</em>). Using this approach, the machine can keep learning over time: the rules underlying the price will evolve and get automatically updated as new sales happen and new car models enter the market.</li>
			</ul>
			<p class="normal">The main difference is that in the traditional approach, our price prediction will leverage the existing human knowledge on the matter (if adequately documented and codified), while the ML way provides for that knowledge (and possibly more) to be autonomously learned from data by the machine.</p>
			<h2 id="_idParaDest-69" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor070"/>Scenario #2: Segmenting customers</h2>
			<p class="normal">You work in the marketing team of a local supermarket chain. You are responsible for preparing a weekly <a id="_idIndexMarker315"/>newsletter to be sent to those customers who signed up for the loyalty program and opted in to receive emails from you. Instead of sending a one-size-fits-all newsletter to everyone, you want to create a reasonable number of different versions and distribute them accordingly to the various groups. By selecting key messages and special offers that are closer to each group's needs, you aim to maximize the engagement and loyalty of your entire customer base.</p>
			<p class="normal">There are at least two ways to create such groups:</p>
			<ul>
				<li class="bullet">The traditional way is to use common sense and your existing knowledge to select the features that can reasonably discriminate across different types of customers, each having a more specific set of needs. For instance, you can decide to use the age of household members and average income level to define different groups: you will end up with groups like the <em class="italic">affluent families with children</em> (to whom you might talk about premium-quality products for kids) and <em class="italic">low-income 60+ empty nesters</em> (more interested in high-value deals). This traditional approach assumes that the needs within each group—in this case, solely defined by age and income—are homogeneous: we might end up ignoring some meaningful differences across other dimensions.</li>
				<li class="bullet">The ML way is to ask an algorithm to identify for us a number of homogeneous groups of customers that systematically display similar shopping behavior. Not being restricted by the cognitive capacity of humans (who would struggle to take into account dozens of variables at once) and their personal biases (driven by their individual and specific experiences), the algorithm can come up with groups that are specific and more closely connected to the actual preferences of each customer, like <em class="italic">food lovers who shop at the weekend</em> (to whom we might send some fancy recipes every Saturday morning) and <em class="italic">high-income pet owners</em> (wanting to take care of their beloved furry companions).</li>
			</ul>
			<p class="normal">Traditionally, we would differentiate actions by considering apparent—and, sometimes, naïve—differences, while the ML way goes straight to the core of the matter and identifies those homogeneous groups that best describe the diversity of our customer base, keeping everyone included and engaged.</p>
			<h2 id="_idParaDest-70" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor071"/>Scenario #3: Finding the best ad strategy</h2>
			<p class="normal">You work in the digital<a id="_idIndexMarker316"/> marketing department of a mid-sized company providing online photo printing services. Your responsibility is to define and execute digital advertising campaigns with the ultimate objective of maximizing their return. Instead of having a single campaign based on the same content, you want to optimize your strategy by testing different digital assets and seeing what works best. For example, you might have banners showing different products (like photo books and cheesy mugs with a portrait on them), various colors and fonts, or alternate versions of the tagline text. You can post your ads on social media and search engines, and you can control the available budget and duration of each test.</p>
			<p class="normal">Also in this case, we can<a id="_idIndexMarker317"/> recognize two possible approaches to make this happen:</p>
			<ul>
				<li class="bullet">The traditional way is to run the so-called A/B/n testing: you define several alternative executions (for instance, three similar ads with the same graphic but three different call-to-action texts like <em class="italic">buy me now</em>, <em class="italic">check it out</em>, or <em class="italic">click to learn more</em>), run each of them—let's imagine—10,000 times, and calculate their individual return by counting, for example, the number of orders generated by each execution. You will need to repeat the test over time to check if it's still valid and, if you want to optimize across other dimensions (like the time of day at which the ad is served, or the location of users, and so on) you will end up with a growing number of combinations to test (and a larger cost of the experiment).</li>
				<li class="bullet">The ML way is to let an algorithm dynamically decide what to test and how, moving progressively toward the path leading to the best combinations of variable aspects. At first, the algorithm will start similarly as in an A/B/n test, trying some random combinations: this will be enough to grasp some first knowledge on the most promising directions to take. Over time, the algorithm will focus its attention (and budget) more and more on the few paths that are working best, finetuning and enriching them with an increasingly larger number of factors. In the end, the algorithm might end up with some very specific choices like <em class="italic">use a pink font and display a photo mug for people in their 50s who are connecting through a laptop</em>.</li>
			</ul>
			<p class="normal">In both approaches, we have used tests to learn what the best ad strategy was. However, in the traditional A/B/n testing approach, we had to define test settings based on prior knowledge and common sense. In the ML way, we put the machine in the driving seat and let it interact with the environment, learn progressively, and dynamically adjust the testing strategy, so as to minimize costs and get higher returns.</p>
			<h2 id="_idParaDest-71" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor072"/>The business value of learning machines</h2>
			<p class="normal">These three scenarios unveil some recurrent differences between the traditional and the ML way to operate business <a id="_idIndexMarker318"/>processes. Let's have a look at the incremental benefits we get from ML:</p>
			<ul>
				<li class="bullet">Both approaches rely on technology and data, but the ML way leverages them <em class="italic">more extensively</em>. Suppose you allow algorithms to explore the full information content of a large database. In that case, you capitalize on the massive horsepower of digital technologies and avoid hitting the bottleneck of human cognitive limitation. With ML, more data will be considered at once (think about the many attributes of customers to be segmented or the factors that differentiate digital ads), which is likely to end up in better business outcomes. In other words, the ML way tends to be <strong class="keyword">more accurate and effective</strong> than traditional approaches, leading to an economic advantage for the company relying on it.</li>
				<li class="bullet">Once it is correctly set up, the ML way can operate <em class="italic">independently</em> and with <em class="italic">minimal supervision</em> from its human companion. This means driving automation<strong class="keyword"> </strong>of intellectual tasks and, as a result, incremental <strong class="keyword">efficiency </strong>and productivity for the business. Because of this automation, ML algorithms can stay <strong class="keyword">always on</strong> and keep learning unceasingly on a 24/7 schedule. This means that they will get better and better at what they do over time, as more data comes in, without necessarily having to invest in further upgrades or human improvements. Think about the new car models appearing in the market or the evolving preferences of customers served by a digital ad: algorithms will observe reality vigilantly, spot trend breakers, and react accordingly to keep the business going.</li>
				<li class="bullet">The traditional approach relies on <em class="italic">previous</em> human knowledge while the ML way generates <em class="italic">additional </em>knowledge. This is a game-changing and fascinating benefit of ML<a id="_idIndexMarker319"/> called <strong class="keyword">Knowledge Discovery</strong>: learning algorithms can provide a better and sometimes insightful understanding of reality (think about the subtle rules that explain car price formation, or the unexpected connections pulling together consumers in homogeneous groups) that can't be spotted by just looking at the data. It is the capacity to <em class="italic">hack</em> reality by finding unexpected patterns in the way things work. If the learning algorithm provides for its outcome to be humanly intelligible (and many of them do), this knowledge will go and accrue to the overall know-how of the organization in terms of customer understanding, market dynamics, operating model, and more: this can be as valuable as gold, if used well!</li>
			</ul>
			<p class="normal">Making processes more efficient and effective, plus systematically acquiring an additional understanding of the business, these benefits by themselves are enough to explain why ML is currently exploding in modern business, making it a competitive advantage that nobody wants the risk of not having. Let's now meet the types of algorithms that can enable all of this.</p>
			<h1 id="_idParaDest-72" class="title"><strong class="keyword"><a id="_idTextAnchor073"/>Three types of learning algorithms</strong></h1>
			<p class="normal">The scenarios we have<a id="_idIndexMarker320"/> seen in the previous section were not selected at random. They match the standard categorization of ML algorithms that provides for three fundamental types: <strong class="keyword">Supervised Learning</strong>, <strong class="keyword">Unsupervised Learning</strong>, and <strong class="keyword">Reinforcement Learning</strong>. When we want to apply the ML way, we need to select one of these three routes: our choice will depend on the nature of the problem we need to solve. Let's now go through each group to understand what they are made of and what types of tasks they fulfill.</p>
			<h2 id="_idParaDest-73" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor074"/>Supervised learning</h2>
			<p class="normal">In supervised learning, your <a id="_idIndexMarker321"/>objective is to predict something "unknown" by learning from some "known" pieces of information. The easiest way to make sense of the supervised learning approach is to think about how it differs from traditional programming. In <em class="italic">Figure 4.2</em>, you will find on the left a very familiar setup. In plain computer programming, we need some input<em class="italic"> data</em>, a <em class="italic">program,</em> and a <em class="italic">computer </em>to generate some<em class="italic"> results</em>. The program is a series of instructions—described in a machine-intelligible idiom, called<a id="_idIndexMarker322"/> the <strong class="keyword">Programming Language</strong>—which the computer will apply to the input data to return the desired results as an output. In supervised ML, we keep all these four elements (data, program, computer, and results) but change the order of two of them. As you can see from the right part of <em class="italic">Figure 4.2</em>, in supervised learning, you give data and results—as inputs—to a computer that will return—as output—the program that "connects" the results to the data.</p>
			<figure class="mediaobject"><img src="image/B17125_04_02.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.2: Traditional programming compared with the supervised ML approach. The ingredients are the same, but the order differs.</p>
			<p class="normal">What empowers the computer to make this "magic" happen is the supervised ML algorithm: this algorithm is a series of steps that can find out the set of transformations (mathematically described as a <strong class="keyword">Statistical Model</strong>) that you can apply to some input data to obtain something close to the desired results. Thanks to these algorithms, the computer will "learn" from past data (for which we know the results) to unveil the approximate mechanism connecting input data to the unknown results.</p>
			<p class="normal">This will be even <a id="_idIndexMarker323"/>clearer if we apply it to <strong class="keyword">Scenario #1</strong> introduced in the <em class="italic">The Machine learning way</em> section: the car price predictions. In this case, our input data is the known attributes of the cars sold in the past. The result that we want to get is the price of those cars. If we leverage the supervised ML approach, we can use our known <em class="italic">past data</em> (features of previously sold cars) and <em class="italic">past results</em> (previous sale prices) to infer such transformation steps (the <em class="italic">program</em>, or model) that, once applied to <em class="italic">future data</em> (features of the next cars to be sold), will return the <em class="italic">future results</em> (predicted prices). In this setup (see <em class="italic">Figure 4.3</em>), the ML algorithm is implemented in the <strong class="keyword">Learner</strong> block. The <strong class="keyword">Predictor </strong>block will just "execute" on new data points from the program that is provided by the learner block.</p>
			<figure class="mediaobject"><img src="image/B17125_04_03.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.3: Supervised ML in action: learning from previously sold cars to understand the unwritten rules of how the features of the cars define their prices</p>
			<p class="normal">Thanks to the supervised ML algorithm, which empowers the learner, we can find out the "hidden rules" of price formation. Ferraris will have a much higher starting point and follow a different price decay over time than Fiat 500s: the algorithm will find those rules out.</p>
			<p class="normal">It is important to recognize that in supervised learning, you always have a specific measure to be predicted: this is called the <strong class="keyword">Target</strong> (or <strong class="keyword">Dependent</strong> variable). In the previous example, the price of the car was the target variable of our learning. All other variables—the ones used to predict what the target will be—are called <strong class="keyword">Features</strong> (or <strong class="keyword">Independent </strong>variables). The model and the age of cars in <em class="italic">Figure 4.3</em> were the two features used in the learning.</p>
			<div>
				<div id="_idContainer133" class="note">
					<p class="Information-Box--PACKT-">When input data is enriched with "results" (also known as <strong class="keyword">labels</strong>), it is called <strong class="keyword">labeled data</strong>. For simplicity, think<a id="_idIndexMarker324"/> about this: a labeled data table will always have multiple columns containing the features and a specific column containing the target. Labeled data is an unmissable ingredient of supervised ML.</p>
				</div>
			</div>
			<p class="normal">Depending on the nature of the target variable, you can identify two scenarios of learning, which require different learning algorithms within the supervised family:</p>
			<ul>
				<li class="bullet">When the target variable is a numeric measure (like <em class="italic">5.21</em> or <em class="italic">$23,000</em>), then you need a <strong class="keyword">Regression </strong>algorithm. Linear Regression<a id="_idIndexMarker325"/> is the easiest and most common example of algorithms able to predict numbers.</li>
				<li class="bullet">When the target variable is a categorical measure (like a string of text indicating to which category or class an element belongs), you will <a id="_idIndexMarker326"/>need a <strong class="keyword">Classification </strong>algorithm. Examples of classes are <em class="italic">red</em>, <em class="italic">blue</em>, and <em class="italic">green</em>, or binary categories like <em class="italic">true</em> and <em class="italic">false</em>, or labels identifying a specific behavior, such as <em class="italic">will buy this product</em> and <em class="italic">will not buy this product</em>. Decision Trees, Random Forests, and Support Vector Machines are just some of the many algorithms available to you when you want to predict to which classes the elements of a table belong. You will learn how to use some of them in the next chapter.</li>
			</ul>
			<p class="normal">Some supervised algorithms can be used for both regression and classification. This is true of Neural Networks, which can predict either numbers or classes.</p>
			<div>
				<div id="_idContainer134" class="note">
					<p class="Information-Box--PACKT-">The Logistic Regression algorithm (a variation of Linear Regression) can predict the likelihood of belonging to<a id="_idIndexMarker327"/> binary classes. Hence, as confusing as it is, Logistic Regression is a classification algorithm even if the name suggests the contrary.</p>
				</div>
			</div>
			<p class="normal">Before we move on to the following type of learning algorithms, it is worth thinking about why this one is called supervised. The analogy we can strike is with a teacher who gives a lesson by providing multiple examples of how something works, hoping that the student will grasp the concept by noticing connections. When sharing various illustrations of a concept (the labeled data), the teacher <em class="italic">supervises</em> the student's learning. Without those examples for which we knew the outcome (the target variable), the teacher would have been unable to guide the student. That's why in supervised learning, you always have a target variable, and you always need to start from some labeled data.</p>
			<p class="normal">Let's move on to the next type of ML algorithm, where you don't need any labeled data to start learning.</p>
			<h2 id="_idParaDest-74" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor075"/>Unsupervised learning</h2>
			<p class="normal">In this case, your <a id="_idIndexMarker328"/>objective is not to make a prediction but to unveil some hidden structure in your data. Unsupervised ML algorithms are capable of <em class="italic">exploring</em> your data table to find out some interesting patterns in the way rows and columns are connected to each other.</p>
			<p class="normal">There is a broad series of use case scenarios where unsupervised learning can be of great value:</p>
			<ul>
				<li class="bullet">The simplest case is<strong class="keyword"> Clustering</strong>. This is about <a id="_idIndexMarker329"/>aggregating your data points to create homogeneous groups, called <a id="_idIndexMarker330"/>clusters. Each group will contain points that are "similar" to each other. This is exactly what we needed to do in <strong class="keyword">Scenario #2</strong>, where we had to build groups of similar supermarket customers to send each of them a meaningful and personalized newsletter. Algorithms like K-means and Hierarchical Clustering are good examples of unsupervised ML algorithms dedicated to identifying clusters.</li>
			</ul>
			<div>
				<div id="_idContainer135" class="note">
					<p class="Information-Box--PACKT-">An interesting extension of clustering in the world of text mining is <strong class="keyword">Topic Modeling</strong>, meaning the<a id="_idIndexMarker331"/> identification of topics (groups of conceptually related words) in text documents. One of the most popular algorithms for topic modeling<a id="_idIndexMarker332"/> is <strong class="keyword">Latent Dirichlet Allocation</strong> (<strong class="keyword">LDA</strong>).</p>
				</div>
			</div>
			<ul>
				<li class="bullet">Finding <strong class="keyword">Association Rules</strong> is another <a id="_idIndexMarker333"/>common need covered by unsupervised learning. Let's imagine that you have an extensive database containing a description of all the receipts generated in a supermarket. Some products might frequently "end up" together in the same receipt: think about milk and coffee or pasta and tomato sauce. Algorithms like Apriori and FP-Growth will scout for several meaningful and statistically significant rules, such as <em class="italic">customers buying pasta will likely also buy tomato sauce</em>. These rules can be insightful information to leverage when optimizing a store's assortment or defining which products<a id="_idIndexMarker334"/> should be on adjacent shelves (<strong class="keyword">Market Basket Analysis</strong>).</li>
				<li class="bullet">Another typical usage of unsupervised learning is called <strong class="keyword">Dimensionality Reduction</strong>. If you have a table <a id="_idIndexMarker335"/>with many columns, it could be that some of them are correlated to each other: as a consequence, your table will be redundant since the information carried by one column might be already present in other columns. To avoid all the drawbacks linked to redundancy (such as performance degradation and loss of accuracy), it is worth reducing the number of columns of the table without losing the overall information contained in it. The algorithms dedicated to dimensionality reduction, such <a id="_idIndexMarker336"/>as <strong class="keyword">Principal Component Analysis</strong> (<strong class="keyword">PCA</strong>), can explore the structure of the table and produce a "narrower" version of it (with fewer columns, so a lower dimensionality) carrying similar informative content. </li>
			</ul>
			<p class="normal">Let's now compare this <a id="_idIndexMarker337"/>unsupervised approach with the supervised one we discussed earlier. The critical difference is that in unsupervised learning, we are not after the connections between features and target: as a matter of fact, we don't have a target column in the first place! Indeed, the input data for an unsupervised algorithm is <em class="italic">unlabeled</em>: no target variable and no labels are required. Following the previous analogy, the student here will not need any "supervision" from the teacher, based on previous examples. The learning happens by exploring the data as-is and looking for patterns that are intrinsic to the data itself (like clusters of items or associations between elements).</p>
			<p class="normal">While in supervised learning, we could easily understand whether a prediction was robust or not (by comparing it with the "real" value), in unsupervised learning, it is more difficult to assess how good the job of the algorithm was. In other words, there is not a definite good or wrong answer in unsupervised learning, only more or less valuable structures unveiled. We will have to measure its effectiveness by looking at how it fits the original purpose we aimed at. We will look more into this complexity later.</p>
			<p class="normal">Let's now move on to the third and last class of ML algorithms.</p>
			<h2 id="_idParaDest-75" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor076"/>Reinforcement learning</h2>
			<p class="normal">When adopting the reinforcement learning<a id="_idIndexMarker338"/> approach, you learn by repeatedly interacting with the environment in a "trial and error" fashion. The fundamental difference with the earlier types of learning methodologies is that, in this case, the algorithm acts as an autonomous <em class="italic">agent</em>: based on the current <em class="italic">state</em>, it will decide what <em class="italic">action</em> to take, execute it in either the real world or in a simulated <em class="italic">environment</em>, and then—depending on the outcome of its action—update its strategy to maximize the total <em class="italic">reward</em>. As you can see in <em class="italic">Figure 4.4</em>, these steps go through a loop of progressive improvements of the strategy, following a simple, common-sense base logic: if the state resulting from my action brings a positive reward, then the behavior leading to that action is positively reinforced (hence the name). If instead, that action brought a negative reward, then that behavior should be penalized so that it doesn't happen again.</p>
			<figure class="mediaobject"><img src="image/B17125_04_04.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.4: Reinforcement learning: an autonomous agent freely interacts with the environment and learns as it goes</p>
			<p class="normal">We can recognize two use <a id="_idIndexMarker339"/>case scenarios where reinforcement learning is used:</p>
			<ul>
				<li class="bullet">You can let the agent interact directly with the <strong class="keyword">external environment</strong>, like in the case of <strong class="keyword">Scenario #3</strong>, the digital advertising strategy for the photo printing company. Employing a series of iterations (testing different types of ads) and moving through a path of gradually increasing rewards (higher media ROI), we will end up having a robust strategy to adopt in our campaigns. The interaction can happen with the physical, real-world environment too: for instance, a robotic arm can learn how to best move some packages using the state captured through its camera sensors and continuously improving the way its engines respond to reach that objective. Reinforcement learning algorithms such as Q-learning are great for maximizing the total rewards of systems like these.</li>
				<li class="bullet">An alternative approach is to provide a <strong class="keyword">simulated environment</strong> for one or multiple agents to interact virtually and progressively learn from what happens. This is the case of algorithms like <strong class="keyword">Monte Carlo Tree Search</strong> (<strong class="keyword">MCTS</strong>) and its most famous implementation, Google AlphaZero, which proved able to learn from scratch and become a champion in virtually any game solely through "self-playing." The only external input required by the algorithm to get started is the list of formal rules of the games: then it proceeds as a true self-learner, playing alone with itself and swapping sides if needed. Let's take the game of chess as an example: at first, the agent will play very silly games made of random (but formally correct) moves. Then, little by little, it will learn that, by making some smart openings and defending some critical positions on the board, the chances of winning will increase. After a few hours of learning (and millions of games played), the agent will have finetuned its strategy of the most advantageous moves and will have become unbeatable by any human chess grandmaster.</li>
			</ul>
			<p class="normal">Reinforcement learning has the <a id="_idIndexMarker340"/>great advantage of not requiring any labeled data to start: the agent will autonomously decide which route of experimentation to take and pursue it, accruing new data points at each step of the path. While potentially quite powerful, reinforcement learning is still not widely used in business applications because of the practical challenges of implementation such as building a working "interface" with the real world or satisfying all safety constraints—like making sure the agent doesn't cause any "damage" as it wanders around during the learning process. For this reason, in the rest of the book, we will focus on supervised and unsupervised learning algorithms: they can enable you to create value for your job quickly before moving onto more sophisticated quests.</p>
			<h2 id="_idParaDest-76" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor077"/>Selecting the right learning algorithm</h2>
			<p class="normal">In the last few pages, we<a id="_idIndexMarker341"/> have heard the name of several different algorithms: this gave us a glimpse of the vast (and continuously growing) selection of ML algorithms that we could use to "go the ML way" when solving a problem. <em class="italic">Figure 4.5</em> offers a view of the catalog of ML algorithms organized by type of learning (supervised, unsupervised, and reinforcement) and objective. For each scenario, we have a choice of alternative algorithms that could do the job for you: a selection of the most commonly used algorithms are on the right-hand side of <em class="italic">Figure 4.5</em>:</p>
			<figure class="mediaobject"><img src="image/B17125_04_05.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.5: Catalog of ML algorithms: depending on your need, you select which route to take</p>
			<p class="normal">As a user of ML, you will <a id="_idIndexMarker342"/>need to decide which algorithms, out of the many alternatives, are best suited for the task you want to accomplish. Each algorithm adopts its own logic, carrying specific strengths and weaknesses: as you select among them, you need to strike a good trade-off between their characteristics. For example, a good algorithm might be very accurate but extremely slow and expensive to run, while another one is the opposite: which one is best for you? Let's start familiarizing ourselves with the most essential attributes that define the various algorithms:</p>
			<ul>
				<li class="bullet"><strong class="keyword">Performance</strong>. Possibly the most important one to consider, this tells us "how well" the algorithm accomplishes its job and "how robust" we expect it to be in the future. For instance, in the case of supervised learning, we would measure how accurate our predictions are or, in other words, how "close" they fall to reality. This is a complex issue to consider: later we will go into more depth regarding the many measures that we can use to assess how accurate and robust an algorithm is.</li>
				<li class="bullet"><strong class="keyword">Speed</strong>. Depending on how many "iterations" are needed to run the full procedure, algorithms might be slow and resource-greedy or fast and light.</li>
				<li class="bullet"><strong class="keyword">Explainability</strong>. Some algorithms offer an easily interpretable output by human beings: this is strictly required when you want to uncover new knowledge from data and transfer it to other people or when you want to give a solid explanation of why the algorithm suggested something. In other cases, we don't need to comprehend how the algorithm operates, and we are OK to receive a complex (but accurate) <em class="italic">Black Box</em> output, impenetrable by human cognition.</li>
				<li class="bullet"><strong class="keyword">Amount of data required</strong>. Some algorithms perform well only with a large number of previous data points to start from. Others can be robust already with dozens of rows and do not require any big data to work.</li>
				<li class="bullet"><strong class="keyword">Prior knowledge required</strong>. In some cases, the algorithm requires you to make assumptions about the data you expect or the environment you operate in. Other procedures will be more agnostic toward their domain of application and do not require any prior knowledge.</li>
			</ul>
			<p class="normal">These five points are just<a id="_idIndexMarker343"/> some of the many attributes you can consider when selecting the right algorithm. The good news is that these algorithms are already conveniently implemented in data analytics software platforms, for example, as KNIME nodes or as libraries in Python. Having them readily available lets you "try a few" and decide accordingly.</p>
			<div>
				<div id="_idContainer138" class="note">
					<p class="Information-Box--PACKT-">In some cases, you can combine different algorithms together in a single learning procedure. In this way, you will take the best of both, collectively smoothing the edges of their individual behavior: this <a id="_idIndexMarker344"/>is called <strong class="keyword">Stacking</strong>.</p>
				</div>
			</div>
			<p class="normal">One thing is sure: there is not a "one size fits all" approach to use ML, and you need to become acquainted with a selection of alternative procedures. All these algorithms are like utensils to keep in your backpack so that you can leverage them depending on the need. By knowing several algorithms, you are free to set the right trade-offs between their contrasting attributes and do the best to solve most business cases you will find on your way.</p>
			<p class="normal">Since performance measures are fundamental, let's get into more details on how we can assess them in machine learning algorithms.</p>
			<h1 id="_idParaDest-77" class="title"><a id="_idTextAnchor078"/>Evaluating performance </h1>
			<p class="normal">Measuring how good an<a id="_idIndexMarker345"/> algorithm is at doing its job is not always an easy task. Take the case of unsupervised learning: we expect a good unsupervised algorithm to unveil the most interesting and useful structures from data. The assessment on what makes them <em class="italic">interesting</em> or <em class="italic">useful</em>, however, will depend on your specific end goal and often requires some human judgment as well. In reinforcement learning, a good algorithm will be able to come back with a sizeable total reward, unlocking the opportunity to keep maximizing the return of our continuous interaction with the environment. Also in this case, the concept of <em class="italic">reward</em> will depend on a specific definition of value, determined by the case we are solving.</p>
			<p class="normal">If we stay, instead, in the area of supervised learning, the performance evaluation is more straightforward: since our objective is to predict something (numbers or categories), we can assess the performance by measuring the differences between predicted and known samples. The results of this comparison between prediction and actual values can be condensed into <a id="_idIndexMarker346"/>summary scores. Let's learn about these scores for both regression and classification.</p>
			<h2 id="_idParaDest-78" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor079"/>Regression</h2>
			<p class="normal">Since regression is<a id="_idIndexMarker347"/> all about predicting numeric values, scoring its performance means assessing the overall distance of the results of the prediction from the actual values we were trying to predict: the smaller the distance, the smaller the error, and the smaller the error, the better. In the case of the simple Linear Regression you see in <em class="italic">Figure 4.6</em>, we are trying to predict the price of second-hand cars (target variable) based solely on their age (our only independent variable). The dotted line shows the result of our model, which gives us a prediction of the price given the age: of course, as the age increases, the price decreases. Hence our line goes down as we move to the right. The circles represent the cars' actual prices, so the error that we make in our prediction is the distance between each circle and the dotted line: this "gap" from reality is called <strong class="keyword">residual</strong>. By properly <a id="_idIndexMarker348"/>aggregating residuals, we can obtain a single performance metric for any regression.</p>
			<figure class="mediaobject"><img src="image/B17125_04_06.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.6: Assessing the regression performance: how much error did we make in the prediction?</p>
			<p class="normal">One way to do so is to<a id="_idIndexMarker349"/> average them out. However, we should consider that residuals can be positive or negative quantities depending on whether the prediction is lower or higher than the actual values (see both cases in <em class="italic">Figure 4.6</em>). To avoid that negative residuals counterbalance (and, so, "mask out") positive residuals, we can calculate their squares, average them out, and then put that under a square root sign so as to bring this metric to the same unit of measure of the predicted quantity (like dollars, in the car example). This is how we obtain one of the most popular scoring metrics for regression: it's<a id="_idIndexMarker350"/> called <strong class="keyword">Root Mean Squared Error</strong>, or <strong class="keyword">RMSE</strong>. Its formula is:</p>
			<figure class="mediaobject"><img src="image/B17125_04_001.png" style="height: 3.5em"/></figure>
			<p class="normal">where <em class="italic">a</em><sub class="italic">i</sub> is the <em class="italic">i</em><sup class="italic">th</sup> actual value, <em class="italic">p</em><sub class="italic">i</sub> is its corresponding prediction, and <em class="italic">N</em> is—simply—the total number of points in your data set. RMSE gives us an immediate indication of the confidence interval we can use together with our prediction. Given its formula, the RMSE is also the standard deviation of the residuals: consequently, we can interpret it as the maximum error to expect in 68% of the predictions. To be on the safer side, we can multiply the<a id="_idIndexMarker351"/> RMSE by 2, obtaining broader intervals and an extended level of confidence: we can presume that our error will be lower than twice the RMSE 95% of the time. Let's imagine that we predict a car price to be $16,000 using a regression model with an RMSE of $1,200: we can state that we are 95% confident that the actual price of that car will lie between $13,600 and $18,400, which is $16,000 ± $2,400 (twice the RMSE). Of course, the lower the RMSE, the better the model, as we can boast narrower confidence intervals for our predictions.</p>
			<div>
				<div id="_idContainer141" class="packt_tip">
					<p class="Tip--PACKT-">Using RMSE to build confidence intervals is not always mathematically correct. In fact, this holds true only under the assumption that residuals follow a normal distribution (the typical Gauss bell curve), which might not always be the case. Still, it's a handy rule of thumb that I recommend keeping in mind when evaluating regressions.</p>
				</div>
			</div>
			<p class="normal">An alternative summary metric for evaluating the performance of regressions is the <strong class="keyword">Coefficient of Determination, </strong><em class="italic">R</em><sup class="italic">2</sup>. It can be <a id="_idIndexMarker352"/>calculated using the following formula:</p>
			<figure class="mediaobject"><img src="image/B17125_04_002.png" style="height: 3.0em"/></figure>
			<p class="normal">where we find, on top of the measures encountered above, <img src="image/B17125_04_003.png" style="height: 0.8em"/>, which is the average of the actual values. Look at the fraction in the formula: we are comparing the squared errors of our model (the same quantity we found in RMSE) with the square error of a <em class="italic">baseline</em> model, which would naively use as a constant prediction the average of the observed values. If our model is similar to this baseline, <em class="italic">R</em><sup class="italic">2</sup> will end up being close to zero, indicating that our model is quite useless. If, instead, our model generates much smaller errors than what the baseline does, then we obtain an <em class="italic">R</em><sup class="italic">2</sup> close to 1. In this case, the higher the <em class="italic">R</em><sup class="italic">2</sup>, the better. </p>
			<p class="normal">One intuitive way to interpret the coefficient of determination is to look at it as the proportion of the variation observed in our target variable, which is actually explained by the model. If in our car price prediction, we obtain <em class="italic">R</em><sup class="italic">2</sup>=0.75; we can say that our model, solely based on the age of the car, explains 75% of the variability in car price, leaving the remaining 25% unaccounted for. If we built a more accurate model or added some additional features, such as mileage and accessories, we will probably be able to explain a larger proportion of the price variability, and our <em class="italic">R</em><sup class="italic">2</sup> will get closer to 1.</p>
			<div>
				<div id="_idContainer144" class="packt_tip">
					<p class="Tip--PACKT-">There are no specific <em class="italic">R</em><sup class="italic">2</sup> reference thresholds that can always tell us if a model is "good" or "bad." Think about an apparently chaotic signal, such as the fluctuation of currency exchange rates. If we built a regression model that explained only 25% of the variability in future exchange rates, we could make a lot of money out of it! It's better not to fix static thresholds of <em class="italic">R</em><sup class="italic">2</sup>.</p>
				</div>
			</div>
			<p class="normal">Differently from RMSE, <em class="italic">R</em><sup class="italic">2</sup> is a <a id="_idIndexMarker353"/>dimensionless metric. This means that we can compare the goodness of regression models even if they predict values lying on different scales. For instance, we can compare a model predicting house prices (in the range of a hundred thousand dollars) with another model predicting motorbike prices (which are typically much cheaper), by juxtaposing their <em class="italic">R</em><sup class="italic">2</sup> values: the higher the <em class="italic">R</em><sup class="italic">2</sup>, the better.</p>
			<h2 id="_idParaDest-79" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor080"/>Classification</h2>
			<p class="normal">The job of classification<a id="_idIndexMarker354"/> algorithms is to assign each item of a data set to a class, predicting a specific value of the target variable. Out of all possible classes, only one is right and matches with reality. Hence, a simple way to measure the performance of a classifier will be to "count" the number of times the algorithm got it right out of the total number of predictions. However, this simple performance score might not tell us the full story. Let's see this concept come to life with an example.</p>
			<p class="normal">You want to assess the performance of an image classification model: however random this task might look (and—in all fairness—it does), the job of your binary classifier is to assign a label that differentiates the content of the image between dogs and muffins. When it comes to Chihuahua and blueberry muffins, your classifier struggles a bit, predicting the content as displayed in <em class="italic">Figure 4.7</em>:</p>
			<figure class="mediaobject"><img src="image/B17125_04_07.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.7: Is that a Chihuahua or a blueberry muffin? This classifier got it right 10 times out of 16.</p>
			<p class="normal">The table you find on the bottom left of <em class="italic">Figure 4.7</em> is <a id="_idIndexMarker355"/>called a <strong class="keyword">Confusion Matrix</strong>: it has the benefit of showing the full picture of the classification outcome, highlighting the number of instances where the classifier got "confused" and assigned the wrong label to the pictures. The confusion matrix counts all the combinations between any predicted class value (columns) and the reality, so the actual class (rows). The cells on the main diagonal will tell us how many times the classifier got it right, while all other cells count the errors. In this case, it looks like our model had an "unbalanced" performance as it had a harder time recognizing the dogs, while it was a bit more robust in spotting muffins. In the case of Chihuahuas and blueberry muffins we are not very worried about this asymmetry; however, in other cases, this might be a big deal, generating very different outcomes.</p>
			<p class="normal">Let's move on to a more serious case: a classifier<a id="_idIndexMarker356"/> that predicts whether a patient is infected by a contagious virus by analyzing a series of features coming from a blood test exam. Also in this case, there are two classes, positive and negative, and we have two different types of classification errors we can make. One is about assigning the class positive to a patient who, in reality, is healthy: this is<a id="_idIndexMarker357"/> called a <strong class="keyword">False Positive</strong>. The outcome of this error is that we communicate the result to the patient, who will immediately start a quarantine, and run some more accurate tests to confirm our findings. The other type of error we can make is when we assign the class negative to a patient who is actually infected by the virus: this<a id="_idIndexMarker358"/> is a <strong class="keyword">False Negative</strong>. Of course, the outcome of this error is much more impactful than the previous case: we would send the patient home, allowing a further spread of the virus due to the contamination of other people and failing to start any early treatment for the person. To summarize: not all errors are born equal when it comes to classification. As a consequence, one single number might not be enough to explain the full situation. That is why it is wise to calculate the confusion matrix and select among multiple metrics the most appropriate to your needs. Depending on the case you are solving, you should pick one of the summary metrics shown on the right-hand side of <em class="italic">Figure 4.8</em> as the most important one to assess performance with. Let's go through each of them:</p>
			<ul>
				<li class="bullet"><strong class="keyword">Accuracy</strong> is<a id="_idIndexMarker359"/> telling you the percentage of good predictions versus the total ones. When the type of error does not matter, you can use this "balanced" measure to explain the overall performance of a classifier. </li>
				<li class="bullet"><strong class="keyword">Precision</strong> will <a id="_idIndexMarker360"/>tell you how confident the classifier is when it labels a case as positive. You can use this metric when you need to avoid at all costs the situation where a case predicted to be positive turns out to be negative. If a very precise classifier tells you that a case is positive, it is most likely right.</li>
				<li class="bullet"><strong class="keyword">Sensitivity</strong> tells you <a id="_idIndexMarker361"/>how confidently the classifier can rule out the possibility that a positive case is not classified as such. You need to use this metric when you want to avoid false negatives. If a very sensitive classifier tells you that a case is negative, it is most likely right. Diagnostic classifiers in medicine are typically built so as to maximize sensitivity at all costs, as you want to be sure to send home without a cure only patients that are really negative.<div id="_idContainer146" class="note"><p class="Information-Box--PACKT-">The classes names positive and negative are just conventional. Depending on your case, you can decide which class is positive and calculate all the scoring metrics accordingly. In the case of more than two classes, it works like that: you select the single positive class, and then the metrics are calculated considering any other class as negative. It's just a convention.</p></div></li>
			</ul>
			<figure class="mediaobject"><img src="image/B17125_04_08.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.8: Assessing performance in classification: pick the metric that makes the most sense in your case</p>
			<p class="normal">With this, we have seen the most popular ways we can use to evaluate the performance of supervised learning predictors. Before building our first ML model, we need to go through one last fundamental concept and learn how to manage it: overfitting.</p>
			<h2 id="_idParaDest-80" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor081"/>Underfitting and overfitting</h2>
			<p class="normal">American mathematician John Nash received the 1994 Nobel Prize for Economics for his landmark work on game theory. His "Nash equilibrium" has become the foundation of how economists predict the outcome of non-cooperative strategic interactions. The story of John Nash has been popularized by the Academy Award-winning movie <em class="italic">A Beautiful Mind</em> starring Russell Crowe as Nash. In the movie, John Nash is portrayed in his life-long struggle with paranoid schizophrenia: his condition brought him to believe he had found "secret messages" hidden in the text of regular magazine articles, supposedly added by Soviet spies for covert communication. Perceiving meaningful connections between unrelated things is a typical tendency of early-stage delusional thought, a condition that psychiatrists call <em class="italic">apophenia</em>. Now, think about it: when you have (a lot of) data and (massive) computing power available, it is likely to fall into the trap of thinking that you have found some interesting patterns of general validity. In reality, you might have just found a spurious, random connection as a consequence of the vast extent of availability of resources.</p>
			<p class="normal">This will become clearer <a id="_idIndexMarker362"/>with an example: let's imagine we have a large database containing all sorts of information on the ticket holders of a nationwide annual lottery. We have two years of history available, and we want to use the information on the past two winners to predict the future ones by identifying the recurrent features. We decide to use a supervised ML algorithm to do so. After some heavy calculation, the algorithm comes up with a complex series of apparently "winning" rules that are shared only by the lucky winners of the two previous editions. </p>
			<p class="normal">These rules are like: <em class="italic">the 4</em><em class="italic">th digit of their telephone numbers is a 7</em>, <em class="italic">their ticket numbers include exactly 3 odd digits</em>, <em class="italic">they were born on a Tuesday</em>, and many others. Clearly, these rules are not going to be able to predict anything meaningful: they are just artificially "connecting" two specific points through a series of meaningless factors that happen to be in common for the winners. As the example shows, when the haystack is large enough, it is easy to find something very similar to a needle! Similarly, when you have a massive amount of data, if you look long enough, you can find any connection, although this doesn't make it meaningful. This is comparable to the apophenia condition we encountered in John Nash's story. We need to avoid at any cost falling into this trap of "analytical fallacy": it is just a deception caused by our desire to find connections at all costs, even if they do not actually exist, by using artificially overcomplicated models. This condition is called <strong class="keyword">overfitting</strong>, and it's a <a id="_idIndexMarker363"/>problem that can potentially arise when attempting any prediction. Hence, we need to systematically avoid it when building a supervised ML model which generates predictions.</p>
			<p class="normal">Let's see overfitting in action in our car price example. <em class="italic">Figure 4.9</em> shows the Polynomial Regression for different degrees, represented by the parameter <strong class="keyword">N</strong>.</p>
			<figure class="mediaobject"><img src="image/B17125_04_09.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.9: Regression models to predict car prices with different polynomial degrees N. Which one would you pick?</p>
			<p class="normal">As <strong class="keyword">N</strong> grows from 1 to 5, the fitting line shows a more convoluted path: this signifies that the underlying model becomes more complex. By looking at the three curves, we can notice the following:</p>
			<ul>
				<li class="bullet">When <strong class="keyword">N = 1</strong> (dotted line), our model is exactly the same as the simple Linear Regression model we encountered earlier. Although it is a good starting point, it looks a bit too "simple" as it fails to consider the stronger devaluation of car prices happening in the first few months of age.</li>
				<li class="bullet">When <strong class="keyword">N = 3</strong> (dashed line), we get a more encouraging fit, as we clearly see a stronger erosion of price in the early life of a car and a subsequent flattening of the curve. This looks solid, as it is in line with what our business understanding suggests.</li>
				<li class="bullet">When <strong class="keyword">N = 5</strong> (continuous line), we have a nearly perfect fit with the existing points. However, this sounds "too good to be true" and, indeed, the shape of the curve is artificially built in a way that meets the points, without providing solid modeling of the price evolution over age. There are some weird bumps like the one happening at around 1.5 years of age, where the price is supposed to be inexplicably higher than what we have with new cars. It looks like we have just "forced" the curve to touch the few "past" points, which is a short-sighted objective. Instead, our real purpose was to find a robust model able to predict the price of the "next" cars coming to market.</li>
			</ul>
			<p class="normal">From this example, we can start seeing that the level of complexity of a supervised model needs some finetuning: if the model is too basic, its predictive performance will be necessarily low. On the other extreme, if the model is too complex, we might have just "connected the previous dots": we end up in the delusional state of weaving together coincidences into an apparent general pattern.</p>
			<p class="normal">Let's build on this concept by bringing an additional supervised example: this time, we deal with classification. As you can see in <em class="italic">Figure 4.10</em>, you have a number of elements on a plate that could be either dots or crosses. You want to predict their class (being a dot or a cross) based on their position by drawing a continuous line that differentiates across elements, leaving<a id="_idIndexMarker364"/> dots on the top-right side of the plate and crosses on the bottom-left side. By applying a non-linear <strong class="keyword">Support Vector Machine</strong> (<strong class="keyword">SVM</strong>) learning algorithm, you obtain three different curves of progressively increasing complexity.</p>
			<figure class="mediaobject"><img src="image/B17125_04_10.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.10: We want to draw a line able to differentiate dots (top-right side) and crosses (bottom-left side). Misclassified elements are in darker gray. Which line is likely to do the job better with future elements?</p>
			<p class="normal">Let's have a look at the three cases:</p>
			<ul>
				<li class="bullet">The model on the<a id="_idIndexMarker365"/> left<strong class="keyword"> </strong>is a straight line that looks like a very rudimentary way to differentiate between dots and crosses. It seems that we are consistently missing some dots in the middle area of the chart, which happen to be just outside the region where they should. Overall, our accuracy level is near 75%, as we made 12 misclassifications.</li>
				<li class="bullet">The model in the middle is slightly more complex than the previous one but also more accurate (only six errors this time). The curvature we now have on the line accounts well for the dots we were consistently missing before. Intuitively, the six misclassifications we made (they are in darker gray in the picture) look more like "exceptions": the curved line seems close to a general rule that is likely to repeat in the future when new elements will land on the plate.</li>
				<li class="bullet">The model on the right is apparently the best: it nailed the class of all elements on the plate, reaching an accuracy of 100%. However, this complex model is unlikely to have a general validity: the curve is zigzagging through the current elements to avoid any misclassification, but we can expect that, if new elements show up, they will be misclassified as a consequence of all these artificial bends.</li>
			</ul>
			<p class="normal">These examples have illustrated an important property of supervised ML: if we want to build models that perform well in predicting "future" cases, we need to strike the right balance of complexity when learning. We can recognize three cases, as summarized in <em class="italic">Table 4.1</em>. Let's go through each of them, starting from the extremes:</p>
			<ul>
				<li class="bullet"><strong class="keyword">Underfitted</strong> <strong class="keyword">models</strong>. Like in the <a id="_idIndexMarker366"/>Polynomial Regression with <strong class="keyword">N = 1</strong> and the first plate of the classification, an underfitted model is just not good enough to predict anything. This naïve model will generate large error rates (higher residuals or many misclassifications) even when asked to fit the known data points. As a logical consequence, we cannot expect the same model to magically start working well on future cases: this makes underfitted model pretty useless for making any prediction.</li>
				<li class="bullet"><strong class="keyword">Overfitted models</strong>. These <a id="_idIndexMarker367"/>models sit at the opposite extreme of underfitted models and are as bad as the former. The mathematical complexity of the model lets it adapt very well to known data points, introducing unrealistic elements like the many bumps of the regression with <strong class="keyword">N = 5</strong> or the zigzags across elements in the classification. We "believe" to have reached a high level of accuracy, but this is just a self-inflicted delusion: whenever new points arrive, our accuracy level will dramatically drop as a consequence of those artificial complexities we have allowed.</li>
				<li class="bullet"><strong class="keyword">Well-fitted models</strong>. As for<a id="_idIndexMarker368"/> many other things in life: <em class="italic">virtue lies in the middle ground</em>. Well-fitted models will be less accurate than overfitted ones when fitting data points. However, given the limitations they had in capturing the complexity of a phenomenon, they will tend to focus on the (fewer) connections that matter most, ignoring the excessively complex paths that fitted models used. Well-fitted models are best suited for predicting the "unknown," which is exactly the point of why we wanted to build a supervised model.</li>
			</ul>
			<table id="table001-3" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p class="Table-Column-Heading--PACKT-">Underfitted</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Heading--PACKT-">Well-fitted</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Heading--PACKT-">Overfitted</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="Table-Column-Heading--PACKT-">Model complexity</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">Low</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">Mid</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">High</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="Table-Column-Heading--PACKT-">Performance on past cases</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">Low</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">Mid</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">High</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="Table-Column-Heading--PACKT-">Performance on future cases</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">Low</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">Mid</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">Low</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p class="Table-Column-Heading--PACKT-">Description</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">The model is too naïve, and the resulting predictions are not accurate. It is unable to describe well the modeled phenomenon.</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">The model is well balanced. It grasps patterns of general validity that are likely to repeat in future cases.</p>
						</td>
						<td class="No-Table-Style">
							<p class="Table-Column-Content--PACKT-">The model is complex and works well only on the very specific points used to learn. It is unable to predict the outcome of future cases.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="packt_figref">Table 4.1: Typical characteristics of under-, well-, and overfitted models.</p>
			<p class="normal">The good news is that ML models can be "tuned" for complexity by changing a set of values, called <strong class="keyword">Hyperparameters</strong>, that <a id="_idIndexMarker369"/>modulate their learning behavior. For example, in the Polynomial Regression, <strong class="keyword">N</strong> is nothing more than a hyperparameter of the model: by making <strong class="keyword">N</strong> vary from 1 to 5 (or more), we can control how complex the model is and, by making some attempts, we can try to find the well-fitted level. We will learn about hyperparameters more when talking through the specific learning algorithms later in the book.</p>
			<div>
				<div id="_idContainer150" class="packt_tip">
					<p class="Tip--PACKT-">Another way to reduce the complexity of a model is to reduce the number of features. The fewer the features, the simpler the model, and the lower the chances to overfit. This is another motive for doing dimensionality reduction, one of the unsupervised scenarios we have previously introduced.</p>
				</div>
			</div>
			<p class="normal">Now we are clear on the pathological condition of overfitted models: it's time to move on and talk about how to diagnose it and what a possible cure can look like.</p>
			<h2 id="_idParaDest-81" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor082"/>Validating a model</h2>
			<p class="normal">By looking<a id="_idIndexMarker370"/> once again at <em class="italic">Table 4.1</em> and, more specifically, at its third row, we find that the only way to spot a well-fitted model is to evaluate its performance on "unseen" samples. Both under- and overfitted models will underperform versus a well-fitted model when it comes to the level of accuracy of future cases. But what if we do not yet have any future cases to use for this purpose?</p>
			<p class="normal">A fundamental "trick" we use in supervised ML is to randomly split the data set of known samples into two subsets: a <strong class="keyword">training set</strong>, which <a id="_idIndexMarker371"/>normally covers 70 to 80% of the original data, and<a id="_idIndexMarker372"/> a <strong class="keyword">test set</strong>, which keeps the remainder of the data. <em class="italic">Figure 4.11</em> shows this operation, called <strong class="keyword">Partitioning</strong>, in action. Then, we use <em class="italic">only </em>the training set for<a id="_idIndexMarker373"/> performing the actual learning, which will generate the model. Finally, we will evaluate the model's performance on the test set: this is data that the algorithm has <em class="italic">not</em> seen yet when learning. This means that, if the model grew overcomplex by creating many bumps and zigzags to adapt to the training set, we would get low-performance scores on the test set. In other words, if the model is overfitted to the training set, then it will perform very badly on the test set. With this trick, we have assessed the accuracy of "future" samples without doing any time travel!</p>
			<figure class="mediaobject"><img src="image/B17125_04_11.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.11: Partitioning a full set in training and test subsets. Rows are randomly sampled and distributed to the two subsets, according to the desired proportion</p>
			<p class="normal"><em class="italic">Figure 4.12</em> shows the<a id="_idIndexMarker374"/> expected amount of prediction error in test and training sets by increasing levels of complexity. The amount of error obtained on the samples included in the training set can be lowered progressively by working on the hyperparameters of the model in a way to increase its complexity. For example, in the Polynomial Regression case, as we move from left to right, we are growing the value of <strong class="keyword">N</strong>: with a high-complexity model (<strong class="keyword">N = 5</strong>, we are on the far right), the error of the training line is almost zero. If you look at the error calculated on the test set (the U-shaped curve), you will face the reality and recognize that the true predictive power of the model is much lower: only a well-fitted model can ensure good performance on "unseen" data points.</p>
			<figure class="mediaobject"><img src="image/B17125_04_12.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.12: The amount of error produced by a supervised ML model as complexity grows: for the test set, it follows a U-shaped curve</p>
			<h2 id="_idParaDest-82" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor083"/>Pulling it all together</h2>
			<p class="normal">We finally have all the ingredients for building and validating a well-fitted supervised ML model. Let's see now what the recipe looks like. We can visualize a recurrent "structure" made of four fundamental blocks that collectively define our basic flow for supervised learning:</p>
			<ol>
				<li class="numbered"><strong class="keyword">Partitioning</strong>. To avoid<a id="_idIndexMarker375"/> overfitting, we need to leverage a validation mechanism that prevents us from scoring a model on the same data used for learning. Thus, the first step we always do in supervised learning is to partition the full set of labeled data points to obtain a training and a test data set. In most cases, the split happens through random sampling.</li>
				<li class="numbered"><strong class="keyword">Learner</strong>. The <a id="_idIndexMarker376"/>training data set can be used to train a model by leveraging the learning algorithm. The output of this operation will be the statistical model (defined through a set of parameters), which can be applied to different data so to obtain a prediction.</li>
				<li class="numbered"><strong class="keyword">Predictor</strong>. We <a id="_idIndexMarker377"/>can now "run" the model learned in the previous step on the test set, which has been kept out of the training process. The output of the predictor will be the test set enriched with an additional column: the predicted value of the target for each row.</li>
				<li class="numbered"><strong class="keyword">Scorer</strong>. The <a id="_idIndexMarker378"/>output of the predictor contains <em class="italic">both</em> the observed target (the actual value we aimed at predicting) and its model-generated prediction. By comparing the values of these two columns, we can assess the performance of the prediction. It will be enough to calculate one or more summary metric scores, like the ones we introduced a few pages ago, like RMSE, <em class="italic">R</em><sup class="italic">2</sup>, sensitivity, or the full confusion matrix.</li>
			</ol>
			<p class="normal">That's it! By following this logic flow, described in <em class="italic">Figure 4.13</em>, you can build a supervised model and assess its true performance, avoiding the risk of overfitting.</p>
			<figure class="mediaobject"><img src="image/B17125_04_13.png" alt=""/></figure>
			<p class="packt_figref">Figure 4.13: The typical flow for validating a supervised ML model. To prevent overfitting, you need to partition the data, learn on the training portion, and finally predict and score on the test partition only.</p>
			<p class="normal">Of course, once you have a validated model, you can confidently apply it to all "future" data points, finally unlocking the real value of ML predictions. Let's take the example of the second-hand cars price prediction: you used your full database containing the historical sales to build and validate a model. Once you have a validated model and you are sure it does not overfit, you are ready for prime time: every time you need to estimate the price of a car, you can now execute the model on the car's features and obtain the predicted price. Of course, this time, you will not have the "real value" to compare it with, but you can use the confidence interval of your prediction (like the RMSE for regression) to anticipate the range of expected errors you are going to get.</p>
			<p class="normal">It's worth spending a few last thoughts on the flow portrayed in <em class="italic">Figure 4.13</em>: this is the "base" process you can adopt when building and validating a supervised ML model. Many improvements can be incrementally applied to make your models better and better. Just to give you some perspective on the many additions we can make, let's mention a few that leverage iterations for improving the process:</p>
			<ul>
				<li class="bullet">The partitioning trick has some limitations: for example, if you have a relatively small data set to start from and hold 30% out from learning, you might end up with an inadequate validation since the model had too few points to learn from. One alternative route, called <strong class="keyword">k-Fold Cross Validation</strong>, is to split your full set into k folds (usually 5 or 10) and <a id="_idIndexMarker379"/>iterate multiple times, using each fold as a test set to be held out each time. In the end, you will get k different models and scores. By averaging them out, you will obtain a much more robust validation than having just a one-off partitioning.</li>
				<li class="bullet">As we saw earlier, you can "tune" the hyperparameters of a model to maximize the performance score obtained on the test set (which will, in turn, ensure maximum accuracy on the future predictions and prove the general validity of your model). You can loop through different hyperparameters, managing them as variables, and spot the set of values that put you at the bottom of the U-shaped curve we saw in <em class="italic">Figure 4.12</em>. This procedure is called <strong class="keyword">Hyperparameter optimization</strong> and <a id="_idIndexMarker380"/>can be implemented by using loops and variables.</li>
				<li class="bullet">As mentioned before, if you have uninformative or redundant features in a data set, your model will be unnecessarily complex. There are many techniques used for identifying the best subset of features to use in your learning: they go under the general name<a id="_idIndexMarker381"/> of <strong class="keyword">Feature Selection</strong>. One simple iterative technique for selecting features is <a id="_idIndexMarker382"/>called <strong class="keyword">Backward Elimination</strong>: you start with having all features selected. Then, at each iteration, you remove one feature—the one that induces the smallest decline (or the biggest increase) of performance if removed from the set. At some point, you will have "tried" multiple combinations of features, and you can pick the one that maximizes the overall predictive performance.</li>
			</ul>
			<p class="normal">These are just some of the many possible techniques you can use and creatively combine to improve the quality of your modeling. Hopefully, this shows you a hint of the fascinating reality of the world you are getting into: the practice of ML is a mix of art and science, and you can always look for some more ingenious ways to squeeze incremental value from data and algorithms.</p>
			<h1 id="_idParaDest-83" class="title"><a id="_idTextAnchor084"/>Summary</h1>
			<p class="normal">In this chapter, you were introduced to the fundamental concepts behind machines that can learn from data. After stripping away the futuristic gloss of AI, we went through a series of practical business scenarios where we saw intelligent algorithms at work. These examples showed us how, if we look carefully, we can often recognize occasions to leverage machines for getting intellectual work done. We saw that, as an alternative to the traditional mode of operating, there is an ML way to get things done: whether we are predicting prices, segmenting consumers, or optimizing a digital advertising strategy, learning algorithms can be our tireless companions. If we coach them well, they can extend human intelligence and provide a sound competitive advantage to our business. We explored the differences among the three types of learning algorithms (supervised, unsupervised, and reinforcement) and understood the fundamental drivers that can guide us in selecting which algorithms to use. We have then learned what needs to happen to build a robust predictive model and properly assess its performance while staying away from the menace of overfitting. It was a long journey in the captivating world of statistical learning, but, as promised, we didn't need to go through many formulas or complex math. This chapter enabled you to get the intuition behind the vital concepts of ML so that you can move quickly to practice and keep learning while doing.</p>
			<p class="normal">It's now time to put our hands back onto KNIME and build (and validate) a few ML models based on real-world data: get ready because this is what the next chapter is all about.</p>
		</div>
	</body></html>