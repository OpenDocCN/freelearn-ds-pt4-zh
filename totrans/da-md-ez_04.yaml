- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is Machine Learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Autonomous self-driving cars, ultraprecise robot surgeons, impeccable virtual
    assistants, fully automated financial traders: some of the most promising AI applications
    seem more like sci-fi material than prospects to an imminent reality. We could
    fill entire books by just collecting and presenting sensational stories of algorithmic
    wonders. If we manage—instead—to keep both feet firmly on the present ground and
    recognize how intelligent algorithms can *already* support our everyday work needs,
    then we start unlocking tangible value for us and our business. This is what this
    chapter is all about: stripping away the myth from reality by meeting in person
    the main machine learning algorithms and techniques. The end objective is to start
    counting on them as everyday companions rather than out-of-reach, futuristic possibilities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will find answers to the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What are AI and machine learning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the "machine learning way" to solve business problems? What's the difference
    between this approach and the traditional approach?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can machines learn? Which algorithms are available out there for making
    this happen? How do they work?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What tradeoffs do I need to consider when selecting the right model for my business
    need?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I assess the performance of a machine learning solution?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although this chapter is the most "analytical" one of the book, you will find
    only a handful of math formulas involved. The point is to give you an intuitive
    understanding of how machine learning works versus providing the whole theoretical
    background behind it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Think about it: you don''t need to be a mathematician to use math, and you
    don''t have to become a computer scientist or an expert coder to use a computer!
    Similarly, the next few pages will not make you able to recreate from scratch
    full modeling procedures: it will, instead, show you how to utilize the ones that—spoiler
    alert—are already conveniently implemented in software platforms like KNIME. In
    this chapter, we will learn the unmissable foundations needed to make you a user
    of machine learning, while in the next one, we will put them into practice using
    KNIME nodes through full tutorials. You might be impatient to jump into the practice,
    but I strongly recommend you go through this chapter first and feel confident
    about it before moving on. Buckle up: let''s talk AI!'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing artificial intelligence and machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Can machines think?* This is what English polymath and wartime codebreaker
    Alan Turing asked himself in his seminal 1950 paper that would lay the groundwork
    for AI. Although Turing does not use the term "artificial intelligence" (it would
    be introduced as a research discipline only six years later), he was convinced
    that machines would eventually compete with human beings in *all purely intellectual
    fields*.'
  prefs: []
  type: TYPE_NORMAL
- en: Using technology devices to extend and partially replace human intellect was
    not a new quest. Back in the 17th century, French mathematician and philosopher
    Blaise Pascal invented the **Pascaline** (*Figure 4.1*), a fully working mechanical
    computer that could do addition and subtraction of numbers entered by rotating
    its dials.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: Pascal''s arithmetic machine, a.k.a. the Pascaline. From the top
    left, clockwise: an original device built in 1652; a view of the underlying system
    of gears; the detailed plan of the sautoir, the ingenious mechanism enabling the
    carryover in additions. The photograph is by Rama, Wikimedia Commons, Cc-by-sa-2.0-fr.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating mathematical operations is a very specific intellectual task. Still,
    the Pascaline was early proof that technology can replicate and amplify people''s
    capacity to do brain work, not just physical activities. This is what AI is all
    about: **Artificial Intelligence** (**AI**) is defined as the ability of machines
    to perform actions that display *some* form of human intelligence, such as solving
    logical problems, using language to communicate, recognizing visual and auditory
    patterns, making sense of the environment, or coordinating physical movements.
    Within the broader field of AI, **Machine Learning** (**ML**) focuses on the artificial
    replication of a *specific* aspect of human intelligence: the ability to learn.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The faculty of learning has immense potential value when applied to any business.
    If a machine can autonomously learn from data for us, we can use it to consistently
    grow our knowledge on customers, competitors, and our own operations. We can reduce
    costs, simplify processes, grow revenue thanks to better decisions, proactively
    prepare for the future, and even improve the experience—and so the loyalty—of
    our customers. ML algorithms are tireless partners in growing our business: they
    can extend our team''s overall intelligence, leveraging the extensive computational
    capacity of digital technology (which gets increasingly cheaper over time) and
    the massive amount of data that would be otherwise largely lying unused in a corporate
    database. The strong potential of autonomous learning explains why, in the last
    few years, ML has grown so much in popularity to unseat its conceptual parent,
    AI, as the trendiest technology phenomenon on everyone''s lips. Today, AI and
    ML are often used as synonyms, and in the rest of the book, we will primarily
    refer to the latter. To avoid confusion in your further readings, just remember:
    AI looks at the full scope of human intelligence, ML concentrates on the autonomous
    learning bit.'
  prefs: []
  type: TYPE_NORMAL
- en: An **Algorithm** is a problem-solving procedure or, in other words, a series
    of pre-defined steps that can be followed to solve a specific task. The steps
    required by a machine to multiply two numbers or to make a prediction based on
    previous values are both examples of algorithms. Computers are often able to solve
    complex problems, provided that a human equips them with the right algorithm to
    follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'One important clarification is needed on the nature of the tasks that we can
    solve with AI and the classification that derives from it. In fact, researchers
    postulate the existence of two types of AI: strong and weak:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Strong AI** (or **AGI**, **Artificial General Intelligence**) is the hypothetical
    aptitude of machines to potentially understand and execute *any* intellectual
    task. A strong AI would autonomously "understand what''s needed" and then "go
    for it," even displaying those features that make us human, such as consciousness,
    self-awareness, creativity, intentionality, and sentience. However fascinating
    (and scary) the concept of strong AI appears, today it still mainly falls into
    the realm of theoretical speculation or fictional exploration. Many researchers
    argue that AGI is decades away, while some believe it will never become a reality.
    In any case, we are not going to investigate it further in this book: here we
    will focus, instead, on the other type of AI, which is undoubtedly more in reach.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weak AI** refers to machines'' ability to solve *pre-determined* and specific
    tasks, like predicting future sales, anticipating the behavior of a user in a
    given situation, or unveiling ways to optimize a particular business process.
    To make weak AI happen, there is always a fundamental role for human operators
    to play when setting things up: algorithms will need to be guided to the problem
    to solve and initially tweaked for operating at their best. In the upcoming part
    of the book, we will learn how to do precisely that: to make AI drive value in
    our everyday work, by setting up the right algorithms in the right way, so as
    to make them operate at best for our advantage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since strong AI is nowhere close to us and weak AI is clearly dependent on
    the people that set it up correctly, one thing is clear: humans and machines are
    not in conflict with each other, fighting for supremacy in the workforce arena
    and protecting their jobs. Actually, it is quite the opposite: the magic happens
    when humans collaborate with machines by "coaching" them properly in their learning
    endeavors. When this happens, intelligent machines show their full value, ultimately
    benefitting their human companions. Having this in mind, let''s start to learn
    how to coach the AI properly, by recognizing the business situations where the
    right algorithm can make the difference.'
  prefs: []
  type: TYPE_NORMAL
- en: The machine learning way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Ironically, one of the foremost barriers preventing the exploitation of ML
    in a business is neither the implementation of the algorithm nor the retrieval
    of the data (the *how*): the toughest part is to recognize the right occasion
    to use it (the *why*)! We need to identify within the complex map of business
    processes (the operating model of the company) the specific steps where algorithms
    can bring real value if adopted. If we develop our sensitivity to recognize such
    leverage points, then we will be able to find in our work the first opportunities
    to put ML into practice.'
  prefs: []
  type: TYPE_NORMAL
- en: There is a machine learning way (we can call it the **ML way**) to operate business
    processes. Let's go through three sample scenarios to distinguish between the
    traditional and the ML ways to create value with data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scenario #1: Predicting market prices'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You work for a car dealership, specializing in multibrand, used vehicles. You
    notice that some cars take much longer to sell because their initial listing price
    was too high versus customers'' expectations. To improve this situation, you want
    to implement a technical solution to guide the price-setting process in a data-based
    manner: the objective is to anticipate the actual market price of each car to
    keep inventory under control while maximizing revenues.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are two possible approaches to solve this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The traditional way is to codify a set of rules that define how the car''s
    features impact the market price and build a "calculator" that implements these
    rules. The calculator will leverage a mix of available data points (like the starting
    price of new cars by brand and model, or the cost of accessories) and some thumb-rules
    defined thanks to common sense and to the expertise of those who have been for
    some time in the business. For example, some rules can be: *the car depreciates
    by 20% during its first year and then by an additional 15% every further year
    of age*, or *cars that run for more than 10,000 miles/year are high-mileage and
    their value is reduced by a further 15%*, and so on. To build this calculator,
    you will need to implement these if-then rules using a programming language, which
    means that you also need a programmer to develop and maintain the code over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The ML way is to get an algorithm to analyze all the data related to previous
    sales and autonomously "learn" the rules that connect the car features (like mileage,
    age, make, model, accessories, and so on) with the actual price at which the car
    sold. The algorithm can identify some recurrent patterns, which are partly confirming
    the rules we already had in mind (maybe adding a further level of precision to
    those approximate thumb rules), and partly identify new and unexpected connections,
    which humans failed to recognize and summarize in a simple rule (like, for instance,
    *model X depreciates 37% more slowly when equipped with this rare optional*).
    Using this approach, the machine can keep learning over time: the rules underlying
    the price will evolve and get automatically updated as new sales happen and new
    car models enter the market.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main difference is that in the traditional approach, our price prediction
    will leverage the existing human knowledge on the matter (if adequately documented
    and codified), while the ML way provides for that knowledge (and possibly more)
    to be autonomously learned from data by the machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scenario #2: Segmenting customers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You work in the marketing team of a local supermarket chain. You are responsible
    for preparing a weekly newsletter to be sent to those customers who signed up
    for the loyalty program and opted in to receive emails from you. Instead of sending
    a one-size-fits-all newsletter to everyone, you want to create a reasonable number
    of different versions and distribute them accordingly to the various groups. By
    selecting key messages and special offers that are closer to each group's needs,
    you aim to maximize the engagement and loyalty of your entire customer base.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are at least two ways to create such groups:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The traditional way is to use common sense and your existing knowledge to select
    the features that can reasonably discriminate across different types of customers,
    each having a more specific set of needs. For instance, you can decide to use
    the age of household members and average income level to define different groups:
    you will end up with groups like the *affluent families with children* (to whom
    you might talk about premium-quality products for kids) and *low-income 60+ empty
    nesters* (more interested in high-value deals). This traditional approach assumes
    that the needs within each group—in this case, solely defined by age and income—are
    homogeneous: we might end up ignoring some meaningful differences across other
    dimensions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ML way is to ask an algorithm to identify for us a number of homogeneous
    groups of customers that systematically display similar shopping behavior. Not
    being restricted by the cognitive capacity of humans (who would struggle to take
    into account dozens of variables at once) and their personal biases (driven by
    their individual and specific experiences), the algorithm can come up with groups
    that are specific and more closely connected to the actual preferences of each
    customer, like *food lovers who shop at the weekend* (to whom we might send some
    fancy recipes every Saturday morning) and *high-income pet owners* (wanting to
    take care of their beloved furry companions).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traditionally, we would differentiate actions by considering apparent—and, sometimes,
    naïve—differences, while the ML way goes straight to the core of the matter and
    identifies those homogeneous groups that best describe the diversity of our customer
    base, keeping everyone included and engaged.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scenario #3: Finding the best ad strategy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You work in the digital marketing department of a mid-sized company providing
    online photo printing services. Your responsibility is to define and execute digital
    advertising campaigns with the ultimate objective of maximizing their return.
    Instead of having a single campaign based on the same content, you want to optimize
    your strategy by testing different digital assets and seeing what works best.
    For example, you might have banners showing different products (like photo books
    and cheesy mugs with a portrait on them), various colors and fonts, or alternate
    versions of the tagline text. You can post your ads on social media and search
    engines, and you can control the available budget and duration of each test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also in this case, we can recognize two possible approaches to make this happen:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The traditional way is to run the so-called A/B/n testing: you define several
    alternative executions (for instance, three similar ads with the same graphic
    but three different call-to-action texts like *buy me now*, *check it out*, or
    *click to learn more*), run each of them—let''s imagine—10,000 times, and calculate
    their individual return by counting, for example, the number of orders generated
    by each execution. You will need to repeat the test over time to check if it''s
    still valid and, if you want to optimize across other dimensions (like the time
    of day at which the ad is served, or the location of users, and so on) you will
    end up with a growing number of combinations to test (and a larger cost of the
    experiment).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The ML way is to let an algorithm dynamically decide what to test and how,
    moving progressively toward the path leading to the best combinations of variable
    aspects. At first, the algorithm will start similarly as in an A/B/n test, trying
    some random combinations: this will be enough to grasp some first knowledge on
    the most promising directions to take. Over time, the algorithm will focus its
    attention (and budget) more and more on the few paths that are working best, finetuning
    and enriching them with an increasingly larger number of factors. In the end,
    the algorithm might end up with some very specific choices like *use a pink font
    and display a photo mug for people in their 50s who are connecting through a laptop*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In both approaches, we have used tests to learn what the best ad strategy was.
    However, in the traditional A/B/n testing approach, we had to define test settings
    based on prior knowledge and common sense. In the ML way, we put the machine in
    the driving seat and let it interact with the environment, learn progressively,
    and dynamically adjust the testing strategy, so as to minimize costs and get higher
    returns.
  prefs: []
  type: TYPE_NORMAL
- en: The business value of learning machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'These three scenarios unveil some recurrent differences between the traditional
    and the ML way to operate business processes. Let''s have a look at the incremental
    benefits we get from ML:'
  prefs: []
  type: TYPE_NORMAL
- en: Both approaches rely on technology and data, but the ML way leverages them *more
    extensively*. Suppose you allow algorithms to explore the full information content
    of a large database. In that case, you capitalize on the massive horsepower of
    digital technologies and avoid hitting the bottleneck of human cognitive limitation.
    With ML, more data will be considered at once (think about the many attributes
    of customers to be segmented or the factors that differentiate digital ads), which
    is likely to end up in better business outcomes. In other words, the ML way tends
    to be **more accurate and effective** than traditional approaches, leading to
    an economic advantage for the company relying on it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once it is correctly set up, the ML way can operate *independently* and with
    *minimal supervision* from its human companion. This means driving automationof
    intellectual tasks and, as a result, incremental **efficiency** and productivity
    for the business. Because of this automation, ML algorithms can stay **always
    on** and keep learning unceasingly on a 24/7 schedule. This means that they will
    get better and better at what they do over time, as more data comes in, without
    necessarily having to invest in further upgrades or human improvements. Think
    about the new car models appearing in the market or the evolving preferences of
    customers served by a digital ad: algorithms will observe reality vigilantly,
    spot trend breakers, and react accordingly to keep the business going.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The traditional approach relies on *previous* human knowledge while the ML
    way generates *additional* knowledge. This is a game-changing and fascinating
    benefit of ML called **Knowledge Discovery**: learning algorithms can provide
    a better and sometimes insightful understanding of reality (think about the subtle
    rules that explain car price formation, or the unexpected connections pulling
    together consumers in homogeneous groups) that can''t be spotted by just looking
    at the data. It is the capacity to *hack* reality by finding unexpected patterns
    in the way things work. If the learning algorithm provides for its outcome to
    be humanly intelligible (and many of them do), this knowledge will go and accrue
    to the overall know-how of the organization in terms of customer understanding,
    market dynamics, operating model, and more: this can be as valuable as gold, if
    used well!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making processes more efficient and effective, plus systematically acquiring
    an additional understanding of the business, these benefits by themselves are
    enough to explain why ML is currently exploding in modern business, making it
    a competitive advantage that nobody wants the risk of not having. Let's now meet
    the types of algorithms that can enable all of this.
  prefs: []
  type: TYPE_NORMAL
- en: '**Three types of learning algorithms**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The scenarios we have seen in the previous section were not selected at random.
    They match the standard categorization of ML algorithms that provides for three
    fundamental types: **Supervised Learning**, **Unsupervised Learning**, and **Reinforcement
    Learning**. When we want to apply the ML way, we need to select one of these three
    routes: our choice will depend on the nature of the problem we need to solve.
    Let''s now go through each group to understand what they are made of and what
    types of tasks they fulfill.'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In supervised learning, your objective is to predict something "unknown" by
    learning from some "known" pieces of information. The easiest way to make sense
    of the supervised learning approach is to think about how it differs from traditional
    programming. In *Figure 4.2*, you will find on the left a very familiar setup.
    In plain computer programming, we need some input *data*, a *program,* and a *computer*
    to generate some *results*. The program is a series of instructions—described
    in a machine-intelligible idiom, called the **Programming Language**—which the
    computer will apply to the input data to return the desired results as an output.
    In supervised ML, we keep all these four elements (data, program, computer, and
    results) but change the order of two of them. As you can see from the right part
    of *Figure 4.2*, in supervised learning, you give data and results—as inputs—to
    a computer that will return—as output—the program that "connects" the results
    to the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: Traditional programming compared with the supervised ML approach.
    The ingredients are the same, but the order differs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'What empowers the computer to make this "magic" happen is the supervised ML
    algorithm: this algorithm is a series of steps that can find out the set of transformations
    (mathematically described as a **Statistical Model**) that you can apply to some
    input data to obtain something close to the desired results. Thanks to these algorithms,
    the computer will "learn" from past data (for which we know the results) to unveil
    the approximate mechanism connecting input data to the unknown results.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This will be even clearer if we apply it to **Scenario #1** introduced in the
    *The Machine learning way* section: the car price predictions. In this case, our
    input data is the known attributes of the cars sold in the past. The result that
    we want to get is the price of those cars. If we leverage the supervised ML approach,
    we can use our known *past data* (features of previously sold cars) and *past
    results* (previous sale prices) to infer such transformation steps (the *program*,
    or model) that, once applied to *future data* (features of the next cars to be
    sold), will return the *future results* (predicted prices). In this setup (see
    *Figure 4.3*), the ML algorithm is implemented in the **Learner** block. The **Predictor**
    block will just "execute" on new data points from the program that is provided
    by the learner block.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: Supervised ML in action: learning from previously sold cars to
    understand the unwritten rules of how the features of the cars define their prices'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to the supervised ML algorithm, which empowers the learner, we can find
    out the "hidden rules" of price formation. Ferraris will have a much higher starting
    point and follow a different price decay over time than Fiat 500s: the algorithm
    will find those rules out.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to recognize that in supervised learning, you always have a
    specific measure to be predicted: this is called the **Target** (or **Dependent**
    variable). In the previous example, the price of the car was the target variable
    of our learning. All other variables—the ones used to predict what the target
    will be—are called **Features** (or **Independent** variables). The model and
    the age of cars in *Figure 4.3* were the two features used in the learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When input data is enriched with "results" (also known as **labels**), it is
    called **labeled data**. For simplicity, think about this: a labeled data table
    will always have multiple columns containing the features and a specific column
    containing the target. Labeled data is an unmissable ingredient of supervised
    ML.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the nature of the target variable, you can identify two scenarios
    of learning, which require different learning algorithms within the supervised
    family:'
  prefs: []
  type: TYPE_NORMAL
- en: When the target variable is a numeric measure (like *5.21* or *$23,000*), then
    you need a **Regression** algorithm. Linear Regression is the easiest and most
    common example of algorithms able to predict numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the target variable is a categorical measure (like a string of text indicating
    to which category or class an element belongs), you will need a **Classification**
    algorithm. Examples of classes are *red*, *blue*, and *green*, or binary categories
    like *true* and *false*, or labels identifying a specific behavior, such as *will
    buy this product* and *will not buy this product*. Decision Trees, Random Forests,
    and Support Vector Machines are just some of the many algorithms available to
    you when you want to predict to which classes the elements of a table belong.
    You will learn how to use some of them in the next chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some supervised algorithms can be used for both regression and classification.
    This is true of Neural Networks, which can predict either numbers or classes.
  prefs: []
  type: TYPE_NORMAL
- en: The Logistic Regression algorithm (a variation of Linear Regression) can predict
    the likelihood of belonging to binary classes. Hence, as confusing as it is, Logistic
    Regression is a classification algorithm even if the name suggests the contrary.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on to the following type of learning algorithms, it is worth
    thinking about why this one is called supervised. The analogy we can strike is
    with a teacher who gives a lesson by providing multiple examples of how something
    works, hoping that the student will grasp the concept by noticing connections.
    When sharing various illustrations of a concept (the labeled data), the teacher
    *supervises* the student's learning. Without those examples for which we knew
    the outcome (the target variable), the teacher would have been unable to guide
    the student. That's why in supervised learning, you always have a target variable,
    and you always need to start from some labeled data.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to the next type of ML algorithm, where you don't need any labeled
    data to start learning.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this case, your objective is not to make a prediction but to unveil some
    hidden structure in your data. Unsupervised ML algorithms are capable of *exploring*
    your data table to find out some interesting patterns in the way rows and columns
    are connected to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a broad series of use case scenarios where unsupervised learning can
    be of great value:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest case is **Clustering**. This is about aggregating your data points
    to create homogeneous groups, called clusters. Each group will contain points
    that are "similar" to each other. This is exactly what we needed to do in **Scenario
    #2**, where we had to build groups of similar supermarket customers to send each
    of them a meaningful and personalized newsletter. Algorithms like K-means and
    Hierarchical Clustering are good examples of unsupervised ML algorithms dedicated
    to identifying clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An interesting extension of clustering in the world of text mining is **Topic
    Modeling**, meaning the identification of topics (groups of conceptually related
    words) in text documents. One of the most popular algorithms for topic modeling
    is **Latent Dirichlet Allocation** (**LDA**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding **Association Rules** is another common need covered by unsupervised
    learning. Let''s imagine that you have an extensive database containing a description
    of all the receipts generated in a supermarket. Some products might frequently
    "end up" together in the same receipt: think about milk and coffee or pasta and
    tomato sauce. Algorithms like Apriori and FP-Growth will scout for several meaningful
    and statistically significant rules, such as *customers buying pasta will likely
    also buy tomato sauce*. These rules can be insightful information to leverage
    when optimizing a store''s assortment or defining which products should be on
    adjacent shelves (**Market Basket Analysis**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another typical usage of unsupervised learning is called **Dimensionality Reduction**.
    If you have a table with many columns, it could be that some of them are correlated
    to each other: as a consequence, your table will be redundant since the information
    carried by one column might be already present in other columns. To avoid all
    the drawbacks linked to redundancy (such as performance degradation and loss of
    accuracy), it is worth reducing the number of columns of the table without losing
    the overall information contained in it. The algorithms dedicated to dimensionality
    reduction, such as **Principal Component Analysis** (**PCA**), can explore the
    structure of the table and produce a "narrower" version of it (with fewer columns,
    so a lower dimensionality) carrying similar informative content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s now compare this unsupervised approach with the supervised one we discussed
    earlier. The critical difference is that in unsupervised learning, we are not
    after the connections between features and target: as a matter of fact, we don''t
    have a target column in the first place! Indeed, the input data for an unsupervised
    algorithm is *unlabeled*: no target variable and no labels are required. Following
    the previous analogy, the student here will not need any "supervision" from the
    teacher, based on previous examples. The learning happens by exploring the data
    as-is and looking for patterns that are intrinsic to the data itself (like clusters
    of items or associations between elements).'
  prefs: []
  type: TYPE_NORMAL
- en: While in supervised learning, we could easily understand whether a prediction
    was robust or not (by comparing it with the "real" value), in unsupervised learning,
    it is more difficult to assess how good the job of the algorithm was. In other
    words, there is not a definite good or wrong answer in unsupervised learning,
    only more or less valuable structures unveiled. We will have to measure its effectiveness
    by looking at how it fits the original purpose we aimed at. We will look more
    into this complexity later.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now move on to the third and last class of ML algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When adopting the reinforcement learning approach, you learn by repeatedly
    interacting with the environment in a "trial and error" fashion. The fundamental
    difference with the earlier types of learning methodologies is that, in this case,
    the algorithm acts as an autonomous *agent*: based on the current *state*, it
    will decide what *action* to take, execute it in either the real world or in a
    simulated *environment*, and then—depending on the outcome of its action—update
    its strategy to maximize the total *reward*. As you can see in *Figure 4.4*, these
    steps go through a loop of progressive improvements of the strategy, following
    a simple, common-sense base logic: if the state resulting from my action brings
    a positive reward, then the behavior leading to that action is positively reinforced
    (hence the name). If instead, that action brought a negative reward, then that
    behavior should be penalized so that it doesn''t happen again.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4: Reinforcement learning: an autonomous agent freely interacts with
    the environment and learns as it goes'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can recognize two use case scenarios where reinforcement learning is used:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can let the agent interact directly with the **external environment**,
    like in the case of **Scenario #3**, the digital advertising strategy for the
    photo printing company. Employing a series of iterations (testing different types
    of ads) and moving through a path of gradually increasing rewards (higher media
    ROI), we will end up having a robust strategy to adopt in our campaigns. The interaction
    can happen with the physical, real-world environment too: for instance, a robotic
    arm can learn how to best move some packages using the state captured through
    its camera sensors and continuously improving the way its engines respond to reach
    that objective. Reinforcement learning algorithms such as Q-learning are great
    for maximizing the total rewards of systems like these.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An alternative approach is to provide a **simulated environment** for one or
    multiple agents to interact virtually and progressively learn from what happens.
    This is the case of algorithms like **Monte Carlo Tree Search** (**MCTS**) and
    its most famous implementation, Google AlphaZero, which proved able to learn from
    scratch and become a champion in virtually any game solely through "self-playing."
    The only external input required by the algorithm to get started is the list of
    formal rules of the games: then it proceeds as a true self-learner, playing alone
    with itself and swapping sides if needed. Let''s take the game of chess as an
    example: at first, the agent will play very silly games made of random (but formally
    correct) moves. Then, little by little, it will learn that, by making some smart
    openings and defending some critical positions on the board, the chances of winning
    will increase. After a few hours of learning (and millions of games played), the
    agent will have finetuned its strategy of the most advantageous moves and will
    have become unbeatable by any human chess grandmaster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reinforcement learning has the great advantage of not requiring any labeled
    data to start: the agent will autonomously decide which route of experimentation
    to take and pursue it, accruing new data points at each step of the path. While
    potentially quite powerful, reinforcement learning is still not widely used in
    business applications because of the practical challenges of implementation such
    as building a working "interface" with the real world or satisfying all safety
    constraints—like making sure the agent doesn''t cause any "damage" as it wanders
    around during the learning process. For this reason, in the rest of the book,
    we will focus on supervised and unsupervised learning algorithms: they can enable
    you to create value for your job quickly before moving onto more sophisticated
    quests.'
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the right learning algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the last few pages, we have heard the name of several different algorithms:
    this gave us a glimpse of the vast (and continuously growing) selection of ML
    algorithms that we could use to "go the ML way" when solving a problem. *Figure
    4.5* offers a view of the catalog of ML algorithms organized by type of learning
    (supervised, unsupervised, and reinforcement) and objective. For each scenario,
    we have a choice of alternative algorithms that could do the job for you: a selection
    of the most commonly used algorithms are on the right-hand side of *Figure 4.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5: Catalog of ML algorithms: depending on your need, you select which
    route to take'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a user of ML, you will need to decide which algorithms, out of the many
    alternatives, are best suited for the task you want to accomplish. Each algorithm
    adopts its own logic, carrying specific strengths and weaknesses: as you select
    among them, you need to strike a good trade-off between their characteristics.
    For example, a good algorithm might be very accurate but extremely slow and expensive
    to run, while another one is the opposite: which one is best for you? Let''s start
    familiarizing ourselves with the most essential attributes that define the various
    algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance**. Possibly the most important one to consider, this tells us
    "how well" the algorithm accomplishes its job and "how robust" we expect it to
    be in the future. For instance, in the case of supervised learning, we would measure
    how accurate our predictions are or, in other words, how "close" they fall to
    reality. This is a complex issue to consider: later we will go into more depth
    regarding the many measures that we can use to assess how accurate and robust
    an algorithm is.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speed**. Depending on how many "iterations" are needed to run the full procedure,
    algorithms might be slow and resource-greedy or fast and light.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explainability**. Some algorithms offer an easily interpretable output by
    human beings: this is strictly required when you want to uncover new knowledge
    from data and transfer it to other people or when you want to give a solid explanation
    of why the algorithm suggested something. In other cases, we don''t need to comprehend
    how the algorithm operates, and we are OK to receive a complex (but accurate)
    *Black Box* output, impenetrable by human cognition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amount of data required**. Some algorithms perform well only with a large
    number of previous data points to start from. Others can be robust already with
    dozens of rows and do not require any big data to work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prior knowledge required**. In some cases, the algorithm requires you to
    make assumptions about the data you expect or the environment you operate in.
    Other procedures will be more agnostic toward their domain of application and
    do not require any prior knowledge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These five points are just some of the many attributes you can consider when
    selecting the right algorithm. The good news is that these algorithms are already
    conveniently implemented in data analytics software platforms, for example, as
    KNIME nodes or as libraries in Python. Having them readily available lets you
    "try a few" and decide accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, you can combine different algorithms together in a single learning
    procedure. In this way, you will take the best of both, collectively smoothing
    the edges of their individual behavior: this is called **Stacking**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One thing is sure: there is not a "one size fits all" approach to use ML, and
    you need to become acquainted with a selection of alternative procedures. All
    these algorithms are like utensils to keep in your backpack so that you can leverage
    them depending on the need. By knowing several algorithms, you are free to set
    the right trade-offs between their contrasting attributes and do the best to solve
    most business cases you will find on your way.'
  prefs: []
  type: TYPE_NORMAL
- en: Since performance measures are fundamental, let's get into more details on how
    we can assess them in machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Measuring how good an algorithm is at doing its job is not always an easy task.
    Take the case of unsupervised learning: we expect a good unsupervised algorithm
    to unveil the most interesting and useful structures from data. The assessment
    on what makes them *interesting* or *useful*, however, will depend on your specific
    end goal and often requires some human judgment as well. In reinforcement learning,
    a good algorithm will be able to come back with a sizeable total reward, unlocking
    the opportunity to keep maximizing the return of our continuous interaction with
    the environment. Also in this case, the concept of *reward* will depend on a specific
    definition of value, determined by the case we are solving.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we stay, instead, in the area of supervised learning, the performance evaluation
    is more straightforward: since our objective is to predict something (numbers
    or categories), we can assess the performance by measuring the differences between
    predicted and known samples. The results of this comparison between prediction
    and actual values can be condensed into summary scores. Let''s learn about these
    scores for both regression and classification.'
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since regression is all about predicting numeric values, scoring its performance
    means assessing the overall distance of the results of the prediction from the
    actual values we were trying to predict: the smaller the distance, the smaller
    the error, and the smaller the error, the better. In the case of the simple Linear
    Regression you see in *Figure 4.6*, we are trying to predict the price of second-hand
    cars (target variable) based solely on their age (our only independent variable).
    The dotted line shows the result of our model, which gives us a prediction of
    the price given the age: of course, as the age increases, the price decreases.
    Hence our line goes down as we move to the right. The circles represent the cars''
    actual prices, so the error that we make in our prediction is the distance between
    each circle and the dotted line: this "gap" from reality is called **residual**.
    By properly aggregating residuals, we can obtain a single performance metric for
    any regression.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: Assessing the regression performance: how much error did we make
    in the prediction?'
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to do so is to average them out. However, we should consider that residuals
    can be positive or negative quantities depending on whether the prediction is
    lower or higher than the actual values (see both cases in *Figure 4.6*). To avoid
    that negative residuals counterbalance (and, so, "mask out") positive residuals,
    we can calculate their squares, average them out, and then put that under a square
    root sign so as to bring this metric to the same unit of measure of the predicted
    quantity (like dollars, in the car example). This is how we obtain one of the
    most popular scoring metrics for regression: it''s called **Root Mean Squared
    Error**, or **RMSE**. Its formula is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'where *a*[i] is the *i*^(th) actual value, *p*[i] is its corresponding prediction,
    and *N* is—simply—the total number of points in your data set. RMSE gives us an
    immediate indication of the confidence interval we can use together with our prediction.
    Given its formula, the RMSE is also the standard deviation of the residuals: consequently,
    we can interpret it as the maximum error to expect in 68% of the predictions.
    To be on the safer side, we can multiply the RMSE by 2, obtaining broader intervals
    and an extended level of confidence: we can presume that our error will be lower
    than twice the RMSE 95% of the time. Let''s imagine that we predict a car price
    to be $16,000 using a regression model with an RMSE of $1,200: we can state that
    we are 95% confident that the actual price of that car will lie between $13,600
    and $18,400, which is $16,000 ± $2,400 (twice the RMSE). Of course, the lower
    the RMSE, the better the model, as we can boast narrower confidence intervals
    for our predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: Using RMSE to build confidence intervals is not always mathematically correct.
    In fact, this holds true only under the assumption that residuals follow a normal
    distribution (the typical Gauss bell curve), which might not always be the case.
    Still, it's a handy rule of thumb that I recommend keeping in mind when evaluating
    regressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative summary metric for evaluating the performance of regressions
    is the **Coefficient of Determination,** *R*². It can be calculated using the
    following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'where we find, on top of the measures encountered above, ![](img/B17125_04_003.png),
    which is the average of the actual values. Look at the fraction in the formula:
    we are comparing the squared errors of our model (the same quantity we found in
    RMSE) with the square error of a *baseline* model, which would naively use as
    a constant prediction the average of the observed values. If our model is similar
    to this baseline, *R*² will end up being close to zero, indicating that our model
    is quite useless. If, instead, our model generates much smaller errors than what
    the baseline does, then we obtain an *R*² close to 1\. In this case, the higher
    the *R*², the better.'
  prefs: []
  type: TYPE_NORMAL
- en: One intuitive way to interpret the coefficient of determination is to look at
    it as the proportion of the variation observed in our target variable, which is
    actually explained by the model. If in our car price prediction, we obtain *R*²=0.75;
    we can say that our model, solely based on the age of the car, explains 75% of
    the variability in car price, leaving the remaining 25% unaccounted for. If we
    built a more accurate model or added some additional features, such as mileage
    and accessories, we will probably be able to explain a larger proportion of the
    price variability, and our *R*² will get closer to 1.
  prefs: []
  type: TYPE_NORMAL
- en: There are no specific *R*² reference thresholds that can always tell us if a
    model is "good" or "bad." Think about an apparently chaotic signal, such as the
    fluctuation of currency exchange rates. If we built a regression model that explained
    only 25% of the variability in future exchange rates, we could make a lot of money
    out of it! It's better not to fix static thresholds of *R*².
  prefs: []
  type: TYPE_NORMAL
- en: 'Differently from RMSE, *R*² is a dimensionless metric. This means that we can
    compare the goodness of regression models even if they predict values lying on
    different scales. For instance, we can compare a model predicting house prices
    (in the range of a hundred thousand dollars) with another model predicting motorbike
    prices (which are typically much cheaper), by juxtaposing their *R*² values: the
    higher the *R*², the better.'
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The job of classification algorithms is to assign each item of a data set to
    a class, predicting a specific value of the target variable. Out of all possible
    classes, only one is right and matches with reality. Hence, a simple way to measure
    the performance of a classifier will be to "count" the number of times the algorithm
    got it right out of the total number of predictions. However, this simple performance
    score might not tell us the full story. Let's see this concept come to life with
    an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'You want to assess the performance of an image classification model: however
    random this task might look (and—in all fairness—it does), the job of your binary
    classifier is to assign a label that differentiates the content of the image between
    dogs and muffins. When it comes to Chihuahua and blueberry muffins, your classifier
    struggles a bit, predicting the content as displayed in *Figure 4.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: Is that a Chihuahua or a blueberry muffin? This classifier got
    it right 10 times out of 16.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The table you find on the bottom left of *Figure 4.7* is called a **Confusion
    Matrix**: it has the benefit of showing the full picture of the classification
    outcome, highlighting the number of instances where the classifier got "confused"
    and assigned the wrong label to the pictures. The confusion matrix counts all
    the combinations between any predicted class value (columns) and the reality,
    so the actual class (rows). The cells on the main diagonal will tell us how many
    times the classifier got it right, while all other cells count the errors. In
    this case, it looks like our model had an "unbalanced" performance as it had a
    harder time recognizing the dogs, while it was a bit more robust in spotting muffins.
    In the case of Chihuahuas and blueberry muffins we are not very worried about
    this asymmetry; however, in other cases, this might be a big deal, generating
    very different outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s move on to a more serious case: a classifier that predicts whether a
    patient is infected by a contagious virus by analyzing a series of features coming
    from a blood test exam. Also in this case, there are two classes, positive and
    negative, and we have two different types of classification errors we can make.
    One is about assigning the class positive to a patient who, in reality, is healthy:
    this is called a **False Positive**. The outcome of this error is that we communicate
    the result to the patient, who will immediately start a quarantine, and run some
    more accurate tests to confirm our findings. The other type of error we can make
    is when we assign the class negative to a patient who is actually infected by
    the virus: this is a **False Negative**. Of course, the outcome of this error
    is much more impactful than the previous case: we would send the patient home,
    allowing a further spread of the virus due to the contamination of other people
    and failing to start any early treatment for the person. To summarize: not all
    errors are born equal when it comes to classification. As a consequence, one single
    number might not be enough to explain the full situation. That is why it is wise
    to calculate the confusion matrix and select among multiple metrics the most appropriate
    to your needs. Depending on the case you are solving, you should pick one of the
    summary metrics shown on the right-hand side of *Figure 4.8* as the most important
    one to assess performance with. Let''s go through each of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy** is telling you the percentage of good predictions versus the total
    ones. When the type of error does not matter, you can use this "balanced" measure
    to explain the overall performance of a classifier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Precision** will tell you how confident the classifier is when it labels
    a case as positive. You can use this metric when you need to avoid at all costs
    the situation where a case predicted to be positive turns out to be negative.
    If a very precise classifier tells you that a case is positive, it is most likely
    right.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sensitivity** tells you how confidently the classifier can rule out the possibility
    that a positive case is not classified as such. You need to use this metric when
    you want to avoid false negatives. If a very sensitive classifier tells you that
    a case is negative, it is most likely right. Diagnostic classifiers in medicine
    are typically built so as to maximize sensitivity at all costs, as you want to
    be sure to send home without a cure only patients that are really negative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The classes names positive and negative are just conventional. Depending on
    your case, you can decide which class is positive and calculate all the scoring
    metrics accordingly. In the case of more than two classes, it works like that:
    you select the single positive class, and then the metrics are calculated considering
    any other class as negative. It''s just a convention.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B17125_04_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: Assessing performance in classification: pick the metric that makes
    the most sense in your case'
  prefs: []
  type: TYPE_NORMAL
- en: 'With this, we have seen the most popular ways we can use to evaluate the performance
    of supervised learning predictors. Before building our first ML model, we need
    to go through one last fundamental concept and learn how to manage it: overfitting.'
  prefs: []
  type: TYPE_NORMAL
- en: Underfitting and overfitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'American mathematician John Nash received the 1994 Nobel Prize for Economics
    for his landmark work on game theory. His "Nash equilibrium" has become the foundation
    of how economists predict the outcome of non-cooperative strategic interactions.
    The story of John Nash has been popularized by the Academy Award-winning movie
    *A Beautiful Mind* starring Russell Crowe as Nash. In the movie, John Nash is
    portrayed in his life-long struggle with paranoid schizophrenia: his condition
    brought him to believe he had found "secret messages" hidden in the text of regular
    magazine articles, supposedly added by Soviet spies for covert communication.
    Perceiving meaningful connections between unrelated things is a typical tendency
    of early-stage delusional thought, a condition that psychiatrists call *apophenia*.
    Now, think about it: when you have (a lot of) data and (massive) computing power
    available, it is likely to fall into the trap of thinking that you have found
    some interesting patterns of general validity. In reality, you might have just
    found a spurious, random connection as a consequence of the vast extent of availability
    of resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This will become clearer with an example: let''s imagine we have a large database
    containing all sorts of information on the ticket holders of a nationwide annual
    lottery. We have two years of history available, and we want to use the information
    on the past two winners to predict the future ones by identifying the recurrent
    features. We decide to use a supervised ML algorithm to do so. After some heavy
    calculation, the algorithm comes up with a complex series of apparently "winning"
    rules that are shared only by the lucky winners of the two previous editions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These rules are like: *the 4**th digit of their telephone numbers is a 7*,
    *their ticket numbers include exactly 3 odd digits*, *they were born on a Tuesday*,
    and many others. Clearly, these rules are not going to be able to predict anything
    meaningful: they are just artificially "connecting" two specific points through
    a series of meaningless factors that happen to be in common for the winners. As
    the example shows, when the haystack is large enough, it is easy to find something
    very similar to a needle! Similarly, when you have a massive amount of data, if
    you look long enough, you can find any connection, although this doesn''t make
    it meaningful. This is comparable to the apophenia condition we encountered in
    John Nash''s story. We need to avoid at any cost falling into this trap of "analytical
    fallacy": it is just a deception caused by our desire to find connections at all
    costs, even if they do not actually exist, by using artificially overcomplicated
    models. This condition is called **overfitting**, and it''s a problem that can
    potentially arise when attempting any prediction. Hence, we need to systematically
    avoid it when building a supervised ML model which generates predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's see overfitting in action in our car price example. *Figure 4.9* shows
    the Polynomial Regression for different degrees, represented by the parameter
    **N**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.9: Regression models to predict car prices with different polynomial
    degrees N. Which one would you pick?'
  prefs: []
  type: TYPE_NORMAL
- en: 'As **N** grows from 1 to 5, the fitting line shows a more convoluted path:
    this signifies that the underlying model becomes more complex. By looking at the
    three curves, we can notice the following:'
  prefs: []
  type: TYPE_NORMAL
- en: When **N = 1** (dotted line), our model is exactly the same as the simple Linear
    Regression model we encountered earlier. Although it is a good starting point,
    it looks a bit too "simple" as it fails to consider the stronger devaluation of
    car prices happening in the first few months of age.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When **N = 3** (dashed line), we get a more encouraging fit, as we clearly see
    a stronger erosion of price in the early life of a car and a subsequent flattening
    of the curve. This looks solid, as it is in line with what our business understanding
    suggests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When **N = 5** (continuous line), we have a nearly perfect fit with the existing
    points. However, this sounds "too good to be true" and, indeed, the shape of the
    curve is artificially built in a way that meets the points, without providing
    solid modeling of the price evolution over age. There are some weird bumps like
    the one happening at around 1.5 years of age, where the price is supposed to be
    inexplicably higher than what we have with new cars. It looks like we have just
    "forced" the curve to touch the few "past" points, which is a short-sighted objective.
    Instead, our real purpose was to find a robust model able to predict the price
    of the "next" cars coming to market.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From this example, we can start seeing that the level of complexity of a supervised
    model needs some finetuning: if the model is too basic, its predictive performance
    will be necessarily low. On the other extreme, if the model is too complex, we
    might have just "connected the previous dots": we end up in the delusional state
    of weaving together coincidences into an apparent general pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build on this concept by bringing an additional supervised example:
    this time, we deal with classification. As you can see in *Figure 4.10*, you have
    a number of elements on a plate that could be either dots or crosses. You want
    to predict their class (being a dot or a cross) based on their position by drawing
    a continuous line that differentiates across elements, leaving dots on the top-right
    side of the plate and crosses on the bottom-left side. By applying a non-linear
    **Support Vector Machine** (**SVM**) learning algorithm, you obtain three different
    curves of progressively increasing complexity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.10: We want to draw a line able to differentiate dots (top-right side)
    and crosses (bottom-left side). Misclassified elements are in darker gray. Which
    line is likely to do the job better with future elements?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a look at the three cases:'
  prefs: []
  type: TYPE_NORMAL
- en: The model on the leftis a straight line that looks like a very rudimentary way
    to differentiate between dots and crosses. It seems that we are consistently missing
    some dots in the middle area of the chart, which happen to be just outside the
    region where they should. Overall, our accuracy level is near 75%, as we made
    12 misclassifications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The model in the middle is slightly more complex than the previous one but
    also more accurate (only six errors this time). The curvature we now have on the
    line accounts well for the dots we were consistently missing before. Intuitively,
    the six misclassifications we made (they are in darker gray in the picture) look
    more like "exceptions": the curved line seems close to a general rule that is
    likely to repeat in the future when new elements will land on the plate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The model on the right is apparently the best: it nailed the class of all elements
    on the plate, reaching an accuracy of 100%. However, this complex model is unlikely
    to have a general validity: the curve is zigzagging through the current elements
    to avoid any misclassification, but we can expect that, if new elements show up,
    they will be misclassified as a consequence of all these artificial bends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These examples have illustrated an important property of supervised ML: if
    we want to build models that perform well in predicting "future" cases, we need
    to strike the right balance of complexity when learning. We can recognize three
    cases, as summarized in *Table 4.1*. Let''s go through each of them, starting
    from the extremes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Underfitted** **models**. Like in the Polynomial Regression with **N = 1**
    and the first plate of the classification, an underfitted model is just not good
    enough to predict anything. This naïve model will generate large error rates (higher
    residuals or many misclassifications) even when asked to fit the known data points.
    As a logical consequence, we cannot expect the same model to magically start working
    well on future cases: this makes underfitted model pretty useless for making any
    prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overfitted models**. These models sit at the opposite extreme of underfitted
    models and are as bad as the former. The mathematical complexity of the model
    lets it adapt very well to known data points, introducing unrealistic elements
    like the many bumps of the regression with **N = 5** or the zigzags across elements
    in the classification. We "believe" to have reached a high level of accuracy,
    but this is just a self-inflicted delusion: whenever new points arrive, our accuracy
    level will dramatically drop as a consequence of those artificial complexities
    we have allowed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Well-fitted models**. As for many other things in life: *virtue lies in the
    middle ground*. Well-fitted models will be less accurate than overfitted ones
    when fitting data points. However, given the limitations they had in capturing
    the complexity of a phenomenon, they will tend to focus on the (fewer) connections
    that matter most, ignoring the excessively complex paths that fitted models used.
    Well-fitted models are best suited for predicting the "unknown," which is exactly
    the point of why we wanted to build a supervised model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|  | Underfitted | Well-fitted | Overfitted |'
  prefs: []
  type: TYPE_TB
- en: '| Model complexity | Low | Mid | High |'
  prefs: []
  type: TYPE_TB
- en: '| Performance on past cases | Low | Mid | High |'
  prefs: []
  type: TYPE_TB
- en: '| Performance on future cases | Low | Mid | Low |'
  prefs: []
  type: TYPE_TB
- en: '| Description | The model is too naïve, and the resulting predictions are not
    accurate. It is unable to describe well the modeled phenomenon. | The model is
    well balanced. It grasps patterns of general validity that are likely to repeat
    in future cases. | The model is complex and works well only on the very specific
    points used to learn. It is unable to predict the outcome of future cases. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4.1: Typical characteristics of under-, well-, and overfitted models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The good news is that ML models can be "tuned" for complexity by changing a
    set of values, called **Hyperparameters**, that modulate their learning behavior.
    For example, in the Polynomial Regression, **N** is nothing more than a hyperparameter
    of the model: by making **N** vary from 1 to 5 (or more), we can control how complex
    the model is and, by making some attempts, we can try to find the well-fitted
    level. We will learn about hyperparameters more when talking through the specific
    learning algorithms later in the book.'
  prefs: []
  type: TYPE_NORMAL
- en: Another way to reduce the complexity of a model is to reduce the number of features.
    The fewer the features, the simpler the model, and the lower the chances to overfit.
    This is another motive for doing dimensionality reduction, one of the unsupervised
    scenarios we have previously introduced.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are clear on the pathological condition of overfitted models: it''s
    time to move on and talk about how to diagnose it and what a possible cure can
    look like.'
  prefs: []
  type: TYPE_NORMAL
- en: Validating a model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By looking once again at *Table 4.1* and, more specifically, at its third row,
    we find that the only way to spot a well-fitted model is to evaluate its performance
    on "unseen" samples. Both under- and overfitted models will underperform versus
    a well-fitted model when it comes to the level of accuracy of future cases. But
    what if we do not yet have any future cases to use for this purpose?
  prefs: []
  type: TYPE_NORMAL
- en: 'A fundamental "trick" we use in supervised ML is to randomly split the data
    set of known samples into two subsets: a **training set**, which normally covers
    70 to 80% of the original data, and a **test set**, which keeps the remainder
    of the data. *Figure 4.11* shows this operation, called **Partitioning**, in action.
    Then, we use *only* the training set for performing the actual learning, which
    will generate the model. Finally, we will evaluate the model''s performance on
    the test set: this is data that the algorithm has *not* seen yet when learning.
    This means that, if the model grew overcomplex by creating many bumps and zigzags
    to adapt to the training set, we would get low-performance scores on the test
    set. In other words, if the model is overfitted to the training set, then it will
    perform very badly on the test set. With this trick, we have assessed the accuracy
    of "future" samples without doing any time travel!'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.11: Partitioning a full set in training and test subsets. Rows are
    randomly sampled and distributed to the two subsets, according to the desired
    proportion'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 4.12* shows the expected amount of prediction error in test and training
    sets by increasing levels of complexity. The amount of error obtained on the samples
    included in the training set can be lowered progressively by working on the hyperparameters
    of the model in a way to increase its complexity. For example, in the Polynomial
    Regression case, as we move from left to right, we are growing the value of **N**:
    with a high-complexity model (**N = 5**, we are on the far right), the error of
    the training line is almost zero. If you look at the error calculated on the test
    set (the U-shaped curve), you will face the reality and recognize that the true
    predictive power of the model is much lower: only a well-fitted model can ensure
    good performance on "unseen" data points.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.12: The amount of error produced by a supervised ML model as complexity
    grows: for the test set, it follows a U-shaped curve'
  prefs: []
  type: TYPE_NORMAL
- en: Pulling it all together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We finally have all the ingredients for building and validating a well-fitted
    supervised ML model. Let''s see now what the recipe looks like. We can visualize
    a recurrent "structure" made of four fundamental blocks that collectively define
    our basic flow for supervised learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Partitioning**. To avoid overfitting, we need to leverage a validation mechanism
    that prevents us from scoring a model on the same data used for learning. Thus,
    the first step we always do in supervised learning is to partition the full set
    of labeled data points to obtain a training and a test data set. In most cases,
    the split happens through random sampling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Learner**. The training data set can be used to train a model by leveraging
    the learning algorithm. The output of this operation will be the statistical model
    (defined through a set of parameters), which can be applied to different data
    so to obtain a prediction.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Predictor**. We can now "run" the model learned in the previous step on the
    test set, which has been kept out of the training process. The output of the predictor
    will be the test set enriched with an additional column: the predicted value of
    the target for each row.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Scorer**. The output of the predictor contains *both* the observed target
    (the actual value we aimed at predicting) and its model-generated prediction.
    By comparing the values of these two columns, we can assess the performance of
    the prediction. It will be enough to calculate one or more summary metric scores,
    like the ones we introduced a few pages ago, like RMSE, *R*², sensitivity, or
    the full confusion matrix.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That's it! By following this logic flow, described in *Figure 4.13*, you can
    build a supervised model and assess its true performance, avoiding the risk of
    overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17125_04_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.13: The typical flow for validating a supervised ML model. To prevent
    overfitting, you need to partition the data, learn on the training portion, and
    finally predict and score on the test partition only.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, once you have a validated model, you can confidently apply it to
    all "future" data points, finally unlocking the real value of ML predictions.
    Let''s take the example of the second-hand cars price prediction: you used your
    full database containing the historical sales to build and validate a model. Once
    you have a validated model and you are sure it does not overfit, you are ready
    for prime time: every time you need to estimate the price of a car, you can now
    execute the model on the car''s features and obtain the predicted price. Of course,
    this time, you will not have the "real value" to compare it with, but you can
    use the confidence interval of your prediction (like the RMSE for regression)
    to anticipate the range of expected errors you are going to get.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s worth spending a few last thoughts on the flow portrayed in *Figure 4.13*:
    this is the "base" process you can adopt when building and validating a supervised
    ML model. Many improvements can be incrementally applied to make your models better
    and better. Just to give you some perspective on the many additions we can make,
    let''s mention a few that leverage iterations for improving the process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The partitioning trick has some limitations: for example, if you have a relatively
    small data set to start from and hold 30% out from learning, you might end up
    with an inadequate validation since the model had too few points to learn from.
    One alternative route, called **k-Fold Cross Validation**, is to split your full
    set into k folds (usually 5 or 10) and iterate multiple times, using each fold
    as a test set to be held out each time. In the end, you will get k different models
    and scores. By averaging them out, you will obtain a much more robust validation
    than having just a one-off partitioning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we saw earlier, you can "tune" the hyperparameters of a model to maximize
    the performance score obtained on the test set (which will, in turn, ensure maximum
    accuracy on the future predictions and prove the general validity of your model).
    You can loop through different hyperparameters, managing them as variables, and
    spot the set of values that put you at the bottom of the U-shaped curve we saw
    in *Figure 4.12*. This procedure is called **Hyperparameter optimization** and
    can be implemented by using loops and variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As mentioned before, if you have uninformative or redundant features in a data
    set, your model will be unnecessarily complex. There are many techniques used
    for identifying the best subset of features to use in your learning: they go under
    the general name of **Feature Selection**. One simple iterative technique for
    selecting features is called **Backward Elimination**: you start with having all
    features selected. Then, at each iteration, you remove one feature—the one that
    induces the smallest decline (or the biggest increase) of performance if removed
    from the set. At some point, you will have "tried" multiple combinations of features,
    and you can pick the one that maximizes the overall predictive performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are just some of the many possible techniques you can use and creatively
    combine to improve the quality of your modeling. Hopefully, this shows you a hint
    of the fascinating reality of the world you are getting into: the practice of
    ML is a mix of art and science, and you can always look for some more ingenious
    ways to squeeze incremental value from data and algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you were introduced to the fundamental concepts behind machines
    that can learn from data. After stripping away the futuristic gloss of AI, we
    went through a series of practical business scenarios where we saw intelligent
    algorithms at work. These examples showed us how, if we look carefully, we can
    often recognize occasions to leverage machines for getting intellectual work done.
    We saw that, as an alternative to the traditional mode of operating, there is
    an ML way to get things done: whether we are predicting prices, segmenting consumers,
    or optimizing a digital advertising strategy, learning algorithms can be our tireless
    companions. If we coach them well, they can extend human intelligence and provide
    a sound competitive advantage to our business. We explored the differences among
    the three types of learning algorithms (supervised, unsupervised, and reinforcement)
    and understood the fundamental drivers that can guide us in selecting which algorithms
    to use. We have then learned what needs to happen to build a robust predictive
    model and properly assess its performance while staying away from the menace of
    overfitting. It was a long journey in the captivating world of statistical learning,
    but, as promised, we didn''t need to go through many formulas or complex math.
    This chapter enabled you to get the intuition behind the vital concepts of ML
    so that you can move quickly to practice and keep learning while doing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s now time to put our hands back onto KNIME and build (and validate) a
    few ML models based on real-world data: get ready because this is what the next
    chapter is all about.'
  prefs: []
  type: TYPE_NORMAL
