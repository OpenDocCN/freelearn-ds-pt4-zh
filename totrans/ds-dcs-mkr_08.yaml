- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unsupervised Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike the more familiar terrain of **supervised learning** (**SL**), where
    data comes neatly labeled and the learning path is predefined, **unsupervised
    learning** (**UL**) ventures into the territory of unlabeled data, offering an
    opportunity to uncover hidden patterns and insights.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter delves into the field of UL, where we will learn about some practical
    examples of UL, the key steps involved in UL, and techniques around clustering,
    anomaly detection, dimensionality reduction, and association rule learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining UL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steps in UL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering – unveiling hidden patterns in your data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Association rule learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications of UL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining UL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: UL is a type of **machine learning** (**ML**) that finds patterns in data without
    any prior training. Distinct from its counterpart, SL, where the model is trained
    using labeled data, UL algorithms work with unlabeled data. The aim is to model
    the underlying structure or distribution in the data to learn more about it.
  prefs: []
  type: TYPE_NORMAL
- en: Think of it as a detective who walks into a crime scene with no initial clues
    or suspects. The detective’s job is to uncover patterns, find hidden groups, or
    establish relationships between different elements at the scene.
  prefs: []
  type: TYPE_NORMAL
- en: Practical examples of UL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To make this concept more tangible, let’s look at some practical examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Market research**: A company wants to understand its customer base better
    and tailor their marketing to different consumer segments. They have a wealth
    of data (for example, customer data or consumer survey data) but no specific categories
    or labels. UL can help identify distinct groups or segments within their customers.
    The company can then better understand the demographics, behaviors, and opinions
    of these different segments, leading to more targeted marketing strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer goods and retail**: An e-commerce store wants to understand the
    buying behavior of its customers. Using UL, they can discover associations between
    different products. For instance, they might find that customers who buy a certain
    brand of remote control also buy a certain battery type and pack size, enabling
    the e-commerce store to automatically recommend items the consumer is likely to
    add to their order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supplier performance analysis**: By clustering suppliers based on performance
    metrics such as delivery time, quality of goods, cost, customer support, and reliability,
    companies can gain insights into their supply chain’s strengths and weaknesses.
    This aids in making informed decisions about which suppliers to prioritize or
    re-evaluate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UL is a powerful tool that can uncover hidden patterns and associations in your
    data. It’s like having a detective on your team who can make sense of seemingly
    unrelated information. Whether you’re looking to understand your customers better,
    optimize your marketing strategies, or discover new opportunities, UL can provide
    valuable insights.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve established a solid understanding of what UL is, let’s dive deeper
    into the process. In the next section, we’ll explore the steps involved in UL,
    from data collection to interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: Steps in UL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'UL is a type of ML that allows us to draw inferences from datasets consisting
    of input data without labeled responses. Unlike SL, where we have a clear target
    or outcome to predict, UL is more about discovering hidden patterns and structures
    within data. But how does this process work? Let’s break it down into digestible
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: Steps involved in unsupervised ML (UML)](img/B19633_08_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: Steps involved in unsupervised ML (UML)'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: While the diagram presents a linear flow, in practice, these steps may not always
    follow a strict linear sequence. Throughout the process, insights gained about
    the data, such as during evaluation, may inform iterations and refinements in
    data processing or model selection.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Data collection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just as with any other ML project, UL begins with data collection. This could
    be customer data for a retail company, patient data for a healthcare organization,
    or user behavior data for a tech firm. The key here is to gather as much relevant
    data as possible to help the model learn and make accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Data preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the data is collected, it needs to be cleaned and preprocessed. This step
    involves handling missing values, removing outliers, and normalizing the data.
    This step is important as the quality of data impacts the ability of the model
    to learn effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Choosing the right model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After preprocessing, the next step is to choose the right model for your data.
    There are various UL algorithms, such as k-means clustering, hierarchical clustering,
    and **Density-Based Spatial Clustering of Applications with Noise** (**DBSCAN**).
    The choice of model depends on the problem at hand and the nature of your data.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now comes the exciting part – training the model. Here, the model learns to
    identify patterns and structures within the data without any supervision. For
    instance, in a market research context, a UL model could identify distinct segments
    within your customer base based on purchasing behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – Interpretation and evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final step involves interpreting the results and evaluating the model’s
    performance. As with SL, the unsupervised model performance can be evaluated with
    evaluation metrics. In UL, evaluation metrics can be a bit tricky as we don’t
    have a clear target to compare our predictions with. However, metrics such as
    Silhouette Score or the **Davies-Bouldin Index** (**DBI**) can be used to evaluate
    the quality of clustering.
  prefs: []
  type: TYPE_NORMAL
- en: In a business context, interpretation is equally important. For example, in
    a retail setting, understanding the characteristics of different customer segments
    can help tailor marketing strategies to each segment, ultimately leading to increased
    sales and customer satisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: In summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By now, you should have an understanding of the steps involved in UL and how
    it can be applied in a business context. But we’re just scratching the surface
    here. Next, we’ll dive deeper into one of the most common techniques in UL – clustering.
    Stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will delve into the world of clustering algorithms,
    exploring how they work, their applications, and how they can be used to drive
    decision-making in business.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering – unveiling hidden patterns in your data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clustering is a powerful tool in the UL toolkit. But what is it, and how can
    it help decision-makers in business? Let’s dive in.
  prefs: []
  type: TYPE_NORMAL
- en: What is clustering?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Clustering is a method of UL that involves grouping data points together based
    on their similarity. Unlike SL, where we have a clear target or outcome variable,
    UL (and, by extension, clustering) is all about finding hidden structures and
    patterns in data without any predefined labels.
  prefs: []
  type: TYPE_NORMAL
- en: Think of clustering as a way to discover and explore unknown territories in
    your data. It’s like an explorer setting out on a journey without a map, using
    only their observations to make sense of the landscape.
  prefs: []
  type: TYPE_NORMAL
- en: How does clustering work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The process of clustering involves several steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature selection**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this step, you choose the characteristics or attributes of your data that
    you believe can help differentiate between different groups. For example, if you’re
    clustering customers, you might select features such as age, income, and purchase
    history.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Distance measurement**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To group similar data points together, you need to define what “similar” means.
    This is done by measuring the “distance” or “dissimilarity” between data points.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: One common distance measure is Euclidean distance, which is the straight-line
    distance between two points. You can imagine this as the distance “as the crow
    flies,” whereas other distance measures, such as Manhattan distance or cosine
    similarity, consider different aspects of the data. The cosine distance is the
    cosine of the angle between two points.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering algorithm**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have your features and distance measures, you apply a clustering algorithm
    to group similar data points together.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Different algorithms make different assumptions about the structure of the
    clusters. Here are some examples:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: k-means tries to partition n observations into k clusters where each observation
    belongs to the cluster with the nearest mean.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Hierarchical clustering builds a hierarchy of clusters, either from individual
    elements by merging clusters (agglomerative approach) or from the entire dataset
    by dividing the dataset into smaller clusters (divisive approach).
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: DBSCAN groups together points that are closely packed together and marks points
    that are in low-density regions as outliers.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluation**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After clustering, you need to evaluate the quality of your clusters. This helps
    determine if your clustering makes sense and is useful for your problem.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics such as Silhouette Score measure how similar an object is to its own
    cluster compared to other clusters. A high silhouette score indicates that the
    object is well matched to its own cluster and poorly matched to neighboring clusters.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Dunn Index** (**DI**) is another metric that measures the ratio between
    the minimal inter-cluster distance and the maximal intra-cluster distance. A higher
    DI indicates better clustering.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember – clustering is an exploratory technique. It can help uncover patterns
    and structures in your data that you might not have known about beforehand. Experiment
    with different features, distance measures, and algorithms to see what insights
    you can uncover in your data.
  prefs: []
  type: TYPE_NORMAL
- en: k-means clustering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is an example of one clustering algorithm called k-means:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: k-means clustering](img/B19633_08_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: k-means clustering'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, let’s look at each side before and after the k-means
    process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Before k-means (****left side)**:'
  prefs: []
  type: TYPE_NORMAL
- en: On this side, before we carry out k-means, the data points are scattered across
    the two-dimensional space defined by axes x1 and x2\. These could be variables
    such as, say, the total spend (x1) and the number of visits (x2) of customers
    at a store.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, the data is unlabeled, meaning we don’t yet know which cluster
    each data point belongs to.
  prefs: []
  type: TYPE_NORMAL
- en: '**After k-means (****right side)**:'
  prefs: []
  type: TYPE_NORMAL
- en: After k-means, the data points have been grouped into clusters based on their
    proximity to one another. These clusters can be informative about underlying patterns
    within the data.
  prefs: []
  type: TYPE_NORMAL
- en: The k-means clustering process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To carry out k-means, we need to choose the number of clusters we want to identify
    in our data. Let’s say we have visualized the data and decided that *k*=3, meaning
    we want to find three clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The k-means algorithm follows these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialization**: Randomly select *k* points from the data as the initial
    centroids (the center of each cluster).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Assignment step**: Assign each data point to the nearest centroid based on
    the distance between the point and the centroid.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Update step**: Recalculate the centroid of each cluster by taking the mean
    of all points assigned to that cluster.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 2* and *3* until the centroids no longer move significantly or
    a maximum number of iterations is reached. This indicates that the clusters have
    stabilized.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After applying the k-means algorithm, the data points are colored differently
    based on the cluster they belong to. In this case, three clusters have been identified:
    Cluster A, Cluster B, and Cluster C.'
  prefs: []
  type: TYPE_NORMAL
- en: The k-means algorithm is widely used because it’s relatively simple and efficient.
    However, it assumes that clusters are spherical and evenly sized, which might
    not always be the case in real-world data. Additionally, the number of clusters
    k needs to be specified beforehand, which can be a drawback if the optimal number
    of clusters is not known. Despite these limitations, k-means remains a powerful
    tool for **exploratory data analysis** (**EDA**) and pattern recognition in various
    fields, which we will explore in this next section.
  prefs: []
  type: TYPE_NORMAL
- en: Practical applications of clustering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Clustering has a wide range of applications across various industries:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Risk assessment in insurance**: In the insurance industry, clustering algorithms
    can be used to group policyholders based on various risk factors. For instance,
    clustering can identify groups of individuals with similar driving habits in auto
    insurance or health profiles in life insurance. This segmentation allows insurance
    companies to tailor their policies and pricing more accurately according to the
    risk levels, leading to more efficient risk management and pricing strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Energy consumption analysis in utilities**: Utility companies can use clustering
    to analyze energy usage patterns of their customers. By grouping customers into
    clusters based on their consumption patterns, peak usage times, and seasonal variations,
    utilities can better understand demand, plan energy distribution, and even design
    customized energy-saving programs. This can also help in identifying areas where
    infrastructure improvements are needed or where energy conservation measures can
    be most effective.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content personalization in digital media**: In the digital media and entertainment
    industry, clustering is used to analyze user preferences and viewing habits. By
    clustering users based on their interactions with different content types (such
    as genres of movies, music, or articles), media companies can provide personalized
    content recommendations. This not only enhances user experience but also increases
    engagement and, potentially, subscription retention.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation metrics for clustering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As decision-makers, it’s important to understand how well your clustering model
    is performing. Here are a few metrics to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Silhouette Score**: The Silhouette Score metric is a way to quantify how
    well data is grouped into clusters. It ranges from -1 to 1\. A score close to
    1 means that the data points are very similar to others in the same cluster but
    dissimilar to those in other clusters, which is ideal. Essentially, it’s a measure
    of how appropriately each data point belongs to its cluster: the higher the score,
    the better each data point fits within its own cluster as opposed to others. This
    score helps to validate consistency within clusters of data and can be used to
    determine the optimal number of clusters by comparing scores across different
    numbers of clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DI**: DI is a more nuanced gauge of clustering quality that considers both
    the compactness of clusters and the separation between them. It does this by examining
    the smallest distance between points in different clusters and the largest distance
    between points within the same cluster. A higher DI indicates that the clusters
    are compact (with data points closely bunched together) and well separated (with
    each cluster being a good distance away from the others). This index is especially
    useful when you want to ensure that clusters are distinct from each other while
    also being internally coherent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember – the choice of metric should align with your business objectives.
    For instance, if your goal is to create highly distinct customer segments for
    targeted marketing, a high silhouette score would be desirable.
  prefs: []
  type: TYPE_NORMAL
- en: In summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Clustering is a powerful UL technique that can reveal hidden patterns and structures
    in your data. By understanding its process and applications, you can harness its
    power to make more informed business decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we’ll explore another key UL technique: association rule
    learning. This method can help you discover interesting relations between variables
    in large datasets – an important skill for any data-savvy decision-maker.'
  prefs: []
  type: TYPE_NORMAL
- en: Association rule learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine you’re at a supermarket, and you notice that people who buy diapers
    often also buy beer. This is not a random observation but a result of a powerful
    UL technique called association rule learning. It uncovers hidden patterns in
    large datasets, enabling businesses to make data-driven decisions.
  prefs: []
  type: TYPE_NORMAL
- en: What is association rule learning?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Association rule learning is an ML method that identifies frequent if-then associations
    called “rules” among a set of items. It’s like finding relationships between products
    often grouped together. These rules can be leveraged to predict future behavior,
    enabling businesses to strategize their marketing efforts effectively.
  prefs: []
  type: TYPE_NORMAL
- en: The Apriori algorithm – a practical example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most popular algorithms used in association rule learning is the
    Apriori algorithm. Let’s break down how it works with a practical example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you’re a decision-maker at a retail store. You want to understand the
    buying patterns of your customers to optimize product placement and boost sales.
    Here’s how you can use the Apriori algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Set a minimum support** **and confidence**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These are two key metrics in the Apriori algorithm. **Support** measures the
    frequency of an item set in all transactions, while **confidence** measures the
    likelihood that item Y is purchased when item X is purchased.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Generate** **item sets**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The algorithm will start by creating a list of all individual items (item sets)
    that meet the minimum support threshold.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Create rules**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each item set, the algorithm will generate rules that meet the minimum confidence
    threshold.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Rank rules**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The rules are then ranked by their lift, another metric that measures how much
    more likely item Y is purchased when item X is purchased, compared to purchasing
    item Y alone.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By following these steps, you might discover rules such as {Diapers} -> {Beer},
    indicating that customers who buy diapers are likely to buy beer as well. This
    insight can be used to strategically place products in your store to increase
    sales.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In association rule learning, the key evaluation metrics are support, confidence,
    and lift. These metrics help in identifying the most relevant rules. However,
    it’s important to strike a balance. High support may lead to obvious rules, while
    high confidence may lead to overly specific rules. Lift, on the other hand, provides
    a balance by measuring the strength of a rule over the random occurrence of item
    sets.
  prefs: []
  type: TYPE_NORMAL
- en: In summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Association rule learning is a powerful tool in the UL toolkit. It uncovers
    hidden patterns in large datasets, enabling businesses to make strategic decisions.
    Whether you’re in retail, marketing, or any industry dealing with large datasets,
    association rule learning can provide valuable insights.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, *Applications of UL*, we’ll explore more applications of
    UL, diving deeper into how these techniques can be leveraged across various business
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of UL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: UL, as we’ve discussed, is a type of ML that identifies patterns in data without
    the need for explicit supervision. It’s like a detective who arrives at a crime
    scene with no witnesses but must still piece together the story from the available
    evidence. But where does this kind of “detective work” find its application in
    the business world? Let’s explore.
  prefs: []
  type: TYPE_NORMAL
- en: Market segmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most common applications of UL is in market segmentation. Businesses
    with a diverse customer base use clustering algorithms to group customers based
    on their behavior, demographics, and purchase history. This allows them to tailor
    their marketing strategies to each group, maximizing engagement and conversion
    rates.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a global retail brand with millions of customers. They could use UL
    to segment their customers into groups, such as “young professionals,” “parents,”
    or “retirees,” each with distinct shopping habits and preferences. The company
    could then create personalized marketing campaigns for each segment, increasing
    customer satisfaction and loyalty.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: UL is also excellent at detecting anomalies or outliers in data. This is particularly
    useful in industries such as finance and cybersecurity, where identifying unusual
    patterns can prevent fraud or security breaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, a bank could use UL to monitor transactions and flag any that
    deviate significantly from a customer’s usual behavior, as shown in the following
    simple diagram. UL algorithms can identify anomalies by measuring the distance
    of a data point from the centroid of its assigned cluster. Data points that are
    far away from their cluster centroid are considered anomalies. This could indicate
    fraudulent activity, prompting the bank to take preventive measures:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: Anomaly detection for financial transactions](img/B19633_08_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: Anomaly detection for financial transactions'
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: UL can also be used for feature extraction, which simplifies complex datasets
    by reducing their dimensionality. This can make other ML tasks more efficient
    and accurate.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a car manufacturer might have data on hundreds of features for
    each vehicle. UL could identify the most important features that affect a car’s
    performance or popularity, allowing the manufacturer to focus on these in their
    design and marketing efforts.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have learned that UL is a versatile tool that can uncover hidden insights
    from data and applies to many business use cases, such as market segmentation,
    anomaly detection, and feature extraction.
  prefs: []
  type: TYPE_NORMAL
- en: By grasping the capabilities of UL, decision-makers can harness it to uncover
    valuable insights, streamline processes, and make data-driven decisions that impact
    the bottom line.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we’ve covered the fundamental concepts of UL, outlined
    its key steps, and explored some of its most prevalent real-world applications.
    We’ve also discussed methods for evaluating the performance of UL models in a
    business setting.
  prefs: []
  type: TYPE_NORMAL
- en: Building on this foundational knowledge of ML, the next chapter will take a
    closer look at strategies for interpreting and assessing ML models, equipping
    you with the tools needed to effectively communicate insights and justify decisions
    based on your ML projects.
  prefs: []
  type: TYPE_NORMAL
