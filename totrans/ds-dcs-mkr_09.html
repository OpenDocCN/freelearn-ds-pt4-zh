<html><head></head><body>
<div id="_idContainer077">
<h1 class="chapter-number" id="_idParaDest-201"><a id="_idTextAnchor216"/><span class="koboSpan" id="kobo.1.1">9</span></h1>
<h1 id="_idParaDest-202"><a id="_idTextAnchor217"/><span class="koboSpan" id="kobo.2.1">Interpreting and Evaluating Machine Learning Models</span></h1>
<p><span class="koboSpan" id="kobo.3.1">The promise and potential of machine learning systems to create systems that can make decisions without the need for hardcoded rules or heuristics is huge. </span><span class="koboSpan" id="kobo.3.2">However, this promise is often far from straightforward to fulfil, and in developing machine learning models or leading teams who develop machine learning models, great care needs to be taken to ensure their accuracy </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">and reliability.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">In this chapter, we will explore how to interpret and evaluate different machine </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">learning models.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">This is one of, if not the most important skill you can have in your toolkit as a decision-maker working on data </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">science projects.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">While it can be convenient to allow data scientists to evaluate their own models and “mark their own homework,” this is a risky decision to make and will, invariably, eventually lead </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">to problems.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1">This chapter covers the </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.13.1">How do I know whether this model will </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">be accurate?</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">evaluation metrics</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">Evaluating </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">classification models</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">Methods for explaining machine </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">learning models</span></span></li>
</ul>
<h1 id="_idParaDest-203"><a id="_idTextAnchor218"/><span class="koboSpan" id="kobo.21.1">How do I know whether this model will be accurate?</span></h1>
<p><span class="koboSpan" id="kobo.22.1">As decision-makers, you</span><a id="_idIndexMarker593"/><span class="koboSpan" id="kobo.23.1"> need to be confident that the machine learning models you’re using provide you with reliable, accurate predictions or insights. </span><span class="koboSpan" id="kobo.23.2">However, how can you be sure? </span><span class="koboSpan" id="kobo.23.3">What metrics should you use to evaluate your models? </span><span class="koboSpan" id="kobo.23.4">And what do these metrics </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">really mean?</span></span></p>
<p><span class="koboSpan" id="kobo.25.1">Let’s attempt to understand how metrics are used to evaluate machine learning models and look at some </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">common examples.</span></span></p>
<h2 id="_idParaDest-204"><a id="_idTextAnchor219"/><span class="koboSpan" id="kobo.27.1">Evaluating on test (holdout) data</span></h2>
<p><span class="koboSpan" id="kobo.28.1">Before we get into the specifics around the different types of evaluation metrics, first, you need to understand the importance </span><a id="_idIndexMarker594"/><span class="koboSpan" id="kobo.29.1">of evaluating on test (a.k.a. </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">holdout) data.</span></span></p>
<p><span class="koboSpan" id="kobo.31.1">One very important aspect of model evaluation is the use of holdout (or test) data. </span><span class="koboSpan" id="kobo.31.2">This is a subset of your data that the model hasn’t seen during training or validation. </span><span class="koboSpan" id="kobo.31.3">Evaluating your model on holdout data gives you a more realistic estimate of its performance in the </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">real world.</span></span></p>
<p><span class="koboSpan" id="kobo.33.1">This test data should follow the same distribution of data that the model would see in the real world once it is in production. </span><span class="koboSpan" id="kobo.33.2">It should not be used in the training process or even for tuning different model hyperparameters, and care should be taken such that data do not leak between the training and test sets or between the independent variables and dependent (</span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">outcome) variables.</span></span></p>
<p><span class="koboSpan" id="kobo.35.1">It is only with a good set of test data that you can accurately evaluate a model and gain some confidence in its performance once it goes live in the </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">real world.</span></span></p>
<h1 id="_idParaDest-205"><a id="_idTextAnchor220"/><span class="koboSpan" id="kobo.37.1">Understanding evaluation metrics</span></h1>
<p><span class="koboSpan" id="kobo.38.1">In machine learning, an evaluation </span><a id="_idIndexMarker595"/><span class="koboSpan" id="kobo.39.1">metric is a measure used to quantify the quality of a </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">model’s predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.41.1">If understood and interpreted correctly, they can provide you with a measure with which to evaluate the quality of a model and, therefore, make more informed decisions about its use or whether more work is needed to train a more </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">accurate model.</span></span></p>
<p><span class="koboSpan" id="kobo.43.1">There is a wide range of evaluation metrics within machine learning, and different types of machine learning models require different </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">evaluation metrics.</span></span></p>
<p><span class="koboSpan" id="kobo.45.1">When considering supervised machine learning, which we covered in </span><a href="B19633_07.xhtml#_idTextAnchor163"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.46.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.47.1">, there are two groups of models: regression models and classification models, each with its own set of </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">evaluation metrics.</span></span></p>
<p><span class="koboSpan" id="kobo.49.1">First, let’s look at some of the more common metrics used for evaluating </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">regression models.</span></span></p>
<h2 id="_idParaDest-206"><a id="_idTextAnchor221"/><span class="koboSpan" id="kobo.51.1">Evaluating regression models</span></h2>
<p><span class="koboSpan" id="kobo.52.1">Imagine you’re a retail executive trying</span><a id="_idIndexMarker596"/><span class="koboSpan" id="kobo.53.1"> to forecast the next quarter’s sales. </span><span class="koboSpan" id="kobo.53.2">You’ve built a regression model for this purpose. </span><span class="koboSpan" id="kobo.53.3">However, how can you </span><a id="_idIndexMarker597"/><span class="koboSpan" id="kobo.54.1">assess its accuracy so that you can have some confidence in the next quarter’s </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">sales projections?</span></span></p>
<p><span class="koboSpan" id="kobo.56.1">Three common metrics for evaluating regression models are R-squared, </span><strong class="bold"><span class="koboSpan" id="kobo.57.1">root mean squared error</span></strong><span class="koboSpan" id="kobo.58.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.59.1">RMSE</span></strong><span class="koboSpan" id="kobo.60.1">), and </span><strong class="bold"><span class="koboSpan" id="kobo.61.1">mean absolute error</span></strong><span class="koboSpan" id="kobo.62.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.63.1">MAE</span></strong><span class="koboSpan" id="kobo.64.1">). </span><span class="koboSpan" id="kobo.64.2">Let’s discuss each </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">in turn.</span></span></p>
<h2 id="_idParaDest-207"><a id="_idTextAnchor222"/><span class="koboSpan" id="kobo.66.1">R-squared</span></h2>
<p><span class="koboSpan" id="kobo.67.1">The R-squared metric, also </span><a id="_idIndexMarker598"/><span class="koboSpan" id="kobo.68.1">known as the coefficient </span><a id="_idIndexMarker599"/><span class="koboSpan" id="kobo.69.1">of determination, is a statistical measure in regression analysis</span><a id="_idIndexMarker600"/><span class="koboSpan" id="kobo.70.1"> that represents the proportion of the variance in the dependent variable that is </span><strong class="bold"><span class="koboSpan" id="kobo.71.1">explained</span></strong><span class="koboSpan" id="kobo.72.1"> by the model. </span><span class="koboSpan" id="kobo.72.2">In simpler terms, it’s a measure of how well the regression predictions approximate the real </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">data points.</span></span></p>
<h3><span class="koboSpan" id="kobo.74.1">R-squared formula</span></h3>
<p><span class="koboSpan" id="kobo.75.1">The formula for R-squared can be</span><a id="_idIndexMarker601"/><span class="koboSpan" id="kobo.76.1"> seen in </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">the following:</span></span></p>
<p class="IMG---Figure"><span class="koboSpan" id="kobo.78.1">R 2 = 1−  SS res _ SS tot </span></p>
<p><span class="koboSpan" id="kobo.79.1">where we see the </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">following denotations:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.81.1">SS res is the sum of the squares of the residuals, also known as the residual sum of squares. </span><span class="koboSpan" id="kobo.81.2">It measures the variability of the </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">model’s errors.</span></span></li>
<li><span class="koboSpan" id="kobo.83.1">SS tot is the total sum of the squares. </span><span class="koboSpan" id="kobo.83.2">It measures the total variability of the </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">dependent variable.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.85.1">The sums of the squares are calculated </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.87.1">SS res = ∑ (y i−  ˆ y  </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">i</span></span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">)</span></span><span class="No-Break"><span class="koboSpan" id="kobo.90.1"> </span></span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">2</span></span></li>
<li><span class="koboSpan" id="kobo.92.1">SS tot = ∑ (y i− _ y ) 2</span></li>
</ul>
<p><span class="koboSpan" id="kobo.93.1">In these formulas, we denote </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.95.1">y i is the actual </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">observed value</span></span></li>
<li><span class="koboSpan" id="kobo.97.1"> ˆ y  i is the predicted value by the </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">regression model</span></span></li>
<li><span class="koboSpan" id="kobo.99.1"> _ y  is the mean of </span><a id="_idIndexMarker602"/><span class="koboSpan" id="kobo.100.1">the </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">observed data</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.102.1">Understanding R-squared</span></h3>
<p><span class="koboSpan" id="kobo.103.1">An R-squared of 1 indicates that the</span><a id="_idIndexMarker603"/><span class="koboSpan" id="kobo.104.1"> regression predictions perfectly fit </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.106.1">An R-squared of 0 means that the model does not explain any of the variability of the response data around </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">its mean.</span></span></p>
<h3><span class="koboSpan" id="kobo.108.1">Example of an R-squared calculation</span></h3>
<p><span class="koboSpan" id="kobo.109.1">Imagine you work for a retailer and </span><a id="_idIndexMarker604"/><span class="koboSpan" id="kobo.110.1">that you have a dataset of monthly sales volumes for one of your top products, as well as the predictions of those sales volumes from a regression model covering the </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">past 6-months:</span></span></p>
<p><span class="koboSpan" id="kobo.112.1">Observed Data (y): [725, 693, 654, 712, </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">722, 695]</span></span></p>
<p><span class="koboSpan" id="kobo.114.1">Predicted Data ( ˆ y ) : [720, 695, 660, 715, </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">724, 698]</span></span></p>
<p><span class="koboSpan" id="kobo.116.1">First, calculate the mean of the observed data ( _ </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">y</span></span><span class="No-Break"><span class="koboSpan" id="kobo.118.1"> </span></span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">)</span></span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">:</span></span></p>
<p class="IMG---Figure"><span class="koboSpan" id="kobo.121.1"> _ y  =  725 + 693 + 654 + 712 + 722 + 695   ________________________  6  = 700.17</span></p>
<p><span class="koboSpan" id="kobo.122.1"> Next, calculate SS res and </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">S</span></span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">S</span></span><span class="No-Break"><span class="koboSpan" id="kobo.125.1"> </span></span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">t</span></span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">o</span></span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">t</span></span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">:</span></span></p>
<p><span class="koboSpan" id="kobo.130.1">SS res = (725 − 720) 2 + (693 − 695) 2 + (654 − 660) 2 + (712 − 715) 2 + (722 − 724) 2 + (695 − 698) 2 = </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">87</span></span></p>
<p><span class="koboSpan" id="kobo.132.1">SS tot = (725 −  _ y ) 2 + (693 −  _ y ) 2 + (654 −  _ y ) 2 + (712 −  _ y ) 2 + (722 −  _ y ) 2 + (695 −  _ y ) 2 = </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">3442.8</span></span></p>
<p><span class="koboSpan" id="kobo.134.1">R 2 = 1−  87 _ 3442.8  = </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">0.97</span></span></p>
<p><span class="koboSpan" id="kobo.136.1">So, in this case, our R-squared value is approximately 0.97, indicating that the regression model can explain 97% of the observed data. </span><span class="koboSpan" id="kobo.136.2">This is a high value, suggesting that the model provides a very good fit for the data (this could be due to overfitting, which we will cover in a </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">later chapter).</span></span></p>
<p><span class="koboSpan" id="kobo.138.1">When interpreting R-squared values, there is no universal benchmark for a “good” R-square value, but understanding that the closer the value is to 1, the better the model is at explaining the data can help </span><a id="_idIndexMarker605"/><span class="koboSpan" id="kobo.139.1">when comparing </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">different models.</span></span></p>
<p><span class="koboSpan" id="kobo.141.1">Two evaluation metrics that can be clearer to interpret are </span><strong class="bold"><span class="koboSpan" id="kobo.142.1">RMSE</span></strong><span class="koboSpan" id="kobo.143.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.144.1">RAE</span></strong><span class="koboSpan" id="kobo.145.1">, which we will look </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">into now.</span></span></p>
<h2 id="_idParaDest-208"><a id="_idTextAnchor223"/><span class="koboSpan" id="kobo.147.1">Root mean squared error</span></h2>
<p><span class="koboSpan" id="kobo.148.1">RMSE is a widely used metric in regression analysis that measures the average magnitude of the errors between the values </span><a id="_idIndexMarker606"/><span class="koboSpan" id="kobo.149.1">predicted by a model and the values observed. </span><span class="koboSpan" id="kobo.149.2">It gives an estimate of the standard deviation of the </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">prediction errors.</span></span></p>
<p><span class="koboSpan" id="kobo.151.1">Unlike R-squared, which is a </span><a id="_idIndexMarker607"/><span class="koboSpan" id="kobo.152.1">relative measure of fit, RMSE provides an absolute scale of measurement, giving a direct interpretation of the model’s prediction accuracy in the units of the variable of interest. </span><span class="koboSpan" id="kobo.152.2">It’s particularly useful in evaluating the precision of prediction models and is sensitive to large errors, making it a useful tool for assessing </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1">model performance.</span></span></p>
<h3><span class="koboSpan" id="kobo.154.1">RMSE formula</span></h3>
<p><span class="koboSpan" id="kobo.155.1">The formula for calculating </span><a id="_idIndexMarker608"/><span class="koboSpan" id="kobo.156.1">the RMSE </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">is this:</span></span></p>
<p class="IMG---Figure"><span class="koboSpan" id="kobo.158.1">√ ____________   1 _ n  ∑ i=1 n ( y i −  ˆ y  i) 2 </span></p>
<p><span class="koboSpan" id="kobo.159.1">where we see the </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">following denotations:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.161.1">n is the number </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">of observations</span></span></li>
<li><span class="koboSpan" id="kobo.163.1">y i is the actual </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">observed value</span></span></li>
<li><span class="koboSpan" id="kobo.165.1"> ˆ y  i is the predicted value by </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">the model</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.167.1">This formula effectively measures the square root of the average squared differences between the actual and predicted </span><a id="_idIndexMarker609"/><span class="koboSpan" id="kobo.168.1">values, providing a clear measure of </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">model accuracy.</span></span></p>
<h3><span class="koboSpan" id="kobo.170.1">Example of an RMSE calculation</span></h3>
<p><span class="koboSpan" id="kobo.171.1">By continuing with the retailer’s dataset </span><a id="_idIndexMarker610"/><span class="koboSpan" id="kobo.172.1">from the R-squared example, where the observed monthly sales volumes (y) are [725, 693, 654, 712, 722, 695] and the predicted sales volumes ( ˆ y ) are [720, 695, 660, 715, 724, 698], we can calculate the RMSE </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.174.1">Calculate the squared differences between the actual and </span><span class="No-Break"><span class="koboSpan" id="kobo.175.1">predicted values.</span></span></li>
<li><span class="koboSpan" id="kobo.176.1">Compute the average of these </span><span class="No-Break"><span class="koboSpan" id="kobo.177.1">squared differences.</span></span></li>
<li><span class="koboSpan" id="kobo.178.1">Take the square root of this average to find </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">the RMSE.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.180.1">Let’s calculate the RMSE for this dataset. </span><span class="koboSpan" id="kobo.180.2">We know from the R-squared calculation that the sum of squared differences between the actual and predicted values </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">is this:</span></span></p>
<p class="IMG---Figure"><span class="koboSpan" id="kobo.182.1">SS res = ∑ (y i−  ˆ y  i) 2 = 87</span></p>
<p><span class="koboSpan" id="kobo.183.1">In addition, we know the number of observations is n = 6 (i.e., </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">6 months).</span></span></p>
<p><span class="koboSpan" id="kobo.185.1">By plugging these numbers into our RMSE equation, we find </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">the following:</span></span></p>
<p><span class="koboSpan" id="kobo.187.1">RMSE = √ ____________   1 _ n  ∑ i=1 n ( y i −  ˆ y  i) 2  = √ _  1 _ 6  * 87  = </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">3.8</span></span></p>
<h3><span class="koboSpan" id="kobo.189.1">Understanding RMSE values</span></h3>
<p><span class="koboSpan" id="kobo.190.1">The RMSE value gives insight into</span><a id="_idIndexMarker611"/><span class="koboSpan" id="kobo.191.1"> the average error in the same units as the response variable, making it intuitively easier to understand. </span><span class="koboSpan" id="kobo.191.2">A lower RMSE value indicates a better fit of the model to </span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.193.1">However, like R-squared, there’s no absolute “good” or “bad” threshold for RMSE, as it depends on the context of the data and the specific domain of its application. </span><span class="koboSpan" id="kobo.193.2">It’s best used comparatively to assess improvements in model accuracy or to compare performance across different models </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">or datasets.</span></span></p>
<p><span class="koboSpan" id="kobo.195.1">In our example, the RMSE for the given dataset is approximately 3.8. </span><span class="koboSpan" id="kobo.195.2">This indicates that, on average, the model’s predictions are within 3.8 units of the actual sales figures. </span><span class="koboSpan" id="kobo.195.3">This appears to be a very accurate set of predictions, but the context of the business needs and how this may compare to</span><a id="_idIndexMarker612"/><span class="koboSpan" id="kobo.196.1"> other models helps us understand the evaluation accuracy </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">in context.</span></span></p>
<h3><span class="koboSpan" id="kobo.198.1">Practical tips for interpreting RMSE</span></h3>
<p><span class="koboSpan" id="kobo.199.1">The following are some practical tips for </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">interpreting RMSE:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.201.1">Comparative analysis</span></strong><span class="koboSpan" id="kobo.202.1">: Use RMSE to </span><a id="_idIndexMarker613"/><span class="koboSpan" id="kobo.203.1">compare model performance, especially when tweaking models or choosing between different types </span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">of models.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.205.1">Unit sensitivity</span></strong><span class="koboSpan" id="kobo.206.1">: Remember that RMSE is sensitive to the scale of the data, so interpret it in the context of the magnitude of your </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">dependent variable.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.208.1">Complement with other metrics</span></strong><span class="koboSpan" id="kobo.209.1">: Combine RMSE with other metrics, such as R-squared, to get a more holistic view of model performance. </span><span class="koboSpan" id="kobo.209.2">While RMSE provides a measure of accuracy in the response variable’s units, R-squared offers insight into the variance explained by </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">the model.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.211.1">Now, let’s consider one other evaluation metric for regression </span><span class="No-Break"><span class="koboSpan" id="kobo.212.1">models: MAE.</span></span></p>
<h2 id="_idParaDest-209"><a id="_idTextAnchor224"/><span class="koboSpan" id="kobo.213.1">Mean absolute error</span></h2>
<p><span class="koboSpan" id="kobo.214.1">MAE is a measure used in regression analysis to quantify the average magnitude of the errors between predicted values and observed actual outcomes without considering their direction. </span><span class="koboSpan" id="kobo.214.2">It calculates the </span><a id="_idIndexMarker614"/><span class="koboSpan" id="kobo.215.1">average of the absolute differences between </span><a id="_idIndexMarker615"/><span class="koboSpan" id="kobo.216.1">the predicted values and actual values, making it a simple yet clear metric for assessing </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">model accuracy.</span></span></p>
<h3><span class="koboSpan" id="kobo.218.1">MAE formula</span></h3>
<p><span class="koboSpan" id="kobo.219.1">The formula for calculating </span><a id="_idIndexMarker616"/><span class="koboSpan" id="kobo.220.1">MAE is </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">the following:</span></span></p>
<p class="IMG---Figure"><span class="koboSpan" id="kobo.222.1">MAE =  1 _ n  ∑ i=1 n |y i −  ˆ y  i|</span></p>
<p><span class="koboSpan" id="kobo.223.1">where, as we have seen before, the </span><span class="No-Break"><span class="koboSpan" id="kobo.224.1">following applies:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.225.1">n is the number </span><span class="No-Break"><span class="koboSpan" id="kobo.226.1">of observations</span></span></li>
<li><span class="koboSpan" id="kobo.227.1">y i is the actual </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">observed value</span></span></li>
<li><span class="koboSpan" id="kobo.229.1"> ˆ y  i is the predicted value from </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">the model</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.231.1">This formula emphasizes the absolute value of the errors, thereby treating all errors with equal weight, regardless</span><a id="_idIndexMarker617"/><span class="koboSpan" id="kobo.232.1"> of </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">their direction.</span></span></p>
<h3><span class="koboSpan" id="kobo.234.1">Example of an MAE calculation</span></h3>
<p><span class="koboSpan" id="kobo.235.1">Continuing with the retailer example used </span><a id="_idIndexMarker618"/><span class="koboSpan" id="kobo.236.1">for the R-squared and RMSE calculations, as an exercise, you can calculate the MAE using the observed sales volume data (y) and predicted data ( ˆ y ) to understand (using a practical illustration) how MAE </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">is determined.</span></span></p>
<p><span class="koboSpan" id="kobo.238.1">A reminder that the absolute value of a difference is the positive magnitude of the difference. </span><span class="koboSpan" id="kobo.238.2">For example, the absolute value of |5 − 10| = |− 5| = 5 and the absolute value of, for example, |7 − 4| = |3| = </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">3</span></span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.241.1">The MAE for the example sales volume data and predictions should </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">be this:</span></span></p>
<p><span class="koboSpan" id="kobo.243.1">MAE = </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">3.5</span></span></p>
<p><span class="koboSpan" id="kobo.245.1">See if you can calculate this answer using the sales volume values and predictions </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">provided previously.</span></span></p>
<h3><span class="koboSpan" id="kobo.247.1">Understanding MAE values</span></h3>
<p><span class="koboSpan" id="kobo.248.1">MAE provides an intuitive understanding of the average error magnitude. </span><span class="koboSpan" id="kobo.248.2">A lower MAE value indicates a model with better </span><a id="_idIndexMarker619"/><span class="koboSpan" id="kobo.249.1">predictive accuracy. </span><span class="koboSpan" id="kobo.249.2">Unlike RMSE, MAE is not as sensitive to outliers, as it does not square the errors before averaging. </span><span class="koboSpan" id="kobo.249.3">This characteristic makes MAE particularly useful in scenarios where you want to avoid the disproportionate effect of </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">large errors.</span></span></p>
<h3><span class="koboSpan" id="kobo.251.1">Practical tips for interpreting MAE</span></h3>
<p><span class="koboSpan" id="kobo.252.1">The following are some practical tips</span><a id="_idIndexMarker620"/><span class="koboSpan" id="kobo.253.1"> for </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">interpreting MAE:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.255.1">Error interpretation</span></strong><span class="koboSpan" id="kobo.256.1">: Use MAE to get a direct understanding of the average error in the same units as the data. </span><span class="koboSpan" id="kobo.256.2">This makes it particularly accessible for </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">non-technical stakeholders.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.258.1">Outlier sensitivity</span></strong><span class="koboSpan" id="kobo.259.1">: Consider the nature of your data and whether emphasizing or de-emphasizing outliers is important. </span><span class="koboSpan" id="kobo.259.2">MAE treats all errors equally, making it a robust measure against large </span><span class="No-Break"><span class="koboSpan" id="kobo.260.1">individual errors.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.261.1">Complementary metrics</span></strong><span class="koboSpan" id="kobo.262.1">: Just as with RMSE, it’s advisable to use MAE alongside other </span><a id="_idIndexMarker621"/><span class="koboSpan" id="kobo.263.1">metrics to get a fuller picture of model performance. </span><span class="koboSpan" id="kobo.263.2">MAE can be particularly informative when used in conjunction with RMSE, as the two metrics together can provide insights into the error distribution and the presence </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">of outliers.</span></span></li>
</ul>
<h2 id="_idParaDest-210"><a id="_idTextAnchor225"/><span class="koboSpan" id="kobo.265.1">When and how to use each metric</span></h2>
<p><span class="koboSpan" id="kobo.266.1">Now that we have seen each of these regression metrics, it is worthwhile discussing when to use each and how they</span><a id="_idIndexMarker622"/><span class="koboSpan" id="kobo.267.1"> complement </span><span class="No-Break"><span class="koboSpan" id="kobo.268.1">each other:</span></span></p>
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.269.1">R-squared</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">:</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.271.1">When to </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.272.1">use it</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.273.1">:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.274.1">It is ideal for assessing the explanatory</span><a id="_idIndexMarker623"/><span class="koboSpan" id="kobo.275.1"> power of </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">the model</span></span></li>
<li><span class="koboSpan" id="kobo.277.1">It is useful for comparing the model’s performance against a baseline model or other models on the </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">same dataset</span></span></li>
</ul>
<p><strong class="bold"><span class="koboSpan" id="kobo.279.1">How to </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.280.1">use it</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">:</span></span></p>
<p><span class="koboSpan" id="kobo.282.1">Higher values (closer to 1) indicate a </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">better fit.</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.284.1">Consider using it in conjunction with other metrics for a comprehensive </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">model evaluation</span></span></li>
</ul>
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.286.1">RMSE</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.287.1">:</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.288.1">When to </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.289.1">use it</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.291.1">It is best for models where</span><a id="_idIndexMarker624"/><span class="koboSpan" id="kobo.292.1"> large errors are </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">particularly undesirable</span></span></li>
<li><span class="koboSpan" id="kobo.294.1">It is suitable for comparing across models or model versions to gauge improvement in </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">predictive accuracy</span></span></li>
</ul>
<p><strong class="bold"><span class="koboSpan" id="kobo.296.1">How to </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.297.1">use it</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.299.1">Lower values indicate a more </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">accurate model</span></span></li>
<li><span class="koboSpan" id="kobo.301.1">Use it as a primary metric for precision, but analyze a model alongside R-squared to understand both fit </span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">and accuracy</span></span></li>
</ul>
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.303.1">MAE</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">:</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.305.1">When to </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.306.1">use it</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.308.1">Use it when you require a</span><a id="_idIndexMarker625"/><span class="koboSpan" id="kobo.309.1"> straightforward metric that is easy to explain </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">and understand</span></span></li>
<li><span class="koboSpan" id="kobo.311.1">Use it in scenarios where outliers are present but should not disproportionately impact the model’s </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">error metric</span></span></li>
</ul>
<p><strong class="bold"><span class="koboSpan" id="kobo.313.1">How to </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.314.1">use it</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.316.1">Lower values are better, indicating tighter conformity of predictions to </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">actual values</span></span></li>
<li><span class="koboSpan" id="kobo.318.1">Consider using MAE to complement RMSE for a nuanced view of error distribution and to assess the impact </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">of outliers</span></span></li>
</ul>
<h2 id="_idParaDest-211"><a id="_idTextAnchor226"/><span class="koboSpan" id="kobo.320.1">Practical evaluation strategies</span></h2>
<p><span class="koboSpan" id="kobo.321.1">Here are some of the most </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">popular strategies:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.323.1">Balanced approach</span></strong><span class="koboSpan" id="kobo.324.1">: Utilize a combination of these metrics to get a holistic view of model performance. </span><span class="koboSpan" id="kobo.324.2">R-squared </span><a id="_idIndexMarker626"/><span class="koboSpan" id="kobo.325.1">offers insights into how well the model explains the data. </span><span class="koboSpan" id="kobo.325.2">RMSE helps identify how large, on average, the errors are, with a penalty for larger errors. </span><span class="koboSpan" id="kobo.325.3">MAE provides a simple average error magnitude, which is useful for understanding the typical </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">error size.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.327.1">Contextual interpretation</span></strong><span class="koboSpan" id="kobo.328.1">: Always contextualize the metrics within your specific business or research objectives. </span><span class="koboSpan" id="kobo.328.2">A good metric value in one context might not be acceptable in another, depending on the precision required or the cost </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">of errors.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.330.1">Comparative analysis</span></strong><span class="koboSpan" id="kobo.331.1">: Use these metrics not just in isolation but also comparatively across different models or iterations of the same model. </span><span class="koboSpan" id="kobo.331.2">This can help with selecting the best model or refining a model to better </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">meet objectives.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.333.1">Error sensitivity</span></strong><span class="koboSpan" id="kobo.334.1">: Consider the nature of your prediction task and the consequences of errors. </span><span class="koboSpan" id="kobo.334.2">If large errors are more problematic, RMSE will be particularly informative. </span><span class="koboSpan" id="kobo.334.3">If consistent errors are of concern, regardless of their size, MAE will provide </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">valuable insights.</span></span></li>
</ul>
<h2 id="_idParaDest-212"><a id="_idTextAnchor227"/><span class="koboSpan" id="kobo.336.1">Summarizing the evaluation of regression models</span></h2>
<p><span class="koboSpan" id="kobo.337.1">By leveraging R-squared, RMSE, and</span><a id="_idIndexMarker627"/><span class="koboSpan" id="kobo.338.1"> MAE thoughtfully, as a decision-maker, you can critically assess model performance beyond just a single dimension of accuracy or fit. </span><span class="koboSpan" id="kobo.338.2">This multi-metric approach enables a more</span><a id="_idIndexMarker628"/><span class="koboSpan" id="kobo.339.1"> nuanced understanding and evaluation of regression models, guiding the selection, development, and refinement of models to align with specific </span><span class="No-Break"><span class="koboSpan" id="kobo.340.1">business goals.</span></span></p>
<p><span class="koboSpan" id="kobo.341.1">Now that we have looked at evaluation metrics for regression models, let’s now turn to classification models and how they can </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">be evaluated.</span></span></p>
<h1 id="_idParaDest-213"><a id="_idTextAnchor228"/><span class="koboSpan" id="kobo.343.1">Evaluating classification models</span></h1>
<p><span class="koboSpan" id="kobo.344.1">Imagine you are running a business with a large portfolio of customers, and you are trying to predict which customers are likely to stop using your service within the next year. </span><span class="koboSpan" id="kobo.344.2">This is a common binary classification model known as a </span><a id="_idIndexMarker629"/><span class="koboSpan" id="kobo.345.1">customer churn model; many companies, whether banks, telecoms providers, insurance companies, or streaming services, can benefit from knowing which of their customers are most likely to churn so that they can take</span><a id="_idIndexMarker630"/><span class="koboSpan" id="kobo.346.1"> action to retain </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">these customers.</span></span></p>
<p><span class="koboSpan" id="kobo.348.1">You may have evaluated your customer churn model’s predictions on a test (holdout) set, for example, for the previous year, where you know whether a customer did, indeed, leave or stay with </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">the company.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.350.1">Important note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.351.1">For this example, let’s refer to a customer who has churned as a “positive” outcome, as this is the outcome we are trying to predict (in this context, “positive” or “negative” does not have anything to do with the sentiment or favorability of </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">the outcome).</span></span></p>
<p><span class="koboSpan" id="kobo.353.1">There are four different types of outcomes you would observe when evaluating your </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">model’s predictions:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.355.1">True positive</span></strong><span class="koboSpan" id="kobo.356.1">: A true positive would be when our model predicts that the customer churned, and the customer did, indeed, churn (i.e., a </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">correct prediction).</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.358.1">False positive</span></strong><span class="koboSpan" id="kobo.359.1">: A false positive, also known as a Type I error, is when our model predicts that a customer churned; however, the actual outcome was that a customer did </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.360.1">not</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.361.1"> churn.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.362.1">True negative</span></strong><span class="koboSpan" id="kobo.363.1">: A true negative is when the model predicted that the customer did not churn, and the actual outcome is that the customer did not churn (i.e., another </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">correct prediction).</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.365.1">False negative</span></strong><span class="koboSpan" id="kobo.366.1">: A false negative, also known as a Type II error, is when our model predicts that the customer did </span><strong class="bold"><span class="koboSpan" id="kobo.367.1">not</span></strong><span class="koboSpan" id="kobo.368.1"> churn; however, the actual outcome was that the customer </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">did churn.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.370.1">Each of these four types of results can help inform us how accurate the model (on the test set) is at predicting the </span><span class="No-Break"><span class="koboSpan" id="kobo.371.1">different outcomes.</span></span></p>
<p><span class="koboSpan" id="kobo.372.1">There are different evaluation </span><a id="_idIndexMarker631"/><span class="koboSpan" id="kobo.373.1">metrics that we can use to calculate the counts of each of these outcomes, which we will see. </span><span class="koboSpan" id="kobo.373.2">A useful way to visualize classification results is with a </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">confusion matrix:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer072">
<span class="koboSpan" id="kobo.375.1"><img alt="Figure 9.1: Confusion matrix for binary classification" src="image/B19633_09_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.376.1">Figure 9.1: Confusion matrix for binary classification</span></p>
<p><span class="koboSpan" id="kobo.377.1">To solidify our understanding of a confusion matrix, let’s map the outcomes from our example onto a</span><a id="_idIndexMarker632"/> <span class="No-Break"><span class="koboSpan" id="kobo.378.1">confusion matrix:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer073">
<span class="koboSpan" id="kobo.379.1"><img alt="Figure 9.2: Confusion matrix for the binary classification of the customer churn example" src="image/B19633_09_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.380.1">Figure 9.2: Confusion matrix for the binary classification of the customer churn example</span></p>
<p><span class="koboSpan" id="kobo.381.1">From the counts of these different outcomes on a test (holdout) dataset, we can calculate useful evaluation metrics for a machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">classification model.</span></span></p>
<p><span class="koboSpan" id="kobo.383.1">Let’s look into some of these metrics and how they can be interpreted to help us understand the predictive power of </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">our models.</span></span></p>
<h2 id="_idParaDest-214"><a id="_idTextAnchor229"/><span class="koboSpan" id="kobo.385.1">Classification model evaluation metrics</span></h2>
<p><span class="koboSpan" id="kobo.386.1">First, let’s consider our example of the customer</span><a id="_idIndexMarker633"/><span class="koboSpan" id="kobo.387.1"> churn model. </span><span class="koboSpan" id="kobo.387.2">Let’s say that on our test data, we predicted the outcome for 1,000 customers. </span><span class="koboSpan" id="kobo.387.3">Of these, 150 were predicted to churn, and they did, in fact, churn (true positives), and the 50 who we predicted to churn did not churn and stayed as customers (false positives). </span><span class="koboSpan" id="kobo.387.4">We also predicted that 600 customers would not churn, and they did not churn (true negatives). </span><span class="koboSpan" id="kobo.387.5">However, 200 customers who we predicted would not churn did churn (</span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">false negatives):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer074">
<span class="koboSpan" id="kobo.389.1"><img alt="Figure 9.3: Confusion matrix results for the binary classification of the customer churn example" src="image/B19633_09_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.390.1">Figure 9.3: Confusion matrix results for the binary classification of the customer churn example</span></p>
<p><span class="koboSpan" id="kobo.391.1">From these values, we can calculate several useful metrics to help evaluate our model. </span><span class="koboSpan" id="kobo.391.2">Let’s take a look at some of these </span><span class="No-Break"><span class="koboSpan" id="kobo.392.1">evaluation metrics.</span></span></p>
<h2 id="_idParaDest-215"><a id="_idTextAnchor230"/><span class="koboSpan" id="kobo.393.1">Precision, recall, and F1-Score</span></h2>
<p><span class="koboSpan" id="kobo.394.1">The first metric we will look at </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">is precision.</span></span></p>
<p><span class="koboSpan" id="kobo.396.1">Precision allows </span><a id="_idIndexMarker634"/><span class="koboSpan" id="kobo.397.1">us to evaluate how </span><strong class="bold"><span class="koboSpan" id="kobo.398.1">precisely</span></strong><span class="koboSpan" id="kobo.399.1"> our model makes </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">positive predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.401.1">More formally, precision</span><a id="_idIndexMarker635"/><span class="koboSpan" id="kobo.402.1"> is the ratio of true positive predictions to the </span><strong class="bold"><span class="koboSpan" id="kobo.403.1">total</span></strong><span class="koboSpan" id="kobo.404.1"> number of positive predictions made by the </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">classification model.</span></span></p>
<p><span class="koboSpan" id="kobo.406.1">It answers the question, Of all the instances labeled as positive by my model, how many are </span><span class="No-Break"><span class="koboSpan" id="kobo.407.1">actually positive?</span></span></p>
<h3><span class="koboSpan" id="kobo.408.1">Precision calculation</span></h3>
<p><span class="koboSpan" id="kobo.409.1">The formula for calculating </span><a id="_idIndexMarker636"/><span class="koboSpan" id="kobo.410.1">precision is </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">given here:</span></span></p>
<p><span class="koboSpan" id="kobo.412.1">Precision =  True Positives (TP)  ____________________________   True Positives (TP) + False Positives (FP) </span></p>
<p><span class="koboSpan" id="kobo.413.1">In our example, the precision would be calculated </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">as follows:</span></span></p>
<p><span class="koboSpan" id="kobo.415.1">Precision =  150 _ 150 + 50  = </span><span class="No-Break"><span class="koboSpan" id="kobo.416.1">0.75</span></span></p>
<p><span class="koboSpan" id="kobo.417.1">Precision can vary from 0 to 1, where precision of 1 implies that the model is perfectly precise at predicting the positive outcome (that the customer churns). </span><span class="koboSpan" id="kobo.417.2">Here, the precision suggests that when the model predicts that a customer will churn, then three out of four times, they will, in </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">fact, churn.</span></span></p>
<h3><span class="koboSpan" id="kobo.419.1">Understanding precision</span></h3>
<p><span class="koboSpan" id="kobo.420.1">Precision focuses solely on the model’s performance in accurately predicting the positive class. </span><span class="koboSpan" id="kobo.420.2">A high precision score indicates that the model is reliable in its positive classifications, meaning that when it predicts a positive result, you can be quite confident in its accuracy. </span><span class="koboSpan" id="kobo.420.3">However, precision does not take into account the false negatives (instances that are positive but predicted as negative) that are covered by another metric, such as recall, which we </span><span class="No-Break"><span class="koboSpan" id="kobo.421.1">will discuss.</span></span></p>
<h3><span class="koboSpan" id="kobo.422.1">When to use precision</span></h3>
<p><span class="koboSpan" id="kobo.423.1">Here are some examples of when best to </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">use precision:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.425.1">High cost of false positives</span></strong><span class="koboSpan" id="kobo.426.1">: Precision is </span><a id="_idIndexMarker637"/><span class="koboSpan" id="kobo.427.1">particularly useful when the cost of a false positive is high. </span><span class="koboSpan" id="kobo.427.2">For example, in email spam detection, a high precision is required because classifying an important email as spam (a false positive) could mean missing </span><span class="No-Break"><span class="koboSpan" id="kobo.428.1">critical information.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.429.1">Imbalanced datasets</span></strong><span class="koboSpan" id="kobo.430.1">: In datasets where the positive class is rare (imbalanced datasets), precision becomes a crucial measure to ensure that the positive predictions made by the model are, </span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">indeed, correct.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.432.1">Precision is a key metric </span><a id="_idIndexMarker638"/><span class="koboSpan" id="kobo.433.1">in classification that helps assess the reliability of the positive predictions made by a model, making it very useful in contexts where false positives have </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">significant consequences.</span></span></p>
<h2 id="_idParaDest-216"><a id="_idTextAnchor231"/><span class="koboSpan" id="kobo.435.1">Recall</span></h2>
<p><span class="koboSpan" id="kobo.436.1">Recall, also known as</span><a id="_idIndexMarker639"/><span class="koboSpan" id="kobo.437.1"> sensitivity or the true positive rate, is a critical performance metric used in </span><a id="_idIndexMarker640"/><span class="koboSpan" id="kobo.438.1">classification tasks to</span><a id="_idIndexMarker641"/><span class="koboSpan" id="kobo.439.1"> evaluate the ability of a model to correctly identify all </span><a id="_idIndexMarker642"/><span class="koboSpan" id="kobo.440.1">relevant instances of a particular class. </span><span class="koboSpan" id="kobo.440.2">It is especially important in situations where the cost of missing a positive instance (false negative) </span><span class="No-Break"><span class="koboSpan" id="kobo.441.1">is high.</span></span></p>
<p><span class="koboSpan" id="kobo.442.1">Here’s a </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">detailed explanation:</span></span></p>
<p><span class="koboSpan" id="kobo.444.1">Recall measures the proportion of actual positive cases that were correctly identified by the model. </span><span class="koboSpan" id="kobo.444.2">It addresses the question, Of all the actual positives in the dataset, how many were correctly identified as positive by </span><span class="No-Break"><span class="koboSpan" id="kobo.445.1">the model?</span></span></p>
<h3><span class="koboSpan" id="kobo.446.1">Formula for recall</span></h3>
<p><span class="koboSpan" id="kobo.447.1">The formula for calculating</span><a id="_idIndexMarker643"/><span class="koboSpan" id="kobo.448.1"> recall is </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">given here:</span></span></p>
<p><span class="koboSpan" id="kobo.450.1">Recall =  True Positives (TP)  _____________________________   True Positives (TP) + False Negatives (FN) </span></p>
<p><span class="koboSpan" id="kobo.451.1">In our example, recall would be calculated according to </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">the following:</span></span></p>
<p><span class="koboSpan" id="kobo.453.1">Recall =  150 _ 150 + 200  ≈ </span><span class="No-Break"><span class="koboSpan" id="kobo.454.1">0.43</span></span></p>
<p><span class="koboSpan" id="kobo.455.1">This suggests that our model correctly identifies less than half of the customers </span><span class="No-Break"><span class="koboSpan" id="kobo.456.1">who churned.</span></span></p>
<h3><span class="koboSpan" id="kobo.457.1">Understanding recall</span></h3>
<p><span class="koboSpan" id="kobo.458.1">Recall focuses on the model’s capability to find all the relevant cases within a dataset. </span><span class="koboSpan" id="kobo.458.2">A high recall score indicates that the model is effective at capturing the majority of positive instances, minimizing the </span><a id="_idIndexMarker644"/><span class="koboSpan" id="kobo.459.1">number of false negatives. </span><span class="koboSpan" id="kobo.459.2">However, it does not account for the correctness of negative predictions, which is covered </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">by specificity.</span></span></p>
<p><span class="koboSpan" id="kobo.461.1">In the case of our example, it may be the case that recall is more important than precision, as we may want to correctly identify all of the customers who will churn so that we can take some remedial actions to try and retain them, even at the cost of some potential </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">false positives.</span></span></p>
<p><span class="koboSpan" id="kobo.463.1">In this situation, it is sometimes possible to change the </span><strong class="bold"><span class="koboSpan" id="kobo.464.1">threshold</span></strong><span class="koboSpan" id="kobo.465.1"> that the model uses to predict true or false outcomes to favor increasing recall at the cost of precision or </span><span class="No-Break"><span class="koboSpan" id="kobo.466.1">vice versa.</span></span></p>
<p><span class="koboSpan" id="kobo.467.1">It is important to understand which is more important for your business case: having fewer false positives (i.e., higher precision) or fewer false negatives (i.e., </span><span class="No-Break"><span class="koboSpan" id="kobo.468.1">higher recall).</span></span></p>
<h3><span class="koboSpan" id="kobo.469.1">When to use recall</span></h3>
<p><span class="koboSpan" id="kobo.470.1">Here are some examples of when best to </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1">use recall:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.472.1">High cost of false negatives</span></strong><span class="koboSpan" id="kobo.473.1">: Recall is crucial in</span><a id="_idIndexMarker645"/><span class="koboSpan" id="kobo.474.1"> contexts where missing a positive instance is more critical than falsely identifying a negative instance as positive. </span><span class="koboSpan" id="kobo.474.2">For instance, in medical screening tests for diseases, a high recall is necessary to ensure that as many positive cases as possible are identified for </span><span class="No-Break"><span class="koboSpan" id="kobo.475.1">further testing.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.476.1">Imbalanced datasets</span></strong><span class="koboSpan" id="kobo.477.1">: In datasets where the positive class is rare, maximizing recall ensures that the model does not overlook the few positive </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">instances present.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.479.1">Comprehensive coverage</span></strong><span class="koboSpan" id="kobo.480.1">: It is useful when the goal is to ensure no positive instance is missed, even at the expense of higher </span><span class="No-Break"><span class="koboSpan" id="kobo.481.1">false positives.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.482.1">Practical implications</span></h3>
<p><span class="koboSpan" id="kobo.483.1">While recall is an essential metric for evaluating</span><a id="_idIndexMarker646"/><span class="koboSpan" id="kobo.484.1"> the comprehensiveness of a model in identifying positive cases, focusing solely on recall can lead to models that classify too many instances as positive (high false positives), reducing precision. </span><span class="koboSpan" id="kobo.484.2">This is why recall is often used alongside precision to understand the trade-offs between capturing all positives and the accuracy of </span><span class="No-Break"><span class="koboSpan" id="kobo.485.1">positive predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.486.1">The balance between recall and precision is quantified by F1-score, which provides a single metric to assess model </span><a id="_idIndexMarker647"/><span class="koboSpan" id="kobo.487.1">performance when both recall and precision are considered important, which we will look </span><span class="No-Break"><span class="koboSpan" id="kobo.488.1">at now.</span></span></p>
<h2 id="_idParaDest-217"><a id="_idTextAnchor232"/><span class="koboSpan" id="kobo.489.1">F1-score</span></h2>
<p><span class="koboSpan" id="kobo.490.1">F1-score is a helpful metric used in the </span><a id="_idIndexMarker648"/><span class="koboSpan" id="kobo.491.1">evaluation of binary classification models, especially in situations where the balance between precision and recall is important. </span><span class="koboSpan" id="kobo.491.2">It is particularly useful when dealing with datasets that have an uneven class distribution or when the cost of false positives and false negatives </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">varies significantly.</span></span></p>
<h3><span class="koboSpan" id="kobo.493.1">Definition of F1-score</span></h3>
<p><span class="koboSpan" id="kobo.494.1">F1-score is the harmonic mean of precision </span><a id="_idIndexMarker649"/><span class="koboSpan" id="kobo.495.1">and recall, providing a single metric that balances both the model’s ability to correctly identify positive instances (recall) and the accuracy of these positive identifications (precision). </span><span class="koboSpan" id="kobo.495.2">Unlike the arithmetic mean, the harmonic mean gives a higher weight to lower numbers, meaning that F1-score will be more influenced by lower precision or recall. </span><span class="koboSpan" id="kobo.495.3">This makes F1-score a stringent measure of a model’s accuracy, which is especially useful when you seek a balance between precision </span><span class="No-Break"><span class="koboSpan" id="kobo.496.1">and recall.</span></span></p>
<h3><span class="koboSpan" id="kobo.497.1">Formula for F1-score</span></h3>
<p><span class="koboSpan" id="kobo.498.1">The formula for </span><a id="_idIndexMarker650"/><span class="koboSpan" id="kobo.499.1">calculating F1-score is </span><span class="No-Break"><span class="koboSpan" id="kobo.500.1">given here:</span></span></p>
<p><span class="koboSpan" id="kobo.501.1">F1 Score = 2 ×  Precision × Recall  _____________  Precision + Recall </span></p>
<p><span class="No-Break"><span class="koboSpan" id="kobo.502.1">Understanding F1-score</span></span></p>
<p><span class="koboSpan" id="kobo.503.1">F1-score ranges from 0 to 1, where a score of 1 indicates perfect precision and recall, and a score of 0 indicates the worst. </span><span class="koboSpan" id="kobo.503.2">A high F1-score suggests that the model has a robust balance between precision and recall, managing to accurately identify a high proportion of actual positives while</span><a id="_idIndexMarker651"/><span class="koboSpan" id="kobo.504.1"> minimizing the number of false positives and </span><span class="No-Break"><span class="koboSpan" id="kobo.505.1">false negatives.</span></span></p>
<h3><span class="koboSpan" id="kobo.506.1">When to use F1-score</span></h3>
<p><span class="koboSpan" id="kobo.507.1">Here are some examples of when best to </span><span class="No-Break"><span class="koboSpan" id="kobo.508.1">use F1-score:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.509.1">Imbalanced classes</span></strong><span class="koboSpan" id="kobo.510.1">: It is particularly </span><a id="_idIndexMarker652"/><span class="koboSpan" id="kobo.511.1">useful in scenarios where there are significantly more instances of one class than another, and the cost of false positives and false negatives are </span><span class="No-Break"><span class="koboSpan" id="kobo.512.1">both critical.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.513.1">Trade-off analysis</span></strong><span class="koboSpan" id="kobo.514.1">: It is ideal when you need to evaluate models based on their balance between precision (the quality of the positive predictions) and recall (the completeness of the </span><span class="No-Break"><span class="koboSpan" id="kobo.515.1">positive predictions).</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.516.1">Comparative model evaluation</span></strong><span class="koboSpan" id="kobo.517.1">: When comparing models and a balance between precision and recall is desired, F1-score provides a single metric to assess performance, </span><span class="No-Break"><span class="koboSpan" id="kobo.518.1">simplifying decision-making.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.519.1">Practical implications</span></h3>
<p><span class="koboSpan" id="kobo.520.1">F1-score is an essential tool in the model </span><a id="_idIndexMarker653"/><span class="koboSpan" id="kobo.521.1">evaluation process, allowing for a more nuanced assessment than evaluating precision or recall independently. </span><span class="koboSpan" id="kobo.521.2">However, it’s important to consider the specific context of </span><span class="No-Break"><span class="koboSpan" id="kobo.522.1">your application.</span></span></p>
<p><span class="koboSpan" id="kobo.523.1">In some cases, precision might be more important than recall or vice versa. </span><span class="koboSpan" id="kobo.523.2">Adjusting the emphasis on one over the other might </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">be necessary.</span></span></p>
<p><span class="koboSpan" id="kobo.525.1">F1-score assumes the equal importance of precision and recall, which might not always align with business objectives or </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">cost considerations.</span></span></p>
<p><span class="koboSpan" id="kobo.527.1">F1-score is a powerful metric for assessing the accuracy of binary classification models, particularly in complex scenarios where both the ability to correctly identify positive instances and the precision of these identifications </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">are important.</span></span></p>
<p><span class="koboSpan" id="kobo.529.1">Alongside evaluating the accuracy of machine learning models, it is also important to understand how they make decisions. </span><span class="koboSpan" id="kobo.529.2">This can often be a difficult process, as many machine learning models can seem like a “black box” to the user. </span><span class="koboSpan" id="kobo.529.3">However, some machine learning models are more explainable than others, and even for those less explainable models, there exist a</span><a id="_idIndexMarker654"/><span class="koboSpan" id="kobo.530.1"> number of techniques in the field of “Explainable AI” that aims to shine a light on the decision-making process of what can be </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1">opaque models.</span></span></p>
<h1 id="_idParaDest-218"><a id="_idTextAnchor233"/><span class="koboSpan" id="kobo.532.1">Methods for explaining machine learning models</span></h1>
<p><span class="koboSpan" id="kobo.533.1">Incorporating methods for interpreting and explaining machine learning models into your analytical toolkit can enhance</span><a id="_idIndexMarker655"/><span class="koboSpan" id="kobo.534.1"> transparency and provide insight into the decision-making process used by a machine </span><span class="No-Break"><span class="koboSpan" id="kobo.535.1">learning model.</span></span></p>
<p><span class="koboSpan" id="kobo.536.1">In some industries, explainability is an important aspect to consider; for example, in sensitive sectors, such as medicine and law, opaque “black-box” models are insufficient in scenarios where the reasoning behind how a machine learning model made a prediction </span><span class="No-Break"><span class="koboSpan" id="kobo.537.1">is needed.</span></span></p>
<p><span class="koboSpan" id="kobo.538.1">Let’s first look at a simple example, using coefficients to understand </span><span class="No-Break"><span class="koboSpan" id="kobo.539.1">regression models.</span></span></p>
<h2 id="_idParaDest-219"><a id="_idTextAnchor234"/><span class="koboSpan" id="kobo.540.1">Making sense of regression models – the power of coefficients</span></h2>
<p><span class="koboSpan" id="kobo.541.1">Imagine you’re using a regression model to predict future sales based on various factors such as marketing spend, seasonality, and product price. </span><span class="koboSpan" id="kobo.541.2">In this context, interpreting coefficients becomes akin</span><a id="_idIndexMarker656"/><span class="koboSpan" id="kobo.542.1"> to decoding the direct influence each factor has on </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">your sales.</span></span></p>
<p><span class="koboSpan" id="kobo.544.1">A positive coefficient for marketing spend would suggest that increasing your marketing budget is likely to boost sales, whereas a negative coefficient for product price might indicate that higher prices could deter customers. </span><span class="koboSpan" id="kobo.544.2">Understanding these coefficients empowers you to prioritize investments and strategic </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">initiatives effectively.</span></span></p>
<h2 id="_idParaDest-220"><a id="_idTextAnchor235"/><span class="koboSpan" id="kobo.546.1">Decoding classification models – unveiling feature importance</span></h2>
<p><span class="koboSpan" id="kobo.547.1">When deploying classification </span><a id="_idIndexMarker657"/><span class="koboSpan" id="kobo.548.1">models—say, to identify which customers are most likely to churn or to flag potentially fraudulent transactions—understanding feature importance is key. </span><span class="koboSpan" id="kobo.548.2">This method ranks the attributes (e.g., customer behavior patterns and transaction sizes) according to their impact on the model’s predictions. </span><span class="koboSpan" id="kobo.548.3">By focusing on the most influential factors, you can tailor interventions more precisely, whether that’s through personalized retention strategies or targeted fraud </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">prevention measures.</span></span></p>
<p><span class="koboSpan" id="kobo.550.1">Imagine you had a machine learning model that predicted the predicted the expected spending of a customer in the next year. </span><span class="koboSpan" id="kobo.550.2">This machine learning model has been trained on a range of different features to </span><a id="_idIndexMarker658"/><span class="koboSpan" id="kobo.551.1">predict the value of a customer. </span><span class="koboSpan" id="kobo.551.2">Generating a feature importance plot (by following the training of a model) can explain which of the features are more important to the model in </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">making predictions:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<span class="koboSpan" id="kobo.553.1"><img alt="Figure 9.4: Feature importance plot" src="image/B19633_09_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.554.1">Figure 9.4: Feature importance plot</span></p>
<p><span class="koboSpan" id="kobo.555.1">In the preceding example, you can see that the features related to the previous number of transactions and spend from the customer are more important to the model in predicting their next year spend, which is contrast to more superfluous information such as page views and whether their cookies </span><span class="No-Break"><span class="koboSpan" id="kobo.556.1">are enabled.</span></span></p>
<h2 id="_idParaDest-221"><a id="_idTextAnchor236"/><span class="koboSpan" id="kobo.557.1">Beyond specific models – universal insights using SHAP values</span></h2>
<p><span class="koboSpan" id="kobo.558.1">Regardless of whether you’re working</span><a id="_idIndexMarker659"/><span class="koboSpan" id="kobo.559.1"> with regression, classification, or any other predictive model, </span><strong class="bold"><span class="koboSpan" id="kobo.560.1">SHAP</span></strong><span class="koboSpan" id="kobo.561.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.562.1">SHapley Additive exPlanations</span></strong><span class="koboSpan" id="kobo.563.1">) offers a powerful, model-agnostic approach to explanation. </span><span class="koboSpan" id="kobo.563.2">SHAP values dissect any prediction to reveal the contribution of </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">each feature.</span></span></p>
<p><span class="koboSpan" id="kobo.565.1">For instance, if a loan application is predicted to be high risk, SHAP can show you exactly how factors such as the applicant’s credit score, income, and loan amount contributed to this assessment. </span><span class="koboSpan" id="kobo.565.2">This level of insight is invaluable for refining risk models, addressing customer inquiries about decision</span><a id="_idIndexMarker660"/><span class="koboSpan" id="kobo.566.1"> outcomes, and ensuring compliance with regulatory requirements </span><span class="No-Break"><span class="koboSpan" id="kobo.567.1">for explainability.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer076">
<span class="koboSpan" id="kobo.568.1"><img alt="Figure 9.5: SHAP value waterfall plot" src="image/B19633_09_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.569.1">Figure 9.5: SHAP value waterfall plot</span></p>
<p><span class="koboSpan" id="kobo.570.1">For example, in the preceding chart, a SHAP plot for an individual prediction on a house pricing dataset is shown. </span><span class="koboSpan" id="kobo.570.2">In this case, you can see the contribution to the prediction from each feature to the final prediction. </span><span class="koboSpan" id="kobo.570.3">For example, you can see that the age of the house (HouseAge) had a negative effect on the predicted </span><span class="No-Break"><span class="koboSpan" id="kobo.571.1">house price.</span></span></p>
<p><span class="koboSpan" id="kobo.572.1">This is an incredibly useful tool for explaining individual predictions, particularly for models that are not inherently explainable. </span><span class="koboSpan" id="kobo.572.2">You can imagine situations where a model’s decisions may need to be audited or explained following, for example, a complaint or investigation, and without tools such as SHAP, this can be a difficult situation for companies to find </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">themselves in.</span></span></p>
<h1 id="_idParaDest-222"><a id="_idTextAnchor237"/><span class="koboSpan" id="kobo.574.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.575.1">This chapter on </span><em class="italic"><span class="koboSpan" id="kobo.576.1">Interpreting and Evaluating Machine Learning Models</span></em><span class="koboSpan" id="kobo.577.1"> emphasizes the critical importance of understanding, interpreting, and evaluating </span><strong class="bold"><span class="koboSpan" id="kobo.578.1">machine learning</span></strong><span class="koboSpan" id="kobo.579.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.580.1">ML</span></strong><span class="koboSpan" id="kobo.581.1">) models in the context of data science projects. </span><span class="koboSpan" id="kobo.581.2">It highlights that the potential of ML systems to make decisions without hardcoded rules presents significant opportunities, yet realizing this potential is complex and requires the careful evaluation of models to ensure accuracy </span><span class="No-Break"><span class="koboSpan" id="kobo.582.1">and reliability.</span></span></p>
<p><span class="koboSpan" id="kobo.583.1">The key takeaways from this chapter include </span><span class="No-Break"><span class="koboSpan" id="kobo.584.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.585.1">The necessity of evaluating ML models on test (holdout) data to get a realistic estimate of their performance in </span><span class="No-Break"><span class="koboSpan" id="kobo.586.1">real-world scenarios.</span></span></li>
<li><span class="koboSpan" id="kobo.587.1">The importance of various evaluation metrics, such as R-squared, RMSE, and MAE, for regression models, and precision, recall, and F1-score for classification models. </span><span class="koboSpan" id="kobo.587.2">These metrics help decision-makers understand a model’s accuracy, how well it fits the data, and its </span><span class="No-Break"><span class="koboSpan" id="kobo.588.1">predictive power.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.589.1">The discussion on feature importance and methods such SHAP values for explaining predictions provides tools for understanding how different features influence a model’s outcomes. </span><span class="koboSpan" id="kobo.589.2">This is crucial for both interpreting complex models and making informed decisions based on </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">their predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.591.1">The chapter concluded by stressing that effectively evaluating and interpreting ML models is essential for making informed business decisions. </span><span class="koboSpan" id="kobo.591.2">By understanding evaluation metrics, using holdout data, and interpreting feature importance, stakeholders can gain confidence in their models’ accuracy </span><span class="No-Break"><span class="koboSpan" id="kobo.592.1">and usefulness.</span></span></p>
<p><span class="koboSpan" id="kobo.593.1">As we transition into the next chapter, </span><em class="italic"><span class="koboSpan" id="kobo.594.1">Common Pitfalls in Machine Learning</span></em><span class="koboSpan" id="kobo.595.1">, we build on the foundation laid in evaluating and interpreting models by exploring the common challenges encountered in ML projects. </span><span class="koboSpan" id="kobo.595.2">This includes issues such as overfitting, underfitting, data quality, the curse of dimensionality, model complexity, and the trade-offs between model accuracy and interpretability. </span><span class="koboSpan" id="kobo.595.3">Understanding these challenges is crucial for developing effective ML solutions that are robust, reliable, and aligned with </span><span class="No-Break"><span class="koboSpan" id="kobo.596.1">business objectives.</span></span></p>
<p><span class="koboSpan" id="kobo.597.1">The next chapter will delve into these challenges, providing insights into navigating the complexities of ML projects and strategies for mitigating common pitfalls, thereby enhancing the success and impact of ML initiatives in </span><span class="No-Break"><span class="koboSpan" id="kobo.598.1">real-world applications.</span></span></p>
</div>
</body></html>