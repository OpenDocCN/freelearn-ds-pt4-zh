<html><head></head><body>
<div id="_idContainer079">
<h1 class="chapter-number" id="_idParaDest-223"><a id="_idTextAnchor238"/><span class="koboSpan" id="kobo.1.1">10</span></h1>
<h1 id="_idParaDest-224"><a id="_idTextAnchor239"/><span class="koboSpan" id="kobo.2.1">Common Pitfalls in Machine Learning</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Picture this: a seasoned data science manager just launched a new recommendation engine to boost product sales. </span><span class="koboSpan" id="kobo.3.2">The model performed brilliantly in tests, but now, customer interest is lukewarm. </span><span class="koboSpan" id="kobo.3.3">The problem? </span><span class="koboSpan" id="kobo.3.4">The model had gotten too good at mirroring the training data – niche tastes of early adopters that didn’t reflect broader </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">customer preferences.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.5.1">Machine learning</span></strong><span class="koboSpan" id="kobo.6.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.7.1">ML</span></strong><span class="koboSpan" id="kobo.8.1">) promises </span><a id="_idIndexMarker661"/><span class="koboSpan" id="kobo.9.1">incredible things, but it’s dangerously easy to stumble. </span><span class="koboSpan" id="kobo.9.2">According to a survey of over 500 developers working with ML systems (https://www.civo.com/newsroom/ai-project-failure), more than half (53%) of respondents have abandoned between 1% and 25% of ML projects, with an additional 24% having left between 26% and 50% of projects. </span><span class="koboSpan" id="kobo.9.3">Only 11% of developers said they have never abandoned a project. </span><span class="koboSpan" id="kobo.9.4">The first lesson is this: ML isn’t some magic algorithm that just needs data. </span><span class="koboSpan" id="kobo.9.5">It’s about understanding what kind of model is right for the job, ensuring your data actually teaches the right lessons, and knowing when your model might be getting </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">tripped up</span><a id="_idTextAnchor240"/><span class="koboSpan" id="kobo.11.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.12.1">This chapter covers the </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.14.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">the complexity</span></span></li>
<li><span class="koboSpan" id="kobo.16.1">Dirty data, damaged models – how data quantity and quality </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">impacts ML</span></span></li>
<li><span class="koboSpan" id="kobo.18.1">Overcoming overfitting </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">and underfitting</span></span></li>
<li><span class="koboSpan" id="kobo.20.1">Mastering overfitting and underfitting for optimal </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">model performance</span></span></li>
<li><span class="koboSpan" id="kobo.22.1">Training-serving skew and </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">model drift</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Bias </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">and fairness</span></span></li>
</ul>
<h1 id="_idParaDest-225"><a id="_idTextAnchor241"/><span class="koboSpan" id="kobo.26.1">Understanding the complexity</span></h1>
<p><span class="koboSpan" id="kobo.27.1">Firstly, let’s acknowledge that ML is a complex field, and it’s not just about crunching numbers. </span><span class="koboSpan" id="kobo.27.2">It involves </span><a id="_idIndexMarker662"/><span class="koboSpan" id="kobo.28.1">intricate algorithms, vast amounts of data, and the ability to interpret and apply the results in a </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">meaningful way.</span></span></p>
<p><span class="koboSpan" id="kobo.30.1">Imagine you’re a marketing executive at a consumer goods company. </span><span class="koboSpan" id="kobo.30.2">You have access to a wealth of customer data and want to use ML to predict which customers are most likely to buy your </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">new product.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">Sounds straightforward, right? </span><span class="koboSpan" id="kobo.32.2">But there are many places where complexity can come in. </span><span class="koboSpan" id="kobo.32.3">We will briefly explain some of the key considerations, then go into each one in </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">more detail:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.34.1">Data quality and quantity</span></strong><span class="koboSpan" id="kobo.35.1">: Is your </span><a id="_idIndexMarker663"/><span class="koboSpan" id="kobo.36.1">data clean and representative </span><a id="_idIndexMarker664"/><span class="koboSpan" id="kobo.37.1">of your target population? </span><span class="koboSpan" id="kobo.37.2">Do you have enough </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">high-quality data?</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.39.1">Model selection and tuning</span></strong><span class="koboSpan" id="kobo.40.1">: Have </span><a id="_idIndexMarker665"/><span class="koboSpan" id="kobo.41.1">you selected the appropriate </span><a id="_idIndexMarker666"/><span class="koboSpan" id="kobo.42.1">model for your data? </span><span class="koboSpan" id="kobo.42.2">Have you correctly trained or fine-tuned </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">your model?</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.44.1">Overfitting and underfitting</span></strong><span class="koboSpan" id="kobo.45.1">: Is your model too complex and just memorizing </span><a id="_idIndexMarker667"/><span class="koboSpan" id="kobo.46.1">the training data (overfitting)? </span><span class="koboSpan" id="kobo.46.2">Or is it too simple and missing </span><a id="_idIndexMarker668"/><span class="koboSpan" id="kobo.47.1">important </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">patterns (underfitting)?</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.49.1">Training-serving skew</span></strong><span class="koboSpan" id="kobo.50.1">: Will your </span><a id="_idIndexMarker669"/><span class="koboSpan" id="kobo.51.1">model perform as well in the </span><a id="_idIndexMarker670"/><span class="koboSpan" id="kobo.52.1">real world as it does on your </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">training data?</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.54.1">Model drift</span></strong><span class="koboSpan" id="kobo.55.1">: How will your </span><a id="_idIndexMarker671"/><span class="koboSpan" id="kobo.56.1">model perform over time as the underlying </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">data changes?</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.58.1">Fairness</span></strong><span class="koboSpan" id="kobo.59.1">: Is your model </span><a id="_idIndexMarker672"/><span class="koboSpan" id="kobo.60.1">biased against certain groups? </span><span class="koboSpan" id="kobo.60.2">Is it treating different sub-groups based on characteristics such as gender, age, and </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">ethnicity fairly?</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.62.1">These are some of the key considerations to have in mind when training ML models, which can initially sound overwhelming. </span><span class="koboSpan" id="kobo.62.2">However, by looking at each of these in turn, with some concrete examples, by the end of this chapter, you should be better equipped to know what to look out for. </span><span class="koboSpan" id="kobo.62.3">You will also know the steps you, or your team, can take to mitigate the challenges associated with deploying ML models </span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">to production.</span></span></p>
<h1 id="_idParaDest-226"><a id="_idTextAnchor242"/><span class="koboSpan" id="kobo.64.1">Dirty data, damaged models – how data quantity and quality impact ML</span></h1>
<p><span class="koboSpan" id="kobo.65.1">When training or using ML and artificial intelligence models, data is not only an asset but also the </span><a id="_idIndexMarker673"/><span class="koboSpan" id="kobo.66.1">foundation of success. </span><span class="koboSpan" id="kobo.66.2">Without high-quality, representative data, even the most sophisticated ML model is useless. </span><span class="koboSpan" id="kobo.66.3">But what happens when you don’t have enough data, or when the data you have is biased </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">or inaccurate?</span></span></p>
<p><span class="koboSpan" id="kobo.68.1">To consider </span><a id="_idIndexMarker674"/><span class="koboSpan" id="kobo.69.1">one hypothetical example, many banks use ML to flag potentially fraudulent transactions and block accounts based on information about the transaction. </span><span class="koboSpan" id="kobo.69.2">Imagine the model was only trained on a subset of account types, such as current accounts that have more regular, lower-value transactions. </span><span class="koboSpan" id="kobo.69.3">Let’s say the bank decides to then also apply the model to savings accounts that may have larger, less frequent transactions. </span><span class="koboSpan" id="kobo.69.4">The model may now incorrectly flag most typical savings account transactions as false positives, leading to frustrated customers and stressed customer </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">service teams.</span></span></p>
<p><span class="koboSpan" id="kobo.71.1">To look at another example, imagine a large language model-based customer service chatbot. </span><span class="koboSpan" id="kobo.71.2">Let’s say this chatbot was trained primarily on interactions where customers are expressing frustration or dissatisfaction. </span><span class="koboSpan" id="kobo.71.3">The chatbot learns to associate most customer inquiries with negativity. </span><span class="koboSpan" id="kobo.71.4">A consequence could be that the chatbot becomes overly apologetic or defensive, even in neutral conversations. </span><span class="koboSpan" id="kobo.71.5">It may misunderstand simple requests and misinterpret the customers’ intent, hindering effective </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">customer support.</span></span></p>
<p><span class="koboSpan" id="kobo.73.1">In this section, we’ll look into the common data considerations around quantity and quality that can affect your ML models and how to </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">address them.</span></span></p>
<h2 id="_idParaDest-227"><a id="_idTextAnchor243"/><span class="koboSpan" id="kobo.75.1">The importance of adequate training data</span></h2>
<p><span class="koboSpan" id="kobo.76.1">Imagine </span><a id="_idIndexMarker675"/><span class="koboSpan" id="kobo.77.1">you’re a coach training a team for a basketball tournament. </span><span class="koboSpan" id="kobo.77.2">If you </span><a id="_idIndexMarker676"/><span class="koboSpan" id="kobo.78.1">only train it on shooting free throws, it will struggle when faced with other aspects of the game such as defense or three-point shooting. </span><span class="koboSpan" id="kobo.78.2">Similarly, an ML model trained on insufficient or unrepresentative data will struggle to make </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">accurate predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.80.1">In industries such as market research and consumer goods, for instance, if a model is trained only </span><a id="_idIndexMarker677"/><span class="koboSpan" id="kobo.81.1">on data from urban consumers, it may not perform </span><a id="_idIndexMarker678"/><span class="koboSpan" id="kobo.82.1">well when applied to </span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">rural consumers.</span></span></p>
<p><span class="koboSpan" id="kobo.84.1">For many ML models, particularly deep learning models, the quantity of data </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">is paramount.</span></span></p>
<h3><span class="koboSpan" id="kobo.86.1">Mitigating the challenge</span></h3>
<p><span class="koboSpan" id="kobo.87.1">To mitigate </span><a id="_idIndexMarker679"/><span class="koboSpan" id="kobo.88.1">this challenge, we must do </span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.90.1">Collect a sufficient volume of data</span></strong><span class="koboSpan" id="kobo.91.1">: This may seem like a brute-force approach, but in many cases, the best way to improve the accuracy of ML models, and particularly deep learning models, is to increase the volume of data the model is being trained on. </span><span class="koboSpan" id="kobo.91.2">One way this may be achieved is via collecting data over a </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">longer period.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.93.1">Collect diverse data</span></strong><span class="koboSpan" id="kobo.94.1">: Ensure your training data covers a wide range of scenarios your model is likely to encounter. </span><span class="koboSpan" id="kobo.94.2">This may be achieved by expanding the sources where data is acquired, either internal data sources (first-party data), or external data sources (second- and third-party data). </span><span class="koboSpan" id="kobo.94.3">It is important, however, to expand data coverage to include only relevant data that is representative of the data your model will see in production. </span><span class="koboSpan" id="kobo.94.4">For example, in the previous chatbot use case, expanding the data to cover all types of customer interactions could benefit the accuracy and reliability of the model. </span><span class="koboSpan" id="kobo.94.5">However, adding irrelevant chatbot data, say from a different company or industry, may have the opposite effect and lead to a less </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">reliable model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.96.1">Use data augmentation techniques</span></strong><span class="koboSpan" id="kobo.97.1">: Data augmentation is the process of adjusting or augmenting data examples you already have. </span><span class="koboSpan" id="kobo.97.2">These techniques can artificially expand your dataset by creating variations of existing data points. </span><span class="koboSpan" id="kobo.97.3">For example, within image recognition, one common data augmentation approach is to adjust existing images by rotating, zooming, blurring, and cropping them, increasing the volume of the </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">training data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.99.1">Generate synthetic data</span></strong><span class="koboSpan" id="kobo.100.1">: Synthetic data refers to artificially created data that closely mirrors the characteristics and patterns of real-world data. </span><span class="koboSpan" id="kobo.100.2">This can be particularly </span><a id="_idIndexMarker680"/><span class="koboSpan" id="kobo.101.1">beneficial when real-world data </span><a id="_idIndexMarker681"/><span class="koboSpan" id="kobo.102.1">is scarce, sensitive, or difficult to obtain. </span><span class="koboSpan" id="kobo.102.2">In the case of </span><strong class="bold"><span class="koboSpan" id="kobo.103.1">large language models</span></strong><span class="koboSpan" id="kobo.104.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.105.1">LLMs</span></strong><span class="koboSpan" id="kobo.106.1">), these can be used to generate realistic synthetic data that can be used for fine-tuning models for specific tasks. </span><span class="koboSpan" id="kobo.106.2">LLMs excel at creating text-based data and can be fine-tuned to produce diverse and targeted variations, filling gaps in your original datasets and ensuring your model is better prepared for various </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">real-world scenarios.</span></span></li>
</ul>
<h2 id="_idParaDest-228"><a id="_idTextAnchor244"/><span class="koboSpan" id="kobo.108.1">Dealing with poor data quality</span></h2>
<p><span class="koboSpan" id="kobo.109.1">Poor data quality, such as missing values, inconsistencies, and outright errors, significantly </span><a id="_idIndexMarker682"/><span class="koboSpan" id="kobo.110.1">hinders the performance of ML models. </span><span class="koboSpan" id="kobo.110.2">Imagine trying to teach someone math with a textbook full of typos and incorrect formulas – they’ll struggle to learn the concepts correctly. </span><span class="koboSpan" id="kobo.110.3">Similarly, a model trained on flawed data will produce </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">unreliable results.</span></span></p>
<p><span class="koboSpan" id="kobo.112.1">Consider, for example, an image recognition model within the healthcare technology industry that is trained to detect tumors from MRI scans. </span><span class="koboSpan" id="kobo.112.2">If the images this model is trained on are poorly labeled, it could lead to potentially disastrous results, with tumors going undetected and false positives being flagged. </span><span class="koboSpan" id="kobo.112.3">For critical applications such as this, having very high data quality is one of the most important considerations, if not the </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">most important.</span></span></p>
<p><span class="koboSpan" id="kobo.114.1">Take another example. </span><span class="koboSpan" id="kobo.114.2">A natural language processing model may be fine-tuned for content moderation on a social media platform. </span><span class="koboSpan" id="kobo.114.3">If the training data is poorly labeled (e.g., sarcastic statements flagged as hate speech) or lacks diverse examples, the model will struggle. </span><span class="koboSpan" id="kobo.114.4">This could lead to false positives, where legitimate content might be wrongly removed, restricting freedom of expression. </span><span class="koboSpan" id="kobo.114.5">Additionally, the poor quality training data could lead to the model producing false negatives, where actual hate speech might slip through, making the platform unsafe </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">for users.</span></span></p>
<h3><span class="koboSpan" id="kobo.116.1">Mitigating the challenge</span></h3>
<p><span class="koboSpan" id="kobo.117.1">There are various methods to mitigate the challenge of poor data quality, which we will describe in this section. </span><span class="koboSpan" id="kobo.117.2">However, often, the best place data quality can be addressed is at </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">the source.</span></span></p>
<p><span class="koboSpan" id="kobo.119.1">For example, consider an ML model trained to classify customers in a CRM as likely or unlikely to churn. </span><span class="koboSpan" id="kobo.119.2">Have the customers, and all the information about them, been accurately </span><a id="_idIndexMarker683"/><span class="koboSpan" id="kobo.120.1">entered into the CRM? </span><span class="koboSpan" id="kobo.120.2">Is there any validation on the forms to make sure invalid data has not been entered, or is important data missing for some customers? </span><span class="koboSpan" id="kobo.120.3">Are there processes for the business teams to follow when entering data? </span><span class="koboSpan" id="kobo.120.4">If there is poor quality or missing data, can this be manually fixed by business teams, or the data science </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">teams themselves?</span></span></p>
<p><span class="koboSpan" id="kobo.122.1">This is all mundane stuff, but if, by the time data is in the hands of data scientists and ML engineers, it is already of poor quality, there is only so much that can be done with the more automated processes we will explain here. </span><span class="koboSpan" id="kobo.122.2">As the well-known expression goes, garbage in, </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">garbage out.</span></span></p>
<p><span class="koboSpan" id="kobo.124.1">Here are some techniques that data scientists, engineers, and analysts can use to mitigate poor </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">data quality:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.126.1">Data cleaning</span></strong><span class="koboSpan" id="kobo.127.1">: There </span><a id="_idIndexMarker684"/><span class="koboSpan" id="kobo.128.1">are several </span><a id="_idIndexMarker685"/><span class="koboSpan" id="kobo.129.1">techniques that data scientists can apply to clean data before training ML models, including </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">the following:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.131.1">Missing values</span></strong><span class="koboSpan" id="kobo.132.1">: Decide whether to remove entries with missing data or replace missing values with estimates (e.g., mean </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">or median)</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.134.1">Duplicates</span></strong><span class="koboSpan" id="kobo.135.1">: Remove redundant entries that can </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">skew results</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.137.1">Inconsistencies</span></strong><span class="koboSpan" id="kobo.138.1">: Correct formatting errors (e.g., date formats), and standardize entries for better model understanding (e.g., convert all addresses </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">to lowercase)</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.140.1">Data validation</span></strong><span class="koboSpan" id="kobo.141.1">: Data </span><a id="_idIndexMarker686"/><span class="koboSpan" id="kobo.142.1">scientists can </span><a id="_idIndexMarker687"/><span class="koboSpan" id="kobo.143.1">apply techniques to validate data and exclude or fix invalid data before training ML models. </span><span class="koboSpan" id="kobo.143.2">It is also important that when the model is in production (i.e., after training and during inference), the same processes for data cleaning and validation </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">are applied:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.145.1">Range checks</span></strong><span class="koboSpan" id="kobo.146.1">: Ensure values fall within an acceptable range (e.g., a person’s age can’t </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">be negative)</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.148.1">Format checks</span></strong><span class="koboSpan" id="kobo.149.1">: Verify that </span><a id="_idIndexMarker688"/><span class="koboSpan" id="kobo.150.1">data adheres to specific formats (e.g., phone numbers, </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">zip codes)</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.152.1">Cross-field checks</span></strong><span class="koboSpan" id="kobo.153.1">: Ensure consistency across related data fields (e.g., if a country is “USA,” the state field should match the list of </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">US states)</span></span></li></ul></li>
</ul>
<h2 id="_idParaDest-229"><a id="_idTextAnchor245"/><span class="koboSpan" id="kobo.155.1">Conclusion</span></h2>
<p><span class="koboSpan" id="kobo.156.1">Bad data will sabotage your ML models, plain and simple. </span><span class="koboSpan" id="kobo.156.2">Addressing these issues is essential to success, and we have covered some of the techniques that you can leverage in your next data science project. </span><span class="koboSpan" id="kobo.156.3">These techniques include improving data collection by expanding the scope and coverage of the training data, augmenting data, and synthesizing data if appropriate, as well as improving the quality of data through data cleaning and validation. </span><span class="koboSpan" id="kobo.156.4">These are the hard yards that will set up your project for success. </span><span class="koboSpan" id="kobo.156.5">The importance of data cannot be emphasized enough, to the extent that there is a growing </span><a id="_idIndexMarker689"/><span class="koboSpan" id="kobo.157.1">approach called Data-centric AI (</span><a href="https://datacentricai.org/"><span class="koboSpan" id="kobo.158.1">https://datacentricai.org/</span></a><span class="koboSpan" id="kobo.159.1">), which is the discipline of systematically engineering the data used to build an </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">AI system.</span></span></p>
<p><span class="koboSpan" id="kobo.161.1">Next, we will explore another key challenge: ensuring your model doesn’t just memorize your training data but can also learn to generalize to new situations. </span><span class="koboSpan" id="kobo.161.2">That means understanding and avoiding overfitting </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">and underfitting.</span></span></p>
<p><span class="koboSpan" id="kobo.163.1">As we move to the next section, we’ll explore this critical aspect of ML – over- and underfitting. </span><span class="koboSpan" id="kobo.163.2">How can we ensure our model performs well, not just on our current data, but also on new, </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">unseen data?</span></span></p>
<h1 id="_idParaDest-230"><a id="_idTextAnchor246"/><span class="koboSpan" id="kobo.165.1">Overcoming overfitting and underfitting</span></h1>
<p><span class="koboSpan" id="kobo.166.1">Choosing the right </span><a id="_idIndexMarker690"/><span class="koboSpan" id="kobo.167.1">complexity for your model is a delicate balancing act. </span><span class="koboSpan" id="kobo.167.2">If your </span><a id="_idIndexMarker691"/><span class="koboSpan" id="kobo.168.1">model is too complex, it might overfit the training data, meaning it performs well on the training data but poorly on new, unseen data. </span><span class="koboSpan" id="kobo.168.2">On the other hand, if your model is too simple, it might underfit the data, missing important patterns and leading to </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">inaccurate predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.170.1">Imagine you’re a market researcher trying to predict consumer trends. </span><span class="koboSpan" id="kobo.170.2">An overfitted model might capture every minor fluctuation in past trends but fail to generalize to future trends. </span><span class="koboSpan" id="kobo.170.3">An underfitted model might miss important </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">trends altogether.</span></span></p>
<h2 id="_idParaDest-231"><a id="_idTextAnchor247"/><span class="koboSpan" id="kobo.172.1">Navigating training-serving skew and model drift</span></h2>
<p><span class="koboSpan" id="kobo.173.1">In an </span><a id="_idIndexMarker692"/><span class="koboSpan" id="kobo.174.1">ideal world, your model would perform </span><a id="_idIndexMarker693"/><span class="koboSpan" id="kobo.175.1">just as well in the real world as it does </span><a id="_idIndexMarker694"/><span class="koboSpan" id="kobo.176.1">on your training data. </span><span class="koboSpan" id="kobo.176.2">But this is rarely the case. </span><span class="koboSpan" id="kobo.176.3">This discrepancy is known as </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.177.1">training-serving skew</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.179.1">Furthermore, as the underlying data changes over time, your model’s performance can degrade. </span><span class="koboSpan" id="kobo.179.2">This is </span><a id="_idIndexMarker695"/><span class="koboSpan" id="kobo.180.1">known as </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.181.1">model drift</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.183.1">Imagine you’re developing an ML model to predict customer churn for a telecommunications company. </span><span class="koboSpan" id="kobo.183.2">During the model training phase, you use a dataset that includes customer information such as demographics, usage patterns, and customer service interactions. </span><span class="koboSpan" id="kobo.183.3">However, when the model is deployed in the production environment (the serving phase), you realize that the data pipeline feeding the model is </span><a id="_idIndexMarker696"/><span class="koboSpan" id="kobo.184.1">missing some important features, such </span><a id="_idIndexMarker697"/><span class="koboSpan" id="kobo.185.1">as the latest customer service interaction data. </span><span class="koboSpan" id="kobo.185.2">This discrepancy between the data used for training and the data available during serving is a classic example of </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">training-serving skew.</span></span></p>
<p><span class="koboSpan" id="kobo.187.1">In this scenario, the model’s performance in production may suffer because it was trained on a more comprehensive dataset than what is available in the serving environment. </span><span class="koboSpan" id="kobo.187.2">The missing features during serving can lead to inaccurate predictions and </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">suboptimal decision-making.</span></span></p>
<p><span class="koboSpan" id="kobo.189.1">To address training-serving skew, it’s important to ensure consistency between the data used for training and the data available during serving. </span><span class="koboSpan" id="kobo.189.2">This can involve regularizing data pipelines, monitoring data quality, and implementing data validation checks to catch any discrepancies early in </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">the process.</span></span></p>
<h2 id="_idParaDest-232"><a id="_idTextAnchor248"/><span class="koboSpan" id="kobo.191.1">Ensuring fairness</span></h2>
<p><span class="koboSpan" id="kobo.192.1">Finally, it’s important </span><a id="_idIndexMarker698"/><span class="koboSpan" id="kobo.193.1">to ensure that your models are fair </span><a id="_idIndexMarker699"/><span class="koboSpan" id="kobo.194.1">and don’t discriminate against certain groups. </span><span class="koboSpan" id="kobo.194.2">This can be a challenge, especially when the training data itself </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">is biased.</span></span></p>
<p><span class="koboSpan" id="kobo.196.1">For example, let’s say you’re an HR manager using ML to screen job applicants. </span><span class="koboSpan" id="kobo.196.2">If your training data is biased against certain groups, your model might unfairly reject qualified candidates from </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">these groups.</span></span></p>
<p><span class="koboSpan" id="kobo.198.1">In this section, we’ve explored why ML can be hard, touching on challenges such as data quality and </span><a id="_idIndexMarker700"/><span class="koboSpan" id="kobo.199.1">quantity, overfitting and underfitting, training-serving </span><a id="_idIndexMarker701"/><span class="koboSpan" id="kobo.200.1">skew, model drift, and fairness. </span><span class="koboSpan" id="kobo.200.2">But don’t be discouraged. </span><span class="koboSpan" id="kobo.200.3">In the following sections, we’ll dive deeper into these challenges and provide practical strategies to </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">overcome them.</span></span></p>
<h1 id="_idParaDest-233"><a id="_idTextAnchor249"/><span class="koboSpan" id="kobo.202.1">Mastering overfitting and underfitting for optimal model performance</span></h1>
<p><span class="koboSpan" id="kobo.203.1">In ML, achieving </span><a id="_idIndexMarker702"/><span class="koboSpan" id="kobo.204.1">reliable predictions is often </span><a id="_idIndexMarker703"/><span class="koboSpan" id="kobo.205.1">the main goal. </span><span class="koboSpan" id="kobo.205.2">Overfitting and underfitting are two common obstacles to this goal. </span><span class="koboSpan" id="kobo.205.3">Let’s break down these concepts and outline concrete techniques to build </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">better models.</span></span></p>
<h2 id="_idParaDest-234"><a id="_idTextAnchor250"/><span class="koboSpan" id="kobo.207.1">Overfitting – when your model is too specific</span></h2>
<p><span class="koboSpan" id="kobo.208.1">Imagine your model as a student preparing for a test. </span><span class="koboSpan" id="kobo.208.2">Overfitting occurs when the student memorizes the practice questions perfectly but struggles to answer variations of the same questions on the actual exam. </span><span class="koboSpan" id="kobo.208.3">Similarly, an overfitted model gets too focused on the details of the training data, including random noise, and fails to grasp the </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">bigger picture.</span></span></p>
<h3><span class="koboSpan" id="kobo.210.1">Real-world consequences</span></h3>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.211.1">Market research</span></strong><span class="koboSpan" id="kobo.212.1">: A model </span><a id="_idIndexMarker704"/><span class="koboSpan" id="kobo.213.1">obsessively tuned to existing customers’ data won’t be able to predict the behavior of new prospects with </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">different characteristics</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.215.1">Retail recommendations</span></strong><span class="koboSpan" id="kobo.216.1">: A system trained exclusively on a loyal customer’s purchase history may offer irrelevant suggestions when trying to attract </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">new shoppers</span></span></li>
</ul>
<h2 id="_idParaDest-235"><a id="_idTextAnchor251"/><span class="koboSpan" id="kobo.218.1">Underfitting – when your model is too simplistic</span></h2>
<p><span class="koboSpan" id="kobo.219.1">Picture underfitting as a student who only grasps the most basic concepts of a subject. </span><span class="koboSpan" id="kobo.219.2">They’ll fail the exam regardless of whether the questions are from practice problems or new material. </span><span class="koboSpan" id="kobo.219.3">Similarly, an underfitted model misses important relationships within the data and performs poorly across </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">the board.</span></span></p>
<h3><span class="koboSpan" id="kobo.221.1">Real-world consequences</span></h3>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.222.1">Sales forecasts</span></strong><span class="koboSpan" id="kobo.223.1">: A model </span><a id="_idIndexMarker705"/><span class="koboSpan" id="kobo.224.1">that ignores factors such as seasonality or marketing promotions will consistently underestimate or overestimate </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">potential sales</span></span></li>
</ul>
<h2 id="_idParaDest-236"><a id="_idTextAnchor252"/><span class="koboSpan" id="kobo.226.1">Spotting the problem</span></h2>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.227.1">Red flag</span></strong><span class="koboSpan" id="kobo.228.1">: Excellent </span><a id="_idIndexMarker706"/><span class="koboSpan" id="kobo.229.1">performance </span><a id="_idIndexMarker707"/><span class="koboSpan" id="kobo.230.1">on training data but terrible results on new data is a classic sign </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">of overfitting</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.232.1">Warning sign</span></strong><span class="koboSpan" id="kobo.233.1">: If your model struggles with both training data and new data, it’s likely due </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">to underfitting</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.235.1">Solutions for building better models</span></h3>
<p><span class="koboSpan" id="kobo.236.1">The </span><a id="_idIndexMarker708"/><span class="koboSpan" id="kobo.237.1">following </span><a id="_idIndexMarker709"/><span class="koboSpan" id="kobo.238.1">are some solutions for building </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">good models:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.240.1">More data = stronger foundation</span></strong><span class="koboSpan" id="kobo.241.1">: Larger, more diverse datasets help the model identify real trends, not just random fluctuations in the </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">training sample.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.243.1">Feature selection = laser focus</span></strong><span class="koboSpan" id="kobo.244.1">: Carefully choose the most relevant data features. </span><span class="koboSpan" id="kobo.244.2">Get rid of those that only add confusion, </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">not insight.</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.246.1">Example – predicting customer churn</span></strong><span class="koboSpan" id="kobo.247.1">: Imagine you’re predicting customer churn for a telecom company. </span><span class="koboSpan" id="kobo.247.2">Your dataset includes relevant features such as monthly charges and customer service calls, but also an irrelevant feature: favorite ice cream flavor. </span><span class="koboSpan" id="kobo.247.3">Including “favorite ice cream flavor” adds noise and makes it harder for the algorithm to identify important patterns. </span><span class="koboSpan" id="kobo.247.4">By selecting only relevant features, you create a focused model that zeroes in on key factors driving churn. </span><span class="koboSpan" id="kobo.247.5">Remember, more data isn’t always better. </span><span class="koboSpan" id="kobo.247.6">Quality and relevance </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">matter most.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.249.1">Regularization = the guardrails</span></strong><span class="koboSpan" id="kobo.250.1">: Regularization is a technique that adds penalties </span><a id="_idIndexMarker710"/><span class="koboSpan" id="kobo.251.1">to the model during training to prevent it from becoming too complex and too reliant on the peculiarities of the </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">training data.</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.253.1">Example – predicting house prices</span></strong><span class="koboSpan" id="kobo.254.1">: When building a model to predict house prices, regularization acts as a safeguard. </span><span class="koboSpan" id="kobo.254.2">It discourages the model from </span><a id="_idIndexMarker711"/><span class="koboSpan" id="kobo.255.1">giving too much importance to a few unusual, expensive houses with unique features in the training data. </span><span class="koboSpan" id="kobo.255.2">By adding these penalties, regularization helps the model generalize better to new, unseen data, rather than getting stuck on the specifics of the </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">training data.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.257.1">Cross-validation = reality check</span></strong><span class="koboSpan" id="kobo.258.1">: Cross-validation is a method that helps assess how well a model will perform on new, unseen data by simulating </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">real-world conditions.</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.260.1">Example – sentiment analysis of movie reviews</span></strong><span class="koboSpan" id="kobo.261.1">: When building a model to predict the sentiment of movie reviews, cross-validation provides a reality check. </span><span class="koboSpan" id="kobo.261.2">Instead of training the model on all the data and assuming it’s performing well, you split the data into subsets. </span><span class="koboSpan" id="kobo.261.3">You train the model on some subsets and test it on others. </span><span class="koboSpan" id="kobo.261.4">By doing this multiple times, you get a more realistic estimate of how the model will perform on new data. </span><span class="koboSpan" id="kobo.261.5">This helps you catch whether the model is just memorizing the training data instead of learning to generalize to </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">new reviews.</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.263.1">One way to visualize the trade-off between underfitting and overfitting is by looking at a bias-variance </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">trade-off chart:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer078">
<span class="koboSpan" id="kobo.265.1"><img alt="Figure 10.1: Bias-variance trade-off" src="image/B19633_10_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.266.1">Figure 10.1: Bias-variance trade-off</span></p>
<p><span class="koboSpan" id="kobo.267.1">The </span><a id="_idIndexMarker712"/><span class="koboSpan" id="kobo.268.1">chart (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.269.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.270.1">.1</span></em><span class="koboSpan" id="kobo.271.1">) visualizes </span><a id="_idIndexMarker713"/><span class="koboSpan" id="kobo.272.1">the relationship between a model’s </span><strong class="bold"><span class="koboSpan" id="kobo.273.1">complexity</span></strong><span class="koboSpan" id="kobo.274.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.275.1">generalizability</span></strong><span class="koboSpan" id="kobo.276.1">, and </span><strong class="bold"><span class="koboSpan" id="kobo.277.1">accuracy</span></strong><span class="koboSpan" id="kobo.278.1"> on unseen data. </span><span class="koboSpan" id="kobo.278.2">This is a very important concept to business-focused decision-makers in data science, ML, and AI because it directly impacts the real-world performance of </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">their models.</span></span></p>
<h3><span class="koboSpan" id="kobo.280.1">Understanding the axes</span></h3>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.281.1">X-axis (model complexity)</span></strong><span class="koboSpan" id="kobo.282.1">: This </span><a id="_idIndexMarker714"/><span class="koboSpan" id="kobo.283.1">represents how flexible or complex your model is. </span><span class="koboSpan" id="kobo.283.2">Simpler </span><a id="_idIndexMarker715"/><span class="koboSpan" id="kobo.284.1">models are on the left, while more complex models are on </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">the right.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.286.1">Y-axis (error)</span></strong><span class="koboSpan" id="kobo.287.1">: This represents the overall error of your model, which is a combination of two key factors: bias </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">and variance.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.289.1">Key parts of the chart</span></h3>
<p><span class="koboSpan" id="kobo.290.1">Let’s </span><a id="_idIndexMarker716"/><span class="koboSpan" id="kobo.291.1">explore the chart </span><a id="_idIndexMarker717"/><span class="koboSpan" id="kobo.292.1">with a real example. </span><span class="koboSpan" id="kobo.292.2">Imagine you’re building a model to predict which customers are likely to stop using your product or </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">service (churn):</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.294.1">Bias</span></strong><span class="koboSpan" id="kobo.295.1">: This refers to the systematic error introduced by the model itself. </span><span class="koboSpan" id="kobo.295.2">It’s the consistent difference between the model’s predictions and the actual values. </span><span class="koboSpan" id="kobo.295.3">A high bias means the model consistently misses the mark, regardless of the specific data point. </span><span class="koboSpan" id="kobo.295.4">A very simple model might only look at one feature, such as a customer’s average purchase amount. </span><span class="koboSpan" id="kobo.295.5">This model is likely to have high bias because it ignores a whole host of complex factors that contribute to churn (support experience, </span><span class="No-Break"><span class="koboSpan" id="kobo.296.1">competitor offerings).</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.297.1">High Variance (Overfitting)</span></strong><span class="koboSpan" id="kobo.298.1">: A very complex model with a huge number of features might fit the training data perfectly. </span><span class="koboSpan" id="kobo.298.2">However, it might pick up on irrelevant patterns or random fluctuations in your historical data, leading to inconsistent predictions for new customers (like darts going all over the board). </span><span class="koboSpan" id="kobo.298.3">This model would perform well on the data it was trained on but fail to generalize and predict new </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">churn reliably.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.300.1">Optimal Balance</span></strong><span class="koboSpan" id="kobo.301.1">: An ideal model would be complex enough to capture the key factors driving churn without overfitting to the specifics of your training data. </span><span class="koboSpan" id="kobo.301.2">This balance would lead to the lowest overall error rate (</span><strong class="bold"><span class="koboSpan" id="kobo.302.1">Total Error</span></strong><span class="koboSpan" id="kobo.303.1"> on the chart), successfully identifying those customers genuinely at risk </span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">of churn.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.305.1">The trade-off</span></h3>
<p><span class="koboSpan" id="kobo.306.1">The </span><a id="_idIndexMarker718"/><span class="koboSpan" id="kobo.307.1">key takeaway from </span><a id="_idIndexMarker719"/><span class="koboSpan" id="kobo.308.1">this chart is the trade-off between bias </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">and variance:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.310.1">Simpler models (left side)</span></strong><span class="koboSpan" id="kobo.311.1">: These tend to have high bias (systematically missing the mark) but low variance (consistent predictions). </span><span class="koboSpan" id="kobo.311.2">This is because they are not flexible enough to capture all the complexities in </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">the data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.313.1">More complex models (right side)</span></strong><span class="koboSpan" id="kobo.314.1">: These tend to have low bias (better fitting the data) but high variance (predictions jumping around for similar data points). </span><span class="koboSpan" id="kobo.314.2">This is because they are more flexible and can fit the training data very well, but </span><a id="_idIndexMarker720"/><span class="koboSpan" id="kobo.315.1">they also </span><a id="_idIndexMarker721"/><span class="koboSpan" id="kobo.316.1">risk memorizing noise or irrelevant patterns in the data, which leads to poor performance on new, </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">unseen data.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.318.1">Finding the optimal model</span></h3>
<p><span class="koboSpan" id="kobo.319.1">The </span><a id="_idIndexMarker722"/><span class="koboSpan" id="kobo.320.1">goal is to find the optimal model complexity that balances bias and variance to achieve the lowest </span><a id="_idIndexMarker723"/><span class="koboSpan" id="kobo.321.1">total error. </span><span class="koboSpan" id="kobo.321.2">This is often achieved through techniques such as regularization, which helps to constrain the model’s flexibility and reduce variance without introducing too </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">much bias.</span></span></p>
<h3><span class="koboSpan" id="kobo.323.1">Relevance to business decisions</span></h3>
<p><span class="koboSpan" id="kobo.324.1">For </span><a id="_idIndexMarker724"/><span class="koboSpan" id="kobo.325.1">business-focused decision-makers, understanding the bias-variance trade-off is useful because </span><a id="_idIndexMarker725"/><span class="koboSpan" id="kobo.326.1">it helps you do </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.328.1">Evaluate the generalizability of your models</span></strong><span class="koboSpan" id="kobo.329.1">: How well will your model perform on real-world data that it hasn’t </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1">seen before?</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.331.1">Make informed choices about model complexity</span></strong><span class="koboSpan" id="kobo.332.1">: Balance the need for accurate predictions with the risk of overfitting and </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">poor generalizability</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.334.1">Avoid common pitfalls</span></strong><span class="koboSpan" id="kobo.335.1">: Knowing the signs of underfitting (high bias) and overfitting (high variance) can help you diagnose and fix issues with </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">your models</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.337.1">By understanding this trade-off, you can make better decisions about your data science projects and ensure that your models are generalizable and impactful for </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">your business.</span></span></p>
<h2 id="_idParaDest-237"><a id="_idTextAnchor253"/><span class="koboSpan" id="kobo.339.1">Conclusion</span></h2>
<p><span class="koboSpan" id="kobo.340.1">The best ML models aren’t about perfectly mimicking the past. </span><span class="koboSpan" id="kobo.340.2">They’re about uncovering patterns that help you make accurate predictions for the future. </span><span class="koboSpan" id="kobo.340.3">By understanding and tackling overfitting and underfitting, you’ll equip your models to deliver the insights that drive better </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">business decisions.</span></span></p>
<p><span class="koboSpan" id="kobo.342.1">As we move forward, we’ll investigate another important aspect of ML: training-serving skew and model drift. </span><span class="koboSpan" id="kobo.342.2">These concepts will further equip you to deploy effective and reliable ML models in </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">your business.</span></span></p>
<h1 id="_idParaDest-238"><a id="_idTextAnchor254"/><span class="koboSpan" id="kobo.344.1">Training-serving skew and model drift</span></h1>
<p><span class="koboSpan" id="kobo.345.1">As decision-makers, it’s important to understand the potential pitfalls in deploying ML models into </span><a id="_idIndexMarker726"/><span class="koboSpan" id="kobo.346.1">production. </span><span class="koboSpan" id="kobo.346.2">Two of these challenges are training-serving </span><a id="_idIndexMarker727"/><span class="koboSpan" id="kobo.347.1">skew and model drift. </span><span class="koboSpan" id="kobo.347.2">Let’s explore these concepts, understand their implications, and learn how to mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.348.1">their effects.</span></span></p>
<h2 id="_idParaDest-239"><a id="_idTextAnchor255"/><span class="koboSpan" id="kobo.349.1">Training-serving skew</span></h2>
<p><span class="koboSpan" id="kobo.350.1">Training-serving skew occurs when the data used to train a model differs from the data used in serving predictions. </span><span class="koboSpan" id="kobo.350.2">This can lead to a significant drop in model performance. </span><span class="koboSpan" id="kobo.350.3">Imagine you’re a retail giant, and you’ve trained a model to predict customer purchasing behavior based on historical data. </span><span class="koboSpan" id="kobo.350.4">If your model is trained on online sales data but used to predict in-store sales, the skew could lead to </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">inaccurate predictions.</span></span></p>
<h3><span class="koboSpan" id="kobo.352.1">Mitigating training-serving skew</span></h3>
<p><span class="koboSpan" id="kobo.353.1">How can </span><a id="_idIndexMarker728"/><span class="koboSpan" id="kobo.354.1">we address this? </span><span class="koboSpan" id="kobo.354.2">Here are some steps </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">to take:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.356.1">Ensure consistency</span></strong><span class="koboSpan" id="kobo.357.1">: Make sure that the data used for training and serving is consistent. </span><span class="koboSpan" id="kobo.357.2">This includes aspects such as data sources, feature extraction methods, and </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">data distribution.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.359.1">Monitor performance</span></strong><span class="koboSpan" id="kobo.360.1">: Regularly monitor your model’s performance. </span><span class="koboSpan" id="kobo.360.2">If there’s a sudden drop in performance, it could be due to </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">training-serving skew.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.362.1">Update model regularly</span></strong><span class="koboSpan" id="kobo.363.1">: Update your model with recent data to ensure it remains relevant </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">and accurate.</span></span></li>
</ul>
<h2 id="_idParaDest-240"><a id="_idTextAnchor256"/><span class="koboSpan" id="kobo.365.1">Model drift</span></h2>
<p><span class="koboSpan" id="kobo.366.1">Model drift refers to the change in model performance over time due to changes in the underlying </span><a id="_idIndexMarker729"/><span class="koboSpan" id="kobo.367.1">data distribution. </span><span class="koboSpan" id="kobo.367.2">Consider a marketing firm that uses a model to predict consumer trends. </span><span class="koboSpan" id="kobo.367.3">If there’s a sudden shift in consumer behavior, the model’s predictions may become less accurate </span><span class="No-Break"><span class="koboSpan" id="kobo.368.1">over time.</span></span></p>
<h3><span class="koboSpan" id="kobo.369.1">Mitigating model drift</span></h3>
<p><span class="koboSpan" id="kobo.370.1">Addressing </span><a id="_idIndexMarker730"/><span class="koboSpan" id="kobo.371.1">model drift involves doing </span><span class="No-Break"><span class="koboSpan" id="kobo.372.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.373.1">Monitor model performance</span></strong><span class="koboSpan" id="kobo.374.1">: Keep a close eye on your model’s performance metrics. </span><span class="koboSpan" id="kobo.374.2">If there’s a gradual decline, it could be due to </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">model drift.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.376.1">Retrain models</span></strong><span class="koboSpan" id="kobo.377.1">: Regularly retrain your models with fresh data to ensure they stay up-to-date with the </span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">latest trends.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.379.1">Use robust models</span></strong><span class="koboSpan" id="kobo.380.1">: Some models are more susceptible to drift than others. </span><span class="koboSpan" id="kobo.380.2">Using robust models that can handle changes in data distribution can help mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">this issue.</span></span></li>
</ul>
<h2 id="_idParaDest-241"><a id="_idTextAnchor257"/><span class="koboSpan" id="kobo.382.1">Key takeaways</span></h2>
<p><span class="koboSpan" id="kobo.383.1">In this section, we’ve explored two common pitfalls in deploying ML models: training-serving skew </span><a id="_idIndexMarker731"/><span class="koboSpan" id="kobo.384.1">and model drift. </span><span class="koboSpan" id="kobo.384.2">We’ve learned how to identify these issues and looked at steps to mitigate their effects. </span><span class="koboSpan" id="kobo.384.3">By ensuring consistency </span><a id="_idIndexMarker732"/><span class="koboSpan" id="kobo.385.1">in training and serving data, monitoring model performance, and regularly updating our models, we can ensure they remain effective </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">and relevant.</span></span></p>
<p><span class="koboSpan" id="kobo.387.1">As we move forward, we’ll explore another critical aspect of ML models: bias and fairness. </span><span class="koboSpan" id="kobo.387.2">This will help us understand how models can be biased against different sub-populations and how to ensure our models </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">are fair.</span></span></p>
<h1 id="_idParaDest-242"><a id="_idTextAnchor258"/><span class="koboSpan" id="kobo.389.1">Bias and fairness</span></h1>
<p><span class="koboSpan" id="kobo.390.1">Within ML, bias and fairness are not just ethical considerations but critical factors that can significantly impact the effectiveness of your ML models. </span><span class="koboSpan" id="kobo.390.2">We have already encountered bias in how it is related to underfitting and overfitting. </span><span class="koboSpan" id="kobo.390.3">We will now explore bias in the context of how the model fully and accurately represents all groups within the data – for example, different demographic groups within a dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">of customers.</span></span></p>
<h2 id="_idParaDest-243"><a id="_idTextAnchor259"/><span class="koboSpan" id="kobo.392.1">Understanding bias</span></h2>
<p><span class="koboSpan" id="kobo.393.1">Bias in ML refers </span><a id="_idIndexMarker733"/><span class="koboSpan" id="kobo.394.1">to a model’s tendency to systematically make errors due to limitations in the training data or the model’s design. </span><span class="koboSpan" id="kobo.394.2">This could be due to various reasons, including </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.396.1">Inadequate or unrepresentative training data</span></strong><span class="koboSpan" id="kobo.397.1">: If your dataset doesn’t fully capture the complexities and diversity of the real world, your model might make </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">inaccurate assumptions</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.399.1">Inherent prejudices in the data collection process</span></strong><span class="koboSpan" id="kobo.400.1">: If there are historical biases embedded in the way data was gathered, your model may perpetuate </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">those biases</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.402.1">Example – bias in loan approval</span></h3>
<p><span class="koboSpan" id="kobo.403.1">Consider a bank that uses an ML model to approve or reject loan applications. </span><span class="koboSpan" id="kobo.403.2">If the training data </span><a id="_idIndexMarker734"/><span class="koboSpan" id="kobo.404.1">used to build this model includes fewer examples of successful loan repayments from a certain demographic group, the model might learn to reject applications from this group more often, regardless of the applicants’ individual creditworthiness. </span><span class="koboSpan" id="kobo.404.2">This is an example </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">of bias.</span></span></p>
<h2 id="_idParaDest-244"><a id="_idTextAnchor260"/><span class="koboSpan" id="kobo.406.1">Understanding fairness</span></h2>
<p><span class="koboSpan" id="kobo.407.1">Fairness is a </span><a id="_idIndexMarker735"/><span class="koboSpan" id="kobo.408.1">broader concept that looks at the impact of a model’s decisions. </span><span class="koboSpan" id="kobo.408.2">A model is considered unfair if it systematically favors one group over another, even if the bias itself </span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">is unintentional.</span></span></p>
<h3><span class="koboSpan" id="kobo.410.1">Example – fairness in advertising</span></h3>
<p><span class="koboSpan" id="kobo.411.1">Imagine an online retailer that uses an ML model to decide which customers to target with a </span><a id="_idIndexMarker736"/><span class="koboSpan" id="kobo.412.1">promotional offer. </span><span class="koboSpan" id="kobo.412.2">If the model systematically excludes certain demographic groups from receiving the offer, it could be considered unfair, leading to missed opportunities and potential </span><span class="No-Break"><span class="koboSpan" id="kobo.413.1">customer alienation.</span></span></p>
<h2 id="_idParaDest-245"><a id="_idTextAnchor261"/><span class="koboSpan" id="kobo.414.1">Mitigating bias and ensuring fairness</span></h2>
<p><span class="koboSpan" id="kobo.415.1">Here are </span><a id="_idIndexMarker737"/><span class="koboSpan" id="kobo.416.1">some key strategies to address </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">these issues:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.418.1">Representative data</span></strong><span class="koboSpan" id="kobo.419.1">: Ensure your training data is as representative of the real-world population as possible. </span><span class="koboSpan" id="kobo.419.2">This may involve collecting more data, using techniques </span><a id="_idIndexMarker738"/><span class="koboSpan" id="kobo.420.1">such as oversampling for underrepresented groups, and carefully addressing inherent biases in </span><span class="No-Break"><span class="koboSpan" id="kobo.421.1">existing datasets.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.422.1">Fairness-aware algorithms</span></strong><span class="koboSpan" id="kobo.423.1">: Explore using algorithms that are specifically designed to consider fairness during the </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">training process.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.425.1">Monitoring and evaluation</span></strong><span class="koboSpan" id="kobo.426.1">: Use evaluation metrics such as disparate impact and equal opportunity difference to measure potential biases and disparities in your model’s predictions. </span><span class="koboSpan" id="kobo.426.2">Regularly monitor these metrics to identify areas where fairness might </span><span class="No-Break"><span class="koboSpan" id="kobo.427.1">be compromised.</span></span></li>
</ul>
<h2 id="_idParaDest-246"><a id="_idTextAnchor262"/><span class="koboSpan" id="kobo.428.1">Key takeaways</span></h2>
<p><span class="koboSpan" id="kobo.429.1">By understanding </span><a id="_idIndexMarker739"/><span class="koboSpan" id="kobo.430.1">bias and fairness, you can take steps to build ML models </span><a id="_idIndexMarker740"/><span class="koboSpan" id="kobo.431.1">that are both accurate and equitable. </span><span class="koboSpan" id="kobo.431.2">This is important not only for ethical reasons but also for ensuring that your models make sound business decisions that benefit </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">all stakeholders.</span></span></p>
<h1 id="_idParaDest-247"><a id="_idTextAnchor263"/><span class="koboSpan" id="kobo.433.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.434.1">In this chapter, we’ve explored some of the common pitfalls in training and deploying ML models, including inadequate training data, poor data quality, over- and underfitting, training-serving skew, and model drift. </span><span class="koboSpan" id="kobo.434.2">We’ve also explored the concepts of bias and fairness, their impact on business outcomes, and how to mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.435.1">these issues.</span></span></p>
<p><span class="koboSpan" id="kobo.436.1">As we move forward, remember that data science is not just about building models, but also about ensuring that these models are reliable, fair, and beneficial to </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">all stakeholders.</span></span></p>
<p><span class="koboSpan" id="kobo.438.1">In the next chapter, we’ll explore the different types of data science projects you might encounter and how to approach each </span><span class="No-Break"><span class="koboSpan" id="kobo.439.1">of them.</span></span></p>
</div>


<div class="Content" id="_idContainer080">
<h1 id="_idParaDest-248" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor264"/><span class="koboSpan" id="kobo.1.1">Part 3: Leading Successful Data Science Projects and Teams</span></h1>
<p><span class="koboSpan" id="kobo.2.1">This part explores the leadership aspects of data science, including project structure, team composition, management strategies, and the importance of continuous learning and staying current with emerging technologies. </span><span class="koboSpan" id="kobo.2.2">This part has the </span><span class="No-Break"><span class="koboSpan" id="kobo.3.1">following chapters:</span></span></p>
<ul>
<li><a href="B19633_11.xhtml#_idTextAnchor265"><em class="italic"><span class="koboSpan" id="kobo.4.1">Chapter 11</span></em></a><em class="italic"><span class="koboSpan" id="kobo.5.1">, The Structure of a Data Science Project</span></em></li>
<li><a href="B19633_12.xhtml#_idTextAnchor291"><em class="italic"><span class="koboSpan" id="kobo.6.1">Chapter 12</span></em></a><em class="italic"><span class="koboSpan" id="kobo.7.1">, The Data Science Team</span></em></li>
<li><a href="B19633_13.xhtml#_idTextAnchor319"><em class="italic"><span class="koboSpan" id="kobo.8.1">Chapter 13</span></em></a><em class="italic"><span class="koboSpan" id="kobo.9.1">, Managing the Data Science Team</span></em></li>
<li><a href="B19633_14.xhtml#_idTextAnchor337"><em class="italic"><span class="koboSpan" id="kobo.10.1">Chapter 14</span></em></a><em class="italic"><span class="koboSpan" id="kobo.11.1">, Continuing Your Journey as a Data Science Leader</span></em></li>
</ul>
</div>
<div>
<div id="_idContainer081">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer082">
</div>
</div>
</body></html>