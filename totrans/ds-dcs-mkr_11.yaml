- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Structure of a Data Science Project
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science projects can vary significantly in their scope, objectives, and
    deliverables. From exploratory data analysis and building reports and dashboards
    to developing and deploying machine learning and artificial intelligence models
    to production – the structure and approach to a data science project needs to
    be tailored accordingly.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will look at the common types of data science projects and
    their associated processes and deliverables. This will equip you, as a leader
    of data science initiatives, with knowledge of how to scope and plan a data science
    project, and the key steps involved in researching, developing, testing, and deploying
    a data product.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to do the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Identify, prioritize, and frame data science use cases
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distinguish different types of data science projects and deliverables
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scope and plan a data science project and create useful artifacts such as requirements
    documents, project plans, and test strategies
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the research and development process associated with data science
    projects
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appreciate the importance of thoroughly testing a data product before delivery
    or deployment
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Safely deploy and monitor a data product in a production environment
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether you are overseeing a short-term data science project or the development
    of a machine-learning-powered software application, understanding the key stages
    and best practices covered in this chapter will help ensure your data science
    initiatives are set up for success.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: The various types of data science projects
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before looking at the structure of a data science project, let’s discuss the
    different types of data science projects you might encounter. The type of data
    science, machine learning, or artificial intelligence project can radically alter
    how the project should be structured.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'The three broadest categories of data science projects are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Data products
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reports and analytics
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Research and methodology
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within these categories are a wide range of projects, but this is a useful distinction
    to understand. This is because data products are deployed and maintained over
    time, whereas a one-off report, analysis, or research has a finite lifespan.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at these in more detail.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Data products
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data products are software applications or systems that can leverage data, machine
    learning algorithms, and artificial intelligence techniques to provide valuable
    features, insights, or automated decision-making capabilities to end users or
    other systems.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: These products are designed to be deployed, maintained, and continuously improved
    over time.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the key characteristics of data products:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: They are driven by data and powered by machine learning or artificial intelligence
    algorithms
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They provide continued value to users through features, predictions, recommendations,
    or automation
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They require ongoing maintenance, updates, and monitoring to ensure performance
    and reliability
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They often involve integration with other systems or APIs
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability and efficiency are important considerations
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To give a concrete example, a data product could be, for instance, a delivery
    time prediction model within a food delivery app. This model could provide, via
    an API, estimates on how long it would take from ordering to the food being delivered
    to the user, with this information being provided continuously during delivery
    based on features such as the distance from the restaurant to the customer’s location,
    the location and availability of drivers, and the traffic levels. You may have
    seen the outputs from one of these models when using apps such as Uber Eats, DoorDash,
    or Deliveroo.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: As you might well imagine, deploying a scoring model that can serve many thousands
    of customers in real time would be a huge engineering effort. Most data products
    aren’t as complex; however, the point of this example is to emphasize that data
    products require a level of design, engineering, testing, and maintenance that
    reports and pure research do not.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Data products are not “fire and forget”; they must be supported and maintained
    after deployment. So, plan with the end in mind and think about how and who will
    maintain a successful product as it serves users.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will primarily focus on how to plan and deliver data products,
    which we will cover later in this chapter. But before this, let’s look at the
    two other broad categories of data science projects that you might encounter.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Reports and analytics
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reports and analytics projects focus on analyzing and deriving insights from
    data to support decision-making or tracking of business performance. These projects
    typically involve collecting, processing, and visualizing data to provide meaningful
    and actionable information to stakeholders.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the key characteristics of reporting and analytics are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Emphasis on data exploration, analysis, and interpretation
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizes statistical methods, data visualization techniques, and business intelligence
    tools
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aims to uncover patterns, trends, and relationships in data
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports data-driven decision-making and strategic planning
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deliverables often include reports, presentations, or interactive visualizations
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Many of these deliverables are one-off, ad hoc outputs with a finite lifespan
    so that you can plan the project accordingly. This may follow the following structure:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '**Gathering requirements**: Gathering business and data requirements and planning
    the analysis or modeling approach.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Collecting data**: Collecting all the relevant data from internal or external
    sources.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Processing data**: Cleaning and wrangling the data so that it’s in the required
    structure for analysis and/or modeling.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis and modeling**: Carrying out data analysis and statistical or machine
    learning modeling to provide insights and understanding of the data that support
    the business requirements.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reporting**: Producing the reporting deliverable, whether it’s a report,
    presentation, or interactive visualization, using data visualization techniques
    and summarizing the data in a way that it can easily be interpreted by the viewer
    while providing insights and recommendations that they can act upon.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This structure may not be strictly linear, and there may be iterations of data
    collection or gathering additional requirements or inputs from the business at
    each stage before the final deliverable is presented.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: The final deliverable should emphasize actionable insights and recommendations
    and encourage the end user to act upon insights that you are confident about.
    Often, reports are merely looked at and no further action is taken, which has
    limited value for the business.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s look at the third type of data science/machine learning project:
    research and methodology. Unless you’re working within academia or a research
    company or lab focused on advancing the field of machine learning or artificial
    intelligence, you may not come across this type of project. Often, within the
    industry, companies rely on tried and tested techniques or models to develop their
    use cases.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Research and methodology
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Research and methodology projects focus on advancing the field of artificial
    intelligence, machine learning, or data science by developing new algorithms,
    techniques, or approaches. These projects often involve experimenting, benchmarking,
    and evaluating different methods to push the boundaries of what is possible and
    improve the state-of-the-art.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the key characteristics of research and methodology projects are as
    follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Emphasis on innovation, experimentation, and pushing the limits of current techniques
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Involves developing novel algorithms, models, or optimization techniques
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requires a deep understanding of the underlying mathematical and statistical
    principles
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often involves comparative analysis and evaluating different approaches
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aims to contribute to the scientific community through publications, open source
    code, or research papers
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This type of project could follow an approach with involves the following stages:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '**Literature review**: Reviewing existing research and identifying gaps or
    areas for improvement.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hypothesis formulation**: Developing a clear research question and hypothesis.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Methodology development**: Designing and implementing novel algorithms, models,
    or techniques.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Experimental setup**: Preparing data, defining evaluation metrics, and setting
    up experiments.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Evaluation and analysis**: Conducting experiments, analyzing results, and
    comparing them with state-of-the-art models.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Documentation and dissemination**: Writing research papers, preparing presentations,
    and sharing code and findings with the company or wider research community.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档编写与传播**：撰写研究论文、准备演示文稿，并与公司或更广泛的研究社区分享代码和发现。'
- en: Now that we have seen the main, broad types of data science projects, let’s
    focus on the structure and stages of a data science project that aims to deliver
    a data product. This is where companies and teams often trip up since designing
    and developing a machine learning or artificial intelligence solution comes with
    a lot of challenges. Planning the project with the right level of expertise and
    resources is crucial.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了数据科学项目的主要类型，让我们重点关注旨在交付数据产品的数据科学项目的结构和阶段。这是公司和团队常常犯错的地方，因为设计和开发机器学习或人工智能解决方案充满了挑战。规划项目时需要具备适当的专业知识和资源至关重要。
- en: The stages of a data product
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据产品的阶段
- en: 'When leading the development of a new machine learning or artificial-intelligence-based
    product, there are several stages that you will encounter and are useful to understand.
    This section will provide you with a framework and tools so that you can work
    with machine learning and artificial intelligence teams in developing successful
    data products:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在领导新机器学习或基于人工智能产品的开发时，你将遇到几个阶段，理解这些阶段非常有用。本节将为你提供框架和工具，帮助你与机器学习和人工智能团队合作，开发成功的数据产品：
- en: '![Figure 11.1: The stages of a data science product](img/B19633_11_1.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1：数据科学产品的阶段](img/B19633_11_1.jpg)'
- en: 'Figure 11.1: The stages of a data science product'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1：数据科学产品的阶段
- en: While the stages of a data science product can be roughly outlined as Identify,
    Evaluate, Plan, Build, and Maintain, it’s important to note that modern product
    development typically follows an Agile methodology. In practice, these stages
    are not strictly sequential, but iterative and interconnected.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据科学产品的阶段可以大致概括为识别、评估、规划、构建和维护，但需要注意的是，现代产品开发通常遵循敏捷方法论。实际上，这些阶段并不是严格的顺序进行，而是迭代和相互关联的。
- en: Teams often work in short sprints, continuously gathering feedback, re-evaluating
    priorities, and adapting their plans. This allows for more flexibility, quicker
    iterations, and the ability to pivot when needed, ultimately leading to a product
    that better meets user needs and business goals.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 团队通常在短期冲刺中工作，持续收集反馈、重新评估优先级并调整计划。这种方式提供了更多的灵活性、更快的迭代速度，并能在需要时做出调整，最终有助于开发出更符合用户需求和商业目标的产品。
- en: So, while this framework provides a helpful overview of the key considerations
    at each stage, keep in mind that the process is more cyclical than linear, with
    insights from later stages often informing and refining earlier assumptions and
    decisions.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管这个框架提供了每个阶段关键考虑因素的有用概述，但请记住，这个过程比线性更具周期性，后期阶段的洞察往往会反过来影响和完善早期的假设和决策。
- en: Identifying use cases
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别用例
- en: An often-overlooked stage in the data science project life cycle is taking time
    to identify the “right” use cases. Many organizations start with the wrong premise,
    wanting to “do artificial intelligence,” “do machine learning” or “do data science”
    without clear business objectives. These companies end up investing time, effort,
    and human resources into projects that deliver little to no value.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学项目生命周期中，一个常被忽视的阶段是花时间识别“正确”的用例。许多组织从错误的前提开始，想要“做人工智能”、“做机器学习”或“做数据科学”，却没有明确的商业目标。这些公司最终投入了大量时间、精力和人力资源，却很少获得实际价值。
- en: This may seem obvious; however, many organizations fail to deliver a **return
    on investment** (**ROI**) through data science, machine learning, or artificial
    intelligence initiatives. One of the most significant factors that contribute
    toward this is developing solutions that do not have a material impact on the
    business’s bottom line. This is much easier said than done.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来显而易见；然而，许多组织未能通过数据科学、机器学习或人工智能项目实现**投资回报**（**ROI**）。导致这种情况的一个重要因素是开发的解决方案未能对企业的盈利产生实质性影响。说起来容易，做起来难。
- en: Spending sufficient time and effort identifying the right use cases, and projecting
    their financial impact, is a foundational step in any data science project. Get
    it right, and you set your project up for success. Get it wrong, and you risk
    wasting time and resources on initiatives that fail to deliver real value.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: A use case, in this context, is a specific application of data science techniques
    to solve a business problem or capture an opportunity. However, it’s important
    to recognize that data science isn’t always the best solution. In many situations,
    traditional business intelligence, software engineering, or even simple process
    improvements can be more effective.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'To identify use cases that are both technically feasible and deliver clear
    business value, it’s best to follow a structured approach:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**Understand the value chain**: Start by understanding the key functions and
    processes within your organization. Identify areas where data science/machine
    learning/artificial intelligence could potentially deliver value, whether by reducing
    costs, increasing revenue, improving efficiency, or mitigating risks. The solution
    should ultimately contribute to the business’s bottom line through one or more
    of the following, either directly or indirectly:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 11.2: Data science use case aims](img/B19633_11_2.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Data science use case aims'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Use this stage to develop a long list of potential data science, machine learning,
    or artificial intelligence use cases.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Try to estimate the financial value for each use case under different scenarios,
    such as via a base-level scenario, a more optimistic scenario, and a more pessimistic
    scenario.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '**Speak to stakeholders**: Conduct workshops and interviews with business stakeholders
    to gain insights into their challenges, pain points, and opportunities for data
    science and machine learning/artificial intelligence. Ask about data availability,
    current analytical capabilities, and decision-making processes:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 11.3: Example business questions to identify use cases](img/B19633_11_3.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Example business questions to identify use cases'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '**Frame the data science use cases**: Based on these insights, start framing
    potential use cases that align with key business objectives. Importantly, these
    use cases need to be framed as problems that data science, machine learning, or
    artificial intelligence can realistically solve. Involve data science/machine
    learning experts to validate the technical feasibility.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating use cases
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you have identified a long list of use cases, you can evaluate each to
    decide where the team should focus their effort with confidence:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '**Prioritize based on value and feasibility**: Gather information on each potential
    use case, including data requirements, technology needs, and estimates of business
    value. Use this to prioritize use cases based on their potential impact and likelihood
    of success.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prototype and test**: Before fully committing to a use case, if there is
    time, it may be useful to develop a rapid prototype using sample data to test
    its technical feasibility and potential value. If the prototype shows promise,
    the use case can be greenlit for full development.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a template use case scorecard for an example use case that
    you can utilize to evaluate the use cases you have identified:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4: Template use case evaluation scorecard](img/B19633_11_4.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Template use case evaluation scorecard'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: By following this pragmatic approach to use case identification, you can generate
    a pipeline of data science projects that are closely tied to business objectives
    and have clear, measurable KPIs. This helps with avoiding common pitfalls, such
    as pursuing use cases that are a poor fit for data science or that are unlikely
    to deliver meaningful outcomes.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll explore best practices for scoping and planning a
    data science project once you’ve identified a promising use case.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Planning the data product
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When planning a data product, top artificial intelligence/machine learning
    teams move away from extensive documentation and rigid, long-term plans. Instead,
    they adopt a more agile, iterative approach that emphasizes collaboration, adaptability,
    and delivering value incrementally. Here’s what that looks like in practice:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'Define clear, measurable objectives:'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Work with stakeholders to establish specific, achievable goals for the data
    product
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure these objectives align with the organization’s overall strategy
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on outcomes, not just outputs
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Build a skilled, cross-functional team:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the key skills needed for the project (for example, machine learning/artificial
    intelligence, data engineering, domain expertise, UX/UI design, and development)
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Assemble a lean, agile team with a mix of these skills
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bring in expertise and insights from outside the team, whether from customers,
    other business units, or external advisors
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Assess data and technology requirements:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine the data and infrastructure needed to support the product
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Plan for data governance, security, and privacy
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Select tools and platforms that enable rapid experimentation and iteration
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Develop a roadmap:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Break the project into manageable sprints, each with clear deliverables
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Prioritize features and tasks based on their value and feasibility
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Remain open to adapting plans based on feedback and learnings
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Foster a collaborative working environment:'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use tools to facilitate planning and communication, including team documentation
    spaces such as Notion or communication channels such as Slack
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Hold meetings as necessary but avoid introducing meetings for their own sake
    or bureaucracy as this slows the team down without a clear benefit
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Promote a culture of peer review among team members, such as data scientists,
    machine learning engineers, and data engineers, to collectively improve the quality
    of the team’s work
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Encourage open communication, continuous feedback, and a focus on iterative
    improvement
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Practical example – planning a data science project in marketing
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s consider a practical example of planning a data science project in the
    marketing industry. A company wants to use data science to optimize its digital
    advertising strategy:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The problem is defined as “*How can we use data science to improve the effectiveness
    of our digital advertising campaigns?*” The stakeholders are the marketing team,
    the sales team, and the company’s leadership.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The deliverable is a minimum viable product predictive model that can forecast
    the performance of different advertising strategies. The data required includes
    historical advertising data, sales data, and customer demographic data.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Success will be measured by the increase in sales attributable to the optimized
    advertising strategy. The constraints include a 6-month timeline, a budget for
    a technical team and testing advertisements, and the need to comply with data
    privacy regulations.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Think about the team you might need, the data and systems you and your team
    would need access to, and how the team will deploy and maintain the solution.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: By focusing on the core elements of planning and embracing an Agile mindset,
    artificial intelligence/machine learning teams can effectively plan and execute
    data product development while remaining responsive to change. The emphasis is
    on collaboration, flexibility, and delivering value to users and stakeholders
    consistently.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Developing a data product
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to developing a data product, following best practices can make
    the difference between a solution that truly delivers value and one that falls
    short. Since you have some knowledge of data science, you understand the potential
    of data products to drive business outcomes, but you also know that the development
    process is not always straightforward.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll cover the key stages of data product development and
    explore the best practices that top artificial intelligence/machine learning teams
    rely on to create successful solutions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation and exploratory analysis
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first stage of developing a data product involves acquiring and analyzing
    the data the product will be built upon. We covered many techniques for this stage
    in *Chapters 2* and *3*.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'The following tasks are included within the data preparation and exploratory
    analysis stage:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Identify and acquire relevant data sources
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform data cleaning, integration, and preprocessing
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conduct exploratory data analysis to gain insights and inform feature engineering
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish data validation and quality control processes
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop data pipelines for both training and inference
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practice
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Invest in building robust, scalable data pipelines that can handle the demands
    of your data product and ensure data quality and consistency between training
    and inference.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Model design and development
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This second stage often involves the most interesting part for machine learning
    and artificial intelligence engineers as they have the chance to bring their expertise
    to the fore in terms of designing and developing (training) the model.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'This could include doing the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Selecting appropriate algorithms and modeling techniques based on the problem
    type and data characteristics
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing the model architecture and hyperparameters
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the model using suitable programming languages and frameworks
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting model training, tuning, and validation
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practice
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Employ techniques such as cross-validation, regularization, and ensemble methods
    to improve model performance and generalization.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation and testing
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before deploying a model to production, ensuring that you thoroughly evaluate
    and test the model is the most important step.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: We covered many evaluation metrics in [*Chapter 9*](B19633_09.xhtml#_idTextAnchor216).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the steps that could be included within this stage:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Defining relevant evaluation metrics and testing procedures
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessing model performance using appropriate validation techniques (for example,
    hold-out validation and k-fold cross-validation)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting thorough testing to verify model behavior and identify potential
    issues
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing sensitivity analysis and stress testing to ensure robustness
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practice
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Use a combination of quantitative metrics and qualitative analysis to gain a
    comprehensive understanding of model performance and limitations.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and monitoring a data product
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, your team is at the stage of deploying the model to production. This
    should be the aim of every successful machine learning or artificial intelligence
    product project, but it must be done with care. There are several steps and best
    practices to follow:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '**Integration**: Integrate the model into the broader system architecture.
    This involves ensuring the model can communicate with other components of the
    system, such as databases, APIs, and user interfaces.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment infrastructure**: Establish deployment processes and infrastructure.
    This includes setting up the necessary servers, containers, or cloud services
    to host the model. Automation tools such as Docker, Kubernetes, and cloud-specific
    services can streamline this process.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Online testing**: Alongside offline evaluation and testing, an important
    process before deploying to production is online testing – that is, testing the
    system on real, live data before deployment. There are various strategies to achieve
    this:'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A/B testing**: If you want to compare the performance of two or more models,
    carry out A/B testing by randomly splitting traffic between the different models
    and measuring key metrics. You should use A/B testing for model selection and
    iterative improvements.'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canary deployment**: After successful shadow testing, perform a canary deployment
    by releasing the model to a small subset of users or traffic while keeping the
    majority on the existing system. Monitor the model’s performance and gather feedback
    from this limited release.'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment strategies**: Deploying to production is a critical step, and
    a successful deployment should be the aim of any machine learning or artificial
    intelligence model development. Following evaluation and testing, you could deploy
    the model directly to production. However, to add an additional level of safety,
    blue/green deployment is one strategy you can implement to ensure continuity:'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blue/green deployment**: If the canary deployment proves successful, proceed
    with a blue/green deployment. Set up two identical production environments (blue
    and green) and deploy the new model to one environment while keeping the existing
    system in the other. Switch traffic to the new environment and monitor for any
    issues. If problems arise, quickly switch back to the previous environment.'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and logging**: Implement comprehensive monitoring and logging
    for the deployed model. This includes tracking model performance metrics, system
    health, and user interactions. Set up alerts to notify the team if any issues
    or anomalies are detected.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feedback loop**: Establish a feedback loop to continually gather data and
    insights from the production system. This data can be used to retrain and update
    the model, ensuring it remains accurate and relevant over time.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a good control test is a challenging but crucial part of the deployment
    process. It requires careful design to ensure the test accurately reflects real-world
    conditions and provides meaningful insights.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Remember, the specific deployment steps and best practices may vary depending
    on your organization’s infrastructure, requirements, and constraints. It’s important
    to adapt these general guidelines to your specific context.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Best practice
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Adopt DevOps and MLOps practices to streamline the deployment and management
    of data products in production environments.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: General best practices for data product development
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To ensure successful outcomes and maintain high standards, top data science,
    artificial intelligence, and machine learning teams employ the following cross-cutting
    best practices throughout the development process:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '**Version control** **and reproducibility:**'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement robust version control systems for code, data, and models. For code
    version control, Git and Git-based software such as GitHub, GitLab, and Bitbucket
    are common tools. For data and model version control, software such as **Data
    Version Control** (**DVC**) and MLflow are also common approaches to tracking
    data, model artifacts, and model training experiments.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure reproducibility by documenting dependencies, configurations, and experimental
    setups.
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use containerization technologies to create reproducible environments for development
    and deployment.
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clear documentation and** **knowledge management**:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain clear and comprehensive documentation for data, code, and models
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish knowledge-sharing practices, such as wikis, tutorials, and internal
    forums
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Encourage team members to document their work, insights, and lessons learned
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous integration and continuous** **delivery** (**CI/CD**):'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement CI/CD pipelines to automate build, testing, and deployment processes
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure code quality through automated testing, code reviews, and static code
    analysis
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable rapid and reliable deployment of models and applications to production
    environments
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adherence to responsible machine learning/artificial** **intelligence principles**:'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prioritize fairness, transparency, and accountability in machine learning/artificial
    intelligence development
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Conduct thorough testing and validation to identify and mitigate biases in models
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide clear explanations of model decisions and ensure interpretability where
    necessary
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish governance frameworks and ethical guidelines for artificial intelligence
    development and deployment
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-centric approach**:'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep the end user at the center of all development efforts
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Gather user feedback and incorporate it into the iterative development process
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuously validate solutions with users to ensure they meet their needs and
    expectations
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By adhering to these best practices and tailoring them to specific contexts,
    you can navigate many of the complexities of data product development. Stay focused
    on delivering value to users, embrace a culture of continuous learning and improvement,
    and foster a collaborative environment that encourages innovation and excellence
    in data science, artificial intelligence, and machine learning initiatives.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Having followed all the processes and best practices for developing and deploying
    successful solutions, there is an important step that should not be overlooked:
    evaluating the business impact.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: As data science practitioners, our work is only valuable if it delivers tangible
    benefits to the organizations we serve. The time, effort, cost, and resources
    invested in developing these solutions must yield real, measurable results; otherwise,
    the work remains a mere technical exercise.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore methods to assess business impact and discuss
    strategies to expand the influence of a solution.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating impact
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alongside evaluating model accuracy, it is essential to gauge the business impact
    of a data product. This involves selecting relevant metrics or **key performance
    indicators** (**KPIs**) that align with the organization’s goals and objectives.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: These metrics or KPIs should provide a clear picture of how the solution is
    affecting the business’s bottom line.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some concrete business examples of data science, machine learning,
    and artificial intelligence solutions across different industries, and how business
    impact could be measured.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Predictive maintenance in manufacturing
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use Case**: Implementing machine learning models to predict equipment failures
    and optimize maintenance schedules within a manufacturing company'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: To measure the impact of manufacturing, the following metrics
    could be tracked:'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in unplanned downtime
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in equipment availability and uptime
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in maintenance costs
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in **overall equipment** **effectiveness** (**OEE**)
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fraud detection in banking
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Deploying artificial-intelligence-powered fraud detection systems
    to identify and prevent fraudulent transactions'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: The banking KPIs that could be tracked for the fraud detection
    model could include the following:'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in fraudulent transactions
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in fraud detection accuracy
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in false positives
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Savings from prevented fraudulent activities
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer churn prediction in telecom
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Using machine learning models to predict customer churn and implement
    targeted retention strategies'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: The KPIs associated with a custom churn and retention solution
    could include the following:'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in customer churn rate
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in customer retention
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in **customer lifetime** **value** (**CLV**)
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in revenue from retained customers
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Demand forecasting in retail
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Utilizing machine learning algorithms to forecast product demand
    and optimize inventory management'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: To measure the impact of a demand forecasting model, the
    following could be tracked:'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in inventory holding costs
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in stockouts and lost sales
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in inventory turnover ratio
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in forecast accuracy
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Personalized recommendations in e-commerce
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Implementing machine-learning-powered recommendation engines
    to personalize product recommendations for customers'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: To track the effectiveness of an e-commerce recommendation
    engine, you could track the following:'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in conversion rate
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in **average order** **value** (**AOV**)
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in customer engagement and loyalty
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in cross-sell and upsell opportunities
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictive maintenance in energy
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Applying machine learning techniques to predict equipment failures
    and optimize maintenance in energy production facilities'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**:'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in unplanned downtime
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in energy production efficiency
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in maintenance costs
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in safety and compliance metrics
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Workforce optimization in quick service restaurants
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Utilizing machine learning algorithms to optimize staffing levels
    and scheduling in restaurants'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**:'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in staff utilization and productivity
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in overtime and agency costs
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in patient satisfaction and care quality
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in employee satisfaction and retention
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbot-assisted customer support
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Implementing a **large language model** (**LLM**)-powered chatbot
    to provide instant customer support and handle common inquiries'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**:'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in customer support costs
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in customer response times
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in customer satisfaction
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deflection rate and human agent productivity
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Expansion of support coverage
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These additional examples further illustrate the wide range of data science,
    machine learning, and artificial intelligence applications across various industries
    and the specific business metrics and KPIs that can be used to measure their impact.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: By aligning data-driven initiatives with key business objectives and tracking
    relevant metrics, organizations can demonstrate the tangible value and ROI of
    their data science/machine learning/artificial intelligence investments.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Think about the core business metrics and KPIs within your organization or industry.
    Which metrics and KPIs relate most closely to the bottom-line profit for the business?
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Which of your use cases will have the greatest impact on those KPIs and the
    overall business performance?
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: By consistently monitoring and reporting on these business impact metrics, data
    science teams can demonstrate the value they bring to the organization and justify
    the investment in their projects. This not only helps secure continued support
    for ongoing initiatives but also paves the way for expanding the impact of successful
    solutions across the enterprise.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the essentials of structuring a data science project,
    focusing on developing impactful data products.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: We discussed three project categories, emphasizing the importance of selecting
    the right use cases that align with your organization’s goals and have the potential
    to deliver real value.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: We provided a framework for evaluating and prioritizing use cases based on feasibility
    and impact, ensuring that you invest resources in projects that drive your business
    forward.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: We also explored the key stages of data product development, from data preparation
    to model design, evaluation, and deployment, while adhering to best practices
    such as responsible AI principles, clear documentation, version control, and CI/CD
    practices.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed evaluating the business impact of your data product by
    selecting relevant metrics and KPIs that align with your company’s goals. By demonstrating
    the tangible value and ROI of your data science initiatives, you can secure ongoing
    support and expand the influence of your solutions across the organization.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: You should now have a much better idea of how to structure and run a data science,
    machine learning, or artificial intelligence project.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: However, nothing beats real-world experience. As you apply these concepts to
    your projects, you’ll encounter unique challenges and opportunities that will
    further refine your skills. Embrace these experiences, learn from successes and
    failures, and continuously adapt your approach.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll focus on building and managing a high-performing
    data science team while exploring key roles, skills, collaboration strategies,
    and best practices for fostering a culture of innovation and continuous learning.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
