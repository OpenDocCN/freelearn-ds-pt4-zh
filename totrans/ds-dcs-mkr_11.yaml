- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Structure of a Data Science Project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science projects can vary significantly in their scope, objectives, and
    deliverables. From exploratory data analysis and building reports and dashboards
    to developing and deploying machine learning and artificial intelligence models
    to production – the structure and approach to a data science project needs to
    be tailored accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will look at the common types of data science projects and
    their associated processes and deliverables. This will equip you, as a leader
    of data science initiatives, with knowledge of how to scope and plan a data science
    project, and the key steps involved in researching, developing, testing, and deploying
    a data product.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify, prioritize, and frame data science use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distinguish different types of data science projects and deliverables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scope and plan a data science project and create useful artifacts such as requirements
    documents, project plans, and test strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the research and development process associated with data science
    projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appreciate the importance of thoroughly testing a data product before delivery
    or deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Safely deploy and monitor a data product in a production environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether you are overseeing a short-term data science project or the development
    of a machine-learning-powered software application, understanding the key stages
    and best practices covered in this chapter will help ensure your data science
    initiatives are set up for success.
  prefs: []
  type: TYPE_NORMAL
- en: The various types of data science projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before looking at the structure of a data science project, let’s discuss the
    different types of data science projects you might encounter. The type of data
    science, machine learning, or artificial intelligence project can radically alter
    how the project should be structured.
  prefs: []
  type: TYPE_NORMAL
- en: 'The three broadest categories of data science projects are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Data products
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reports and analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Research and methodology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within these categories are a wide range of projects, but this is a useful distinction
    to understand. This is because data products are deployed and maintained over
    time, whereas a one-off report, analysis, or research has a finite lifespan.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at these in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Data products
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data products are software applications or systems that can leverage data, machine
    learning algorithms, and artificial intelligence techniques to provide valuable
    features, insights, or automated decision-making capabilities to end users or
    other systems.
  prefs: []
  type: TYPE_NORMAL
- en: These products are designed to be deployed, maintained, and continuously improved
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the key characteristics of data products:'
  prefs: []
  type: TYPE_NORMAL
- en: They are driven by data and powered by machine learning or artificial intelligence
    algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They provide continued value to users through features, predictions, recommendations,
    or automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They require ongoing maintenance, updates, and monitoring to ensure performance
    and reliability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They often involve integration with other systems or APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability and efficiency are important considerations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To give a concrete example, a data product could be, for instance, a delivery
    time prediction model within a food delivery app. This model could provide, via
    an API, estimates on how long it would take from ordering to the food being delivered
    to the user, with this information being provided continuously during delivery
    based on features such as the distance from the restaurant to the customer’s location,
    the location and availability of drivers, and the traffic levels. You may have
    seen the outputs from one of these models when using apps such as Uber Eats, DoorDash,
    or Deliveroo.
  prefs: []
  type: TYPE_NORMAL
- en: As you might well imagine, deploying a scoring model that can serve many thousands
    of customers in real time would be a huge engineering effort. Most data products
    aren’t as complex; however, the point of this example is to emphasize that data
    products require a level of design, engineering, testing, and maintenance that
    reports and pure research do not.
  prefs: []
  type: TYPE_NORMAL
- en: Data products are not “fire and forget”; they must be supported and maintained
    after deployment. So, plan with the end in mind and think about how and who will
    maintain a successful product as it serves users.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will primarily focus on how to plan and deliver data products,
    which we will cover later in this chapter. But before this, let’s look at the
    two other broad categories of data science projects that you might encounter.
  prefs: []
  type: TYPE_NORMAL
- en: Reports and analytics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reports and analytics projects focus on analyzing and deriving insights from
    data to support decision-making or tracking of business performance. These projects
    typically involve collecting, processing, and visualizing data to provide meaningful
    and actionable information to stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the key characteristics of reporting and analytics are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Emphasis on data exploration, analysis, and interpretation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizes statistical methods, data visualization techniques, and business intelligence
    tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aims to uncover patterns, trends, and relationships in data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports data-driven decision-making and strategic planning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deliverables often include reports, presentations, or interactive visualizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Many of these deliverables are one-off, ad hoc outputs with a finite lifespan
    so that you can plan the project accordingly. This may follow the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Gathering requirements**: Gathering business and data requirements and planning
    the analysis or modeling approach.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Collecting data**: Collecting all the relevant data from internal or external
    sources.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Processing data**: Cleaning and wrangling the data so that it’s in the required
    structure for analysis and/or modeling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis and modeling**: Carrying out data analysis and statistical or machine
    learning modeling to provide insights and understanding of the data that support
    the business requirements.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reporting**: Producing the reporting deliverable, whether it’s a report,
    presentation, or interactive visualization, using data visualization techniques
    and summarizing the data in a way that it can easily be interpreted by the viewer
    while providing insights and recommendations that they can act upon.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This structure may not be strictly linear, and there may be iterations of data
    collection or gathering additional requirements or inputs from the business at
    each stage before the final deliverable is presented.
  prefs: []
  type: TYPE_NORMAL
- en: The final deliverable should emphasize actionable insights and recommendations
    and encourage the end user to act upon insights that you are confident about.
    Often, reports are merely looked at and no further action is taken, which has
    limited value for the business.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s look at the third type of data science/machine learning project:
    research and methodology. Unless you’re working within academia or a research
    company or lab focused on advancing the field of machine learning or artificial
    intelligence, you may not come across this type of project. Often, within the
    industry, companies rely on tried and tested techniques or models to develop their
    use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: Research and methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Research and methodology projects focus on advancing the field of artificial
    intelligence, machine learning, or data science by developing new algorithms,
    techniques, or approaches. These projects often involve experimenting, benchmarking,
    and evaluating different methods to push the boundaries of what is possible and
    improve the state-of-the-art.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the key characteristics of research and methodology projects are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Emphasis on innovation, experimentation, and pushing the limits of current techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Involves developing novel algorithms, models, or optimization techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requires a deep understanding of the underlying mathematical and statistical
    principles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often involves comparative analysis and evaluating different approaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aims to contribute to the scientific community through publications, open source
    code, or research papers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This type of project could follow an approach with involves the following stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Literature review**: Reviewing existing research and identifying gaps or
    areas for improvement.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hypothesis formulation**: Developing a clear research question and hypothesis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Methodology development**: Designing and implementing novel algorithms, models,
    or techniques.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Experimental setup**: Preparing data, defining evaluation metrics, and setting
    up experiments.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Evaluation and analysis**: Conducting experiments, analyzing results, and
    comparing them with state-of-the-art models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Documentation and dissemination**: Writing research papers, preparing presentations,
    and sharing code and findings with the company or wider research community.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have seen the main, broad types of data science projects, let’s
    focus on the structure and stages of a data science project that aims to deliver
    a data product. This is where companies and teams often trip up since designing
    and developing a machine learning or artificial intelligence solution comes with
    a lot of challenges. Planning the project with the right level of expertise and
    resources is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: The stages of a data product
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When leading the development of a new machine learning or artificial-intelligence-based
    product, there are several stages that you will encounter and are useful to understand.
    This section will provide you with a framework and tools so that you can work
    with machine learning and artificial intelligence teams in developing successful
    data products:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1: The stages of a data science product](img/B19633_11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: The stages of a data science product'
  prefs: []
  type: TYPE_NORMAL
- en: While the stages of a data science product can be roughly outlined as Identify,
    Evaluate, Plan, Build, and Maintain, it’s important to note that modern product
    development typically follows an Agile methodology. In practice, these stages
    are not strictly sequential, but iterative and interconnected.
  prefs: []
  type: TYPE_NORMAL
- en: Teams often work in short sprints, continuously gathering feedback, re-evaluating
    priorities, and adapting their plans. This allows for more flexibility, quicker
    iterations, and the ability to pivot when needed, ultimately leading to a product
    that better meets user needs and business goals.
  prefs: []
  type: TYPE_NORMAL
- en: So, while this framework provides a helpful overview of the key considerations
    at each stage, keep in mind that the process is more cyclical than linear, with
    insights from later stages often informing and refining earlier assumptions and
    decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying use cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An often-overlooked stage in the data science project life cycle is taking time
    to identify the “right” use cases. Many organizations start with the wrong premise,
    wanting to “do artificial intelligence,” “do machine learning” or “do data science”
    without clear business objectives. These companies end up investing time, effort,
    and human resources into projects that deliver little to no value.
  prefs: []
  type: TYPE_NORMAL
- en: This may seem obvious; however, many organizations fail to deliver a **return
    on investment** (**ROI**) through data science, machine learning, or artificial
    intelligence initiatives. One of the most significant factors that contribute
    toward this is developing solutions that do not have a material impact on the
    business’s bottom line. This is much easier said than done.
  prefs: []
  type: TYPE_NORMAL
- en: Spending sufficient time and effort identifying the right use cases, and projecting
    their financial impact, is a foundational step in any data science project. Get
    it right, and you set your project up for success. Get it wrong, and you risk
    wasting time and resources on initiatives that fail to deliver real value.
  prefs: []
  type: TYPE_NORMAL
- en: A use case, in this context, is a specific application of data science techniques
    to solve a business problem or capture an opportunity. However, it’s important
    to recognize that data science isn’t always the best solution. In many situations,
    traditional business intelligence, software engineering, or even simple process
    improvements can be more effective.
  prefs: []
  type: TYPE_NORMAL
- en: 'To identify use cases that are both technically feasible and deliver clear
    business value, it’s best to follow a structured approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Understand the value chain**: Start by understanding the key functions and
    processes within your organization. Identify areas where data science/machine
    learning/artificial intelligence could potentially deliver value, whether by reducing
    costs, increasing revenue, improving efficiency, or mitigating risks. The solution
    should ultimately contribute to the business’s bottom line through one or more
    of the following, either directly or indirectly:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 11.2: Data science use case aims](img/B19633_11_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Data science use case aims'
  prefs: []
  type: TYPE_NORMAL
- en: Use this stage to develop a long list of potential data science, machine learning,
    or artificial intelligence use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Try to estimate the financial value for each use case under different scenarios,
    such as via a base-level scenario, a more optimistic scenario, and a more pessimistic
    scenario.
  prefs: []
  type: TYPE_NORMAL
- en: '**Speak to stakeholders**: Conduct workshops and interviews with business stakeholders
    to gain insights into their challenges, pain points, and opportunities for data
    science and machine learning/artificial intelligence. Ask about data availability,
    current analytical capabilities, and decision-making processes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 11.3: Example business questions to identify use cases](img/B19633_11_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Example business questions to identify use cases'
  prefs: []
  type: TYPE_NORMAL
- en: '**Frame the data science use cases**: Based on these insights, start framing
    potential use cases that align with key business objectives. Importantly, these
    use cases need to be framed as problems that data science, machine learning, or
    artificial intelligence can realistically solve. Involve data science/machine
    learning experts to validate the technical feasibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating use cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you have identified a long list of use cases, you can evaluate each to
    decide where the team should focus their effort with confidence:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prioritize based on value and feasibility**: Gather information on each potential
    use case, including data requirements, technology needs, and estimates of business
    value. Use this to prioritize use cases based on their potential impact and likelihood
    of success.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prototype and test**: Before fully committing to a use case, if there is
    time, it may be useful to develop a rapid prototype using sample data to test
    its technical feasibility and potential value. If the prototype shows promise,
    the use case can be greenlit for full development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a template use case scorecard for an example use case that
    you can utilize to evaluate the use cases you have identified:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4: Template use case evaluation scorecard](img/B19633_11_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Template use case evaluation scorecard'
  prefs: []
  type: TYPE_NORMAL
- en: By following this pragmatic approach to use case identification, you can generate
    a pipeline of data science projects that are closely tied to business objectives
    and have clear, measurable KPIs. This helps with avoiding common pitfalls, such
    as pursuing use cases that are a poor fit for data science or that are unlikely
    to deliver meaningful outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll explore best practices for scoping and planning a
    data science project once you’ve identified a promising use case.
  prefs: []
  type: TYPE_NORMAL
- en: Planning the data product
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When planning a data product, top artificial intelligence/machine learning
    teams move away from extensive documentation and rigid, long-term plans. Instead,
    they adopt a more agile, iterative approach that emphasizes collaboration, adaptability,
    and delivering value incrementally. Here’s what that looks like in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define clear, measurable objectives:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Work with stakeholders to establish specific, achievable goals for the data
    product
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure these objectives align with the organization’s overall strategy
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on outcomes, not just outputs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Build a skilled, cross-functional team:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the key skills needed for the project (for example, machine learning/artificial
    intelligence, data engineering, domain expertise, UX/UI design, and development)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Assemble a lean, agile team with a mix of these skills
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bring in expertise and insights from outside the team, whether from customers,
    other business units, or external advisors
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Assess data and technology requirements:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine the data and infrastructure needed to support the product
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Plan for data governance, security, and privacy
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Select tools and platforms that enable rapid experimentation and iteration
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Develop a roadmap:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Break the project into manageable sprints, each with clear deliverables
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Prioritize features and tasks based on their value and feasibility
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Remain open to adapting plans based on feedback and learnings
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Foster a collaborative working environment:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use tools to facilitate planning and communication, including team documentation
    spaces such as Notion or communication channels such as Slack
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Hold meetings as necessary but avoid introducing meetings for their own sake
    or bureaucracy as this slows the team down without a clear benefit
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Promote a culture of peer review among team members, such as data scientists,
    machine learning engineers, and data engineers, to collectively improve the quality
    of the team’s work
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Encourage open communication, continuous feedback, and a focus on iterative
    improvement
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Practical example – planning a data science project in marketing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s consider a practical example of planning a data science project in the
    marketing industry. A company wants to use data science to optimize its digital
    advertising strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: The problem is defined as “*How can we use data science to improve the effectiveness
    of our digital advertising campaigns?*” The stakeholders are the marketing team,
    the sales team, and the company’s leadership.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The deliverable is a minimum viable product predictive model that can forecast
    the performance of different advertising strategies. The data required includes
    historical advertising data, sales data, and customer demographic data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Success will be measured by the increase in sales attributable to the optimized
    advertising strategy. The constraints include a 6-month timeline, a budget for
    a technical team and testing advertisements, and the need to comply with data
    privacy regulations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Think about the team you might need, the data and systems you and your team
    would need access to, and how the team will deploy and maintain the solution.
  prefs: []
  type: TYPE_NORMAL
- en: By focusing on the core elements of planning and embracing an Agile mindset,
    artificial intelligence/machine learning teams can effectively plan and execute
    data product development while remaining responsive to change. The emphasis is
    on collaboration, flexibility, and delivering value to users and stakeholders
    consistently.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a data product
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to developing a data product, following best practices can make
    the difference between a solution that truly delivers value and one that falls
    short. Since you have some knowledge of data science, you understand the potential
    of data products to drive business outcomes, but you also know that the development
    process is not always straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll cover the key stages of data product development and
    explore the best practices that top artificial intelligence/machine learning teams
    rely on to create successful solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation and exploratory analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first stage of developing a data product involves acquiring and analyzing
    the data the product will be built upon. We covered many techniques for this stage
    in *Chapters 2* and *3*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following tasks are included within the data preparation and exploratory
    analysis stage:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify and acquire relevant data sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform data cleaning, integration, and preprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conduct exploratory data analysis to gain insights and inform feature engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish data validation and quality control processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop data pipelines for both training and inference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practice
  prefs: []
  type: TYPE_NORMAL
- en: Invest in building robust, scalable data pipelines that can handle the demands
    of your data product and ensure data quality and consistency between training
    and inference.
  prefs: []
  type: TYPE_NORMAL
- en: Model design and development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This second stage often involves the most interesting part for machine learning
    and artificial intelligence engineers as they have the chance to bring their expertise
    to the fore in terms of designing and developing (training) the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'This could include doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Selecting appropriate algorithms and modeling techniques based on the problem
    type and data characteristics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing the model architecture and hyperparameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the model using suitable programming languages and frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting model training, tuning, and validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practice
  prefs: []
  type: TYPE_NORMAL
- en: Employ techniques such as cross-validation, regularization, and ensemble methods
    to improve model performance and generalization.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation and testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before deploying a model to production, ensuring that you thoroughly evaluate
    and test the model is the most important step.
  prefs: []
  type: TYPE_NORMAL
- en: We covered many evaluation metrics in [*Chapter 9*](B19633_09.xhtml#_idTextAnchor216).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the steps that could be included within this stage:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining relevant evaluation metrics and testing procedures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessing model performance using appropriate validation techniques (for example,
    hold-out validation and k-fold cross-validation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting thorough testing to verify model behavior and identify potential
    issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing sensitivity analysis and stress testing to ensure robustness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practice
  prefs: []
  type: TYPE_NORMAL
- en: Use a combination of quantitative metrics and qualitative analysis to gain a
    comprehensive understanding of model performance and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and monitoring a data product
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, your team is at the stage of deploying the model to production. This
    should be the aim of every successful machine learning or artificial intelligence
    product project, but it must be done with care. There are several steps and best
    practices to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Integration**: Integrate the model into the broader system architecture.
    This involves ensuring the model can communicate with other components of the
    system, such as databases, APIs, and user interfaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment infrastructure**: Establish deployment processes and infrastructure.
    This includes setting up the necessary servers, containers, or cloud services
    to host the model. Automation tools such as Docker, Kubernetes, and cloud-specific
    services can streamline this process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Online testing**: Alongside offline evaluation and testing, an important
    process before deploying to production is online testing – that is, testing the
    system on real, live data before deployment. There are various strategies to achieve
    this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A/B testing**: If you want to compare the performance of two or more models,
    carry out A/B testing by randomly splitting traffic between the different models
    and measuring key metrics. You should use A/B testing for model selection and
    iterative improvements.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canary deployment**: After successful shadow testing, perform a canary deployment
    by releasing the model to a small subset of users or traffic while keeping the
    majority on the existing system. Monitor the model’s performance and gather feedback
    from this limited release.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment strategies**: Deploying to production is a critical step, and
    a successful deployment should be the aim of any machine learning or artificial
    intelligence model development. Following evaluation and testing, you could deploy
    the model directly to production. However, to add an additional level of safety,
    blue/green deployment is one strategy you can implement to ensure continuity:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blue/green deployment**: If the canary deployment proves successful, proceed
    with a blue/green deployment. Set up two identical production environments (blue
    and green) and deploy the new model to one environment while keeping the existing
    system in the other. Switch traffic to the new environment and monitor for any
    issues. If problems arise, quickly switch back to the previous environment.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and logging**: Implement comprehensive monitoring and logging
    for the deployed model. This includes tracking model performance metrics, system
    health, and user interactions. Set up alerts to notify the team if any issues
    or anomalies are detected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feedback loop**: Establish a feedback loop to continually gather data and
    insights from the production system. This data can be used to retrain and update
    the model, ensuring it remains accurate and relevant over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a good control test is a challenging but crucial part of the deployment
    process. It requires careful design to ensure the test accurately reflects real-world
    conditions and provides meaningful insights.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, the specific deployment steps and best practices may vary depending
    on your organization’s infrastructure, requirements, and constraints. It’s important
    to adapt these general guidelines to your specific context.
  prefs: []
  type: TYPE_NORMAL
- en: Best practice
  prefs: []
  type: TYPE_NORMAL
- en: Adopt DevOps and MLOps practices to streamline the deployment and management
    of data products in production environments.
  prefs: []
  type: TYPE_NORMAL
- en: General best practices for data product development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To ensure successful outcomes and maintain high standards, top data science,
    artificial intelligence, and machine learning teams employ the following cross-cutting
    best practices throughout the development process:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Version control** **and reproducibility:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement robust version control systems for code, data, and models. For code
    version control, Git and Git-based software such as GitHub, GitLab, and Bitbucket
    are common tools. For data and model version control, software such as **Data
    Version Control** (**DVC**) and MLflow are also common approaches to tracking
    data, model artifacts, and model training experiments.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure reproducibility by documenting dependencies, configurations, and experimental
    setups.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use containerization technologies to create reproducible environments for development
    and deployment.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clear documentation and** **knowledge management**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain clear and comprehensive documentation for data, code, and models
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish knowledge-sharing practices, such as wikis, tutorials, and internal
    forums
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Encourage team members to document their work, insights, and lessons learned
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous integration and continuous** **delivery** (**CI/CD**):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement CI/CD pipelines to automate build, testing, and deployment processes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure code quality through automated testing, code reviews, and static code
    analysis
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable rapid and reliable deployment of models and applications to production
    environments
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adherence to responsible machine learning/artificial** **intelligence principles**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prioritize fairness, transparency, and accountability in machine learning/artificial
    intelligence development
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Conduct thorough testing and validation to identify and mitigate biases in models
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide clear explanations of model decisions and ensure interpretability where
    necessary
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish governance frameworks and ethical guidelines for artificial intelligence
    development and deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-centric approach**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep the end user at the center of all development efforts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Gather user feedback and incorporate it into the iterative development process
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuously validate solutions with users to ensure they meet their needs and
    expectations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By adhering to these best practices and tailoring them to specific contexts,
    you can navigate many of the complexities of data product development. Stay focused
    on delivering value to users, embrace a culture of continuous learning and improvement,
    and foster a collaborative environment that encourages innovation and excellence
    in data science, artificial intelligence, and machine learning initiatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having followed all the processes and best practices for developing and deploying
    successful solutions, there is an important step that should not be overlooked:
    evaluating the business impact.'
  prefs: []
  type: TYPE_NORMAL
- en: As data science practitioners, our work is only valuable if it delivers tangible
    benefits to the organizations we serve. The time, effort, cost, and resources
    invested in developing these solutions must yield real, measurable results; otherwise,
    the work remains a mere technical exercise.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore methods to assess business impact and discuss
    strategies to expand the influence of a solution.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating impact
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alongside evaluating model accuracy, it is essential to gauge the business impact
    of a data product. This involves selecting relevant metrics or **key performance
    indicators** (**KPIs**) that align with the organization’s goals and objectives.
  prefs: []
  type: TYPE_NORMAL
- en: These metrics or KPIs should provide a clear picture of how the solution is
    affecting the business’s bottom line.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some concrete business examples of data science, machine learning,
    and artificial intelligence solutions across different industries, and how business
    impact could be measured.
  prefs: []
  type: TYPE_NORMAL
- en: Predictive maintenance in manufacturing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use Case**: Implementing machine learning models to predict equipment failures
    and optimize maintenance schedules within a manufacturing company'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: To measure the impact of manufacturing, the following metrics
    could be tracked:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in unplanned downtime
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in equipment availability and uptime
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in maintenance costs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in **overall equipment** **effectiveness** (**OEE**)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fraud detection in banking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Deploying artificial-intelligence-powered fraud detection systems
    to identify and prevent fraudulent transactions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: The banking KPIs that could be tracked for the fraud detection
    model could include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in fraudulent transactions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in fraud detection accuracy
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in false positives
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Savings from prevented fraudulent activities
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer churn prediction in telecom
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Using machine learning models to predict customer churn and implement
    targeted retention strategies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: The KPIs associated with a custom churn and retention solution
    could include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in customer churn rate
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in customer retention
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in **customer lifetime** **value** (**CLV**)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in revenue from retained customers
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Demand forecasting in retail
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Utilizing machine learning algorithms to forecast product demand
    and optimize inventory management'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: To measure the impact of a demand forecasting model, the
    following could be tracked:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in inventory holding costs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in stockouts and lost sales
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in inventory turnover ratio
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in forecast accuracy
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Personalized recommendations in e-commerce
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Implementing machine-learning-powered recommendation engines
    to personalize product recommendations for customers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**: To track the effectiveness of an e-commerce recommendation
    engine, you could track the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in conversion rate
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in **average order** **value** (**AOV**)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in customer engagement and loyalty
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in cross-sell and upsell opportunities
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictive maintenance in energy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Applying machine learning techniques to predict equipment failures
    and optimize maintenance in energy production facilities'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in unplanned downtime
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in energy production efficiency
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in maintenance costs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in safety and compliance metrics
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Workforce optimization in quick service restaurants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Utilizing machine learning algorithms to optimize staffing levels
    and scheduling in restaurants'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in staff utilization and productivity
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in overtime and agency costs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in patient satisfaction and care quality
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in employee satisfaction and retention
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbot-assisted customer support
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Use case**: Implementing a **large language model** (**LLM**)-powered chatbot
    to provide instant customer support and handle common inquiries'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics/KPIs**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in customer support costs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement in customer response times
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase in customer satisfaction
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deflection rate and human agent productivity
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Expansion of support coverage
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These additional examples further illustrate the wide range of data science,
    machine learning, and artificial intelligence applications across various industries
    and the specific business metrics and KPIs that can be used to measure their impact.
  prefs: []
  type: TYPE_NORMAL
- en: By aligning data-driven initiatives with key business objectives and tracking
    relevant metrics, organizations can demonstrate the tangible value and ROI of
    their data science/machine learning/artificial intelligence investments.
  prefs: []
  type: TYPE_NORMAL
- en: Think about the core business metrics and KPIs within your organization or industry.
    Which metrics and KPIs relate most closely to the bottom-line profit for the business?
  prefs: []
  type: TYPE_NORMAL
- en: Which of your use cases will have the greatest impact on those KPIs and the
    overall business performance?
  prefs: []
  type: TYPE_NORMAL
- en: By consistently monitoring and reporting on these business impact metrics, data
    science teams can demonstrate the value they bring to the organization and justify
    the investment in their projects. This not only helps secure continued support
    for ongoing initiatives but also paves the way for expanding the impact of successful
    solutions across the enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the essentials of structuring a data science project,
    focusing on developing impactful data products.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed three project categories, emphasizing the importance of selecting
    the right use cases that align with your organization’s goals and have the potential
    to deliver real value.
  prefs: []
  type: TYPE_NORMAL
- en: We provided a framework for evaluating and prioritizing use cases based on feasibility
    and impact, ensuring that you invest resources in projects that drive your business
    forward.
  prefs: []
  type: TYPE_NORMAL
- en: We also explored the key stages of data product development, from data preparation
    to model design, evaluation, and deployment, while adhering to best practices
    such as responsible AI principles, clear documentation, version control, and CI/CD
    practices.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed evaluating the business impact of your data product by
    selecting relevant metrics and KPIs that align with your company’s goals. By demonstrating
    the tangible value and ROI of your data science initiatives, you can secure ongoing
    support and expand the influence of your solutions across the organization.
  prefs: []
  type: TYPE_NORMAL
- en: You should now have a much better idea of how to structure and run a data science,
    machine learning, or artificial intelligence project.
  prefs: []
  type: TYPE_NORMAL
- en: However, nothing beats real-world experience. As you apply these concepts to
    your projects, you’ll encounter unique challenges and opportunities that will
    further refine your skills. Embrace these experiences, learn from successes and
    failures, and continuously adapt your approach.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll focus on building and managing a high-performing
    data science team while exploring key roles, skills, collaboration strategies,
    and best practices for fostering a culture of innovation and continuous learning.
  prefs: []
  type: TYPE_NORMAL
