<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer110">
<h1 class="chapter-num er" id="_idParaDest-134"><a id="_idTextAnchor228"/>7</h1>
<h1 id="_idParaDest-135"><a id="_idTextAnchor229"/>A Primer on Machine Learning and Deep Learning</h1>
<p><a id="_idTextAnchor230"/>Before applying any machine learning algorithm, having a comprehensive understanding of the dataset and its key features is essential. This understanding is typically derived through <strong class="old">exploratory data analysis</strong> (<strong class="old">EDA</strong>). Once acquainted with the data, we must invest time in feature engineering, which involves selecting, transforming, and creating new features (if necessary) to enable the use of the chosen model or enhance its performance. Feature engineering may include tasks such as converting classes into numerical values, scaling or normalizing features, creating new features from existing ones, and more. This process is tailored for each specific model and dataset under analysis. Once this process is completed, we can proceed <span class="No-Break">to modeling.</span></p>
<p>The goal of this chapter is to review introductory concepts of machine learning and deep learning, laying the foundation for <em class="italic">Part 2</em> of this book. In <em class="italic">Part 2</em>, we will delve into various use cases where artificial intelligence is applied to Web3 data. While not covering every possible model in detail, we will provide brief descriptions of project motivations, the models themselves, and the tools used, and include useful references for <span class="No-Break">further reading.</span></p>
<p>We will explore the main concepts of machine learning and deep learning, discussing two typical machine learning pipelines – one using scikit-learn and the other using Keras. Additionally, we have compiled an extensive <em class="italic">Further reading</em> section for each theme covered in this chapter to encourage <span class="No-Break">continued learning.</span></p>
<p>Specifically, the following topics will <span class="No-Break">be addressed:</span></p>
<ul>
<li>Basic concepts of machine learning and <span class="No-Break">deep learning</span></li>
<li>Machine learning pipeline with scikit-learn <span class="No-Break">and Keras</span></li>
</ul>
<h1 id="_idParaDest-136"><a id="_idTextAnchor231"/>Technical requirements</h1>
<p>We will <a id="_idTextAnchor232"/>be using <strong class="old">scikit-learn</strong>, a popular Python library specially designed for machine learning tasks. It offers algorithms and tools for data preprocessing, feature selection, model selection, and <span class="No-Break">model evaluation.</span></p>
<p>If you have not worked with scikit-learn before, it can be installed by using the following <span class="No-Break">code snippet:</span></p>
<pre class="console">
pip install scikit-learn</pre> <p>The documentation for scikit-learn can be found <span class="No-Break">at </span><span class="No-Break">https://scikit-learn.org/stable/</span><span class="No-Break">.</span></p>
<p>For deep learning, we have the option to use <strong class="old">TensorFlow</strong> or <strong class="old">Keras</strong>. TensorFlow is a powerful open source library for numerical computation that provides solutions to train, test, and deploy a variety of deep learning neural networks. It serves as the infrastructure layer, which enables low-level tensor operations on the CPU, TPU, and GPU. On the other hand, Keras is a high-level Python API built on top of TensorFlow. It is specially prepared to enable fast experimentation and provides informative feedback when an error is discovered. According to the 2022 survey <em class="italic">State of Data Science and Machine Learning</em>, by Kaggle, Keras reached a 61% adoption rate among machine learning developers and <span class="No-Break">data scientists.</span></p>
<p>If you have not worked with TensorFlow or Keras before, they can be installed with the following <span class="No-Break">code snippet:</span></p>
<pre class="console">
pip install tensorflow
pip install keras</pre> <p>For deep learning, a large amount of computational power is required; our normal CPU may not be fully prepared for the task, resulting in slow training and inference. The alternative is to run a GPU locally or in the cloud – hosted using Kaggle Kernel or Google Colab. They have a similar UI that resembles the structure of a Jupyter notebook, making it easy to run the code from the repository on any of <span class="No-Break">these platforms.</span></p>
<p>You can find all the data and code files for this chapter in this book’s GitHub repository at <a href="https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter07">https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter07</a>. We recommend that you read through the code files in the <strong class="source-inline">Chapter07</strong> folder to <span class="No-Break">follow along.</span></p>
<h1 id="_idParaDest-137"><a id="_idTextAnchor233"/>Introducing machine learning</h1>
<p>The definition<a id="_idIndexMarker392"/> of machine learning, as provided by Computer Science Wiki, is “<em class="italic">a field of inquiry devoted to understanding and building methods that “learn” – that is, methods that leverage data to improve performance on some set of tasks. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to </em><span class="No-Break"><em class="italic">do so</em></span><span class="No-Break">.”</span></p>
<p>(<span class="No-Break">Source: </span><a href="https://computersciencewiki.org/index.php/Machine_learning"><span class="No-Break">https://computersciencewiki.org/index.php/Machine_learning</span></a><span class="No-Break">)</span></p>
<p>Professor Jason Brownlee defines deep learning as “<em class="italic">a subfield of machine learning concerned with algorithms inspired by the structure and function of the brain called artificial neural networks</em>.” Deep learning is distinguishable from other machine learning methods because it uses artificial neural networks as a basis for <span class="No-Break">its methods.</span></p>
<p>The relationship between these two fields is generally represented <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer100">
<img alt="Figure 7.1 – Venn diagram of artificial intelligence" height="847" src="image/B19446_07_01.jpg" width="847"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Venn diagram of artificial intelligence</p>
<p>Let’s analyze the <a id="_idIndexMarker393"/>definition of machine <span class="No-Break">learning further:</span></p>
<ul>
<li>Machine learning models create their own rules based on the data we provide, as stated by the phrases “<em class="italic">understanding and building methods that learn</em>” and “<em class="italic">make predictions or decisions without being explicitly programmed to do so</em>.” Previously, we used filters in our queries or <em class="italic">if statements</em> in our programs. With machine learning, particularly supervised learning, we feed data and let the model infer the rules. In the book <em class="italic">Python Data Science Handbook</em>, the author challenges the idea that the model learns by itself, instead suggesting that it tunes the parameters we provide by adapting to the <a id="_idIndexMarker394"/>observed data. Once it fits those parameters to the seen data, it can infer results as needed from <span class="No-Break">unseen data.</span></li>
<li>“<em class="italic">Machine learning algorithms build a model based on sample data, known as training data</em>.” Data passed to machine learning algorithms needs to be split at least into two: training and test data. The training dataset is used to build the model. The test dataset is used to evaluate the model’s capacity to make predictions with data it has not seen before. The model’s predictions are then compared to the ground-truth data and the evaluation metrics <span class="No-Break">are calculated.</span></li>
</ul>
<p>Machine learning techniques<a id="_idIndexMarker395"/> can be classified as supervised learning, unsupervised learning, and reinforcement learning. Common tasks that are solved by machine learning techniques are shown in <span class="No-Break"><em class="italic">Figure 7</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer101">
<img alt="Figure 7.2 – Machine learning applications" height="944" src="image/B19446_07_02.jpg" width="1211"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Machine learning applications</p>
<p><strong class="old">Supervised learning</strong> consists <a id="_idIndexMarker396"/>of creating a function that can<a id="_idIndexMarker397"/> map inputs to outputs, allowing the<a id="_idIndexMarker398"/> model to infer outputs from unseen or similar inputs. In this process, we use features to describe the characteristics of a variable and labels or tags to identify the predicted variable. Through this, our model can learn the relationship between the features and the labels <span class="No-Break">or tags.</span></p>
<p>In Web3 analysis, <strong class="old">tagging</strong> plays a <a id="_idIndexMarker399"/>crucial role as it allows us to attribute an identity to addresses that are a combination of numbers and letters and have no direct connection to the outside world. However, creating a library of tagged addresses can be a challenging task and just recently, it has become the business of a company named Arkham that incentivizes the “<em class="italic">de-anonymizing of the blockchain</em>” with public data. Tagged <a id="_idIndexMarker400"/>addresses are one of the main leverages for companies such as Nansen, which have made significant progress in tagging hundreds of addresses on Ethereum and other chains, enabling machine learning techniques and data <span class="No-Break">analysis reports.</span></p>
<p>Tagging <a id="_idIndexMarker401"/>can <a id="_idIndexMarker402"/>also be found in Etherscan, where important projects tag their addresses to enable public audits. Also, Dune and Flipside have tables with labels where their research teams add relevant information that can help with queries. If you want to learn more about identity attribution, Nick Fourneaux, in the book <em class="italic">Investigating Cryptocurrencies</em>, teaches how to extract addresses from websites such as forums or software-sharing sites, download HTML as raw text, and execute a <span class="No-Break">regex analysis.</span></p>
<p>Supervised learning can be further divided into regression and classification techniques. In classification techniques, we have a discrete set of categories as labels (such as fraudulent transactions or non-fraudulent transactions). In regression, we have quantitative labels, such as the price of NFT art <span class="No-Break">or tokens.</span></p>
<p><strong class="old">Unsupervised learning</strong> consists <a id="_idIndexMarker403"/>of trying to<a id="_idIndexMarker404"/> identify the structure or patterns of a dataset that may not be explicit. The tasks that fall under unsupervised learning typically include <span class="No-Break">the following:</span></p>
<ul>
<li>Clustering – that is, identifying groups within a <span class="No-Break">given dataset</span></li>
<li>Dimensionality reduction – that is, attempting to represent the dataset with a smaller amount <span class="No-Break">of features</span></li>
<li>Novelty detection – that is, trying to identify when a change has occurred in <span class="No-Break">the data</span></li>
</ul>
<p><strong class="old">Reinforcement learning</strong> teaches <a id="_idIndexMarker405"/>a model to find <a id="_idIndexMarker406"/>the optimal solution for a problem by leveraging what the model already knows and what it can learn via a cumulative reward after interacting with its environment. The model receives feedback from the environment in the form of rewards or penalties, and its goal is to maximize its total reward. The idea behind reinforcement learning is to mimic the way humans learn by trial <span class="No-Break">and error:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer102">
<img alt="Figure 7.3 – Agent-environment loop (adapted from https://gymnasium.farama.org/content/basic_usage/)" height="802" src="image/B19446_07_03.jpg" width="1022"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Agent-environment loop (adapted from <a href="https://gymnasium.farama.org/content/basic_usage/">https://gymnasium.farama.org/content/basic_usage/</a>)</p>
<p>To make a project <a id="_idIndexMarker407"/>come to life, there are some initial business/data steps that must <span class="No-Break">be undertaken:</span></p>
<ul>
<li><em class="italic">Defining a Web3 data science problem</em> means stating what we want to solve with the data we have with precision. In such a definition, we have to be able to describe the problem we want to solve, why we want to solve it, and what assumptions <span class="No-Break">are considered.</span></li>
<li><em class="italic">Getting the data</em> means getting our hands on the dataset we will work with. It is possible that the dataset has already been built with all the rows and columns of interest, or that we have to build it by combining multiple sources of data. An initial list of data sources is listed in <em class="italic">Chapters 2</em> and <em class="italic">3</em>. More data sources may be needed, depending on the problem we <span class="No-Break">will tackle.</span></li>
<li><em class="italic">EDA</em> is used to make sense of the dataset using summary statistics and data visualization techniques. <em class="italic">Data preparation</em> is a preprocessing step where we transform the dataset to improve its quality or make it digestible to the model. On-chain data may need a lot of transformations. We analyzed some of those methods in <a href="B19446_06.xhtml#_idTextAnchor210"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><span class="No-Break">.</span></li>
</ul>
<p>Now, let’s analyze the steps to select, train, and evaluate <span class="No-Break">a model.</span></p>
<h1 id="_idParaDest-138"><a id="_idTextAnchor234"/>Building a machine learning pipeline</h1>
<p>After <a id="_idIndexMarker408"/>cleaning the data and selecting the most important features, the machine learning flow can be summarized into steps, as shown in <span class="No-Break"><em class="italic">Figure 7</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer103">
<img alt="Figure 7.4 – Machine learning pipeline" height="730" src="image/B19446_07_04.jpg" width="1085"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – Machine learning pipeline</p>
<p>To carry out this process, we must do <span class="No-Break">the following:</span></p>
<ol>
<li>Select a model and its initial parameters based on the problem and <span class="No-Break">available data.</span></li>
<li>Train: First, we must split the data into a training set and a test set. The process of training consists of making the model learn from the data. Each model’s training process can vary in time and computational consumption. To improve the model’s performance, we must employ hyperparameter tuning through techniques such as grid search or random <span class="No-Break">grid search.</span></li>
<li>Predict and evaluate: The trained model is then used to predict over the test set, which contains rows of data that have not been seen by the algorithm. If we evaluate the model with the data that we used to train it, the model will always predict well, and we will not be able to improve it. Model performance is assessed using task-specific <span class="No-Break">evaluation metrics.</span></li>
</ol>
<p>When we achieve<a id="_idIndexMarker409"/> a good model, we must save it so that we can use it when we receive unseen data. We can use tools such as <em class="italic">Pickle</em> and <em class="italic">Keras Tokenizer</em> to accomplish this. Pickle serializes the trained model and converts it into a file, allowing it to be used in another environment. To produce a result, we must pass data with the same structure that it is ready to receive so that the model can <span class="No-Break">make predictions.</span></p>
<p>Let’s apply this pipeline with a hands-on example. In <strong class="source-inline">Chapter07/ML_warmup</strong>, we aim to identify fraudulent transactions on the Ethereum network using a Kaggle dataset named <em class="italic">Ethereum Fraud Detection Dataset</em>, where only 17% of its rows are fraudulent. This is a typical supervised <span class="No-Break">classification task.</span></p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor235"/>Model</h2>
<p>Based <a id="_idIndexMarker410"/>on the problem at hand, we must select a model or a couple of models to test which one performs better on our data. If we are unsure about the model to select, we can examine similar structured problems solved on Kaggle. In the Jupyter notebook, we selected a random forest classifier with the following <span class="No-Break">code snippet:</span></p>
<pre class="console">
random_forest = RandomForestClassifier(random_state=42)</pre> <p>Many algorithms are available for training and the choice can be difficult. One way to choose among many models is to reduce the reducible error. Literature usually refers to this matter as the bias-variance trade-off. Before addressing that trade-off, we need to understand the different types of errors that exist. The prediction error for any machine learning algorithm can be classified <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="old">Noise</strong> or <strong class="old">irreducible error</strong>: This<a id="_idIndexMarker411"/> type of error cannot be deleted, no matter how well we implement <span class="No-Break">the model.</span></li>
<li><strong class="old">Bias error</strong>: This <a id="_idIndexMarker412"/>can be reduced. Wikipedia defines it as “<em class="italic">an error from erroneous assumptions in the learning algorithm</em>.” A model with high bias oversimplifies reality and leads to a high error between the prediction and the ground-truth value. High-bias models oversimplify, which means that they do not have enough parameters to capture the complexity <a id="_idIndexMarker413"/>of the data they learn from, resulting in underfitting. More on this concept will be covered in the <span class="No-Break">next section.</span></li>
<li><strong class="old">Variance error</strong>: This <a id="_idIndexMarker414"/>can also be reduced. Wikipedia defines it as an error derived from “<em class="italic">sensitivity to small fluctuations in the training set</em>.” This means that the model is learning the particularities of the training dataset so well that it will not generalize enough to predict on unseen data. These models are highly dependent on the exact training data and are unable to generalize. We encounter this error when the model performs well on training data but poorly on test/validation data, indicating  an <span class="No-Break">overfitting problem.</span></li>
</ul>
<p>Low variance<a id="_idIndexMarker415"/> with high bias algorithms train less complex models with a rather simple or rigid underlying structure – for example, linear regression. On the other hand, high variance with low bias algorithms train complex, flexible models that can be exact on training data but inconsistent in prediction – for <span class="No-Break">example, KNN.</span></p>
<p>If we understand bias and variance and recognize that both are derived from the choice of the model we make, to make an optimal decision we will have to choose the model that reduces the total error with a trade-off <span class="No-Break">between both:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer104">
<img alt="Figure 7.5 – The bias-variance trade-off" height="651" src="image/B19446_07_05.jpg" width="951"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.5 – The bias-variance trade-off</p>
<p>Another criterion for<a id="_idIndexMarker416"/> selecting a model is its performance, which is measured by the evaluation metric of choice. We can run multiple models and evaluate them all with the same metric, and the <a id="_idIndexMarker417"/>model that performs better is the one we continue tuning. We will discuss evaluation metrics in <span class="No-Break">subsequent sections.</span></p>
<p>In <strong class="source-inline">Chapter07/ML_warmup</strong>, we selected a random forest classifier. This algorithm looks to reduce the variance of the model without compromising bias and performs well in the evaluation metric known as recall. More about the random forest algorithm can be found in the <em class="italic">Further </em><span class="No-Break"><em class="italic">reading</em></span><span class="No-Break"> section.</span></p>
<h2 id="_idParaDest-140"><a id="_idTextAnchor236"/>Training</h2>
<p>To begin the<a id="_idIndexMarker418"/> training process, we split the data into a training dataset and a test dataset. This allows us to keep part of the data unseen by the model during training, and we can evaluate its <span class="No-Break">performance afterward:</span></p>
<pre class="console">
X_train, X_test, y_train, y_test = train_test_split(X, y,\
    test_size=0.33, random_state=42)</pre> <p>The training process consists of passing the features and labels to the algorithm so that it learns from them. The learning algorithm will try to find patterns in the training data that map the attributes of the input data to the target. The trained model captures <span class="No-Break">these patterns.</span></p>
<p>In <strong class="source-inline">Chapter07/ML_warmup</strong>, we instruct the model to learn with the following <span class="No-Break">code snippet:</span></p>
<pre class="console">
random_forest.fit(X_train, y_train)</pre> <h2 id="_idParaDest-141"><a id="_idTextAnchor237"/>Underfitting and overfitting</h2>
<p>Let’s consider<a id="_idIndexMarker419"/> three scenarios, where the model is represented<a id="_idIndexMarker420"/> by a black line. Which scenario performs <span class="No-Break">classification better?</span></p>
<div>
<div class="IMG---Figure" id="_idContainer105">
<img alt="Figure 7.6 – Three classification scenarios" height="382" src="image/B19446_07_06.jpg" width="1321"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.6 – Three classification scenarios</p>
<p>Let’s <a id="_idIndexMarker421"/>understand <span class="No-Break">the scenarios:</span></p>
<ul>
<li><strong class="old">Scenario A</strong>: The <a id="_idIndexMarker422"/>model is very simple and unable to capture the boundary between <a id="_idIndexMarker423"/>the two classes. This is <span class="No-Break">called </span><span class="No-Break"><strong class="old">underfitting</strong></span><span class="No-Break">.</span></li>
<li><strong class="old">Scenario B</strong>: The model was able to find an acceptable boundary between both classes, although it may misclassify some of the border samples. In general, it captures the complexity of <span class="No-Break">the dataset.</span></li>
<li><strong class="old">Scenario C</strong>: The model adapted too much to the training dataset and learned all the details, not just the relevant characteristics that differentiate one class from another. It was unable to generalize. This <a id="_idIndexMarker424"/>is <span class="No-Break">called </span><span class="No-Break"><strong class="old">overfitting</strong></span><span class="No-Break">.</span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer106">
<img alt="Figure 7.7 – What a model does when overfitting (source: https://twitter.com/MaartenvSmeden/status/1522230905468862464)" height="834" src="image/B19446_07_07.jpg" width="567"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.7 – What a model does when overfitting (source: https://twitter.com/MaartenvSmeden/status/1522230905468862464)</p>
<p>We aim<a id="_idIndexMarker425"/> for <a id="_idIndexMarker426"/>scenario B, where the model is complex enough to capture the important features but does not adapt too much to the training data so that it performs well on <span class="No-Break">unseen samples.</span></p>
<h2 id="_idParaDest-142"><a id="_idTextAnchor238"/>Prediction and evaluation</h2>
<p>Here, we<a id="_idIndexMarker427"/> pass unseen data to our trained model and <a id="_idIndexMarker428"/>evaluate how accurate its predictions are compared to the ground truth. If the result is acceptable, we keep the model; otherwise, we tune hyperparameters and train again. <em class="italic">A hyperparameter is a variable that is set before the training process and cannot be changed during learning. Parameters are those that are fine-tuned </em><span class="No-Break"><em class="italic">during training.</em></span></p>
<p>In the Jupyter notebook, we use the following code snippet to predict and evaluate <span class="No-Break">the model:</span></p>
<pre class="console">
y_test_pred = random_forest.predict(X_test)
print(classification_report(y_test_pred,y_test))
conf_mat=confusio<a id="_idTextAnchor239"/>n_matrix(y_test_pred,y_test)</pre> <p>To evaluate whether the result is acceptable and we can keep the model, we can use the confusion matrix for a binary classification task. The resulting confusion matrix for the dataset we analyzed in<a id="_idIndexMarker429"/> the <a id="_idIndexMarker430"/>Jupyter notebook is shown in <span class="No-Break"><em class="italic">Figure 7</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer107">
<img alt="Figure 7.8 – Confusion matrix" height="831" src="image/B19446_07_08.jpg" width="1255"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.8 – Confusion matrix</p>
<p>Let’s understand the components of the <span class="No-Break">confusion matrix:</span></p>
<ul>
<li><strong class="old">True negative</strong> (<strong class="old">TN</strong>): The model predicted negative, and it is true. These transactions are <span class="No-Break">not fraudulent.</span></li>
<li><strong class="old">True positive</strong> (<strong class="old">TP</strong>): The model predicted positive, and it is true. These transactions <span class="No-Break">are fraudulent.</span></li>
<li><strong class="old">False negative</strong> (<strong class="old">FN</strong>): The model failed to predict and they <span class="No-Break">were fraudulent.</span></li>
<li><strong class="old">False positive</strong> (<strong class="old">FP</strong>): The model flagged these transactions as fraudulent, but they <span class="No-Break">were not.</span></li>
</ul>
<p>Based on these numbers, we can calculate <a id="_idIndexMarker431"/>precision and recall. <strong class="old">Precision</strong> answers the question, of all the classes we predicted as positive, how many were <span class="No-Break">actually positive?</span></p>
<p class="IMG---Figure"><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>Our precision <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">0.91</strong></span><span class="No-Break">.</span></p>
<p><strong class="old">Recall</strong> answers <a id="_idIndexMarker432"/>the question, of all the fraudulent classes, how many did our model predict correctly? The formula for this is <span class="No-Break">as follows:</span></p>
<p class="IMG---Figure"><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>Our recall <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">0.98</strong></span><span class="No-Break">.</span></p>
<p>The <a id="_idIndexMarker433"/>evaluation of the results depends on the problem at hand. Selecting the metrics correctly is very important as it will impact the subsequent <a id="_idIndexMarker434"/>decisions we make. In <strong class="source-inline">Chapter07/ML_warmup</strong>, we are working to find fraudulent transactions, so we value models that result in higher recall than precision. We prefer recall because the cost of missing a fraudulent transaction is much higher than flagging a potentially harmless transaction. However, the number of FP flags cannot be enormous because of the cost of the transaction and its impact on <span class="No-Break">the client.</span></p>
<p>Real-world datasets are mostly imbalanced, which means that the classes are not equally represented. It is our job to apply techniques that enable the model to learn about the existence and characteristics of both classes, particularly when the less frequent class is the <a id="_idTextAnchor240"/>one that we are trying <span class="No-Break">to detect.</span></p>
<p class="callout-heading">A note on balanced and imbalanced datasets</p>
<p class="callout"><strong class="old">Accuracy</strong>, as the <a id="_idIndexMarker435"/>percentage of correct predictions, is another commonly used evaluation metric. However, it will not yield good results if the dataset is not balanced. If we <a id="_idIndexMarker436"/>take accuracy as an evaluation metric <a id="_idIndexMarker437"/>in an imbalanced dataset, the model only needs to identify the majority class to return a good result, and that does not guarantee that this is a <span class="No-Break">good model.</span></p>
<p class="callout">In our EDA, we will examine the proportion of each class and determine whether we are dealing with a balanced or imbalanced dataset. For example, in <strong class="source-inline">Chapter07/ML_warmup</strong>, we know that the proportion of fraudulent stances <span class="No-Break">is 17%.</span></p>
<p class="callout">We can solve this by using oversampling or undersampling techniques in the feature engineering preprocessing step. This must be done with caution as it may alter the underlying relationships in our data or remove some <span class="No-Break">critical information.</span></p>
<p class="callout">We can also use algorithms that have already been optimized for imbalanced datasets and allow the user to add that information to the training process – for example, by using the <strong class="source-inline">class_weight</strong> parameter in the random <span class="No-Break">forest algorithm.</span></p>
<p class="callout">Additionally, we can optimize the split by considering the unequal representation of the classes by<a id="_idTextAnchor241"/> using <strong class="source-inline">stratify</strong> <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">train_test_split</strong></span><span class="No-Break">.</span></p>
<h1 id="_idParaDest-143"><a id="_idTextAnchor242"/>Introducing deep learning</h1>
<p>In <em class="italic">Part 2</em> of this book, we <a id="_idIndexMarker438"/>will also use deep learning methodologies when solving the use cases. Deep learning models employ multiple layers of interconnected nodes called neurons, which process input data and produce outputs based on learned weights and activation functions. The connections between neurons facilitate information flow, and the architecture of the network determines how information is processed <span class="No-Break">and transformed.</span></p>
<p>We will study three types of neural network architectures in detail in their corresponding chapters. For now, let’s introduce the framework and terminology that we will use <span class="No-Break">in them.</span></p>
<p>The neuron serves as the fundamental building block of the system and can be defined as a node with one or more input values, weights, and <span class="No-Break">output values:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer108">
<img alt="Figure 7.9 – A neuron’s structure" height="612" src="image/B19446_07_09.jpg" width="1211"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.9 – A neuron’s structure</p>
<p>When we<a id="_idIndexMarker439"/> stack multiple layers with this structure, it becomes a neural network. This architecture typically consists of an input layer, hidden layers, and an <span class="No-Break">output layer:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer109">
<img alt="Figure 7.10 – Neural network structure" height="814" src="image/B19446_07_10.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.10 – Neural network structure</p>
<p>The input layer initiates the network and passes data to the hidden layers, which perform calculations on the features and patterns. The more hidden layers there are, the more complex calculations <span class="No-Break">are executed.</span></p>
<p>The output<a id="_idIndexMarker440"/> layer receives the processed information from the hidden layers and provides a result or output summarizing the information that’s been processed within <span class="No-Break">the network.</span></p>
<p>The connections between nodes contain weights that carry information on how to solve a specific problem. During model training, we calibrate these weights to adapt the model to our dataset. The weights represent the learnable parameters of <span class="No-Break">the model.</span></p>
<p>This flexible structure allows users to tune numerous hyperparameters to enhance the model’s performance. The fundamentals are <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="old">Learning rate</strong>: This<a id="_idIndexMarker441"/> hyperparameter controls how much a model changes in response to weight updates. Finding the correct value is crucial as a very small learning rate may result in a lengthy training process, while a higher one can lead to sub-optimal weight sets and altered results. The learning rate is closely related to <span class="No-Break">the optimizers.</span></li>
<li><strong class="old">Activation functions</strong>: These<a id="_idIndexMarker442"/> functions determine whether a neuron should be activated or not, meaning they decide whether the neuron’s input to the network is important for the prediction process using simple mathematical operations. The activation function derives output from a set of input values fed into each layer. A list of activation functions in Keras can be found <span class="No-Break">at </span><a href="https://keras.io/api/layers/activations/"><span class="No-Break">https://keras.io/api/layers/activations/</span></a><span class="No-Break">.</span></li>
<li><strong class="old">Cost functions</strong>: These<a id="_idIndexMarker443"/> functions quantify the error between the predicted and expected values, summarizing the model’s performance in a single value to be minimized during training. The choice of the cost function depends on the problem being solved, with common examples being mean squared error for regression tasks and categorical cross-entropy for classification tasks. Keras lists the various losses <span class="No-Break">at </span><a href="https://keras.io/api/losses/"><span class="No-Break">https://keras.io/api/losses/</span></a><span class="No-Break">.</span></li>
<li><strong class="old">Optimizers</strong>: These<a id="_idIndexMarker444"/> algorithms help improve model performance by adjusting the attributes of the neural network. Its responsibility in the architecture is to change the learning rate and weights of the neurons to reach the minimum of the loss function. The supported optimizers in Keras are listed <span class="No-Break">here: </span><a href="https://keras.io/api/optimizers/"><span class="No-Break">https://keras.io/api/optimizers/</span></a><span class="No-Break">.</span></li>
<li><strong class="old">Epochs</strong>: This<a id="_idIndexMarker445"/> denotes the number of times the algorithm runs through the <span class="No-Break">entire dataset.</span></li>
<li><strong class="old">Batch size</strong>: This <a id="_idIndexMarker446"/>refers to the number of samples considered to update the model parameters. A batch size of <em class="italic">N</em> means that <em class="italic">N</em> samples from the training dataset will be used to update the model parameters. Keep in mind that these samples are held in memory, so a higher batch size requires <span class="No-Break">more memory.</span></li>
</ul>
<p>All the models we use, will be analyzed within the Keras framewo<a id="_idTextAnchor243"/>rk, which has <span class="No-Break">excellent documentation.</span></p>
<h2 id="_idParaDest-144"><a id="_idTextAnchor244"/>Model preparation</h2>
<p>In <strong class="source-inline">Chapter07/DL_warmup</strong>, we will work with the same dataset as in the previous section – <em class="italic">Ethereum Fraud Detection Dataset</em>. This time, we will select fewer columns <a id="_idIndexMarker447"/>and standardize the numbers using <strong class="source-inline">RobustScaler()</strong> <span class="No-Break">from sklearn.</span></p>
<p>As in all prediction problems, we want to separate the test and training datasets with <strong class="source-inline">train test </strong><span class="No-Break"><strong class="source-inline">split ()</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-145"><a id="_idTextAnchor245"/>Model building</h2>
<p>We’ll <a id="_idIndexMarker448"/>create a sequential model with Keras. The structure of sequential models consists of a stack of the same or different layers, where the output of one layer goes into <span class="No-Break">the other.</span></p>
<p>The following code snippet sets the input layer to expect rows of data with the number of columns of the dataset. In this case, we are only working with <span class="No-Break">11 columns:</span></p>
<pre class="console">
model.add(Input(shape=(X_train.shape[1],)))</pre> <p>We add three hidden layers, each with a decreasing number of nodes. All of them use <strong class="source-inline">relu</strong> as the activation function. The <strong class="source-inline">Dense</strong> layer is a fully connected layer and is one of the many types of layers, such as <strong class="source-inline">Convolutional</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">LSTM</strong></span><span class="No-Break">:</span></p>
<pre class="console">
model.add(Dense(30, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(5, activation='relu'))
model.add(Dense(1, activation='sigmoid'))</pre> <p>Since this is a binary classification task, in the last layer, we will use the <strong class="source-inline">sigmoid</strong> activation function and <strong class="source-inline">1</strong> in the <span class="No-Break">output layer:</span></p>
<pre class="console">
model.add(Dense(1, activation='sigmoid'))</pre> <p>Before<a id="_idIndexMarker449"/> training the model, it needs to be compiled with the optimizer, the loss functions, and the metrics. The compiler configures the learning process. It’s worth mentioning that as this is an imbalanced dataset, we are interested in precision and recall, so we must build the metric by leveraging the <strong class="source-inline">keras</strong> library, <span class="No-Break">as follows:</span></p>
<pre class="console">
metrics = [
    keras.metrics.Precision(name="precision"),\
    keras.metrics.Recall(name="recall"),
]</pre> <p>Now, we must add it to <span class="No-Break">the compiler:</span></p>
<pre class="console">
model.compile(optimizer=keras.optimizers.Adam(1e-2), \
    loss=loss_function, metrics=metrics)</pre> <h2 id="_idParaDest-146"><a id="_idTextAnchor246"/>Training and evaluating a model</h2>
<p>Once<a id="_idIndexMarker450"/> the model has been built, we have to feed it our dataset, which means we have to train it. This is done with <strong class="source-inline">fit(),</strong> and in this case, we decided to do it for <span class="No-Break">90 epochs.</span></p>
<p>Once training <a id="_idIndexMarker451"/>has been performed, it is necessary to evaluate the model by predicting data that has not been part of the training. We can do this with <strong class="source-inline">X_test</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">y_test</strong></span><span class="No-Break">.</span></p>
<p>The classification report shows that recall for the minority class is 95%, which is very good. With more data preprocessing and by applying techniques for imbalanced datasets and hyperparameter tuning, we could further improve <span class="No-Break">the results.</span></p>
<p>In this particular <a id="_idIndexMarker452"/>exercise, one of the Zen of Python principles applies perfectly. <em class="italic">Simple is better than complex</em> – a simpler machine learning model performed <a id="_idIndexMarker453"/>better than a complex <span class="No-Break">neural network.</span></p>
<p>Now that we have explored <a id="_idIndexMarker454"/>both methodologies, we will highlight additional characteristics of <span class="No-Break">each field:</span></p>
<table class="T---Table _idGenTablePara-1" id="table001-7">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="T---Table">
<td class="T---Table T---Body T---Body">
<p><span class="No-Break"><strong class="old">Machine learning</strong></span></p>
</td>
<td class="T---Table T---Body T---Body">
<p><span class="No-Break"><strong class="old">Deep learning</strong></span></p>
</td>
</tr>
<tr class="T---Table">
<td class="T---Table T---Body T---Body">
<p>Can train and make inferences from <span class="No-Break">smaller datasets</span></p>
</td>
<td class="T---Table T---Body T---Body">
<p>Requires large amounts <span class="No-Break">of data</span></p>
</td>
</tr>
<tr class="T---Table">
<td class="T---Table T---Body T---Body">
<p>Shorter training and can be done with <span class="No-Break">a CPU</span></p>
</td>
<td class="T---Table T---Body T---Body">
<p>Longer training and needs a GPU to <span class="No-Break">train effectively</span></p>
</td>
</tr>
<tr class="T---Table">
<td class="T---Table T---Body T---Body">
<p>Makes <span class="No-Break">simple correlations</span></p>
</td>
<td class="T---Table T---Body T---Body">
<p>Makes non-linear <span class="No-Break">complex correlations</span></p>
</td>
</tr>
<tr class="T---Table">
<td class="T---Table T---Body T---Body">
<p><span class="No-Break">Mostly explainable</span></p>
</td>
<td class="T---Table T---Body T---Body">
<p>Opaque model, complex <span class="No-Break">to explain</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 7.1 – Differences between machine learning and deep learning</p>
<p class="callout-heading"><a id="_idTextAnchor247"/>A note on the ethical and social impact of artificial intelligence</p>
<p class="callout">Discussions regarding ethics and social impact may appear distant from our daily work, but given that our projects typically unfold within a business environment, it is advisable to consider their broader implications. The ethical and social ramifications of machine learning and deep learning encompass diverse dimensions, including <span class="No-Break">the following:</span></p>
<p class="callout"><strong class="old">Bias</strong>: Similar<a id="_idIndexMarker455"/> to the bias error, which oversimplifies its learning outcome, machine learning models can inherit biases present in training data, potentially leading to discriminatory outcomes. Bias can be introduced at various stages of the machine learning life cycle, from data collection to model deployment. It is important to obtain unbiased data to train our models and regularly audit them to detect and <span class="No-Break">rectify bias.</span></p>
<p class="callout"><strong class="old">Transparency</strong>: The <a id="_idIndexMarker456"/>opacity of complex machine learning models poses challenges for regulators and may undermine user trust. Many DeFi ventures are actively seeking regulatory approval to facilitate the flow of funds from traditional banking systems into the DeFi world. Given the highly regulated nature of the finance sector, data scientists working in this domain must make efforts to enhance model interpretability and provide explanations for their decisions to <span class="No-Break">regulatory authorities.</span></p>
<p class="callout">Addressing these ethical considerations necessitates a multidisciplinary approach that involves technology developers, policymakers, ethicists, and more. As professionals working with models, we need to keep these challenges in mind, especially when selecting datasets, preprocessing them, or evaluating their results in the <span class="No-Break">real world.</span></p>
<h1 id="_idParaDest-147"><a id="_idTextAnchor248"/>Summary</h1>
<p>In this chapter, we delved into the fundamental concepts of artificial intelligence, which will serve as the foundation for our journey in <em class="italic">Part 2</em> of this book. We explored various types of tasks, including supervised learning, unsupervised learning, and reinforcement learning. Through a hands-on example, we gained insights into the typical machine learning process, which encompasses model selection, training, <span class="No-Break">and evaluation.</span></p>
<p>Throughout this chapter, we acquired essential knowledge related to common challenges in machine learning, such as striking the right balance between underfitting and overfitting models, the existence of imbalanced datasets, and which metrics are relevant to evaluate models that are trained with them. Understanding these concepts is vital for any successful machine <span class="No-Break">learning project.</span></p>
<p>Moreover, we progressed into the basics of deep learning, where we explored the key components of a neural network using Keras. Additionally, we implemented a pipeline to tackle a supervised problem to see all the concepts <span class="No-Break">duly applied.</span></p>
<p>In the next chapter, we will discuss an important topic, <span class="No-Break">sentiment analysis.</span></p>
<h1 id="_idParaDest-148"><a id="_idTextAnchor249"/>Further reading</h1>
<p>To learn more about the topics that were covered in this chapter, take a look at the <span class="No-Break">following resources:</span></p>
<ul>
<li><span class="No-Break">Definitions:</span><ul><li>Igual, L. and Seguí, S. (2017). <em class="italic">Introduction to data science</em>:<em class="italic"> A python approach to concepts, techniques and </em><span class="No-Break"><em class="italic">applications</em></span><span class="No-Break">. Springer.</span></li><li>Ertel, W. (2018). <em class="italic">Introduction to artificial </em><span class="No-Break"><em class="italic">intelligence</em></span><span class="No-Break">. Springer.</span></li><li>Skansi, S. (2018). <em class="italic">Introduction to deep learning: From logical calculus to artificial </em><span class="No-Break"><em class="italic">intelligence</em></span><span class="No-Break">. Springer.</span></li><li>Ian Goodfellow, Yoshua Bengio, and Aaron Courville. (2016). <em class="italic">Deep Learning</em>. Available <span class="No-Break">at </span><a href="https://www.deeplearningbook.org/"><span class="No-Break">https://www.deeplearningbook.org/</span></a><span class="No-Break">.</span></li><li>Chollet, F. (2017). <em class="italic">Deep Learning with Python</em>. <span class="No-Break">Manning Publications.</span></li><li>Müller, A. C. and Guido, S. (2016). <em class="italic">Introduction to Machine Learning with Python: A guide for data scientists</em>. <span class="No-Break">O’Reilly Media.</span></li><li>VanderPlas, J. (n.d.). <em class="italic">What Is Machine Learning?</em> Pythonic Perambulations. Available <span class="No-Break">at </span><a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.01-what-is-machine-learning.xhtml"><span class="No-Break">https://jakevdp.github.io/PythonDataScienceHandbook/05.01-what-is-machine-learning.xhtml</span></a><span class="No-Break">.</span></li><li><em class="italic">What is Deep </em><span class="No-Break"><em class="italic">Learning?</em></span><span class="No-Break">: </span><a href="https://machinelearningmastery.com/what-is-deep-learning/"><span class="No-Break">https://machinelearningmastery.com/what-is-deep-learning/</span></a><span class="No-Break">.</span></li><li>Mining addresses from websites: Furneaux, Nick. <em class="italic">Investigating Cryptocurrencies, </em><a href="B19446_09.xhtml#_idTextAnchor269"><em class="italic">Chapter 9</em></a>. Understanding, Extracting, and Analyzing Blockchain Evidence, Wiley, 2018. <span class="No-Break">Page 125.</span></li><li>James, G., Witten, D., Hastie, T., and Tibshirani, R. (2022). <em class="italic">An Introduction to Statistical Learning: With Applications</em>. In <span class="No-Break">R. Springer.</span></li><li>Gymnasium <span class="No-Break">documentation: </span><a href="https://gymnasium.farama.org/"><span class="No-Break">https://gymnasium.farama.org/</span></a><span class="No-Break">.</span></li><li><em class="italic">Introduction – Spinning up documentation</em>. (n.d.). Welcome to Spinning Up in Deep RL! Spinning Up documentation. Available <span class="No-Break">at </span><a href="https://spinningup.openai.com/en/latest/user/introduction.xhtml#what-this-is"><span class="No-Break">https://spinningup.openai.com/en/latest/user/introduction.xhtml#what-this-is</span></a><span class="No-Break">.</span></li><li><em class="italic">Nansen Wallet Labels and Emojis: What Do They Mean?</em> (2023, March 14). Nansen – Crypto, DeFi and NFT Analytics. Available <span class="No-Break">at </span><a href="https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean#alpha-labels"><span class="No-Break">https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean#alpha-labels</span></a><span class="No-Break">.</span></li></ul></li>
<li><span class="No-Break">Pipelines:</span><ul><li>EliteDataScience. (2022, July 8). <em class="italic">WTF is the Bias-Variance Tradeoff?</em> (Infographic). Available <span class="No-Break">at </span><a href="https://elitedatascience.com/bias-variance-tradeoff"><span class="No-Break">https://elitedatascience.com/bias-variance-tradeoff</span></a><span class="No-Break">.</span></li><li><em class="italic">Sklearn.ensemble.RandomForestClassifier</em>. (n.d.). scikit-learn. Retrieved March 14, 2023, <span class="No-Break">from </span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.xhtml"><span class="No-Break">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.xhtml</span></a><span class="No-Break">.</span></li><li><em class="italic">SMOTE oversampling</em>. (n.d.). Machine Learning Mastery. Available <span class="No-Break">at </span><a href="https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"><span class="No-Break">https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/</span></a><span class="No-Break">.</span></li><li>Nyuytiymbiy, K. (2022, March 28). <em class="italic">Parameters and Hyperparameters in Machine Learning and Deep Learning</em>. Medium. Available <span class="No-Break">at </span><a href="https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac"><span class="No-Break">https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac</span></a><span class="No-Break">.</span></li><li>Heatmap on <strong class="source-inline">Chapter07/ML_warmup</strong>: T, D. (2019, July 25). <em class="italic">Confusion matrix visualization</em>. Medium. Available <span class="No-Break">at </span><a href="mailto:https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea"><span class="No-Break">https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea</span></a><span class="No-Break">.</span></li><li>Tutorial to use a Kaggle dataset on Colaboratory. Useful to follow along with <strong class="source-inline">Chapter07/ML_warmup</strong>: Gupta, K. (2022, August 24). <em class="italic">How to Load Kaggle Datasets into Google Colab?</em> Analytics Vidhya. Available <span class="No-Break">at </span><a href="https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"><span class="No-Break">https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/</span></a><span class="No-Break">.</span></li><li>Pramoditha, R. (2022, January 26). <em class="italic">How to Choose the Right Activation Function for Neural Networks</em>. Medium. Available <span class="No-Break">at </span><a href="https://towardsdatascience.com/how-to-choose-the-right-activation-function-for-neural-networks-3941ff0e6f9c"><span class="No-Break">https://towardsdatascience.com/how-to-choose-the-right-activation-function-for-neural-networks-3941ff0e6f9c</span></a><span class="No-Break">.</span></li><li>Gupta, A. (2022, May 24). <em class="italic">A Comprehensive Guide on Deep Learning Optimizers</em>. Analytics Vidhya. Available <span class="No-Break">at </span><a href="https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-on-deep-learning-optimizers/"><span class="No-Break">https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-on-deep-learning-optimizers/</span></a><span class="No-Break">.</span></li><li><em class="italic">PEP 20 – The Zen of Python</em>. (2022, March 15). PEP 0 – Index of Python Enhancement Proposals (PEPs) | peps.python.org. Available <span class="No-Break">at </span><a href="https://peps.python.org/pep-0020/"><span class="No-Break">https://peps.python.org/pep-0020/</span></a></li><li>Keras Team. (2020, April 17). <em class="italic">Keras documentation: Imbalanced classification: credit card fraud detection</em>. Keras: Deep Learning for Humans. Available <span class="No-Break">at </span><a href="https://keras.io/examples/structured_data/imbalanced_classification/"><span class="No-Break">https://keras.io/examples/structured_data/imbalanced_classification/</span></a><span class="No-Break">.</span></li><li>Ramchandani, P. (2021, April 10). <em class="italic">Random Forests and the Bias-Variance Tradeoff</em>. Medium. Available <span class="No-Break">at </span><a href="https://towardsdatascience.com/random-forests-and-the-bias-variance-tradeoff-3b77fee339b4"><span class="No-Break">https://towardsdatascience.com/random-forests-and-the-bias-variance-tradeoff-3b77fee339b4</span></a><span class="No-Break">.</span></li><li>Tuning with Bayesian optimization: Rendyk. (2023, August 17). <em class="italic">Tuning the Hyperparameters and layers of neural network deep learning</em>. Analytics Vidhya. Available <span class="No-Break">at </span><a href="https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/"><span class="No-Break">https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/</span></a><span class="No-Break">.</span></li><li><em class="italic">How to Grid Search Hyperparameters for Deep Learning Models in Python with Keras</em>. (2022, August). Machine Learning Mastery. Available <span class="No-Break">at </span><a href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"><span class="No-Break">https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/</span></a><span class="No-Break">.</span></li></ul></li>
</ul>
</div>
</div></body></html>