["```py\n    import pandas as pd\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com/PacktWorkshops'\\\n               '/The-Data-Science-Workshop/master/Chapter03'\\\n               '/bank-full.csv'\n    ```", "```py\n    # Loading the data using pandas\n    bankData = pd.read_csv(file_url, sep=\";\")\n    bankData.head()\n    pd.read_csv() function's arguments are the filename as a string and the limit separator of a CSV, which is \";\". After reading the file, the DataFrame is printed using the .head() function. Note that the # symbol in the code above denotes a comment. Comments are added into code to help explain specific bits of logic. \n    ```", "```py\n    # Printing the shape of the data \n    print(bankData.shape function is used to find the overall shape of the dataset.You should get the following output:\n\n    ```", "```py\n\n    ```", "```py\n    # Summarizing the statistics of the numerical raw data\n    bankData.describe()\n    ```", "```py\n    # Importing library files\n    import matplotlib.pyplot as plt\n    import numpy as np\n    ```", "```py\n    # Create a simple list of categories\n    jobList = ['admin','scientist','doctor','management']\n    ```", "```py\n    # Getting two categories ( 'yes','No') for each of jobs\n    jobYes = [20,60,70,40]\n    jobNo = [80,40,30,60]\n    ```", "```py\n    # Get the length of x axis labels and arranging its indexes\n    xlabels = len(jobList)\n    ind = np.arange(xlabels)\n    ```", "```py\n    # Get width of each bar\n    width = 0.35\n    # Getting the plots\n    p1 = plt.bar(ind, jobYes, width)\n    p2 = plt.bar(ind, jobNo, width, bottom=jobYes)\n    ```", "```py\n    # Getting the labels for the plots\n    plt.ylabel('Proportion of Jobs')\n    plt.title('Job')\n    ```", "```py\n    # Defining the x label indexes and y label indexes\n    plt.xticks(ind, jobList)\n    plt.yticks(np.arange(0, 100, 10))\n    ```", "```py\n    # Defining the legends\n    plt.legend((p1[0], p2[0]), ('Yes', 'No'))\n    # To rotate the axis labels \n    plt.xticks(rotation=90)\n    plt.show()\n    ```", "```py\n    import pandas as pd\n    import altair as alt\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/The-Data-Science-Workshop/'\\\n               'master/Chapter03/bank-full.csv'\n    bankData = pd.read_csv(file_url, sep=\";\")\n    ```", "```py\n    filter_mask = bankData['y'] == 'yes'\n    bankSub1 = bankData[filter_mask]\\\n               .groupby('age')['y'].agg(agegrp='count')\\\n               .reset_index()\n    ```", "```py\n    # Visualising the relationship using altair\n    alt.Chart(bankSub1).mark_line().encode(x='age', y='agegrp')\n    ```", "```py\n    # Getting another perspective\n    ageTot = bankData.groupby('age')['y']\\\n             .agg(ageTot='count').reset_index()\n    ageTot.head()\n    ```", "```py\n    # Getting all the details in one place\n    ageProp = bankData.groupby(['age','y'])['y']\\\n              .agg(ageCat='count').reset_index()\n    ageProp.head()\n    ```", "```py\n    # Merging both the data frames\n    ageComb = pd.merge(ageProp, ageTot,left_on = ['age'], \\\n                       right_on = ['age'])\n    ageComb['catProp'] = (ageComb.ageCat/ageComb.ageTot)*100\n    ageComb.head()\n    ```", "```py\n    # Visualising the relationship using altair\n    alt.Chart(ageComb).mark_line()\\\n       .encode(x='age', y='catProp').facet(column='y')\n    ```", "```py\n    import pandas as pd\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter03/bank-full.csv'\n    ```", "```py\n    # Reading the banking data\n    bankData = pd.read_csv(file_url, sep=\";\")\n    ```", "```py\n    # Relationship between housing and propensity for term deposits\n    bankData.groupby(['housing', 'y'])['y']\\\n            .agg(houseTot='count').reset_index()\n    ```", "```py\n    \"\"\"\n    Relationship between having a loan and propensity for term \n    deposits\n    \"\"\"\n    bankData.groupby(['loan', 'y'])['y']\\\n            .agg(loanTot='count').reset_index()\n    # symbol. \n    ```", "```py\n    #Taking the quantiles for 25%, 50% and 75% of the balance data\n    import numpy as np\n    np.quantile(bankData['balance'],[0.25,0.5,0.75])\n    ```", "```py\n    Step 4, we calculated the 25th, 50th, and 75th percentiles, which resulted in 72, 448, and 1428.\n    ```", "```py\n    bankData['balanceClass'] = 'Quant1'\n    bankData.loc[(bankData['balance'] > 72) \\\n                  & (bankData['balance'] < 448), \\\n                  'balanceClass'] = 'Quant2'\n    bankData.loc[(bankData['balance'] > 448) \\\n                  & (bankData['balance'] < 1428), \\\n                  'balanceClass'] = 'Quant3'\n    bankData.loc[bankData['balance'] > 1428, \\\n                 'balanceClass'] = 'Quant4'\n    bankData.head()\n    ```", "```py\n    # Calculating the customers under each quantile \n    balanceTot = bankData.groupby(['balanceClass'])['y']\\\n                         .agg(balanceTot='count').reset_index()\n    balanceTot\n    ```", "```py\n    \"\"\"\n    Calculating the total customers categorised as per quantile \n    and propensity classification\n    \"\"\"\n    balanceProp = bankData.groupby(['balanceClass', 'y'])['y']\\\n                          .agg(balanceCat='count').reset_index()\n    balanceProp\n    ```", "```py\n    # Merging both the data frames\n    balanceComb = pd.merge(balanceProp, balanceTot, \\\n                           on = ['balanceClass'])\n    balanceComb['catProp'] = (balanceComb.balanceCat \\\n                              / balanceComb.balanceTot)*100\n    balanceComb\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter03/bank-full.csv'\n    ```", "```py\n    # Reading the banking data\n    bankData = pd.read_csv(file_url,sep=\";\")\n    ```", "```py\n    # Normalizing data\n    from sklearn import preprocessing\n    x = bankData[['balance']].values.astype(float)\n    ```", "```py\n    minmaxScaler = preprocessing.MinMaxScaler()\n    ```", "```py\n    bankData['balanceTran'] = minmaxScaler.fit_transform(x)\n    ```", "```py\n    bankData.head()\n    ```", "```py\n    # Adding a small numerical constant to eliminate 0 values\n    bankData['balanceTran'] = bankData['balanceTran'] + 0.00001\n    ```", "```py\n    # Let us transform values for loan data\n    bankData['loanTran'] = 1\n    # Giving a weight of 5 if there is no loan\n    bankData.loc[bankData['loan'] == 'no', 'loanTran'] = 5\n    bankData.head()\n    ```", "```py\n    # Let us transform values for Housing data\n    bankData['houseTran'] = 5\n    ```", "```py\n    bankData.loc[bankData['housing'] == 'no', 'houseTran'] = 1\n    print(bankData.head())\n    ```", "```py\n    \"\"\" \n    Let us now create the new variable which is a product of all \n    these\n    \"\"\"\n    bankData['assetIndex'] = bankData['balanceTran'] \\\n                             * bankData['loanTran'] \\\n                             * bankData['houseTran']\n    bankData.head()\n    ```", "```py\n    # Finding the quantile\n    np.quantile(bankData['assetIndex'],[0.25,0.5,0.75])\n    ```", "```py\n    bankData['assetClass'] = 'Quant1'\n    bankData.loc[(bankData['assetIndex'] > 0.38) \\\n                  & (bankData['assetIndex'] < 0.57), \\\n                  'assetClass'] = 'Quant2'\n    bankData.loc[(bankData['assetIndex'] > 0.57) \\\n                  & (bankData['assetIndex'] < 1.9), \\\n                  'assetClass'] = 'Quant3'\n    bankData.loc[bankData['assetIndex'] > 1.9, \\\n                 'assetClass'] = 'Quant4'\n    bankData.head()\n    bankData.assetClass[bankData['assetIndex'] > 1.9] = 'Quant4'\n    bankData.head()\n    ```", "```py\n    # Calculating total of each asset class\n    assetTot = bankData.groupby('assetClass')['y']\\\n                       .agg(assetTot='count').reset_index()\n    # Calculating the category wise counts\n    assetProp = bankData.groupby(['assetClass', 'y'])['y']\\\n                        .agg(assetCat='count').reset_index()\n    ```", "```py\n    # Merging both the data frames\n    assetComb = pd.merge(assetProp, assetTot, on = ['assetClass'])\n    assetComb['catProp'] = (assetComb.assetCat \\\n                            / assetComb.assetTot)*100\n    assetComb\n    ```", "```py\n# Looking at Data types\nprint(bankData.dtypes)\n# Looking at descriptive statistics\nprint(bankData.describe())\n```", "```py\n    import pandas as pd\n    file_url = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter03/bank-full.csv'\n    bankData = pd.read_csv(file_url, sep=\";\")\n    ```", "```py\n    from pandas import set_option\n    ```", "```py\n    bankNumeric = bankData[['age','balance','day','duration',\\\n                            'campaign','pdays','previous']]\n    ```", "```py\n    set_option('display.width',150)\n    set_option('precision',3)\n    bankCorr = bankNumeric.corr(method = 'pearson')\n    bankCorr\n    ```", "```py\n    from matplotlib import pyplot\n    corFig = pyplot.figure()\n    figAxis = corFig.add_subplot(111)\n    corAx = figAxis.matshow(bankCorr,vmin=-1,vmax=1)\n    corFig.colorbar(corAx)\n    pyplot.show()\n    ```", "```py\n# Skewness of numeric attributes\nbankNumeric.skew()\n```", "```py\n# Histograms\nfrom matplotlib import pyplot as plt\nfig, axs = plt.subplots(1,2)\naxs[0].hist(bankNumeric['age'])\naxs[0].set_title('Distribution of age')\naxs[1].hist(bankNumeric['balance'])\naxs[1].set_title('Distribution of Balance')\n# Ensure plots do not overlap\nplt.tight_layout()\n```", "```py\nfrom matplotlib import pyplot as plt\n# Density plots\nbankNumeric['age'].plot(kind = 'density', subplots = False, \\\n                        layout = (1,1))\nplt.title('Age Distribution')\nplt.xlabel('Age')\nplt.ylabel('Normalised age distribution')\npyplot.show()\n```", "```py\n# Standardize data (0 mean, 1 stdev)\nfrom sklearn.preprocessing import StandardScaler\nfrom numpy import set_printoptions\nscaling = StandardScaler().fit(bankNumeric)\nrescaledNum = scaling.transform(bankNumeric)\nset_printoptions(precision = 3)\nprint(rescaledNum)\n```", "```py\n# Normalizing Data (Length of 1)\nfrom sklearn.preprocessing import Normalizer\nnormaliser = Normalizer().fit(bankNumeric)\nnormalisedNum = normaliser.transform(bankNumeric)\nset_printoptions(precision = 3)\nprint(normalisedNum)\n```", "```py\n    import pandas as pd\n    import altair as alt\n    file_url = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter03/bank-full.csv'\n    bankData = pd.read_csv(file_url, sep=\";\")\n    ```", "```py\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n    bankData.dtypes\n    ```", "```py\n    \"\"\"\n    Converting all the categorical variables to dummy variables\n    \"\"\"\n    bankCat = pd.get_dummies\\\n              (bankData[['job','marital',\\\n                         'education','default','housing',\\\n                         'loan','contact','month','poutcome']])\n    bankCat.shape\n    ```", "```py\n    (45211, 44)\n    ```", "```py\n    bankNum = bankData[['age','balance','day','duration',\\\n                        'campaign','pdays','previous']]\n    bankNum.shape\n    ```", "```py\n    (45211, 7)\n    ```", "```py\n    # Preparing the X variables\n    X = pd.concat([bankCat, bankNum], axis=1)\n    print(X.shape)\n    # Preparing the Y variable\n    Y = bankData['y']\n    print(Y.shape)\n    X.head()\n    ```", "```py\n    # Splitting the data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (X, Y, test_size=0.3, \\\n                                        random_state=123)\n    ```", "```py\n    bankModel = LogisticRegression()\n    bankModel.fit(X_train, y_train)\n    ```", "```py\n    pred = bankModel.predict(X_test)\n    print('Accuracy of Logistic regression model' \\\n          'prediction on test set: {:.2f}'\\\n          .format(bankModel.score(X_test, y_test)))\n    ```", "```py\n    # Confusion Matrix for the model\n    from sklearn.metrics import confusion_matrix\n    confusionMatrix = confusion_matrix(y_test, pred)\n    print(confusionMatrix)\n    ```", "```py\n    from sklearn.metrics import classification_report\n    print(classification_report(y_test, pred))\n    ```"]