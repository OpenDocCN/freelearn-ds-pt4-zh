["```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n    # data doesn't have headers, so let's create headers\n    _headers = ['buying', 'maint', 'doors', 'persons', \\\n                'lug_boot', 'safety', 'car']\n    ```", "```py\n    df = pd.read_csv('https://raw.githubusercontent.com/'\\\n                     'PacktWorkshops/The-Data-Science-Workshop/'\\\n                     'master/Chapter06/Dataset/car.data', \\\n                     names=_headers, index_col=None)\n    ```", "```py\n    df.head()\n    ```", "```py\n    training, evaluation = train_test_split(df, test_size=0.3, \\\n                                            random_state=0)\n    ```", "```py\n    validation, test = train_test_split(evaluation, test_size=0.5, \\\n                                        random_state=0)\n    ```", "```py\ntemperature = 23\n```", "```py\ntemp_1 = 23\ntemp_2 = 24\ntemp_3 = 23\ntemp_4 = 22\ntemp_5 = 22\n```", "```py\ntemps_list = [23, 24, 23, 22, 22]\n```", "```py\nimport numpy as np\ntemps_ndarray = np.array(temps_list)\n```", "```py\nprint(type(temps_ndarray))\n```", "```py\nprint(temps_ndarray)\n```", "```py\nprint(temps_list)\n```", "```py\nprint(temps_ndarray.shape)\n```", "```py\ntemps_matrix = temps_ndarray.reshape(-1, 1)\n```", "```py\nprint(temps_matrix.shape)\n```", "```py\nprint(temps_matrix)\n```", "```py\nprint(temps_matrix.reshape(1,5))\n```", "```py\nvector = temps_matrix.reshape(-1)\n```", "```py\n    # import libraries\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LinearRegression\n    ```", "```py\n    # column headers\n    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', \\\n                'MLOGP', 'response']\n    # read in data\n    df = pd.read_csv('https://raw.githubusercontent.com/'\\\n                     'PacktWorkshops/The-Data-Science-Workshop/'\\\n                     'master/Chapter06/Dataset/'\\\n                     'qsar_fish_toxicity.csv', \\\n                     names=_headers, sep=';')\n    ```", "```py\n    # Let's split our data\n    features = df.drop('response', axis=1).values\n    labels = df[['response']].values\n    X_train, X_eval, y_train, y_eval = train_test_split\\\n                                       (features, labels, \\\n                                        test_size=0.2, \\\n                                        random_state=0)\n    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval,\\\n                                                    random_state=0)\n    ```", "```py\n    model = LinearRegression()\n    ```", "```py\n    model.fit(X_train, y_train)\n    ```", "```py\n    y_pred = model.predict(X_val)\n    ```", "```py\n    r2 = model.score(X_val, y_val)\n    print('R^2 score: {}'.format(r2))\n    ```", "```py\n    _ys = pd.DataFrame(dict(actuals=y_val.reshape(-1), \\\n                            predicted=y_pred.reshape(-1)))\n    _ys.head()\n    ```", "```py\n    # Import libraries\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LinearRegression\n    from sklearn.metrics import mean_absolute_error\n    ```", "```py\n    # column headers\n    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', \\\n                'MLOGP', 'response']\n    # read in data\n    df = pd.read_csv('https://raw.githubusercontent.com/'\\\n                     'PacktWorkshops/The-Data-Science-Workshop/'\\\n                     'master/Chapter06/Dataset/'\\\n                     'qsar_fish_toxicity.csv', \\\n                     names=_headers, sep=';')\n    ```", "```py\n    # Let's split our data\n    features = df.drop('response', axis=1).values\n    labels = df[['response']].values\n    X_train, X_eval, y_train, y_eval = train_test_split\\\n                                       (features, labels, \\\n                                        test_size=0.2, \\\n                                        random_state=0)\n    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval,\\\n                                                    random_state=0)\n    ```", "```py\n    # create a simple Linear Regression model\n    model = LinearRegression()\n    # train the model\n    model.fit(X_train, y_train)\n    ```", "```py\n    # let's use our model to predict on our validation dataset\n    y_pred = model.predict(X_val)\n    ```", "```py\n    # Let's compute our MEAN ABSOLUTE ERROR\n    mae = mean_absolute_error(y_val, y_pred)\n    print('MAE: {}'.format(mae))\n    ```", "```py\n    # Let's get the R2 score\n    r2 = model.score(X_val, y_val)\n    print('R^2 score: {}'.format(r2))\n    ```", "```py\n    # Import libraries\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LinearRegression\n    from sklearn.metrics import mean_absolute_error\n    # pipeline\n    from sklearn.pipeline import Pipeline\n    # preprocessing\n    from sklearn.preprocessing import MinMaxScaler\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.preprocessing import PolynomialFeatures\n    ```", "```py\n    # column headers\n    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', \\\n                'MLOGP', 'response']\n    # read in data\n    df = pd.read_csv('https://raw.githubusercontent.com/'\\\n                     'PacktWorkshops/The-Data-Science-Workshop/'\\\n                     'master/Chapter06/Dataset/'\\\n                     'qsar_fish_toxicity.csv', \\\n                     names=_headers, sep=';')\n    ```", "```py\n    # Let's split our data\n    features = df.drop('response', axis=1).values\n    labels = df[['response']].values\n    X_train, X_eval, y_train, y_eval = train_test_split\\\n                                       (features, labels, \\\n                                        test_size=0.2, \\\n                                        random_state=0)\n    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval,\\\n                                                    random_state=0)\n    ```", "```py\n    # create a pipeline and engineer quadratic features\n    steps = [('scaler', MinMaxScaler()),\\\n             ('poly', PolynomialFeatures(2)),\\\n             ('model', LinearRegression())]\n    ```", "```py\n    # create a simple Linear Regression model with a pipeline\n    model = Pipeline(steps)\n    ```", "```py\n    # train the model\n    model.fit(X_train, y_train)\n    ```", "```py\n    # let's use our model to predict on our validation dataset\n    y_pred = model.predict(X_val)\n    ```", "```py\n    # Let's compute our MEAN ABSOLUTE ERROR\n    mae = mean_absolute_error(y_val, y_pred)\n    print('MAE: {}'.format(mae))\n    ```", "```py\n    # Let's get the R2 score\n    r2 = model.score(X_val, y_val)\n    print('R^2 score: {}'.format(r2))\n    ```", "```py\n    # import libraries\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LogisticRegression\n    ```", "```py\n    # data doesn't have headers, so let's create headers\n    _headers = ['buying', 'maint', 'doors', 'persons', \\\n                'lug_boot', 'safety', 'car']\n    # read in cars dataset\n    df = pd.read_csv('https://raw.githubusercontent.com/'\\\n                     'PacktWorkshops/The-Data-Science-Workshop/'\\\n                     'master/Chapter06/Dataset/car.data', \\\n                     names=_headers, index_col=None)\n    df.head()\n    ```", "```py\n    # encode categorical variables\n    _df = pd.get_dummies(df, columns=['buying', 'maint', 'doors',\\\n                                      'persons', 'lug_boot', \\\n                                      'safety'])\n    _df.head()\n    ```", "```py\n    # split data into training and evaluation datasets\n    features = _df.drop('car', axis=1).values\n    labels = _df['car'].values\n    X_train, X_eval, y_train, y_eval = train_test_split\\\n                                       (features, labels, \\\n                                        test_size=0.3, \\\n                                        random_state=0)\n    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval,\\\n                                                    test_size=0.5, \\\n                                                    random_state=0)\n    ```", "```py\n    # train a Logistic Regression model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    ```", "```py\n    # make predictions for the validation set\n    y_pred = model.predict(X_val)\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    ```", "```py\n    confusion_matrix(y_val, y_pred)\n    ```", "```py\n    from sklearn.metrics import precision_score\n    ```", "```py\n    precision_score(y_val, y_pred, average='macro')\n    ```", "```py\n    from sklearn.metrics import recall_score\n    ```", "```py\n    recall_score(y_val, y_pred, average='macro')\n    ```", "```py\n    from sklearn.metrics import f1_score\n    ```", "```py\n    f1_score(y_val, y_pred, average='macro')\n    ```", "```py\n    from sklearn.metrics import accuracy_score\n    ```", "```py\n    _accuracy = accuracy_score(y_val, y_pred)\n    print(_accuracy)\n    ```", "```py\n    from sklearn.metrics import log_loss\n    ```", "```py\n    _loss = log_loss(y_val, model.predict_proba(X_val))\n    print(_loss)\n    ```", "```py\n    # import libraries\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import roc_curve\n    from sklearn.metrics import auc\n    ```", "```py\n    # data doesn't have headers, so let's create headers\n    _headers = ['Age', 'Delivery_Nbr', 'Delivery_Time', \\\n                'Blood_Pressure', 'Heart_Problem', 'Caesarian']\n    # read in cars dataset\n    df = pd.read_csv('https://raw.githubusercontent.com/'\\\n                     'PacktWorkshops/The-Data-Science-Workshop/'\\\n                     'master/Chapter06/Dataset/caesarian.csv.arff',\\\n                     names=_headers, index_col=None, skiprows=15)\n    df.head()\n    # target column is 'Caesarian'\n    ```", "```py\n    # target column is 'Caesarian'\n    features = df.drop(['Caesarian'], axis=1).values\n    labels = df[['Caesarian']].values\n    # split 80% for training and 20% into an evaluation set\n    X_train, X_eval, y_train, y_eval = train_test_split\\\n                                       (features, labels, \\\n                                        test_size=0.2, \\\n                                        random_state=0)\n    \"\"\"\n    further split the evaluation set into validation and test sets \n    of 10% each\n    \"\"\"\n    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval,\\\n                                                    test_size=0.5, \\\n                                                    random_state=0)\n    ```", "```py\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    ```", "```py\n    y_proba = model.predict_proba(X_val)\n    ```", "```py\n    _false_positive, _true_positive, _thresholds = roc_curve\\\n                                                   (y_val, \\\n                                                    y_proba[:, 0])\n    ```", "```py\n    print(_false_positive)\n    ```", "```py\n    print(_true_positive)\n    ```", "```py\n    print(_thresholds)\n    ```", "```py\n    # Plot the RoC\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    plt.plot(_false_positive, _true_positive, lw=2, \\\n             label='Receiver Operating Characteristic')\n    plt.xlim(0.0, 1.2)\n    plt.ylim(0.0, 1.2)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.show()\n    ```", "```py\n    y_proba = model.predict_proba(X_val)\n    ```", "```py\n    from sklearn.metrics import roc_auc_score\n    _auc = roc_auc_score(y_val, y_proba[:, 0])\n    print(_auc)\n    ```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LinearRegression\n    ```", "```py\n    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', \\\n                'MLOGP', 'response']\n    # read in data\n    df = pd.read_csv('https://raw.githubusercontent.com/'\\\n                     'PacktWorkshops/The-Data-Science-Workshop/'\\\n                     'master/Chapter06/Dataset/'\\\n                     'qsar_fish_toxicity.csv', \\\n                     names=_headers, sep=';')\n    ```", "```py\n    df.head()\n    ```", "```py\n    features = df.drop('response', axis=1).values\n    labels = df[['response']].values\n    X_train, X_eval, y_train, y_eval = train_test_split\\\n                                       (features, labels, \\\n                                        test_size=0.2, \\\n                                        random_state=0)\n    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval,\\\n                                                    random_state=0)\n    ```", "```py\n    model = LinearRegression()\n    print(model)\n    ```", "```py\n    model.fit(X_train, y_train)\n    ```", "```py\n    y_pred = model.predict(X_val)\n    ```", "```py\n    from sklearn.externals import joblib\n    ```", "```py\n    joblib.dump(model, './model.joblib')\n    ```", "```py\n    m2 = joblib.load('./model.joblib')\n    ```", "```py\n    m2_preds = m2.predict(X_val)\n    ```", "```py\n    ys = pd.DataFrame(dict(predicted=y_pred.reshape(-1), \\\n                           m2=m2_preds.reshape(-1)))\n    ys.head()\n    ```", "```py\n    dt_model = DecisionTreeClassifier(max_depth= 6)\n    ```", "```py\n    dt_model.fit(train_X, train_y)\n    ```", "```py\n    dt_preds = dt_model.predict(val_X)\n    ```", "```py\n    dt_report = classification_report(val_y, dt_preds)\n    print(dt_report)\n    ```"]