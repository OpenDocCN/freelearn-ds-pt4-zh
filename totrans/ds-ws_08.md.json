["```py\nfrom sklearn import neighbors\n# initialize with default hyperparameters\nknn = neighbors.KNeighborsClassifier()\n# examine the defaults\nprint(knn.get_params())\n```", "```py\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, \n 'p': 2, 'weights': 'uniform'}\n```", "```py\n?knn\n```", "```py\n\"\"\"\ninitialize with k = 15 and all other hyperparameters as default\n\"\"\"\nknn = neighbors.KNeighborsClassifier(n_neighbors=15)\n# examine\nprint(knn.get_params())\n```", "```py\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 15, \n 'p': 2, 'weights': 'uniform'}\n```", "```py\n\"\"\"\ninitialize with k = 15, weights = distance and all other \nhyperparameters as default \n\"\"\"\nknn = neighbors.KNeighborsClassifier(n_neighbors=15, \\\n                                     weights='distance')\n# examine\nprint(knn.get_params())\n```", "```py\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 15, \n 'p': 2, 'weights': 'distance'}\n```", "```py\n    from sklearn import neighbors, datasets, model_selection\n    ```", "```py\n    # dataset\n    cancer = datasets.load_breast_cancer()\n    # target\n    y = cancer.target\n    # features\n    X = cancer.data\n    ```", "```py\n    # no arguments specified\n    knn = neighbors.KNeighborsClassifier()\n    ```", "```py\n    # 10 folds, scored on precision\n    cv = model_selection.cross_val_score(knn, X, y, cv=10,\\\n                                         scoring='precision')\n    ```", "```py\n    # precision scores\n    print(cv)\n    ```", "```py\n    [0.91666667 0.85       0.91666667 0.94736842 0.94594595 \n     0.94444444 0.97222222 0.92105263 0.96969697 0.97142857]\n    ```", "```py\n    # average over all folds\n    print(round(cv.mean(), 2))\n    ```", "```py\n    0.94\n    ```", "```py\n    # k = 15\n    knn = neighbors.KNeighborsClassifier(n_neighbors=15)\n    cv = model_selection.cross_val_score(knn, X, y, cv=10, \\\n                                         scoring='precision')\n    print(round(cv.mean(), 2))\n    ```", "```py\n    0.93\n    ```", "```py\n    def evaluate_knn(k):\n        knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n        cv = model_selection.cross_val_score(knn, X, y, cv=10, \\\n                                             scoring='precision')\n        print(round(cv.mean(), 2))\n    evaluate_knn(k=7)\n    evaluate_knn(k=3)\n    evaluate_knn(k=1)\n    ```", "```py\n    0.93\n    0.93\n    0.92\n    ```", "```py\n    # k =5, weights evaluated using distance\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5, \\\n                                         weights='distance')\n    cv = model_selection.cross_val_score(knn, X, y, cv=10, \\\n                                         scoring='precision')\n    print(round(cv.mean(), 2))\n    ```", "```py\n    0.93\n    ```", "```py\nfrom sklearn import neighbors, datasets, model_selection\n# load data\ncancer = datasets.load_breast_cancer()\n# target\ny = cancer.target\n# features\nX = cancer.data\n# hyperparameter grid\ngrid = {'k': [1, 3, 5, 7]}\n```", "```py\n# for every value of k in the grid\nfor k in grid['k']:\n    # initialize the knn estimator\n    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n    # conduct a 10-fold cross-validation\n    cv = model_selection.cross_val_score(knn, X, y, cv=10, \\\n                                         scoring='precision')\n    # calculate the average precision value over all folds\n    cv_mean = round(cv.mean(), 3)\n    # report the result\n    print('With k = {}, mean precision = {}'.format(k, cv_mean))\n```", "```py\n# for every value of k in the grid \nfor k in grid['k']:\n    # initialize the knn estimator\n    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n    # print the hyperparameterization\n    print(knn.get_params())\n```", "```py\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 1, \n 'p': 2, 'weights': 'uniform'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski',\n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, \n 'p': 2, 'weights': 'uniform'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, \n 'p': 2, 'weights': 'uniform'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, \n 'p': 2, 'weights': 'uniform'}\n```", "```py\n# hyperparameter grid\ngrid = {'k': [1, 3, 5, 7],\\\n        'weight_function': ['uniform', 'distance']}\n# for every value of k in the grid\nfor k in grid['k']:\n    # and every possible weight_function in the grid \n    for weight_function in grid['weight_function']:\n        # initialize the knn estimator\n        knn = neighbors.KNeighborsClassifier\\\n              (n_neighbors=k, \\\n               weights=weight_function)\n        # conduct a 10-fold cross-validation\n        cv = model_selection.cross_val_score(knn, X, y, cv=10, \\\n                                             scoring='precision')\n        # calculate the average precision value over all folds\n        cv_mean = round(cv.mean(), 3)\n        # report the result\n        print('With k = {} and weight function = {}, '\\\n              'mean precision = {}'\\\n              .format(k, weight_function, cv_mean))\n```", "```py\n# for every value of k in the grid\nfor k in grid['k']:\n    # and every possible weight_function in the grid \n    for weight_function in grid['weight_function']:\n        # initialize the knn estimator\n        knn = neighbors.KNeighborsClassifier\\\n              (n_neighbors=k, \\\n               weights=weight_function)\n        # print the hyperparameterizations\n        print(knn.get_params())\n```", "```py\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 1, \n 'p': 2, 'weights': 'uniform'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 1, \n 'p': 2, 'weights': 'distance'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, \n 'p': 2, 'weights': 'uniform'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, \n 'p': 2, 'weights': 'distance'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, \n 'p': 2, 'weights': 'uniform'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, \n 'p': 2, 'weights': 'distance'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, \n 'p': 2, 'weights': 'uniform'}\n{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', \n 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, \n 'p': 2, 'weights': 'distance'}\n```", "```py\nfrom sklearn import model_selection, datasets, neighbors\n# load the data\ncancer = datasets.load_breast_cancer()\n# target\ny = cancer.target\n# features\nX = cancer.data\n```", "```py\n# initialize the estimator\nknn = neighbors.KNeighborsClassifier()\n```", "```py\n# grid contains k and the weight function\ngrid = {'n_neighbors': [1, 3, 5, 7],\\\n        'weights': ['uniform', 'distance']}\n```", "```py\n\"\"\"\n set up the grid search with scoring on precision and \nnumber of folds = 10\n\"\"\"\ngscv = model_selection.GridSearchCV(estimator=knn, \\\n                                    param_grid=grid, \\\n                                    scoring='precision', cv=10)\n```", "```py\n# start the search\ngscv.fit(X, y)\n```", "```py\n# view the results\nprint(gscv.cv_results_)\n```", "```py\nimport pandas as pd\n# convert the results dictionary to a dataframe\nresults = pd.DataFrame(gscv.cv_results_)\n\"\"\"\nselect just the hyperparameterizations tried, \nthe mean test scores, order by score and show the top 5 models\n\"\"\"\nprint(results.loc[:,['params','mean_test_score']]\\\n      .sort_values('mean_test_score', ascending=False).head(5))\n```", "```py\n# visualise the result\nresults.loc[:,['params','mean_test_score']]\\\n       .plot.barh(x = 'params')\n```", "```py\n    from sklearn import datasets, svm, model_selection\n    ```", "```py\n    # load data\n    digits = datasets.load_digits()\n    # target\n    y = digits.target\n    # features\n    X = digits.data\n    ```", "```py\n    # support vector machine classifier\n    clr = svm.SVC(gamma='scale')\n    ```", "```py\n    # hyperparameter grid. contains linear and polynomial kernels\n    grid = [{'kernel': ['linear']},\\\n            {'kernel': ['poly'], 'degree': [2, 3, 4]}]\n    ```", "```py\n    \"\"\"\n    setting up the grid search to score on accuracy and \n    evaluate over 10 folds\n    \"\"\"\n    cv_spec = model_selection.GridSearchCV\\\n              (estimator=clr, param_grid=grid, \\\n               scoring='accuracy', cv=10)\n    ```", "```py\n    # start the grid search\n    cv_spec.fit(X, y)\n    ```", "```py\n    # what is the available information\n    print(cv_spec.cv_results_.keys())\n    ```", "```py\n    import pandas as pd\n    # convert the dictionary of results to a pandas dataframe\n    results = pd.DataFrame(cv_spec.cv_results_)\n    # show hyperparameterizations\n    print(results.loc[:,['params','mean_test_score']]\\\n          .sort_values('mean_test_score', ascending=False))\n    ```", "```py\n    # visualize the result\n    (results.loc[:,['params','mean_test_score']]\\\n            .sort_values('mean_test_score', ascending=True)\\\n            .plot.barh(x='params', xlim=(0.8)))\n    ```", "```py\n# list of all xs\nX = list(range(1, 11))\nprint(X)\n```", "```py\n [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n```", "```py\n# pmf, 1/n * n = 1\np_X_x = [1/len(X)] * len(X)\n# sums to 1\nprint(p_X_x)\n```", "```py\nimport matplotlib.pyplot as plt\nplt.bar(X, p_X_x)\nplt.xlabel('X')\nplt.ylabel('P(X=x)')\n```", "```py\nimport numpy as np\n# range of xs\nx = np.linspace(-10, 10, 100)\n```", "```py\nimport scipy.stats as stats\n# first normal distribution with mean = 0, variance = 1\np_X_1 = stats.norm.pdf(x=x, loc=0.0, scale=1.0**2)\n# second normal distribution with mean = 0, variance = 2.25\np_X_2 = stats.norm.pdf(x=x, loc=0.0, scale=1.5**2)\n```", "```py\nplt.plot(x,p_X_1, color='blue')\nplt.plot(x, p_X_2, color='orange')\nplt.xlabel('X')\nplt.ylabel('P(X)')\n```", "```py\nfrom sklearn import datasets, linear_model, model_selection\n# load the data\ndiabetes = datasets.load_diabetes()\n# target\ny = diabetes.target\n# features\nX = diabetes.data\n```", "```py\n# the first patient has index 0\nprint(y[0])\n```", "```py\n 151.0\n```", "```py\n# let's look at the first patients data\nprint(dict(zip(diabetes.feature_names, X[0])))\n```", "```py\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n# values of alpha\nx = np.linspace(1, 20, 100)\n# probabilities\np_X = stats.gamma.pdf(x=x, a=1, loc=1, scale=2)\nplt.plot(x,p_X)\nplt.xlabel('alpha')\nplt.ylabel('P(alpha)')\n```", "```py\n# n sample values\nn_iter = 100\n# sample from the gamma distribution\nsamples = stats.gamma.rvs(a=1, loc=1, scale=2, \\\n                          size=n_iter, random_state=100)\n```", "```py\n# visualize the sample distribution\nplt.hist(samples)\nplt.xlabel('alpha')\nplt.ylabel('sample count')\n```", "```py\n# we will store the results inside a dictionary\nresult = {}\n# for each sample\nfor sample in samples:\n    \"\"\"\n    initialize a ridge regression estimator with alpha set \n    to the sample value\n    \"\"\"\n    reg = linear_model.Ridge(alpha=sample)\n    \"\"\"\n    conduct a 10-fold cross validation scoring on \n    negative mean squared error\n    \"\"\"\n    cv = model_selection.cross_val_score\\\n         (reg, X, y, cv=10, \\\n          scoring='neg_mean_squared_error')\n    # retain the result in the dictionary\n    result[sample] = [cv.mean()]\n```", "```py\nimport pandas as pd\n\"\"\"\nconvert the result dictionary to a pandas dataframe, \ntranspose and reset the index\n\"\"\"\ndf_result = pd.DataFrame(result).T.reset_index()\n# give the columns sensible names\ndf_result.columns = ['alpha', 'mean_neg_mean_squared_error']\nprint(df_result.sort_values('mean_neg_mean_squared_error', \\\n                            ascending=False).head())\n```", "```py\nplt.scatter(df_result.alpha, \\\n            df_result.mean_neg_mean_squared_error)\nplt.xlabel('alpha')\nplt.ylabel('-MSE')\n```", "```py\nfrom sklearn import datasets, model_selection, linear_model\n# load the data\ndiabetes = datasets.load_diabetes()\n# target\ny = diabetes.target\n# features\nX = diabetes.data\n# initialise the ridge regression\nreg = linear_model.Ridge()\n```", "```py\nfrom scipy import stats\n# alpha ~ gamma(1,1)\nparam_dist = {'alpha': stats.gamma(a=1, loc=1, scale=2)}\n```", "```py\n\"\"\"\nset up the random search to sample 100 values and \nscore on negative mean squared error\n\"\"\"\nrscv = model_selection.RandomizedSearchCV\\\n       (estimator=reg, param_distributions=param_dist, \\\n        n_iter=100, scoring='neg_mean_squared_error')\n# start the search\nrscv.fit(X,y)\n```", "```py\nimport pandas as pd\n# convert the results dictionary to a pandas data frame\nresults = pd.DataFrame(rscv.cv_results_)\n# show the top 5 hyperparamaterizations\nprint(results.loc[:,['params','rank_test_score']]\\\n      .sort_values('rank_test_score').head(5))\n```", "```py\n    from sklearn import datasets\n    # import data\n    digits = datasets.load_digits()\n    # target\n    y = digits.target\n    # features\n    X = digits.data\n    ```", "```py\n    from sklearn import ensemble\n    # an ensemble of 100 estimators\n    rfc = ensemble.RandomForestClassifier(n_estimators=100, \\\n                                          random_state=100)\n    ```", "```py\n    # how many features do we have in our dataset?\n    n_features = X.shape[1]\n    print(n_features)\n    ```", "```py\n    64\n    ```", "```py\n    from scipy import stats\n    \"\"\"\n    we would like to smaple from criterion and \n    max_features as discrete uniform distributions\n    \"\"\"\n    param_dist = {'criterion': ['gini', 'entropy'],\\\n                  'max_features': stats.randint(low=1, \\\n                                                high=n_features)}\n    ```", "```py\n    from sklearn import model_selection\n    \"\"\"\n    setting up the random search sampling 50 times and \n    conducting 5-fold cross-validation\n    \"\"\"\n    rscv = model_selection.RandomizedSearchCV\\\n           (estimator=rfc, param_distributions=param_dist, \\\n            n_iter=50, cv=5, scoring='accuracy' , random_state=100)\n    ```", "```py\n    # start the process\n    rscv.fit(X,y)\n    ```", "```py\n    import pandas as pd\n    # convert the dictionary of results to a pandas dataframe\n    results = pd.DataFrame(rscv.cv_results_)\n    # removing duplication\n    distinct_results = results.loc[:,['params',\\\n                                      'mean_test_score']]\n    # convert the params dictionaries to string data types\n    distinct_results.loc[:,'params'] = distinct_results.loc\\\n                                       [:,'params'].astype('str')\n    # remove duplicates\n    distinct_results.drop_duplicates(inplace=True)\n    # look at the top 5 best hyperparamaterizations\n    distinct_results.sort_values('mean_test_score', \\\n                                 ascending=False).head(5)\n    ```", "```py\n    # top performing models\n    distinct_results[distinct_results.mean_test_score > 0.93]\\\n                     .sort_values('mean_test_score')\\\n                     .plot.barh(x='params', xlim=(0.9))\n    ```", "```py\n    {'criterion': ['gini', 'entropy'],\\\n     'max_features': [2, 4, 6, 8, 10, 12, 14]}\n    ```", "```py\n    {'criterion': ['gini', 'entropy'],\\\n     'max_features': stats.randint(low=1, high=max_features)}\n    ```"]