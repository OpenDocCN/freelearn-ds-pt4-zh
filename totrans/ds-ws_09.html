<html><head></head><body><div id="sbo-rt-content"><div>
			<div id="_idContainer427" class="Content">
			</div>
		</div>
		<div id="_idContainer428" class="Content">
			<h1 id="_idParaDest-228">9. <a id="_idTextAnchor227"/>Interpreting a Machine Learning Model</h1>
		</div>
		<div id="_idContainer471" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">This chapter will show you how to interpret a machine learning model's results and get deeper insights into the patterns it found. By the end of the chapter, you will be able to analyze weights from linear models and variable importance for <strong class="source-inline">RandomForest</strong>. You will be able to implement variable importance via permutation to analyze feature importance. You will use a partial dependence plot to analyze single variables and make use of the lime package for local interpretation.</p>
			<h1 id="_idParaDest-229"><a id="_idTextAnchor228"/>Introduction</h1>
			<p>In the previous chapter, you saw how to find the optimal hyperparameters of some of the most popular machine learning algorithms in order to get better predictive performance (that is, more accurate predictions). </p>
			<p>Machine learning algorithms are always referred to as black box where we can only see the inputs and outputs and the implementation inside the algorithm is quite opaque, so people don't know what is happening inside. </p>
			<p>With each day that passes, we can sense the elevated need for more transparency in machine learning models. In the last few years, we have seen some cases where algorithms have been accused of discriminating against groups of people. For instance, a few years ago, a not-for-profit news organization called ProPublica highlighted bias in the COMPAS algorithm, built by the Northpointe company. The objective of the algorithm is to assess the likelihood of re-offending for a criminal. It was shown that the algorithm was predicting a higher level of risk for specific groups of people based on their demographics rather than other features. This example highlighted the importance of interpreting the results of your model and its logic properly and clearly.</p>
			<p>Luckily, some machine learning algorithms provide methods to understand the parameters they learned for a given task and dataset. There are also some functions that are model-agnostic and can help us to better understand the predictions made. So, there are different techniques that are either model-specific or model-agnostic for interpreting a model.</p>
			<p>These techniques can also differ in their scope. In the literature, we either have a global or local interpretation. A global interpretation means we are looking at the variables for all observations from a dataset and we want to understand which features have the biggest overall influence on the target variable. For instance, if you are predicting customer churn for a telco company, you may find the most important features for your model are customer usage and the average monthly amount paid. Local interpretation, on the other hand, focuses only on a single observation and analyzes the impact of the different variables. We will look at a single specific case and see what led the model to make its final prediction. For example, you will look at a specific customer who is predicted to churn and will discover that they usually buy the new iPhone model every year, in September.</p>
			<p>In this chapter, we will go through some techniques on how to interpret your models or their results.</p>
			<h1 id="_idParaDest-230"><a id="_idTextAnchor229"/>Linear Model Coefficients</h1>
			<p>In <em class="italic">Chapter 2, Regression</em>, and <em class="italic">Chapter 3, Binary Classification</em>, you saw that linear regression models learn function parameters in the form of the following:</p>
			<div>
				<div id="_idContainer429" class="IMG---Figure">
					<img src="Images/B15019_09_01.jpg" alt="Figure 9.1: Function parameters for linear regression models&#13;&#10;" width="1560" height="88"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1: Function parameters for linear regression models</p>
			<p>The objective is to find the best parameters (w<span class="subscript">1</span>, w<span class="subscript">2</span> …, w<span class="subscript">n</span>) that will get the predictions, ŷ̂, very close to the actual target values, <strong class="source-inline">y</strong>. So, once you have trained your model and are getting good predictive performance without much overfitting, you can use these parameters (or coefficients) to understand which variables largely impacted the predictions. If a coefficient is close to 0, this means the related feature didn't impact much the outcome. On the other hand, if it is quite high (positively or negatively), it means its feature is influencing the prediction outcome vastly. </p>
			<p>Let's take the example of the following function: <strong class="source-inline">100 + 0.2 * x</strong><span class="subscript">1</span><strong class="source-inline"> + 200 * x</strong><span class="subscript">2</span><strong class="source-inline"> - 180 * x</strong><span class="subscript">3</span>. The coefficient of x<span class="subscript">1</span> is only <strong class="bold">0.2</strong>. It is quite low compared to the other ones. It doesn't have much impact on the final outcome. The coefficient of x<span class="subscript">2</span> is positive, so it will positively impact the prediction. It is the opposite of the x<span class="subscript">3</span> coefficient because the x<span class="subscript">3</span> coefficient is negative.</p>
			<p>But to be able to compare apples versus apples, you need to rescale the features so that they have the same scale so you can compare their coefficients. If not, then maybe x<span class="subscript">1</span> ranges from 1 million to 5 million, while x<span class="subscript">2</span> and x<span class="subscript">3</span> are between <strong class="bold">1</strong> and <strong class="bold">88</strong>. In this case, even though the x<span class="subscript">1</span> coefficient is small, a small change in the x<span class="subscript">1</span> value has a drastic impact on the prediction. On the other hand, if all 3 coefficients are between -1 and 1, then we can say the key drivers in predicting the target variable are the features x<span class="subscript">2</span> and x<span class="subscript">3</span>.</p>
			<p>In <strong class="source-inline">sklearn</strong>, it is extremely easy to get the coefficient of a linear model; you just need to call the <strong class="source-inline">coef_</strong> attribute.  Let's implement this on a real example with the Diabetes dataset from <strong class="source-inline">sklearn</strong>:</p>
			<p class="source-code">from sklearn.datasets import load_diabetes</p>
			<p class="source-code">from sklearn.linear_model import LinearRegression</p>
			<p class="source-code">data = load_diabetes()</p>
			<p class="source-code"># fit a linear regression model to the data</p>
			<p class="source-code">lr_model = LinearRegression()</p>
			<p class="source-code">lr_model.fit(data.data, data.target)</p>
			<p class="source-code">lr_model.coef_</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer430" class="IMG---Figure">
					<img src="Images/B15019_09_02.jpg" alt="Figure 9.2: Coefficients of the linear regression parameters&#13;&#10;" width="905" height="88"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.2: Coefficients of the linear regression parameters</p>
			<p>Let's create a DataFrame with these values and column names:</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">coeff_df = pd.DataFrame()</p>
			<p class="source-code">coeff_df['feature'] = data.feature_names</p>
			<p class="source-code">coeff_df['coefficient'] = lr_model.coef_</p>
			<p class="source-code">coeff_df.head()</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer431" class="IMG---Figure">
					<img src="Images/B15019_09_03.jpg" alt="Figure 9.3: Coefficients of the linear regression model&#13;&#10;" width="666" height="219"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3: Coefficients of the linear regression model</p>
			<p>A large positive or a large negative number for a feature coefficient means it has a strong influence on the outcome. On the other hand, if the coefficient is close to 0, this means the variable does not have much impact on the prediction.</p>
			<p>From this table, we can see that column <strong class="source-inline">s1</strong> has a very low coefficient (a large negative number) so it negatively influences the final prediction. If <strong class="source-inline">s1</strong> increases by a unit of 1, the prediction value will decrease by <strong class="source-inline">-792.184162</strong>. On the other hand, <strong class="source-inline">bmi</strong> has a large positive number (<strong class="source-inline">519.839787</strong>) on the prediction, so the risk of diabetes is highly linked to this feature: an increase in body mass index (BMI) means a significant increase in the risk of diabetes.</p>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor230"/>Exercise 9.01: Extracting the Linear Regression Coefficient </h2>
			<p>In this exercise, we will train a linear regression model to predict the customer drop-out ratio and extract its coefficients.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset we will be using is shared by Carl Rasmussen from the University of Toronto: <a href="https://packt.live/37hInDr">https://packt.live/37hInDr</a>.</p>
			<p class="callout">This dataset was synthetically generated from a simulation for predicting the fraction of bank customers who leave a bank because of long queues.</p>
			<p class="callout">The CSV version of this dataset can be found here: <a href="https://packt.live/3kZrggU">https://packt.live/3kZrggU</a>.</p>
			<p class="callout">A data dictionary presenting the variables in this dataset can be found here:</p>
			<p class="callout"><a href="https://packt.live/3aBGhQD">https://packt.live/3aBGhQD</a>.</p>
			<p>The following steps will help you complete the exercise:</p>
			<ol>
				<li>Open a new Colab notebook.</li>
				<li>Import the following packages: <strong class="source-inline">pandas</strong>, <strong class="source-inline">train_test_split</strong> from <strong class="source-inline">sklearn.model_selection</strong>, <strong class="source-inline">StandardScaler</strong> from <strong class="source-inline">sklearn.preprocessing</strong>, <strong class="source-inline">LinearRegression</strong> from  <strong class="source-inline">sklearn.linear_model</strong>, <strong class="source-inline">mean_squared_error</strong> from <strong class="source-inline">sklearn.metrics</strong>, and <strong class="source-inline">altair</strong>: <p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.preprocessing import StandardScaler</p><p class="source-code">from sklearn.linear_model import LinearRegression</p><p class="source-code">from sklearn.metrics import mean_squared_error</p><p class="source-code">import altair as alt</p></li>
				<li>Create a variable called <strong class="source-inline">file_url</strong> that contains the URL to the dataset:<p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/The-Data-Science-Workshop/'\</p><p class="source-code">           'master/Chapter09/Dataset/phpYYZ4Qc.csv'</p></li>
				<li>Load the dataset into a DataFrame called <strong class="source-inline">df</strong> using <strong class="source-inline">.read_csv()</strong>:<p class="source-code">df = pd.read_csv(file_url)</p></li>
				<li>Print the first five rows of the DataFrame:<p class="source-code">df.head()</p><p>You should get the following output:</p><div id="_idContainer432" class="IMG---Figure"><img src="Images/B15019_09_04.jpg" alt="Figure 9.4: First five rows of the loaded DataFrame&#13;&#10;" width="975" height="305"/></div><p class="figure-caption">Figure 9.4: First five rows of the loaded DataFrame</p><p class="callout-heading">Note</p><p class="callout">The output has been truncated for presentation purposes. Please refer <a href="https://packt.live/3kZrggU">https://packt.live/3kZrggU</a> for complete output.</p></li>
				<li>Extract the <strong class="source-inline">rej</strong> column using <strong class="source-inline">.pop()</strong> and save it into a variable called <strong class="source-inline">y</strong>:<p class="source-code">y = df.pop('rej')</p></li>
				<li>Print the summary of the DataFrame using <strong class="source-inline">.describe()</strong>.<p class="source-code">df.describe()</p><p>You should get the following output:</p><div id="_idContainer433" class="IMG---Figure"><img src="Images/B15019_09_05.jpg" alt="Figure 9.5: Statistical measures of the DataFrame&#13;&#10;" width="967" height="484"/></div><p class="figure-caption">Figure 9.5: Statistical measures of the DataFrame</p><p class="callout-heading">Note</p><p class="callout">The preceding figure is a truncated version of the output. </p><p>From this output, we can see the data is not standardized. The variables have different scales.</p></li>
				<li>Split the DataFrame into training and testing sets using <strong class="source-inline">train_test_split()</strong> with <strong class="source-inline">test_size=0.3</strong> and <strong class="source-inline">random_state = 1</strong>:<p class="source-code">X_train, X_test, y_train, y_test = train_test_split\</p><p class="source-code">                                   (df, y, test_size=0.3, \</p><p class="source-code">                                    random_state=1)</p></li>
				<li>Instantiate <strong class="source-inline">StandardScaler</strong>:<p class="source-code">scaler = StandardScaler()</p></li>
				<li>Train <strong class="source-inline">StandardScaler</strong> on the training set and standardize it using <strong class="source-inline">.fit_transform()</strong>:<p class="source-code">X_train = scaler.fit_transform(X_train)</p></li>
				<li>Standardize the testing set using <strong class="source-inline">.transform()</strong>:<p class="source-code">X_test = scaler.transform(X_test)</p></li>
				<li>Instantiate <strong class="source-inline">LinearRegression</strong> and save it to a variable called <strong class="source-inline">lr_model</strong>:<p class="source-code">lr_model = LinearRegression()</p></li>
				<li>Train the model on the training set using <strong class="source-inline">.fit()</strong>:<p class="source-code">lr_model.fit(X_train, y_train)</p><p>You should get the following output:</p><div id="_idContainer434" class="IMG---Figure"><img src="Images/B15019_09_06.jpg" alt="Figure 9.6: Logs of LinearRegression&#13;&#10;" width="1557" height="66"/></div><p class="figure-caption">Figure 9.6: Logs of LinearRegression</p></li>
				<li>Predict the outcomes of the training and testing sets using <strong class="source-inline">.predict()</strong>:<p class="source-code">preds_train = lr_model.predict(X_train)</p><p class="source-code">preds_test = lr_model.predict(X_test)</p></li>
				<li>Calculate the mean squared error on the training set and print its value:<p class="source-code">train_mse = mean_squared_error(y_train, preds_train)</p><p class="source-code">train_mse</p><p>You should get the following output:</p><div id="_idContainer435" class="IMG---Figure"><img src="Images/B15019_09_07.jpg" alt="Figure 9.7: MSE score of the training set&#13;&#10;" width="1272" height="45"/></div><p class="figure-caption">Figure 9.7: MSE score of the training set</p><p>We achieved quite a low MSE score on the training set.</p></li>
				<li>Calculate the mean squared error on the testing set and print its value:<p class="source-code">test_mse = mean_squared_error(y_test, preds_test)</p><p class="source-code">test_mse</p><p>You should get the following output:</p><div id="_idContainer436" class="IMG---Figure"><img src="Images/B15019_09_08.jpg" alt="Figure 9.8: MSE score of the testing set&#13;&#10;" width="1665" height="51"/></div><p class="figure-caption">Figure 9.8: MSE score of the testing set</p><p>We also have a low MSE score on the testing set that is very similar to the training one. So, our model is not overfitting.</p><p class="callout-heading">Note</p><p class="callout">You may get slightly different outputs than those present here. However, the values you would obtain should largely agree with those obtained in this exercise.</p></li>
				<li>Print the coefficients of the linear regression model using <strong class="source-inline">.coef_</strong>:<p class="source-code">lr_model.coef_</p><p>You should get the following output:</p><div id="_idContainer437" class="IMG---Figure"><img src="Images/B15019_09_09.jpg" alt="Figure 9.9: Coefficients of the linear regression model&#13;&#10;" width="916" height="208"/></div><p class="figure-caption">Figure 9.9: Coefficients of the linear regression model</p></li>
				<li>Create an empty DataFrame called <strong class="source-inline">coef_df</strong>:<p class="source-code">coef_df = pd.DataFrame()</p></li>
				<li>Create a new column called <strong class="source-inline">feature</strong> for this DataFrame with the name of the columns of <strong class="source-inline">df</strong> using <strong class="source-inline">.columns</strong>:<p class="source-code">coef_df['feature'] = df.columns</p></li>
				<li>Create a new column called <strong class="source-inline">coefficient</strong> for this DataFrame with the coefficients of the linear regression model using <strong class="source-inline">.coef_</strong>:<p class="source-code">coef_df['coefficient'] = lr_model.coef_</p></li>
				<li>Print the first five rows of <strong class="source-inline">coef_df</strong>:<p class="source-code">coef_df.head()</p><p>You should get the following output:</p><div id="_idContainer438" class="IMG---Figure"><img src="Images/B15019_09_10.jpg" alt="Figure 9.10: The first five rows of coef_df&#13;&#10;" width="1646" height="574"/></div><p class="figure-caption">Figure 9.10: The first five rows of coef_df</p><p>From this output, we can see the variables <strong class="source-inline">a1sx</strong> and <strong class="source-inline">a1sy</strong> have the lowest value (the biggest negative value) so they are contributing more to the prediction than the three other variables shown here.</p></li>
				<li>Plot a bar chart with Altair using <strong class="source-inline">coef_df</strong> and <strong class="source-inline">coefficient</strong> as the <strong class="source-inline">x</strong> axis and <strong class="source-inline">feature</strong> as the <strong class="source-inline">y</strong> axis:<p class="source-code">alt.Chart(coef_df).mark_bar().encode(x='coefficient',\</p><p class="source-code">                                     y="feature")</p><p>You should get the following output:</p><div id="_idContainer439" class="IMG---Figure"><img src="Images/B15019_09_11.jpg" alt="Figure 9.11: Graph showing the coefficients of the linear regression model&#13;&#10;" width="1046" height="1315"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.11: Graph showing the coefficients of the linear regression model</p>
			<p>From this output, we can see the variables that impacted the prediction the most were: </p>
			<ul>
				<li><strong class="source-inline">a2pop</strong>, which corresponds to the population of area 2</li>
				<li><strong class="source-inline">a1pop</strong>, which corresponds to the population of area 1 </li>
				<li><strong class="source-inline">a3pop</strong>, which corresponds to the population of area 3 </li>
				<li><strong class="source-inline">mxql</strong>, which is the maximum length of the queues</li>
				<li><strong class="source-inline">b1eff</strong>, which is the level of efficiency of bank 1</li>
				<li><strong class="source-inline">temp</strong>, which is the temperature</li>
			</ul>
			<p>The first three variables impacted the outcome positively (increasing the target variable value). This means as the population grows in any of the three areas, the chance of customer churn increases. On the other hand, the last three features negatively impacted the target variable (decreasing the target variable value): if the maximum length, bank-1 efficiency level, or temperature increases, the risk of customers leaving decreases.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3kZrggU">https://packt.live/3kZrggU</a>.</p>
			<p class="callout">This section does not currently have an online interactive example, but can be run as usual on Google Colab.</p>
			<p>In this exercise, you learned how to extract the coefficients learned by a linear regression model and identified which variables make the biggest contribution to the prediction.</p>
			<h1 id="_idParaDest-232"><a id="_idTextAnchor231"/>RandomForest Variable Importance</h1>
			<p><em class="italic">Chapter 4</em>, <em class="italic">Multiclass Classification with RandomForest</em>, introduced you to a very powerful tree-based algorithm: <strong class="source-inline">RandomForest</strong>. It is one of the most popular algorithms in the industry, not only because it achieves very good results in terms of prediction but also for the fact that it provides several tools for interpreting it, such as variable importance.</p>
			<p>Remember from <em class="italic">Chapter 4</em>, <em class="italic">Multiclass Classification with RandomForest</em>, that <strong class="source-inline">RandomForest</strong> builds multiple independent trees and then averages their results to make a final prediction. We also learned that it creates nodes in each tree to find the best split that will clearly separate the observations into two groups. <strong class="source-inline">RandomForest</strong> uses different measures to find the best split. In <strong class="source-inline">sklearn</strong>, you can either use the Gini or Entropy measure for the classification task and MSE or MAE for regression. Without going into the details of each of them, these measures calculate the level of impurity of a given split. This level of impurity looks at how different the observations are from each other within a node. For instance, if a group has all the same values within a feature, it will have a high level of purity. On the other hand, if the group has a lot of different values, it will have a high level of impurity. </p>
			<p>Each sub-tree built will decrease this impurity score. So, we can use this impurity score to assess the importance of each variable for the final prediction. This technique is not specific to <strong class="source-inline">RandomForest</strong> only; it can be applied to any tree-based algorithm, such as decision tree or gradient-boosted tree.</p>
			<p>After training <strong class="source-inline">RandomForest</strong>, you can assess its variable importance (or feature importance) with the <strong class="source-inline">feature_importances_</strong> attribute.</p>
			<p>Let's see how to extract this information from the Breast Cancer dataset from <strong class="source-inline">sklearn</strong>:</p>
			<p class="source-code">from sklearn.datasets import load_breast_cancer</p>
			<p class="source-code">from sklearn.ensemble import RandomForestClassifier</p>
			<p class="source-code">data = load_breast_cancer()</p>
			<p class="source-code">X, y = data.data, data.target</p>
			<p class="source-code">rf_model = RandomForestClassifier(random_state=168)</p>
			<p class="source-code">rf_model.fit(X, y)</p>
			<p class="source-code">rf_model.feature_importances_</p>
			<p>The output will be as shown in the following figure:</p>
			<div>
				<div id="_idContainer440" class="IMG---Figure">
					<img src="Images/B15019_09_12.jpg" alt="Figure 9.12: Feature importance of a Random Forest model&#13;&#10;" width="655" height="136"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.12: Feature importance of a Random Forest model</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Due to randomization, you may get a slightly different result.</p>
			<p>It might be a little difficult to evaluate which importance value corresponds to which variable from this output. Let's create a DataFrame that will contain these values with the name of the columns:</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">varimp_df = pd.DataFrame()</p>
			<p class="source-code">varimp_df['feature'] = data.feature_names</p>
			<p class="source-code">varimp_df['importance'] = rf_model.feature_importances_</p>
			<p class="source-code">varimp_df.head()</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer441" class="IMG---Figure">
					<img src="Images/B15019_09_13.jpg" alt="Figure 9.13: RandomForest variable importance for the first five features &#13;&#10;of the Breast Cancer dataset&#13;&#10;" width="758" height="278"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.13: RandomForest variable importance for the first five features of the Breast Cancer dataset</p>
			<p>From this output, we can see that <strong class="source-inline">mean radius</strong> and <strong class="source-inline">mean perimeter</strong> have the highest scores, which means they are the most important in predicting the target variable. The <strong class="source-inline">mean smoothness</strong> column has a very low value, so it seems it doesn't influence the model much to predict the output.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The range of values of variable importance is different for datasets; it is not a standardized measure.</p>
			<p>Let's plot these variable importance values onto a graph using <strong class="source-inline">altair</strong>:</p>
			<p class="source-code">import altair as alt</p>
			<p class="source-code">alt.Chart(varimp_df).mark_bar().encode(x='importance',\</p>
			<p class="source-code">                                       y="feature")</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer442" class="IMG---Figure">
					<img src="Images/B15019_09_14.jpg" alt="Figure 9.14: Graph showing RandomForest variable importance&#13;&#10;" width="977" height="1094"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.14: Graph showing RandomForest variable importance</p>
			<p>From this graph, we can see the most important features for this Random Forest model are <strong class="source-inline">worst perimeter</strong>, <strong class="source-inline">worst area</strong>, and <strong class="source-inline">worst concave points</strong>. So now we know these features are the most important ones in predicting whether a tumor is benign or malignant for this Random Forest model.</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor232"/>Exercise 9.02: Extracting RandomForest Feature Importance</h2>
			<p>In this exercise, we will extract the feature importance of a Random Forest classifier model trained to predict the customer drop-out ratio.</p>
			<p>We will be using the same dataset as in the previous exercise.</p>
			<p>The following steps will help you complete the exercise:</p>
			<ol>
				<li value="1">Open a new Colab notebook.</li>
				<li>Import the following packages: <strong class="source-inline">pandas</strong>, <strong class="source-inline">train_test_split</strong> from <strong class="source-inline">sklearn.model_selection</strong>, and <strong class="source-inline">RandomForestRegressor</strong> from <strong class="source-inline">sklearn.ensemble</strong>:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.ensemble import RandomForestRegressor</p><p class="source-code">from sklearn.metrics import mean_squared_error</p><p class="source-code">import altair as alt</p></li>
				<li>Create a variable called <strong class="source-inline">file_url</strong> that contains the URL to the dataset:<p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/The-Data-Science-Workshop/'\</p><p class="source-code">           'master/Chapter09/Dataset/phpYYZ4Qc.csv'</p></li>
				<li>Load the dataset into a DataFrame called <strong class="source-inline">df</strong> using <strong class="source-inline">.read_csv()</strong>:<p class="source-code">df = pd.read_csv(file_url)</p></li>
				<li>Extract the <strong class="source-inline">rej</strong> column using <strong class="source-inline">.pop()</strong> and save it into a variable called <strong class="source-inline">y</strong>:<p class="source-code">y = df.pop('rej')</p></li>
				<li>Split the DataFrame into training and testing sets using <strong class="source-inline">train_test_split()</strong> with <strong class="source-inline">test_size=0.3</strong> and <strong class="source-inline">random_state = 1</strong>:<p class="source-code">X_train, X_test, y_train, y_test = train_test_split\</p><p class="source-code">                                   (df, y, test_size=0.3, \</p><p class="source-code">                                    random_state=1)</p></li>
				<li>Instantiate <strong class="source-inline">RandomForestRegressor</strong> with <strong class="source-inline">random_state=1</strong>, <strong class="source-inline">n_estimators=50</strong>, <strong class="source-inline">max_depth=6</strong>, and <strong class="source-inline">min_samples_leaf=60</strong>:<p class="source-code">rf_model = RandomForestRegressor(random_state=1, \</p><p class="source-code">                                 n_estimators=50, max_depth=6,\</p><p class="source-code">                                 min_samples_leaf=60)</p></li>
				<li>Train the model on the training set using <strong class="source-inline">.fit()</strong>:<p class="source-code">rf_model.fit(X_train, y_train)</p><p>You should get the following output:</p><div id="_idContainer443" class="IMG---Figure"><img src="Images/B15019_09_15.jpg" alt="Figure 9.15: Logs of the Random Forest model&#13;&#10;" width="915" height="177"/></div><p class="figure-caption">Figure 9.15: Logs of the Random Forest model</p></li>
				<li>Predict the outcomes of the training and testing sets using <strong class="source-inline">.predict()</strong>:<p class="source-code">preds_train = rf_model.predict(X_train)</p><p class="source-code">preds_test = rf_model.predict(X_test)</p></li>
				<li>Calculate the mean squared error on the training set and print its value:<p class="source-code">train_mse = mean_squared_error(y_train, preds_train)</p><p class="source-code">train_mse</p><p>You should get the following output:</p><div id="_idContainer444" class="IMG---Figure"><img src="Images/B15019_09_16.jpg" alt="Figure 9.16: MSE score of the training set&#13;&#10;" width="1569" height="45"/></div><p class="figure-caption">Figure 9.16: MSE score of the training set</p><p>We achieved quite a low MSE score on the training set.</p></li>
				<li>Calculate the MSE on the testing set and print its value:<p class="source-code">test_mse = mean_squared_error(y_test, preds_test)</p><p class="source-code">test_mse</p><p>You should get the following output:</p><div id="_idContainer445" class="IMG---Figure"><img src="Images/B15019_09_17.jpg" alt="Figure 9.17: MSE score of the testing set&#13;&#10;" width="1338" height="44"/></div><p class="figure-caption">Figure 9.17: MSE score of the testing set</p><p>We also have a low MSE score on the testing set that is very similar to the training one. So, our model is not overfitting.</p></li>
				<li>Print the variable importance using <strong class="source-inline">.feature_importances_</strong>:<p class="source-code">rf_model.feature_importances_</p><p>You should get the following output:</p><div id="_idContainer446" class="IMG---Figure"><img src="Images/B15019_09_18.jpg" alt="Figure 9.18: MSE score of the testing set&#13;&#10;" width="915" height="213"/></div><p class="figure-caption">Figure 9.18: MSE score of the testing set</p></li>
				<li>Create an empty DataFrame called <strong class="source-inline">varimp_df</strong>:<p class="source-code">varimp_df = pd.DataFrame()</p></li>
				<li>Create a new column called <strong class="source-inline">feature</strong> for this DataFrame with the name of the columns of <strong class="source-inline">df</strong>, using <strong class="source-inline">.columns</strong>:<p class="source-code">varimp_df['feature'] = df.columns</p><p class="source-code">varimp_df['importance'] = rf_model.feature_importances_</p></li>
				<li>Print the first five rows of <strong class="source-inline">varimp_df</strong>:<p class="source-code">varimp_df.head()</p><p>You should get the following output:</p><div id="_idContainer447" class="IMG---Figure"><img src="Images/B15019_09_19.jpg" alt="Figure 9.19: Variable importance of the first five variables&#13;&#10;" width="1639" height="574"/></div><p class="figure-caption">Figure 9.19: Variable importance of the first five variables</p><p>From this output, we can see the variables <strong class="source-inline">a1cy</strong> and <strong class="source-inline">a1sy</strong> have the highest value, so they are more important for predicting the target variable than the three other variables shown here.</p></li>
				<li>Plot a bar chart with Altair using <strong class="source-inline">coef_df</strong> and <strong class="source-inline">importance</strong> as the <strong class="source-inline">x</strong> axis and <strong class="source-inline">feature</strong> as the <strong class="source-inline">y</strong> axis:<p class="source-code">alt.Chart(varimp_df).mark_bar().encode(x='importance',\</p><p class="source-code">                                       y="feature")</p><p>You should get the following output:</p><div id="_idContainer448" class="IMG---Figure"><img src="Images/B15019_09_20.jpg" alt="Figure 9.20: Graph showing the variable importance of the first five variables&#13;&#10;" width="1000" height="1267"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.20: Graph showing the variable importance of the first five variables</p>
			<p>From this output, we can see the variables that impact the prediction the most for this Random Forest model are <strong class="source-inline">a2pop</strong>, <strong class="source-inline">a1pop</strong>, <strong class="source-inline">a3pop</strong>, <strong class="source-inline">b1eff</strong>, and <strong class="source-inline">temp</strong>, by decreasing order of importance.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/327Pi0i">https://packt.live/327Pi0i</a>.</p>
			<p class="callout">This section does not currently have an online interactive example, but can be run as usual on Google Colab.</p>
			<p>In this exercise, you learned how to extract the feature importance learned by a Random Forest model and identified which variables are the most important for its predictions.</p>
			<h1 id="_idParaDest-234"><a id="_idTextAnchor233"/>Variable Importance via Permutation</h1>
			<p>In the previous section, we saw how to extract feature importance for RandomForest. There is actually another technique that shares the same name, but its underlying logic is different and can be applied to any algorithm, not only tree-based ones.</p>
			<p>This technique can be referred to as variable importance via permutation. Let's say we trained a model to predict a target variable with five classes and achieved an accuracy of 0.95. One way to assess the importance of one of the features is to remove and train a model and see the new accuracy score. If the accuracy score dropped significantly, then we could infer that this variable has a significant impact on the prediction. On the other hand, if the score slightly decreased or stayed the same, we could say this variable is not very important and doesn't influence the final prediction much. So, we can use this difference between the model's performance to assess the importance of a variable. </p>
			<p>The drawback of this method is that you need to retrain a new model for each variable. If it took you a few hours to train the original model and you have 100 different features, it would take quite a while to compute the importance of each variable. It would be great if we didn't have to retrain different models. So, another solution would be to generate noise or new values for a given column and predict the final outcomes from this modified data and compare the accuracy score. For example, if you have a column with values between 0 and 100, you can take the original data and randomly generate new values for this column (keeping all other variables the same) and predict the class for them.</p>
			<p>This option also has a catch. The randomly generated values can be very different from the original data. Going back to the same example we saw before, if the original range of values for a column is between 0 and 100 and we generate values that can be negative or take a very high value, it is not very representative of the real distribution of the original data. So, we will need to understand the distribution of each variable before generating new values.</p>
			<p>Rather than generating random values, we can simply swap (or permute) values of a column between different rows and use these modified cases for predictions. Then, we can calculate the related accuracy score and compare it with the original one to assess the importance of this variable. For example, we have the following rows in the original dataset:</p>
			<div>
				<div id="_idContainer449" class="IMG---Figure">
					<img src="Images/B15019_09_21.jpg" alt="Figure 9.21: Example of the dataset&#13;&#10;" width="1665" height="269"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.21: Example of the dataset</p>
			<p>We can swap the values for the X1 column and get a new dataset:</p>
			<div>
				<div id="_idContainer450" class="IMG---Figure">
					<img src="Images/B15019_09_22.jpg" alt="Figure 9.22: Example of a swapped column from the dataset&#13;&#10;" width="1665" height="289"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.22: Example of a swapped column from the dataset</p>
			<p>The <strong class="source-inline">mlxtend</strong> package provides a function to perform variable permutation and calculate variable importance values: <strong class="source-inline">feature_importance_permutation</strong>. Let's see how to use it with the Breast Cancer dataset from <strong class="source-inline">sklearn</strong>. </p>
			<p>First, let's load the data and train a Random Forest model:</p>
			<p class="source-code">from sklearn.datasets import load_breast_cancer</p>
			<p class="source-code">from sklearn.ensemble import RandomForestClassifier</p>
			<p class="source-code"> </p>
			<p class="source-code">data = load_breast_cancer()</p>
			<p class="source-code">X, y = data.data, data.target</p>
			<p class="source-code">rf_model = RandomForestClassifier(random_state=168)</p>
			<p class="source-code">rf_model.fit(X, y)</p>
			<p>Then, we will call the <strong class="source-inline">feature_importance_permutation</strong> function from <strong class="source-inline">mlxtend.evaluate</strong>. This function takes the following parameters:</p>
			<ul>
				<li><strong class="source-inline">predict_method</strong>: A function that will be called for model prediction. Here, we will provide the <strong class="source-inline">predict</strong> method from our trained <strong class="source-inline">rf_model</strong> model.</li>
				<li><strong class="source-inline">X</strong>: The features from the dataset. It needs to be in NumPy array form.</li>
				<li><strong class="source-inline">y</strong>: The target variable from the dataset. It needs to be in <strong class="source-inline">Numpy</strong> array form.</li>
				<li><strong class="source-inline">metric</strong>: The metric used for comparing the performance of the model. For the classification task, we will use accuracy.</li>
				<li><strong class="source-inline">num_round</strong>: The number of rounds <strong class="source-inline">mlxtend</strong> will perform permutation on the data and assess the performance change.</li>
				<li><strong class="source-inline">seed</strong>: The seed set for getting reproducible results.</li>
			</ul>
			<p>Consider the following code snippet:</p>
			<p class="source-code">from mlxtend.evaluate import feature_importance_permutation</p>
			<p class="source-code">imp_vals, _ = feature_importance_permutation\</p>
			<p class="source-code">              (predict_method=rf_model.predict, X=X, y=y, \</p>
			<p class="source-code">               metric='r2', num_rounds=1, seed=2)</p>
			<p class="source-code">imp_vals</p>
			<p>The output should be as follows:</p>
			<div>
				<div id="_idContainer451" class="IMG---Figure">
					<img src="Images/B15019_09_23.jpg" alt="Figure 9.23: Variable importance by permutation&#13;&#10;" width="648" height="109"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.23: Variable importance by permutation</p>
			<p>Let's create a DataFrame containing these values and the names of the features and plot them on a graph with <strong class="source-inline">altair</strong>:</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">varimp_df = pd.DataFrame()</p>
			<p class="source-code">varimp_df['feature'] = data.feature_names</p>
			<p class="source-code">varimp_df['importance'] = imp_vals</p>
			<p class="source-code">varimp_df.head()</p>
			<p class="source-code">import altair as alt</p>
			<p class="source-code">alt.Chart(varimp_df).mark_bar().encode(x='importance',\</p>
			<p class="source-code">                                       y="feature")</p>
			<p>The output should be as follows: </p>
			<div>
				<div id="_idContainer452" class="IMG---Figure">
					<img src="Images/B15019_09_24.jpg" alt="Figure 9.24: Graph showing variable importance by permutation&#13;&#10;" width="900" height="1077"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.24: Graph showing variable importance by permutation</p>
			<p>These results are different from the ones we got from <strong class="source-inline">RandomForest</strong> in the previous section. Here, worst concave points is the most important, followed by worst area, and worst perimeter has a higher value than mean radius. So, we got the same list of the most important variables but in a different order. This confirms these three features are indeed the most important in predicting whether a tumor is malignant or not. The variable importance from <strong class="source-inline">RandomForest</strong> and the permutation have different logic, therefore, you might get different outputs when you run the code given in the preceding section. </p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor234"/>Exercise 9.03: Extracting Feature Importance via Permutation</h2>
			<p>In this exercise, we will compute and extract feature importance by permutating a Random Forest classifier model trained to predict the customer drop-out ratio.</p>
			<p>We will using the same dataset as in the previous exercise.</p>
			<p>The following steps will help you complete the exercise:</p>
			<ol>
				<li value="1">Open a new Colab notebook.</li>
				<li>Import the following packages: <strong class="source-inline">pandas</strong>, <strong class="source-inline">train_test_split</strong> from <strong class="source-inline">sklearn.model_selection</strong>, <strong class="source-inline">RandomForestRegressor</strong> from  <strong class="source-inline">sklearn.ensemble</strong>, <strong class="source-inline">feature_importance_permutation</strong> from <strong class="source-inline">mlxtend.evaluate</strong>, and <strong class="source-inline">altair</strong>:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.ensemble import RandomForestRegressor</p><p class="source-code">from mlxtend.evaluate import feature_importance_permutation</p><p class="source-code">import altair as alt</p></li>
				<li>Create a variable called <strong class="source-inline">file_url</strong> that contains the URL of the dataset:<p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/The-Data-Science-Workshop/'\</p><p class="source-code">           'master/Chapter09/Dataset/phpYYZ4Qc.csv'</p></li>
				<li>Load the dataset into a DataFrame called <strong class="source-inline">df</strong> using <strong class="source-inline">.read_csv()</strong>:<p class="source-code">df = pd.read_csv(file_url)</p></li>
				<li>Extract the <strong class="source-inline">rej</strong> column using <strong class="source-inline">.pop()</strong> and save it into a variable called <strong class="source-inline">y</strong>:<p class="source-code">y = df.pop('rej')</p></li>
				<li>Split the DataFrame into training and testing sets using <strong class="source-inline">train_test_split()</strong> with <strong class="source-inline">test_size=0.3</strong> and <strong class="source-inline">random_state = 1</strong>:<p class="source-code">X_train, X_test, y_train, y_test = train_test_split\</p><p class="source-code">                                   (df, y, test_size=0.3, \</p><p class="source-code">                                    random_state=1)</p></li>
				<li>Instantiate <strong class="source-inline">RandomForestRegressor</strong> with <strong class="source-inline">random_state=1</strong>, <strong class="source-inline">n_estimators=50</strong>, <strong class="source-inline">max_depth=6</strong>, and <strong class="source-inline">min_samples_leaf=60</strong>:<p class="source-code">rf_model = RandomForestRegressor(random_state=1, \</p><p class="source-code">                                 n_estimators=50, max_depth=6, \</p><p class="source-code">                                 min_samples_leaf=60)</p></li>
				<li>Train the model on the training set using <strong class="source-inline">.fit()</strong>:<p class="source-code">rf_model.fit(X_train, y_train)</p><p>You should get the following output:</p><div id="_idContainer453" class="IMG---Figure"><img src="Images/B15019_09_25.jpg" alt="Figure 9.25: Logs of RandomForest&#13;&#10;" width="909" height="171"/></div><p class="figure-caption">Figure 9.25: Logs of RandomForest</p></li>
				<li>Extract the feature importance via permutation using <strong class="source-inline">feature_importance_permutation</strong> from <strong class="source-inline">mlxtend</strong> with the Random Forest model, the testing set, <strong class="source-inline">r2</strong> as the metric used, <strong class="source-inline">num_rounds=1</strong>, and <strong class="source-inline">seed=2</strong>. Save the results into a variable called <strong class="source-inline">imp_vals</strong> and print its values:<p class="source-code">imp_vals, _ = feature_importance_permutation\</p><p class="source-code">              (predict_method=rf_model.predict, \</p><p class="source-code">               X=X_test.values, y=y_test.values, \</p><p class="source-code">               metric='r2', num_rounds=1, seed=2)</p><p class="source-code">imp_vals</p><p>You should get the following output:</p><div id="_idContainer454" class="IMG---Figure"><img src="Images/B15019_09_26.jpg" alt="Figure 9.26: Variable importance by permutation&#13;&#10;" width="913" height="201"/></div><p class="figure-caption">Figure 9.26: Variable importance by permutation</p><p>It is quite hard to interpret the raw results. Let's plot the variable importance by permutating the model on a graph. </p></li>
				<li>Create a DataFrame called <strong class="source-inline">varimp_df</strong> with two columns: <strong class="source-inline">feature</strong> containing the name of the columns of <strong class="source-inline">df</strong>, using <strong class="source-inline">.columns</strong> and <strong class="source-inline">'importance'</strong> containing the values of <strong class="source-inline">imp_vals</strong>:<p class="source-code">varimp_df = pd.DataFrame({'feature': df.columns, \</p><p class="source-code">                          'importance': imp_vals})</p></li>
				<li>Plot a bar chart with Altair using <strong class="source-inline">coef_df</strong> and <strong class="source-inline">importance</strong> as the <strong class="source-inline">x</strong> axis and <strong class="source-inline">feature</strong> as the <strong class="source-inline">y</strong> axis:<p class="source-code">alt.Chart(varimp_df).mark_bar().encode(x='importance',\</p><p class="source-code">                                       y="feature")</p><p>You should get the following output:</p><div id="_idContainer455" class="IMG---Figure"><img src="Images/B15019_09_27.jpg" alt="Figure 9.27: Graph showing the variable importance by permutation&#13;&#10;" width="1046" height="1300"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.27: Graph showing the variable importance by permutation</p>
			<p>From this output, we can see the variables that impact the prediction the most for this Random Forest model are: <strong class="source-inline">a2pop</strong>, <strong class="source-inline">a1pop</strong>, <strong class="source-inline">a3pop</strong>, <strong class="source-inline">b1eff</strong>, and <strong class="source-inline">temp</strong>, in decreasing order of importance. This is very similar to the results of <em class="italic">Exercise 9.02</em>,<em class="italic"> Extracting RandomForest Feature Importance</em>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YdstY9">https://packt.live/2YdstY9</a>.</p>
			<p class="callout">This section does not currently have an online interactive example, but can be run as usual on Google Colab.</p>
			<p>You successfully extracted the feature importance by permutating this model and identified which variables are the most important for its predictions.</p>
			<h1 id="_idParaDest-236"><a id="_idTextAnchor235"/>Partial Dependence Plots</h1>
			<p>Another tool that is model-agnostic is a partial dependence plot. It is a visual tool for analyzing the effect of a feature on the target variable. To achieve this, we can plot the values of the feature we are interested in analyzing on the <strong class="source-inline">x</strong>-axis and the target variable on the <strong class="source-inline">y</strong>-axis and then show all the observations from the dataset on this graph. Let's try it on the Breast Cancer dataset from <strong class="source-inline">sklearn</strong>:</p>
			<p class="source-code">from sklearn.datasets import load_breast_cancer</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">data = load_breast_cancer()</p>
			<p class="source-code">df = pd.DataFrame(data.data, columns=data.feature_names)</p>
			<p class="source-code">df['target'] = data.target</p>
			<p>Now that we have loaded the data and converted it to a DataFrame, let's have a look at the worst concave points column:</p>
			<p class="source-code">import altair as alt</p>
			<p class="source-code">alt.Chart(df).mark_circle(size=60)\</p>
			<p class="source-code">             .encode(x='worst concave points', y='target')</p>
			<p>The resulting plot is as follows:</p>
			<div>
				<div id="_idContainer456" class="IMG---Figure">
					<img src="Images/B15019_09_28.jpg" alt="Figure 9.28: Scatter plot of the worst concave points and target variables&#13;&#10;" width="939" height="672"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.28: Scatter plot of the worst concave points and target variables</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The preceding code and figure are just examples. We encourage you to analyze different features by changing the values assigned to <strong class="source-inline">x</strong> and <strong class="source-inline">y</strong> in the preceding code. For example, you can possibly analyze worst concavity versus worst perimeter by setting <strong class="source-inline">x='worst concavity'</strong> and <strong class="source-inline">y='worst perimeter'</strong> in the preceding code.</p>
			<p>From this plot, we can see:</p>
			<ul>
				<li>Most cases with 1 for the target variable have values under 0.16 for the worst concave points column.</li>
				<li>Cases with a 0 value for the target have values of over 0.08 for worst concave points.</li>
			</ul>
			<p>With this plot, we are not too sure about which outcome (0 or 1) we will get for the values between 0.08 and 0.16 for worst concave points. There are multiple possible reasons why the outcome of the observations within this range of values is uncertain, such as the fact that there are not many records that fall into this case, or other variables might influence the outcome for these cases. This is where a partial dependence plot can help.</p>
			<p>The logic is very similar to variable importance via permutation but rather than randomly replacing the values in a column, we will test every possible value within that column for all observations and see what predictions it leads to. If we take the example from figure 9.21, from the three observations we had originally, this method will create six new observations by keeping columns <strong class="source-inline">X2</strong> and <strong class="source-inline">X3</strong> as they were and replacing the values of <strong class="source-inline">X1</strong>:</p>
			<div>
				<div id="_idContainer457" class="IMG---Figure">
					<img src="Images/B15019_09_29.jpg" alt="Figure 9.29: Example of records generated from a partial dependence plot&#13;&#10;" width="1041" height="450"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.29: Example of records generated from a partial dependence plot</p>
			<p>With this new data, we can see, for instance, whether the value 12 really has a strong influence on predicting 1 for the target variable. The original records, with the values 42 and 1 for the <strong class="source-inline">X1</strong> column, lead to outcome 0 and only value 12 generated a prediction of 1. But if we take the same observations for <strong class="source-inline">X1</strong>, equal to 42 and 1, and replace that value with 12, we can see whether the new predictions will lead to 1 for the target variable. This is exactly the logic behind a partial dependence plot, and it will assess all the permutations possible for a column and plot the average of the predictions. </p>
			<p><strong class="source-inline">sklearn</strong> provides a function called <strong class="source-inline">plot_partial_dependence()</strong> to display the partial dependence plot for a given feature. Let's see how to use it on the Breast Cancer dataset. First, we need to get the index of the column we are interested in. We will use the <strong class="source-inline">.get_loc()</strong> method from <strong class="source-inline">pandas</strong> to get the index for the <strong class="source-inline">worst concave points</strong> column:</p>
			<p class="source-code">import altair as alt</p>
			<p class="source-code">from sklearn.inspection import plot_partial_dependence</p>
			<p class="source-code">feature_index = df.columns.get_loc("worst concave points")</p>
			<p>Now we can call the <strong class="source-inline">plot_partial_dependence()</strong> function. We need to provide the following parameters: the trained model, the training set, and the indices of the features to be analyzed:</p>
			<p class="source-code">plot_partial_dependence(rf_model, df, \</p>
			<p class="source-code">                        features=[feature_index])</p>
			<div>
				<div id="_idContainer458" class="IMG---Figure">
					<img src="Images/B15019_09_30.jpg" alt="Figure 9.30: Partial dependence plot for the worst concave points column&#13;&#10;" width="960" height="410"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.30: Partial dependence plot for the worst concave points column</p>
			<p>This partial dependence plot shows us that, on average, all the observations with a value under 0.17 for the worst concave points column will most likely lead to a prediction of 1 for the target (probability over 0.5) and all the records over 0.17 will have a prediction of 0 (probability under 0.5).</p>
			<h2 id="_idParaDest-237"><a id="_idTextAnchor236"/>Exercise 9.04: Plotting Partial Dependence</h2>
			<p>In this exercise, we will plot partial dependence plots for two variables, <strong class="source-inline">a1pop</strong> and <strong class="source-inline">temp</strong>, from a Random Forest classifier model trained to predict the customer drop-out ratio.</p>
			<p>We will using the same dataset as in the previous exercise.</p>
			<ol>
				<li value="1">Open a new Colab notebook.</li>
				<li>Import the following packages: <strong class="source-inline">pandas</strong>, <strong class="source-inline">train_test_split</strong> from <strong class="source-inline">sklearn.model_selection</strong>, <strong class="source-inline">RandomForestRegressor</strong> from  <strong class="source-inline">sklearn.ensemble</strong>, <strong class="source-inline">plot_partial_dependence</strong> from <strong class="source-inline">sklearn.inspection</strong>, and <strong class="source-inline">altair</strong>:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.ensemble import RandomForestRegressor</p><p class="source-code">from sklearn.inspection import plot_partial_dependence</p><p class="source-code">import altair as alt</p></li>
				<li>Create a variable called <strong class="source-inline">file_url</strong> that contains the URL for the dataset:<p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/The-Data-Science-Workshop/'\</p><p class="source-code">           'master/Chapter09/Dataset/phpYYZ4Qc.csv'</p></li>
				<li>Load the dataset into a DataFrame called <strong class="source-inline">df</strong> using <strong class="source-inline">.read_csv()</strong>:<p class="source-code">df = pd.read_csv(file_url)</p></li>
				<li>Extract the <strong class="source-inline">rej</strong> column using <strong class="source-inline">.pop()</strong> and save it into a variable called <strong class="source-inline">y</strong>:<p class="source-code">y = df.pop('rej')</p></li>
				<li>Split the DataFrame into training and testing sets using <strong class="source-inline">train_test_split()</strong> with <strong class="source-inline">test_size=0.3</strong> and <strong class="source-inline">random_state = 1</strong>:<p class="source-code">X_train, X_test, y_train, y_test = train_test_split\</p><p class="source-code">                                   (df, y, test_size=0.3, \</p><p class="source-code">                                    random_state=1)</p></li>
				<li>Instantiate <strong class="source-inline">RandomForestRegressor</strong> with <strong class="source-inline">random_state=1</strong>, <strong class="source-inline">n_estimators=50</strong>, <strong class="source-inline">max_depth=6</strong>, and <strong class="source-inline">min_samples_leaf=60</strong>:<p class="source-code">rf_model = RandomForestRegressor(random_state=1, \</p><p class="source-code">                                 n_estimators=50, max_depth=6,\</p><p class="source-code">                                 min_samples_leaf=60)</p></li>
				<li>Train the model on the training set using <strong class="source-inline">.fit()</strong>:<p class="source-code">rf_model.fit(X_train, y_train)</p><p>You should get the following output:</p><div id="_idContainer459" class="IMG---Figure"><img src="Images/B15019_09_31.jpg" alt="Figure 9.31: Logs of RandomForest&#13;&#10;" width="913" height="171"/></div><p class="figure-caption">Figure 9.31: Logs of RandomForest</p></li>
				<li>Plot the partial dependence plot using <strong class="source-inline">plot_partial_dependence()</strong> from <strong class="source-inline">sklearn</strong> with the Random Forest model, the testing set, and the index of the <strong class="source-inline">a1pop</strong> column:<p class="source-code">plot_partial_dependence(rf_model, X_test, \</p><p class="source-code">                        features=[df.columns.get_loc('a1pop')])</p><p>You should get the following output:</p><div id="_idContainer460" class="IMG---Figure"><img src="Images/B15019_09_32.jpg" alt="Figure 9.32: Partial dependence plot for a1pop&#13;&#10;" width="991" height="398"/></div><p class="figure-caption">Figure 9.32: Partial dependence plot for a1pop</p><p>This partial dependence plot shows that, on average, the <strong class="source-inline">a1pop</strong> variable doesn't affect the target variable much when its value is below 2, but from there the target increases linearly by 0.04 for each unit increase of <strong class="source-inline">a1pop</strong>. This means if the population size of area 1 is below the value of 2, the risk of churn is almost null. But over this limit, every increment of population size for area 1 increases the chance of churn by <strong class="source-inline">4%</strong>. </p></li>
				<li>Plot the partial dependence plot using <strong class="source-inline">plot_partial_dependence()</strong> from <strong class="source-inline">sklearn</strong> with the Random Forest model, the testing set, and the index of the <strong class="source-inline">temp</strong> column:<p class="source-code">plot_partial_dependence(rf_model, X_test, \</p><p class="source-code">                        features=[df.columns.get_loc('temp')])</p><p>You should get the following output:</p><div id="_idContainer461" class="IMG---Figure"><img src="Images/B15019_09_33.jpg" alt="Figure 9.33: Partial dependence plot for temp&#13;&#10;" width="960" height="403"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.33: Partial dependence plot for temp</p>
			<p>This partial dependence plot shows that, on average, the <strong class="source-inline">temp</strong> variable has a negative linear impact on the target variable: when <strong class="source-inline">temp</strong> increases by 1, the target variable will decrease by 0.12. This means if the temperature increases by a degree, the chance of leaving the queue decreases by 12%.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2DWnSmn">https://packt.live/2DWnSmn</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2DWnUL1">https://packt.live/2DWnUL1</a>.</p>
			<p>You learned how to plot and analyze a partial dependence plot for the <strong class="source-inline">a1pop</strong> and <strong class="source-inline">temp</strong> features. In this exercise, we saw that <strong class="source-inline">a1pop</strong> has a positive linear impact on the target, while <strong class="source-inline">temp</strong> has a negative linear influence.</p>
			<h1 id="_idParaDest-238"><a id="_idTextAnchor237"/>Local Interpretation with LIME </h1>
			<p>After training our model, we usually use it for predicting outcomes on unseen data. The global interpretations we saw earlier, such as model coefficient, variable importance, and the partial dependence plot, gave us a lot of information on the features at an overall level. Sometimes we want to understand what has influenced the model for a specific case to predict a specific outcome. For instance, if your model is to assess the risk of offering credit to a new client, you may want to understand why it rejected the case for a specific lead. This is what local interpretation is for: analyzing a single observation and understanding the rationale behind the model's decision. In this section, we will introduce you to a technique called <strong class="bold">Locally Interpretable Model-Agnostic Explanations</strong> (<strong class="bold">LIME</strong>).</p>
			<p>If we are using a linear model, it is extremely easy to understand the contribution of each variable to the predicted outcome. We just need to look at the coefficients of the model. For instance, the model will learn the following function: <strong class="source-inline">y = 100 + 0.2 * x</strong><span class="subscript">1</span><strong class="source-inline"> + 200 * x</strong><span class="subscript">2</span><strong class="source-inline"> - 180 * x</strong><span class="subscript">3</span>. So, if we received an observation of x<span class="subscript">1</span>=0, x<span class="subscript">2</span>=2 and x<span class="subscript">3</span>=1, we would know the contribution of:</p>
			<ul>
				<li>x<span class="subscript">1</span> was 0.2 * 0 = 0</li>
				<li>x<span class="subscript">2</span> was 200 * 2 = +400</li>
				<li>x<span class="subscript">3</span> was -180 * 1 = -180</li>
			</ul>
			<p>So, the final prediction (100 +0 + 400 -180 = 320) was mainly driven by x<span class="subscript">2</span>. </p>
			<p>But for a nonlinear model, it is quite hard to get such a clear view. LIME is one way to get more visibility in such cases. The underlying logic of LIME is to approximate the original nonlinear model with a linear one. Then, it uses the coefficients of that linear model in order to explain the contribution of each variable, as we just saw in the preceding example. But rather than trying to approximate the entire model for the whole dataset, LIME tries to approximate it locally around the observation you are interested in. LIME uses the trained model to predict new data points near your observation and then fit a linear regression on that predicted data.</p>
			<p>Let's see how we can use it on the Breast Cancer dataset. First, we will load the data and train a Random Forest model:</p>
			<p class="source-code">from sklearn.datasets import load_breast_cancer</p>
			<p class="source-code">from sklearn.model_selection import train_test_split</p>
			<p class="source-code">from sklearn.ensemble import RandomForestClassifier</p>
			<p class="source-code">data = load_breast_cancer()</p>
			<p class="source-code">X, y = data.data, data.target</p>
			<p class="source-code">X_train, X_test, y_train, y_test = train_test_split\</p>
			<p class="source-code">                                   (X, y, test_size=0.3, \</p>
			<p class="source-code">                                    random_state=1)</p>
			<p class="source-code">rf_model = RandomForestClassifier(random_state=168)</p>
			<p class="source-code">rf_model.fit(X_train, y_train)</p>
			<p>The <strong class="source-inline">lime</strong> package is not directly accessible on Google Colab, so we need to manually install it with the following command:</p>
			<p class="source-code">!pip install lime</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer462" class="IMG---Figure">
					<img src="Images/B15019_09_34.jpg" alt="Figure 9.34: Installation logs for the lime package&#13;&#10;" width="1205" height="562"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.34: Installation logs for the lime package</p>
			<p>Once installed, we will instantiate the <strong class="source-inline">LimeTabularExplainer</strong> class by providing the training data, the names of the features, the names of the classes to be predicted, and the task type (in this example, it is <strong class="source-inline">classification</strong>):</p>
			<p class="source-code">from lime.lime_tabular import LimeTabularExplainer</p>
			<p class="source-code">lime_explainer = LimeTabularExplainer\</p>
			<p class="source-code">                 (X_train, feature_names=data.feature_names,\</p>
			<p class="source-code">                 class_names=data.target_names,\</p>
			<p class="source-code">                 mode='classification')</p>
			<p>Then, we will call the <strong class="source-inline">.explain_instance()</strong> method with the observations we are interested in (here, it will be the second observation from the testing set) and the function that will predict the outcome probabilities (here, it is <strong class="source-inline">.predict_proba()</strong>). Finally, we will call the <strong class="source-inline">.show_in_notebook()</strong> method to display the results from <strong class="source-inline">lime</strong>:</p>
			<p class="source-code">exp = lime_explainer.explain_instance\</p>
			<p class="source-code">      (X_test[1], rf_model.predict_proba, num_features=10)</p>
			<p class="source-code">exp.show_in_notebook()</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer463" class="IMG---Figure">
					<img src="Images/B15019_09_35.jpg" alt="Figure 9.35: Output of LIME&#13;&#10;" width="1289" height="486"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.35: Output of LIME</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Your output may differ slightly. This is due to the random sampling process of LIME.</p>
			<p>There is a lot of information in the preceding output. Let's go through it a bit at a time. The left-hand side shows the prediction probabilities for the two classes of the target variable. For this observation, the model thinks there is a 0.85 probability that the predicted value will be malignant:</p>
			<div>
				<div id="_idContainer464" class="IMG---Figure">
					<img src="Images/B15019_09_36.jpg" alt="Figure 9.36: Prediction probabilities from LIME&#13;&#10;" width="1238" height="121"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.36: Prediction probabilities from LIME</p>
			<p>The right-hand side shows the value of each feature for this observation. Each feature is color-coded to highlight its contribution toward the possible classes of the target variable. The list sorts the features by decreasing importance. In this example, the mean perimeter, mean area, and area error contributed to the model to increase the probability toward class 1. All the other features influenced the model to predict outcome 0:</p>
			<div>
				<div id="_idContainer465" class="IMG---Figure">
					<img src="Images/B15019_09_37.jpg" alt="Figure 9.37: Value of the feature for the observation of interest&#13;&#10;" width="677" height="301"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.37: Value of the feature for the observation of interest</p>
			<p>Finally, the central part shows how each variable contributed to the final prediction. In this example, the <strong class="source-inline">worst concave points</strong> and <strong class="source-inline">worst compactness</strong> variables led to an increase of, respectively, 0.10 and 0.05 probability in predicting outcome 0. On the other hand, <strong class="source-inline">mean perimeter</strong> and <strong class="source-inline">mean area</strong> both contributed to an increase of 0.03 probability of predicting class 1:</p>
			<div>
				<div id="_idContainer466" class="IMG---Figure">
					<img src="Images/B15019_09_38.jpg" alt="Figure 9.38: Contribution of each feature to the final prediction&#13;&#10;" width="679" height="426"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.38: Contribution of each feature to the final prediction</p>
			<p>It's as simple as that. With LIME, we can easily see how each variable impacted the probabilities of predicting the different outcomes of the model. As you saw, the LIME package not only computes the local approximation but also provides a visual representation of its results. It is much easier to interpret than looking at raw outputs. It is also very useful for presenting your findings and illustrating how different features influenced the prediction of a single observation. </p>
			<h2 id="_idParaDest-239"><a id="_idTextAnchor238"/>Exercise 9.05: Local Interpretation with LIME</h2>
			<p>In this exercise, we will analyze some predictions from a Random Forest classifier model trained to predict the customer drop-out ratio using LIME.</p>
			<p>We will be using the same dataset as in the previous exercise.</p>
			<ol>
				<li value="1">Open a new Colab notebook.</li>
				<li>Import the following packages: <strong class="source-inline">pandas</strong>, <strong class="source-inline">train_test_split</strong> from <strong class="source-inline">sklearn.model_selection</strong>, and <strong class="source-inline">RandomForestRegressor</strong> from <strong class="source-inline">sklearn.ensemble</strong>:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.ensemble import RandomForestRegressor</p></li>
				<li>Create a variable called <strong class="source-inline">file_url</strong> that contains the URL of the dataset:<p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/The-Data-Science-Workshop/'\</p><p class="source-code">           'master/Chapter09/Dataset/phpYYZ4Qc.csv'</p></li>
				<li>Load the dataset into a DataFrame called <strong class="source-inline">df</strong> using <strong class="source-inline">.read_csv()</strong>:<p class="source-code">df = pd.read_csv(file_url)</p></li>
				<li>Extract the <strong class="source-inline">rej</strong> column using <strong class="source-inline">.pop()</strong> and save it into a variable called <strong class="source-inline">y</strong>:<p class="source-code">y = df.pop('rej')</p></li>
				<li>Split the DataFrame into training and testing sets using <strong class="source-inline">train_test_split()</strong> with <strong class="source-inline">test_size=0.3</strong> and <strong class="source-inline">random_state = 1</strong>:<p class="source-code">X_train, X_test, y_train, y_test = train_test_split\</p><p class="source-code">                                   (df, y, test_size=0.3, \</p><p class="source-code">                                    random_state=1)</p></li>
				<li>Instantiate <strong class="source-inline">RandomForestRegressor</strong> with <strong class="source-inline">random_state=1</strong>, <strong class="source-inline">n_estimators=50</strong>, <strong class="source-inline">max_depth=6</strong>, and <strong class="source-inline">min_samples_leaf=60</strong>:<p class="source-code">rf_model = RandomForestRegressor(random_state=1, \</p><p class="source-code">                                 n_estimators=50, max_depth=6,\</p><p class="source-code">                                 min_samples_leaf=60)</p></li>
				<li>Train the model on the training set using <strong class="source-inline">.fit()</strong>:<p class="source-code">rf_model.fit(X_train, y_train)</p><p>You should get the following output:</p><div id="_idContainer467" class="IMG---Figure"><img src="Images/B15019_09_39.jpg" alt="Figure 9.39: Logs of RandomForest&#13;&#10;" width="903" height="167"/></div><p class="figure-caption">Figure 9.39: Logs of RandomForest</p></li>
				<li>Install the lime package using the <strong class="source-inline">!pip</strong> install command:<p class="source-code">!pip install lime</p></li>
				<li>Import <strong class="source-inline">LimeTabularExplainer</strong> from <strong class="source-inline">lime.lime_tabular</strong>:<p class="source-code">from lime.lime_tabular import LimeTabularExplainer</p></li>
				<li>Instantiate <strong class="source-inline">LimeTabularExplainer</strong> with the training set and <strong class="source-inline">mode='regression'</strong>:<p class="source-code">lime_explainer = LimeTabularExplainer\</p><p class="source-code">                 (X_train.values, \</p><p class="source-code">                  feature_names=X_train.columns, \</p><p class="source-code">                  mode='regression')</p></li>
				<li>Display the LIME analysis on the first row of the testing set using <strong class="source-inline">.explain_instance()</strong> and <strong class="source-inline">.show_in_notebook()</strong>:<p class="source-code">exp = lime_explainer.explain_instance\</p><p class="source-code">      (X_test.values[0], rf_model.predict)</p><p class="source-code">exp.show_in_notebook()</p><p>You should get the following output:</p><div id="_idContainer468" class="IMG---Figure"><img src="Images/B15019_09_40.jpg" alt="Figure 9.40: LIME output for the first observation of the testing set&#13;&#10;" width="1218" height="357"/></div><p class="figure-caption">Figure 9.40: LIME output for the first observation of the testing set</p><p>This output shows that the predicted value for this observation is a 0.02 chance of customer drop-out and it has been mainly influenced by the <strong class="source-inline">a1pop</strong>, <strong class="source-inline">a3pop</strong>, <strong class="source-inline">a2pop</strong>, and <strong class="source-inline">b2eff</strong> features. For instance, the fact that <strong class="source-inline">a1pop</strong> was under 0.87 has decreased the value of the target variable by 0.01.</p></li>
				<li>Display the LIME analysis on the third row of the testing set using <strong class="source-inline">.explain_instance()</strong> and <strong class="source-inline">.show_in_notebook()</strong>:<p class="source-code">exp = lime_explainer.explain_instance\</p><p class="source-code">      (X_test.values[2], rf_model.predict)</p><p class="source-code">exp.show_in_notebook()</p><p>You should get the following output:</p><p> </p><div id="_idContainer469" class="IMG---Figure"><img src="Images/B15019_09_41.jpg" alt="Figure 9.41: LIME output for the third observation of the testing set&#13;&#10;" width="1289" height="360"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.41: LIME output for the third observation of the testing set</p>
			<p>This output shows that the predicted value for this observation is a 0.09 chance of customer drop-out and it has been mainly influenced by the <strong class="source-inline">a2pop</strong>, <strong class="source-inline">a3pop</strong>, <strong class="source-inline">a1pop</strong>, and <strong class="source-inline">b1eff</strong> features. For instance, the fact that <strong class="source-inline">b1eff</strong> was under 0.87 has increased the value of the target variable by 0.01. The <strong class="source-inline">b1eff</strong> feature represents the level of efficiency of bank 1, so the results from LIME are telling us that the chance of customers leaving increases if this level of efficiency goes lower than 0.87.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2Q5i3Fp">https://packt.live/2Q5i3Fp</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/327Nl3Z">https://packt.live/327Nl3Z</a>.</p>
			<p>You have completed the last exercise of this chapter. You saw how to use LIME to interpret the prediction of single observations. We learned that the <strong class="source-inline">a1pop</strong>, <strong class="source-inline">a2pop</strong>, and <strong class="source-inline">a3pop</strong> features have a strong negative impact on the first and third observations of the training set. </p>
			<h2 id="_idParaDest-240"><a id="_idTextAnchor239"/>Activity 9.01: Train and Analyze a Network Intrusion Detection Model</h2>
			<p>You are working for a cybersecurity company and you have been tasked with building a model that can recognize network intrusion then analyze its feature importance, plot partial dependence, and perform local interpretation on a single observation using LIME.</p>
			<p>The dataset provided contains data from 7 weeks of network traffic.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset used in this activity is from KDD Cup 1999:</p>
			<p class="callout"><a href="https://packt.live/2tFKUIV">https://packt.live/2tFKUIV</a>.</p>
			<p class="callout">The CSV version of this dataset can be found here: </p>
			<p class="callout"><a href="https://packt.live/2RyVsBm">https://packt.live/2RyVsBm</a>.</p>
			<p>The following steps will help you to complete this activity:</p>
			<ol>
				<li value="1">Download and load the dataset using <strong class="source-inline">.read_csv()</strong> from <strong class="source-inline">pandas</strong>.</li>
				<li>Extract the response variable using <strong class="source-inline">.pop()</strong> from <strong class="source-inline">pandas</strong>.</li>
				<li>Split the dataset into training and test sets using <strong class="source-inline">train_test_split()</strong> from <strong class="source-inline">sklearn.model_selection</strong>.</li>
				<li>Create a function that will instantiate and fit <strong class="source-inline">RandomForestClassifier</strong> using <strong class="source-inline">.fit()</strong> from <strong class="source-inline">sklearn.ensemble</strong>.</li>
				<li>Create a function that will predict the outcome for the training and testing sets using <strong class="source-inline">.predict()</strong>.</li>
				<li>Create a function that will print the accuracy score for the training and testing sets using <strong class="source-inline">accuracy_score()</strong> from <strong class="source-inline">sklearn.metrics</strong>.</li>
				<li>Compute the feature importance via permutation with <strong class="source-inline">feature_importance_permutation()</strong> and display it on a bar chart using <strong class="source-inline">altair</strong>.</li>
				<li>Plot the partial dependence plot using <strong class="source-inline">plot_partial_dependence</strong> on the <strong class="source-inline">src_bytes</strong> variable.</li>
				<li>Install <strong class="source-inline">lime</strong> using <strong class="source-inline">!pip install</strong>.</li>
				<li>Perform a LIME analysis on row <strong class="source-inline">99893</strong> with <strong class="source-inline">explain_instance()</strong>.<p>The output should be as follows:</p><div id="_idContainer470" class="IMG---Figure"><img src="Images/B15019_09_42.jpg" alt="Figure 9.42: Output for LIME analysis&#13;&#10;" width="1079" height="346"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.42: Output for LIME analysis</p>
			<p>You have successfully trained a Random Forest model to predict the type of network connection. You have also analyzed which features are the most important for this Random Forest model and learned that it mainly relies on the <strong class="source-inline">src_bytes</strong> feature. We also analyzed the partial dependence plot for this feature in order to understand its impact on the <strong class="source-inline">normal</strong> class. Finally, we used LIME to analyze a single observation and found out which variables led to the predicted outcome.</p>
			<h1 id="_idParaDest-241"><a id="_idTextAnchor240"/>Summary</h1>
			<p>In this chapter, we learned a few techniques for interpreting machine learning models. We saw that there are techniques that are specific to the model used: coefficients for linear models and variable importance for tree-based models. There are also some methods that are model-agnostic, such as variable importance via permutation. </p>
			<p>All these techniques are global interpreters, which look at the entire dataset and analyze the overall contribution of each variable to predictions. We can use this information not only to identify which variables have the most impact on predictions but also to shortlist them. Rather than keeping all features available from a dataset, we can just keep the ones that have a stronger influence. This can significantly reduce the computation time for training a model or calculating predictions. </p>
			<p>We also went through a local interpreter scenario with LIME, which analyzes a single observation. It helped us to better understand the decisions made by the model in predicting the final outcome for a given case. This is a very powerful tool to assess whether a model is biased toward a specific variable that could contain sensitive information such as personal details or demographic data. We can also use it to compare two different observations and understand the rationale for getting different outcomes from the model.</p>
			<p>In the next chapter, we will be focusing on analyzing a dataset and will learn exploratory data analysis and data visualization techniques to get a good understanding of the information it contains.</p>
		</div>
		<div>
			<div id="_idContainer472" class="Content">
			</div>
		</div>
		<div>
			<div id="_idContainer473" class="Content">
			</div>
		</div>
	</div></body></html>