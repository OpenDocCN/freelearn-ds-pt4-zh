<html><head></head><body><div id="sbo-rt-content"><div>
			<div id="_idContainer636" class="Content">
			</div>
		</div>
		<div id="_idContainer637" class="Content">
			<h1 id="_idParaDest-285"><a id="_idTextAnchor284"/>13. Imbalanced Datasets</h1>
		</div>
		<div id="_idContainer664" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">By the end of this chapter, you will be able to identify use cases where datasets are likely to be imbalanced; formulate strategies for dealing with imbalanced datasets; build classification models, such as logistic regression models, after balancing datasets; and analyze classification metrics to validate whether adopted strategies are yielding the desired results.</p>
			<p class="callout">In this chapter, you will be dealing with imbalanced datasets, which are very prevalent in real-life scenarios. You will be using techniques such as <strong class="source-inline">SMOTE</strong>, <strong class="source-inline">MSMOTE</strong>, and random undersampling to address imbalanced datasets.</p>
			<h1 id="_idParaDest-286"><a id="_idTextAnchor285"/>Introduction</h1>
			<p>In the previous chapter, <em class="italic">Chapter 12</em>, <em class="italic">Feature Engineering</em>, where we dealt with data points related to dates, we were addressing scenarios pertaining to features. In this chapter, we will deal with scenarios where the proportions of examples in the overall dataset pose challenges. </p>
			<p>Let's revisit the dataset we dealt with in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification</em>, in which the examples pertaining to 'No' for term deposits far outnumbered the ones with 'Yes' with a ratio of 88% to 12%. We also determined that one reason for suboptimal results with a logistic regression model on that dataset was the skewed proportion of examples. Datasets like the one we analyzed in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification,</em> which are called imbalanced datasets, are very common in real-world use cases.</p>
			<p>Some of the use cases where we encounter imbalanced datasets include the following:</p>
			<ul>
				<li>Fraud detection for credit cards or insurance claims</li>
				<li>Medical diagnoses where we must detect the presence of rare diseases</li>
				<li>Intrusion detection in networks</li>
			</ul>
			<p>In all of these use cases, we can see that what we really want to detect will be minority cases. For instance, in domains such as the medical diagnosis of rare diseases, examples where rare diseases exist could even be less than 1% of the total examples. One inherent characteristic of use cases with imbalanced datasets is that the quality of the classifier is not apparent if the right metric is not used. This makes the problem of imbalanced datasets really challenging. </p>
			<p>In this chapter, we will discuss strategies for identifying imbalanced datasets and ways to mitigate the effects of imbalanced datasets.</p>
			<h1 id="_idParaDest-287"><a id="_idTextAnchor286"/>Understanding the Business Context</h1>
			<p>The business head of the bank for which you are working as a data scientist recently raised the alarm about the results of the term deposit propensity model that you built in<em class="italic"> Chapter 3</em>, <em class="italic">Binary Classification</em>. It has been observed that a large proportion of customers who were identified as potential cases for targeted marketing for term deposits have turned down the offer. This has made a big dent in the sales team's metrics on upselling and cross-selling. The business team urgently requires your help in fixing the issue to meet the required sales targets for the quarter. Don't worry, though – this is the problem that we will be solving later in this chapter. </p>
			<p>First, we begin with an analysis of the issue.</p>
			<h2 id="_idParaDest-288"><a id="_idTextAnchor287"/>Exercise 13.01: Benchmarking the Logistic Regression Model on the Dataset</h2>
			<p>In this exercise, we will be analyzing the problem of predicting whether a customer will buy a term deposit. For this, you will be fitting a logistic regression model, as you did in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification</em>, and you will look closely at the metrics:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset you will be using in this exercise can be found on our GitHub repository: <a href="https://packt.live/2twFgIM">https://packt.live/2twFgIM</a>.</p>
			<ol>
				<li>Open a new notebook in Google Colab.</li>
				<li>Next, import <strong class="source-inline">pandas</strong> and load the data from the GitHub repository:<p class="source-code">import pandas as pd</p><p class="source-code">filename = 'https://raw.githubusercontent.com/PacktWorkshops'\</p><p class="source-code">           '/The-Data-Science-Workshop/master/'\</p><p class="source-code">           'Chapter13/Dataset/bank-full.csv'</p></li>
				<li>Now, load the data using <strong class="source-inline">pandas</strong><p class="source-code">#Loading the data using pandas</p><p class="source-code">bankData = pd.read_csv(filename,sep=";")</p><p class="source-code">bankData.head()</p><p>Your output would be as follows:</p><div id="_idContainer638" class="IMG---Figure"><img src="Images/B15019_13_01.jpg" alt="Figure 13.1: The first 5 rows of bankData&#13;&#10;" width="1447" height="243"/></div><p class="figure-caption">Figure 13.1: The first 5 rows of bankData</p><p>Now, to break the dataset down further, let's perform some feature-engineering steps. </p></li>
				<li>Normalize the numerical features (age, balance, and duration) through scaling, which was covered in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification</em>. Enter the following code:<p class="source-code">from sklearn.preprocessing import RobustScaler</p><p class="source-code">rob_scaler = RobustScaler()</p><p>In the preceding code snippet, we used a scaling function called <strong class="source-inline">RobustScaler()</strong> to scale the numerical data. <strong class="source-inline">RobustScaler()</strong> is a scaling function similar to <strong class="source-inline">MinMaxScaler</strong> in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification</em>. </p></li>
				<li>After scaling the numerical data, we convert each of the columns to a scaled version, as in the following code snippet: <p class="source-code"># Converting each of the columns to scaled version</p><p class="source-code">bankData['ageScaled'] = rob_scaler.fit_transform\</p><p class="source-code">                        (bankData['age'].values.reshape(-1,1))</p><p class="source-code">bankData['balScaled'] = rob_scaler.fit_transform\</p><p class="source-code">                        (bankData['balance']\</p><p class="source-code">                         .values.reshape(-1,1))</p><p class="source-code">bankData['durScaled'] = rob_scaler.fit_transform\</p><p class="source-code">                        (bankData['duration']\</p><p class="source-code">                         .values.reshape(-1,1))</p></li>
				<li>Now, drop the original features after we introduce the scaled features using the <strong class="source-inline">.drop()</strong> function: <p class="source-code"># Dropping the original columns</p><p class="source-code">bankData.drop(['age','balance','duration'], \</p><p class="source-code">              axis=1, inplace=True)</p></li>
				<li>Display the first five columns using the <strong class="source-inline">.head()</strong> function:<p class="source-code">bankData.head()</p><p>The output is as follows:</p><div id="_idContainer639" class="IMG---Figure"><img src="Images/B15019_13_02.jpg" alt="Figure 13.2: bankData with scaled features&#13;&#10;" width="1492" height="231"/></div><p class="figure-caption">Figure 13.2: bankData with scaled features</p><p>The categorical features in the dataset must be converted into numerical values by transforming them into dummy values, which was covered in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification</em>. </p></li>
				<li>Convert all the categorical variables to dummy variables using the <strong class="source-inline">.get_dummies()</strong> function:<p class="source-code">bankCat = pd.get_dummies(bankData[['job','marital','education',\</p><p class="source-code">                                   'default','housing','loan',\</p><p class="source-code">                                   'contact','month',\</p><p class="source-code">                                   'poutcome']])</p></li>
				<li>Separate the numerical data and observe the shape:<p class="source-code">bankNum = bankData[['ageScaled','balScaled','day',\</p><p class="source-code">                    'durScaled','campaign','pdays','previous']]</p><p class="source-code">bankNum.shape</p><p>The output would be as follows:</p><p class="source-code">(45211, 7)</p><p>After the categorical values are transformed, they must be combined with the scaled numerical values of the data frame to get the feature-engineered dataset. </p></li>
				<li>Create the independent variables, <strong class="source-inline">X</strong>, and dependent variables, <strong class="source-inline">Y</strong>, from the combined dataset for modeling, as in the following code snippet:<p class="source-code"># Merging with the original data frame</p><p class="source-code"># Preparing the X variables</p><p class="source-code">X = pd.concat([bankCat, bankNum], axis=1)</p><p class="source-code">print(X.shape)</p><p class="source-code"># Preparing the Y variable</p><p class="source-code">Y = bankData['y']</p><p class="source-code">print(Y.shape)</p><p class="source-code">X.head()</p><p>The output is as follows: </p><div id="_idContainer640" class="IMG---Figure"><img src="Images/B15019_13_03.jpg" alt="Figure 13.3: The independent variables and the combined data (truncated)&#13;&#10;" width="1394" height="320"/></div><p class="figure-caption">Figure 13.3: The independent variables and the combined data (truncated)</p><p>We are now ready for the modeling task. Let's first import the necessary packages.</p></li>
				<li>Now, <strong class="source-inline">import</strong> the necessary functions of <strong class="source-inline">train_test_split()</strong> and <strong class="source-inline">LogisticRegression</strong> from <strong class="source-inline">sklearn</strong>:<p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.linear_model import LogisticRegression</p></li>
				<li>Split the data into train and test sets at a <strong class="bold">70:30</strong> ratio using the <strong class="source-inline">test_size = 0.3</strong> variable in the splitting function. We also set <strong class="source-inline">random_state</strong> for the reproducibility of the code:<p class="source-code">X_train, X_test, y_train, y_test = train_test_split\</p><p class="source-code">                                   (X, Y, test_size=0.3, \</p><p class="source-code">                                    random_state=123)</p></li>
				<li>Now, fit the model using <strong class="source-inline">.fit</strong> on the training data:<p class="source-code"># Defining the LogisticRegression function</p><p class="source-code">bankModel = LogisticRegression()</p><p class="source-code">bankModel.fit(X_train, y_train)</p><p>Your output should be as follows: </p><div id="_idContainer641" class="IMG---Figure"><img src="Images/B15019_13_04.jpg" alt="Figure 13.4: Fitting the model&#13;&#10;" width="1349" height="295"/></div><p class="figure-caption">Figure 13.4: Fitting the model</p><p>Now that the model is fit, let's now predict the test set and generate the metrics. </p></li>
				<li>Next, find the prediction on the test set and print the accuracy scores:<p class="source-code">pred = bankModel.predict(X_test)</p><p class="source-code">print('Accuracy of Logistic regression model prediction on '\</p><p class="source-code">      'test set: {:.2f}'\</p><p class="source-code">      .format(bankModel.score(X_test, y_test)))</p><p>You should get the following output:</p><p class="source-code">Accuracy of Logistic regression model prediction on test set: 0.90</p></li>
				<li>Now, use both the <strong class="source-inline">confusion_matrix()</strong> and <strong class="source-inline">classification_report()</strong> functions to generate the metrics for further analysis, which we will cover in the <em class="italic">Analysis of the Result</em> section:<p class="source-code"># Confusion Matrix for the model</p><p class="source-code">from sklearn.metrics import confusion_matrix</p><p class="source-code">confusionMatrix = confusion_matrix(y_test, pred)</p><p class="source-code">print(confusionMatrix)</p><p class="source-code">from sklearn.metrics import classification_report</p><p class="source-code">print(classification_report(y_test, pred))</p><p>You should get the following output:</p><div id="_idContainer642" class="IMG---Figure"><img src="Images/B15019_13_05.jpg" alt="Figure 13.5: Metrics showing the accuracy result along with the confusion matrix&#13;&#10;" width="623" height="224"/></div></li>
			</ol>
			<p class="figure-caption">Figure 13.5: Metrics showing the accuracy result along with the confusion matrix</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You will get metrics similar to the following. However, the values will vary due to the variability in the modeling process.</p>
			<p>In this exercise, we have found a report that may have caused the issue with the number of customers expected to purchase the term deposit plan. From the metrics, we can see that the number of values for <strong class="source-inline">No</strong> is relatively higher than that for <strong class="source-inline">Yes</strong>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3hapnvB">https://packt.live/3hapnvB</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hh6Xta">https://packt.live/3hh6Xta</a>.</p>
			<p>To understand more about the reasons behind the skewed results, we will analyze these metrics in detail in the following section.</p>
			<h2 id="_idParaDest-289"><a id="_idTextAnchor288"/>Analysis of the Result</h2>
			<p>To analyze the results obtained in the previous section, let's expand the confusion matrix in the form: </p>
			<div>
				<div id="_idContainer643" class="IMG---Figure">
					<img src="Images/B15019_13_06.jpg" alt="Figure 13.6: Confusion matrix of the resulting metrics obtained&#13;&#10;" width="1665" height="285"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.6: Confusion matrix of the resulting metrics obtained</p>
			<p>We enter the values <strong class="source-inline">11707</strong>, <strong class="source-inline">291</strong>, <strong class="source-inline">1060</strong>, and <strong class="source-inline">506</strong> from the output we got from the previous exercise. We then place these values as shown in the diagram. We will represent the propensity to take a term deposit (<strong class="source-inline">No</strong>) as the positive class and the other as the negative class. So, from the confusion matrix, we can calculate the accuracy measures, which were covered in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification</em>. The accuracy of the model is given by:</p>
			<div>
				<div id="_idContainer644" class="IMG---Figure">
					<img src="Images/B15019_13_07.jpg" alt="Figure 13.7: Accuracy of a model&#13;&#10;" width="1352" height="115"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.7: Accuracy of a model</p>
			<p>In our case, it will be (11707 + 506) / (11707 + 1060 + 291 + 506), or 90%. </p>
			<p>From the accuracy perspective, the model would seem like it is doing a reasonable job. However, the reality might be quite different. To find out what's really the case, let's look at the precision and recall values, which are available from the classification report we obtained. The formulae for precision for any class was covered in <em class="italic">Chapter 3</em>, <em class="italic">Binary Classification</em></p>
			<p>The precision value of any class is given by:</p>
			<div>
				<div id="_idContainer645" class="IMG---Figure">
					<img src="Images/B15019_13_08.jpg" alt="Figure 13.8: Precision of a model&#13;&#10;" width="1295" height="113"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.8: Precision of a model</p>
			<p>In our case, for the positive class, the precision is <em class="italic">TP/(TP + FP)</em>, which is 11707/ (11707 + 1060), which comes to approximately 92%. </p>
			<p>In the case of the negative class, the precision could be written as <em class="italic">TN / (TN + FN)</em>, which is 506 / (506 + 291), which comes to approximately 63%.</p>
			<p>Similarly, the recall value for any class can be represented as follows:</p>
			<div>
				<div id="_idContainer646" class="IMG---Figure">
					<img src="Images/B15019_13_09.jpg" alt="Figure 13.9: Recalling a model&#13;&#10;" width="1327" height="115"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.9: Recalling a model</p>
			<p>The recall value for the positive class, <em class="italic">TP / (TP + FN)</em> = 11707 / (11707 + 291), comes to approximately 98%. </p>
			<p>The recall value for the negative class, <em class="italic">TN / (TN + FP)</em> = 506 / (506 + 1060), comes to approximately 32%.</p>
			<p>Recall indicates the ability of the classifier to correctly identify the respective classes. From the metrics, we see that the model that we built does a good job of identifying the positive classes, but does a very poor job of correctly identifying the negative class. </p>
			<p>Why do you think that the classifier is biased toward one class? The answer to this can be unearthed by looking at the class balance in the training set. </p>
			<p>The following code will generate the percentages of the classes in the training data:</p>
			<p class="source-code">print('Percentage of negative class :',\</p>
			<p class="source-code">      (y_train[y_train=='yes'].value_counts()\</p>
			<p class="source-code">       /len(y_train) ) * 100)</p>
			<p class="source-code">print('Percentage of positive class :',\</p>
			<p class="source-code">      (y_train[y_train=='no'].value_counts()\</p>
			<p class="source-code">       /len(y_train) ) * 100)</p>
			<p>You should get the following output:</p>
			<p class="source-code">Percentage of negative class: yes    11.764148</p>
			<p class="source-code">Name: y, dtype: float64</p>
			<p class="source-code">Percentage of positive class: no    88.235852</p>
			<p class="source-code">Name: y, dtype: float64</p>
			<p>From this, we can see that the majority of the training set (88%) is made up of the positive class. This imbalance is one of the major reasons behind the poor metrics that we have had with the logistic regression classifier we have selected. </p>
			<p>Now, let's look at the challenges of imbalanced datasets.</p>
			<h1 id="_idParaDest-290"><a id="_idTextAnchor289"/>Challenges of Imbalanced Datasets</h1>
			<p>As seen from the classifier example, one of the biggest challenges with imbalanced datasets is the bias toward the majority class, which ended up being 88% in the previous example. This will result in suboptimal results. However, what makes such cases even more challenging is the deceptive nature of results if the right metric is not used. </p>
			<p>Let's take, for example, a dataset where the negative class is around 99% and the positive class is 1% (as in a use case where a rare disease has to be detected, for instance). </p>
			<p>Have a look at the following code snippet:</p>
			<p class="source-code">Data set Size: 10,000 examples</p>
			<p class="source-code">Negative class : 9910</p>
			<p class="source-code">Positive Class : 90</p>
			<p>Suppose we had a poor classifier that was capable of only predicting the negative class; we would get the following confusion matrix:</p>
			<div>
				<div id="_idContainer647" class="IMG---Figure">
					<img src="Images/B15019_13_10.jpg" alt="Figure 13.10: Confusion matrix of the poor classifier&#13;&#10;" width="1003" height="302"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.10: Confusion matrix of the poor classifier</p>
			<p>From the confusion matrix, let's calculate the accuracy measures. Have a look at the following code snippet:</p>
			<p class="source-code"># Classifier biased to only negative class</p>
			<p class="source-code">Accuracy = (TP + TN ) / ( TP + FP + FN + TN)</p>
			<p class="source-code"> = (0 + 9900) / ( 0 + 0 + 90 + 9900) = 9900/10000</p>
			<p class="source-code"> = 99%</p>
			<p>With such a classifier, if we were to use a metric such as accuracy, we still would get a result of around 99%, which, in normal circumstances, would look outstanding. However, in this case, the classifier is doing a bad job. Think of the real-life impact of using such a classifier and a metric such as accuracy. The impact on patients who have rare diseases and who get wrongly classified as not having the disease could be fatal. </p>
			<p>Therefore, it is important to identify cases with imbalanced datasets and equally important to pick the right metric for analyzing such datasets. The right metric in this example would have been to look at the recall values for both the classes:</p>
			<p class="source-code">Recall Positive class  = TP / ( TP + FN ) = 0 / ( 0 + 90)</p>
			<p class="source-code"> = 0</p>
			<p class="source-code">Recall Negative Class = TN / ( TN + FP) = 9900 / ( 9900 + 0)</p>
			<p class="source-code">= 100%</p>
			<p>From the recall values, we could have identified the bias of the classifier toward the majority class, prompting us to look at strategies for mitigating such biases, which is the next topic we will focus on.</p>
			<h1 id="_idParaDest-291"><a id="_idTextAnchor290"/>Strategies for Dealing with Imbalanced Datasets</h1>
			<p>Now that we have identified the challenges of imbalanced datasets, let's look at strategies for combatting imbalanced datasets: </p>
			<div>
				<div id="_idContainer648" class="IMG---Figure">
					<img src="Images/B15019_13_11.jpg" alt="Figure 13.11: Strategies for dealing with imbalanced datasets&#13;&#10;" width="839" height="627"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.11: Strategies for dealing with imbalanced datasets</p>
			<h2 id="_idParaDest-292"><a id="_idTextAnchor291"/>Collecting More Data</h2>
			<p>Having encountered an imbalanced dataset, one of the first questions you need to ask is whether it is possible to get more data. This might appear naïve, but collecting more data, especially from the minority class, and then balancing the dataset should be the first strategy for addressing the class imbalance. </p>
			<h2 id="_idParaDest-293"><a id="_idTextAnchor292"/>Resampling Data</h2>
			<p>In many circumstances, collecting more data, especially from minority classes, can be challenging as data points for the minority class will be very minimal. In such circumstances, we need to adopt different strategies to work with our constraints and still strive to balance our dataset. One effective strategy is to resample our dataset to make the dataset more balanced. Resampling would mean taking samples from the available dataset to create a new dataset, thereby making the new dataset balanced. </p>
			<p>Let's look at the idea in detail:</p>
			<div>
				<div id="_idContainer649" class="IMG---Figure">
					<img src="Images/B15019_13_12.jpg" alt="Figure 13.12: Random undersampling of the majority class&#13;&#10;" width="1454" height="527"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.12: Random undersampling of the majority class</p>
			<p>As seen in <em class="italic">Figure 13.8</em>, the idea behind resampling is to randomly pick samples from the majority class to make the final dataset more balanced. In the diagram, we can see that the minority class has the same number of examples as the original dataset and that the majority class is under-sampled to make the final dataset more balanced. Resampling examples of this type is called random undersampling as we are undersampling the majority class. We will perform random undersampling in the following exercise.</p>
			<h2 id="_idParaDest-294"><a id="_idTextAnchor293"/>Exercise 13.02: Implementing Random Undersampling and Classification on Our Banking Dataset to Find the Optimal Result</h2>
			<p>In this exercise, you will undersample the majority class (propensity <strong class="source-inline">'No'</strong>) and then make the dataset balanced. On the new balanced dataset, you will fit a logistic regression model and then analyze the results:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset you will be using in this exercise can be found on our GitHub repository: <a href="https://packt.live/2twFgIM">https://packt.live/2twFgIM</a>.</p>
			<ol>
				<li value="1">Open a new Colab notebook for this exercise.</li>
				<li>Perform the initial 12 steps of <em class="italic">Exercise 13.01</em>, <em class="italic">Benchmarking the Logistic Regression Model on the Dataset</em>, such that the dataset is split into training and testing sets.</li>
				<li>Now, join the <strong class="source-inline">X</strong> and <strong class="source-inline">y</strong> variables for the training set before resampling:<p class="source-code">"""</p><p class="source-code">Let us first join the train_x and train_y for ease of operation</p><p class="source-code">"""</p><p class="source-code">trainData = pd.concat([X_train,y_train],axis=1)</p><p>In this step, we concatenated the <strong class="source-inline">X_train</strong> and <strong class="source-inline">y_train</strong> datasets to one single dataset. This is done to make the resampling process in the subsequent steps easier. To concatenate the two datasets, we use the <strong class="source-inline">.concat()</strong> function from <strong class="source-inline">pandas</strong>. In the code, we use <strong class="source-inline">axis = 1</strong> to indicate that the concatenation is done horizontally, which is along the columns.</p></li>
				<li>Now, display the new data with the <strong class="source-inline">.head()</strong> function:<p class="source-code">trainData.head()</p><p>You should get the following output</p><div id="_idContainer650" class="IMG---Figure"><img src="Images/B15019_13_13.jpg" alt="Figure 13.13: Displaying the first five rows of the dataset using .head()&#13;&#10;" width="1239" height="204"/></div><p class="figure-caption">Figure 13.13: Displaying the first five rows of the dataset using .head()</p><p>The preceding output shows some of the columns of the dataset.</p><p>Now, let's move onto separating the minority and majority classes into separate datasets.</p><p>What we will do next is separate the minority class and the majority class. This is required because we have to sample separately from the majority class to make a balanced dataset. To separate the minority class, we have to identify the indexes of the dataset where the dataset has 'yes.' The indexes are identified using <strong class="source-inline">.index()</strong> function. </p><p>Once those indexes are identified, they are separated from the main dataset using the <strong class="source-inline">.loc()</strong> function and stored in a new variable for the minority class. The shape of the minority dataset is also printed. A similar process is followed for the majority class and, after these two steps, we have two datasets: one for the minority class and one for the majority class.</p></li>
				<li>Next, find the indexes of the sample dataset where the propensity is <strong class="source-inline">yes</strong>:<p class="source-code">ind = trainData[trainData['y']=='yes'].index</p><p class="source-code">print(len(ind))</p><p>You should get the following output:</p><p class="source-code">3723</p></li>
				<li>Separate by the minority class as in the following code snippet:<p class="source-code">minData = trainData.loc[ind]</p><p class="source-code">print(minData.shape)</p><p>You should get the following output:</p><p class="source-code">(3723, 52)</p></li>
				<li>Now, find the indexes of the majority class:<p class="source-code">ind1 = trainData[trainData['y']=='no'].index</p><p class="source-code">print(len(ind1))</p><p>You should get the following output:</p><p class="source-code">27924</p></li>
				<li>Separate by the majority class as in the following code snippet:<p class="source-code">majData = trainData.loc[ind1]</p><p class="source-code">print(majData.shape)</p><p class="source-code">majData.head()</p><p>You should get the following output:</p><div id="_idContainer651" class="IMG---Figure"><img src="Images/B15019_13_14.jpg" alt="Figure 13.14: Output after separating the majority classes&#13;&#10;" width="1124" height="229"/></div><p class="figure-caption">Figure 13.14: Output after separating the majority classes</p><p>Once the majority class is separated, we can proceed with sampling from the majority class. Once the sampling is done, the shape of the majority class dataset and its head are printed.</p><p>Take a random sample equal to the length of the minority class to make the dataset balanced.</p></li>
				<li>Extract the samples using the <strong class="source-inline">.sample()</strong> function:<p class="source-code">majSample = majData.sample(n=len(ind),random_state = 123)</p><p>The number of examples that are sampled is equal to the number of examples in the minority class. This is implemented with the parameters <strong class="source-inline">(n=len(ind))</strong>.</p></li>
				<li>Now that sampling is done, the shape of the majority class dataset and its head is printed:<p class="source-code">print(majSample.shape)</p><p class="source-code">majSample.head()</p><p>You should get the following output:</p><div id="_idContainer652" class="IMG---Figure"><img src="Images/B15019_13_15.jpg" alt="Figure 13.15: Output showing the shape of the majority class dataset&#13;&#10;" width="1244" height="227"/></div><p class="figure-caption">Figure 13.15: Output showing the shape of the majority class dataset</p><p>Now, we move onto preparing the new training data</p></li>
				<li>After preparing the individual dataset, we can now concatenate them together using the <strong class="source-inline">pd.concat()</strong> function:<p class="source-code">"""</p><p class="source-code">Concatenating both data sets and then shuffling the data set</p><p class="source-code">"""</p><p class="source-code">balData = pd.concat([minData,majSample],axis = 0)</p><p class="callout-heading">Note</p><p class="callout">In this case, we are concatenating in the vertical direction and, therefore, <strong class="source-inline">axis = 0</strong> is used.</p></li>
				<li>Now, shuffle the dataset so that both the minority and majority classes are evenly distributed using the <strong class="source-inline">shuffle()</strong> function:<p class="source-code"># Shuffling the data set</p><p class="source-code">from sklearn.utils import shuffle</p><p class="source-code">balData = shuffle(balData)</p><p class="source-code">balData.head()</p><p>You should get the following output:</p><div id="_idContainer653" class="IMG---Figure"><img src="Images/B15019_13_16.jpg" alt="Figure 13.16: Output after shuffling the dataset&#13;&#10;" width="1245" height="204"/></div><p class="figure-caption">Figure 13.16: Output after shuffling the dataset</p></li>
				<li>Now, separate the shuffled dataset into the independent variables, <strong class="source-inline">X_trainNew</strong>, and dependent variables, <strong class="source-inline">y_trainNew</strong>. The separation is to be done using the index features <strong class="source-inline">0</strong> to <strong class="source-inline">51</strong> for the dependent variables using the <strong class="source-inline">.iloc()</strong> function in <strong class="source-inline">pandas</strong>. The dependent variables are separated by sub-setting with the column name <strong class="source-inline">'y'</strong>:<p class="source-code"># Making the new X_train and y_train</p><p class="source-code">X_trainNew = balData.iloc[:,0:51]</p><p class="source-code">print(X_trainNew.head())</p><p class="source-code">y_trainNew = balData['y']</p><p class="source-code">print(y_trainNew.head())</p><p>You should get the following output:</p><div id="_idContainer654" class="IMG---Figure"><img src="Images/B15019_13_17.jpg" alt="Figure 13.17: Shuffling the dataset into independent variables&#13;&#10;" width="842" height="328"/></div><p class="figure-caption">Figure 13.17: Shuffling the dataset into independent variables</p><p>Now, fit the model on the new data and generate the confusion matrix and classification report for our analysis.</p></li>
				<li>First, define the <strong class="source-inline">LogisticRegression</strong> function with the following code snippet:<p class="source-code">from sklearn.linear_model import LogisticRegression</p><p class="source-code">bankModel1 = LogisticRegression()</p><p class="source-code">bankModel1.fit(X_trainNew, y_trainNew)</p><p>You should get the following output:</p><div id="_idContainer655" class="IMG---Figure"><img src="Images/B15019_13_18.jpg" alt="Figure 13.18: Fitting the model&#13;&#10;" width="1346" height="301"/></div><p class="figure-caption">Figure 13.18: Fitting the model</p></li>
				<li>Next, perform the prediction on the test with the following code snippet:<p class="source-code">pred = bankModel1.predict(X_test)</p><p class="source-code">print('Accuracy of Logistic regression model prediction on '\</p><p class="source-code">      'test set for balanced data set: {:.2f}'\</p><p class="source-code">      .format(bankModel1.score(X_test, y_test)))</p><p>You should get the following output:</p><p class="source-code">Accuracy of Logistic regression model prediction on test set for balanced data set:0.83</p><p><strong class="source-inline">{:.2f}'.format</strong> is used to print the string values along with the accuracy score, which is output from <strong class="source-inline">bankModel1.score(X_test, y_test)</strong>. In this, <strong class="source-inline">2f</strong> means a numerical score with two decimals.</p></li>
				<li>Now, generate the confusion matrix for the model and print the results:<p class="source-code">from sklearn.metrics import confusion_matrix</p><p class="source-code">confusionMatrix = confusion_matrix(y_test, pred)</p><p class="source-code">print(confusionMatrix)</p><p class="source-code">from sklearn.metrics import classification_report</p><p class="source-code">print(classification_report(y_test, pred))</p><p>You should get the following output:</p><div id="_idContainer656" class="IMG---Figure"><img src="Images/B15019_13_19.jpg" alt="Figure 13.19: Confusion matrix for the model obtained&#13;&#10;" width="1072" height="427"/></div></li>
			</ol>
			<p class="figure-caption">Figure 13.19: Confusion matrix for the model obtained</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The values can vary in the output as the modeling process is subject to variation.</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/348njjY">https://packt.live/348njjY</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/318R81I">https://packt.live/318R81I</a>.</p>
			<h2 id="_idParaDest-295"><a id="_idTextAnchor294"/>Analysis</h2>
			<p>Let's analyze the results and compare them with those of the benchmark logistic regression model that we built at the beginning of this chapter. In the benchmark model, we had the problem of the model being biased toward the majority class with a very low recall value for the <strong class="source-inline">yes</strong> cases.</p>
			<p>Now, by balancing the dataset, we have seen that the recall for the minority class has improved tremendously, from a low of <strong class="source-inline">0.32</strong> to around <strong class="source-inline">0.82</strong>. This means that by balancing the dataset, the classifier has improved its ability to identify negative cases.</p>
			<p>However, we can see that our overall accuracy has taken a hit. From a high of around 90%, it has come down to around 85%. One major area where accuracy has taken a hit is the number of false positives, which are those <strong class="source-inline">No</strong> cases that were wrongly predicted as <strong class="source-inline">Yes</strong>. </p>
			<p>Analyzing the result from a business perspective, this is a much better scenario than the one we got in the benchmark model. In the benchmark model, out of the total 1,566 <strong class="source-inline">Yes</strong> cases, only 506 were correctly identified. However, after balancing, we were able to identify 1,277 out of 1,566 customers from the dataset who were likely to buy term deposits, which can potentially result in a better conversion rate. However, the flip side of this is that the sales team will also have to spend a lot of time on customers who are unlikely to buy term deposits. From the confusion matrix, we can see that false negatives have gone up to 1,795 from the earlier 291 we got in the benchmark model. Ideally, we would want quadrants 2 and 3 to come down in favor of the other two quadrants.</p>
			<h1 id="_idParaDest-296"><a id="_idTextAnchor295"/>Generating Synthetic Samples</h1>
			<p>In the previous section, we looked at the undersampling method, where we downsized the majority class to make the dataset balanced. However, when undersampling, we reduced the size of the dataset. In many circumstances, downsizing the dataset can have adverse effects on the predictive power of the classifier. An effective way to counter the downsizing of the dataset is to oversample the minority class. Oversampling is done by generating new synthetic data points similar to those of the minority class, thereby balancing the dataset. </p>
			<p>Two very popular methods for generating such synthetic points are:</p>
			<ul>
				<li><strong class="bold">Synthetic Minority Oversampling Technique</strong> (<strong class="bold">SMOTE</strong>)</li>
				<li><strong class="bold">Modified SMOTE</strong> (<strong class="bold">MSMOTE</strong>)</li>
			</ul>
			<p>The way the <strong class="source-inline">SMOTE</strong> algorithm generates synthetic data is by looking at the neighborhood of minority classes and generating new data points within the neighborhood:</p>
			<div>
				<div id="_idContainer657" class="IMG---Figure">
					<img src="Images/B15019_13_20.jpg" alt="Figure 13.20: Dataset with two classes&#13;&#10;" width="779" height="342"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.20: Dataset with two classes</p>
			<p>Let's explain the concept of generating synthetic datasets with a pictorial representation. Let's assume that <em class="italic">Figure 13.15</em> represents a dataset with two classes: the grey circles represent the minority class, and the black circles represent the majority class. </p>
			<p>In creating synthetic points, an imaginary line connecting all the minority samples in the neighborhood is created and new data points are generated on this line, as shown in <em class="italic">Figure 13.16</em>, thereby balancing the dataset:</p>
			<div>
				<div id="_idContainer658" class="IMG---Figure">
					<img src="Images/B15019_13_21.jpg" alt="Figure 13.21: Connecting samples in a neighborhood&#13;&#10;" width="836" height="342"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.21: Connecting samples in a neighborhood</p>
			<p>However, <strong class="source-inline">MSMOTE</strong> is an advancement over the <strong class="source-inline">SMOTE</strong> algorithm and has a different approach to generating synthetic points. <strong class="source-inline">MSMOTE</strong> classifies the minority class into three distinct groups: <strong class="bold">security samples</strong>, <strong class="bold">border samples</strong>, and <strong class="bold">latent noise samples</strong>. Different strategies are adopted to generate neighborhood points based on the group each minority class falls into. </p>
			<p>We will see the implementation of both <strong class="source-inline">SMOTE</strong> and <strong class="source-inline">MSMOTE</strong> in the following section.</p>
			<h2 id="_idParaDest-297"><a id="_idTextAnchor296"/>Implementation of SMOTE and MSMOTE</h2>
			<p><strong class="source-inline">SMOTE</strong> and <strong class="source-inline">MSMOTE</strong> can be implemented from a package called <strong class="source-inline">smote-variants</strong> in Python. The library can be installed through <strong class="source-inline">pip install</strong> in the Colab notebook as shown here:</p>
			<p class="source-code">!pip install smote-variants</p>
			<p class="callout-heading">Note</p>
			<p class="callout">More details on the package and its different variations can be obtained at <a href="https://packt.live/2QsNhat">https://packt.live/2QsNhat</a>.</p>
			<p>Let's now implement both these methods and analyze the results.</p>
			<h2 id="_idParaDest-298"><a id="_idTextAnchor297"/>Exercise 13.03: Implementing SMOTE on Our Banking Dataset to Find the Optimal Result</h2>
			<p>In this exercise, we will generate synthetic samples of the minority class using <strong class="source-inline">SMOTE</strong> and then make the dataset balanced. Then, on the new balanced dataset, we will fit a logistic regression model and analyze the results:</p>
			<ol>
				<li value="1">Implement all the steps of <em class="italic">Exercise 13.01</em>, <em class="italic">Benchmarking the Logistic Regression Model on the Dataset</em>, until the splitting of the train and test sets (<em class="italic">Step 12</em>).</li>
				<li>Now, print the count of both the classes before we oversample:<p class="source-code"># Shape before oversampling</p><p class="source-code">print("Before OverSampling count of yes: {}"\</p><p class="source-code">      .format(sum(y_train=='yes')))</p><p class="source-code">print("Before OverSampling count of no: {} \n"\</p><p class="source-code">      .format(sum(y_train=='no')))</p><p>You should get the following output:</p><p class="source-code">Before OverSampling count of yes: 3694</p><p class="source-code">Before OverSampling count of no: 27953</p><p class="callout-heading">Note</p><p class="callout">The counts mentioned in this output can vary because of a variability in the sampling process.</p><p>Next, we will be oversampling the training set using <strong class="source-inline">SMOTE</strong>.</p></li>
				<li>Begin by importing <strong class="source-inline">sv</strong> and <strong class="source-inline">numpy</strong>:<p class="source-code">!pip install smote-variants</p><p class="source-code">import smote_variants as sv</p><p class="source-code">import numpy as np</p><p>The library files that are required for oversampling the training set include the <strong class="source-inline">smote_variants</strong> library, which we installed earlier. This is imported as <strong class="source-inline">sv</strong>. The other library that is required is <strong class="source-inline">numpy</strong>, as the training set will have to be given a <strong class="source-inline">numpy</strong> array for the <strong class="source-inline">smote_variants</strong> library. </p></li>
				<li>Now, instantiate the <strong class="source-inline">SMOTE</strong> library to a variable called <strong class="source-inline">oversampler</strong> using the <strong class="source-inline">sv.SMOTE()</strong> function:<p class="source-code"># Instantiating the SMOTE class</p><p class="source-code">oversampler= sv.SMOTE()</p><p>This is a common way of instantiating any of the variants of <strong class="source-inline">SMOTE</strong> from the <strong class="source-inline">smote_variants</strong> library.</p></li>
				<li>Now, sample the process using the <strong class="source-inline">.sample()</strong> function of <strong class="source-inline">oversampler</strong>:<p class="source-code"># Creating new training set</p><p class="source-code">X_train_os, y_train_os = oversampler.sample\</p><p class="source-code">                         (np.array(X_train), np.array(y_train))</p><p class="callout-heading">Note</p><p class="callout">Both the <strong class="source-inline">X</strong> and <strong class="source-inline">y</strong> variables are converted to <strong class="source-inline">numpy</strong> arrays before applying the <strong class="source-inline">.sample()</strong> function.</p></li>
				<li>Now, print the shapes of the new <strong class="source-inline">X</strong> and <strong class="source-inline">y</strong> variables and the <strong class="source-inline">counts</strong> of the classes. You will note that the size of the overall dataset has increased from the earlier count of around 31,647 (3694 + 27953) to 55,906. The increase in size can be attributed to the fact that the minority class has been oversampled from 3,694 to 27,953:<p class="source-code"># Shape after oversampling</p><p class="source-code">print('After OverSampling, the shape of train_X: {}'\</p><p class="source-code">      .format(X_train_os.shape))</p><p class="source-code">print('After OverSampling, the shape of train_y: {} \n'\</p><p class="source-code">      .format(y_train_os.shape))</p><p class="source-code">print("After OverSampling, counts of label 'Yes': {}"\</p><p class="source-code">      .format(sum(y_train_os=='yes')))</p><p class="source-code">print("After OverSampling, counts of label 'no': {}"\</p><p class="source-code">      .format(sum(y_train_os=='no')))</p><p>You should get the following output:</p><p class="source-code">After OverSampling, the shape of train_X: (55906, 51)</p><p class="source-code">After OverSampling, the shape of train_y: (55906,) </p><p class="source-code">After OverSampling, counts of label 'Yes': 27953</p><p class="source-code">After OverSampling, counts of label 'no': 27953</p><p class="callout-heading">Note</p><p class="callout">The counts mentioned in this output can vary because of variability in the sampling process.</p><p>Now that we have generated synthetic points using <strong class="source-inline">SMOTE</strong> and balanced the dataset, let's fit a logistic regression model on the new sample and analyze the results using a confusion matrix and a classification report.</p></li>
				<li>Define the <strong class="source-inline">LogisticRegression</strong> function:<p class="source-code"># Training the model with Logistic regression model</p><p class="source-code">from sklearn.linear_model import LogisticRegression</p><p class="source-code">bankModel2 = LogisticRegression()</p><p class="source-code">bankModel2.fit(X_train_os, y_train_os)</p></li>
				<li>Now, predict using <strong class="source-inline">.predict</strong> on the test set, as mentioned in the following code snippet:<p class="source-code">pred = bankModel2.predict(X_test)</p></li>
				<li>Next, <strong class="source-inline">print</strong> the accuracy values:<p class="source-code">print('Accuracy of Logistic regression model prediction on '\</p><p class="source-code">      'test set for Smote balanced data set: {:.2f}'\</p><p class="source-code">      .format(bankModel2.score(X_test, y_test)))</p><p>Your output should be as follows:</p><p class="source-code">Accuracy of Logistic regression model prediction on test set for Smote balanced data set: 0.83</p></li>
				<li>Then, generate <strong class="source-inline">ConfusionMatrix</strong> for the model:<p class="source-code">from sklearn.metrics import confusion_matrix</p><p class="source-code">confusionMatrix = confusion_matrix(y_test, pred)</p><p class="source-code">print(confusionMatrix)</p><p>The matrix is as follows:</p><p class="source-code">[[10042  1956]</p><p class="source-code"> [  306  1260]]</p></li>
				<li>Generate <strong class="source-inline">Classification_report</strong> for the model:<p class="source-code">from sklearn.metrics import classification_report</p><p class="source-code">print(classification_report(y_test, pred))</p><p>You should get the following output:</p><div id="_idContainer659" class="IMG---Figure"><img src="Images/B15019_13_22.jpg" alt="Figure 13.22: Classification report for the model&#13;&#10;" width="907" height="262"/></div></li>
			</ol>
			<p class="figure-caption">Figure 13.22: Classification report for the model</p>
			<p>From the generated metrics, we can see that the results are very similar to the undersampling results, with the exception that the recall value of the <strong class="source-inline">'Yes'</strong> cases has reduced from <strong class="source-inline">0.82</strong> to around <strong class="source-inline">0.80</strong>. The results that are generated vary from one use case to the next. <strong class="source-inline">SMOTE</strong> and its variants have been proven to have robust results in balancing data and are therefore the most popular methods used when encountering use cases with highly imbalanced data.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The values can vary in the output as the modeling process is subject to variation.</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2Ycxu34">https://packt.live/2Ycxu34</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2FDvTgo">https://packt.live/2FDvTgo</a>.</p>
			<p>In the next exercise, we will be implementing <strong class="source-inline">MSMOTE</strong>.</p>
			<h2 id="_idParaDest-299"><a id="_idTextAnchor298"/>Exercise 13.04: Implementing MSMOTE on Our Banking Dataset to Find the Optimal Result</h2>
			<p>In this exercise, we will generate synthetic samples of the minority class using <strong class="source-inline">MSMOTE</strong> and then make the dataset balanced. Then, on the new balanced dataset, we will fit a logistic regression model and analyze the results. This exercise will be very similar to the previous one.</p>
			<ol>
				<li value="1">Implement all the steps of <em class="italic">Exercise 13.01</em>, <em class="italic">Benchmarking the Logistic Regression Model on the Dataset</em>, until the splitting of the train and test sets (<em class="italic">Step 12</em>).</li>
				<li>Now, print the count of both the classes before we oversample:<p class="source-code"># Shape before oversampling</p><p class="source-code">print("Before OverSampling count of yes: {}"\</p><p class="source-code">      .format(sum(y_train=='yes')))</p><p class="source-code">print("Before OverSampling count of no: {} \n"\</p><p class="source-code">      .format(sum(y_train=='no')))</p><p>You should get the following output:</p><p class="source-code">Before OverSampling count of yes: 3723</p><p class="source-code">Before OverSampling count of no: 27924</p><p class="callout-heading">Note</p><p class="callout">The counts mentioned in this output can vary because of variability in the sampling process.</p><p>Next, we will be oversampling the training set using <strong class="source-inline">MSMOTE</strong>.</p></li>
				<li>Begin by importing the <strong class="source-inline">sv</strong> and <strong class="source-inline">numpy</strong>:<p class="source-code">!pip install smote-variants</p><p class="source-code">import smote_variants as sv</p><p class="source-code">import numpy as np</p><p>The library files that are required for oversampling the training set include the <strong class="source-inline">smote_variants</strong> library, which we installed earlier. This is imported as <strong class="source-inline">sv</strong>. The other library that is required is <strong class="source-inline">numpy</strong>, as the training set will have to be given a <strong class="source-inline">numpy</strong> array for the <strong class="source-inline">smote_variants</strong> library. </p></li>
				<li>Now, instantiate the <strong class="source-inline">MSMOTE</strong> library to a variable called <strong class="source-inline">oversampler</strong> using the <strong class="source-inline">sv.MSMOTE()</strong> function:<p class="source-code"># Instantiating the MSMOTE class</p><p class="source-code">oversampler= sv.MSMOTE()</p></li>
				<li>Now, sample the process using the <strong class="source-inline">.sample()</strong> function of <strong class="source-inline">oversampler</strong>:<p class="source-code"># Creating new training set</p><p class="source-code">X_train_os, y_train_os = oversampler.sample\</p><p class="source-code">                         (np.array(X_train), np.array(y_train))</p><p class="callout-heading">Note</p><p class="callout">Both the <strong class="source-inline">X</strong> and <strong class="source-inline">y</strong> variables are converted to <strong class="source-inline">numpy</strong> arrays before applying the <strong class="source-inline">.sample()</strong> function.</p><p>Now, print the shapes of the new <strong class="source-inline">X</strong> and <strong class="source-inline">y</strong> variables and also the <strong class="source-inline">counts</strong> of the classes:</p><p class="source-code"># Shape after oversampling</p><p class="source-code">print('After OverSampling, the shape of train_X: {}'\</p><p class="source-code">      .format(X_train_os.shape))</p><p class="source-code">print('After OverSampling, the shape of train_y: {} \n'\</p><p class="source-code">      .format(y_train_os.shape))</p><p class="source-code">print("After OverSampling, counts of label 'Yes': {}"\</p><p class="source-code">      .format(sum(y_train_os=='yes')))</p><p class="source-code">print("After OverSampling, counts of label 'no': {}"\</p><p class="source-code">      .format(sum(y_train_os=='no')))</p><p>You should get the following output:</p><p class="source-code">After OverSampling, the shape of train_X: (55848, 51)</p><p class="source-code">After OverSampling, the shape of train_y: (55848,) </p><p class="source-code">After OverSampling, counts of label 'Yes': 27924</p><p class="source-code">After OverSampling, counts of label 'no': 27924</p><p>Now that we have generated synthetic points using <strong class="source-inline">MSMOTE</strong> and balanced the dataset, let's fit a logistic regression model on the new sample and analyze the results using a confusion matrix and a classification report.</p></li>
				<li>Define the <strong class="source-inline">LogisticRegression</strong> function:<p class="source-code"># Training the model with Logistic regression model</p><p class="source-code">from sklearn.linear_model import LogisticRegression</p><p class="source-code"># Defining the LogisticRegression function</p><p class="source-code">bankModel3 = LogisticRegression()</p><p class="source-code">bankModel3.fit(X_train_os, y_train_os)</p></li>
				<li>Now, predict using <strong class="source-inline">.predict</strong> on the test set as in the following code snippet:<p class="source-code">pred = bankModel3.predict(X_test)</p></li>
				<li>Next, <strong class="source-inline">print</strong> the accuracy values:<p class="source-code">print('Accuracy of Logistic regression model prediction on '\</p><p class="source-code">      'test set for MSMOTE balanced data set: {:.2f}'\</p><p class="source-code">      .format(bankModel3.score(X_test, y_test)))</p><p>You should get the following output:</p><p class="source-code">Accuracy of Logistic regression model prediction on test set for MSMOTE balanced data set: 0.84</p></li>
				<li>Generate the <strong class="source-inline">ConfusionMatrix</strong> for the model:<p class="source-code">from sklearn.metrics import confusion_matrix</p><p class="source-code">confusionMatrix = confusion_matrix(y_test, pred)</p><p class="source-code">print(confusionMatrix)</p><p>The matrix should be as follows:</p><p class="source-code">[[10167  1831]</p><p class="source-code"> [  314  1252]]</p></li>
				<li>Generate the <strong class="source-inline">Classification_report</strong> for the model:<p class="source-code">from sklearn.metrics import classification_report</p><p class="source-code">print(classification_report(y_test, pred))</p><p>You should get the following output:</p><div id="_idContainer660" class="IMG---Figure"><img src="Images/B15019_13_23.jpg" alt="Figure 13.23: Classification report for the model&#13;&#10;" width="910" height="305"/></div></li>
			</ol>
			<p class="figure-caption">Figure 13.23: Classification report for the model</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The values can vary in the output as the modeling process is subject to variation.</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/34bCWHd">https://packt.live/34bCWHd</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2Edccvh">https://packt.live/2Edccvh</a>.</p>
			<p>From the implementation of <strong class="source-inline">MSMOTE</strong>, it is seen that the metrics have degraded compared to the <strong class="source-inline">SMOTE</strong> implementation from <em class="italic">Exercise 13.03</em>, <em class="italic">Implementing SMOTE on Our Banking Dataset to Find the Optimal Result</em>. We can then conclude that <strong class="source-inline">MSMOTE</strong> might not be the best method for this use case.</p>
			<h2 id="_idParaDest-300"><a id="_idTextAnchor299"/>Applying Balancing Techniques on a Telecom Dataset</h2>
			<p>Now that we have seen different balancing techniques, let's apply these techniques to a new dataset that is related to the churn of telecom customers. This dataset is available at the following link: <a href="https://packt.live/37IvqSX">https://packt.live/37IvqSX</a>.</p>
			<p>This dataset has various variables related to the usage level of a mobile connection, such as total call minutes, call charges, calls made during certain periods of the day, details of international calls, and details of calls to customer services. </p>
			<p>The problem statement is to predict whether a customer will churn. This dataset is a highly imbalanced one, with the cases where customers churn being the minority. You will be using this dataset in the following activity.</p>
			<h2 id="_idParaDest-301"><a id="_idTextAnchor300"/>Activity 13.01: Finding the Best Balancing Technique by Fitting a Classifier on the Telecom Churn Dataset</h2>
			<p>You are working as a data scientist for a telecom company. You have encountered a dataset that is highly imbalanced, and you want to correct the class imbalance before fitting the classifier to analyze the churn. You know different methods for correcting the imbalance in datasets and you want to compare them to find the best method before fitting the model.</p>
			<p>In this activity, you need to implement all of the three methods that you have come across so far and compare the results. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">You will be using the telecom churn dataset that you used in <em class="italic">Chapter 10</em>, <em class="italic">Analyzing a Dataset</em>.</p>
			<p>Use the <strong class="source-inline">MinMaxscaler</strong> function to scale the dataset instead of the robust scaler function you have been using so far. Compare the methods based on the results you get by fitting a logistic regression model on the dataset.</p>
			<p>The steps are as follows:</p>
			<ol>
				<li value="1">Implement all the initial steps, which include installing smote-variants and loading the data using pandas.</li>
				<li>Normalize the numerical raw data using the <strong class="source-inline">MinMaxScaler()</strong> function we learned about in <em class="italic">Chapter 3, Binary Classification</em>.</li>
				<li>Create dummy data for the categorical variables using the <strong class="source-inline">pd.get_dummies()</strong> function.</li>
				<li>Separate the numerical data from the original data frame.</li>
				<li>Concatenate numerical data and dummy categorical data using the <strong class="source-inline">pd.concat()</strong> function.</li>
				<li>Split the earlier dataset into train and test sets using the <strong class="source-inline">train_test_split()</strong> function.<p>Since the dataset is imbalanced, you need to perform the various techniques mentioned in the following steps.</p></li>
				<li>For the undersampling method, find the index of the minority class using the <strong class="source-inline">.index()</strong> function and separate the minority class. After that, sample the majority class and make the majority dataset equal to the minority class using the <strong class="source-inline">.sample()</strong> function. Concatenate both the minority and under-sampled majority class to form a new dataset. Shuffle the dataset and separate the <strong class="source-inline">X</strong> and <strong class="source-inline">Y</strong> variables.</li>
				<li>Fit a logistic regression model on the under-sampled dataset and name it <strong class="source-inline">churnModel1</strong>.</li>
				<li>For the <strong class="source-inline">SMOTE</strong> method, create the oversampler using the <strong class="source-inline">sv.SMOTE()</strong> function and create the new <strong class="source-inline">X</strong> and <strong class="source-inline">Y</strong> training sets.</li>
				<li>Fit a logistic regression model using <strong class="source-inline">SMOTE</strong> and name it <strong class="source-inline">churnModel2</strong>.</li>
				<li>Import the <strong class="source-inline">smote-variant</strong> library and instantiate the <strong class="source-inline">MSMOTE</strong> algorithm using the <strong class="source-inline">sv.MSMOTE()</strong> function.</li>
				<li>Create the oversampled data using the oversampler. Please note that the <strong class="source-inline">X</strong> and <strong class="source-inline">y</strong> variables have to be converted to a <strong class="source-inline">numpy</strong> array before oversampling</li>
				<li>Fit the logistic regression model using the <strong class="source-inline">MSMOTE</strong> dataset and name the model <strong class="source-inline">churnModel3</strong>.</li>
				<li>Generate the three separate predictions for each model.</li>
				<li>Generate separate accuracy metrics, classification reports, and confusion matrices for each of the predictions.</li>
				<li>Analyze the results and select the best method.</li>
			</ol>
			<p><strong class="bold">Expected Output</strong>: </p>
			<p>The final metrics that you can expect will be similar to what you see here.</p>
			<p><strong class="bold">Undersampling Output</strong></p>
			<div>
				<div id="_idContainer661" class="IMG---Figure">
					<img src="Images/B15019_13_24.jpg" alt="Figure 13.24: Undersampling output report&#13;&#10;" width="983" height="331"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.24: Undersampling output report</p>
			<p><strong class="bold">SMOTE Output</strong></p>
			<div>
				<div id="_idContainer662" class="IMG---Figure">
					<img src="Images/B15019_13_25.jpg" alt="Figure 13.25: SMOTE output report&#13;&#10;" width="1049" height="336"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.25: SMOTE output report</p>
			<p><strong class="bold">MSMOTE Output</strong></p>
			<div>
				<div id="_idContainer663" class="IMG---Figure">
					<img src="Images/B15019_13_26.jpg" alt="Figure 13.26: MSMOTE output report&#13;&#10;" width="1053" height="330"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.26: MSMOTE output report</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You will have different output as the modeling is stochastic in nature.</p>
			<p class="callout">The solution to the activity can be found here: <a href="https://packt.live/2GbJloz">https://packt.live/2GbJloz</a>.</p>
			<h1 id="_idParaDest-302"><a id="_idTextAnchor301"/>Summary</h1>
			<p>In this chapter, we learned about imbalanced datasets and strategies for addressing imbalanced datasets. We introduced the use cases where imbalanced datasets would be encountered. We looked at the challenges posed by imbalanced datasets and we were introduced to the metrics that should be used in the case of an imbalanced dataset. We formulated strategies for dealing with imbalanced datasets and implemented different strategies, such as random undersampling and oversampling, for balancing datasets. We then fit different models after balancing the datasets and analyzed the results.</p>
			<p>Balancing datasets is a very effective way to improve the performance of your classifiers. However, it should be noted that there could be a degradation of overall accuracy measures for the majority class due to balancing. What strategies to adopt in what situations should be arrived at based on the problem statement and also after rigorous experiments for those problem statements.</p>
			<p>Having learned about methods for dealing with imbalanced datasets, we will now be introduced to another important technique that is prevalent in many modern datasets called dimensionality reduction. Different techniques for dimensionality reduction will be addressed in <em class="italic">Chapter 14</em>, <em class="italic">Dimensionality Reduction</em>.</p>
		</div>
	</div></body></html>