["```py\n    import pandas as pd\n    ```", "```py\n    # Defining file name of the GitHub repository\n    filename = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter14/Dataset/ad.data'\n    ```", "```py\n    adData = pd.read_csv(filename,sep=\",\",header = None,\\\n                         error_bad_lines=False)\n    adData.head()\n    ```", "```py\n    # Printing the shape of the data\n    print(adData.shape)\n    ```", "```py\n    (3279, 1559)\n    ```", "```py\n    # Summarizing the statistics of the numerical raw data\n    adData.describe()\n    ```", "```py\n    # Separate the dependent and independent variables\n    # Preparing the X variables\n    X = adData.loc[:,0:1557]\n    print(X.shape)\n    # Preparing the Y variable\n    Y = adData[1558]\n    print(Y.shape)\n    ```", "```py\n    (3279, 1558)\n    (3279, )\n    ```", "```py\n    # Printing the head of the independent variables\n    X.head(15)\n    ```", "```py\n    # Printing the data types\n    print(X.dtypes)\n    ```", "```py\n    \"\"\"\n    Replacing special characters in first 3 columns \n    which are of type object\n    \"\"\"\n    for i in range(0,3):\n        X[i] = X[i].str.replace(\"?\", 'nan')\\\n                   .values.astype(float)\n    print(X.head(15))\n    ```", "```py\n    \"\"\"\n    Replacing special characters in the remaining \n    columns which are of type integer\n    \"\"\"\n    for i in range(3,1557):\n        X[i] = X[i].replace(\"?\", 'NaN').values.astype(float)\n    ```", "```py\n    import numpy as np\n    # Impute the 'NaN'  with mean of the values\n    for i in range(0,1557):\n        X[i] = X[i].fillna(X[i].mean())\n    print(X.head(15))\n    ```", "```py\n    # Scaling the data sets\n    # Import library function\n    from sklearn import preprocessing\n    # Creating the scaling function\n    minmaxScaler = preprocessing.MinMaxScaler()\n    # Transforming with the scaler function\n    X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n    # Printing the output\n    X_tran.head() \n    ```", "```py\nimport pandas as pd\nimport numpy as np\n```", "```py\n# Creating a simple data frame\ndf = pd.np.array([[1, 2, 3], [4, 5, 6]])\nprint(df.shape)\ndf\n```", "```py\n# Replicating the data frame and noting the time\nimport time\n# Starting a timing function\nt0=time.time()\nNewdf = pd.DataFrame(pd.np.tile(df, (1, 5)))\nprint(Newdf.shape)\nprint(Newdf)\n# Finding the end time\nprint(\"Total time:\", round(time.time()-t0, 3), \"s\")\n```", "```py\n    Total training time: 23.86 s\n    ```", "```py\n# Defining the file name from GitHub\nfilename = 'https://raw.githubusercontent.com'\\\n           '/PacktWorkshops/The-Data-Science-Workshop'\\\n           '/master/Chapter14/Dataset/ad.data'\n```", "```py\n# import pandas as pd\n# Loading the data using pandas\nadData = pd.read_csv(filename,sep=\",\",header = None,\\\n                     error_bad_lines=False)\n```", "```py\n# Creating a high dimension dataset\nX_hd = pd.DataFrame(pd.np.tile(adData, (1, 500)))\n```", "```py\n    filename = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter14/Dataset/ad.data'\n    import pandas as pd\n    adData = pd.read_csv(filename,sep=\",\",header = None,\\\n                         error_bad_lines=False)\n    X = adData.loc[:,0:1557]\n    Y = adData[1558]\n    import numpy as np\n    for i in range(0,3):\n        X[i] = X[i].str.replace(\"?\", 'NaN').values.astype(float)\n    for i in range(3,1557):\n        X[i] = X[i].replace(\"?\", 'NaN').values.astype(float)\n    for i in range(0,1557):\n        X[i] = X[i].fillna(X[i].mean())\n    from sklearn import preprocessing\n    minmaxScaler = preprocessing.MinMaxScaler()\n    X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n    ```", "```py\n    # Creating a high dimension data set\n    X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 2)))\n    print(X_hd.shape)\n    ```", "```py\n    (3279, 3116)\n    ```", "```py\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.feature_selection import RFE\n    # Defining the Classification function\n    backModel = LogisticRegression()\n    \"\"\"\n    Reducing dimensionality to 250 features for the \n    backward elimination model\n    \"\"\"\n    rfe = RFE(backModel, 250)\n    ```", "```py\n    # Fitting the rfe for selecting the top 250 features\n    import time\n    t0 = time.time()\n    rfe = rfe.fit(X_hd, Y)\n    t1 = time.time()\n    print(\"Backward Elimination time:\", \\\n          round(t1-t0, 3), \"s\")\n    ```", "```py\n    # Getting the indexes of the features used\n    rfe.get_support(indices = True)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    # Splitting the data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (X_hd, Y, test_size=0.3,\\\n                                        random_state=123)\n    print('Training set shape',X_train.shape)\n    print('Test set shape',X_test.shape)\n    ```", "```py\n    Training set shape (2295, 3116)\n    Test set shape (984, 3116)\n    ```", "```py\n    # Transforming both train and test sets\n    X_train_tran = rfe.transform(X_train)\n    X_test_tran = rfe.transform(X_test)\n    print(\"Training set shape\",X_train_tran.shape)\n    print(\"Test set shape\",X_test_tran.shape)\n    ```", "```py\n    Training set shape (2295, 250)\n    Test set shape (984, 250)\n    ```", "```py\n    # Fitting the logistic regression model\n    import time\n    # Defining the LogisticRegression function\n    RfeModel = LogisticRegression()\n    # Starting a timing function\n    t0=time.time()\n    # Fitting the model\n    RfeModel.fit(X_train_tran, y_train)\n    # Finding the end time\n    print(\"Total training time:\", \\\n          round(time.time()-t0, 3), \"s\")\n    ```", "```py\n    Total training time: 0.016 s\n    ```", "```py\n    # Predicting on the test set and getting the accuracy\n    pred = RfeModel.predict(X_test_tran)\n    print('Accuracy of Logistic regression model after '\\\n          'backward elimination: {:.2f}'\\\n          .format(RfeModel.score(X_test_tran, y_test)))\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    confusionMatrix = confusion_matrix(y_test, pred)\n    print(confusionMatrix)\n    ```", "```py\n    from sklearn.metrics import classification_report\n    # Getting the Classification_report\n    print(classification_report(y_test, pred))\n    ```", "```py\n    filename = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter14/Dataset/ad.data'\n    import pandas as pd\n    adData = pd.read_csv(filename,sep=\",\",header = None,\\\n                         error_bad_lines=False)\n    X = adData.loc[:,0:1557]\n    Y = adData[1558]\n    import numpy as np\n    for i in range(0,3):\n        X[i] = X[i].str.replace(\"?\", 'NaN')\\\n                   .values.astype(float)\n    for i in range(3,1557):\n        X[i] = X[i].replace(\"?\", 'NaN').values.astype(float)\n    for i in range(0,1557):\n        X[i] = X[i].fillna(X[i].mean())\n    from sklearn import preprocessing\n    minmaxScaler = preprocessing.MinMaxScaler()\n    X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n    ```", "```py\n    # Creating a high dimension dataset\n    X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 50)))\n    print(X_hd.shape)\n    ```", "```py\n    (3279, 77900)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    # Splitting the data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (X_hd, Y, test_size=0.3, \\\n                                        random_state=123)\n    ```", "```py\n    from sklearn.feature_selection import SelectKBest\n    # feature extraction\n    feats = SelectKBest(k=250)\n    ```", "```py\n    # Fitting the features for training set\n    import time\n    t0 = time.time()\n    fit = feats.fit(X_train, y_train)\n    t1 = time.time()\n    print(\"Forward selection fitting time:\", \\\n          round(t1-t0, 3), \"s\")\n    ```", "```py\n    Forward selection fitting time: 2.682 s\n    ```", "```py\n    # Creating new training set and test sets \n    features_train = fit.transform(X_train)\n    features_test = fit.transform(X_test)\n    ```", "```py\n    \"\"\"\n    Printing the shape of training and test sets \n    before transformation\n    \"\"\"\n    print('Train shape before transformation',\\\n          X_train.shape)\n    print('Test shape before transformation',\\\n          X_test.shape)\n    \"\"\"\n    Printing the shape of training and test sets \n    after transformation\n    \"\"\"\n    print('Train shape after transformation',\\\n          features_train.shape)\n    print('Test shape after transformation',\\\n          features_test.shape)\n    ```", "```py\n    # Fitting a Logistic Regression Model\n    from sklearn.linear_model import LogisticRegression\n    import time\n    t0 = time.time()\n    forwardModel = LogisticRegression()\n    forwardModel.fit(features_train, y_train)\n    t1 = time.time()\n    ```", "```py\n    print(\"Total training time:\", round(t1-t0, 3), \"s\")\n    ```", "```py\n    Total training time: 0.035 s\n    ```", "```py\n    # Predicting with the forward model\n    pred = forwardModel.predict(features_test)\n    print('Accuracy of Logistic regression'\\\n          ' model prediction on test set: {:.2f}'\n          .format(forwardModel.score(features_test, y_test)))\n    ```", "```py\n    Accuracy of Logistic regression model prediction on test set: 0.94\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    confusionMatrix = confusion_matrix(y_test, pred)\n    print(confusionMatrix)\n    ```", "```py\n    from sklearn.metrics import classification_report\n    # Getting the Classification_report\n    print(classification_report(y_test, pred))\n    ```", "```py\nimport numpy as np\n# Setting the seed for reproducibility\nseed = np.random.RandomState(123)\n# Generating an array of random numbers\nX = seed.rand(100,2)\n# Printing the shape of the dataset\nX.shape\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.scatter(X[:, 0], X[:, 1])\nplt.axis('equal')\n```", "```py\n(-0.04635361265714105,\n 1.0325632864350174,\n -0.003996887112708292,\n 1.0429468329457663)\n```", "```py\nfrom sklearn.decomposition import PCA\n# Defining one component\npca = PCA(n_components=1)\n# Fitting the PCA function\npca.fit(X)\n# Getting the new dataset\nX_pca = pca.transform(X)\n# Printing the shapes\nprint(\"Original data set:   \", X.shape)\nprint(\"Data set after transformation:\", X_pca.shape)\n```", "```py\noriginal shape: (100, 2)\ntransformed shape: (100, 1)\n```", "```py\n# Reversing the transformation and plotting \nX_reverse = pca.inverse_transform(X_pca)\n# Plotting the original data\nplt.scatter(X[:, 0], X[:, 1], alpha=0.1)\n# Plotting the reversed data\nplt.scatter(X_reverse[:, 0], X_reverse[:, 1], alpha=0.9)\nplt.axis('equal');\n```", "```py\n    filename = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter14/Dataset/ad.data'\n    import pandas as pd\n    adData = pd.read_csv(filename,sep=\",\",header = None,\\\n                         error_bad_lines=False)\n    X = adData.loc[:,0:1557]\n    Y = adData[1558]\n    import numpy as np\n    for i in range(0,3):\n        X[i] = X[i].str.replace(\"?\", 'NaN').values.astype(float)\n    for i in range(3,1557):\n        X[i] = X[i].replace(\"?\", 'NaN').values.astype(float)\n    for i in range(0,1557):\n        X[i] = X[i].fillna(X[i].mean())\n    from sklearn import preprocessing\n    minmaxScaler = preprocessing.MinMaxScaler()\n    X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n    ```", "```py\n    # Creating a high dimension data set\n    X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 50)))\n    print(X_hd.shape)\n    ```", "```py\n    (3279, 77900)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    # Splitting the data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (X_hd, Y, test_size=0.3, \\\n                                        random_state=123)\n    ```", "```py\n    from sklearn.decomposition import PCA\n    import time\n    t0 = time.time()\n    pca = PCA().fit(X_train)\n    t1 = time.time()\n    print(\"PCA fitting time:\", round(t1-t0, 3), \"s\")\n    ```", "```py\n    PCS fitting time: 179.545 s\n    ```", "```py\n    %matplotlib inline\n    import numpy as np\n    import matplotlib.pyplot as plt\n    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n    plt.xlabel('Number of Principal Components')\n    plt.ylabel('Cumulative explained variance');\n    ```", "```py\n    # Defining PCA with 250 components\n    pca = PCA(n_components=250)\n    # Fitting PCA on the training set\n    pca.fit(X_train)\n    ```", "```py\n    # Transforming training set and test set\n    X_pca = pca.transform(X_train)\n    X_test_pca = pca.transform(X_test)\n    ```", "```py\n    \"\"\"\n    Printing the shape of train and test sets before \n    and after transformation\n    \"\"\"\n    print(\"original shape of Training set:   \", \\\n          X_train.shape)\n    print(\"original shape of Test set:   \", \\\n          X_test.shape)\n    print(\"Transformed shape of training set:\", \\\n          X_pca.shape)\n    print(\"Transformed shape of test set:\", \\\n          X_test_pca.shape)\n    ```", "```py\n    # Fitting a Logistic Regression Model\n    from sklearn.linear_model import LogisticRegression\n    import time\n    pcaModel = LogisticRegression()\n    t0 = time.time()\n    pcaModel.fit(X_pca, y_train)\n    t1 = time.time()\n    ```", "```py\n    print(\"Total training time:\", round(t1-t0, 3), \"s\")\n    ```", "```py\n    Total training time: 0.293 s\n    ```", "```py\n    # Predicting with the pca model\n    pred = pcaModel.predict(X_test_pca)\n    print('Accuracy of Logistic regression model '\\\n          'prediction on test set: {:.2f}'\\\n          .format(pcaModel.score(X_test_pca, y_test)))\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    confusionMatrix = confusion_matrix(y_test, pred)\n    print(confusionMatrix)\n    ```", "```py\n    from sklearn.metrics import classification_report\n    # Getting the Classification_report\n    print(classification_report(y_test, pred))\n    ```", "```py\n    filename = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter14/Dataset/ad.data'\n    import pandas as pd\n    adData = pd.read_csv(filename,sep=\",\",header = None,\\\n                         error_bad_lines=False)\n    X = adData.loc[:,0:1557]\n    Y = adData[1558]\n    import numpy as np\n    for i in range(0,3):\n        X[i] = X[i].str.replace(\"?\", 'NaN')\\\n                   .values.astype(float)\n    for i in range(3,1557):\n        X[i] = X[i].replace(\"?\", 'NaN')\\\n                   .values.astype(float)  \n    for i in range(0,1557):\n        X[i] = X[i].fillna(X[i].mean())\n    from sklearn import preprocessing\n    minmaxScaler = preprocessing.MinMaxScaler()\n    X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n    ```", "```py\n    # Creating a high dimension data set\n    X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 50)))\n    print(X_hd.shape)\n    ```", "```py\n    (3279, 77900)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    # Splitting the data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (X_hd, Y, test_size=0.3,\\\n                                        random_state=123)\n    ```", "```py\n    # Defining the ICA with number of components\n    from sklearn.decomposition import FastICA \n    ICA = FastICA(n_components=250, random_state=123)\n    ```", "```py\n    \"\"\"\n    Fitting the ICA method and transforming the \n    training set import time\n    \"\"\"\n    t0 = time.time()\n    X_ica=ICA.fit_transform(X_train)\n    t1 = time.time()\n    print(\"ICA fitting time:\", round(t1-t0, 3), \"s\")\n    ```", "```py\n    ICA fitting time: 203.02 s\n    ```", "```py\n    # Transforming the test set \n    X_test_ica=ICA.transform(X_test)\n    ```", "```py\n    \"\"\"\n    Printing the shape of train and test sets \n    before and after transformation\n    \"\"\"\n    print(\"original shape of Training set:   \", \\\n          X_train.shape)\n    print(\"original shape of Test set:   \", \\\n          X_test.shape)\n    print(\"Transformed shape of training set:\", \\\n          X_ica.shape)\n    print(\"Transformed shape of test set:\", \\\n          X_test_ica.shape)\n    ```", "```py\n    # Fitting a Logistic Regression Model\n    from sklearn.linear_model import LogisticRegression\n    import time\n    icaModel = LogisticRegression()\n    t0 = time.time()\n    icaModel.fit(X_ica, y_train)\n    t1 = time.time()\n    ```", "```py\n    print(\"Total training time:\", round(t1-t0, 3), \"s\")\n    ```", "```py\n    Total training time: 0.054 s\n    ```", "```py\n    # Predicting with the ica model\n    pred = icaModel.predict(X_test_ica)\n    print('Accuracy of Logistic regression model '\\\n          'prediction on test set: {:.2f}'\\\n          .format(icaModel.score(X_test_ica, y_test)))\n    ```", "```py\n    Accuracy of Logistic regression model prediction on test set: 0.87\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    confusionMatrix = confusion_matrix(y_test, pred)\n    print(confusionMatrix)\n    ```", "```py\n    from sklearn.metrics import classification_report\n    # Getting the Classification_report\n    print(classification_report(y_test, pred))\n    ```", "```py\n    filename = 'https://raw.githubusercontent.com'\\\n               '/PacktWorkshops/The-Data-Science-Workshop'\\\n               '/master/Chapter14/Dataset/ad.data'\n    import pandas as pd\n    adData = pd.read_csv(filename,sep=\",\",header = None,\\\n                         error_bad_lines=False)\n    X = adData.loc[:,0:1557]\n    Y = adData[1558]\n    import numpy as np\n    for i in range(0,3):\n        X[i] = X[i].str.replace(\"?\", 'NaN')\\\n                   .values.astype(float)\n    for i in range(3,1557):\n        X[i] = X[i].replace(\"?\", 'NaN')\\\n                   .values.astype(float)  \n    for i in range(0,1557):\n        X[i] = X[i].fillna(X[i].mean())\n    from sklearn import preprocessing\n    minmaxScaler = preprocessing.MinMaxScaler()\n    X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n    ```", "```py\n    # Creating a high dimension data set\n    X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 50)))\n    print(X_hd.shape)\n    ```", "```py\n    (3279, 77900)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    # Splitting the data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (X_hd, Y, test_size=0.3,\\\n                                        random_state=123)\n    ```", "```py\n    # Defining the number of factors\n    from sklearn.decomposition import FactorAnalysis\n    fa = FactorAnalysis(n_components = 20,\\\n                        random_state=123)\n    ```", "```py\n    \"\"\"\n    Fitting the Factor analysis method and \n    transforming the training set\n    \"\"\"\n    import time\n    t0 = time.time()\n    X_fac=fa.fit_transform(X_train)\n    t1 = time.time()\n    print(\"Factor analysis fitting time:\", \\\n          round(t1-t0, 3), \"s\")\n    ```", "```py\n    Factor analysis fitting time: 130.688 s\n    ```", "```py\n    # Transforming the test set \n    X_test_fac=fa.transform(X_test)\n    ```", "```py\n    \"\"\"\n    Printing the shape of train and test sets \n    before and after transformation\n    \"\"\"\n    print(\"original shape of Training set:   \", \\\n          X_train.shape)\n    print(\"original shape of Test set:   \", \\\n          X_test.shape)\n    print(\"Transformed shape of training set:\", \\\n          X_fac.shape)\n    print(\"Transformed shape of test set:\", \\\n          X_test_fac.shape)\n    ```", "```py\n    # Fitting a Logistic Regression Model\n    from sklearn.linear_model import LogisticRegression\n    import time\n    facModel = LogisticRegression()\n    t0 = time.time()\n    facModel.fit(X_fac, y_train)\n    t1 = time.time()\n    ```", "```py\n    print(\"Total training time:\", round(t1-t0, 3), \"s\")\n    ```", "```py\n    Total training time: 0.028 s\n    ```", "```py\n    # Predicting with the factor analysis model\n    pred = facModel.predict(X_test_fac)\n    print('Accuracy of Logistic regression '\\\n          'model prediction on test set: {:.2f}'\n          .format(facModel.score(X_test_fac, y_test)))\n    ```", "```py\n    Accuracy of Logistic regression model prediction on test set: 0.92\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    confusionMatrix = confusion_matrix(y_test, pred)\n    print(confusionMatrix)\n    ```", "```py\n    from sklearn.metrics import classification_report\n    # Getting the Classification_report\n    print(classification_report(y_test, pred))\n    ```", "```py\nimport pandas as pd\nimport numpy as np\n```", "```py\n# Creating a simple data frame\ndf = pd.np.array([[1, 2, 3], [4, 5, 6]])\nprint(df.shape)\ndf\n```", "```py\n# Defining the mean and standard deviation\nmu, sigma = 0, 0.1 \n# Generating random sample\nnoise = np.random.normal(mu, sigma, [2,3]) \nnoise.shape\n```", "```py\n(2, 3)\n```", "```py\n# Sampled data frame\nnoise\n```", "```py\narray([[-0.07175021, -0.21135372,  0.10258917],\n       [ 0.03737542,  0.00045449, -0.04866098]])\n```", "```py\n# Creating a new data set by adding sampled data frame\ndf_new = df + noise\ndf_new\n```", "```py\narray([[0.92824979, 1.78864628, 3.10258917],\n       [4.03737542, 5.00045449, 5.95133902]])\n```"]