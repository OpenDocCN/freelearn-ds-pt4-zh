<html><head></head><body>
		<div id="_idContainer032">
			<h1 id="_idParaDest-38" class="chapter-number"><a id="_idTextAnchor038"/>2</h1>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor039"/>Biases in Data Augmentation</h1>
			<p>As<strong class="bold"> artificial intelligence</strong> (<strong class="bold">AI</strong>) becomes embedded in our society, biases in AI systems will adversely affect your quality of life. These AI systems, particularly in <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) and generative AI, depend on the input data you are using to extend <span class="No-Break">data augmentation.</span></p>
			<p>AI systems rely heavily on data to make decisions, and if the data used to train the system is biased, then the AI system will make unfair decisions. It will lead to the unjust treatment of individuals or groups and perpetuate systemic inequalities. AI plays a decisive role in life-changing decisions, such as how much your monthly mortgage insurance rate is, whether you can be approved for a car loan, your application qualification for a job, who will receive government assistance, how much you pay for milk, what you read on social media newsfeeds, and how much oil your country will import or export, to name <span class="No-Break">a few.</span></p>
			<p>By learning data biases before diving deep into learning data augmentation, you will be able to help develop ethical and fair AI systems that benefit society. It will help you make informed decisions about the data they use and prevent the perpetuation of existing biases and inequalities. Additionally, understanding data bias will help you make informed decisions about the data collection process and ensure it’s representative <span class="No-Break">and unbiased.</span></p>
			<p>Data biases may be problematic for data scientists and college students because they are seldom discussed or unavailable in college courses. There is no ready-made fairness matrix to follow programmatically for data augmentation. Maybe by using the latest generative AI, the biases may even originate from computer systems and not be so heavily due <span class="No-Break">to humans.</span></p>
			<p>There are many strategies to provide protected and safe software products and services, but AI systems require new processes and perspectives. Trustworthy and responsible AI is about fairness, ethical design, and minimizing biases. Achieving trustworthy AI starts with transparency, datasets, <strong class="bold">test, evaluation, validation, and verification</strong> (<strong class="bold">TEVV</strong>), as defined by the <em class="italic">Standard for Identifying and Managing Bias in Artificial Intelligence, National Institute of Standards and Technology (NIST)</em> special <span class="No-Break">publication 1270.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">In 2016, Twitter corrupted the Microsoft AI chatbot <strong class="bold">Tay</strong> in 1 day. Microsoft created Tay for online casual and playful conversation. Tay was designed to learn and take input from raw, uncurated data and comments from the web. The Twitter community thought it would be fun to teach Tay with misogynistic, racist, and violent tweets. To this day, Tay is a poster child for lessons learned in data bias input for AI. As one blogger put it, “<em class="italic">Flaming garbage pile in, flaming garbage </em><span class="No-Break"><em class="italic">pile out</em></span><span class="No-Break">.”</span></p>
			<p>This chapter will provide a crash course on recognizing the differences in <strong class="bold">computation</strong>, <strong class="bold">human</strong>, and <strong class="bold">systemic</strong> biases. We will learn about bias but not practice how to compute bias programmatically. The fairness and confusion matrixes are used to gauge AI’s prediction in terms of <strong class="bold">true-positive</strong>, <strong class="bold">false-positive</strong>, <strong class="bold">true-negative</strong>, and <strong class="bold">false-negative</strong>. However, the fairness and confusion matrixes are used for building AI systems, not data augmentation. While looking at real-world text datasets, we will attempt to write Python code for a fairness matrix with word counts and misspelled words, but for the most part, we will rely on Pluto and your observations to name the biases in image and <span class="No-Break">text data.</span></p>
			<p>The Python code in this chapter will focus on helping you learn how to download real-world datasets from the <em class="italic">Kaggle</em> website. The later chapters will reuse the helper and wrapper functions shown in <span class="No-Break">this chapter.</span></p>
			<p>By the end of this chapter, you will have a deeper appreciation for a balanced dataset. In particular, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li><span class="No-Break">Computational biases</span></li>
				<li><span class="No-Break">Human biases</span></li>
				<li><span class="No-Break">Systemic biases</span></li>
				<li><span class="No-Break">Python Notebook</span></li>
				<li><span class="No-Break">Image biases</span></li>
				<li><span class="No-Break">Text biases</span></li>
			</ul>
			<p>Pluto will begin with the easier of the three biases – <span class="No-Break">computational biases.</span></p>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor040"/>Computational biases</h1>
			<p>Before we<a id="_idIndexMarker064"/> start, a fair warning is that you will not be learning how to write Python code to calculate a numeric score for computational bias in datasets. The primary focus of this chapter is to help you learn how to fetch real-world datasets from the Kaggle website and use observation to spot biases in data. There will be some coding to calculate the fairness or balance in <span class="No-Break">the datasets.</span></p>
			<p>For example, we will compute the word counts per record and the misspelled words in the <span class="No-Break">text datasets.</span></p>
			<p>You may think all biases are the same, but it helps to break them into three distinct categories. The bias categories’ differences can be subtle when first reading about data biases. One method to help distinguish the differences is to think about how you could remove or reduce the error in AI forecasting. For example, computational biases can be resolved by changing the datasets, while systemic biases can be fixed by changing the deployment and access strategy of the <span class="No-Break">AI system.</span></p>
			<p>Computational biases originate from the unevenness in the dataset for the general population. In other words, it favors or underrepresents one group or data category. The prejudices could be unintentional or deep-seated. The data is skewed higher than the usual randomness. As a result, the algorithm will be plagued with higher false-positive and <span class="No-Break">false-negative predictions.</span></p>
			<p><strong class="bold">Dataset representation</strong> (<strong class="bold">DR</strong>) and <strong class="bold">machine learning algorithms</strong> (<strong class="bold">MLAs</strong>) are two types<a id="_idIndexMarker065"/> of computation<a id="_idIndexMarker066"/> biases. DR is easier to understand and more closely related to augmenting data. Many of the examples in this section are from DR biases. MLA is specific to a project and can’t <span class="No-Break">be generalized.</span></p>
			<p>Here are a few examples of <span class="No-Break">computational biases:</span></p>
			<ul>
				<li><em class="italic">Kodak’s Shirley Cards Set Photography’s Skin-Tone Standard</em> from the mid-1970s is one <a id="_idIndexMarker067"/>of the more famous examples of technology biases. The <strong class="bold">Shirley card</strong> from <a id="_idIndexMarker068"/>Kodak is used to calibrate the image, such as skin tone and shadow, before printing people’s pictures. It is a part of the setting up process and is frequently used at the printing facility. Shirley is the name of an employee at Kodak. Because of this innocent and unintentional discrimination, for three decades, photos printed in the USA did not show the true skin tone of anyone who did not have a white <span class="No-Break">skin tone.</span></li>
				<li><em class="italic">Google Open AI DALL-E 2</em>, from 2022, is an AI model that generates pictures from texts. For example, you can type the input as <em class="italic">a hippo eating broccoli wearing a pink polka dot swimsuit</em>, and DALL-E 2 will generate the picture. Even with this highly touted technology breakthrough, there are prejudices, as reported by the <em class="italic">NBC Tech</em> news written by Jake Traylor in the article <em class="italic">No quick fix: How OpenAI’s DALL-E 2 illustrated the challenges of bias in AI</em>. For example, in DALL-E, a builder produced images featuring only men, while the caption of a flight attendant generated only images of women. DALL-E 2 additionally inherits various biases from its training data, and its outputs sometimes reinforce <span class="No-Break">societal stereotypes.</span></li>
				<li>The United Kingdom’s <strong class="bold">Information Commissioner’s Office</strong> (<strong class="bold">ICO</strong>) disclosed on July 2022 that<a id="_idIndexMarker069"/> AI automation’s potential discrimination could have grave consequences for society. For example, it could result in unfair or biased job rejection, bank loans, or university acceptance. In addition, coinciding with the ICO is <a id="_idIndexMarker070"/>the <em class="italic">Guardian newspaper</em> article <em class="italic">UK data watchdog investigates whether AI systems show racial bias</em>, by Dan Milmo. The ICO’s goal is to create a fair and ethical AI <span class="No-Break">system guideline.</span></li>
			</ul>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Using <a id="_idIndexMarker071"/>generative AI and <strong class="bold">Stable Diffusion</strong> on <em class="italic">GitHub</em>, forked by Duc Haba on Python Notebook, Pluto wrote, “<em class="italic">A cute adorable baby hippo made of crystal ball with low poly eye surrounded by glowing aura highly detailed intricated concept art trending art station 8k eating broccoli in the city wearing pink polka dots.</em>” After running repeatedly with slightly altering wordings, his favorite generated images were created. These are the <span class="No-Break">original images:</span></p>
			<div>
				<div id="_idContainer013" class="IMG---Figure">
					<img src="image/B17990_02_01.jpg" alt="Figure 2.1 – Generative AI, Stable Diffusion forked"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1 – Generative AI, Stable Diffusion forked</p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.1</em> displays a hippo eating broccoli. On that fun note, we have concluded this section on<a id="_idIndexMarker072"/> computational biases. Pluto is a digital dog but can speak about human biases, which he’ll do in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor041"/>Human biases</h1>
			<p>Human biases are<a id="_idIndexMarker073"/> even harder to calculate using Python code. There is no Python or other language library for computing a numeric score for human bias in a dataset. We rely on observation to spot such human biases. It is time-consuming to manually study a particular dataset before deriving possible human biases. We could argue that it is not a programmer’s or data scientist’s job because there is no programable method <span class="No-Break">to follow.</span></p>
			<p>Human biases reflect systematic errors in human thought. In other words, when you develop an AI system, you are limited by the algorithm and data chosen by you. Thus, the prediction of a limited outcome could be biased by your selections. These prejudices are implicit in individuals, groups, institutions, businesses, education, <span class="No-Break">and government.</span></p>
			<p>There is a wide variety of human biases. Cognitive and perceptual biases show themselves in all domains and are not unique to human interactions with AI. There is an entire field of study centered around biases and heuristics in thinking, decision-making, and behavioral economics, such as anchoring bias and <span class="No-Break">confirmation bias.</span></p>
			<p>As data scientists that are augmenting data, by simply being aware of the inherent human prejudices, we<a id="_idIndexMarker074"/> can call out the flaws in the data before developing and training <span class="No-Break">the model.</span></p>
			<p>Here are a few examples of human biases in real-world <span class="No-Break">AI systems:</span></p>
			<ul>
				<li>The <strong class="bold">People’s Republic of China</strong> (<strong class="bold">PRC</strong>) implemented facial recognition AI in the<a id="_idIndexMarker075"/> province of<a id="_idIndexMarker076"/> Xinjiang to monitor ethnic minorities such as the Uyghurs. It is the first known example of a government using AI specifically for racial profiling. The system is flawed with discrimination as it identifies the poor and the old as ethnic minorities in false-positive predictions. Compounding the problem is when Myanmar bought the PRC system to crack down on political dissidents, as <a id="_idIndexMarker077"/>the <strong class="bold">Council on Foreign Relations</strong> reported in their <em class="italic">The Importance of International Norms in Artificial Intelligence Ethics</em> article <span class="No-Break">in 2022.</span></li>
				<li>To stop advertisers from abusing the AI Facebook newsfeed, Meta limited the target algorithm from using health, race, ethnicity, political affiliation, religion, and sexual orientation. <strong class="bold">NPR</strong> reported in the article that Facebook had scrapped advertised targeting based on politics, race, and other “<em class="italic">sensitive</em>” topics. The changes took effect on January 10 across Meta’s apps, including Facebook, Instagram, Messenger, and the Audience Network. It is reported that advertisers microtargeted people with tailored messages. In other words, the advertisers excluded people based on protected characteristics and targeted advertisements using <span class="No-Break">anti-Semitic phrases.</span></li>
				<li>The article <em class="italic">Racial Bias Found in a Major Health Care Risk Algorithm</em>, published by <strong class="bold">Scientific American</strong> on October 4, 2019, found many biases in the healthcare system. Black patients would pay more for interventions and emergency visits. In addition to incurring higher costs, black patients would receive lesser-quality care. AI scientists used race and wealth in historical data to train the healthcare system. Thus, the system displayed prejudice toward minority groups <a id="_idIndexMarker078"/>and affected 200 <span class="No-Break">million Americans.</span></li>
			</ul>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">This challenge is a thought experiment. How could you build an AI without biases, given a substantial budget and ample time? Hint: think about when we had world peace or no crime in our city. It can’t be an absolute answer. It has to be a level <span class="No-Break">of acceptance.</span></p>
			<p>It may be challenging to see the differences between human and computational biases. Some biases are not one or the other. In other words, they are not mutually exclusive – you can have both human and computational biases in one <span class="No-Break">AI system.</span></p>
			<p>Human biases are difficult to identify because they shape our perception of the world. However, systemic biases may be easier to address in theory, but may be challenging to put <span class="No-Break">into practice.</span></p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor042"/>Systemic biases</h1>
			<p>If we cannot <a id="_idIndexMarker079"/>conceive a method to calculate computational and human biases, then it is impossible to devise an algorithm to compute systemic biases programmatically. We must rely on human judgment to spot the systemic bias in the dataset. Furthermore, it has to be specific to a particular dataset with a distinct AI prediction goal. There are no generalization rules and no fairness matrix <span class="No-Break">to follow.</span></p>
			<p>Systemic biases in AI are the most notorious of all AI biases. Simply put, systemic discrimination is when a business, institution, or government limits access to AI benefits to a group and excludes other underserved groups. It is insidious because it hides behind society’s existing rules and norms. Institutional racism and sexism are the most common examples. Another AI accessibility issue in everyday occurrences is limiting or excluding admission to people with disabilities, such as the sight and <span class="No-Break">hearing impaired.</span></p>
			<p>The poor and the underserved have no representation in the process of developing the AI system, but they are forced to accept the AI’s prediction or forecast. These AIs make significant life decisions, including those for the poor and underserved, such as how much to pay for a car or health insurance, options for housing or a business bank loan, or whether they are eligible for <span class="No-Break">medical treatments.</span></p>
			<p>Here are a few real-world examples of AI <span class="No-Break">systemic biases:</span></p>
			<ul>
				<li>The article <em class="italic">Researchers use AI to predict crime, biased policing in major U.S. cities like L.A.</em>, published by The Los Angeles Times on July 4, 2022, found AI biases in policing crimes. The University of Chicago’s AI crime prediction system does not address law enforcement systemic biases. The forecast for possible crime locations, or hot spots, is based on flawed input and environmental factors associated with poor neighborhoods, rather than the actual locations where crimes are committed. The AI reflects the systemic bias in law enforcement practices and procedures. Thus, it forecasts a higher crime rate in poor neighborhoods because of the police’s prior <span class="No-Break">systemic biases.</span></li>
				<li>The US Department of <a id="_idIndexMarker080"/>Justice reviewed the <strong class="bold">Prisoner Assessment Tool Targeting Estimated Risk and Needs</strong> (<strong class="bold">PATTERN</strong>) and found systemic bias in who can access PATTERN. This was discussed in <em class="italic">Addressing an Algorithmic PATTERN of Bias</em>, published by the Regulatory Review on May 10, 2020. The report reinforces the Justice Department’s biased view that low-risk criminals<a id="_idIndexMarker081"/> should be the only ones eligible for early release. PATTERN classifies inmates as low, medium, or high risk, which forecasts if those individuals would engage in crime after release. Since PATTERN is limited to a particular group, it precludes other inmates from <span class="No-Break">early release.</span></li>
				<li>The article <em class="italic">The Potential For Bias In Machine Learning And Opportunities For Health Insurers To Address It</em> reports growing concerns about how ML can reflect and perpetuate past and present systemic inequities and biases. This was published by Health Affairs in February 2022 published the article. Limited access to the likelihood of hospitalization, admission to pharmacies, and missing or incomplete data are a few systemic biases for racism and underrepresented populations. Thus, the AI predictions may reflect those systemic biases, and the policy decisions based on the forecast risk reinforcing and exacerbating <span class="No-Break">existing inequities.</span></li>
			</ul>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">This challenge is a thought experiment. Which category of biases is easier to spot? Hint: think about <span class="No-Break">company profit.</span></p>
			<p>Computation, human, and systemic biases have similarities and are not mutually exclusive. There is no algorithm or libraries to guide you in coding. It relies on your observation from studying the datasets. At this point, Pluto is ready to learn about fetching real-world<a id="_idIndexMarker082"/> datasets from the <em class="italic">Kaggle</em> website. Optionally, he will ask you to spot the biases in <span class="No-Break">the datasets.</span></p>
			<h1 id="_idParaDest-43"><a id="_idTextAnchor043"/>Python Notebook</h1>
			<p>This chapter’s coding<a id="_idIndexMarker083"/> lessons primarily focus on downloading real-world datasets from the <em class="italic">Kaggle</em> website. The later chapters rely on or reuse these <span class="No-Break">fetching functions.</span></p>
			<p>In the previous chapter, you learned about this book’s general rules for development on the Python Notebook. The object-oriented class <a id="_idIndexMarker084"/>named <strong class="bold">Pluto</strong> contains the methods and attributes, and you add new methods to Pluto as you learn new concepts and techniques. Review <a href="B17990_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic">Chapter 1</em></span></a> if you are uncertain about the <span class="No-Break">development philosophy.</span></p>
			<p>In this <a id="_idIndexMarker085"/>book, the term <strong class="bold">P</strong><strong class="bold">ython Notebook</strong> is <a id="_idIndexMarker086"/>used <a id="_idIndexMarker087"/>synonymously for <strong class="bold">Jupyter Notebook</strong>, <strong class="bold">JupyterLab</strong>, and <strong class="bold">Google </strong><span class="No-Break"><strong class="bold">Colab Notebook</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">Pluto challenges you to change the object’s name from <strong class="bold">Pluto</strong> to any other name. If you do change the name, then substitute that name where you see <strong class="bold">Pluto</strong> in your text and code. For example, if you change the object name to <strong class="bold">Sandy</strong>, then <strong class="source-inline">pluto.draw_batch_image()</strong> <span class="No-Break">becomes </span><span class="No-Break"><strong class="source-inline">sandy.draw_batch_image()</strong></span><span class="No-Break">.</span></p>
			<p>Starting with this chapter, the setup process for using the Python Notebook will be the same for every chapter. The goal of this chapter is to help you gain a deeper understanding of the datasets and not to write Python code for calculating the bias value for each dataset. The setup steps are <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Load <span class="No-Break">Python Notebook.</span></li>
				<li><span class="No-Break">Clone GitHub.</span></li>
				<li><span class="No-Break">Instantiate Pluto.</span></li>
				<li><span class="No-Break">Verify Pluto.</span></li>
				<li>Create <span class="No-Break">Kaggle ID.</span></li>
				<li>Download <span class="No-Break">real-world datasets.</span></li>
			</ol>
			<p>Let’s start with loading the <span class="No-Break">Python Notebook.</span></p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor044"/>Python Notebook</h2>
			<p>The first<a id="_idIndexMarker088"/> step is to locate the <strong class="source-inline">data_augmentation_with_python_chapter_2.ipynb</strong> file. It is in this book’s GitHub repository at <a href="https://github.com/PacktPublishing/Data-Augmentation-with-Python">https://github.com/PacktPublishing/Data-Augmentation-with-Python</a>. Refer to <a href="B17990_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic">Chapter 1</em></span></a> if you forgot how to load the <span class="No-Break">Python Notebook.</span></p>
			<p>The next step is to clone the <span class="No-Break">GitHub repository.</span></p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor045"/>GitHub</h2>
			<p>The<a id="_idIndexMarker089"/> second <a id="_idIndexMarker090"/>step is locating the <strong class="source-inline">~/Data-Augmentation-with-Python/pluto/pluto_chapter_1.py</strong> file. It’s in the main GitHub repository for this book, under the <span class="No-Break"><strong class="source-inline">pluto</strong></span><span class="No-Break"> folder.</span></p>
			<p>Pluto is using the Python Notebook on <strong class="bold">Google Colab</strong>. It starts with a new session every time – that is, no permanent storage is saved from the previous session. Thus, the faster and easier method to load all the required files is to clone the GitHub repository. It could be this book’s GitGub or the GitHub repository that <span class="No-Break">you forked.</span></p>
			<p>From this point onward, all commands, code, and references are from the <strong class="source-inline">data_augmentation_with_python_chapter_2.ipynb</strong> <span class="No-Break">Python Notebook.</span></p>
			<p>Pluto uses the<strong class="source-inline">!git clone {url}</strong> command to clone a GitHub repository, where <strong class="source-inline">{url}</strong> is the link for the GitHub repository. The code snippet is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># load from official GitHub repo.</strong>
!git clone https://github.com/PacktPublishing/Data-Augmentation-with-Python
<strong class="bold"># optional step, sustitute duchaba with your GitHub space</strong>
!git clone https://github.com/duchaba/Data-Augmentation-with-Python</pre>
			<p>In the Python Notebook, any code cell that begins with an exclamation point (<strong class="source-inline">!</strong>) will tell the system to run as a system shell command line. For Google Colab, it is <a id="_idIndexMarker091"/>a <strong class="bold">bsh</strong> shell. In addition, all <a id="_idIndexMarker092"/>code that begins with a percent sign (<strong class="source-inline">%</strong>) are special <a id="_idIndexMarker093"/>commands. They<a id="_idIndexMarker094"/> are called <strong class="bold">magic keywords</strong> or <span class="No-Break"><strong class="bold">magic commands</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Jupyter Notebook’s built-in magic commands provide convenience functions to the underlying <strong class="bold">operating system</strong> (<strong class="bold">OS</strong>) kernel. The <a id="_idIndexMarker095"/>magic commands begin with the percent sign character (<strong class="source-inline">%</strong>). For example, <strong class="source-inline">%ldir</strong> is for listing the current directory files, <strong class="source-inline">%cp</strong> is for copying files in your local directory, <strong class="source-inline">%debug</strong> is for debugging, and so on. The helpful <strong class="source-inline">%lsmagic</strong> command is for listing all the available magic commands supported by your current Python Notebook environment. The exclamation character (<strong class="source-inline">!</strong>) is for running the underlying OS command-line function. For example, in a Linux system, <strong class="source-inline">!ls -la</strong> is for listing the files in the current directory, while <strong class="source-inline">!pip</strong> is for installing <span class="No-Break">Python libraries.</span></p>
			<p>Now that <a id="_idIndexMarker096"/>you <a id="_idIndexMarker097"/>have downloaded the Pluto Python code, the next step is to <span class="No-Break">instantiate Pluto.</span></p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor046"/>Pluto</h2>
			<p>The Python<a id="_idIndexMarker098"/> Notebook’s <a id="_idIndexMarker099"/>magic command for instantiating Pluto is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># instantiate pluto</strong>
pluto_file='Data-Augmentation-with-Python/pluto/pluto_chapter_1.py'
%run {pluto_file}</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<pre class="console">
---------------------------- : ---------------------------
            Hello from class : &lt;class '__main__.PackTDataAug'&gt; Class: PackTDataAug
                   Code name : Pluto
                   Author is : Duc Haba
---------------------------- : ---------------------------</pre>
			<p>The next-to-last <a id="_idIndexMarker100"/>step in the setup process is to verify that Pluto is running with the <span class="No-Break">correct version.</span></p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor047"/>Verifying Pluto</h2>
			<p>For <a id="_idIndexMarker101"/>double-checking, Pluto<a id="_idIndexMarker102"/> runs the <span class="No-Break">following function:</span></p>
			<pre class="source-code">
<strong class="bold"># Are you ready to play?</strong>
pluto.say_sys_info()</pre>
			<p>The results should be similar to the <span class="No-Break">following output:</span></p>
			<pre class="console">
---------------------------- : ----------------------------
                 System time : 2022/08/16 06:26
                    Platform : linux
       Python version (3.7+) : 3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]
     Pluto Version (Chapter) : 1.0
            PyTorch (1.11.0) : actual: 1.12.1+cu113
              Pandas (1.3.5) : actual: 1.3.5
                 PIL (9.0.0) : actual: 7.1.2
          Matplotlib (3.2.2) : actual: 3.2.2
                   CPU count : 2
                  CPU speed : NOT available
---------------------------- : ----------------------------</pre>
			<p>Since this code is from <a href="B17990_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, the Pluto version is <strong class="bold">1.0</strong>. Before Pluto can download the<a id="_idIndexMarker103"/> dataset <a id="_idIndexMarker104"/>from the <em class="italic">Kaggle</em> website, he needs <a id="_idIndexMarker105"/>Kaggle’s <strong class="bold">key</strong> and <span class="No-Break"><strong class="bold">access token</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor048"/>Kaggle ID</h2>
			<p>Pluto uses Kaggle datasets <a id="_idIndexMarker106"/>because he wants to learn how to<a id="_idIndexMarker107"/> retrieve real-world data for learning data augmentation. It is more impactful than using a small set of dummy data. Thus, the first two steps are installing the library to aid in downloading the Kaggle data and signing up <span class="No-Break">with </span><a href="https://Kaggle.com"><span class="No-Break">Kaggle.com</span></a><span class="No-Break">.</span></p>
			<p>The code for installing and importing can be found in the<a id="_idIndexMarker108"/> open source <strong class="bold">opendatasets</strong> library by <strong class="bold">Jovian</strong>. The <a id="_idIndexMarker109"/>function code is in the Python Notebook; here is a code snippet <span class="No-Break">from it:</span></p>
			<pre class="source-code">
<strong class="bold"># install opendatasets library</strong>
!pip install opendatasets --upgrade
import opendatasets</pre>
			<p>After you create an account on <a href="http://Kaggle.com">Kaggle.com</a>, you will <a id="_idIndexMarker110"/>have a <strong class="bold">Kaggle username</strong> and receive a <strong class="bold">Kaggle key</strong>. Next, go to the <strong class="bold">Account</strong> page, scroll down to the <strong class="bold">API</strong> section, and click on the <strong class="bold">Create New API Token</strong> button to generate the <span class="No-Break"><strong class="bold">Kaggle key</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B17990_02_02.jpg" alt="Figure 2.2 – Kaggle Account page – new token"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2 – Kaggle Account page – new token</p>
			<p>Once you have a <strong class="bold">Kaggle username and key</strong>, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.2</em>, use Pluto’s <strong class="source-inline">remember_kaggle_access_key()</strong> wrapper method to store the attributes inside the object. The code uses the Python <strong class="source-inline">self</strong> keyword to store this information – for example, <strong class="source-inline">self.kaggle_username</strong>. The method’s definition is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># method definition</strong>
def remember_kaggle_access_keys(self,username,key):</pre>
			<p>Other methods will use these attributes automatically. Pluto runs the following method to remember <a id="_idIndexMarker111"/>your<a id="_idIndexMarker112"/> Kaggle username <span class="No-Break">and key:</span></p>
			<pre class="source-code">
<strong class="bold"># save Kaggle username and key</strong>
pluto.remember_kaggle_access_keys("your_username_here",
  "your_key_here")</pre>
			<p>The <strong class="source-inline">_write_kaggle_credit()</strong> method writes your Kaggle username and key in two locations – <strong class="source-inline">~/.kaggle/kaggle.json</strong> and <strong class="source-inline">./kaggle.json</strong>. It also changes the file attribute to <strong class="source-inline">0o600</strong>. This function begins with an underscore; hence, it is a helper function used primarily by <span class="No-Break">other methods.</span></p>
			<p>There are two methods for Pluto to fetch data from Kaggle: <strong class="source-inline">fetch_kaggle_comp_data(competition_name)</strong>, where <strong class="source-inline">competition_name</strong> is the title of the contest, and <strong class="source-inline">fetch_kaggle_dataset(url)</strong>, where <strong class="source-inline">url</strong> is the link to <span class="No-Break">the dataset.</span></p>
			<p>In the <strong class="source-inline">fetch_kaggle_comp_data()</strong> wrapper method, the primary code line that does most of the work is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># code snippet for fetcing competition data</strong>
kaggle.api.competition_download_cli(str(path))</pre>
			<p>In the <strong class="source-inline">fetch_kaggle_dataset()</strong> method, the primary code line that does most of the<a id="_idIndexMarker113"/> work is <a id="_idIndexMarker114"/><span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># fetching real-world dataset for the Kaggle website</strong>
opendatasets.download(url,data_dir=dest)</pre>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">As of 2022, there are over 2,500 past and current competitions on the Kaggle website and more than 150,000 datasets. These datasets are diverse, from medical and financial to other <span class="No-Break">industry-specific datasets.</span></p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor049"/>Image biases</h1>
			<p>Pluto has access to <a id="_idIndexMarker115"/>thousands of datasets, and downloading these datasets is as simple as replacing the <strong class="bold">URL</strong>. In particular, he will download the <span class="No-Break">following datasets:</span></p>
			<ul>
				<li>The <em class="italic">State Farm distracted drivers detection (</em><span class="No-Break"><em class="italic">SFDDD)</em></span><span class="No-Break"> dataset</span></li>
				<li>The <em class="italic">Nike </em><span class="No-Break"><em class="italic">shoes</em></span><span class="No-Break"> dataset</span></li>
				<li>The <em class="italic">Grapevine </em><span class="No-Break"><em class="italic">leaves</em></span><span class="No-Break"> dataset</span></li>
			</ul>
			<p>Let’s start with the <span class="No-Break">SFDDD dataset.</span></p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor050"/>State Farm distracted drivers detection</h2>
			<p>To start, Pluto<a id="_idIndexMarker116"/> will<a id="_idIndexMarker117"/> slow down and explain every step in downloading the real-world datasets, even though he will use a wrapper function, which seems deceptively simple. Pluto will not write any Python code for programmatically computing the bias fairness matrix values. He relies on your observation to spot the biases in <span class="No-Break">the dataset.</span></p>
			<p>Give Pluto a command to fetch, and he will download and <strong class="bold">unzip</strong> or <strong class="bold">untar</strong> the data to your local disk space. For example, in retrieving data from a competition, ask Pluto to fetch it with the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
<strong class="bold"># fetch real-world data</strong>
pluto.fetch_kaggle_comp_data(
  "state-farm-distracted-driver-detection")</pre>
			<p>Since this data is from a competition, you must join the State Farm competition before downloading the dataset. You should go to the <strong class="bold">State Farm Distracted Driver Detection</strong> competition and click the <strong class="bold">Join</strong> button. The description for the competition from the <em class="italic">Kaggle</em> website is <span class="No-Break">as follows:</span></p>
			<p class="author-quote">“State Farm hopes to improve these alarming statistics and better insure their customers by testing whether dashboard cameras can automatically detect drivers engaging in distracting behaviors. Given a dataset of 2D dashboard camera images, State Farm is challenging Kagglers to classify each driver’s behavior.”</p>
			<p><em class="italic">State Farm</em> provided the dataset, announced in 2016. The rules and usage licenses can be found <span class="No-Break">at </span><a href="https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/rules"><span class="No-Break">https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/rules</span></a><span class="No-Break">.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">You have to join a Kaggle competition to download competition data, but you don’t need to enter a competition to download a <span class="No-Break">Kaggle dataset.</span></p>
			<p>Not all the methods are in the Python Notebook’s <strong class="bold">global space</strong> but in the Pluto object. Hence, you can’t access a wrapper function directly. You have to prefix it with <strong class="source-inline">pluto</strong>. For example, you can’t do <span class="No-Break">the following:</span></p>
			<p><strong class="bold"># example of </strong><span class="No-Break"><strong class="bold">wrong syntax</strong></span></p>
			<pre class="source-code">
fetch_kaggle_dataset(url)</pre>
			<p>However, using the <strong class="source-inline">pluto</strong> prefix is correct, as <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
<strong class="bold"># example of correct syntax</strong>
pluto.fetch_kaggle_dataset(url)</pre>
			<p>Before Pluto displays the image in batches, he must write a few simple code lines to check if the downloads <span class="No-Break">are correct:</span></p>
			<pre class="source-code">
<strong class="bold"># read the image file</strong>
f = 'state-farm-distracted-driver-detection/imgs/train/c0/img_100026.jpg'
img = PIL.Image.open(f)
<strong class="bold"># display image using Python Notebook build-in command</strong>
display(img)</pre>
			<p>The output is<a id="_idIndexMarker118"/> <span class="No-Break">as</span><span class="No-Break"><a id="_idIndexMarker119"/></span><span class="No-Break"> follows:</span></p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B17990_02_03.jpg" alt="Figure 2.3 – State Farm Distracted driver"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3 – State Farm Distracted driver</p>
			<p>The SFDDD dataset consists of 22,423 images, and viewing one photo at a time, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.3</em>, will not help Pluto to see the biases. Pluto loves putting lists and tabular data into the Python pandas library. Luckily, the State Farm competition comes with a <strong class="bold">comma-separated values</strong> (<strong class="bold">CSV</strong>) file. It<a id="_idIndexMarker120"/> will make writing the <strong class="source-inline">fetch_df(self, csv)</strong> method easier. The relevant line of code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># code snippet to import into Pandas</strong>
df = pandas.read_csv(csv)</pre>
			<p>Pluto uses the <strong class="source-inline">fetch_df(self, csv)</strong> wrapper function to download the data, and he uses Pandas to display the last three rows. The code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># fetch data</strong>
pluto.df_sf_data = pluto.fetch_df('state-farm-distracted-driver-detection/driver_imgs_list.csv')
<strong class="bold"># display last three records</strong>
pluto.df_sf_data.tail(3)</pre>
			<p>The result is <a id="_idIndexMarker121"/><span class="No-Break">as</span><span class="No-Break"><a id="_idIndexMarker122"/></span><span class="No-Break"> follows:</span></p>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B17990_02_04.jpg" alt="Figure 2.4 – State Farm data – last three rows"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.4 – State Farm data – last three rows</p>
			<p>Pluto likes the data in the original CSV file, shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.4</em>, but it does not have a column with a full path to an image file. Pandas makes creating a new column containing the full image path <a id="_idIndexMarker123"/>super easy. There<a id="_idIndexMarker124"/> are no complicated <strong class="bold">for loops</strong> or <strong class="bold">if else</strong> statements. There are only two lines of code for the wrapper function, <strong class="source-inline">build_sf_fname(self, df)</strong>, where <strong class="source-inline">df</strong> is the original DataFrame. The code snippet is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># code snippet to create full image path</strong>
root = 'state-farm-distracted-driver-detection/imgs/train/'
df["fname"] = f'{root}/{df.classname}/{df.img}</pre>
			<p>The full function code can be found in the Python Notebook. Pluto adds the full path name column and displays the first three rows with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold">#create new fname column</strong>
pluto.build_sf_fname(pluto.df_sf_data)
pluto.df_sf_data.head(3)</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer017" class="IMG---Figure">
					<img src="image/B17990_02_05.jpg" alt="Figure 2.5 – State Farm data – full path image name"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.5 – State Farm data – full path image name</p>
			<p>For<a id="_idIndexMarker125"/> double-<a id="_idIndexMarker126"/>checking, Pluto writes a few lines of simple code to display an image from the pandas <strong class="source-inline">fname</strong> column, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.5</em>, using<a id="_idIndexMarker127"/> the <strong class="bold">PIL</strong> library. The code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># display the image</strong>
img = PIL.Image.open(pluto.df_sf_data.fname[0])
display(img)</pre>
			<p>The resulting image is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B17990_02_06.jpg" alt="Figure 2.6 – State Farm data – the fname column"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.6 – State Farm data – the fname column</p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.6</em> shows a driver. Using the <strong class="source-inline">fname</strong> column, drawing a batch or collection of images is<a id="_idIndexMarker128"/> relatively <a id="_idIndexMarker129"/>easy. The <strong class="source-inline">draw_batch()</strong> wrapper function’s definition is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># function definition</strong>
def draw_batch(self, df_filenames,
  disp_max=10,
  is_shuffle=False,
  figsize=(16,8)):</pre>
			<p>= <strong class="source-inline">df_filenames</strong> is the list of file =names, and it is in a pandas DataFrame. <strong class="source-inline">disp_max</strong> defaults to 10, which is an increment of 5, as in five photos per row. <strong class="source-inline">is_shuffle</strong> defaults to <strong class="source-inline">False</strong>. If you can set it to <strong class="source-inline">True</strong>, each batch is randomly selected. Lastly, <strong class="source-inline">figsize</strong> is the size of the output from the <strong class="bold">Matplotlib</strong> library, where the first number is the <strong class="bold">width</strong> and the second number is the <strong class="bold">height</strong>. The default <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">(16,8)</strong></span><span class="No-Break">.</span></p>
			<p>Using the <strong class="source-inline">draw_batch()</strong> wrapper method, Pluto can draw any photo collection. For example, Pluto can draw 10 random images from the SFDDD competition with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold"># display image batch</strong>
x = pluto.draw_batch(pluto.df_sf_data["fname"],
  is_shuffle=True)</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B17990_02_07.jpg" alt="Figure 2.7 – State F﻿arm data – draw_patch()"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.7 – State Farm data – draw_patch()</p>
			<p>Pluto runs the code repeatedly to see different images in the dataset, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.7</em>. For <a id="_idIndexMarker130"/>example, he <a id="_idIndexMarker131"/>can draw 20 random images at a time using the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold"># display image batch</strong>
x = pluto.draw_batch(pluto.df_sf_data["fname"],
  is_shuffle=True,
  disp_max=20,
  figsize=(18,14))</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B17990_02_08.jpg" alt="Figure 2.8 – State Farm data – 20 randomly selected images"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.8 – State Farm data – 20 randomly selected images</p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.8</em> displays 20 photos of drivers. Using the <strong class="source-inline">fetch_kaggle_comp_data()</strong>, <strong class="source-inline">fetch_df()</strong>, and <strong class="source-inline">draw_batch()</strong> wrapper functions, Pluto can retrieve any of the thousand real-<a id="_idIndexMarker132"/>world<a id="_idIndexMarker133"/> datasets <span class="No-Break">from Kaggle.</span></p>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">This challenge is a thought experiment. Before reading Pluto’s answer, what biases do you see in the images? It is optional, and there is no algorithm or library that you can use to compute the bias fairness value. It relies on <span class="No-Break">your observation.</span></p>
			<p>Pluto read the SFDDD’s goal and thought about computational, human, and systemic biases. The following bullet points are not errors to be fixed, but they could be biases. These biases are observations from <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.7</em> of underrepresented groups. Pluto assumes the long-term goal of the SFDDD is for it to be deployed across the <span class="No-Break">United States:</span></p>
			<ul>
				<li>Pluto does not see any older adults as drivers in <span class="No-Break">the dataset.</span></li>
				<li>The driver demographic distribution is limited. There are about a dozen drivers represented in the dataset, and the long-term goal is to deploy this AI system in the United States. Therefore, the AI system will be trained on a limited number <span class="No-Break">of drivers.</span></li>
				<li>There are few vehicle types represented in the dataset. They are primary sedans, compacts, or SUVs. A sports car or truck interior is different, which might affect the prediction of false positives or <span class="No-Break">false negatives.</span></li>
				<li>There are other distracting activities while driving that are not represented, such as eating ice cream, watching an event unfolding outside of the car, head or hair grooming, and <span class="No-Break">so on.</span></li>
				<li>All drivers in the dataset wear urban-style clothing. More elaborate or ethnic-centric clothing styles might cause the AI to predict false positives or <span class="No-Break">false negatives.</span></li>
				<li>The goal is to <a id="_idIndexMarker134"/>save<a id="_idIndexMarker135"/> lives. Thus, a systemic bias could be affordable access to everyone, not just the tech-savvy <span class="No-Break">urban elites.</span></li>
			</ul>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">This challenge is a thought experiment. Can you find other biases? There are no absolute right or wrong answers. The biases listed here can’t be <span class="No-Break">spotted programmatically.</span></p>
			<p>That was a detailed<a id="_idIndexMarker136"/> discussion of the SFDDD dataset. Pluto will fetch another dataset from the <em class="italic">Kaggle</em> website, the <em class="italic">Nike </em><span class="No-Break"><em class="italic">shoes</em></span><span class="No-Break"> dataset.</span></p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor051"/>Nike shoes</h2>
			<p>The Nike shoes<a id="_idIndexMarker137"/> dataset was chosen because <a id="_idIndexMarker138"/>it will show different biases. Like the State Farm photos, there is no algorithm or library to compute the fairness matrix. We rely on Pluto and <span class="No-Break">your observations.</span></p>
			<p>The <em class="italic">Nike, Adidas, and Converse Shoes Images</em> (Nike) dataset contains images in folders; there is no <strong class="bold">CSV</strong> file. The Nike dataset’s description on the Kaggle website is <span class="No-Break">as follows:</span></p>
			<p>“<em class="italic">This dataset is ideal for performing multiclass classification with deep neural networks such as CNNs or simpler machine learning classification models. You can use TensorFlow, its high-level API Keras, sklearn, PyTorch, or other deep/machine </em><span class="No-Break"><em class="italic">learning libraries.</em></span><span class="No-Break">”</span></p>
			<p>The author is <em class="italic">Iron486</em>, and the license is <strong class="bold">CC0: Public </strong><span class="No-Break"><strong class="bold">Domain</strong></span><span class="No-Break">: </span><a href="https://creativecommons.org/publicdomain/zero/1.0/"><span class="No-Break">https://creativecommons.org/publicdomain/zero/1.0/</span></a><span class="No-Break">.</span></p>
			<p>Since there is no CSV file for Pluto to import into pandas, Pluto has written the <strong class="source-inline">build_df_fname(self,</strong> <strong class="source-inline">start_path)</strong> method, where <strong class="source-inline">start_path</strong> is the directory where the data <span class="No-Break">is stored.</span></p>
			<p>The key <a id="_idIndexMarker139"/>code line is the <span class="No-Break"><strong class="source-inline">os.walk()</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
<strong class="bold"># code snippet for generating meta data</strong>
for root, dirs, files in os.walk(start_path, topdown=False):
   for name in files:</pre>
			<p>Pluto will perform the three familiar steps for reviewing the Nike dataset. They are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># 1. fetch data</strong>
fname='https://www.kaggle.com/datasets/die9origephit/nike-adidas-and-converse-imaged'
pluto.fetch_kaggle_dataset(fname)
<strong class="bold"># 2. import meta data to Pandas</strong>
pluto.df_shoe_data = pluto.build_shoe_fname(
  'kaggle/nike-adidas-and-converse-imaged/train')
<strong class="bold"># 3. display image batch</strong>
x = pluto.draw_batch(pluto.df_shoe_data["fname"],
  is_shuffle=True,
  disp_max=20,
  figsize=(18,14))</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B17990_02_09.jpg" alt="Figure 2.9 – Nike data – 20 randomly selected images"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.9 – Nike data – 20 randomly selected images</p>
			<p>The<a id="_idIndexMarker140"/> following is<a id="_idIndexMarker141"/> Pluto’s list of data biases observations from <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.9</em></span><span class="No-Break">:</span></p>
			<ul>
				<li>The shoes are too clean. Where are the muddy or <span class="No-Break">dirty shoes?</span></li>
				<li>The photos are professionally taken. Thus, when the AI-powered app is deployed, people might find their app giving a wrong prediction because their pictures are <span class="No-Break">taken haphazardly.</span></li>
				<li>There is a lack of shoe images in urban, farming, or <span class="No-Break">hiking settings.</span></li>
			</ul>
			<p>Let’s ask Pluto to <a id="_idIndexMarker142"/>grab one more image dataset before switching gears and digging into the <span class="No-Break">text dataset.</span></p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor052"/>Grapevine leaves</h2>
			<p>The Grapevine<a id="_idIndexMarker143"/> leaves dataset is the<a id="_idIndexMarker144"/> third and last example of a real-world image dataset Pluto will fetch from the Kaggle website. The primary goal is for you to practice downloading datasets and importing the metadata into pandas. Incidentally, Pluto will use the Grapevine leaves dataset to name other types of data biases through observation. He does not rely on defining a fairness matrix through coding because it not yet feasible. Maybe the next level of generative AI will be able to process all the photos in a dataset and deduce <span class="No-Break">the biases.</span></p>
			<p>Here is an excerpt from the Grapevine <span class="No-Break">leaves dataset:</span></p>
			<p class="author-quote">“The main product of grapevines is grapes that are consumed fresh or processed. In addition, grapevine leaves are harvested once a year as a by-product. The species of grapevine leaves are important in terms of price and taste.”</p>
			<p>The authors are <em class="italic">Koklu M., Unlersen M. F., Ozkan I. A., Aslan M. F., and Sabanci K.</em>, and the license is <strong class="bold">CC0: Public </strong><span class="No-Break"><strong class="bold">Domain</strong></span><span class="No-Break">: </span><a href="https://creativecommons.org/publicdomain/zero/1.0/"><span class="No-Break">https://creativecommons.org/publicdomain/zero/1.0/</span></a><span class="No-Break">.</span></p>
			<p>The filenames in the Grapevine dataset contains a space character in the filename, which may confuse many Python libraries. Thus, Pluto runs a few simple Linux scripts to convert the space into an underscore. The code snippet is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># remove white space from file and directory name</strong>
f2 = 'kaggle/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset'
!find {f2} -name "* *" -type f | rename 's/ /_/g'</pre>
			<p>After cleaning up the filenames, Pluto will perform the three familiar steps for fetching, importing, and displaying the Grapevine dataset. The images are in the same folder structure as the Nike photos. Thus, Pluto reuses the same <span class="No-Break"><strong class="source-inline">pluto.fetch_df()</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
<strong class="bold"># fetch data</strong>
fname=' https://www.kaggle.com/datasets/muratkokludataset/grapevine-leaves-image-dataset'
pluto.fetch_kaggle_dataset(fname)
<strong class="bold"># import to Pandas</strong>
pluto.df_grapevine_data=pluto.fetch_df("kaggle/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset")
<strong class="bold"># display image batch</strong>
x = pluto.draw_batch(pluto.df_grapevine_data["fname"],
  is_shuffle=True,
  disp_max=20,
  figsize=(18,14))</pre>
			<p>The <a id="_idIndexMarker145"/>output is<a id="_idIndexMarker146"/> <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B17990_02_10.jpg" alt="Figure 2.10 – Grapevine data – 20 randomly selected images"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.10 – Grapevine data – 20 randomly selected images</p>
			<p>The following is Pluto’s list of data biases from <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">:</span></p>
			<ul>
				<li>The photos are too perfect, and undoubtedly, they are uncomplicated to augment and <a id="_idIndexMarker147"/>train, but how does the general public use the AI system? If the winemakers access the AI system through an iPhone, the grapevine leaf pictures they take are nothing like the flawless photos in the dataset. The resulting predictions could be <span class="No-Break">false positives.</span></li>
				<li>Similar to the perfect photo bias, the leaf is flat, and the background is white, which is not common in real-world usage. The training cycle will achieve high accuracy, but it is unsuitable for <span class="No-Break">real-world use.</span></li>
				<li>If the model is trained as-is and deployed, then the resulting AI will have a systemic bias, only being available for lab technicians and <span class="No-Break">not farmers.</span></li>
			</ul>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">There are thousands of image datasets on the <em class="italic">Kaggle</em> website. Pluto challenges you to select, download, display, and list the biases for three different <span class="No-Break">image datasets.</span></p>
			<p>Other<a id="_idIndexMarker148"/> than <a id="_idIndexMarker149"/>Distracted Drivers, Nike shoes, and Grapevine Leaves, there are more examples in the Python Notebook. However, next, Pluto will move on from biases to <span class="No-Break">text augmentation.</span></p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor053"/>Text biases</h1>
			<p>By now, you should <a id="_idIndexMarker150"/>recognize the patterns for fetching real-world image datasets and importing metadata into pandas. It is the same pattern for text datasets. Pluto will guide you through two sessions and use his power of observation to name the biases. He could employ the latest in generative AI such as OpenAI GPT3 or GPT4 to list the biases in the text. Maybe he will do that later, but for now, he will use his noggin. Nevertheless, Pluto will attempt to write Python code to gain insight into the texts' structures, such as the word count and misspelled words. It is not the fairness matrix but a step in the <span class="No-Break">right direction.</span></p>
			<p>Pluto searches the Kaggle website<a id="_idIndexMarker151"/> for the <strong class="bold">Natural Language Processing</strong> (<strong class="bold">NLP</strong>) dataset, and the result consists of over 2,000 datasets. He chooses the <em class="italic">Netflix Shows</em> and the <em class="italic">Amazon Reviews</em> datasets. Retrieving and viewing the NLP dataset follows the same fetching, importing, and printing steps outlined in the <span class="No-Break">image dataset.</span></p>
			<p>Let’s start with the <span class="No-Break">Netflix data.</span></p>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor054"/>Netflix</h2>
			<p>Pluto reuses <a id="_idIndexMarker152"/>the wrapper function to download the<a id="_idIndexMarker153"/> data. The command is <span class="No-Break">as follows:</span></p>
			<pre class="console">
<strong class="bold"># fectch real-world dataset</strong>
fname='https://www.kaggle.com/datasets/infamouscoder/dataset-Netflix-shows'
pluto.fetch_kaggle_dataset(fname)</pre>
			<p>The Netflix dataset’s description from the Kaggle website is <span class="No-Break">as follows:</span></p>
			<p class="author-quote">“The raw data is web scrapped through Selenium. It contains unlabelled text data of around 9,000 Netflix shows and movies, along with full details such as cast, release year, rating, description, and so on.”</p>
			<p>The author is <em class="italic">InFamousCoder</em>, and the license is <strong class="bold">CC0: Public </strong><span class="No-Break"><strong class="bold">Domain</strong></span><span class="No-Break">: </span><a href="https://creativecommons.org/publicdomain/zero/1.0/"><span class="No-Break">https://creativecommons.org/publicdomain/zero/1.0/</span></a><span class="No-Break">.</span></p>
			<p>The second step is to import the data into a pandas DataFrame. The Netflix data comes with a <strong class="bold">CSV</strong> file; therefore, Pluto reuses the <strong class="source-inline">fetch_df()</strong> method to import the Netflix reviews into the<a id="_idIndexMarker154"/> DataFrame and displays the first three<a id="_idIndexMarker155"/> rows, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># import metadata into Pandas</strong>
pluto.df_netflix_data = pluto.fetch_df(
  'kaggle/dataset-Netflix-shows/Netflix_titles.csv')
pluto.df_netflix_data[['show_id',
  'type', 'title', 'director', 'cast']].head(3)</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B17990_02_11.jpg" alt="Figure 2.11 – Netflix data, left columns"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.11 – Netflix data, left columns</p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.11</em> displays the Netflix metadata. The first two steps do not require Pluto to write new code, but<a id="_idIndexMarker156"/> Pluto has to write code for the third<a id="_idIndexMarker157"/> step, which is to display the movie’s title and description. The goal is for Pluto to find any biases in the <span class="No-Break">movie description.</span></p>
			<p>Pandas<a id="_idIndexMarker158"/> made <a id="_idIndexMarker159"/>writing<a id="_idIndexMarker160"/> the <strong class="source-inline">display_batch_text()</strong> wrapper<a id="_idIndexMarker161"/> method effortless. The method has no <strong class="bold">loops</strong>, <strong class="bold">index counter</strong>, <strong class="bold">shuffle algorithm</strong>, <strong class="bold">or if-else</strong> statements. There are just three lines of code, so Pluto displays the code in its <span class="No-Break">entirety here:</span></p>
			<pre class="source-code">
<strong class="bold"># define wrapper function</strong>
def print_batch_text(self, df_orig,
  disp_max=10,
  cols= ["title", "description"]):
  df = df_orig[cols]
  with pandas.option_context("display.max_colwidth", None):
    display(df.sample(disp_max))
  return</pre>
			<p>Pluto displays the Netflix movies’ titles and descriptions in batch using the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold"># print text batch</strong>
pluto.print_batch_text(pluto.df_netflix_data)</pre>
			<p>The<a id="_idIndexMarker162"/> result<a id="_idIndexMarker163"/> is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B17990_02_12.jpg" alt="Figure 2.12 – Netflix movie title and description"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.12 – Netflix movie title and description</p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Every time Pluto runs the <strong class="source-inline">print_batch_text()</strong> wrapper function, movie titles and descriptions are displayed. It would be best to run the wrapper function repeatedly to gain more insight into <span class="No-Break">the data.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.12</em> displays a text batch. Pluto has read hundreds of movie descriptions and found no apparent bias. It is a job for a linguist. In general, the English language can have the <span class="No-Break">following biases:</span></p>
			<ul>
				<li><span class="No-Break">Religious bias</span></li>
				<li><span class="No-Break">Gender bias</span></li>
				<li><span class="No-Break">Ethnicity bias</span></li>
				<li><span class="No-Break">Racial bias</span></li>
				<li><span class="No-Break">Age bias</span></li>
				<li>Mental <span class="No-Break">health bias</span></li>
				<li>Former <span class="No-Break">felon bias</span></li>
				<li><span class="No-Break">Elitism bias</span></li>
				<li><span class="No-Break">LGBTQ bias</span></li>
				<li><span class="No-Break">Disability bias</span></li>
			</ul>
			<p>Pluto is not a<a id="_idIndexMarker164"/> linguist, but there are other data attributes could<a id="_idIndexMarker165"/> contribute to language biases, such as word count and misspelled words. In other words, are the Netflix movie descriptions all relatively the same length? And are there many <span class="No-Break">misspelled words?</span></p>
			<p>This is an attempt to code a small fraction of the fairness matrix. When using a pandas DataFrame, the <strong class="source-inline">count_words()</strong> method has one line of code. It is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># attempt at fairness matrix, count words</strong>
def count_word(self, df, col_dest="description"):
  df['wordc'] = df[col_dest].apply(lambda x: len(x.split()))
  return</pre>
			<p>Pluto counted the number of words in the Netflix movie and double-checked the result by using the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold"># count words and dislay result</strong>
pluto.count_word(pluto.df_netflix_data)
pluto.print_batch_text(pluto.df_netflix_data,
  cols=['description','wordc'])</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B17990_02_13.jpg" alt="Figure 2.13 – Movie description word count"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.13 – Movie description word count</p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.13</em> displays<a id="_idIndexMarker166"/> the<a id="_idIndexMarker167"/> word count for each record. The next step is to<a id="_idIndexMarker168"/> plot<a id="_idIndexMarker169"/> the word count using the <strong class="bold">BoxPlot</strong> and <strong class="bold">Histogram</strong> graphs. When using a pandas DataFrame, drawing graphs is relatively easy. The two key code lines in the <strong class="source-inline">draw_word_count()</strong> function are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># code snippet for draw word count</strong>
df.boxplot(ax=pic[0],
  column=[wc],
  vert=False,
  color="black")
df[wc].hist(ax=pic[1],
  color="cornflowerblue",
  alpha=0.9)</pre>
			<p>The full function code can be found in the Python Notebook. Pluto draws the BoxPlot and Histogram graphs with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold"># draw word count</strong>
pluto.draw_word_count(pluto.df_netflix_data)</pre>
			<p>The<a id="_idIndexMarker170"/> result is <a id="_idIndexMarker171"/><span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B17990_02_14.jpg" alt="Figure 2.14 – Netflix movie description word count"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.14 – Netflix movie description word count</p>
			<p>As shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.14</em>, the BoxPlot and Histogram plots show that the distribution is even. There are a few outliers, the mean is 23.88, and the bulk of the Netflix movie descriptions are between 22 and 25 words. Thus, there is no bias here. Pluto investigates the misspelled <span class="No-Break">words next.</span></p>
			<p>Pluto uses the <strong class="source-inline">pip</strong> command to<a id="_idIndexMarker172"/> install the <strong class="bold">pyspellchecker</strong> library and import the <strong class="source-inline">spellchecker</strong> class. The <strong class="source-inline">check_spelling()</strong> method takes the pandas DataFrame and the designated column as parameters. The function key code lines are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># code snippet for check spelling</strong>
df["misspelled"] = df[col_dest].apply(
  lambda x: spell.unknown(self._strip_punc(x).split()))
df["misspelled_count"] = df["misspelled"].apply(
  lambda x: len(x))</pre>
			<p>Pluto checks the<a id="_idIndexMarker173"/> Netflix movie descriptions' <a id="_idIndexMarker174"/>spelling and uses the <strong class="source-inline">print_batch_text()</strong> function to display the result. The code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># check spelling</strong>
pluto.check_spelling(pluto.df_netflix_data)
<strong class="bold"># print batch text withh correct spelling</strong>
pluto.print_batch_text(pluto.df_netflix_data,
  cols=['description', 'misspelled'])</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/B17990_02_15.jpg" alt="Figure 2.15 – Netflix misspelled words"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.15 – Netflix misspelled words</p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.15</em> displays <a id="_idIndexMarker175"/>the misspelled words. Pluto displays this data in <a id="_idIndexMarker176"/>graphs by reusing the same <strong class="source-inline">draw_word_count()</strong> function, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># draw word count</strong>
pluto.draw_word_count(pluto.df_netflix_data,
  wc='misspelled_count')</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B17990_02_16.jpg" alt="Figure 2.16 – Netflix misspelled words graph"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.16 – Netflix misspelled words graph</p>
			<p>The misspelled words are mostly person or product names, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.16</em>. The average is 0.92 per Netflix movie description and there are only a handful of outliners. Without<a id="_idIndexMarker177"/> a linguist’s help, Pluto can’t find any <a id="_idIndexMarker178"/>biases in the Netflix movie description. Let’s move on to the Amazon reviews and see if we can find <span class="No-Break">any biases.</span></p>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor055"/>Amazon reviews</h2>
			<p>The Amazon<a id="_idIndexMarker179"/> reviews <a id="_idIndexMarker180"/>dataset is the last real-world text dataset to download for this chapter. Pluto follows the same pattern, and you should now be comfortable with the code and ready to download any real-world datasets from the Kaggle website. In addition, as with the Netflix data, Pluto will use his powerful insight, as a digital dog, to find the biases in the text. He will use the same techniques and library to programmatically find the word count and <span class="No-Break">misspelled words.</span></p>
			<p>Pluto will not explain how the code is written for the Amazon reviews because he re-used the same functions in the Netflix data. The complete code can be found in the Python Notebook. The<a id="_idIndexMarker181"/> bare code snippet is <span class="No-Break">as </span><span class="No-Break"><a id="_idIndexMarker182"/></span><span class="No-Break">follows:</span></p>
			<pre class="source-code">
<strong class="bold"># fetch data</strong>
pluto.fetch_kaggle_dataset(
  'https://www.kaggle.com/datasets/tarkkaanko/amazon')
<strong class="bold"># import to Pandas</strong>
pluto.df_amazon_data = pluto.fetch_df(
  'kaggle/amazon/amazon_reviews.csv')
<strong class="bold"># count words and misspell</strong>
pluto.count_word(pluto.df_amazon_data,
  col_dest='reviewText')
pluto.check_spelling(pluto.df_amazon_data,
  col_dest='reviewText')</pre>
			<p>The data description of the Amazon reviews dataset on Kaggle is <span class="No-Break">as follows:</span></p>
			<p class="author-quote">“One of the most important problems in eCommerce is the correct calculation of the points given to after-sales products. The solution to this problem is to provide greater customer satisfaction for the eCommerce site, product prominence for sellers, and a seamless shopping experience for buyers. Another problem is the correct ordering of the comments given to the products. The prominence of misleading comments will cause both financial losses and customer losses.”</p>
			<p>The author is <em class="italic">Tarık kaan Koç</em>, and the license is <strong class="bold">CC BY-NC-SA </strong><span class="No-Break"><strong class="bold">4.0</strong></span><span class="No-Break">: </span><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="No-Break">https://creativecommons.org/licenses/by-nc-sa/4.0/</span></a><span class="No-Break">.</span></p>
			<p>Pluto prints the batch using the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold"># display misspelled words</strong>
pluto.print_batch_text(pluto.df_amazon_data,
  cols=['reviewText','misspelled'])</pre>
			<p>The <a id="_idIndexMarker183"/>result is<a id="_idIndexMarker184"/> <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B17990_02_17.jpg" alt="Figure 2.17 – Amazon reviews misspelled words"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.17 – Amazon reviews misspelled words</p>
			<p>Pluto has chosen<a id="_idIndexMarker185"/> to<a id="_idIndexMarker186"/> display two data columns in the <strong class="source-inline">print_batch</strong> function, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.17</em>, but there are 12 data columns in the dataset. They are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">reviewerName</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">overall</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">reviewText</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">reviewTime</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">day_diff</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">helpful_yes</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">helpful_no</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">total_vote</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">score_pos_neg_diff</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">score_average_rating</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">wilson_lower_bound</strong></span></li>
			</ul>
			<p>Pluto draws <a id="_idIndexMarker187"/>the <a id="_idIndexMarker188"/>word counts and the misspelled words using the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
<strong class="bold"># display word count</strong>
pluto.draw_word_count(pluto.df_amazon_data)
<strong class="bold"># draw misspelled words</strong>
pluto.draw_word_count(pluto.df_amazon_data,
  wc='misspelled_count')</pre>
			<p>The result for the word counts is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B17990_02_18.jpg" alt="Figure 2.18 – Amazon reviews word count"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.18 – Amazon reviews word count</p>
			<p>Here<a id="_idIndexMarker189"/> is<a id="_idIndexMarker190"/> the graph for the <span class="No-Break">misspelled words:</span></p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B17990_02_19.jpg" alt="Figure 2.19 – Amazon reviews misspelled﻿ words graph"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.19 – Amazon reviews misspelled words graph</p>
			<p>Pluto notices that<a id="_idIndexMarker191"/> the <a id="_idIndexMarker192"/>biases in the Amazon reviews, as shown in <em class="italic">Figures 2.17</em>, <em class="italic">2.18</em>, and <em class="italic">2.19</em>, are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>There are more grammatical errors in the Amazon reviews than in the Netflix movie description. Thus, there could be bias against <span class="No-Break">well-written reviews.</span></li>
				<li>There are many more technical product names and jargon in the reviews. Therefore, there could be bias against <span class="No-Break">non-technical reviewers.</span></li>
				<li>There are many outlines. The mean is 50.46 words per review, with the bulk feedback between 20 and 180 words. It is worth digging deeper using other columns, such as <strong class="source-inline">helpful_yes</strong>, <strong class="source-inline">total_vote</strong>, and <strong class="source-inline">score_pos_neg_diff</strong>, to see if there is bias in the review length <span class="No-Break">per category.</span></li>
				<li>The Amazon reviews have more misspelled words than the Netflix movie description, reinforcing the well-written <span class="No-Break">reviewer’s bias.</span></li>
			</ul>
			<p>Before jumping into <a id="_idIndexMarker193"/>the summary, here is <a id="_idIndexMarker194"/>a <span class="No-Break">fun fact.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Cathy O’Neil’s book, <em class="italic">Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</em>, published in 2016, describes many biases in algorithms and AI, and it is a must-read for data scientists and college students. The two prominent examples are an accomplished teacher fired by a computer algorithm and a qualified college student rejected by the candidate <span class="No-Break">screening software.</span></p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor056"/>Summary</h1>
			<p>This chapter was not a typical one in this book because we discussed more theory than practical data augmentation techniques. At first, the link between data biases and data augmentation seems tenuous. Still, as you begin to learn about computational, human, and systemic biases, you see the strong connection because they all share the same goal of ensuring successful ethical AI system usage <span class="No-Break">and acceptance.</span></p>
			<p>In other words, data augmentation increases the AI’s prediction accuracy while reducing the data biases in augmenting, ensuring the AI forecast has fewer false-negative and <span class="No-Break">true-negative outcomes.</span></p>
			<p>The computational, human, and systemic biases are similar but are not mutually exclusive. However, providing plenty of examples of real-world biases and observing three real-world image datasets and two real-world text datasets made these biases easier <span class="No-Break">to understand.</span></p>
			<p>The nature of data bias in augmenting makes it challenging to compute biases programmatically. However, you learned to write Python code for the fairness matrix in the text dataset using word counts and misspelled word techniques. You could use generative AI, such as Stable Diffusion or DALL-E, to automatically spot the biases in the photo and use OpenAI GPT3, GPT4, or Google Bard to compute the biases in text data. Unfortunately, generative AI is outside the scope of <span class="No-Break">this book.</span></p>
			<p>Initially, Pluto tended to go slow with step-by-step explanations, but as you learned, he shortened the justification and showed only the bare minimum code. The complete code can be found in the <span class="No-Break">Python Notebook.</span></p>
			<p>Most of the Python code is devoted to teaching you how to download real-world datasets from the <em class="italic">Kaggle</em> website and importing the metadata into pandas. The later chapters will reuse these helper and <span class="No-Break">wrapper functions.</span></p>
			<p>Throughout this chapter, there were <em class="italic">fun facts</em> and <em class="italic">fun challenges</em>. Pluto hopes you will take advantage of these and expand your experience beyond the scope of <span class="No-Break">this chapter.</span></p>
			<p>Pluto looks forward to <a href="B17990_03.xhtml#_idTextAnchor058"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, where he will play with image augmentation <span class="No-Break">in Python.</span></p>
		</div>
	

		<div id="_idContainer033" class="Content">
			<h1 id="_idParaDest-57"><a id="_idTextAnchor057"/>Part 2: Image Augmentation</h1>
			<p>This part includes the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B17990_03.xhtml#_idTextAnchor058"><em class="italic">Chapter 3</em></a>, <em class="italic">Image Augmentation for Classification</em></li>
				<li><a href="B17990_04.xhtml#_idTextAnchor082"><em class="italic">Chapter 4</em></a>, <em class="italic">Image Augmentation for Segmentation</em></li>
			</ul>
		</div>
	</body></html>