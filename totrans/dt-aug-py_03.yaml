- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image Augmentation for Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image augmentation in **machine learning** (**ML**) is a stable diet for increasing
    prediction accuracy, especially for the image classification domain. The causality
    logic is linear, meaning the more robust the data input, the higher the forecast
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Deep learning** (**DL**) is a subset of ML that uses artificial neural networks
    to learn patterns and forecast based on the input data. Unlike traditional ML
    algorithms, which depend on programmer coding and rules to analyze data, DL algorithms
    automatically learn, solve, and categorize the relationship between data and labels.
    Thus, expanding the datasets directly impacts DL predictions on new insights that
    the model has not seen in the training data.'
  prefs: []
  type: TYPE_NORMAL
- en: DL algorithms are designed to mimic the human brain, with layers of neurons
    that process information and pass it on to the next layer. Each layer of neurons
    learns to extract increasingly complex features from the input data, allowing
    the network to identify patterns and make predictions with increasing accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: DL for image classification has proven highly effective in various industries,
    ranging from healthcare, finance, transportation, and consumer products to social
    media. Some examples include *identifying 120 dog breeds*, *detecting cervical
    spine fractures*, *cataloging landmarks*, *classifying Nike shoes*, *spotting
    celebrity faces*, and *separating paper and plastic* *for recycling*.
  prefs: []
  type: TYPE_NORMAL
- en: There is no standard formula to estimate how many images you need to achieve
    a designer prediction accuracy for image classification. Acquiring additional
    photos may not be a viable option because of cost and time. On the other hand,
    image data augmentation is a cost-effective technique that increases the number
    of photos for image classification training.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter consists of two parts. First, you will learn the concepts and techniques
    of augmentation for image classification, followed by hands-on Python coding and
    a detailed explanation of the image augmentation techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: The image dataset is typically broken into 75% training, 20% validation, and
    5% testing in the image classification model. Typically, the images allotted for
    training are augmented but outside the validation and testing set.
  prefs: []
  type: TYPE_NORMAL
- en: The two primary approaches for image augmentation are pre-processing and dynamic.
    They share the same techniques but differ when augmentation is done. The pre-processing
    method creates and saves the augmented photos in disk storage before training,
    while the dynamic method expands the input images during the training cycle.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038), you learned about data biases,
    and it is worth remembering that image augmentation will increase the DL model’s
    accuracy and may also increase the biases.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to biases, the other noteworthy concept is *safety*. It refers to
    the distortion magnitude that does not alter the original image label post-transformation.
    Different photo domains have different *safety* levels. For example, horizontally
    flipping a person’s portrait photo is an acceptable augmentation technique, but
    reversing the hand gesture images in sign language is unsafe.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will have learned the concepts and hands-on
    techniques in Python coding for classification image augmentation using real-world
    datasets. In addition, you will have examined several Python open source libraries
    for image augmentation. In particular, this chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Photometric transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random erasing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcing your learning through Python code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geometric transformations are the primary image augmentation technique used
    commonly across multiple image datasets. Thus, this is a good place to begin discussing
    image augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: Geometric transformations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Geometric transformation alters the photo’s geometry, which is done by flipping
    along the X-axis or Y-axis, cropping, padding, rotating, warping, and translation.
    Complex augmentation uses these base photo-altering techniques. While working
    with geometric transformations, the distortion magnitude has to be kept to a safe
    level, depending on the image topic. Thus, no general formula governing geometric
    transformation applies to all photos. In the second half of this chapter, the
    Python coding section, you and Pluto will download real-world image datasets to
    define the safe level for each image set.
  prefs: []
  type: TYPE_NORMAL
- en: The following techniques are not mutually exclusive. You can combine horizontal
    flipping with cropping, resizing, padding, rotating, or any combination thereof.
    The one constraint is the safe level for distortion.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, you will learn the following techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: Flipping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cropping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resizing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Padding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rotating
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Noise injection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with flipping.
  prefs: []
  type: TYPE_NORMAL
- en: Flipping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The two flipping types are the horizontal Y-axis and the vertical X-axis. Turning
    the photos along the Y-axis is like looking in a mirror. Therefore, it can be
    used for most types of pictures except for directional images such as street signs.
    There are many cases where rotating along the X-axis is not safe, such as landscape
    or cityscape images where the sky should be at the top of the picture.
  prefs: []
  type: TYPE_NORMAL
- en: It is not an either-or proposition, and the image can use horizontal and vertical
    flips, such as aerial photos from a plane. Therefore, flipping is generally safe
    to use. However, some pictures are not safe for either transformation, such as
    street signs, where any rotation changes the integrity of the original label post-translation.
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, you will learn how to flip images using Python code with
    an image augmentation library, but for now, here is a teaser demonstration. The
    function’s name is `pluto.draw_image_teaser_flip()`; the explanation will come
    later.
  prefs: []
  type: TYPE_NORMAL
- en: 'The image output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 3.1 – Image vertic\uFEFFal flip](img/B17990_03_01.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – Image vertical flip
  prefs: []
  type: TYPE_NORMAL
- en: Flipping keeps all the image content intact. However, the following technique,
    known as cropping, loses information.
  prefs: []
  type: TYPE_NORMAL
- en: Cropping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cropping an image involves removing the edges of the picture. Most **convolutional
    neural networks** (**CNNs**) use a square image as input. Therefore, photos in
    portrait or landscape mode are regularly chopped to a square image. In most cases,
    the removal of the edges is based on the center of the picture, but there is no
    rule implying it has to be the center of the image.
  prefs: []
  type: TYPE_NORMAL
- en: The photo’s center point is 50% of the width and 50% of the height. However,
    in image augmentation, you can choose to move the cropping center to 45% of the
    width and 60% of the height. The cropping center can vary, depending on the photo’s
    subject. Once you have identified the safe range for moving the cropping center,
    you can try dynamically cropping the images per training epoch. Thus, every training
    epoch has a different set of photos. The effect is that the ML model will likely
    not overfit and gives higher accuracy from having more images.
  prefs: []
  type: TYPE_NORMAL
- en: The `pluto.draw_image_teaser_crop()` function is another teaser demonstration.
    Moving forward, I will only display the teaser images for some augmentation methods
    since you will learn about all of them in more depth by using Python code later
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output image for **center cropping** is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Image center crop](img/B17990_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – Image center crop
  prefs: []
  type: TYPE_NORMAL
- en: Cropping is not the same as resizing an image, which we will discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Resizing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Resizing can be done by keeping the aspect ratio the same or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Zooming** is the same as enlarging, cropping, and maintaining the same aspect
    ratio.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Squishing** is the same as enlarging or shrinking and changing the original
    aspect ratio. The safe level for zooming, squishing, or other resizing techniques
    depends on the image category.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `pluto.draw_image_teaser_resize()` function is a fun demonstration of **resizing**
    an image using the **squishing** mode. The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Image resizing with squishing mode](img/B17990_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – Image resizing with squishing mode
  prefs: []
  type: TYPE_NORMAL
- en: When resizing a photo and not keeping the original aspect ratio, you need to
    pad the new image. There are different methods for **padding**.
  prefs: []
  type: TYPE_NORMAL
- en: Padding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Padding involves filling the outer edge of the canvas that is not an image.
    There are three popular methods for padding:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Zero padding** refers to padding the image with black, white, gray, or Gaussian
    noise'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reflection padding** mirrors the padding area with the original image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Border padding** involves repeating the borderline in the padding section'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Padding is used in combination with cropping, resizing, translation, and rotating.
    Therefore, the safe proportion depends on cropping, resizing, and rotating.
  prefs: []
  type: TYPE_NORMAL
- en: Rotating
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rotating an image involves turning the picture clockwise or counterclockwise.
    The measurement of turning is by a degree and clockwise direction. Therefore,
    turning 180 degrees is the same as flipping vertically, while rotating 360 degrees
    returns the photo to its original position.
  prefs: []
  type: TYPE_NORMAL
- en: General rotating operates on the X-Y plane, whereas turning in the Z plane is
    known as **tilting**. **Skewing** or **shearing** involves rotating on all three
    planes – that is, X, Y, and Z. As with most geometric transformations, rotating
    is a safe operation with a set limit for some image datasets and not for others.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pluto.draw_image_teaser_rotate()` function is a fun demonstration of **rotating**
    an image with **reflection padding** mode. The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Image rotating and reflection padding mode](img/B17990_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – Image rotating and reflection padding mode
  prefs: []
  type: TYPE_NORMAL
- en: Similar to rotating is shifting the images, which leads to the next technique,
    known as translation.
  prefs: []
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The translation method shifts the image left or right along the X-axis or up
    or down along the Y-axis. It uses padding to backfill the negative space left
    by shifting the photo. Translation is beneficial for reducing center image biases,
    such as when people’s portraits are centered in the picture. The photo’s subject
    will dictate the safe parameters for how much to move the images.
  prefs: []
  type: TYPE_NORMAL
- en: The next geometric transformation is different from the ones we’ve talked about
    so far because noise injection reduces the photo’s clarity.
  prefs: []
  type: TYPE_NORMAL
- en: Noise injection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Noise injection adds random black, white, or color pixels to a picture. It creates
    a grainy effect on the original image. Gaussian noise is a de facto standard for
    generating natural noises in a photo. It is based on the Gaussian distribution
    algorithm developed by mathematician Carl Friedrich Gauss in the 1830s.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pluto.draw_image_teaser_noise()` function is a fun demonstration of **noise
    injection** using **Gaussian** mode. The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Image noise injection using Gaussian mode](img/B17990_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – Image noise injection using Gaussian mode
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a thought experiment: can you think of other geometric image transformations?
    Hint: use the Z-axis, not just the X-axis and the Y-axis.'
  prefs: []
  type: TYPE_NORMAL
- en: In the second part of this chapter, Pluto and you will discover how to code
    geometric transformations, such as flipping, cropping, resizing, padding, rotation,
    and noise injection, but there are a few more image augmentations techniques to
    learn first. The next category is photometric transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Photometric transformations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Photometric transformations are also known as lighting transformations.
  prefs: []
  type: TYPE_NORMAL
- en: 'An image is represented in a three-dimensional array or a rank 3 tensor, and
    the first two dimensions are the picture’s width and height coordinates for each
    pixel position. The third dimension is a **red, blue, and green** (**RGB**) value
    ranging from zero to 255 or #0 to #FF in hexadecimal. The equivalent of RGB in
    printing is **cyan, magenta, yellow, and key** (**CMYK**). The other popular format
    is **hue, saturation, and value** (**HSV**). The salient point is that a photo
    is a matrix of an integer or float when normalized.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the image as a matrix of numbers makes it easy to transform it.
    For example, in HSV format, changing the **saturation** value to zero in the matrix
    will convert an image from color into grayscale.
  prefs: []
  type: TYPE_NORMAL
- en: Dozens of filters alter the color space characteristics, from the basics to
    exotic ones. The basic methods are **darkened**, **lightened**, **sharpened**,
    **blurring**, **contrast**, and **color casting**. Aside from the basics, there
    are too many filter categories to list here, such as **retro**, **groovy**, **steampunk**,
    and many others. Furthermore, photo software, such as Adobe Photoshop, and online
    image editors create new image filters frequently.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, this section will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic and classic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced and exotic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s begin with basic and classic.
  prefs: []
  type: TYPE_NORMAL
- en: Basic and classic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Photometric transformations in image augmentation are a proven technique for
    increasing AI model accuracy. Most scholarly papers, such as *A comprehensive
    survey of recent trends in deep learning for digital images augmentation*, by
    Nour Eldeen Khalifa, Mohamed Loey, and Seyedali Mirjalili, published by *Artificial
    Intelligence Review* on September 4, 2021, use the classic filters exclusively
    because code execution is fast. There are many open source Python libraries for
    the classic filters, which Pluto and you will explore later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, you will learn the following classic techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: Darken and lighten
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Color saturation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hue shifting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Color casting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contrast
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s begin with the most common technique: the darken and lighten filter.'
  prefs: []
  type: TYPE_NORMAL
- en: Darken and lighten
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lightening an image means increasing the brightness level, while lowering the
    brightness value means darkening an image. In Python code, a photo is an integer
    or float values matrix, and once converted into HSV format, raising or lowering
    the **value** (**V**) in the HSV matrix increases or decreases the picture’s brightness
    level.
  prefs: []
  type: TYPE_NORMAL
- en: When it is time for you to write the functions for lightening or darkening the
    image for the Pluto object, you will use a Python image library to do the heavy
    lifting, but it is not hard to write the code from scratch. The safe range for
    the brightness value depends on the image subject and label target.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pluto.draw_image_teaser_brightness()` function is a fun demonstration
    of **darkening** an image. The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Image brightness, darken mode](img/B17990_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – Image brightness, darken mode
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, color saturation is also easy to code in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Color saturation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Color saturation involves increasing or decreasing the intensity of the color
    in a photo. By reducing the saturation values close to zero, the image becomes
    a grayscale image. Inversely, the picture will show a more intense or vibrant
    color when raising the saturation value.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the brightness level coding, manipulating the picture’s **saturation**
    (**S**) value in the HSV matrix gives the desired effects. The safe range for
    color saturation depends on the image subject and label target.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve looked at the *S* and the *V* in *HSV*, but what does the *H*
    value do? It is for hue shifting.
  prefs: []
  type: TYPE_NORMAL
- en: Hue shifting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Shifting the **hue** (**H**) value in the Python image matrix in HSV format
    alternates the photo’s color. Typically, a circle represents the hue values. Thus,
    the value starts at zero and ends at 360 degrees. Red is at the top of the rotation,
    beginning with zero, followed by yellow, green, cyan, blue, and magenta. Each
    color is separated by 60 degrees. Therefore, the last color, magenta, starts at
    310 and ends at 360 degrees.
  prefs: []
  type: TYPE_NORMAL
- en: Hue shifting is an excellent image editing filter, but for AI image augmentation,
    it is not helpful because it distorts the image beyond the intended label. For
    example, suppose you are developing an AI model to classify different species
    of chameleons. In that case, the hue-switching technique is sufficient for image
    augmentation. Still, if your project is to differentiate cats and fluffy furball
    toys, it might lead to false positives because you would get fluorescent pink
    cats.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pluto.draw_image_teaser_hue()` function is a fun demonstration of **hue
    shifting**. The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – Image hue shifting](img/B17990_03_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – Image hue shifting
  prefs: []
  type: TYPE_NORMAL
- en: Similar to hue shifting is color casting.
  prefs: []
  type: TYPE_NORMAL
- en: Color casting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Color casting is also known as color tinting. It is when the white color is
    not balanced or is inaccurate. The tint colors are commonly **red, green, or blue**
    (**RGB**). In Python, tinting a photo is as easy as altering the RGB value in
    the image matrix. There is the same concern for the safe range as in the hue-shifting
    filter. In other words, color casting has limited use in AI image augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: There is no formal definition of which filters are basic or classic and which
    are advanced and exotic. Hence, we have chosen to look at the contrast filter
    for our final example of classic photometric transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Contrast
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Contrast is the difference in luminance or color that distinguishes objects
    in a picture from one another. For example, most photographers want a high contrast
    between a person in the foreground concerning the background. Usually, the foreground
    object is brighter and in sharper focus than the background. The safe range for
    the contrast value depends on the image subject and label target.
  prefs: []
  type: TYPE_NORMAL
- en: Pluto and you will explore the contrast filter and all other classic photometric
    transformations using Python code in the second half of this chapter. The following
    section will cover advanced and exotic filters.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced and exotic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The advanced or exotic techniques have no Python library for implementing these
    filters in data augmentation. Online photo editing websites and desktop software
    frequently create new exotic filters monthly.
  prefs: []
  type: TYPE_NORMAL
- en: If you review the filters section of *Adobe Photoshop* or many online photo
    editing websites, such as [www.fotor.com](https://www.fotor.com), you will find
    dozens or hundreds of filter options. Specialized filters for image subjects include
    people portraits, landscapes, cityscapes, still life, and many others. Filters
    are also categorized by styles, such as retro, vintage, steampunk, trendy, mellow,
    groovy, and many others.
  prefs: []
  type: TYPE_NORMAL
- en: The exotic filters are not featured in scholarly papers partly due to the lack
    of available Python libraries and the high CPU or GPU resource time to perform
    these operations during the training cycle. Nevertheless, in theory, exotic filters
    are excellent techniques for image augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do a thought experiment. Can generative AI, like stable diffusion or
    DALL-E, create new images for augmentation? Generative AI can create hundreds
    or thousands of images from input text. For example, let’s say you’ve been tasked
    with developing an AI for identifying a unicorn, pegasus, or minotaur; is it more
    difficult to find images of those mythical creatures in print or real life? Generative
    AI can do this, but is it a practical technique? Hint: think about static versus
    dynamic augmentation disk space and time.'
  prefs: []
  type: TYPE_NORMAL
- en: Photometric and geometric transformations manipulate photos, but random erasing
    adds new elements to a picture.
  prefs: []
  type: TYPE_NORMAL
- en: Random erasing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random erasing selects a rectangle region in an image and replaces or overlays
    it with a gray, black, white, or Gaussian noise pixels rectangle. It is counterintuitive
    to why this technique increases the AI model’s forecasting accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The strength of any ML model, especially CNN, is in predicting or forecasting
    data that has not been seen in the training or validating stage. Thus, dropout,
    where randomly selected neurons are ignored during training, is a well-proven
    method to reduce overfitting and increase accuracy. Therefore, random erasing
    has the same effect as increasing the dropout rate.
  prefs: []
  type: TYPE_NORMAL
- en: A paper called *Random Erasing Data Augmentation*, which was published on November
    16, 2017, by arXiv, shows how random erasing increases accuracy and reduces overfitting
    in a CNN-based model. The paper’s authors are Zhun Zhong, Liang Zheng, Guoliang
    Kang, Shaozi Li, and Yi Yang from the Cognitive Science Department, at Xiamen
    University, China, and the University of Technology Sydney, Australia.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, the random erasing rectangle region, also known as the cutout, is
    filled with random pixels using *Gaussian randomization*. The safe range for random
    erasing depends on the image subject and label target.
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: There is one creative example of using random erasing in image augmentation
    that reduces biases. In a self-driving automobile system, one of the image classification
    models is to identify and classify street signs. The AI model was trained with
    clear and pristine street sign photos, so the AI model was biased against the
    real-world pictures of street signs in poor neighborhoods in the USA, where street
    signs are defaced with graffiti and abused. Randomly adding cutouts of graffiti,
    paint, dirt, and bullet holes increased the model’s accuracy and reduced overfitting
    and biases against poor neighborhood street signs.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the image dataset subject, random erasing, photometric, and geometric
    transformations can be mixed and matched. Let’s discuss this in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Combining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The techniques or filters in geometric transformations can be readily combined
    with most image topics. For example, you can mix horizontal flip, cropping, resizing,
    padding, rotation, translation, and noise injection for many domains, such as
    people, landscapes, cityscapes, and others.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, taking landscape as a topic, you can combine many filters in photometric
    transformations, such as darkening, lightening, color saturation, and contrast.
    Hue shifting and color casting may not apply to landscape photos. However, advanced
    photographic transformation filters, such as adding rain or snow to landscape
    images, are acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s more: you can add random erasing to landscape images. As a result,
    1,000 landscape images may increase to 200,000 photos for training. That is the
    power of image augmentation.'
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a thought experiment: should you augment the entire image dataset or
    only a segment?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data augmentation can generate hundreds of thousands of new images for training,
    increasing AI prediction accuracy by decreasing the overfitting problem. But what
    if you also augmented the validation and testing dataset? Hint: think about real-world
    applications, DL generalization, and false negatives and false positives.'
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have discussed various image augmentation filters and techniques.
    The next step is for you and Pluto to write Python code to reinforce your understanding
    of these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcing your learning through Python code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will pursue the same approach as in [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038).
    Start by loading the `data_augmentation_with_python_chapter_3.ipynb` file in Google
    Colab or your chosen Jupyter Notebook or JupyterLab environment. From this point
    onward, the code snippets will be from the Python Notebook, which contains all
    the functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter’s coding lessons topics are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Pluto and the Python Notebook
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-world image dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image augmentation library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geometric transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Photometric transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random erasing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next step is to download, set up, and verify that Pluto and the Python Notebook
    are working adequately.
  prefs: []
  type: TYPE_NORMAL
- en: Pluto and the Python Notebook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before loading Pluto from [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038), we
    must retrieve him by cloning this book’s `%run` magic command, we can invoke Pluto.
    If you improved or hacked Pluto, load that file. You should review [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038)
    if these steps are not familiar to you.
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: The startup process for coding is the same for every chapter. Pluto only displays
    the essential code snippets in this book, and he relies on you to review the complete
    code in the Python Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following code to clone the Python Notebook and invoke Pluto:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Double-check that Pluto has loaded correctly by running the following code
    in the Python Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows or something similar, depending on your system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Pluto has verified that the Python Notebook is working correctly, so the next
    step is downloading real-world image datasets from the *Kaggle* website.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world image datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038), Pluto learned how to download
    thousands of real-world datasets from the *Kaggle* website. For this chapter,
    he has selected six image datasets to illustrate different image augmentation
    techniques. Still, you can substitute or add new *Kaggle* image datasets by passing
    the new URLs to the code in the Python Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Download two additional real-world datasets from the Kaggle website. Pluto
    likes to play fetch, so it is no problem for it to fetch new datasets. Hint: go
    to [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets) and search
    for **image classification**. Downloading additional real-world data will further
    reinforce your understanding of image augmentation concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto has chosen six image datasets based on the challenges each topic brings
    to bear on augmentation techniques. In other words, one concept may be acceptable
    for one subject but not for another. In particular, the six image datasets are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Covid-19 image dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indian people
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Edible and poisonous fungi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sea animals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vietnamese food
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mall crowd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: The code for downloading these six real-world datasets from the *Kaggle* website
    looks repetitive. It is easy by design because Pluto worked hard to create reusable
    methods in [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038). He wants it to be
    easy so that you can download any real-world dataset from the *Kaggle* website.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with the Covid-19 data.
  prefs: []
  type: TYPE_NORMAL
- en: Covid-19 image dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Medical is a popular category for AI image predictive models. Therefore, Pluto
    selected the *Covid-19 Image Dataset*. He fetched the pictures and made the necessary
    pandas DataFrame using the methods shown in [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038).
    Note that the complete code is in the Python Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following commands fetch and load the data into pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The first three records of the pandas DataFrame are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – The first three rows of the pandas DataFrame](img/B17990_03_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – The first three rows of the pandas DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: 'On the *Kaggle* website, the data’s context is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: “*Helping Deep Learning and AI Enthusiasts like me to contribute to improving
    Covid-19 detection using just Chest X-rays. It contains around 137 cleaned images
    of Covid-19 and 317 containing Viral Pneumonia and Normal Chest X-Rays structured
    into the test and train directories.*”
  prefs: []
  type: TYPE_NORMAL
- en: 'This citation is from the *University of Montreal*, and the collaborator listed
    is **Pranav Raikote** (owner), license: **CC BY-SA** **4.0**: [https://choosealicense.com/licenses/cc-by-sa-4.0](https://choosealicense.com/licenses/cc-by-sa-4.0).'
  prefs: []
  type: TYPE_NORMAL
- en: Now that Pluto has downloaded the Covid-19 data, it will start working on the
    *People* dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Indian People
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The second typical category in image prediction or classification is people.
    Pluto has chosen the *Indian People* dataset. The following code snippet from
    the Python Notebook fetches and loads the data into pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'On the *Kaggle* website, there is no description of the dataset. It’s not uncommon
    to get a dataset without an explanation or goals and be asked to augment it. The
    collaborator listed is **Ayush Sinha** (owner), license: **None, Visible to**
    **the public**.'
  prefs: []
  type: TYPE_NORMAL
- en: The typical usage for people data is to identify or classify age, sex, ethnicity,
    emotional sentiment, facial recognition, and many more.
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: There are controversial image classification AI systems, such as those for predicting
    people as criminals or not criminals, forecasting worthiness to society, identifying
    sexual orientation, and selecting immigrants or citizens. However, other creative
    uses include identifying a potential new whale – a super high casino spender from
    a casino installing cameras in the lobby and feeding them to an AI.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at the fungi data.
  prefs: []
  type: TYPE_NORMAL
- en: Edible and poisonous fungi
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The third most often used topic for image classification is safety, such as
    distracted drivers, poisonous snakes, or cancerous tumors. Pluto found the real-word
    *Edible and Poisonous Fungi* dataset on the *Kaggle* website. The following code
    snippet from the Python Notebook fetches and loads the data into pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'On the *Kaggle* website, the description is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: “*We created this dataset as part of our school’s research project. As we didn’t
    find something similar when we started, we decided to publish it here so that
    future research with mushrooms and AI can benefit from it.*”
  prefs: []
  type: TYPE_NORMAL
- en: 'The collaborator listed is **Marcos Volpato** (owner), license: **Open Data
    Commons Open Database License (****ODbL)**: [https://opendatacommons.org/licenses/odbl/1-0/](https://opendatacommons.org/licenses/odbl/1-0/).'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at the sea animals data.
  prefs: []
  type: TYPE_NORMAL
- en: Sea animals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The fourth theme is nature. Pluto selected the *Sea Animals Image Dataset*.
    The following commands fetch and load the data into pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The *Kaggle* website’s description for this dataset is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: “*Most life forms began their evolution in aquatic environments. The oceans
    provide about 90% of the world’s living space in terms of volume. Fish, which
    are only found in water, are the first known vertebrates. Some of these transformed
    into amphibians, which dwell on land and water for parts of the day.*”
  prefs: []
  type: TYPE_NORMAL
- en: 'The collaborators listed are **Vince Vence** (owner), license: **Other— Educational
    purposes and Free for Commercial Use (****FFCU)**: [https://www.flickr.com/people/free_for_commercial_use/](https://www.flickr.com/people/free_for_commercial_use/).'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at food data.
  prefs: []
  type: TYPE_NORMAL
- en: Vietnamese food
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The fifth widespread subject for image classification is food. Pluto found
    the *30VNFoods – A Dataset for Vietnamese Food Images Recognition* dataset. The
    following commands fetch and load the data into pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The *Kaggle* website’s description is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: “*This paper introduces a large dataset of 25,136 images of 30 popular Vietnamese
    foods. Several machine learning and deep learning image classification techniques
    have been applied to test the dataset, and the results were compared and reported.*”
  prefs: []
  type: TYPE_NORMAL
- en: 'The collaborators listed are **Quan Dang** (owner), **Anh Nguyen Duc Duy**
    (editor), **Hoang-Nhan Nguyen** (viewer), **Phuoc Pham Phu** (viewer), and **Tri
    Nguyen** (viewer), license: **CC BY-SA** **4.0**: [https://choosealicense.com/licenses/cc-by-sa-4.0](https://choosealicense.com/licenses/cc-by-sa-4.0).'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s move on to mall crowd data.
  prefs: []
  type: TYPE_NORMAL
- en: Mall crowd
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Pluto chose the sixth and last dataset for the creative use of AI image classification
    – the *Mall - Crowd Estimation* dataset. The following code snippet from the Python
    Notebook fetches and loads the data into pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The *Kaggle* website’s description is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: “The mall dataset was collected from a publicly accessible webcam for crowd
    counting and profiling research.”
  prefs: []
  type: TYPE_NORMAL
- en: 'The collaborator listed is **Feras** (owner), license: **None, Visible to**
    **the public**.'
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Refactor the code provided and write one function that downloads all six datasets.
    Hint: put the six *Kaggle* data URLs into an array. Pluto does not write the uber-big
    method because he focuses on making the augmentation techniques easier to understand
    rather than writing compact code that might obfuscate the meaning.'
  prefs: []
  type: TYPE_NORMAL
- en: After downloading all six datasets, Pluto must draw an image batch.
  prefs: []
  type: TYPE_NORMAL
- en: Drawing an image batch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s look at the pictures in the six datasets. Pluto will take samples from
    the pandas DataFrame and use the `draw_batch()` function defined in [*Chapter
    2*](B17990_02.xhtml#_idTextAnchor038).
  prefs: []
  type: TYPE_NORMAL
- en: 'The output for two Covid-19, two people, two fungi, two sea animals, one food,
    and one mall crowd picture are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 – Six image datasets](img/B17990_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – Six image datasets
  prefs: []
  type: TYPE_NORMAL
- en: Pluto has downloaded plenty of real-world pictures, so the next step is selecting
    an image augmentation library.
  prefs: []
  type: TYPE_NORMAL
- en: Image augmentation library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many open source Python image augmentation and processing libraries.
    Most libraries have filters for geometric and photometric transformations. In
    addition, a few libraries have specialized functions for particular image topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto will cover only some of these libraries. The most popular libraries are
    Albumentations, Fast.ai, **Pillow** (**PIL**), OpenCV, scikit-learn, Mahotas,
    and pgmagick:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Albumentations** is a fast and highly customizable image augmentation Python
    library. It has become the de facto standard for research areas related to computer
    vision and DL. Albumentations efficiently implements over 70 varieties of image
    transform operations optimized for performance. Albumentations’ substantial benefit
    is broad integration with many DL frameworks. It was introduced in 2019\. It can
    be found on GitHub at [https://github.com/albumentations-team/albumentations](https://github.com/albumentations-team/albumentations).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fast.ai** is a best-of-class for DL and AI library and framework. It was
    founded in 2016 by Jeremy Howard and Rachel Thomas to democratize DL. Fast.ai
    has extensive built-in functions for image augmentation. Furthermore, its image
    augmentation operations use GPU, so it is possible to perform dynamic image augmentation
    during the training cycle. In other words, because of the GPU, it is the best
    performance image augmentation library in the market. It can be found on GitHub
    at [https://github.com/fastai](https://github.com/fastai).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pillow** is a friendly modern fork of the **Python Imaging Library** (**PIL**)
    repository. PIL is a popular open source library for image processing and augmentation
    because it was first released in 1995\. Many open source Python image processing,
    displaying, and augmenting libraries are built on top of PIL. It can be found
    on GitHub at [https://github.com/python-pillow/Pillow](https://github.com/python-pillow/Pillow).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AugLy** is an open source Python project by Meta (Facebook) for data augmentation.
    The library provides over 100 audio, video, image, and text data augmentation
    methods. It can be found on GitHub at [https://github.com/facebookresearch/AugLy](https://github.com/facebookresearch/AugLy).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenCV** was developed by Intel in 2000 as an open source library. ML primarily
    uses OpenCV in computer vision tasks such as object classification and detection,
    face recognition, and image segmentation. In addition, OpenCV contains essential
    methods for ML. It can be found on GitHub at [https://github.com/opencv/opencv](https://github.com/opencv/opencv).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scikit-learn** was one of the early open source libraries in 2009 for image
    augmentation. Part of scikit-learn is written in Cython, a programming language
    that is a superset of Python. One of its crucial benefits is high-performance
    speed, where a NumPy array is used as the image’s structure. It can be found on
    GitHub at [https://github.com/scikit-image/scikit-image](https://github.com/scikit-image/scikit-image).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mahotas** is an image processing and augmentation library specialized in
    bioimage informatics. Mahotas uses NumPy arrays and is written C++ with a Python
    interface. It was released in 2016\. It can be found on GitHub at [https://github.com/luispedro/mahotas](https://github.com/luispedro/mahotas).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pgmagick**: pgmagick is a GraphicsMagick binding for Python. GraphicsMagick
    is best known for supporting large images in a gigapixel-size range. It was initially
    derived from ImageMagick in 2002\. It can be found on GitHub at [https://github.com/hhatto/pgmagick](https://github.com/hhatto/pgmagick).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No library is better than another, and you can choose to use multiple libraries
    in a project. However, Pluto recommends picking two or three libraries and becoming
    proficient, maybe even an expert, in them.
  prefs: []
  type: TYPE_NORMAL
- en: Pluto will hide the library or libraries and create a wrapper function, such
    as `draw_image_flip()`, that uses other libraries to perform the transformation.
    The other reason for writing wrapper functions is to switch out the libraries
    and minimize the code changes. Pluto has chosen the **Albumentations**, **Fast.ai**,
    and **PIL** libraries for this chapter as the under-the-hood engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have two options: creating image augmentation dynamically per batch or
    statically. When doing this statically, also known as pre-processing, you create
    and save the augmented pictures in your local or cloud drive.'
  prefs: []
  type: TYPE_NORMAL
- en: For this chapter, Pluto has chosen to augment the image dynamically because,
    depending on the combinations of filters, you can generate over a million acceptable
    altered pictures. The only difference between the two methods is that the pre-processing
    method saves the augmented photos in local or cloud drives while the dynamic method
    does not.
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a thought experiment: should you select an augmentation library with
    more augmented methods over a library that runs on GPU? Hint: think about the
    goal of your project and its disk and time resources.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin writing code for the geometric transformation filters.
  prefs: []
  type: TYPE_NORMAL
- en: Geometric transformation filters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pluto can write Python code for many geometric transformation filters, and he
    will select two or three image datasets to illustrate each concept. In addition,
    by using multiple image subjects, he can discover the safe level. The range for
    the safe level is subjective, and you may need to consult a domain subject expert
    to know how far to distort the photo. When convenient, Pluto will write the same
    method using different libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with flipping images.
  prefs: []
  type: TYPE_NORMAL
- en: Flipping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Pluto will begin with the simplest filter: the horizontal flip. It mirrors
    the image, or in other words, it flips the photo along the Y-axis. The wrapper
    function is called `draw_image_flip()`. All image augmentation methods are prefixed
    with `draw_image_` as this makes it easy for Pluto to remember them. In addition,
    he can use the Python Notebook auto-complete typing feature. By typing `pluto.draw_im`,
    a popup menu containing all the filter functions will be displayed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `draw_image_flip_pil()` function, when using the PIL library, the relevant
    code line is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Thus, Pluto selects an image from the People dataset and flips it using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows, with the original image at the top and the flip image
    at the bottom:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – Horizontal flip using the PIL library](img/B17990_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 – Horizontal flip using the PIL library
  prefs: []
  type: TYPE_NORMAL
- en: Rather than viewing one image at a time, it is more advantageous to examine
    the entire dataset one batch at a time. This is because a filter may be applicable,
    or the **safe** range is acceptable for one image but not for another in the same
    dataset. The **F****ast.ai** library has the data-batch class that supports many
    ML functions, including accepting a transformation method and displaying a random
    collection of pictures, also known as displaying a batch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto will write two new methods: `_make_data_loader()`, which is a helper
    function for creating the `draw_image_flip()` function, which encodes the transformation
    for horizontal flip and displays the image batch using the data-loader `show_batch()`
    method.'
  prefs: []
  type: TYPE_NORMAL
- en: '`show_batch()` will select a random set of pictures to display, where `max_n`
    sets the number of images in a bunch. The Fast.ai transformation, by default,
    performs the modification at 75% probability. In other words, three out of four
    images in the dataset will be transformed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The horizontal flip filter has no safe level, regardless of whether it applies
    to the image set. Pluto will use the `draw_image_flip()` method with the `aug`
    value, is different. The entirety of the flip wrapper code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The definition of the `aug` variable differs from one wrapper function to another.
    Pluto needs to run a function on the Python Notebook for the People dataset with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 3.11 – Horizontal flip on the People dataset](img/B17990_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – Horizontal flip on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: The complete fully functional object-oriented code can be found in the Python
    Notebook. You can hack it to show flip, rotate, tilt, and dozens of other augmentation
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure the horizontal flip is acceptable, you can repeatedly run the `draw_image_flip()`
    function in the Python Notebook to see a collection of varying image batches.
    Horizontal flip is a safe filter for fungi, sea animals, food, and mall crowd
    pictures. Common sense dictates that you wouldn’t expect otherwise. Here is the
    command for the Fungi dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12 – Horizontal flip on the Fungi dataset](img/B17990_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 – Horizontal flip on the Fungi dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'For medical images, such as the Covid-19 photos, you need a domain expert to
    confirm that flipping horizontally does not change the image’s integrity. It does
    not make any difference to the layman, but it can be deceptively wrong and might
    create a **false-positive** or **false-negative** prediction. Here is the command
    for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.13 – Horizontal flip on the Covid-19 dataset](img/B17990_03_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 – Horizontal flip on the Covid-19 dataset
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the Fast.ai transformation cropped the images center square. Therefore,
    in some pictures, content is lost – for example, a picture of a woman with most
    of her face missing. This is because Fast.ai is for ML, so the images need to
    be square. The default behavior is a center square crop.
  prefs: []
  type: TYPE_NORMAL
- en: Before Pluto can start cropping and padding, he must complete the flipping filter
    by combining horizontal flipping with vertical flipping. The people, Covid-19,
    fungi, and mall crowd pictures cannot be flipped vertically, but the sea animals
    and food pictures can.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, Pluto needs to create the `draw_image_flip_both()` method, with the
    transformation set to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, Pluto must run the function on the People dataset with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.14 – Unsafe horizontal and vertical flips on the People dataset](img/B17990_03_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.14 – Unsafe horizontal and vertical flips on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'He can apply the same function to the food pictures, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.15 – Safe horizontal and vertical flips on the food dataset](img/B17990_03_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.15 – Safe horizontal and vertical flips on the food dataset
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: Pluto loves to play the same game over and over again. You know, because he
    is a dog. :-) Thus, you can ask Pluto to run any wrapper functions repeatedly
    on the Python Notebook to see a different set of image batches from the data stored
    in pandas. Each real-world image dataset contains thousands of photos, and each
    batch displays 15 images; therefore, you must run the wrapper functions repeatedly
    to have a good mental picture of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The next filters we will look at are for cropping and padding.
  prefs: []
  type: TYPE_NORMAL
- en: Cropping and padding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Reusing the same process as when writing the flipping filter, Pluto can write
    the `draw_image_crop()` method. The one new code line uses a different item transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The padding mode can be **zeros**, which means the padding color is black, **border**,
    which means the padding repeats the border pixel, or **reflection**, which means
    padding is mirrored from the picture.
  prefs: []
  type: TYPE_NORMAL
- en: After much trial and error on the Python Notebook, Pluto found the safe range
    for cropping and padding for each of the six datasets. Before moving on, Pluto
    encourages you to use the Python Notebook to find the best safe parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto found that the safe setting for the people data is using a cropped image
    size of 640 and pad mode on the border:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.16 – Horizontal and vertical flip on the People dataset](img/B17990_03_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.16 – Horizontal and vertical flip on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of the next dataset, Pluto found that the safe setting for the fungi
    images is a cropped image size of 240 and a pad mode of zeros:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 3.17 – Horizontal and vertical flip on the \uFEFFfungi dataset](img/B17990_03_17.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 3.17 – Horizontal and vertical flip on the fungi dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'For the food pictures, Pluto discovered that the safe parameters are a cropped
    image size of 640 and a pad mode of reflection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.18 – Horizontal and vertical flip on the food dataset](img/B17990_03_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.18 – Horizontal and vertical flip on the food dataset
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: Find the safe cropping parameters for all six image datasets. You will get bonus
    points for applying these new functions to the set of images from your project
    or downloading them from the Kaggle website.
  prefs: []
  type: TYPE_NORMAL
- en: For the other image datasets, the results are in the Python Notebook. The safe
    parameter is 340 pixels with reflection padding for the sea animals pictures and
    512 pixels with border padding for the mall crowd pictures. A cropping filter
    is not an option for the Covid-19 pictures.
  prefs: []
  type: TYPE_NORMAL
- en: Next, Pluto will rotate images, which is similar to flipping.
  prefs: []
  type: TYPE_NORMAL
- en: Rotating
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Rotation specifies how many degrees to turn the image clockwise or counter-clockwise.
    Since Pluto sets the max rotation value, the actual rotation is a random number
    between the minimum and the maximum value. The minimum default value is zero.
    Therefore, a higher maximum value will generate more augmentation images because
    every time the system fetches a new data batch, a different rotation value is
    chosen. In addition, randomness is the reason for selecting the dynamic augmentation
    option over saving the images to a local disk drive, as in the static option.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, Pluto has written the `draw_image_rotate()` method using the `max_rotate
    = max_rotate` transformation parameter, where the second `max_rotate` is the passed-in
    value. The key code line in the wrapper function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Once again, Pluto has arrived at the following safe parameter for rotating after
    much trial and error on the Python Notebook, but don’t take Pluto’s word for it.
    Pluto challenges you to find better safe parameters by experimenting with the
    Python Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sea animals data, Pluto has arrived at a safe parameter of `180.0`
    for the maximum rotation and reflection for padding. The command in the Python
    Notebook is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.19 – Rotation on the sea animals dataset](img/B17990_03_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.19 – Rotation on the sea animals dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'For the people pictures, Pluto has arrived at a safe parameter of `25.0` for
    the maximum rotation and border for padding. The command in the Python Notebook
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.20 – Rotation on the People dataset](img/B17990_03_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.20 – Rotation on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: For the other image datasets, the results are in the Notebook. The safe parameters
    are `16.0` maximum rotation with border padding for the mall crowd photos, `45.0`
    maximum rotation with border padding for the fungi pictures, `90.0` maximum rotation
    with reflection padding for the food images, and `12.0` maximum rotation with
    border zeros for the Covid-19 data. I encourage you to extend beyond Pluto’s safe
    range on the Notebook and see what happens to the pictures for yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s continue with the shifting image theme. The next filter we’ll look
    at is the translation filter.
  prefs: []
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The translation filter shifts the image to the left, right, up, or down. It
    is not one of the commonly used filters. Pluto uses the `ImageChops.offset()`
    method in the `draw_image_shift()` function. A negative horizontal shift value
    moves the image to the left, a positive value moves the image to the right, and
    the vertical shift parameter moves the image up or down. The relevant code line
    in the wrapper function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To test the function, Pluto selects a picture and shifts it left by 150 pixels
    and up by 50 pixels. The command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.21 – Translation using the PIL library; the top image is the original](img/B17990_03_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.21 – Translation using the PIL library; the top image is the original
  prefs: []
  type: TYPE_NORMAL
- en: The translation filter is seldom used because it is easy to find the safe level
    for one picture but not for the entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: So far, Pluto has shown you the **flipping**, **cropping**, **padding**, **resizing**,
    **rotating**, and **translation** filters. However, there are many more geometric
    transformation filters, such as for **warping**, **zooming**, **tilting**, and
    **scaling**. Unfortunately, there are too many to cover, but the coding process
    is the same.
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement two more geometric transformation techniques, such as warping and
    tilting. Hint: copy and paste from Pluto’s wrapper functions and change the `aug`
    and `item_tfms` variables.'
  prefs: []
  type: TYPE_NORMAL
- en: Moving from geometric to photometric transformations follows the same coding
    process. First, Pluto writes the wrapper functions using the Albumentations library,
    then uses the real-world image dataset to test them.
  prefs: []
  type: TYPE_NORMAL
- en: Photographic transformations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pluto chose the Albumentations library to power the photometric transformations.
    The primary reasons are that the **Albumentations** library has over 70 filters,
    and you can integrate it into the **Fast.ai** framework. Fast.ai has most of the
    basic photometric filters, such as hue shifting, contrast, and lighting, but only
    Albumentations has more exotic filters, such as those for adding rain, motion
    blur, and FancyPCA. Be careful when using fancy filters. Even though they are
    easy to implement, you should research AI scholarly published papers to see if
    the filter is beneficial for achieving a higher accuracy rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with the geometric transformations coding process, Pluto creates the base
    method and writes the wrapper function for each photometric transformation. The
    `_draw_image_album()` method is used to select a sample set of images from the
    data, convert it into a `numpy` array, do the transformation, and display them
    in batch mode. The pertinent code for the `_draw_image_album()` function is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The wrapper function code is straightforward. For example, the code for the
    brightness filter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: For any of the Albumentations functions, you can append a question mark (`?`)
    and run the code cell to see the documentation in the Python Notebook; for example,
    `albumentations.ColorJitter?`. Append two question marks (`??`) to see the function’s
    Python source code; for example, `albumentations.ColorJitter??`. A bonus fun fact
    is that Albumentations types are followed by a dot – for example, `albumentations.`
    – in the Python Notebook and wait for a second. A list of all the available functions
    appears in a drop-down list, where you can choose one. In other words, the Python
    Notebook has auto-complete typing.
  prefs: []
  type: TYPE_NORMAL
- en: The definition of the `aug_albm` variable differs from one wrapper function
    to another. Let’s test out the brightness filter.
  prefs: []
  type: TYPE_NORMAL
- en: Brightness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It isn’t easy to view most of the photometric transformations in grayscale
    because you are reading them in a book. That is more reason for joining Pluto
    with coding in the Notebook as you can see color. Rather than showing you all
    optimal safe parameters for each filter, Pluto will show you the *unsafe* range
    for one dataset and a safe parameter for the other dataset. The key code line
    for brightness in the wrapper function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the mistake in this book by exaggerating the brightness – for example,
    if it’s too bright or too dark. Once again, you should look at the Notebook to
    see the brightness effects in color. For the people photos, the *unsafe* value
    is a brightness equal to `1.7`. Pluto runs the following command on the Python
    Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.22 – Unsafe brightness level for the People dataset](img/B17990_03_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.22 – Unsafe brightness level for the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: The People dataset does not have any objective. Therefore, it is challenging
    to find safe parameters. If the goal is as simple as classifying people’s ages,
    the brightness level can be relatively high, but without knowing the intended
    use of the dataset, you don’t know how much to distort the pictures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto found that the safe brightness value for the food dataset is `0.3`, but
    it may not be easy to see the effects in this book. Here is the command that he
    used on the Python Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.23 – Safe brightness level for the food dataset](img/B17990_03_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.23 – Safe brightness level for the food dataset
  prefs: []
  type: TYPE_NORMAL
- en: The brightness level for the other four datasets is similar. Pluto has left
    it up to you to experiment and find the safe level in the Python Notebook. The
    Covid-19 images are in grayscale, and the intent is to predict Covid-19 patients
    from their chest X-ray photos. A decrease or increase in the brightness level
    may result in a false-positive or false-negative prediction. You should consult
    with the domain experts to confirm the safe parameters for Covid-19 images.
  prefs: []
  type: TYPE_NORMAL
- en: The grayscale filter wasn’t discussed in the first half of this chapter, but
    it is similar to the brightness filter.
  prefs: []
  type: TYPE_NORMAL
- en: Grayscale
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A few scholarly papers describe the benefit of grayscale, such as *Data Augmentation
    Methods Applying Grayscale Images for Convolutional Neural Networks in Machine
    Vision*, by Jinyeong Wang and Sanghwan Lee in 2021 from the Department of *Mechanical
    Convergence Engineering, Hanyang University, Seoul 04763, Korea*. The paper explains
    the effective data augmentation method for grayscale images in CNN-based machine
    vision with mono cameras.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `draw_image_grayscale()` method, Pluto uses the Albumentations library
    function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The fungi dataset aims to classify whether a mushroom is edible or poisonous,
    and the mushroom’s color significantly affects the classification. Therefore,
    converting into grayscale is not advisable. Nevertheless, Pluto illustrates the
    grayscale filter with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.24 – Unsafe use of grayscale on the fungi dataset](img/B17990_03_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.24 – Unsafe use of grayscale on the fungi dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The mall crowd dataset’s goal is to estimate the crowd size in a shopping mall.
    Thus, converting the photos into grayscale should not affect the prediction. Pluto
    runs the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.25 – Safe use of grayscale on the mall crowd dataset](img/B17990_03_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.25 – Safe use of grayscale on the mall crowd dataset
  prefs: []
  type: TYPE_NORMAL
- en: Pluto left the other four datasets for you to experiment with to determine whether
    it is safe to use the grayscale filter. After you use the Python Notebook to explore
    these datasets, come back here, where we will examine the contrast, saturation,
    and hue-shifting filters.
  prefs: []
  type: TYPE_NORMAL
- en: Contrast, saturation, and hue shifting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The contrast, saturation, and hue-shifting filters are beneficial. They are
    proven to aid in training AI models to achieve a higher accuracy rate, such as
    in the *Improving Deep Learning using Generic Data Augmentation* scholarly paper
    by Luke Taylor and Geoff Nitschke, published in 2017 by the *Arxiv* website.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for the contrast, saturation, and hue-shifting wrapper functions is
    straightforward with the Albumentations library. Let’s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto has exaggerated the *unsafe* value so that you can see the results in
    this book. The *unsafe* parameter for contrast in the sea animals dataset is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.26 – Unsafe use of contrast on the sea animals dataset](img/B17990_03_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.26 – Unsafe use of contrast on the sea animals dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The *unsafe* parameter for saturation in the food dataset is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.27 – Unsafe use of saturation on the food dataset](img/B17990_03_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.27 – Unsafe use of saturation on the food dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The *unsafe* parameter for hue shifting in the People dataset is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.28 – Unsafe use of hue shifting on the People dataset](img/B17990_03_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.28 – Unsafe use of hue shifting on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: Contrast, saturation, and hue shifting apply to five of the image datasets,
    and the key is to find the safe range for each dataset. The exception is the medical
    images – the Covid-19 photos. You need to consult a domain expert to see how much
    you can distort the images and retain their integrity.
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a thought experiment: can you think of an image category that would
    safely use hue shifting? In other words, in what photo subject can you shift the
    hue value and not compromise the image’s integrity? Hint: think of an animal that
    hunts by sonar or heat source.'
  prefs: []
  type: TYPE_NORMAL
- en: The next filter we’ll cover is the noise injection filter, which can be easily
    recognized in this book’s grayscale photos.
  prefs: []
  type: TYPE_NORMAL
- en: Noise injection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Noise injection is a strange filter because it is counterintuitive. Image augmentation
    distorts the original pictures within a safe limit, but injecting noise into a
    photo causes the images to degrade deliberately.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scholarly paper *Data Augmentation in Training CNNs: Injecting Noise to
    Images*, by Murtaza Eren Akbiyik, published in 2019, and reviewed at the *ICLR
    2020 Conference*, analyzes the effects of adding or applying different noise models
    of varying magnitudes to CNN architectures. It shows that noise injection provides
    a better understanding of optimal learning procedures for image classification.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the `draw_image_noise()` wrapper method, Pluto uses the Albumentation’s
    Gaussian noise method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto bumps the noise level to the extreme for the exaggerated *unsafe* case.
    The command in the Python Notebook is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.29 – Unsafe use of noise injection on the fungi dataset](img/B17990_03_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.29 – Unsafe use of noise injection on the fungi dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the goal of the mall crowd dataset is to estimate the crowd size, adding
    some noise to the image is acceptable. Pluto found that the *safe* noise level
    is from about `200` to `400`. The command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.30 – Safe use of noise injection on the mall crowd dataset](img/B17990_03_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.30 – Safe use of noise injection on the mall crowd dataset
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: Here is both a thought and a hands-on experiment. Can you define a set of ranges
    for each image augmentation that applies to a specific image topic, such as landscape,
    birds, or house appliances? If you think that is possible, can you write a Python
    function that uses Pluto’s wrapper functions?
  prefs: []
  type: TYPE_NORMAL
- en: This is when Pluto begins experimenting with more exotic filters, but he limits
    his choices to the image augmentation methods studied in published scholarly papers.
    The next two filters we will look at are the rain and sun flare filters.
  prefs: []
  type: TYPE_NORMAL
- en: Rain and sun flare
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In image augmentation, rain and sun flare effects are not widely used in AI.
    However, it is an acceptable option if the image domain is landscape or cityscape.
    The rain and sun flare implementations are simplistic because they are optimized
    for speed over a realistic depiction of rain or sun flare.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you require a natural rain effect, then you can refer to a paper that presents
    a new approach to synthesizing realistic rainy scenes using a **generative adversarial
    network** (**GAN**): *Synthesized Rain Images for Deraining Algorithms*, by Jaewoong
    Choi, Dae Ha Kim, Sanghyuk Lee, Sang Hyuk Lee, and Byung Cheol Song, published
    in 2022 in *Neurocomputing* *Volume 492*.'
  prefs: []
  type: TYPE_NORMAL
- en: The realistic rendering will take some time. Therefore, you should use the pre-processing
    augmentation method, which generates the images and saves them to local or cloud
    disk storage, before training the AI model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto does not have access to the GAN method, so he uses the Albumentations
    library for dynamically generating the effects. The key code inside the `draw_image_rain()`,
    and `draw_image_sunflare()` wrapper functions is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto exaggerates the effects of the sun flare filter to an *unsafe* level.
    The command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.31 – Unsafe use of the sun flare filter on the People dataset](img/B17990_03_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.31 – Unsafe use of the sun flare filter on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto discovered that the *safe* level for the fungi dataset is a radius of
    `120`, with a `flare-roi` of `(0, 0, 1)`. The command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.32 – Safe use of the sun flare filter on the fungi dataset](img/B17990_03_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.32 – Safe use of the sun flare filter on the fungi dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'For the People dataset, Pluto found that the safe parameter is a `drop_length`
    equal to `20`, a `drop_width` equal to `1`, and a `blur_value` equal to `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.33 – Safe use of the rain filter on the People dataset](img/B17990_03_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.33 – Safe use of the rain filter on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Many more photometric transformations are available; for example, Albumentations
    has over 70 image filters. However, for now, Pluto will present two more effects:
    the Sepia and FancyPCA filters.'
  prefs: []
  type: TYPE_NORMAL
- en: Sepia and FancyPCA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sepia involves altering the color tone to a brownish color. This brown is the
    color of cuttlefish ink, and the result gives the effect of old or aged pictures.
    Fancy **Principal Components Analysis** (**FancyPCA**) color augmentation alters
    the RGB channels’ intensities along the images’ natural variations.
  prefs: []
  type: TYPE_NORMAL
- en: 'A scholarly research paper used the FancyPCA filter to improve DL prediction
    of rock properties in reservoir formations: *Predicting mineralogy using a deep
    neural network and fancy PCA* by Dokyeong Kim, Junhwan Choi, Dowan Kim, and Joongmoo
    Byun, in 2022, presented at the *SEG International Exposition and* *Annual Meeting*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the `draw_image_sepia()` and `draw_image_fancyPCA()` wrapper functions,
    Pluto uses the Albumentations library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the results in the Python Notebook’s color output images. Pluto
    has chosen the People dataset to experiment with the sepia and FancyPCA filters
    because it has no objective. Assuming the target is to classify people’s age ranges,
    both filters are applicable. For the sepia filter, the command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.34 – Safe use of sepia on the People dataset](img/B17990_03_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.34 – Safe use of sepia on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto overstates the FancyPCA filter to an *unsafe* level by setting the alpha
    value to `5.0`. The command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.35 – Unsafe use of FancyPCA on the People dataset](img/B17990_03_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.35 – Unsafe use of FancyPCA on the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: So far, you and Pluto have covered and written many wrapper functions for photometric
    transformations, such as lighting, grayscale, contrast, saturation, hue shifting,
    noise injection, rain, sun flare, sepia, and FancyPCA. Still, there are far more
    image filters in the Albumentations library. Pluto follows the golden image augmentation
    rule for selecting a filter that improves prediction accuracy, as a published
    scholarly paper describes, such as *The Effectiveness of Data Augmentation in
    Image Classification using Deep Learning* paper by **Luis Perez, Jason Wang**,
    published by the *Cornell University Arxiv* in December 2017.
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a thought experiment: there are too many image augmentation techniques
    to count. So, how do you know which augmentation function is suitable to use?
    For example, is the Cinematic Anamorphic photo filter an effective image augmentation
    technique? Hint: think about the subject domain and the processing speed.'
  prefs: []
  type: TYPE_NORMAL
- en: Moving away from photographic transformations, next, Pluto will dig into the
    random erasing filter.
  prefs: []
  type: TYPE_NORMAL
- en: Random erasing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Random erasing adds a block of noise, while noise injection adds one pixel at
    a time.
  prefs: []
  type: TYPE_NORMAL
- en: Two recently published papers show that random erasing filters and extended
    random erasing increase the prediction accuracy of the DL model. The first paper
    is called *Random Erasing Data Augmentation*, by Zhun Zhong, Liang Zheng, Guoliang
    Kang, Shaozi Li, and Yi Yang, in 2020, and was presented at the *AAAI Conference
    on Artificial Intelligence*. The second paper is called *Perlin Random Erasing
    for Data Augmentation*, by Murat Saran, Fatih Nar, and Ayşe Nurdan Saran, in 2021,
    and was presented at the 29th *Signal Processing and Communications Applications*
    *Conference (SIU)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto uses the Fast.ai library in the `draw_image_erasing()` wrapper function.
    The pertinent code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'It is challenging to find a safe level for random erasing. It depends on the
    image subject, DL base model, and target label. Generally, Pluto selects a random
    erasing safe parameter and trains the AI model. If the DL model is overfitting,
    then he increases the random erasing effects, and if the model’s prediction accuracy
    is diverging, he decreases the random erasing parameters. Here is a safe starting
    point for the food dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.36 – Unsafe use of FancyPCA on the food dataset](img/B17990_03_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.36 – Unsafe use of FancyPCA on the food dataset
  prefs: []
  type: TYPE_NORMAL
- en: So far, Pluto uses one filter at a time. Next, he will combine multiple geographic
    and photographic transformations with random erasing.
  prefs: []
  type: TYPE_NORMAL
- en: Combining
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The power of image augmentation is that Pluto can combine multiple image filters
    in one dataset. This increases the number of images for training by a multiplication
    factor.
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: The horizontal flip filter’s default is set to 50% probability. The result is
    that the image size increases by half – that is, `total_flip = image_size + (0.5
    * image_size)`. The image size will increase by a multiplication factor when the
    random cropping and padding are added together with a padding mode of 3 – that
    is, `total_2_combine = total_fip + (3 * (image_size + (0.5 * image_size)) + (image_size
    * random_croping_factor))`, where `random_croping_factor` is between zero and
    the safe cropping value, which is less than 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, Pluto covered 15 image augmentation methods. Therefore, combining
    most or all of the filters into one dataset will increase its size substantially.
    Increasing the total number of images for training in DL is a proven method to
    reduce or eliminate the overfitting problem.
  prefs: []
  type: TYPE_NORMAL
- en: There are general rules for the applicable filters and safe parameters that
    should work with most image datasets. However, Pluto follows the golden rule of
    image augmentation. This golden rule selects which image filter to use and sets
    the safe parameters based on the photo subject and the predictive model’s goal.
    In other words, each project will have different image augmentation filters and
    safe parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before unveiling the table representing the safe parameters for each filter
    per six real-world image datasets, Pluto must review the image datasets’ topics
    and goals:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Covid-19** dataset consists of people’s chest X-ray images. The goal is
    to predict between Covid-19, viral pneumonia, and normal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **People** dataset consists of pictures of everyday people. No goal is stated,
    but Pluto assumes the usage could classify age, sex, ethnicity, emotional sentiment,
    and facial recognition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Fungi** dataset consists of photos of fungi in a natural environment.
    The goal is to predict if the fungi are edible or poisonous.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Sea Animal** dataset consists of images of sea animals, mainly underwater.
    The goal is to classify the 19 sea animals provided.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Food** dataset consists of images of commonly served Vietnamese dishes.
    The goal is to classify the 31 types of dishes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Mall Crowd** dataset consists of images of people in a typical shopping
    mall. The goal is to predict the size of the crowd.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To generate the filters and safe parameters table for each image dataset, Pluto
    has written a quick function, `print_safe_parameters()`, using pandas, because
    he thinks coding is fun. For readability, there are two parts to the table, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.37 – Safe parameter for each image dataset – part 1](img/B17990_03_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.37 – Safe parameter for each image dataset – part 1
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3**.37* shows the first half of the big table, and *Figure 3**.38*
    displays the second half.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.38 – Safe parameter for each image dataset – part 2](img/B17990_03_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.38 – Safe parameter for each image dataset – part 2
  prefs: []
  type: TYPE_NORMAL
- en: The safe parameters are from Pluto’s exploration of the Python Notebook, but
    you may find more suitable values than Pluto. There are no rigid or fixed rules
    regarding image augmentation. Therefore, you should use the Python Notebook to
    explore the possibilities. If you read a scholarly paper about a new image augmentation
    technique, implement it using the Albumentations or other image libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Pluto has written six wrapper functions for reinforcing learning through coding,
    one for each image dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact
  prefs: []
  type: TYPE_NORMAL
- en: You can run the wrapper function repeatedly because it generates a different
    image set every time. In addition, it will randomly select other base images from
    the real-world dataset. Therefore, you can run it a thousand times and only see
    the same output once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each wrapper function defines a set of Fast.ai image augmentation filters;
    for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: In addition, the wrapper function uses a helper method to fetch the `Albumentations`
    filters – for example, `_fetch_album_covid19()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pluto reviews the image augmentation for the Covid-19 dataset by using the
    following command in the Python Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.39 – Image augmentation for the Covid-19 dataset](img/B17990_03_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.39 – Image augmentation for the Covid-19 dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The relevant code lines for the combination filters for the People dataset
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto reviews the image augmentation for the People dataset by using the following
    command in the Python Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.40 – Image augmentation for the People dataset](img/B17990_03_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.40 – Image augmentation for the People dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The relevant code lines for the fungi combination filters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto reviews the image augmentation for the fungi dataset by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 3.41 – Image augmentation for the \uFEFFfungi dataset](img/B17990_03_41.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 3.41 – Image augmentation for the fungi dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The relevant code lines for the sea animal combination filters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto reviews the image augmentation for the sea animal dataset by using the
    following command in the Python Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.42 – Image augmentation for the sea animals dataset](img/B17990_03_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.42 – Image augmentation for the sea animals dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The relevant code lines for the food combination filters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto reviews the image augmentation for the food dataset by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.43 – Image augmentation for the food dataset](img/B17990_03_43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.43 – Image augmentation for the food dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'The relevant code lines for the mall crowd combination filters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Pluto reviews the image augmentation for the mall crowd dataset by using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.44 – Image augmentation for the mall crowd dataset](img/B17990_03_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.44 – Image augmentation for the mall crowd dataset
  prefs: []
  type: TYPE_NORMAL
- en: Every time Pluto runs any of the draw augmentation methods, there is an equal
    chance that one of the filters will be selected and that 50% of the filter will
    be applied per image in the batch. Pluto can override the default batch size of
    15 using the `bsize` parameter. Since Pluto employs the safe range on all filters,
    you may not notice the difference. However, that is expected because the goal
    is to distort the images without compromising the target label before pre-processing.
  prefs: []
  type: TYPE_NORMAL
- en: Fun challenge
  prefs: []
  type: TYPE_NORMAL
- en: Write a new combination wrapper function for a real-world dataset. If you have
    not downloaded or imported a new real-world image dataset, do so now and write
    a combined wrapper function as Pluto did.
  prefs: []
  type: TYPE_NORMAL
- en: This was a challenging chapter. Together, you and Pluto learned about image
    augmentation and how to use Python code to gain a deeper insight. Now, let’s summarize
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first part of this chapter, you and Pluto learn about the image augmentation
    concepts for classification. Pluto grouped the filters into geometric transformations,
    photometric transformations, and random erasing to make the image filters more
    manageable.
  prefs: []
  type: TYPE_NORMAL
- en: When it came to geometric transformations, Pluto covered horizontal and vertical
    flipping, cropping and padding, rotating, warping, and translation. These filters
    are suitable for most image datasets, and there are other geometric transformations,
    such as tilting or skewing. Still, Pluto followed the golden image augmentation
    rule for selecting a filter that improves prediction accuracy described in a published
    scholarly paper.
  prefs: []
  type: TYPE_NORMAL
- en: 'This golden rule is more suitable for photometric transformations because there
    are about 70 image filters in the Albumentations library and hundreds more available
    in other image augmentation libraries. This chapter covered the most commonly
    used photometric transformations cited in published scholarly papers: lighting,
    grayscale, contrast, saturation, hue shifting, noise injection, rain, sepia, and
    FancyPCA. You are encouraged to explore more filters from the Albumations library
    in the Python Notebook provided.'
  prefs: []
  type: TYPE_NORMAL
- en: The second part of this chapter consisted of Python code to reinforce your understanding
    of various image augmentation techniques. Pluto led you through the process of
    downloading the six real-world image datasets from the *Kaggle* website. Pluto
    wrote the fetching data code in [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038).
    He reused the fetch functions to retrieve the Covid-19, people, fungi, sea animals,
    food, and mall crowd real-world image datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before digging into the code, Pluto reviewed seven popular image augmentation
    libraries: Albumentations, Fast.ai, PIL, OpenCV, scikit-learn, Mahotas, and GraphicsMagick.
    Pluto used the Albumentations, Fast.ai, and PIL libraries to code the wrapper
    functions.'
  prefs: []
  type: TYPE_NORMAL
- en: The goal of these wrapper functions was to explain each image filter clearly.
    In all cases, the functions use the library augmentation methods under the hood.
    Many photometric transformations are more visible in the Python Notebook’s color
    output. Pluto showed the safe and *unsafe* parameters for each filter applied
    to the six image datasets. You are encouraged to run and even hack the Python
    Notebook’s code because there are no absolute right or wrong safe levels.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of Python code was provided, but it consisted of simple wrapper functions
    that followed good OOP standards and there were no other methods. The goal was
    to give you insight into each image filter and make it easy for you to explore
    and hack the code provided.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this chapter, Pluto pulled together to create an image filter
    combination table customized for each of the six image datasets. He then wrote
    six combined augmentation methods for each image dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, there were *fun facts* and *fun challenges*. Pluto
    hopes you will take advantage of these and expand your experience beyond the scope
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover image segmentation, which reuses many of
    the image classification functions that were covered in this chapter.
  prefs: []
  type: TYPE_NORMAL
