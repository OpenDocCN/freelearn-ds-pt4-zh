<html><head></head><body>
		<div id="_idContainer142">
			<h1 id="_idParaDest-101" class="chapter-number"><a id="_idTextAnchor101"/>5</h1>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor102"/>Text Augmentation</h1>
			<p>Text augmentation is a technique that is used in <strong class="bold">Natural Language Processing</strong> (<strong class="bold">NLP</strong>) to generate <a id="_idIndexMarker431"/>additional data by modifying or creating new text from existing text data. Text augmentation involves techniques such as character swapping, noise injection, synonym replacement, word deletion, word insertion, and word swapping. Image and text augmentation have the same goal. They strive to increase the size of the training dataset and improve AI <span class="No-Break">prediction accuracy.</span></p>
			<p>Text augmentation is relatively more challenging to evaluate because it is not as intuitive as image augmentation. The intent of an image augmentation technique is clear, such as flipping a photo, but a character-swapping technique will be disorienting to the reader. Therefore, readers might perceive the benefits <span class="No-Break">as subjective.</span></p>
			<p>The effectiveness of text augmentation depends on the quality of the generated data and the specific NLP task being performed. It can be challenging to determine the appropriate <em class="italic">safe</em> level of text augmentation that is required for a given dataset, and it often requires experimentation and testing to achieve the <span class="No-Break">desired results.</span></p>
			<p>Customer feedback or social media chatter is fair game for text augmentation because the writing is messy and, predominantly, contains grammatical errors. Conversely, legal documents or written medical communications, such as doctor’s prescriptions or reports, are off-limits because the message is precise. In other words, error injections, synonyms, or even AI-generated text might change the legal or medical meaning beyond the <span class="No-Break"><em class="italic">safe</em></span><span class="No-Break"> level.</span></p>
			<p>The biases in text augmentation are equally difficult to discern.  For example, adding noise by purposely misspelling words using the Keyboard augmentation method might introduce bias against real-world tweets, which typically contain misspelled words. There are no generalized rules to follow, and the answer only becomes evident after thoroughly studying the data and reviewing the AI <span class="No-Break">forecasting objective.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">As generative AI <a id="_idIndexMarker432"/>becomes more widely available, you can use <strong class="bold">OpenAI’s GPT-3</strong>, <strong class="bold">Google Bard</strong>, or <strong class="bold">Facebook’s Roberta</strong> system to generate original <a id="_idIndexMarker433"/>articles <a id="_idIndexMarker434"/>for text augmentation. For example, you can ask generative AI to create positive or negative reviews about a company product, then use the AI-written articles to train predictive AI on <span class="No-Break">sentiment analysis.</span></p>
			<p>In <a href="B17990_05.xhtml#_idTextAnchor101"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, you will learn about text augmentation and how to code the methods in Python notebooks. In particular, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li><span class="No-Break">Character augmenting</span></li>
				<li><span class="No-Break">Word augmenting</span></li>
				<li>Sentence and <span class="No-Break">flow augmenting</span></li>
				<li>Text <span class="No-Break">augmentation libraries</span></li>
				<li>Real-world <span class="No-Break">text datasets</span></li>
				<li>Reinforcing learning through <span class="No-Break">Python Notebook</span></li>
			</ul>
			<p>Let’s get started with the simplest topic, <span class="No-Break">character augmentation.</span></p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor103"/>Character augmenting</h1>
			<p>Character augmentation <a id="_idIndexMarker435"/>substitutes or injects characters into the text. In other words, it creates typing errors. Therefore, the method seems counterintuitive. Still, just like noise injection in image augmentation, scholarly published papers illustrate the benefit of character augmentation in improving AI forecasting accuracy, such as <em class="italic">Effective Character-Augmented Word Embedding for Machine Reading Comprehension</em> by <em class="italic">Zhuosheng Zhang, Yafang Huang, Pengfei Zhu, and Hai Zhao</em>, from the 2018 <em class="italic">CCF International Conference on Natural </em><span class="No-Break"><em class="italic">Language Processing</em></span><span class="No-Break">.</span></p>
			<p>The three standard methods for character augmentation are listed <span class="No-Break">as follows:</span></p>
			<ul>
				<li>The <strong class="bold">Optical Character Recognition (OCR) augmenting</strong> function substitutes <a id="_idIndexMarker436"/>frequent errors in OCR by converting images into text, such as the letter <em class="italic">o</em> into the number <em class="italic">0</em> or the capital letter <em class="italic">I</em> into the <span class="No-Break">number </span><span class="No-Break"><em class="italic">1</em></span><span class="No-Break">.</span></li>
				<li>The <strong class="bold">Keyboard augmenting</strong> method replaces a character with other characters <a id="_idIndexMarker437"/>that are adjacent to it. For example, a typical typing error for character <em class="italic">b</em> is hitting key <em class="italic">v</em> or key <span class="No-Break"><em class="italic">n</em></span><span class="No-Break"> instead.</span></li>
				<li>The <strong class="bold">Random character</strong> function <a id="_idIndexMarker438"/>randomly swaps, inserts, or deletes characters within the piece <span class="No-Break">of text.</span></li>
			</ul>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Computer encoding text was very different from 1963 to 1970; for example, a computer would <a id="_idIndexMarker439"/>encode the letter <em class="italic">A</em> as an integer 64 or Hexidecimal 41. This originated from the <strong class="bold">American National Standards Institute</strong> (<strong class="bold">ANSI</strong>) in 1964, and <a id="_idIndexMarker440"/>the <strong class="bold">International Organization for Standardization</strong> (<strong class="bold">ISO</strong>) adopted <a id="_idIndexMarker441"/>the standard around 1970. In 1980, the <strong class="bold">Unification Code</strong> (<strong class="bold">Unicode</strong>) subsumed the ISO standard for all international languages. However, if <a id="_idIndexMarker442"/>you come across computer text from around 1964, it could be encoded in <strong class="bold">Extended Binary Coded Decimal Interchange Code</strong> (<strong class="bold">EBCDIC</strong>), which encodes the letter <em class="italic">A</em> as 193 or Hexidecimal C1. As a programmer, you might have to answer this question: <em class="italic">does your website or mobile app </em><span class="No-Break"><em class="italic">support Unicode?</em></span></p>
			<p>After character augmenting, the next category is <span class="No-Break">word augmenting.</span></p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor104"/>Word augmenting</h1>
			<p>Word augmentations <a id="_idIndexMarker443"/>carry the same bias and <em class="italic">safe</em> level warning as character augmentations. Over half of these augmentation methods inject errors into the text, but other functions generate new text using synonyms or a pretrained AI model. The standard word augmentation functions are listed <span class="No-Break">as follows:</span></p>
			<ul>
				<li>The <strong class="bold">Misspell augmentation</strong> function <a id="_idIndexMarker444"/>uses a predefined dictionary to simulate spelling mistakes. It is based on the scholarly paper <em class="italic">Text Data Augmentation Made Simple By Leveraging NLP Cloud APIs</em> by <strong class="bold">Claude Coulombe</strong>, which was published <span class="No-Break">in 2018.</span></li>
				<li>The <strong class="bold">Split augmentation</strong> function <a id="_idIndexMarker445"/>splits words into two <span class="No-Break">tokens randomly.</span></li>
				<li>The <strong class="bold">Random word</strong> augmentation <a id="_idIndexMarker446"/>method applies <a id="_idIndexMarker447"/>random behavior to the text with four parameters: <strong class="bold">substitute</strong>, <strong class="bold">swap</strong>, <strong class="bold">delete</strong>, and <strong class="bold">crop</strong>. It is based on two scholarly papers: <em class="italic">Synthetic and Natural Noise Both Break Neural Machine Translation</em> by <strong class="bold">Yonatan Belinkov and Yonatan Bisk</strong>, published in 2018, and <em class="italic">Data Augmentation via Dependency Tree Morphing for Low-Resource Languages</em> by <strong class="bold">Gozde Gul Sahin and </strong><span class="No-Break"><strong class="bold">Mark Steedman</strong></span><span class="No-Break">.</span></li>
				<li>The <strong class="bold">Synonym augmentation</strong> function substitutes words with synonyms from a predefined <a id="_idIndexMarker448"/>database. The first option <a id="_idIndexMarker449"/>is to use <strong class="bold">WordNet</strong>. WordNet is an extensive lexical database of English from <em class="italic">Princeton University</em>. The database groups nouns, verbs, adjectives, and adverbs into sets of cognitive synonyms. The second <a id="_idIndexMarker450"/>option is to use a <strong class="bold">Paraphrase Database</strong> (<strong class="bold">PPDB</strong>). A PPDB is an automatically extracted database containing millions of paraphrases in 16 languages. A PPDB aims to improve language processing by making systems more robust to language variability and unseen words. The entire PPDB resource is freely available under the United States <strong class="bold">Creative Commons Attribution </strong><span class="No-Break"><strong class="bold">3.0</strong></span><span class="No-Break"> license.</span></li>
				<li>The <strong class="bold">Antonym augmentation</strong> function replaces words with antonyms. It is based <a id="_idIndexMarker451"/>on the scholarly paper, <em class="italic">Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models</em>, by <strong class="bold">Tong Niu and Mohit Bansal</strong>, which was published <span class="No-Break">in 2018.</span></li>
				<li>The <strong class="bold">Reserved Word augmentation</strong> method swaps target words where you define <a id="_idIndexMarker452"/>a word list. It is the same as synonyms, except the terms are <span class="No-Break">created manually.</span></li>
			</ul>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">Here is a thought experiment: can you think of a new character or word augmentation technique? A hint is to think about how a dyslexic <span class="No-Break">person reads.</span></p>
			<p>Next, we will look at <span class="No-Break">sentence augmentation.</span></p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor105"/>Sentence augmentation</h1>
			<p>Sentence augmenting <a id="_idIndexMarker453"/>uses generative AI to create new texts. Examples of AI models are BERT, Roberta, GPT-2, <span class="No-Break">and others.</span></p>
			<p>The three sentence augmentation methods are listed <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Contextual Word Embeddings</strong> uses <a id="_idIndexMarker454"/>GPT-2, Distilled-GPT-2, <span class="No-Break">and XLNet.</span></li>
				<li><strong class="bold">Abstractive Summarization</strong> uses <a id="_idIndexMarker455"/>Facebook <span class="No-Break">Robertaand T5-Large.</span></li>
				<li><strong class="bold">Top-n Similar Word</strong> <span class="No-Break">uses </span><span class="No-Break"><a id="_idIndexMarker456"/></span><span class="No-Break">LAMBADA.</span></li>
			</ul>
			<p> Before Pluto explains the code in the Python Notebook, let’s review the text <span class="No-Break">augmentation libraries.</span></p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor106"/>Text augmentation libraries</h1>
			<p>There are <a id="_idIndexMarker457"/>many more Python open source image augmentation libraries than text augmentation libraries. Some libraries are more adaptable to a particular category than others, but in general, it is a good idea to pick one or two and become proficient <span class="No-Break">in them.</span></p>
			<p>The well-known libraries are <strong class="bold">Nlpaug</strong>, <strong class="bold">Natural Language Toolkit</strong> (<strong class="bold">NLTK</strong>), <strong class="bold">Generate Similar</strong> (<strong class="bold">Gensim</strong>), <strong class="bold">TextBlob</strong>, <strong class="bold">TextAugment</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="bold">AugLy</strong></span><span class="No-Break">:</span></p>
			<ul>
				<li><strong class="bold">Nlpaug</strong> is a library <a id="_idIndexMarker458"/>used for textual <a id="_idIndexMarker459"/>augmentation for DL. The goal is to improve DL model <a id="_idIndexMarker460"/>performance by generating textual data. The GitHub link <span class="No-Break">is </span><a href="https://github.com/makcedward/nlpaug"><span class="No-Break">https://github.com/makcedward/nlpaug</span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">NLTK</strong> is a platform <a id="_idIndexMarker461"/>used for building Python <a id="_idIndexMarker462"/>programs to work with human language data. It provides interfaces to over 50 corpora and lexical resources, such as WordNet. NLTK <a id="_idIndexMarker463"/>contains text-processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning. The GitHub link <span class="No-Break">is </span><a href="https://github.com/nltk/nltk"><span class="No-Break">https://github.com/nltk/nltk</span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">Gensim</strong> is a popular <a id="_idIndexMarker464"/>open source NLP library used for unsupervised <a id="_idIndexMarker465"/>topic modeling. It uses academic models and modern statistical machine learning to perform word vectors, corpora, topic identification, document comparison, and analyzing <a id="_idIndexMarker466"/>plain-text documents. The GitHub link <span class="No-Break">is </span><a href="https://github.com/RaRe-Technologies/gensim"><span class="No-Break">https://github</span><span class="No-Break">.com/RaRe-Technologies/gensim</span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">TextBlob</strong> is a library <a id="_idIndexMarker467"/>that is used for <a id="_idIndexMarker468"/>processing textual data. It provides a simple API for diving into typical NLP tasks such as part-of-speech tagging, noun phrase extraction, sentiment <a id="_idIndexMarker469"/>analysis, classification, and translation. The GitHub link <span class="No-Break">is </span><a href="https://github.com/sloria/TextBlob"><span class="No-Break">https://github.com/sloria/TextBlob</span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">TextAugment</strong> is a library <a id="_idIndexMarker470"/>that is used <a id="_idIndexMarker471"/>for augmenting text in NLP applications. It uses <a id="_idIndexMarker472"/>and combines the NLTK, Gensim, and TextBlob libraries. The GitHub link <span class="No-Break">is </span><a href="https://github.com/dsfsi/textaugment"><span class="No-Break">https://github.com/dsfsi/textaugment</span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">AugLy</strong> is a data <a id="_idIndexMarker473"/>augmentation library from Facebook that supports <a id="_idIndexMarker474"/>audio, image, text, and video modules and over 100 augmentations. The augmentation of each modality is <a id="_idIndexMarker475"/>categorized into sub-libraries. The GitHub link <span class="No-Break">is </span><a href="https://github.com/facebookresearch/AugLy&#13;"><span class="No-Break">https://github.com/facebookresearch/AugLy</span></a></li>
			</ul>
			<p>Similarly to image augmentation wrapper functions, Pluto will write wrapper functions that use the library under the hood. You can pick more than one library for a project, but Pluto will use the <strong class="bold">Nlpaug</strong> library to power the <span class="No-Break">wrapper functions.</span></p>
			<p>Let’s start by downloading the real-world text datasets from the <span class="No-Break"><em class="italic">Kaggle</em></span><span class="No-Break"> website.</span></p>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor107"/>Real-world text datasets</h1>
			<p>The <em class="italic">Kaggle</em> website is <a id="_idIndexMarker476"/>an online community platform for data scientists and machine learning enthusiasts. The Kaggle website has thousands of real-world datasets; Pluto found a little over 2,900 <strong class="bold">NLP</strong> datasets and has selected two NLP datasets for <span class="No-Break">this chapter.</span></p>
			<p>In <a href="B17990_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, Pluto uses the <strong class="bold">Netflix</strong> and <strong class="bold">Amazon</strong> datasets as examples with which to understand biases. Pluto keeps the <strong class="bold">Netflix</strong> NLP dataset because the movie reviews are curated . There are a few syntactical errors, but overall, the input texts are of <span class="No-Break">high quality.</span></p>
			<p>The second <strong class="bold">NLP</strong> dataset is <strong class="bold">Twitter Sentiment Analysis</strong> (<strong class="bold">TSA</strong>). The 29,530 real-world tweets <a id="_idIndexMarker477"/>contain many grammatical errors and misspelled words. The challenge is to classify the tweets into two categories: (1) normal or (2) racist <span class="No-Break">and sexist.</span></p>
			<p>The dataset was published in 2021 by <strong class="bold">Mayur Dalvi</strong>, and the license is <strong class="bold">CC0: Public </strong><span class="No-Break"><strong class="bold">Domain</strong></span><span class="No-Break">, </span><a href="https://creativecommons.org/publicdomain/zero/1.0/"><span class="No-Break">https://creativecommons.org/publicdomain/zero/1.0/</span></a><span class="No-Break">.</span></p>
			<p>After selecting the two NLP datasets, you can use the same four steps to begin the process of practical learning through a Python Notebook. If you need clarification, review <em class="italic">Chapters 2</em> and <em class="italic">3</em>. The steps are listed <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Retrieve Python Notebook <span class="No-Break">and Pluto.</span></li>
				<li>Download <span class="No-Break">real-world data.</span></li>
				<li>Import <span class="No-Break">into pandas.</span></li>
				<li><span class="No-Break">View data.</span></li>
			</ol>
			<p>Let’s start <span class="No-Break">with Pluto.</span></p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor108"/>The Python Notebook and Pluto</h2>
			<p>Start by loading the <strong class="source-inline">data_augmentation_with_python_chapter_5.ipynb</strong> file into <strong class="bold">Google Colab</strong> or your chosen Jupyter notebook or JupyterLab environment. From this <a id="_idIndexMarker478"/>point onward, the code snippets are <a id="_idIndexMarker479"/>from the Python Notebook, which contains <a id="_idIndexMarker480"/>the <span class="No-Break">complete code.</span></p>
			<p>The next step <a id="_idIndexMarker481"/>is to clone the repository. Pluto will reuse the code from <a href="B17990_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a> because it has the downloading Kaggle data methods and not the image augmentation functions. The <strong class="source-inline">!git</strong> and <strong class="source-inline">%run</strong> statements are used to start up Pluto. The command is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># clone GitHub repo</strong>
!git clone 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'
<strong class="bold"># instantiate Pluto</strong>
%run 'Data-Augmentation-with-Python/pluto/pluto_chapter_2.py'</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<pre class="console">
---------------------------- : ---------------------------
            Hello from class : &lt;class '__main__.PacktDataAug'&gt; Class: PacktDataAug
                   Code name : Pluto
                   Author is : Duc Haba
---------------------------- : ---------------------------</pre>
			<p>We need one more check to ensure Pluto has been loaded satisfactorily. The following command asks Pluto to say <span class="No-Break">his status:</span></p>
			<pre class="source-code">
pluto.say_sys_info()</pre>
			<p>The output should be as follows or similar, depending on <span class="No-Break">your system:</span></p>
			<pre class="console">
---------------------------- : ---------------------------
                 System time : 2022/10/30 06:52
                    Platform : linux
     Pluto Version (Chapter) : 2.0
             Python (3.7.10) : actual: 3.7.15 (default, Oct 12 2022, 19:14:55) [GCC 7.5.0]
            PyTorch (1.11.0) : actual: 1.12.1+cu113
              Pandas (1.3.5) : actual: 1.3.5
                 PIL (9.0.0) : actual: 7.1.2
          Matplotlib (3.2.2) : actual: 3.2.2
                   CPU count : 2
                  *CPU speed : NOT available
---------------------------- : ---------------------------</pre>
			<p>Here, Pluto <a id="_idIndexMarker482"/>reported that he is from <a href="B17990_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, which is <a id="_idIndexMarker483"/>also known as <strong class="bold">version 2.0</strong>. This is <a id="_idIndexMarker484"/>what we wanted because we don’t need any image <a id="_idIndexMarker485"/>augmentation functions from <em class="italic">Chapters 3</em> and <em class="italic">4</em>. The next step is to download the real-world <strong class="bold">Netflix</strong> and <strong class="bold">Twitter</strong> <span class="No-Break">NLP datasets.</span></p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor109"/>Real-world NLP datasets</h2>
			<p>There has <a id="_idIndexMarker486"/>yet to be any new code written for this chapter. Pluto reuses <a id="_idIndexMarker487"/>the <strong class="source-inline">fetch_kaggle_dataset()</strong> method to download the <strong class="bold">Netflix</strong> dataset, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># fetch data</strong>
url = 'https://www.kaggle.com/datasets/infamouscoder/dataset-netflix-shows'
pluto.fetch_kaggle_dataset(url)</pre>
			<p>The <strong class="source-inline">dataset-netflix-shows.zip</strong> file is 1.34 MB, and the function automatically unzips in the <span class="No-Break"><strong class="bold">kaggle</strong></span><span class="No-Break"> directory.</span></p>
			<p>The method <a id="_idIndexMarker488"/>for fetching the Twitter dataset <a id="_idIndexMarker489"/>is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># fetch data</strong>
url = 'https://www.kaggle.com/datasets/mayurdalvi/twitter-sentiments-analysis-nlp'
pluto.fetch_kaggle_dataset(url)</pre>
			<p>The <strong class="source-inline">twitter-sentiments-analysis-nlp.zip</strong> file is 1.23 MB, and the function automatically unzips in the <span class="No-Break"><strong class="bold">kaggle</strong></span><span class="No-Break"> directory.</span></p>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">The challenge is to search and download two additional real-world NLP datasets from the Kaggle website. Hint: use the <strong class="source-inline">pluto.fetch_kaggle_dataset()</strong> method. Pluto is an imaginary digital Siberian Husky. Therefore, he will happily fetch data until your disk space <span class="No-Break">is full.</span></p>
			<p>The next step is to load the data <span class="No-Break">into pandas.</span></p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor110"/>Pandas</h2>
			<p><strong class="bold">Pandas</strong> is the de <a id="_idIndexMarker490"/>facto standard for data scientists to manage and manipulate <a id="_idIndexMarker491"/>tabular data. It is fast, flexible, easy to use, and <a id="_idIndexMarker492"/>powerful. Therefore, Pluto uses pandas to import the <strong class="bold">Comma-Separated Values</strong> (<strong class="bold">CSV</strong>) file, and he reuses the <strong class="source-inline">fetch_df()</strong> method. Note that <strong class="source-inline">df</strong> is a typical shorthand for the pandas <span class="No-Break"><strong class="bold">DataFrame</strong></span><span class="No-Break"> class.</span></p>
			<p>For the <strong class="bold">Netflix</strong> data, Pluto uses the following two commands for importing to pandas and printing out the <span class="No-Break">data batch:</span></p>
			<pre class="source-code">
<strong class="bold"># import into Panda</strong>
f = 'kaggle/dataset-netflix-shows/netflix_titles.csv'
pluto.df_netflix_data = pluto.fetch_df(f)
<strong class="bold"># display data batch</strong>
pluto.print_batch_text(pluto.df_netflix_data,
  cols=['title', 'description'])</pre>
			<p>The  output <a id="_idIndexMarker493"/>is <span class="No-Break">as </span><span class="No-Break"><a id="_idIndexMarker494"/></span><span class="No-Break">follows:</span></p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B17990_05_01.jpg" alt="Figure 5.1 – Netflix movie descriptions"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – Netflix movie descriptions</p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">The <strong class="source-inline">fetch_df()</strong> method randomly selects several records to display in the data batch. The number of records, or batch size, is the <strong class="source-inline">bsize</strong> parameter. The default is <span class="No-Break">10 records.</span></p>
			<p>The <strong class="bold">Netflix</strong> movie-reviewed data is curated; therefore, it is clean. Pluto doesn’t have to scrub <a id="_idIndexMarker495"/>the data. However, the <strong class="bold">Twitter</strong> data is <span class="No-Break">another story.</span></p>
			<p>The commands <a id="_idIndexMarker496"/>for cleaning, importing, and batch-displaying the <strong class="bold">Twitter</strong> data to pandas are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># clean space-char</strong>
f = 'kaggle/twitter-sentiments-analysis-nlp'
!find {f} -name "* *" -type f | rename 's/ /_/g'
<strong class="bold"># import into Pandas</strong>
f = 'kaggle/twitter-sentiments-analysis-nlp/Twitter_Sentiments.csv'
pluto.df_twitter_data = pluto.fetch_df(f)
<strong class="bold"># display data batch</strong>
pluto.print_batch_text(pluto.df_twitter_data,cols=['label', 'tweet'])</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B17990_05_02.jpg" alt="Figure 5.2 – Twitter tweets"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Twitter tweets</p>
			<p>Since the real-world tweets from <strong class="bold">Twitter</strong> have been written by the public, they contain misspelled words, bad words, and all sorts <span class="No-Break">of shenanigans.</span></p>
			<p>The goal is <a id="_idIndexMarker497"/>to predict regular versus racist or sexist tweets. Pluto focuses on learning text argumentation; therefore, he prefers to have tweets <a id="_idIndexMarker498"/>with printable characters, no HTML tags, and no words <span class="No-Break">of profanity.</span></p>
			<p>Pluto writes two simple helper methods to clean the text and remove the words of profanity. The <strong class="source-inline">_clean_text()</strong> function uses the <strong class="source-inline">regex</strong> library, and the one line of code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
return (re.sub('[^A-Za-z0-9 .,!?#@]+', '', str(x)))</pre>
			<p>The <strong class="source-inline">_clean_bad_word()</strong> helper function uses the <strong class="source-inline">filter-profanity</strong> library, and the one line of code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
return (profanity.censor_profanity(x, ''))</pre>
			<p>The <strong class="source-inline">clean_text()</strong> method uses the two helper functions with pandas’ powerful <strong class="source-inline">apply</strong> function.    Using pandas’ built-in functions, Pluto writes the <strong class="source-inline">clean_text()</strong> function with <a id="_idIndexMarker499"/>two code lines instead of a dozen lines using standard <strong class="source-inline">if-else</strong> and <strong class="source-inline">for</strong>-loop construct. The code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># clean text</strong>
df['clean_tweet'] = df.tweet.apply(self._clean_text)
<strong class="bold"># remove profanity words</strong>
df['clean_tweet'] = df['clean_tweet'].apply(
    self._clean_bad_word)</pre>
			<p>The commands <a id="_idIndexMarker500"/>for the clean tweets and showing the data batch are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># clean tweets</strong>
pluto.clean_text(pluto.df_twitter_data)
<strong class="bold"># display data batch</strong>
pluto.print_batch_text(pluto.df_twitter_data,
    cols=['label', 'clean_tweet'])</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B17990_05_03.jpg" alt="Figure 5.3 – Clean Twitter tweets"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – Clean Twitter tweets</p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Who would <a id="_idIndexMarker501"/>have known that a dog and a panda could work <a id="_idIndexMarker502"/>together well? The next <em class="italic">Kung Fu Panda</em> movie is about <strong class="bold">Po</strong> and <strong class="bold">Pluto</strong> teaming up to defend and augment the city wall against the storm of the century, which has been caused by <span class="No-Break">global warming.</span></p>
			<p>Let’s use pandas and some other libraries to visualize the <span class="No-Break">NLP dataset.</span></p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor111"/>Visualizing NLP data</h2>
			<p><a href="B17990_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a> uses <a id="_idIndexMarker503"/>the <strong class="source-inline">draw_word_count()</strong> method to <a id="_idIndexMarker504"/>display the average word per record and the shortest and longest movie reviews. The right-hand side of the graph shows the histogram of the movie review word counts. The pandas library generates beautiful word count charts. Pluto reuses the function to display the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># draw word count</strong>
pluto.draw_word_count(pluto.df_netflix_data)</pre>
			<p>The <a id="_idIndexMarker505"/>output is <a id="_idIndexMarker506"/><span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B17990_05_04.jpg" alt="Figure 5.4 – Netflix word counts"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Netflix word counts</p>
			<p>The Netflix movie description mean is 23.88 words, with a minimum of 10 words and a maximum of 48 words. Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># draw word count</strong>
pluto.draw_word_count(pluto.df_twitter_data)</pre>
			<p>The <a id="_idIndexMarker507"/>output <a id="_idIndexMarker508"/>is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B17990_05_05.jpg" alt="Figure 5.5 – Twitter word counts"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Twitter word counts</p>
			<p>The average word count of the Twitter tweets is 12.78 words, with a minimum of 1 word and a maximum of <span class="No-Break">33 words.</span></p>
			<p>Pluto writes the <strong class="source-inline">draw_text_null_data()</strong> method to check whether there is any missing data, also known as a <strong class="bold">null</strong> value. The missing data shows up as a white line. The <strong class="source-inline">Missingno</strong> library generates the graph with the following key line <span class="No-Break">of code:</span></p>
			<pre class="source-code">
missingno.matrix(df,color=color,ax=pic)</pre>
			<p>Pluto draws <a id="_idIndexMarker509"/>the <strong class="source-inline">null</strong> data graph for the Netflix data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># draw missing data/null value</strong>
pluto.draw_text_null_data(pluto.df_netflix_data)</pre>
			<p>The <a id="_idIndexMarker510"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B17990_05_06.jpg" alt="Figure 5.6 – Netflix missing data"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6 – Netflix missing data</p>
			<p>There is missing data in the <strong class="bold">director</strong>, <strong class="bold">cast</strong>, and <strong class="bold">country</strong> categories for the <strong class="bold">Netflix</strong> data, but the <strong class="bold">description</strong> category, also known as the movie review, has no <span class="No-Break">missing data.</span></p>
			<p>Pluto does the same for the <strong class="bold">Twitter</strong> data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># draw missing data/null value</strong>
pluto.draw_text_null_data(pluto.df_twitter_data)</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B17990_05_07.jpg" alt="Figure 5.7 – Twitter missing data"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – Twitter missing data</p>
			<p>There <a id="_idIndexMarker511"/>is no missing data in the <span class="No-Break"><strong class="bold">Twitter</strong></span><span class="No-Break"> data.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Many multimillion-dollar AI systems have failed primarily because of a lack of control over the input data. For example, the <em class="italic">Amazon Recruiting</em> system in 2020 failed because there was no diversity in the dataset, and the most egregious debacle was <em class="italic">Microsoft’s Chatbot Tay</em> in 2016. It was corrupted by Twitter users inputting sexist and <span class="No-Break">racist tweets.</span></p>
			<p>The next <a id="_idIndexMarker512"/>chart is the word cloud infographic diagram. This is an extraordinary method for visualizing the NLP text. The most commonly used words are displayed in a large font, while the least used terms are displayed in a smaller font. The <strong class="bold">WordCloud</strong> library generates the infographic chart, and the essential code snippet is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># generate word cloud</strong>
img = wordcloud.WordCloud(width = 1600,
        height = 800,
        background_color ='white',
        stopwords = xignore_words,
        min_font_size = 10).generate(words_str)
<strong class="bold"># covert Pandas to word string input</strong>
orig = df_1column.str.cat()
word_clean = re.sub('[^A-Za-z0-9 ]+', '', orig)</pre>
			<p>Pluto <a id="_idIndexMarker513"/>uses the <strong class="source-inline">_draw_text_wordcloud()</strong> helper function <a id="_idIndexMarker514"/>and the <strong class="source-inline">draw_text_wordcloud()</strong> method to display the infographic chart for real-world <strong class="bold">Netflix</strong> data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># draw word cloud</strong>
pluto.draw_text_wordcloud(pluto.df_netflix_data.description,
    xignore_words=wordcloud.STOPWORDS,
    title='Word Cloud: Netflix Movie Review')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B17990_05_08.jpg" alt="Figure 5.8 – Netflix word cloud, with approximately 246,819 words"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – Netflix word cloud, with approximately 246,819 words</p>
			<p>Pluto <a id="_idIndexMarker515"/>does the <a id="_idIndexMarker516"/>same for the real-world <strong class="bold">Twitter</strong> data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># draw word cloud</strong>
pluto.draw_text_wordcloud(pluto.df_twitter_data.clean_tweet,
    xignore_words=wordcloud.STOPWORDS,
    title='Clean Tweets Word Cloud')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B17990_05_09.jpg" alt="Figure 5.9 – Twitter    word cloud, with approximately 464,992 words"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – Twitter    word cloud, with approximately 464,992 words</p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Here is a fun fact about the history of word cloud graphs. The word cloud, also known as a tag cloud, Wordle, or weighted list, was first used in print by <strong class="bold">Douglas Coupland</strong> in the book <em class="italic">Microserfs</em>. It was published in 1995, but not until 2004 did the word clouds exist in digital format on the <em class="italic">Flickr </em>website. Today, word cloud infographics are widespread on the web and in <span class="No-Break">academic papers.</span></p>
			<p>So far, Pluto <a id="_idIndexMarker517"/>has discussed character, word, and sentence augmentation <a id="_idIndexMarker518"/>theories, chosen the <strong class="bold">Nlpaug</strong> text augmentation library, and downloaded the real-world <strong class="bold">Netflix</strong> and <strong class="bold">Twitter</strong> NLP datasets. It is time for Pluto to reinforce his learning by performing text augmentation with <span class="No-Break">Python code.</span></p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor112"/>Reinforcing learning through Python Notebook</h1>
			<p>Pluto <a id="_idIndexMarker519"/>uses the Python Notebook to reinforce <a id="_idIndexMarker520"/>our understanding of text augmentation. He uses the batch function to display text in batches. This works similarly to the batch functions for images. In other words, it randomly selects new records and transforms them using the <span class="No-Break">augmentation methods.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Pluto recommends running the batch functions repeatedly to gain a deeper insight into the text augmentation methods. There are thousands of text records in the <strong class="bold">Twitter</strong> and <strong class="bold">Amazon</strong> datasets. Each time you run the batch functions, it displays different records from <span class="No-Break">the dataset.</span></p>
			<p>As with <a id="_idIndexMarker521"/>the image augmentation implementation, the wrapper functions use the <strong class="bold">Nlpaug</strong> library under the hood. The wrapper <a id="_idIndexMarker522"/>function allows you to focus on the text transformation concepts and not be distracted by the library implementation. You can use another text augmentation library, and the wrapper function input and output will remain <span class="No-Break">the same.</span></p>
			<p>Pluto could write one complex function that contains all the text transformation techniques, and it may be more efficient, but that is not the goal of this book. After reading this book, you can choose to rewrite or hack the Python Notebook to suit your style <span class="No-Break">with confidence.</span></p>
			<p>In this chapter, Pluto uses an opening line from the book <em class="italic">A Tale of Two Cities</em> by <strong class="bold">Charles Dickens</strong> as the control text. Pluto paraphrases the text by substituting the commas between the phrases with periods because this makes it easier for the text augmentation process. The control text is <span class="No-Break">as follows:</span></p>
			<p><em class="italic">“It was the best of times. It was the worst of times. It was the age of wisdom. It was the age of foolishness. It was the epoch of belief. It was the epoch </em><span class="No-Break"><em class="italic">of incredulity.”</em></span></p>
			<p> The Python Notebook covers the <span class="No-Break">following topics:</span></p>
			<ul>
				<li><span class="No-Break">Character augmentation</span></li>
				<li><span class="No-Break">Word augmentation</span></li>
			</ul>
			<p>Let’s start with the three character <span class="No-Break">augmentation techniques.</span></p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor113"/>Character augmentation</h2>
			<p>Character <a id="_idIndexMarker523"/>augmentation involves injecting errors into the text. The process is counterintuitive because it purposely adds errors to the data. In other words, it makes the text harder for humans to understand. In contrast, computers use deep learning algorithms to predict the outcome, particularly the <strong class="bold">Convolutional Neural Network</strong> (<strong class="bold">CNN</strong>) and the <strong class="bold">Recurrent Neural Network</strong> (<strong class="bold">RNN</strong>) algorithms. For example, sentiment classification for tweets does not affect by <span class="No-Break">misspelled words.</span></p>
			<p>In particular, Pluto will explain the following <span class="No-Break">three methods:</span></p>
			<ul>
				<li><span class="No-Break">OCR augmenting</span></li>
				<li><span class="No-Break">Keyboard augmenting</span></li>
				<li><span class="No-Break">Random augmenting</span></li>
			</ul>
			<p>Let’s start <span class="No-Break">with OCR.</span></p>
			<h3>OCR augmenting</h3>
			<p>The OCR <a id="_idIndexMarker524"/>process converts an image into a piece of text, with frequent errors such as mixing <em class="italic">0</em> and <em class="italic">o</em> during <span class="No-Break">the conversion.</span></p>
			<p>Pluto writes the <strong class="source-inline">_print_aug_batch()</strong> helper function to randomly select sample records from the NLP data, apply the text augmenting method, and print it using pandas. The input or method definition is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># method definition</strong>
def _print_aug_batch(self, df,
    aug_func,
    col_dest="description",
    bsize=3,
    aug_name='Augmented'):</pre>
			<p>Here, <strong class="source-inline">df</strong> is the pandas DataFrame, <strong class="source-inline">aug_function</strong> is the augmentation method from the wrapper function, <strong class="source-inline">col_dest</strong> is the chosen column destination, <strong class="source-inline">bsize</strong> is the number of samples in the batch with a default of three, and <strong class="source-inline">title</strong> is the optional title for <span class="No-Break">the chart.</span></p>
			<p>The OCR <a id="_idIndexMarker525"/>wrapper function is elementary. The two lines of code are the <strong class="bold">Nlpaug</strong> library text augmentation method (<strong class="source-inline">aug_func</strong>) and the helper function. The entire code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># method definiton</strong>
@add_method(PacktDataAug)
def print_aug_ocr(self, df,
    col_dest="description",
    bsize=3,
    aug_name='Augmented'):
    aug_func = nlpaug.augmenter.char.OcrAug()
    self._print_aug_batch(df,
        aug_func,
        col_dest=col_dest,
        bsize=bsize,
        aug_name=aug_name)
    return</pre>
			<p>Pluto uses the <strong class="source-inline">print_aug_ocr()</strong> method with the <strong class="bold">Netflix</strong> data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use OCR method</strong>
pluto.print_aug_ocr(pluto.df_netflix_data,
    col_dest='description',
    aug_name='OCR Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B17990_05_10.jpg" alt="Figure 5.10 – Netflix OCR augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.10 – Netflix OCR augmenting</p>
			<p>In <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.10</em>, the first line is <strong class="bold">Dickens’</strong> control text, with the augmented text on the left-hand side and the original text on the right-hand side. The following three rows are randomly <a id="_idIndexMarker526"/>sampled from the <strong class="bold">Netflix</strong> NLP data. Pluto recommends that you read the left-hand augmented text first. Stop and try to decipher the meaning before reading the <span class="No-Break">original text.</span></p>
			<p class="callout-heading">Fun fact</p>
			<p class="callout">Pluto recommends repeatedly running the <strong class="source-inline">print_aug_ocr()</strong> method to see other movie descriptions. You can increase <strong class="source-inline">bsize</strong> to see more than two records at <span class="No-Break">a time.</span></p>
			<p>Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># print the batch</strong>
pluto.print_aug_ocr(pluto.df_twitter_data,
    col_dest='clean_tweet',
    aug_name='OCR Augment')</pre>
			<p>The <a id="_idIndexMarker527"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B17990_05_11.jpg" alt="Figure 5.11 – Twitter OCR augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.11 – Twitter OCR augmenting</p>
			<p>Next, Pluto moves on from the OCR method to the <span class="No-Break">keyboard technique.</span></p>
			<h3>Keyboard augmenting</h3>
			<p>The keyboard augmenting method replaces a character with a close-distance key on a keyboard. For example, a typical typing error for character <em class="italic">b</em> is using key <em class="italic">v</em> or key <em class="italic">n</em>.    The augmentation variable defines <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function variable definition</strong>
aug_func = nlpaug.augmenter.char.KeyboardAug()</pre>
			<p>Pluto <a id="_idIndexMarker528"/>uses the <strong class="source-inline">print_aug_keyboard()</strong> wrapper function with the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use keyboard augmentation technique</strong>
pluto.print_aug_keyboard(pluto.df_netflix_data,
    col_dest='description',
    aug_name='Keyboard Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B17990_05_12.jpg" alt="Figure 5.12 – Netflix keyboard augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.12 – Netflix keyboard augmenting</p>
			<p>Pluto <a id="_idIndexMarker529"/>does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use keyboard augmentation technique</strong>
pluto.print_aug_keyboard(pluto.df_twitter_data,
    col_dest='clean_tweet',
    aug_name='Keyboard Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B17990_05_13.jpg" alt="Figure 5.13 – Twitter keyboard augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.13 – Twitter keyboard augmenting</p>
			<p>The last <a id="_idIndexMarker530"/>of the three text augmentation methods is the <span class="No-Break">random technique.</span></p>
			<h3>Random augmenting</h3>
			<p>The <a id="_idIndexMarker531"/>random character function randomly swaps, inserts, or deletes characters in the text. The four modes for the random process are <strong class="bold">inserting</strong>, <strong class="bold">deleting</strong>, <strong class="bold">substituting</strong>, and <strong class="bold">swapping</strong>. The augmentation variable defines <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function variable definition</strong>
aug_func = nlpaug.augmenter.char.RandomCharAug(action=action)</pre>
			<p>Pluto uses the <strong class="source-inline">print_aug_random()</strong> wrapper function with <strong class="source-inline">action</strong> set to <strong class="source-inline">insert</strong> in the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random insert augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_netflix_data,
    action='insert',
    col_dest='description',
    aug_name='Random Insert Augment')</pre>
			<p>The <a id="_idIndexMarker532"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/B17990_05_14.jpg" alt="Figure 5.14 – Netflix random insert augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.14 – Netflix random insert augmenting</p>
			<p>Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random insert augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_twitter_data,
    action='insert',
    col_dest='clean_tweet',
    aug_name='Random Insert Augment')</pre>
			<p>The <a id="_idIndexMarker533"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/B17990_05_15.jpg" alt="Figure 5.15 – Twitter random insert augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.15 – Twitter random insert augmenting</p>
			<p>Pluto uses the <strong class="source-inline">print_aug_random()</strong> wrapper function with <strong class="source-inline">action</strong> set to <strong class="source-inline">delete</strong> for the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random delete augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_netflix_data,
    action='delete',
    col_dest='description',
    aug_name='Random Delete Augment')</pre>
			<p>The <a id="_idIndexMarker534"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="image/B17990_05_16.jpg" alt="Figure 5.16 – Netflix random delete augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.16 – Netflix random delete augmenting</p>
			<p>Pluto does the same for the Twitter NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random delete augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_twitter_data,
    action='delete', col_dest='clean_tweet',
    aug_name='Random Delete Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer123" class="IMG---Figure">
					<img src="image/B17990_05_17.jpg" alt="Figure 5.17 – Twitter random delete augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.17 – Twitter random delete augmenting</p>
			<p>Pluto <a id="_idIndexMarker535"/>uses the <strong class="source-inline">print_aug_random()</strong> wrapper function with <strong class="source-inline">actio</strong>n set to <strong class="source-inline">substitute</strong> for the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random substitute augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_netflix_data,
    action='substitute',
    col_dest='description',
    aug_name='Random Substitute Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/B17990_05_18.jpg" alt="Figure 5.18 – Netflix random substitute augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.18 – Netflix random substitute augmenting</p>
			<p>Pluto <a id="_idIndexMarker536"/>does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random substitude augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_twitter_data,
    action='substitute',
    col_dest='clean_tweet',
    aug_name='Random Substitute Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/B17990_05_19.jpg" alt="Figure 5.19 – Twitter random substitute augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.19 – Twitter random substitute augmenting</p>
			<p>Pluto <a id="_idIndexMarker537"/>uses the <strong class="source-inline">print_aug_random()</strong> wrapper function with <strong class="source-inline">action</strong> set to <strong class="source-inline">swap</strong> for the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random swap augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_netflix_data,
    action='swap',
    col_dest='description',
    aug_name='Random Swap Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/B17990_05_20.jpg" alt="Figure 5.20 – Netflix random swap augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.20 – Netflix random swap augmenting</p>
			<p>Pluto <a id="_idIndexMarker538"/>does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use random swap augmentation technique</strong>
pluto.print_aug_char_random(pluto.df_twitter_data,
    action='swap',
    col_dest='clean_tweet',
    aug_name='Random Swap Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/B17990_05_21.jpg" alt="Figure 5.21 – Twitter random swap augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.21 – Twitter random swap augmenting</p>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">Here is a thought experiment: if the input text contains misspelled words and bad grammar, such as tweets, could correcting the spelling and grammar be a valid <span class="No-Break">augmentation method?</span></p>
			<p>Pluto <a id="_idIndexMarker539"/>has covered the <strong class="bold">OCR</strong>, <strong class="bold">Keyboard</strong>, and four modes of <strong class="bold">Random</strong> character augmentation techniques. The next step is <span class="No-Break">augmenting words.</span></p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor114"/>Word augmenting</h2>
			<p>At this <a id="_idIndexMarker540"/>point in the book, Pluto might think text augmentation is effortless, and it is true. We built a solid foundation layer in <a href="B17990_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic">Chapter 1</em></span></a> with an object-oriented class and learned how to extend the object as we learned about new augmentation techniques. In <a href="B17990_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, Pluto added the functions for downloading any <em class="italic">Kaggle</em> real-world dataset, and <em class="italic">Chapters 3</em> and <em class="italic">4</em> gave us the wrapper function pattern. Therefore, at this point, Pluto reuses the methods and patterns to make the Python code concise and easy <span class="No-Break">to understand.</span></p>
			<p>The word <a id="_idIndexMarker541"/>augmentation process is similar to character augmentation. Pluto uses the same <strong class="bold">Nlpaug</strong> library to write the wrapper functions, which will invoke the <strong class="source-inline">_print_aug_batch()</strong> helper method. In particular, Pluto will cover the <strong class="bold">Misspell</strong>, <strong class="bold">Split</strong>, <strong class="bold">Random</strong>, <strong class="bold">Synonyms</strong>, <strong class="bold">Antonyms</strong>, and <strong class="bold">Reserved</strong> word <span class="No-Break">augmenting techniques.</span></p>
			<p>Let’s start with the misspell <span class="No-Break">augmentation technique.</span></p>
			<h3>Misspell augmenting</h3>
			<p>The <a id="_idIndexMarker542"/>misspell augmentation function uses a predefined dictionary to simulate spelling mistakes. The augmentation variable defines this <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function variable definition</strong>
aug_func = nlpaug.augmenter.word.SpellingAug()</pre>
			<p>Pluto uses the <strong class="source-inline">print_aug_word_misspell()</strong> wrapper function on the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word missplell augmentation</strong>
pluto.print_aug_word_misspell(pluto.df_netflix_data,
    col_dest='description',
    aug_name='Word Spelling Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/B17990_05_22.jpg" alt="Figure 5.22 – Netflix misspell word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.22 – Netflix misspell word augmenting</p>
			<p>Pluto <a id="_idIndexMarker543"/>does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word missplell augmentation</strong>
pluto.print_aug_word_misspell(pluto.df_twitter_data,
    col_dest='clean_tweet',
    aug_name='Word Spelling Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/B17990_05_23.jpg" alt="Figure 5.23 – Twitter misspell word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.23 – Twitter misspell word augmenting</p>
			<p>Similar <a id="_idIndexMarker544"/>to <strong class="bold">Misspell</strong> is the <strong class="bold">Split</strong> word <span class="No-Break">augmentation technique.</span></p>
			<h3>Split augmenting</h3>
			<p>The split <a id="_idIndexMarker545"/>augmentation function randomly splits words into two tokens. The augmentation variable defines this <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function variable definition</strong>
aug_func = nlpaug.augmenter.word.SplitAug()</pre>
			<p>Pluto uses the <strong class="source-inline">print_aug_word_split()</strong> wrapper function on the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word split augmentation</strong>
pluto.print_aug_word_split(pluto.df_netflix_data,
    col_dest='description',
    aug_name='Word Split Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/B17990_05_24.jpg" alt="Figure 5.24 – Netflix split word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.24 – Netflix split word augmenting</p>
			<p>Pluto <a id="_idIndexMarker546"/>does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word split augmentation</strong>
pluto.print_aug_word_split(pluto.df_twitter_data,
    col_dest='clean_tweet',
    aug_name='Word Split Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/B17990_05_25.jpg" alt="Figure 5.25 – Twitter split word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.25 – Twitter split word augmenting</p>
			<p>After <a id="_idIndexMarker547"/>the split word method, Pluto presents the random word <span class="No-Break">augmenting method.</span></p>
			<h3>Random augmenting</h3>
			<p>The random <a id="_idIndexMarker548"/>word augmentation method applies random behavior to the text with four parameters: <strong class="bold">Swap</strong>, <strong class="bold">Crop</strong>, <strong class="bold">Substitute</strong>, or <strong class="bold">Delete</strong>. The augmentation variable defines this <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function variable definition</strong>
aug_func = nlpaug.augmenter.word.RandomWordAug(action=action)</pre>
			<p>Pluto uses the <strong class="source-inline">print_aug_word_random()</strong> wrapper function for swapping mode on the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word random swap augmentation</strong>
pluto.print_aug_word_random(pluto.df_netflix_data,
    action='swap',
    col_dest='description',
    aug_name='Word Random Swap Augment')</pre>
			<p>The <a id="_idIndexMarker549"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="image/B17990_05_26.jpg" alt="Figure 5.26 – Netflix random swap word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.26 – Netflix random swap word augmenting</p>
			<p>Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word random swap augmentation</strong>
pluto.print_aug_word_random(pluto.df_twitter_data,
    action='swap',
    col_dest='clean_tweet',
    aug_name='Word Random Swap Augment')</pre>
			<p>The <a id="_idIndexMarker550"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer133" class="IMG---Figure">
					<img src="image/B17990_05_27.jpg" alt="Figure 5.27 – Twitter random swap word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.27 – Twitter random swap word augmenting</p>
			<p>Pluto uses the <strong class="source-inline">print_aug_word_random()</strong> wrapper function for cropping mode on the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word random crop augmentation</strong>
pluto.print_aug_word_random(pluto.df_netflix_data,
    action='crop',
    col_dest='description',
    aug_name='Word Random Crop Augment')</pre>
			<p>The <a id="_idIndexMarker551"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer134" class="IMG---Figure">
					<img src="image/B17990_05_28.jpg" alt="Figure 5.28 – Netflix random crop word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.28 – Netflix random crop word augmenting</p>
			<p>Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word random swap augmentation</strong>
pluto.print_aug_word_random(pluto.df_twitter_data,
    action='crop',
    col_dest='clean_tweet',
    aug_name='Word Random Crop Augment')</pre>
			<p>The <a id="_idIndexMarker552"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer135" class="IMG---Figure">
					<img src="image/B17990_05_29.jpg" alt="Figure 5.29 – Twitter random crop word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.29 – Twitter random crop word augmenting</p>
			<p>So, Pluto has described the <strong class="bold">Swap</strong> and <strong class="bold">Crop</strong> word augmentation methods but not the <strong class="bold">Substitute</strong> and <strong class="bold">Delete</strong> ones. This is because they are similar to the character augmenting functions and are in the Python Notebook. Next on the block is <span class="No-Break">synonym augmenting.</span></p>
			<h3>Synonym augmenting</h3>
			<p>The <a id="_idIndexMarker553"/>synonym augmentation function substitutes words with synonyms from a predefined database. <strong class="bold">WordNet</strong> and <strong class="bold">PPBD</strong> are two optional databases. The augmentation variable defines this process <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function variable definition</strong>
aug_func = nlpaug.augmenter.word.SynonymAug(
    aug_src='wordnet')</pre>
			<p>Pluto <a id="_idIndexMarker554"/>uses the <strong class="source-inline">print_aug_word_synonym()</strong> wrapper function on the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word synonym augmentation</strong>
pluto.print_aug_word_synonym(pluto.df_netflix_data,
    col_dest='description',
    aug_name='Synonym WordNet Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer136" class="IMG---Figure">
					<img src="image/B17990_05_30.jpg" alt="Figure 5.30 – Netflix synonym word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.30 – Netflix synonym word augmenting</p>
			<p>It is <a id="_idIndexMarker555"/>interesting and funny that the <a id="_idIndexMarker556"/>synonym of <em class="italic">It</em> is <strong class="bold">Information Technology</strong> for the control text. Mr. Dickens, who wrote Tale of Two Cities in 1859, could never have known that IT is a popular acronym for information technology. Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word synonym augmentation</strong>
pluto.print_aug_word_synonym(pluto.df_twitter_data,
    col_dest='clean_tweet',
    aug_name='Synonym WordNet Augment')</pre>
			<p>The output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer137" class="IMG---Figure">
					<img src="image/B17990_05_31.jpg" alt="Figure 5.31 – Twitter synonym word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.31 – Twitter synonym word augmenting</p>
			<p>When <a id="_idIndexMarker557"/>there are synonyms, you will also <span class="No-Break">find antonyms.</span></p>
			<h3>Antonym augmenting</h3>
			<p>The <a id="_idIndexMarker558"/>antonym augmentation function randomly replaces words with antonyms. The augmentation variable defines this <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function variable definition</strong>
aug_func = nlpaug.augmenter.word.AntonymAug()</pre>
			<p>Pluto uses the <strong class="source-inline">print_aug_word_antonym()</strong> wrapper function on the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word antonym augmentation</strong>
pluto.print_aug_word_antonym(pluto.df_netflix_data,
    col_dest='description',
    aug_name='Antonym Augment')</pre>
			<p>The <a id="_idIndexMarker559"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer138" class="IMG---Figure">
					<img src="image/B17990_05_32.jpg" alt="Figure 5.32 – Netflix antonym word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.32 – Netflix antonym word augmenting</p>
			<p>Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word antonym augmentation</strong>
pluto.print_aug_word_antonym(pluto.df_twitter_data,
    col_dest='clean_tweet',
    aug_name='Antonym Augment')</pre>
			<p>The <a id="_idIndexMarker560"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer139" class="IMG---Figure">
					<img src="image/B17990_05_33.jpg" alt="Figure 5.33 – Twitter antonym word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.33 – Twitter antonym word augmenting</p>
			<p>After synonyms and antonyms, which are automated, reserved word augmentation requires a manual <span class="No-Break">word list.</span></p>
			<h3>Reserved word augmenting</h3>
			<p>The <a id="_idIndexMarker561"/>reserved word augmentation method swaps target words where you define a word list. It is the same as synonyms, except the terms are created manually. Pluto uses the <strong class="bold">Netflix</strong> and <strong class="bold">Twitter</strong> word cloud diagrams, <em class="italic">Figures 5.8</em> and <em class="italic">5.9</em>, to select the top three reoccurring words in the NLP datasets. The augmentation variable defines this process <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># define augmentation function</strong>
aug_func = nlpaug.augmenter.word.ReservedAug(
    reserved_tokens=reserved_tokens)
<strong class="bold"># define control sentence reserved words</strong>
pluto.reserved_control = [['wisdom', 'sagacity',
    'intelligence', 'prudence'],
    ['foolishness', 'folly', 'idiocy', 'stupidity']]
<strong class="bold"># define Netflix reserved words</strong>
pluto.reserved_netflix = [['family','household', 'brood',
    'unit', 'families'],
    ['life','existance', 'entity', 'creation'],
    ['love', 'warmth', 'endearment','tenderness']]
pluto.reserved_netflix = pluto.reserved_control +
    pluto.reserved_netflix
<strong class="bold"># define Twitter reserved words</strong>
pluto.reserved_twitter = [['user', 'users', 'customer',
    'client','people','member','shopper'],
    ['happy', 'cheerful', 'joyful', 'carefree'],
    ['time','clock','hour']]
pluto.reserved_twitter = pluto.reserved_control +
    pluto.reserved_twitter</pre>
			<p>Pluto <a id="_idIndexMarker562"/>uses the <strong class="source-inline">print_aug_word_reserved()</strong> wrapper function on the <strong class="bold">Netflix</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word reserved augmentation</strong>
pluto.print_aug_word_reserved(pluto.df_netflix_data,
    col_dest='description',
    reserved_tokens=pluto.reserved_netflix)</pre>
			<p>The <a id="_idIndexMarker563"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer140" class="IMG---Figure">
					<img src="image/B17990_05_34.jpg" alt="Figure 5.34 – Netflix reserved word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.34 – Netflix reserved word augmenting</p>
			<p>Notice the words <strong class="bold">wisdom</strong> and <strong class="bold">foolishness</strong> are substituted with <strong class="bold">Intelligence</strong> and <strong class="bold">idiocy</strong>, <strong class="bold">life</strong> with <strong class="bold">existance</strong>, and <strong class="bold">family</strong> with <strong class="bold">brood</strong>. Pluto does the same for the <strong class="bold">Twitter</strong> NLP data, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold"># use word reserved augmentation</strong>
pluto.print_aug_word_reserved(pluto.df_twitter_data,
    col_dest='clean_tweet',
    reserved_tokens=pluto.reserved_twitter)</pre>
			<p>The <a id="_idIndexMarker564"/>output is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer141" class="IMG---Figure">
					<img src="image/B17990_05_35.jpg" alt="Figure 5.35 – Twitter reserved word augmenting"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.35 – Twitter reserved word augmenting</p>
			<p>Notice the words <strong class="bold">wisdom</strong> and <strong class="bold">foolishness</strong> are substituted with <strong class="bold">sagacity</strong> and <strong class="bold">idiocy</strong>, and <strong class="bold">user</strong> with <strong class="bold">people</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">customer</strong></span><span class="No-Break">.</span></p>
			<p><strong class="bold">Reserved Word</strong> augmenting is the last word augmentation method of this chapter. Pluto has covered <strong class="bold">Misspell</strong>, <strong class="bold">Split</strong>, <strong class="bold">Random</strong>, <strong class="bold">Synonym</strong>, <strong class="bold">Antonym</strong>, and <strong class="bold">Reserved Word</strong> augmentation, but these are only some of the possible word augmentation techniques you <span class="No-Break">can use.</span></p>
			<p class="callout-heading">Fun challenge</p>
			<p class="callout">The challenge is to use the Augly library or the NLTK, Gensim, or Textblob libraries to write a new wrapper function. It is relatively easy. The first step is to copy a wrapper function, such as the <strong class="source-inline">print_aug_keyboard()</strong> function. The second and last step is to replace <strong class="source-inline">aug_func = nlpaug.augmenter.char.KeyboardAug()</strong> with <strong class="source-inline">aug_func = augly.text.functional.simulate_typos()</strong>. There are more parameters in the Augly function. A hint is to use the <strong class="source-inline">augly.text.functional.simulate_typos?</strong> command to display the <span class="No-Break">function documentation.</span></p>
			<p>The <strong class="bold">Nlpaug</strong> library and other text augmentation libraries, such as <strong class="bold">NLTK</strong>, <strong class="bold">Gensim</strong>, <strong class="bold">Textblob</strong>, and <strong class="bold">Augly</strong>, have additional text augmentation methods. In addition, newly published <a id="_idIndexMarker565"/>scholarly papers are an excellent source in which to discover new text <span class="No-Break">augmentation techniques.</span></p>
			<p>Let’s summarize <span class="No-Break">this chapter.</span></p>
			<h1 id="_idParaDest-115"><a id="_idTextAnchor115"/>Summary</h1>
			<p>At first glance, text augmentation seems counterintuitive and problematic because the techniques inject errors into the text. Still, DL based on CNNs or RNNs recognizes patterns regardless of a few misspellings or synonym replacements. Furthermore, many published scholarly papers have described the benefits of text augmentation to increase prediction or <span class="No-Break">forecast accuracy.</span></p>
			<p>In <a href="B17990_05.xhtml#_idTextAnchor101"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, you learned about three <strong class="bold">Character</strong> augmentation techniques, <strong class="bold">OCR, Keyboard</strong>, and <strong class="bold">Random</strong>. In addition, the six <strong class="bold">Word</strong> augmentation techniques are the <strong class="bold">Misspell</strong>, <strong class="bold">Split</strong>, <strong class="bold">Random</strong>, <strong class="bold">Synonyms</strong>, <strong class="bold">Antonyms</strong>, and <strong class="bold">Reserved</strong> words. There are more text augmentation methods in the Nlgaug, NLTK, Gensim, TextBlob, and <span class="No-Break">Augly libraries.</span></p>
			<p>Implementing the text augmentation methods using a Python Notebook is deceptively simple. This is because Pluto built a solid foundation layer in <a href="B17990_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic">Chapter 1</em></span></a> with an object-oriented class and learned how to extend the object with <strong class="bold">decorator</strong> as he discovered new augmentation techniques. In <a href="B17990_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, Pluto added the functions for downloading any <em class="italic">Kaggle</em> real-world dataset, and <em class="italic">Chapters 3</em> and <em class="italic">4</em> gave us the wrapper function pattern. Therefore, in this chapter, Pluto reused the methods and patterns to make the Python Notebook code concise and easy <span class="No-Break">to understand.</span></p>
			<p>Throughout the chapter, there are <em class="italic">Fun facts</em> and <em class="italic">Fun challenges</em>. Pluto hopes you will take advantage of them and expand your experience beyond the scope of <span class="No-Break">this chapter.</span></p>
			<p>The next chapter will delve deeper into text augmentation using machine learning methods. Ironically, the goal of text augmentation is to make machine learning and DL predict and forecast accurately, and we will use the same AI system to increase the efficiency of text augmentation. It is a circular logic or <span class="No-Break">cyclical process.</span></p>
			<p>Pluto is waiting for you in the next chapter, <em class="italic">Text Augmentation with </em><span class="No-Break"><em class="italic">Machine Learning</em></span><span class="No-Break">.</span></p>
		</div>
	</body></html>