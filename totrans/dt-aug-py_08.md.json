["```py\n# draw Spectrogram\npluto.draw_spectrogram(pluto.audio_control_dmajor)\n```", "```py\n# Clone GitHub repo.\nurl = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n!git clone {url}\n# Intialize Pluto from Chapter 7\npluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_7.py'\n%run {pluto_file}\n# Verify Pluto\npluto.say_sys_info()\n# Fetch Musical emotions classification\nurl = 'https://www.kaggle.com/datasets/kingofarmy/musical-emotions-classification'\npluto.fetch_kaggle_dataset(url)\nf = 'kaggle/musical-emotions-classification/Train.csv'\npluto.df_music_data = pluto.fetch_df(f)\n# Fetch human speaking\nurl = 'https://www.kaggle.com/datasets/ejlok1/cremad'\npluto.fetch_kaggle_dataset(url)\nf = 'kaggle/cremad/AudioWAV'\npluto.df_voice_data = pluto.make_dir_dataframe(f)\n# Fetch urban sound\nurl='https://www.kaggle.com/datasets/rupakroy/urban-sound-8k'\npluto.fetch_kaggle_dataset(url)\nf = 'kaggle/urban-sound-8k/UrbanSound8K/UrbanSound8K/audio'\npluto.df_sound_data = pluto.make_dir_dataframe(f)\n```", "```py\n# read audio file\ndata_amp, sam_rate = librosa.load(lname, mono=True)\n# draw the spectrogram plot\nspectrum, freq, ts, ax = pic.specgram(data_amp, Fs=sam_rate)\n```", "```py\n# plot the Spectrogram\npluto.draw_spectrogram(pluto.audio_control_dmajor)\n```", "```py\n# plot the Waveform\npluto._draw_audio(data_amp, sam_rate, 'Original: ' + fname)\n```", "```py\n# plot the spectrogram in different color map\npluto.draw_spectrogram(pluto.df_music_data, cmap='plasma')\n```", "```py\n# plot the Spectrogram in different color map\npluto.draw_spectrogram(pluto.df_voice_data, cmap='cool')\n```", "```py\n# plot the Spectrogram with different color map\npluto.draw_spectrogram(pluto.df_sound_data, cmap='brg')\n```", "```py\n# control audio file\npluto.draw_spectrogram(pluto.audio_control_dmajor,\n  window=matplotlib.mlab.window_none)\n# Human speech\npluto.draw_spectrogram(pluto.df_voice_data,\n  cmap='cool',\n  window=matplotlib.mlab.window_none)\n```", "```py\n# the control piano scale in D major\npluto.draw_spectrogram(pluto.df_music_data,\n  cmap='plasma',\n  sides='twosided')\n# the music dataset\npluto.draw_spectrogram(pluto.audio_control_dmajor,\n  window=matplotlib.mlab.window_none,\n  sides='twosided',\n  mode='angle')\n```", "```py\n# code snippeet for the melspectrogram\nmel = librosa.feature.melspectrogram(y=data_amp,\n  sr=sam_rate,\n  n_mels=128,\n  fmax=8000)\nmel_db = librosa.power_to_db(mel, ref=numpy.max)\nself._draw_melspectrogram(mel_db, sam_rate, data_amp,\n  cmap=cmap,\n  fname=tname)\n```", "```py\n# Control piano scale\npluto.draw_melspectrogram(pluto.audio_control_dmajor)\n# Music dataset\npluto.draw_melspectrogram(pluto.df_voice_data, cmap='cool')\n```", "```py\n# code snippet for the chroma_stft\nstft = librosa.feature.chroma_stft(data_amp,\n  sr=sam_rate)\nself._draw_melspectrogram(stft, sam_rate, data_amp,\n  cmap=cmap,\n  fname=tname,\n  y_axis=yax,\n  y_label=ylab)\n```", "```py\n# Control piano scale\npluto.draw_melspectrogram(pluto.audio_control_dmajor,\n  is_chroma=True)\n# Music dataset\npluto.draw_melspectrogram(pluto.df_music_data,\n  is_chroma=True,\n  cmap='plasma')\n# Urban sound dataset\npluto.draw_melspectrogram(pluto.df_sound_data,\n  is_chroma=True,\n  cmap='brg')\n```", "```py\n# add is_waveform parameter\n@add_method(PacktDataAug)\ndef _audio_transform(self, df, xtransform,\n  Title = '',\n  is_waveform = True):\n```", "```py\n# keep the default to be same for Chapter 7, Waveform graph\nif (is_waveform):\n  # augmented waveform\n  self._draw_audio(xaug, sam_rate,\n    title + ' Augmented: ' + fname)\n  display(IPython.display.Audio(xaug, rate=sam_rate))\n  # original waveform\n  self._draw_audio(data_amp, sam_rate, 'Original: ' + fname)\n# update to use spectrogram, me-spectrogram, and Chroma\nelse:\n  xdata = [xaug, sam_rate, lname, 'Pluto']\n  self.draw_spectrogram(xdata)\n  self.draw_melspectrogram(xdata)\n  self.draw_melspectrogram(xdata, is_chroma=True)\n```", "```py\n# augment the audio with time shift\npluto.play_aug_time_shift(pluto.audio_control_dmajor,\n  min_fraction=0.8,\n  is_waveform=False)\n```", "```py\n# augment audio using time shift\npluto.play_aug_time_shift(pluto.df_voice_data,\n  min_fraction=0.8,\n  is_waveform=False)\n```", "```py\n# augment audio with noise injection\npluto.play_aug_noise_injection(pluto.df_music_data,\n  min_amplitude=0.008,\n  max_amplitude=0.05,\n  is_waveform=False)\n```", "```py\n# Original use white noise, code snippet\nxtransform = audiomentations.AddGaussianNoise(\n  min_amplitude=min_amplitude,\n  max_amplitude=max_amplitude,\n  p=1.0)\n# Update to using unwanted noise file\nxtransform = audiomentations.AddShortNoises(\n  sounds_path=\"~/path_to_unwanted_noise_file\",\n  min_snr_in_db=3.0,\n  max_snr_in_db=30.0,\n  noise_rms=\"relative_to_whole_input\",\n  min_time_between_sounds=2.0,\n  max_time_between_sounds=8.0,\n  noise_transform=PolarityInversion(),\n  p=1.0)\n```"]