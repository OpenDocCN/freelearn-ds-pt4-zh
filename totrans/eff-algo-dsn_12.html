<html><head></head><body>
		<div id="_idContainer1634" epub:type="chapter" class="calibre2">
			<h1 id="_idParaDest-114" class="chapter-number"><a id="_idTextAnchor129" class="pcalibre pcalibre1 calibre6"/><st c="0">9</st></h1>
			<h1 id="_idParaDest-115" class="calibre5"><a id="_idTextAnchor130" class="pcalibre pcalibre1 calibre6"/><st c="2">Randomized Algorithms</st></h1>
			<p class="calibre3"><st c="23">Building on the deterministic algorithms discussed in previous chapters, we now turn our attention to situations where uncertainty and randomness are significant factors. </st><st c="195">In this chapter, we will explore how to design algorithms that make the best possible decisions despite the presence of unpredictable elements. </st><st c="339">Randomized algorithms introduce elements of chance into their logic, providing innovative ways to tackle problems that may be challenging or inefficient to solve using purely deterministic methods. </st><st c="537">These algorithms can often simplify solutions, improve performance, and offer new perspectives on problem-solving. </st><st c="652">Throughout this chapter, we will examine various strategies and techniques that leverage randomness to achieve desired outcomes. </st><st c="781">By understanding the principles behind randomized algorithms, we can develop robust solutions that excel in uncertain environments. </st><st c="913">Our discussion will cover theoretical foundations, practical applications, and examples that illustrate the power and versatility of incorporating randomness into </st><span><st c="1076">algorithm design.</st></span></p>
			<p class="calibre3"><a id="_idTextAnchor131" class="pcalibre pcalibre1 calibre6"/><st c="1093">Please note that although we use some preliminary topics in probability theory in this chapter, a sufficient amount of familiarity with probability theory is necessary to understand this chapter holistically. </st><st c="1303">If you are not well versed in probability theory, we recommend refreshing your knowledge using reputable reference books and textbooks on the subject </st><span><st c="1453">before proceeding.</st></span></p>
			<p class="calibre3"><st c="1471">In this chapter, we will cover the </st><span><st c="1507">following topics:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="1524">A review of </st><span><st c="1537">probabilistic algorithms</st></span></li>
				<li class="calibre13"><st c="1561">Analysis of </st><span><st c="1574">randomized algorithms</st></span></li>
				<li class="calibre13"><span><st c="1595">Case studies</st></span></li>
			</ul>
			<h1 id="_idParaDest-116" class="calibre5"><a id="_idTextAnchor132" class="pcalibre pcalibre1 calibre6"/><st c="1608">A review of probabilistic algorithms</st></h1>
			<p class="calibre3"><st c="1645">To begin, let’s explore whether we can apply the concepts covered so far to solve the following </st><span><st c="1742">hypothetical problems:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="1764">A new online dating app, </st><em class="italic"><st c="1790">Matcher</st></em><st c="1797">, has been developed to help users find potential partners. </st><st c="1857">The app functions like a game, aiming to match users with their best </st><span><st c="1926">possible dates:</st></span><ul class="calibre50"><li class="calibre13"><st c="1941">There are </st><img src="image/1469.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1094"/><st c="1952"/><st c="1953"> potential matches available on the app (the total number of matches is unknown to the users). </st><st c="2048">Let’s consider a user </st><span><st c="2070">named Tom.</st></span></li><li class="calibre13"><st c="2080">When Tom opens the </st><em class="italic"><st c="2100">Matcher</st></em><st c="2107"> app, he is presented with one potential match at a time, selected randomly. </st><st c="2184">Tom has the option to either like (swipe right) or dislike (swipe left) </st><span><st c="2256">each profile.</st></span></li><li class="calibre13"><st c="2269">Tom’s decisions are irreversible; once he swipes right or left on a profile, he cannot change his mind. </st><st c="2374">All decisions </st><span><st c="2388">are final.</st></span></li><li class="calibre13"><st c="2398">Tom can like a maximum of </st><img src="image/23.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre166"/><st c="2425"/><st c="2426"> profiles (where </st><em class="italic"><st c="2443">n</st></em><st c="2444"> is much smaller than </st><em class="italic"><st c="2466">N</st></em><st c="2467">). </st><st c="2470">Once Tom has liked </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="2489"/><st c="2538"> profiles, the app will no longer show him any </st><span><st c="2584">more profiles.</st></span></li><li class="calibre13"><st c="2598">The interaction ends either when Tom has liked </st><img src="image/1054.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre239"/><st c="2646"/><st c="2647"> profiles or when there are no more profiles left </st><span><st c="2697">to show.</st></span></li><li class="calibre13"><st c="2705">It is important to note that liking a profile does not guarantee a match; it still requires the other person to like Tom’s </st><span><st c="2829">profile back.</st></span></li><li class="calibre13"><st c="2842">The challenge for Tom is to make the best possible use of his </st><img src="image/23.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1095"/><st c="2905"/><st c="2906"> likes to choose the most suitable matches. </st><st c="2950">He needs to decide when to stop browsing and start liking profiles to maximize the chances of selecting the best </st><span><st c="3063">available options.</st></span></li></ul></li>
				<li class="calibre13"><a id="_idTextAnchor133" class="pcalibre pcalibre1 calibre6"/><st c="3081">Fang has been invited to her friend’s house, which is located in the middle of a long, one-way street. </st><st c="3185">Parking is allowed only on one side of the street. </st><st c="3236">The street is busy, and finding a parking spot is challenging. </st><st c="3299">Based on experience, about 10% of the </st><img src="image/210.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre188"/><st c="3337"/><st c="3338"> parking spots are typically available at any given time. </st><st c="3396">Fang can only see one spot at a time as she passes by and cannot see the spots ahead. </st><st c="3482">The objective is to determine the optimal moment for her to decide to take an available </st><span><st c="3570">parking spot.</st></span></li>
			</ul>
			<p class="calibre3"><st c="3583">Both problems mentioned share a fundamental similarity: they are all search problems. </st><st c="3670">In each scenario, the objective is to identify the best option from a sequence </st><span><st c="3749">of possibilities:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="3766">Tom is searching for the best match on a </st><span><st c="3808">dating app</st></span></li>
				<li class="calibre13"><st c="3818">Fang is trying to find the closest parking spot to her </st><span><st c="3874">friend’s house</st></span></li>
			</ul>
			<p class="calibre3"><st c="3888">However, these problems differ from traditional search settings. </st><st c="3954">Unlike classical search problems where all data items are available for comparison, here, data items appear sequentially and unpredictably. </st><st c="4094">This sequential arrival of data means we cannot predict the next item, rendering standard comparison-based search </st><span><st c="4208">algorithms ineffective.</st></span></p>
			<p class="calibre3"><st c="4231">In these scenarios, the challenge is not about identifying the best data item through comparison but deciding when to stop searching and </st><a id="_idTextAnchor134" class="pcalibre pcalibre1 calibre6"/><st c="4369">make a selection. </st><st c="4387">The decision-making process involves evaluating each option as it arrives and determining whether to accept it or continue searching for a potentially better option. </st><st c="4553">The following are key characteristics of </st><span><st c="4594">these problems:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="4609">Sequential data arrival</st></strong><st c="4633">: Data items arrive one at a time, and decisions must be made immediately without knowing </st><span><st c="4724">future data.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="4736">Irreversible decisions</st></strong><st c="4759">: Once a decision is made to accept or reject an option, it cannot be reversed. </st><st c="4840">This adds a layer of complexity as you cannot revisit </st><span><st c="4894">previous choices.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="4911">Optimal stopping rule</st></strong><st c="4933">: The core of these problems is finding the optimal stopping point. </st><st c="5002">This involves deciding at what point to stop searching and accept the current option as the </st><span><st c="5094">best available.</st></span></li>
			</ul>
			<p class="calibre3"><st c="5109">Optimal stopping theory provides a framework for solving these types of problems. </st><st c="5192">The theory helps in determining the point at which the probability of finding a better option is outweighed by the cost of continuing the search. </st><st c="5338">For example, let’s consider </st><span><st c="5366">the following:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="5380">Tom can use a strategy where he initially reviews a set number of profiles without making any decisions (to gather information about the quality of matches) and then selects the next profile that is better than those he has reviewed </st><span><st c="5614">so far</st></span></li>
				<li class="calibre13"><st c="5620">Fang can drive past the first few parking spots (to gauge availability and proximity) and then take the first spot that is closer than those she has </st><span><st c="5770">already seen</st></span></li>
			</ul>
			<p class="calibre3"><st c="5782">These problems exemplify the practical application of optimal stopping theory in real-life scenarios where data arrives </st><a id="_idTextAnchor135" class="pcalibre pcalibre1 calibre6"/><st c="5903">sequentially and decisions must be made in real time. </st><st c="5957">By understanding and applying this theory, one can make informed decisions on when to stop searching and accept an option, even in the face of uncertainty and incomplete information. </st><st c="6140">This approach shifts the focus from finding the best data item to determining the optimal moment to </st><a id="_idTextAnchor136" class="pcalibre pcalibre1 calibre6"/><st c="6240">make </st><span><st c="6245">a decision.</st></span></p>
			<p class="calibre3"><st c="6256">The optimal stopping problem is a prime example of a randomized algorithm. </st><st c="6332">Before we explore randomized algorithms in detail, let’s revisit the fundamental concept of an algorithm. </st><st c="6438">An algorithm is a system that transforms a set of input data into a set of output data. </st><span><em class="italic"><st c="6526">Figure 9</st></em></span><em class="italic"><st c="6534">.1</st></em><st c="6536"> provides a simple block diagram to illustrate </st><span><st c="6583">this concept.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1497" class="img---figure">
					<img src="image/B22248_09_1.jpg" alt="Figure 9.1: A block diagram showing the mapping of input data to output data through an algorithm" class="calibre144"/><st c="6596"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="6630">Figure 9.1: A block diagram showing the mapping of input data to output data through an algorithm</st></p>
			<p class="calibre3"><st c="6727">Let’s revisit the concept of an algorithm through the lens of mapping input to output. </st><st c="6815">Assume we have an input dataset represented by </st><img src="image/1475.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt;&lt;&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt;…&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;&gt;&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1096"/><st c="6862"/><st c="6874">. An algorithm, which consists of a set of procedural instructions, transforms </st><img src="image/1033.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre797"/><st c="6953"/><st c="6954"> into an </st><span><st c="6963">output </st></span><span><img src="image/1477.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mo&gt;&lt;&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;b&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;b&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt;…&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;b&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;&gt;&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1097"/><st c="6970"/></span><span><st c="6994">.</st></span></p>
			<p class="calibre3"><st c="6995">In the context of deterministic algorithms, this transformation process is consistent and repeatable. </st><st c="7098">Given the same input </st><img src="image/1478.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1098"/><st c="7119"/><st c="7120">, a deterministic algorithm will always produce the same output </st><img src="image/1479.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1099"/><st c="7184"/><st c="7185">. This predictability is a hallmark of deterministic algorithms, ensuring that their behavior is fully determined by the input </st><span><st c="7312">they receive.</st></span></p>
			<p class="calibre3"><st c="7325">For instance, consider the sorting and searching algorithms we have introduced in previous chapters. </st><st c="7427">These algorithms are deterministic because they guarantee the same result each time they are run with the </st><span><st c="7533">same input.</st></span></p>
			<p class="calibre3"><st c="7544">Deterministic algorithms offer predictability and reliability by ensuring that the same input will always produce the same output. </st><st c="7676">This characteristic is fundamental to many algorithms used in computer science, especially in tasks that require consistent and repeatable results, such as sorting and searching. </st><st c="7855">Understanding this concept lays the groundwork for exploring randomized algorithms, which introduce elements of chance to achieve different goals and handle uncertainty in </st><span><st c="8027">unique ways.</st></span></p>
			<h1 id="_idParaDest-117" class="calibre5"><a id="_idTextAnchor137" class="pcalibre pcalibre1 calibre6"/><st c="8039">Non-deterministic algorithms</st></h1>
			<p class="calibre3"><strong class="bold"><st c="8068">Non-deterministic algorithms</st></strong><st c="8097"> are theoretical constructs used primarily in the study of computational complexity. </st><st c="8182">They assume the existence of a “non-deterministic” machine, such as a non-deterministic Turing machine, which can make arbitrary choices to explore different computational paths simultaneously. </st><st c="8376">Non-deterministic algorithms are often used to define classes of problems, such as </st><strong class="bold"><st c="8459">nondeterministic polynomial time</st></strong><st c="8491"> (</st><strong class="bold"><st c="8493">NP</st></strong><st c="8495">), which includes problems for which a solution can be verified in polynomial time by a deterministic algorithm. </st><st c="8609">Non-deterministic algorithms are not practically implementable on standard deterministic machines. </st><st c="8708">They serve as a way to understand the potential power of parallel computation and to classify </st><span><st c="8802">problem complexity.</st></span></p>
			<p class="callout-heading"><st c="8821">Note</st></p>
			<p class="callout"><st c="8826">Non-deterministic algorithms are not practically implementable on standard deterministic machines. </st><st c="8926">Randomized algorithms, on the other hand, are practical algorithms that use random numbers to influence their decision-making process. </st><st c="9061">These algorithms can be implemented on standard computers and have applications in many areas of computer science </st><span><st c="9175">and engineering.</st></span></p>
			<p class="calibre3"><span><em class="italic"><st c="9191">Figure 9</st></em></span><em class="italic"><st c="9200">.2</st></em><st c="9202"> provides a simple block diagram to illustrate the concept of randomized algorithms. </st><st c="9287">Randomized algorithms include an element of chance that acts as an additional hidden input, which we cannot control. </st><st c="9404">This element of randomness introduces uncertainty, effectively serving as a second input to the algorithm. </st><st c="9511">It is this inherent randomness that causes the algorithm to have different behavior and/or performance even when the explicit input remains </st><span><st c="9651">the same.</st></span></p>
			<p class="calibre3"><st c="9660">Consider the </st><strong class="bold"><st c="9674">randomized quick sort</st></strong><st c="9695"> algorithm. </st><st c="9707">Unlike the traditional quick sort, which typically selects a fixed pivot (such as the first, last, or middle element), randomized quick sort selects a pivot at random. </st><st c="9875">This random selection can lead to different sequences of comparisons and swaps each time the algorithm is run, even on the same input sequence. </st><st c="10019">For instance, given the input sequence </st><img src="image/1480.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt; &lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;9&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;6&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1100"/><st c="10058"/><st c="10059">, a traditional quick sort algorithm might always choose the middle element as the pivot. </st><st c="10149">In contrast, randomized quick sort might choose any element as the pivot, resulting in a different sequence of steps and partitioning in each run. </st><st c="10296">Consequently, the intermediate steps can vary, potentially leading to different overall running times even with the </st><span><st c="10412">same data.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1504" class="img---figure">
					<img src="image/B22248_09_2.jpg" alt="Figure 9.2: A block diagram showing the mapping of input data to output data through a non-deterministic algorithm" class="calibre144"/><st c="10422"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="10467">Figure 9.2: A block diagram showing the mapping of input data to output data through a non-deterministic algorithm</st></p>
			<p class="calibre3"><st c="10581">Any random input to the algorithm introduces variability in the algorithm’s performance and behavior. </st><st c="10684">While the average case time complexity of randomized quick sort remains </st><img src="image/1481.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1101"/><st c="10756"/><st c="10765">, the actual runtime for a specific instance can differ due to the random pivot selection. </st><st c="10856">In the worst case, if the pivot selection is particularly poor repeatedly, the performance can degrade, although such scenarios are </st><span><st c="10988">statistically unlikely.</st></span></p>
			<p class="calibre3"><st c="11011">By introducing randomness, these </st><a id="_idIndexMarker577" class="pcalibre pcalibre1 calibre6"/><st c="11045">algorithms can avoid pathological cases that deterministic algorithms might encounter. </st><st c="11132">For instance, randomized quick sort avoids the worst-case scenario of </st><img src="image/1045.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1102"/><st c="11202"/><st c="11208"> that occurs in traditional quick sort with certain inputs. </st><st c="11267">Randomized algorithms are often more robust and adaptable. </st><st c="11326">They perform well on average across a wide range of inputs, making them versatile tools in practice. </st><st c="11427">In the next section, we explore the framework to analyze </st><span><st c="11484">randomized algorithms.</st></span></p>
			<p class="calibre3"><st c="11506">To effectively study randomized algorithms, we need to explore several </st><span><st c="11578">key topics:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="11589">Analysis of randomized algorithms</st></strong><st c="11623">: Understanding the behavior of algorithms in terms of probability and expected outcomes is crucial. </st><st c="11725">This involves analyzing the average-case performance rather than focusing solely on worst-case scenarios. </st><st c="11831">This topic will be covered in detail in the upcoming section titled </st><em class="italic"><st c="11899">Analysis of </st></em><span><em class="italic"><st c="11911">randomized algorithms</st></em></span><span><st c="11932">.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="11933">Randomized data structures</st></strong><st c="11960">: Designing data structures that incorporate randomness can lead to more efficient operations. </st><st c="12056">Examples include skip lists and hash tables. </st><st c="12101">Skip lists, in particular, will be explored in </st><a href="B22248_11.xhtml#_idTextAnchor164" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><st c="12148">Chapter 11</st></em></span></a><span><st c="12158">.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="12159">Case studies</st></strong><st c="12172">: To apply the concepts learned, we will analyze specific problems under uncertainty, such as those mentioned at the beginning of this section. </st><st c="12317">Detailed solutions and discussions will be presented in the section titled </st><span><em class="italic"><st c="12392">Case studies</st></em></span><span><st c="12404">.</st></span></li>
			</ul>
			<p class="calibre3"><st c="12405">By exploring these topics, we will gain a comprehensive understanding of how randomized algorithms operate and how to leverage them effectively in </st><span><st c="12553">various applications.</st></span></p>
			<h1 id="_idParaDest-118" class="calibre5"><a id="_idTextAnchor138" class="pcalibre pcalibre1 calibre6"/><st c="12574">Analysis of randomized algorithms</st></h1>
			<p class="calibre3"><st c="12608">To analyze </st><a id="_idIndexMarker578" class="pcalibre pcalibre1 calibre6"/><st c="12620">randomized algorithms, we often use </st><strong class="bold"><st c="12656">probabilistic analysis</st></strong><st c="12678">. Instead</st><a id="_idIndexMarker579" class="pcalibre pcalibre1 calibre6"/><st c="12687"> of focusing on the worst-case scenario, we examine the </st><em class="italic"><st c="12743">expected</st></em><st c="12751"> performance of the algorithm over all possible random choices. </st><st c="12815">This expected value provides a more realistic picture of the algorithm’s typical behavior. </st><st c="12906">Here are the </st><span><st c="12919">key principles:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="12934">We calculate the expected value of key performance metrics, such as running time or space usage. </st><st c="13032">This involves averaging the performance over all possible inputs, weighted by </st><span><st c="13110">their probability.</st></span></li>
				<li class="calibre13"><st c="13128">We study the distribution and variance of the algorithm’s performance metrics to understand how much they deviate from the expected value. </st><st c="13268">This helps in assessing the reliability and consistency of </st><span><st c="13327">the algorithm.</st></span></li>
				<li class="calibre13"><st c="13341">The focus is on analyzing the algorithm’s behavior on typical or randomly chosen inputs rather than worst-case inputs. </st><st c="13461">This provides a more realistic measure of the algorithm’s </st><span><st c="13519">practical performance.</st></span></li>
				<li class="calibre13"><st c="13541">We use realistic input models that reflect the expected usage scenarios of the algorithm. </st><st c="13632">For example, in sorting, assume inputs are randomly permuted rather than always sorted or </st><span><st c="13722">reverse sorted.</st></span></li>
				<li class="calibre13"><st c="13737">We establish performance bounds that hold with high probability. </st><st c="13803">For example, an algorithm might run in </st><img src="image/997.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre775"/><st c="13842"/><st c="13851"> time with high probability, even if it occasionally </st><span><st c="13903">runs slower.</st></span></li>
				<li class="calibre13"><st c="13915">Random variables are employed to model the internal randomness of the algorithm. </st><st c="13997">We analyze how these variables influence the algorithm’s behavior and performance. </st><st c="14080">We also consider the independence or correlation between random variables to simplify the analysis or derive more accurate </st><span><st c="14203">performance estimates.</st></span></li>
			</ul>
			<p class="calibre3"><st c="14225">In addition to the principles discussed earlier, the analysis of randomized algorithms often involves specific techniques and models. </st><st c="14360">Random sampling is a fundamental technique used to make decisions or estimate properties of larger datasets efficiently. </st><st c="14481">Monte Carlo and Las Vegas algorithms leverage randomness in different ways. </st><st c="14557">Monte Carlo algorithms provide probabilistic guarantees and run in fixed time with some probability of error, while Las Vegas algorithms guarantee correctness but have variable running times. </st><st c="14749">Markov chains and random walks are essential models for analyzing more advanced randomized algorithms. </st><st c="14852">Markov chains help understand the behavior of systems with state transitions, while random walks are used in various network algorithms and </st><span><st c="14992">optimization problems.</st></span></p>
			<p class="calibre3"><st c="15014">The approach to</st><a id="_idIndexMarker580" class="pcalibre pcalibre1 calibre6"/><st c="15030"> analysis can be either adaptive or adversarial. </st><st c="15079">Adaptive analysis studies how algorithms respond to varying input conditions or environmental changes. </st><st c="15182">Adversarial analysis, on the other hand, considers scenarios where inputs are designed to challenge the algorithm’s performance to its limits. </st><st c="15325">It is important to note that while these principles and techniques are crucial for a comprehensive understanding of randomized algorithms, they extend beyond the scope of this book. </st><st c="15507">Therefore, we will not cover all of these principles in </st><span><st c="15563">detail here.</st></span></p>
			<p class="calibre3"><st c="15575">It is often most effective to illustrate the analysis of randomized algorithms through a few examples, demonstrating the step-by-step process in detail. </st><st c="15729">The first example is the well-known </st><em class="italic"><st c="15765">Monty Hall problem</st></em><st c="15783">. The second example is the </st><em class="italic"><st c="15811">birthday paradox</st></em><st c="15827"> and finally, we discuss the well-known </st><em class="italic"><st c="15867">hiring </st></em><span><em class="italic"><st c="15874">secretary problem</st></em></span><span><st c="15891">.</st></span></p>
			<h2 id="_idParaDest-119" class="calibre5"><a id="_idTextAnchor139" class="pcalibre pcalibre1 calibre6"/><st c="15892">Monty Hall problem</st></h2>
			<p class="calibre3"><st c="15911">The </st><strong class="bold"><st c="15916">Monty Hall problem</st></strong><st c="15934"> is a </st><a id="_idIndexMarker581" class="pcalibre pcalibre1 calibre6"/><st c="15940">classic brain teaser that illustrates the power and sometimes counterintuitive nature of probabilistic reasoning, which is a core concept in the analysis of </st><span><st c="16097">randomized algorithms.</st></span></p>
			<p class="calibre3"><st c="16119">The problem is as follows: You are presented with three doors (labeled as A, B, and C). </st><st c="16208">Behind one door is a car, and behind the other two are goats. </st><st c="16270">You pick a door (let’s say door A). </st><st c="16306">The host, who knows what is behind each door, opens another door (let’s say door B) to reveal a goat. </st><st c="16408">The host then offers you the choice to switch to the remaining closed door (door C). </st><st c="16493">Should you stick with your initial choice or switch to maximize your chances of winning </st><span><st c="16581">the car?</st></span></p>
			<p class="calibre3"><st c="16589">The counterintuitive answer is yes, you should absolutely switch. </st><st c="16656">Switching doors doubles your chances of winning the car. </st><st c="16713">At first glance, it might seem that after one door is revealed, the odds are 50/50 between the remaining two doors. </st><st c="16829">However, this is a common misconception. </st><st c="16870">The correct strategy is to always switch doors, and here </st><span><st c="16927">is why:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="16934">The probability that the car is behind door A (your initial </st><span><st c="16995">choice): </st></span><span><img src="image/1484.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1103"/><st c="17004"/></span><span><st c="17005">.</st></span></li>
				<li class="calibre13"><st c="17006">The probability that the car is behind door B or </st><span><st c="17056">C: </st></span><span><img src="image/1485.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1103"/><st c="17059"/></span><span><st c="17060">.</st></span></li>
				<li class="calibre13"><st c="17061">The host’s action of opening door B (which always reveals a goat) does not change the initial probabilities. </st><st c="17171">Instead, it provides additional information that affects the distribution of </st><span><st c="17248">these probabilities.</st></span></li>
			</ul>
			<p class="calibre3"><st c="17268">Let’s break down the </st><a id="_idIndexMarker582" class="pcalibre pcalibre1 calibre6"/><st c="17290">probabilities and consider the two possible scenarios for the location of </st><span><st c="17364">the car:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="17372">The probability of the car being behind your initial choice (door </st><span><st c="17439">A): </st></span><span><img src="image/1484.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1103"/><st c="17443"/></span><span><st c="17444">:</st></span><ul class="calibre50"><li class="calibre13"><st c="17445">If you stick with door A, you win the car with a probability </st><span><st c="17506">of </st></span><span><img src="image/1484.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1103"/><st c="17509"/></span></li><li class="calibre13"><st c="17510">If you switch to door C, you lose with a probability </st><span><st c="17563">of </st></span><span><img src="image/1484.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1103"/><st c="17566"/></span></li></ul></li>
				<li class="calibre13"><st c="17567">The probability of the car being behind one of the other doors (door B or door </st><span><st c="17646">C): </st></span><span><img src="image/1485.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1103"/><st c="17650"/></span><span><st c="17651">:</st></span><ul class="calibre50"><li class="calibre13"><st c="17652">Since the host reveals a goat behind door B, the car must be behind door C if it is not behind </st><span><st c="17747">door A</st></span></li><li class="calibre13"><st c="17753">If you switch to door C, you win the car with a probability </st><span><st c="17814">of </st></span><span><img src="image/1485.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1103"/><st c="17817"/></span></li></ul></li>
			</ul>
			<p class="calibre3"><st c="17818">Then, by switching doors, you effectively bet on the probability that your initial choice was wrong, which is </st><img src="image/1491.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1104"/><st c="17928"/><st c="17932">. Therefore, switching doors increases your chances of winning the car from </st><img src="image/1492.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1104"/><st c="18008"/><st c="18010"> to  </st><img src="image/1491.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1105"/><st c="18013"/><st c="18017">. This counterintuitive result is a classic example of how human intuition can often be misleading in</st><a id="_idIndexMarker583" class="pcalibre pcalibre1 calibre6"/><st c="18118"> probabilistic scenarios. </st><st c="18144">The Monty Hall problem highlights the importance of understanding probability and making decisions based on mathematical analysis rather than </st><span><st c="18286">gut feelings.</st></span></p>
			<h2 id="_idParaDest-120" class="calibre5"><a id="_idTextAnchor140" class="pcalibre pcalibre1 calibre6"/><st c="18299">Birthday paradox</st></h2>
			<p class="calibre3"><st c="18316">The </st><strong class="bold"><st c="18321">birthday paradox</st></strong><st c="18337">, also </st><a id="_idIndexMarker584" class="pcalibre pcalibre1 calibre6"/><st c="18344">known as the </st><strong class="bold"><st c="18357">birthday problem</st></strong><st c="18373">, is a famous probability problem that demonstrates a counterintuitive result. </st><st c="18452">It deals with the likelihood that, in a group of people, at least two individuals will share the same birthday. </st><st c="18564">The surprising aspect is how small the group needs to be for this probability to be </st><span><st c="18648">relatively high.</st></span></p>
			<p class="calibre3"><st c="18664">The problem can be stated as follows: What is the probability that, in a group of </st><img src="image/1158.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre736"/><st c="18747"/><st c="18748"> people, at least two people share the same birthday? </st><st c="18802">Assume there are 365 days in a year, and each person’s birthday is equally likely to fall on any of </st><span><st c="18902">these days.</st></span></p>
			<p class="calibre3"><st c="18913">To understand the birthday paradox, it is easier to calculate the complementary probability— the probability that no two people in the group share the same birthday—and then subtract this from 1. </st><st c="19110">Let’s break down the calculation of the complementary probability of the birthday problem </st><span><st c="19200">as follows:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="19211">The probability that the first person has a unique birthday is </st><img src="image/1495.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;365&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;365&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1106"/><st c="19275"/><st c="19281"> (since no one else has been </st><span><st c="19309">chosen yet)</st></span></li>
				<li class="calibre13"><st c="19320">The probability that the second person has a different birthday from the first </st><span><st c="19400">is </st></span><span><img src="image/1496.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;364&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;365&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1107"/><st c="19403"/></span></li>
				<li class="calibre13"><st c="19404">The probability that the third person has a different birthday from the first two </st><span><st c="19486">is </st></span><span><img src="image/1497.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;363&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;365&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1107"/><st c="19489"/></span></li>
				<li class="calibre13"><st c="19490">….</st></li>
				<li class="calibre13"><st c="19492">For </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="19497"/><st c="19546"> people, the probability </st><img src="image/1499.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;unique&lt;/mtext&gt;&lt;mtext&gt;birthday&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1108"/><st c="19570"/><st c="19589"> that all birthdays are unique is </st><span><st c="19622">as follows:</st></span><p class="calibre3"><img src="image/1500.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;unique&lt;/mtext&gt;&lt;mtext&gt;birthday&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;365&lt;/mn&gt;&lt;mn&gt;365&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;364&lt;/mn&gt;&lt;mn&gt;365&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;363&lt;/mn&gt;&lt;mn&gt;365&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;365&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;mn&gt;365&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1109"/><st c="19633"/></p><p class="calibre3"><st c="19675">Or, it is </st><span><st c="19685">as follows:</st></span></p><p class="calibre3"><img src="image/1501.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;unique&lt;/mtext&gt;&lt;mtext&gt;birthday&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∏&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mn&gt;365&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1110"/><st c="19696"/></p></li>
			</ul>
			<p class="calibre3"><st c="19738">Then, the probability </st><img src="image/1502.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;shared&lt;/mtext&gt;&lt;mtext&gt;birthday&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1111"/><st c="19760"/><st c="19779"> that at least two people share the same birthday is </st><span><st c="19831">as follows:</st></span></p>
			<p class="calibre3"><img src="image/1503.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;shared&lt;/mtext&gt;&lt;mtext&gt;birthday&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;unique&lt;/mtext&gt;&lt;mtext&gt;birthday&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1112"/><st c="19842"/></p>
			<p class="calibre3"><st c="19887">The results show that the</st><a id="_idIndexMarker585" class="pcalibre pcalibre1 calibre6"/><st c="19912"> probability of shared birthdays increases rapidly with the size of the group. </st><st c="19991">The following is a simple Python core to simulate the </st><span><st c="20045">birthday paradox:</st></span></p>
			<pre class="source-code"><st c="20062" class="calibre11">
import random
import matplotlib.pyplot as plt
def simulate_birthday_paradox(trials, n):
    shared_birthday_count = 0
    for _ in range(trials):
        birthdays = []
        for person in range(n):
            birthday = random.randint(1, 365)
            if birthday in birthdays:
                shared_birthday_count += 1
                break
            birthdays.append(birthday)
    return shared_birthday_count / trials
def main():
    trials = 10000
    results = []
    group_sizes = range(2, 367)
    for n in group_sizes:
        probability = simulate_birthday_paradox(trials, n)
        results.append(probability)
        print(f"Group size: {n}, Probability of shared birthday: {probability:.4f}")
    plt.figure(figsize=(10, 6))
    plt.plot(group_sizes, results, marker='o')
    plt.title('Birthday Paradox Simulation')
    plt.xlabel('Group Size')
    plt.ylabel('Probability of Shared Birthday')
    plt.grid(True)
    plt.show()
if __name__ == "__main__":
    main()</st></pre>			<p class="calibre3"><st c="20885">This function runs the </st><a id="_idIndexMarker586" class="pcalibre pcalibre1 calibre6"/><st c="20909">birthday paradox simulation for a given group size </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1113"/><st c="20960"/><st c="21009"> and a number of trials, which is 10,000. </st><st c="21050">It counts the number of trials where at least two people share the same birthday. </st><st c="21132">For each trial, it generates random birthdays for </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="21182"/><st c="21231"> people and checks for duplicates. </st><span><em class="italic"><st c="21265">Figure 9</st></em></span><em class="italic"><st c="21273">.3</st></em><st c="21275"> illustrates the results of </st><span><st c="21303">the simulation.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1530" class="img---figure">
					<img src="image/B22248_09_3.jpg" alt="Figure 9.3: The simulation demonstrates how quickly the probability of sharing a birthday increases with the size of the group" class="calibre144"/><st c="21318"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="21445">Figure 9.3: The simulation demonstrates how quickly the probability of sharing a birthday increases with the size of the group</st></p>
			<p class="calibre3"><st c="21571">The rapid increase in the probability of shared birthdays is counterintuitive because our instinct might suggest that a much larger group would be needed for a high probability of shared birthdays. </st><st c="21770">This can be observed in </st><span><em class="italic"><st c="21794">Figure 9</st></em></span><span><em class="italic"><st c="21802">.3</st></em></span><span><st c="21804">.</st></span></p>
			<p class="calibre3"><st c="21805">The birthday paradox </st><a id="_idIndexMarker587" class="pcalibre pcalibre1 calibre6"/><st c="21827">illustrates how human intuition can often misjudge probabilities in scenarios involving combinations and large numbers. </st><st c="21947">It serves as a valuable lesson in probability theory and demonstrates the importance of mathematical calculation in understanding seemingly simple problems. </st><st c="22104">The paradox also has practical applications, such as in cryptography, where the concept of hash collisions is analogous to the </st><span><st c="22231">birthday problem.</st></span></p>
			<h2 id="_idParaDest-121" class="calibre5"><a id="_idTextAnchor141" class="pcalibre pcalibre1 calibre6"/><st c="22248">Hiring secretary problem</st></h2>
			<p class="calibre3"><st c="22273">The </st><strong class="bold"><st c="22278">hiring secretary problem</st></strong><st c="22302">, also</st><a id="_idIndexMarker588" class="pcalibre pcalibre1 calibre6"/><st c="22308"> kn</st><a id="_idTextAnchor142" class="pcalibre pcalibre1 calibre6"/><st c="22311">own as the </st><strong class="bold"><st c="22323">secretary problem</st></strong><st c="22340"> or the </st><strong class="bold"><st c="22348">best choice problem</st></strong><st c="22367">, is a famous problem in optimal stopping theory. </st><st c="22417">It describes a scenario where an employer wants to hire the best secretary out of </st><img src="image/23.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre35"/><st c="22499"/><st c="22500"> applicants who are interviewed sequentially. </st><st c="22546">The employer must decide whether to hire a candidate immediately after the interview, without the possibility of returning to previous candidates. </st><st c="22693">The goal is to maximize the probability of selecting the </st><span><st c="22750">best candidate.</st></span></p>
			<p class="calibre3"><st c="22765">The following are given in </st><span><st c="22793">this problem:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="22806">Sequential interviews</st></strong><st c="22828">: </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="22831"/><st c="22880"> candidates </st><a id="_idIndexMarker589" class="pcalibre pcalibre1 calibre6"/><st c="22891">are interviewed one by one in </st><span><st c="22921">random order.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="22934">Immediate decision</st></strong><st c="22953">: After </st><a id="_idIndexMarker590" class="pcalibre pcalibre1 calibre6"/><st c="22962">each interview, the employer must decide whether to hire that candidate. </st><st c="23035">If rejected, the candidate cannot </st><span><st c="23069">be reconsidered.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="23085">Objective</st></strong><st c="23095">: The </st><a id="_idIndexMarker591" class="pcalibre pcalibre1 calibre6"/><st c="23102">goal is to maximize the probability of selecting the </st><span><st c="23155">best candidate.</st></span></li>
			</ul>
			<p class="calibre3"><st c="23170">The optimal strategy for this problem is surprisingly elegant and counterintuitive. </st><st c="23255">It involves </st><span><st c="23267">two phases:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="23278">Observation phase</st></strong><st c="23296">: Reject the </st><a id="_idIndexMarker592" class="pcalibre pcalibre1 calibre6"/><st c="23310">first </st><img src="image/1508.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1114"/><st c="23316"/><st c="23317"> candidates outright. </st><st c="23339">This phase is purely for observation to get a sense of the quality of candidates. </st><st c="23421">The first </st><img src="image/1508.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1114"/><st c="23431"/><st c="23432"> candidate is also called a </st><span><st c="23460">training sample.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="23476">Selection phase</st></strong><st c="23492">: From </st><a id="_idIndexMarker593" class="pcalibre pcalibre1 calibre6"/><st c="23500">the </st><img src="image/1510.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" class="calibre1115"/><st c="23504"/><st c="23505"> candidate onward, hire the first candidate who is better than all the previously </st><span><st c="23587">interviewed candidates.</st></span></li>
			</ul>
			<p class="calibre3"><st c="23610">One question that might arise is this: What if none of the candidates after the first </st><img src="image/1511.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1116"/><st c="23697"/><st c="23698"> are better than those initially rejected? </st><st c="23741">In this unfortunate scenario, the only option is to hire the last candidate. </st><st c="23818">This outcome increases the overall cost of interviewing and heightens the risk of hiring an </st><span><st c="23910">unsuitable candidate.</st></span></p>
			<p class="calibre3"><st c="23931">The value of </st><img src="image/1512.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="23945"/><st c="23946"> that maximizes the probability of selecting the best candidate can be approximated by </st><img src="image/1513.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1117"/><st c="24033"/><st c="24034">, where </st><img src="image/1514.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1118"/><st c="24042"/><st c="24043"> is the base of the natural logarithm (approximately </st><img src="image/1515.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;2.718&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1119"/><st c="24096"/><st c="24097">). </st><st c="24100">For large </st><img src="image/23.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre35"/><st c="24110"/><st c="24111">, this simplifies to roughly </st><img src="image/1517.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;37&lt;/mml:mn&gt;&lt;mml:mi&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1120"/><st c="24140"/><st c="24145"> of the total number </st><span><st c="24165">of candidates.</st></span></p>
			<p class="calibre3"><st c="24179">The probability </st><img src="image/1518.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1121"/><st c="24196"/><st c="24202"> of selecting the best candidate using the optimal stopping rule is given by </st><span><st c="24278">the following:</st></span></p>
			<p class="calibre3"><img src="image/1519.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mspace width=&quot;0em&quot; /&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1122"/><st c="24292"/></p>
			<p class="calibre3"><st c="24294">We know </st><span><st c="24302">that </st></span><span><img src="image/1520.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1123"/><st c="24307"/></span><span><st c="24312">.</st></span></p>
			<p class="calibre3"><st c="24313">The following Python </st><a id="_idIndexMarker594" class="pcalibre pcalibre1 calibre6"/><st c="24335">code estimates </st><img src="image/1521.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" class="calibre1124"/><st c="24350"/><st c="24351"> for various values of </st><img src="image/1522.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1125"/><st c="24374"/><st c="24375"> and also estimates the ratio of </st><img src="image/1523.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1126"/><st c="24408"/><st c="24409"> that maximizes the </st><span><st c="24429">probability </st></span><span><img src="image/1524.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" class="calibre1127"/><st c="24441"/></span><span><st c="24442">:</st></span></p>
			<pre class="source-code"><st c="24443" class="calibre11">
import numpy as np
import matplotlib.pyplot as plt
def calculate_p_n(n, k):
    if k == 1:
        return 1 / n
    sum_term = sum(1 / (j - 1) for j in range(k, n + 1))
    return (k - 1) / n * sum_term
def find_optimal_k(n):
    probabilities = [calculate_p_n(n, k) for k in range(1, n + 1)]
    optimal_k = np.argmax(probabilities) + 1
    return optimal_k, probabilities
n_values = np.arange(10, 501, 1)  # Smoother plot with more points
optimal_k_ratios = []
for n in n_values:
    optimal_k, probabilities = find_optimal_k(n)
    optimal_k_ratios.append(optimal_k / n)
plt.figure(figsize=(10, 6))
plt.plot(n_values, optimal_k_ratios, marker='o', linestyle='-', markersize=4, label='Optimal k/n Ratio')
plt.axhline(1/np.e, color='r', linestyle='--', label='1/e (approximately 0.3679)')
plt.title('Optimal k/n Ratio for Different Values of n')
plt.xlabel('n')
plt.ylabel('Optimal k/n Ratio')
plt.legend()
plt.grid(True)
plt.show()</st></pre>			<p class="calibre3"><st c="25336">Let’s briefly explain the code. </st><st c="25369">The </st><strong class="source-inline"><st c="25373">calculate_p_n</st></strong><st c="25386"> function calculates the probability </st><img src="image/1525.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1128"/><st c="25423"/><st c="25429"> for a given </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="25441"/><st c="25490"> and </st><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="25494"/><st c="25495"> using the formula provided. </st><st c="25524">The </st><strong class="source-inline"><st c="25528">find_optimal_k</st></strong><st c="25542"> function computes </st><img src="image/1528.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1129"/><st c="25561"/><st c="25567"> for all </st><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="25575"/><st c="25576"> from 1 to </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="25587"/><st c="25636"> and finds the value of </st><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="25659"/><st c="25660"> that maximizes </st><img src="image/1524.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" class="calibre1127"/><st c="25676"/><st c="25677">. The parameters are </st><span><st c="25698">as follows:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="source-inline1"><st c="25709">n_values</st></strong><st c="25718">: Different values of </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="25741"/> <span><st c="25790">to analyze.</st></span></li>
				<li class="calibre13"><strong class="source-inline1"><st c="25801">optimal_k_ratios</st></strong><st c="25818">: This stores the ratio </st><img src="image/1534.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1130"/><st c="25843"/><st c="25844"> that maximizes </st><img src="image/1524.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" class="calibre1127"/><st c="25860"/><st c="25861"> for </st><span><st c="25866">each </st></span><span><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="25871"/></span><span><st c="25920">.</st></span></li>
				<li class="calibre13"><st c="25921">The first plot (</st><span><em class="italic"><st c="25938">Figure 9</st></em></span><em class="italic"><st c="25947">.4</st></em><st c="25949">) shows </st><img src="image/1537.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1131"/><st c="25958"/><st c="25964"> versus </st><img src="image/1538.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1132"/><st c="25971"/><st c="25972"> for different values of </st><img src="image/1539.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1133"/><st c="25997"/><st c="25998">. The second plot (</st><span><em class="italic"><st c="26017">Figure 9</st></em></span><em class="italic"><st c="26026">.5</st></em><st c="26028">) shows the ratio of </st><img src="image/1534.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1130"/><st c="26050"/><st c="26051"> that maximizes </st><img src="image/1524.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" class="calibre1127"/><st c="26067"/><st c="26068"> for different values of </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="26093"/><st c="26142">. It also includes a horizontal line at </st><img src="image/1543.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1134"/><st c="26182"/> <span><st c="26183">for reference.</st></span></li>
			</ul>
			<p class="calibre3"><span><em class="italic"><st c="26197">Figure 9</st></em></span><em class="italic"><st c="26206">.4</st></em><st c="26208"> shows how the probability </st><img src="image/1518.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1135"/><st c="26235"/><st c="26241"> varies with </st><img src="image/441.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre904"/><st c="26253"/><st c="26254"> for different values of </st><img src="image/1546.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1136"/><st c="26279"/><st c="26280"> and </st><span><em class="italic"><st c="26285">Figure 9</st></em></span><em class="italic"><st c="26293">.5</st></em><st c="26295"> demonstrates that the ratio </st><img src="image/1534.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1130"/><st c="26324"/><st c="26325"> that maximizes this probability tends to approximate </st><img src="image/1548.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.37&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1137"/><st c="26379"/><st c="26380"> or 37% of the total number of candidates, validating the </st><span><st c="26438">theoretical approximation.</st></span></p>
			<p class="calibre3"><st c="26464">The logic behind this </st><a id="_idIndexMarker595" class="pcalibre pcalibre1 calibre6"/><st c="26487">strategy is based on the trade-off between gathering enough information to make an informed decision and the risk of missing out on the best candidate by waiting too long. </st><st c="26659">By rejecting the first </st><img src="image/1549.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1138"/><st c="26682"/><st c="26683"> candidates, the employer sets a benchmark for evaluating the subsequent candidates. </st><st c="26768">The probability of selecting the best candidate using this strategy is approximately </st><img src="image/1550.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1139"/><st c="26853"/><st c="26854">, or about </st><img src="image/1517.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;37&lt;/mml:mn&gt;&lt;mml:mi&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1120"/><st c="26865"/><st c="26870"> (see </st><span><em class="italic"><st c="26875">Figure 9</st></em></span><em class="italic"><st c="26883">.4</st></em><st c="26885">). </st><st c="26889">This means that, on average, the employer has a 37% chance of selecting the best candidate by following the </st><span><st c="26997">optimal strategy.</st></span></p>
			<h3 class="calibre8"><st c="27014">Example 9.1</st></h3>
			<p class="calibre3"><st c="27026">Using the optimal </st><a id="_idIndexMarker596" class="pcalibre pcalibre1 calibre6"/><st c="27045">stopping theory, suggest a strategy to hire an individual among </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="27109"/> <span><st c="27158">candidates.</st></span></p>
			<p class="calibre3"><st c="27169">Consider </st><img src="image/1553.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1140"/><st c="27179"/><st c="27180"> candidates. </st><st c="27193">Using the optimal </st><span><st c="27211">stopping rule:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="27225">Observation phase</st></strong><st c="27243">: Reject the first </st><img src="image/1554.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mn&gt;3.7&lt;/mn&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1141"/><st c="27263"/> <span><st c="27276">candidates.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="27287">Selection phase</st></strong><st c="27303">: From the fifth candidate onward, hire the first one who is better than all </st><span><st c="27381">previous candidates.</st></span></li>
			</ul>
			<p class="calibre3"><st c="27401">If the best candidate is among the first four, they will be missed. </st><st c="27470">If the best candidate is in the fifth position or later, there is a good chance they will be selected because they are likely to be better than those in the </st><span><st c="27627">observation phase.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1580" class="img---figure">
					<img src="image/B22248_09_4.jpg" alt="Figure 9.4: The probability ​​P​ n​​​(k)​​ versus ​k​ for a various number of candidates (​n​)" class="calibre144"/><st c="27645"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="27838">Figure 9.4: The probability </st><img src="image/1555.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1142"/><st c="27866"/><st c="27867"> versus </st><img src="image/1556.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1143"/><st c="27875"/><st c="27876"> for a various number of candidates (</st><img src="image/298.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre259"/><st c="27913"/><st c="27915">)</st></p>
			<div class="calibre2">
				<div id="_idContainer1584" class="img---figure">
					<img src="image/B22248_09_5.jpg" alt="Figure 9.5: Optimal k/n ratio for various number of candidates (n). As n increases, the ​k / n​ ratio converges the golden ratio ​1 / e = 0.37​ or ​37%​ of total number of candidates." class="calibre144"/><st c="27916"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="28087">Figure 9.5: Optimal k/n ratio for various number of candidates (n). </st><st c="28155">As n increases, the </st><img src="image/1558.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1144"/><st c="28175"/><st c="28176"> ratio converges the golden ratio </st><img src="image/1559.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;e&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.37&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1145"/><st c="28210"/><st c="28211"> or </st><img src="image/1560.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;37&lt;/mml:mn&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1146"/><st c="28215"/><st c="28216"> of total number of candidates.</st></p>
			<p class="calibre3"><st c="28247">The preceding</st><a id="_idIndexMarker597" class="pcalibre pcalibre1 calibre6"/><st c="28261"> hiring problem is a classic example of optimal stopping theory, demonstrating the application of probabilistic decision-making in real-time scenarios. </st><st c="28413">It has several interesting implications </st><span><st c="28453">and extensions:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="28468">Unknown number of candidates</st></strong><st c="28497">: If the number of candidates </st><img src="image/1561.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre147"/><st c="28528"/><st c="28529"> is unknown, adaptive strategies can </st><span><st c="28566">be developed</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="28578">Multiple selections</st></strong><st c="28598">: Variants where more than one candidate can be selected, adjusting the </st><span><st c="28671">strategy accordingly</st></span></li>
			</ul>
			<p class="calibre3"><st c="28691">This theory has many practical applications. </st><st c="28737">While the model is simplified, it provides insights into decision-making processes in hiring and other sequential selection scenarios (see next section). </st><st c="28891">Similar strategies can be applied in online auctions, where bidders must decide when to stop bidding based on observed prices. </st><st c="29018">The theory has some behavioral insights too. </st><st c="29063">The problem highlights how optimal strategies often defy intuition, requiring a rigorous mathematical approach to identify the best course </st><span><st c="29202">of action.</st></span></p>
			<p class="calibre3"><st c="29212">The hiring </st><a id="_idIndexMarker598" class="pcalibre pcalibre1 calibre6"/><st c="29224">secretary problem elegantly combines elements of probability, decision theory, and optimal stopping. </st><st c="29325">It provides a clear example of how structured strategies can significantly improve decision-making in scenarios characterized by uncertainty and sequential choices. </st><st c="29490">By understanding the principles behind this problem, one gains valuable insights into the broader field of optimal stopping theory and </st><span><st c="29625">its applications.</st></span></p>
			<h1 id="_idParaDest-122" class="calibre5"><a id="_idTextAnchor143" class="pcalibre pcalibre1 calibre6"/><st c="29642">Case studies</st></h1>
			<p class="calibre3"><st c="29655">At the beginning of this chapter, we introduced three problems faced by Tom and Fang. </st><st c="29742">These problems involve randomized algorithms and probabilistic reasoning and can be solved using the optimal stopping theory. </st><st c="29868">Essentially, these problems focus on determining when to stop searching rather than what to search for. </st><st c="29972">As case studies, we will analyze and solve these problems in detail, applying the concepts we have learned in </st><span><st c="30082">this chapter.</st></span></p>
			<h2 id="_idParaDest-123" class="calibre5"><a id="_idTextAnchor144" class="pcalibre pcalibre1 calibre6"/><st c="30095">Optimal selection in an online dating app</st></h2>
			<p class="calibre3"><st c="30137">A new </st><a id="_idIndexMarker599" class="pcalibre pcalibre1 calibre6"/><st c="30144">online dating app, </st><em class="italic"><st c="30163">Matcher</st></em><st c="30170">, has</st><a id="_idIndexMarker600" class="pcalibre pcalibre1 calibre6"/><st c="30175"> been designed to help users find their best possible partners. </st><st c="30239">The app operates similarly to a game, where users are presented with one potential match at a time, selected randomly from a pool of </st><img src="image/1562.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1147"/><st c="30372"/><st c="30373"> potential matches (the total number of matches is unknown to the users). </st><st c="30447">Tom, our user, has a maximum of </st><img src="image/1065.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre672"/><st c="30479"/><st c="30480"> likes available (where</st><img src="image/1564.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;≪&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1148"/><st c="30503"/><st c="30505">). </st><st c="30508">His goal is to maximize his chances of finding the best possible matches using his </st><span><st c="30591">limited likes.</st></span></p>
			<p class="calibre3"><st c="30605">When Tom opens the </st><em class="italic"><st c="30625">Matcher</st></em><st c="30632"> app, he can either </st><em class="italic"><st c="30652">like</st></em><st c="30656"> (swipe right) or </st><em class="italic"><st c="30674">dislike</st></em><st c="30681"> (swipe left) each profile. </st><st c="30709">Once a decision is made, it is final, and he cannot change his mind. </st><st c="30778">Tom needs to carefully decide when to stop browsing and start using his likes to maximize his chances of selecting the best available matches. </st><st c="30921">We should note </st><span><st c="30936">the following:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="30950">Tom must decide in real time whether to </st><em class="italic"><st c="30991">like</st></em><st c="30995"> or </st><em class="italic"><st c="30999">dislike</st></em><st c="31006"> each profile as they are </st><span><st c="31032">presented sequentially</st></span></li>
				<li class="calibre13"><st c="31054">Once Tom has </st><em class="italic"><st c="31068">liked</st></em> <img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="31073"/><st c="31123"> profiles, the app will no longer show him any </st><span><st c="31169">more profiles</st></span></li>
				<li class="calibre13"><st c="31182">The objective is to maximize the probability of selecting the best matches within the constraints of his </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="31288"/> <span><em class="italic"><st c="31337">likes</st></em></span></li>
			</ul>
			<p class="calibre3"><st c="31342">There are </st><span><st c="31353">some constraints:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="31370">Tom cannot revisit </st><span><st c="31390">previous profiles</st></span></li>
				<li class="calibre13"><em class="italic"><st c="31407">Liking</st></em><st c="31414"> a profile does not guarantee a match; it also requires the other person to like Tom’s </st><span><st c="31501">profile back</st></span></li>
			</ul>
			<p class="calibre3"><st c="31513">The optimal stopping </st><a id="_idIndexMarker601" class="pcalibre pcalibre1 calibre6"/><st c="31535">theory provides a strategy to maximize the chances of selecting the best option from a sequence of choices. </st><st c="31643">The strategy involves two phases: an observation phase and a </st><span><st c="31704">selection phase:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="31720">Observation phase</st></strong><st c="31738">: Tom should observe and reject the first </st><img src="image/1174.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1149"/><st c="31781"/><st c="31782"> profiles to gather information about the pool of candidates. </st><st c="31844">The optimal choice of </st><img src="image/1568.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1150"/><st c="31866"/><st c="31867"> in classical secretary problems is approximately </st><img src="image/1569.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1151"/><st c="31917"/><st c="31918">. However, since </st><img src="image/1562.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1152"/><st c="31935"/><st c="31936"> is unknown, Tom can use an adaptive strategy to </st><span><st c="31985">estimate </st></span><span><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="31994"/></span><span><st c="31995">.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="31996">Selection phase</st></strong><st c="32012">: After the observation phase, Tom should start liking the next profile that is better than all the profiles he has seen so far during the observation phase. </st><st c="32171">If Tom does not find a better profile, he will like the last few profiles he encounters, ensuring he uses all </st><img src="image/945.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre736"/><st c="32281"/> <span><st c="32282">likes.</st></span></li>
			</ul>
			<p class="calibre3"><st c="32288">In the absence of knowledge about the total number of profiles (</st><img src="image/1469.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1153"/><st c="32353"/><st c="32355">), one practical approach is to assume </st><img src="image/1562.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1154"/><st c="32394"/><st c="32395"> as a large number, such as </st><img src="image/1575.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1000&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1155"/><st c="32423"/><st c="32424">. Tom can then use a strategy based on the optimal stopping theory. </st><st c="32492">However, this approach has significant drawbacks when implemented in a </st><span><st c="32563">real-world scenario.</st></span></p>
			<p class="calibre3"><st c="32583">Tom assumes </st><img src="image/1562.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1156"/><st c="32596"/><st c="32597"> is large, for </st><span><st c="32612">example, </st></span><span><img src="image/1577.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1000&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1157"/><st c="32621"/></span><span><st c="32622">:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="32623">Observation phase</st></strong><st c="32640">: Reject the first </st><img src="image/1578.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;37&lt;/mml:mn&gt;&lt;mml:mi&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1158"/><st c="32660"/><st c="32664"> of the profiles. </st><st c="32681">For </st><img src="image/1579.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1000&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1159"/><st c="32685"/><st c="32686">, this means rejecting the first </st><img src="image/1580.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;370&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre993"/><st c="32719"/> <span><st c="32720">profiles.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="32729">Selection phase</st></strong><st c="32745">: Start liking profiles from the </st><img src="image/1581.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;371&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" class="calibre1160"/><st c="32779"/><st c="32780"> profile onward, only if they are better than all the profiles seen in the </st><span><st c="32855">observation phase.</st></span></li>
			</ul>
			<p class="calibre3"><st c="32873">These are the drawbacks of the proposed strategy </st><span><st c="32923">are twofold:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="32935">Human memory limitation</st></strong><st c="32959">: It is impractical for Tom to remember and compare </st><img src="image/1582.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;370&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1161"/><st c="33012"/><st c="33013"> profiles with every new profile he sees. </st><st c="33055">This requires an immense cognitive load and is not feasible for </st><span><st c="33119">most individuals.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="33136">Potential bias in ordered profiles</st></strong><st c="33171">: If the profiles are ordered in any way (e.g., by the number of likes they have received), this strategy can fail. </st><st c="33288">If the best profiles are at the beginning or end, the strategy won’t work effectively because it relies on</st><a id="_idIndexMarker602" class="pcalibre pcalibre1 calibre6"/><st c="33394"> the randomness of </st><span><st c="33413">profile order.</st></span></li>
			</ul>
			<p class="calibre3"><st c="33427">Given the impracticality of the preceding strategy, we can adopt a more practical approach that mitigates these issues. </st><st c="33548">Instead of using a fixed </st><img src="image/1583.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;37&lt;/mml:mn&gt;&lt;mml:mi&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1162"/><st c="33573"/><st c="33577"> of a large assumed </st><img src="image/1562.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1152"/><st c="33596"/><st c="33597">, reduce the observation phase to a manageable number of profiles based on Tom’s total number of likes (</st><img src="image/23.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1163"/><st c="33701"/><st c="33703">). </st><st c="33706">For example, use a smaller fraction such as </st><img src="image/547.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre437"/><st c="33750"/><st c="33751"> for the observation phase. </st><st c="33779">The other benefit of this practical approach is that it uses a relative comparison strategy where Tom only needs to remember the best profile seen so far rather than </st><span><st c="33945">all profiles.</st></span></p>
			<p class="calibre3"><st c="33958">Let’s explore the proposed practical approach. </st><st c="34006">Tom can choose to observe the first </st><img src="image/1174.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre312"/><st c="34042"/><st c="34043"> profiles where </st><img src="image/1588.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;≈&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1164"/><st c="34059"/><st c="34062">. This is a heuristic that balances exploration and exploitation in the absence of information </st><span><st c="34157">about </st></span><span><img src="image/1562.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1165"/><st c="34163"/></span><span><st c="34164">.</st></span></p>
			<p class="calibre3"><st c="34165">Let’s assume Tom has 10 likes available. </st><st c="34207">First, we </st><span><st c="34217">choose k:</st></span></p>
			<p class="calibre3"><img src="image/1590.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;5&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1166"/><st c="34226"/></p>
			<p class="calibre3"><st c="34228">Tom observes and rejects the first five profiles. </st><st c="34278">From the  sixth profile onwa</st><a id="_idTextAnchor145" class="pcalibre pcalibre1 calibre6"/><st c="34305">rd, Tom likes the next profile that is better than any of the first five profiles he observed. </st><st c="34401">If none of the subsequent profiles are better, he uses his likes on the last profiles </st><span><st c="34487">he sees.</st></span></p>
			<p class="calibre3"><st c="34495">By using this strategy, Tom maximizes his chances of finding high-quality matches within the constraints of his </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="34608"/><st c="34657"> likes. </st><st c="34664">The heuristic approach balances the need to gather information and the need to make timely decisions without knowing the total number </st><span><st c="34798">of candidates.</st></span></p>
			<p class="calibre3"><st c="34812">The revised optimal</st><a id="_idIndexMarker603" class="pcalibre pcalibre1 calibre6"/><st c="34832"> stopping strategy for Tom on the </st><em class="italic"><st c="34866">Matcher</st></em><st c="34873"> app</st><a id="_idIndexMarker604" class="pcalibre pcalibre1 calibre6"/><st c="34877"> involves using a fraction of his likes for the observation phase and then applying the gathered information to make decisions in the selection phase. </st><st c="35028">This method provides a practical solution for sequential decision-making under uncertainty, ensuring Tom uses his likes effectively to maximize his chances of finding the </st><span><st c="35199">best matches.</st></span></p>
			<h2 id="_idParaDest-124" class="calibre5"><a id="_idTextAnchor146" class="pcalibre pcalibre1 calibre6"/><st c="35212">Finding the closest parking spot</st></h2>
			<p class="calibre3"><st c="35245">Fang is driving to her friend’s </st><a id="_idIndexMarker605" class="pcalibre pcalibre1 calibre6"/><st c="35278">house on a busy one-way street with </st><img src="image/48.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre64"/><st c="35314"/><st c="35363"> parking spots, where parking is only allowed on one side of the street. </st><st c="35435">Based on past experience, about </st><img src="image/1593.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;mml:mi&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1120"/><st c="35467"/><st c="35471"> of the parking spots are typically available at any given time. </st><st c="35535">Fang can only see one spot at a time as she passes by and cannot see the spots ahead. </st><st c="35621">The goal is to determine the optimal moment for her to take an available parking spot using the optimal stopping theory. </st><span><em class="italic"><st c="35742">Figure 9</st></em></span><em class="italic"><st c="35750">.6</st></em><st c="35752"> illustrates this problem. </st><st c="35779">In the figure, the left side of the street shows where cars can park, with some available spots highlighted. </st><st c="35888">The right side of the street is a </st><span><st c="35922">no-parking zone.</st></span></p>
			<p class="calibre3"><st c="35938">The optimal stopping theory helps Fang decide when to stop searching and take an available parking spot by balancing the exploration of spots and the exploitation of the best spot found </st><span><st c="36125">so far.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1621" class="img---figure">
					<img src="image/B22248_09_6.jpg" alt="Figure 9.6: Illustration of Fang’s parking problem" class="calibre144"/><st c="36132"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="36145">Figure 9.6: Illustration of Fang’s parking problem</st></p>
			<p class="calibre3"><st c="36195">In both the hiring and dating app problems, there were implicit and subjective criteria to rank the candidates. </st><st c="36308">In contrast, the parking problem has an explicit criterion: the distance from the parking spot to Fang’s friend’s house. </st><st c="36429">Therefore, our strategy highly depends on the location</st><a id="_idIndexMarker606" class="pcalibre pcalibre1 calibre6"/><st c="36483"> of the destination. </st><st c="36504">We can identify </st><span><st c="36520">three scenarios:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="36536">Destination at the beginning of the street</st></strong><st c="36579">: This is the easiest case because Fang should choose the first available parking spot she encounters. </st><st c="36683">There is no need to apply the optimal stopping theory here, as this represents the </st><span><st c="36766">best-case scenario.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="36785">Destination at the end of the street</st></strong><st c="36822">: This is the worst-case scenario. </st><st c="36858">Fang needs to find the closest available parking spot, so she should reject as many spots as possible to maximize her chances of finding a spot near the end. </st><st c="37016">The optimal stopping theory is particularly useful in </st><span><st c="37070">this situation.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="37085">Destination in the middle of the street</st></strong><st c="37125">: This represents an average-case scenario, assuming the destination is exactly in the middle of the street. </st><st c="37235">Here, the optimal stopping theory is also applicable to help Fang decide when to stop and take an available parking spot. </st><st c="37357">We solve the problem for </st><span><st c="37382">this case.</st></span></li>
			</ul>
			<p class="calibre3"><st c="37392">The average-case scenario can be approached in </st><span><st c="37440">two parts:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="37450">Before reaching the destination</st></strong><st c="37482">: This part is similar to the worst-case scenario. </st><st c="37534">Fang will try to reject as many spots as possible using the optimal stopping theory. </st><st c="37619">She should reject the first </st><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="37647"/><st c="37648"> spots and then select the </st><img src="image/1595.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" class="calibre1167"/><st c="37675"/><st c="37676"> spot that </st><span><st c="37687">is available.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="37700">After passing the destination</st></strong><st c="37730">: If Fang cannot find any available spot before reaching her destination, the strategy changes. </st><st c="37827">At this point, the problem turns into the best-case scenario. </st><st c="37889">Fang should park at the very first available spot she encounters after passing </st><span><st c="37968">the destination.</st></span></li>
			</ul>
			<p class="calibre3"><st c="37984">We can solve this problem for the average-case scenario step by step (hereafter, the destination is referred to as </st><span><st c="38100">the midpoint):</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="38114">Determine </st></strong><strong class="bold"><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="38125"/></strong><st c="38126">: For the optimal stopping strategy, we calculate </st><img src="image/1597.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;≈&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt;" class="calibre1168"/><st c="38176"/><st c="38179">. However, given that only about </st><img src="image/1598.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;mml:mi&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1169"/><st c="38212"/><st c="38215"> of all parking spots are typically available at any time, we need to adjust our calculations accordingly. </st><st c="38321">Fang can estimate the total number of cars that can be parked on the street by considering the length of the street divided by the average length of a sedan car. </st><st c="38483">Since her destination is in the middle of the street, we multiply the availability by </st><img src="image/824.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre652"/><st c="38569"/><st c="38570">. If her destination were, for example, in the first third of the street, this coefficient would be </st><img src="image/1600.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;0.33&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1170"/><st c="38670"/><st c="38671">. Thus, we adjust </st><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre345"/><st c="38689"/> <span><st c="38690">as follows:</st></span><p class="calibre3"><img src="image/1602.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;100&lt;/mn&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;54.3&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1171"/><st c="38701"/></p></li>
			</ul>
			<p class="calibre3"><st c="38703">The following represents the </st><a id="_idIndexMarker607" class="pcalibre pcalibre1 calibre6"/><st c="38732">number of spots Fang will pass before she starts considering </st><span><st c="38793">parking seriously:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="38811">Before the midpoint</st></strong><st c="38831">: Fang should drive past the first </st><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1172"/><st c="38867"/><st c="38868"> spots without parking. </st><st c="38892">After passing </st><img src="image/1174.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1173"/><st c="38906"/><st c="38907"> spots, Fang will then park in the next available spot that is better than any of the spots she has seen </st><span><st c="39012">so far.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="39019">After the midpoint</st></strong><st c="39038">: If Fang has not found a suitable spot by the time she reaches the midpoint, she will park at the very first available spot </st><span><st c="39164">she encounters.</st></span></li>
			</ul>
			<p class="calibre3"><st c="39179">This approach divides the problem into manageable parts and applies the optimal stopping theory effectively within each part. </st><st c="39306">Before the midpoint, by rejecting the first </st><img src="image/422.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1174"/><st c="39350"/><st c="39351"> spots, Fang gathers enough information to make an informed decision based on the quality of the spots. </st><st c="39455">This strategy maximizes her chances of finding a better spot close to her destination. </st><st c="39542">However, after the midpoint, we switch to the best-case scenario approach, ensuring that Fang minimizes her walking distance to her friend’s house if she has not found a spot before </st><span><st c="39724">the midpoint.</st></span></p>
			<h1 id="_idParaDest-125" class="calibre5"><a id="_idTextAnchor147" class="pcalibre pcalibre1 calibre6"/><st c="39737">Summary</st></h1>
			<p class="calibre3"><st c="39745">In this chapter, we explored various problems that involved making optimal decisions under uncertainty using the optimal stopping theorem and randomized algorithms. </st><st c="39911">We examined scenarios such as the hiring problem, the </st><em class="italic"><st c="39965">Matcher</st></em><st c="39972"> dating app, and Fang’s parking problem, each requiring a strategic balance between gathering information and making timely decisions. </st><st c="40107">Through these examples, we illustrated how the optimal stopping theorem provides a structured approach to maximize the chances of selecting the best option by setting appropriate observation phases and selection criteria. </st><st c="40329">This chapter demonstrated the power of probabilistic reasoning and optimal stopping rules in practical decision-making scenarios. </st><st c="40459">In the next chapter, we will explore dynamic programming, a powerful technique for solving complex problems by breaking them down into </st><span><st c="40594">simpler subproblems.</st></span></p>
			<h1 id="_idParaDest-126" class="calibre5"><a id="_idTextAnchor148" class="pcalibre pcalibre1 calibre6"/><st c="40614">References and further reading</st></h1>
			<ul class="calibre14">
				<li class="calibre13"><em class="italic"><st c="40645">Introduction to Algorithms</st></em><st c="40672">. By Thomas H. </st><st c="40687">Cormen, Charles E. </st><st c="40706">Leiserson, Ronald L. </st><st c="40727">Rivest, and Clifford Stein. </st><st c="40755">Fourth Edition. </st><st c="40771">MIT </st><span><st c="40775">Press. </st><st c="40782">2022:</st></span><ul class="calibre50"><li class="calibre13"><em class="italic"><st c="40787">Chapter 5</st></em><st c="40797">, </st><em class="italic"><st c="40799">Probabilistic Analysis and </st></em><span><em class="italic"><st c="40826">Randomized Algorithms</st></em></span></li></ul></li>
				<li class="calibre13"><em class="italic"><st c="40847">Algorithms to Live By: The Computer Science of Human Decisions</st></em><st c="40910">. By Brian Christian and Tom Griffiths. </st><st c="40950">Henry Holt and </st><span><st c="40965">Co. </st><st c="40969">2016.</st></span></li>
				<li class="calibre13"><em class="italic"><st c="40974">Who Solved the Secretary Problem</st></em><st c="41007">. By T. </st><st c="41015">S. </st><st c="41018">Ferguson. </st><em class="italic"><st c="41028">Statist. </st><st c="41037">Sci</st></em><st c="41040">.4 (</st><span><st c="41044">3): 282–89.</st></span></li>
				<li class="calibre13"><em class="italic"><st c="41056">Monty Hall </st></em><span><em class="italic"><st c="41068">Problem</st></em></span><span><st c="41075">. </st></span><a href="https://en.wikipedia.org/wiki/Monty_Hall_problem" class="pcalibre pcalibre1 calibre6"><span><st c="41077">https://en.wikipedia.org/wiki/Monty_Hall_problem</st></span></a><span><st c="41125">.</st></span></li>
			</ul>
		</div>
	<div id="charCountTotal" value="41126" class="calibre2"/></body></html>