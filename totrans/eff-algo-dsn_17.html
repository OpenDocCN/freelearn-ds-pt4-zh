<html><head></head><body>
		<div id="_idContainer1998" epub:type="chapter" class="calibre2">
			<h1 id="_idParaDest-171" class="chapter-number"><a id="_idTextAnchor200" class="pcalibre pcalibre1 calibre6"/><st c="0">13</st></h1>
			<h1 id="_idParaDest-172" class="calibre5"><a id="_idTextAnchor201" class="pcalibre pcalibre1 calibre6"/><st c="3">Non-Linear Data Structures</st></h1>
			<p class="calibre3"><strong class="bold"><st c="30">Non-linear data structures</st></strong><st c="57"> form </st><a id="_idIndexMarker792" class="pcalibre pcalibre1 calibre6"/><st c="63">a crucial class of data structures with extensive applications in designing efficient algorithms. </st><st c="161">Unlike linear data structures, such as arrays and linked lists, non-linear structures allow data elements to be stored and accessed in a more complex, hierarchical manner. </st><st c="333">These structures enable the efficient handling of relationships, dependencies, and hierarchical data, making them vital for solving a wide range of </st><span><st c="481">computational problems.</st></span></p>
			<p class="calibre3"><st c="504">In this chapter, we begin by exploring the general properties and characteristics that define non-linear data structures. </st><st c="627">Following this, we discuss two major groups: graphs and trees. </st><strong class="bold"><st c="690">Graphs</st></strong><st c="696"> are </st><a id="_idIndexMarker793" class="pcalibre pcalibre1 calibre6"/><st c="701">versatile structures used to model relationships between objects, while </st><strong class="bold"><st c="773">trees</st></strong><st c="778"> represent</st><a id="_idIndexMarker794" class="pcalibre pcalibre1 calibre6"/><st c="788"> hierarchical relationships in a more structured form. </st><st c="843">Finally, we</st><a id="_idIndexMarker795" class="pcalibre pcalibre1 calibre6"/><st c="854"> examine a special case of binary trees, known as </st><strong class="bold"><st c="904">heaps</st></strong><st c="909">, which are essential for implementing efficient algorithms such as heapsort. </st><st c="987">Learning about non-linear data structures is essential for algorithm design, as they play a key role in many algorithms, including those for sorting and searching. </st><st c="1151">Additionally, graphs, trees, and other forms of non-linear data structures are extensively used in advanced fields such as AI, machine learning, and optimization, where efficient data management and processing </st><span><st c="1361">are critical.</st></span></p>
			<p class="calibre3"><st c="1374">This chapter covers the </st><span><st c="1399">following topics:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="1416">Introduction to non-linear </st><span><st c="1444">data structures</st></span></li>
				<li class="calibre13"><span><st c="1459">Graphs</st></span></li>
				<li class="calibre13"><span><st c="1466">Trees</st></span></li>
				<li class="calibre13"><span><st c="1472">Heaps</st></span></li>
			</ul>
			<h1 id="_idParaDest-173" class="calibre5"><a id="_idTextAnchor202" class="pcalibre pcalibre1 calibre6"/><st c="1478">Introduction to non-linear data structures</st></h1>
			<p class="calibre3"><st c="1521">In </st><a href="B22248_11.xhtml#_idTextAnchor164" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><st c="1525">Chapter 11</st></em></span></a><st c="1535">, we</st><a id="_idIndexMarker796" class="pcalibre pcalibre1 calibre6"/><st c="1539"> introduced the concept of </st><strong class="bold"><st c="1566">abstract data types</st></strong><st c="1585"> (</st><strong class="bold"><st c="1587">ADTs</st></strong><st c="1591">), classifying</st><a id="_idIndexMarker797" class="pcalibre pcalibre1 calibre6"/><st c="1606"> them into two main categories: linear and non-linear. </st><st c="1661">We followed this with an in-depth discussion of linear data structures in </st><a href="B22248_12.xhtml#_idTextAnchor187" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><st c="1735">Chapter 12</st></em></span></a><st c="1745">, where we examined their relevance to our core focus – designing and analyzing efficient algorithms. </st><st c="1847">While we touched on many essential aspects of linear data structures, it is worth noting that this area of study is vast and could easily warrant its own in-depth exploration. </st><st c="2023">For those interested in deeper exploration of data structures, we have included references at the end of both </st><em class="italic"><st c="2133">Chapters 11</st></em> <span><st c="2144">and </st></span><span><em class="italic"><st c="2149">12</st></em></span><span><st c="2151">.</st></span></p>
			<p class="calibre3"><st c="2152">In this chapter, our focus shifts to non-linear data structures. </st><st c="2218">Like the previous chapter, we will approach this topic with an eye on its relationship with efficient algorithm design. </st><st c="2338">Our goal is not merely to present the various types of non-linear data structures but to highlight their roles and applications in improving the performance </st><span><st c="2495">of algorithms.</st></span></p>
			<p class="calibre3"><st c="2509">Let’s begin by briefly discussing what defines non-linear data structures, their key characteristics, and some of the most commonly </st><span><st c="2642">used types.</st></span></p>
			<p class="calibre3"><st c="2653">Unlike linear data structures, where elements are arranged in a sequential manner (e.g., arrays, linked lists), non-linear data structures organize data in a hierarchical or interconnected way. </st><st c="2848">In non-linear structures, each element may be connected to multiple other elements, forming complex relationships that enable more efficient data processing for </st><span><st c="3009">certain operations.</st></span></p>
			<p class="calibre3"><st c="3028">The following are the </st><a id="_idIndexMarker798" class="pcalibre pcalibre1 calibre6"/><st c="3051">key features of non-linear </st><span><st c="3078">data structures:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="3094">Hierarchical relationships</st></strong><st c="3121">: Elements are structured in a way that reflects a hierarchy, meaning </st><a id="_idIndexMarker799" class="pcalibre pcalibre1 calibre6"/><st c="3192">some elements may act as </st><strong class="bold"><st c="3217">parents</st></strong><st c="3224"> while others are </st><strong class="bold"><st c="3242">children</st></strong><st c="3250">. This is particularly true for structures such as </st><strong class="bold"><st c="3301">trees</st></strong> <span><st c="3306">and </st></span><span><strong class="bold"><st c="3311">graphs</st></strong></span><span><st c="3317">.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="3318">Complex traversal patterns</st></strong><st c="3345">: Unlike linear structures, where traversal is relatively</st><a id="_idIndexMarker800" class="pcalibre pcalibre1 calibre6"/><st c="3403"> straightforward, moving through non-linear data structures requires more sophisticated techniques, often specific to the structure </st><span><st c="3535">being used.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="3546">Variable access time</st></strong><st c="3567">: The time </st><a id="_idIndexMarker801" class="pcalibre pcalibre1 calibre6"/><st c="3579">it takes to search, insert, or delete elements can vary greatly depending on the structure and the way it is implemented. </st><st c="3701">In many cases, non-linear data structures allow for more efficient operations compared </st><a id="_idIndexMarker802" class="pcalibre pcalibre1 calibre6"/><st c="3788">to their </st><span><st c="3797">linear counterparts.</st></span></li>
			</ul>
			<p class="calibre3"><st c="3817">Non-linear data structures are</st><a id="_idIndexMarker803" class="pcalibre pcalibre1 calibre6"/><st c="3848"> composed of several key elements that define their structure and functionality. </st><st c="3929">The most important components include nodes, edges, parents, children, roots, leaves, and subtrees. </st><st c="4029">Let’s understand these components </st><span><st c="4063">in detail:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="4073">Nodes</st></strong><st c="4079">: A </st><a id="_idIndexMarker804" class="pcalibre pcalibre1 calibre6"/><st c="4084">node or vertex is the fundamental building block of most non-linear data structures. </st><st c="4169">Each node typically contains data and may also have connections to other vertices, depending on the type of structure. </st><st c="4288">In trees, for example, vertices represent individual elements within the hierarchy. </st><st c="4372">For example, in a social network graph, each node represents a user, and the data stored in the node might be the user’s </st><span><st c="4493">profile information.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="4513">Edges</st></strong><st c="4519">: An </st><a id="_idIndexMarker805" class="pcalibre pcalibre1 calibre6"/><st c="4525">edge or arrow is a link or connection between two nodes. </st><st c="4582">In non-linear structures, edges play a critical role in defining the relationships between nodes. </st><st c="4680">In a binary tree, edges define the relationship between a parent and its children. </st><st c="4763">For example, if a parent node represents a manager, the edges would connect to child nodes that represent their employees. </st><st c="4886">In a graph, an edge represents a relationship between two entities. </st><st c="4954">In a transportation network, for instance, an edge might represent a direct flight between </st><span><st c="5045">two cities.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="5056">Parents and children</st></strong><st c="5077">: In hierarchical non-linear data structures such as trees, nodes are organized in levels, where parent nodes are directly connected to the child nodes below them. </st><st c="5242">The parent-child relationship is a fundamental concept </st><span><st c="5297">in trees:</st></span><ul class="calibre50"><li class="calibre13"><strong class="bold"><st c="5306">Parent</st></strong><st c="5313">: A </st><a id="_idIndexMarker806" class="pcalibre pcalibre1 calibre6"/><st c="5318">node that has one or more child nodes directly </st><span><st c="5365">beneath it</st></span></li><li class="calibre13"><strong class="bold"><st c="5375">Child</st></strong><st c="5381">: A node</st><a id="_idIndexMarker807" class="pcalibre pcalibre1 calibre6"/><st c="5390"> that is directly connected to another node above it (</st><span><st c="5444">its parent)</st></span></li></ul><p class="calibre3"><st c="5456">For example, in a corporate hierarchy tree, a manager is a parent node, and their subordinates are the </st><span><st c="5560">child nodes.</st></span></p></li>
				<li class="calibre13"><strong class="bold"><st c="5572">Root</st></strong><st c="5577">: The root is</st><a id="_idIndexMarker808" class="pcalibre pcalibre1 calibre6"/><st c="5591"> the topmost node in a tree structure and acts as the starting point for traversing the tree. </st><st c="5685">A tree can only have one root, and all other nodes are descendants of this root. </st><st c="5766">If a node has no parent, it is considered the root. </st><st c="5818">In a filesystem, the root directory is the topmost folder, and all other directories or files branch out </st><span><st c="5923">from it.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="5931">Leaf</st></strong><st c="5936">: A </st><a id="_idIndexMarker809" class="pcalibre pcalibre1 calibre6"/><st c="5941">leaf is a node that has no children. </st><st c="5978">Leaves represent the endpoints of a tree structure, where no further branching occurs. </st><st c="6065">These are crucial in many algorithms, as they often signal completion points in traversals </st><span><st c="6156">or searches.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="6168">Subtree</st></strong><st c="6176">: A</st><a id="_idIndexMarker810" class="pcalibre pcalibre1 calibre6"/><st c="6180"> subtree is a smaller portion of a tree that includes a node and all its descendants. </st><st c="6266">Subtrees allow trees to be treated recursively, where each node, along with its children, can be considered a tree on its own. </st><st c="6393">In a decision tree, each node and its branches form a subtree, representing a subset of </st><span><st c="6481">possible decisions.</st></span></li>
			</ul>
			<p class="calibre3"><st c="6500">There are several types of non-linear data structures, each suited to different kinds of algorithmic problems. </st><st c="6612">The most common non-linear data structures include graphs, trees, and heaps. </st><st c="6689">In the following sections, we will examine these three fundamental non-linear data structures in detail. </st><st c="6794">Each of the structures has unique characteristics and applications, and understanding them is crucial for designing efficient algorithms. </st><st c="6932">We will explore their properties, how they are implemented, and the roles they play in solving various </st><span><st c="7035">computational problems.</st></span></p>
			<h1 id="_idParaDest-174" class="calibre5"><a id="_idTextAnchor203" class="pcalibre pcalibre1 calibre6"/><st c="7058">Graphs</st></h1>
			<p class="calibre3"><strong class="bold"><st c="7065">Graphs</st></strong><st c="7072"> are</st><a id="_idIndexMarker811" class="pcalibre pcalibre1 calibre6"/><st c="7076"> one of the most versatile and widely used non-linear data structures. </st><st c="7147">They are used to represent relationships between entities, where entities are represented as nodes (also called </st><strong class="bold"><st c="7259">vertices</st></strong><st c="7267">) and</st><a id="_idIndexMarker812" class="pcalibre pcalibre1 calibre6"/><st c="7273"> relationships as edges. </st><st c="7298">Graphs can model a wide range of real-world problems, from social networks to transportation systems and </st><span><st c="7403">communication protocols.</st></span></p>
			<p class="calibre3"><st c="7427">Graphs come in various types, each with specific properties that make them suitable for different tasks. </st><st c="7533">Here are the most common types </st><span><st c="7564">of graphs:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="7574">Undirected graphs</st></strong><st c="7592">: In </st><a id="_idIndexMarker813" class="pcalibre pcalibre1 calibre6"/><st c="7598">undirected graphs, edges have no direction. </st><st c="7642">The </st><a id="_idIndexMarker814" class="pcalibre pcalibre1 calibre6"/><st c="7646">relationship between two nodes is bidirectional (see </st><span><em class="italic"><st c="7699">Figure 13</st></em></span><em class="italic"><st c="7708">.1</st></em><st c="7710">). </st><st c="7714">If there is an edge between node A and node B, you can traverse from A to B or from B to A without any restrictions. </st><st c="7831">An example of an undirected graph is the social network of Facebook friends, where connections are mutual. </st><st c="7938">This means if A is friends with B, then B is also friends with A, reflecting the bidirectional nature of </st><span><st c="8043">the relationship.</st></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer1880" class="img---figure">
					<img src="image/B22248_13_1.jpg" alt="Figure 13.1: An undirected graph" class="calibre144"/><st c="8060"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="8062">Figure 13.1: An undirected graph</st></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="8094">Directed graphs (digraphs)</st></strong><st c="8121">: In digraphs, edges have a direction. </st><st c="8161">The relationship </st><a id="_idIndexMarker815" class="pcalibre pcalibre1 calibre6"/><st c="8178">between nodes is one-way, meaning</st><a id="_idIndexMarker816" class="pcalibre pcalibre1 calibre6"/><st c="8211"> that if there is a directed edge from node A to node B, you can only traverse from A to B, not the other way around, for example, a website where pages have links pointing to other pages, forming a digraph. </st><span><em class="italic"><st c="8419">Figure 13</st></em></span><em class="italic"><st c="8428">.2</st></em><st c="8430"> shows an example of digraphs. </st><st c="8461">As illustrated, graphs do not have to be </st><span><st c="8502">fully connected.</st></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer1881" class="img---figure">
					<img src="image/B22248_13_2.jpg" alt="Figure 13.2: A digraph" class="calibre144"/><st c="8518"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="8522">Figure 13.2: A digraph</st></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="8544">Weighted graphs</st></strong><st c="8560">: In a </st><a id="_idIndexMarker817" class="pcalibre pcalibre1 calibre6"/><st c="8568">weighted graph, each edge is </st><a id="_idIndexMarker818" class="pcalibre pcalibre1 calibre6"/><st c="8597">assigned a numerical value or </st><strong class="bold"><st c="8627">weight</st></strong><st c="8633">. This weight often represents a cost, distance, or time associated with the connection between nodes. </st><st c="8736">An example of a weighted graph is a road network where the weight of an edge represents the </st><a id="_idIndexMarker819" class="pcalibre pcalibre1 calibre6"/><st c="8828">distance or travel time </st><a id="_idIndexMarker820" class="pcalibre pcalibre1 calibre6"/><st c="8852">between cities. </st><span><em class="italic"><st c="8868">Figure 13</st></em></span><em class="italic"><st c="8877">.3</st></em><st c="8879"> depicts a weighted graph, where the weights are assigned to </st><span><st c="8940">the edges.</st></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer1882" class="img---figure">
					<img src="image/B22248_13_3.jpg" alt="Figure 13.3: A weighted graph" class="calibre144"/><st c="8950"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="8952">Figure 13.3: A weighted graph</st></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="8981">Unweighted graphs</st></strong><st c="8999">: In unweighted graphs, all edges have equal significance, meaning </st><a id="_idIndexMarker821" class="pcalibre pcalibre1 calibre6"/><st c="9067">that there is no particular cost or distance </st><a id="_idIndexMarker822" class="pcalibre pcalibre1 calibre6"/><st c="9112">associated with traveling between nodes. </st><st c="9153">In </st><span><em class="italic"><st c="9156">Figure 13</st></em></span><em class="italic"><st c="9165">.1</st></em><st c="9167">, the graph </st><span><st c="9179">is unweighted.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="9193">Cyclic and acyclic graphs</st></strong><st c="9219">: A cyclic graph contains at least one cycle, meaning</st><a id="_idIndexMarker823" class="pcalibre pcalibre1 calibre6"/><st c="9273"> you</st><a id="_idIndexMarker824" class="pcalibre pcalibre1 calibre6"/><st c="9277"> can start from a node, traverse </st><a id="_idIndexMarker825" class="pcalibre pcalibre1 calibre6"/><st c="9310">edges, and return to the </st><a id="_idIndexMarker826" class="pcalibre pcalibre1 calibre6"/><st c="9335">same node. </st><st c="9346">An acyclic graph has no such cycles, making them essential for applications such as task scheduling. </st><st c="9447">The graph in </st><span><em class="italic"><st c="9460">Figure 13</st></em></span><em class="italic"><st c="9469">.1</st></em> <span><st c="9471">has cycles.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="9483">Signed graphs</st></strong><st c="9497">: In </st><a id="_idIndexMarker827" class="pcalibre pcalibre1 calibre6"/><st c="9503">signed graphs, edges are labeled with</st><a id="_idIndexMarker828" class="pcalibre pcalibre1 calibre6"/><st c="9540"> either positive or negative signs, typically representing favorable or unfavorable relationships. </st><st c="9639">These graphs are useful in scenarios where relationships can have polarities, such as in social networks, where edges </st><a id="_idIndexMarker829" class="pcalibre pcalibre1 calibre6"/><st c="9757">could represent</st><a id="_idIndexMarker830" class="pcalibre pcalibre1 calibre6"/><st c="9772"> friendship (positive) or conflict (negative). </st><st c="9819">Social networks in which positive edges represent friendships and negative edges represent rivalries is an example of a </st><span><st c="9939">signed graph.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="9952">Hypergraphs</st></strong><st c="9964">: A </st><a id="_idIndexMarker831" class="pcalibre pcalibre1 calibre6"/><st c="9969">hypergraph </st><a id="_idIndexMarker832" class="pcalibre pcalibre1 calibre6"/><st c="9980">generalizes the</st><a id="_idIndexMarker833" class="pcalibre pcalibre1 calibre6"/><st c="9995"> concept of a graph by allowing edges (called </st><strong class="bold"><st c="10041">hyperedges</st></strong><st c="10051">) to connect more than two nodes at a time. </st><st c="10096">This type of graph is particularly useful in representing complex relationships where a single connection might involve multiple entities. </st><st c="10235">For example, in a research collaboration network, a hyperedge might represent a publication authored by three or more researchers, connecting all of </st><span><st c="10384">them simultaneously.</st></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer1883" class="img---figure">
					<img src="image/B22248_13_4.jpg" alt="Figure 13.4: A hypergraph" class="calibre144"/><st c="10404"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="10406">Figure 13.4: A hypergraph</st></p>
			<p class="calibre3"><span><em class="italic"><st c="10431">Figure 13</st></em></span><em class="italic"><st c="10441">.4</st></em><st c="10443"> illustrates an example of a hypergraph with the following components: The set of vertices is </st><img src="image/1836.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfenced open=&quot;{&quot; close=&quot;}&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;b&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1349"/><st c="10537"/><st c="10562">, and the set of hyperedges is </st><img src="image/1837.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfenced open=&quot;{&quot; close=&quot;}&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1350"/><st c="10593"/><st c="10605">. Each hyperedge connects multiple vertices as follows: </st><img src="image/1838.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfenced open=&quot;{&quot; close=&quot;}&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;b&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1351"/><st c="10661"/><st c="10677">, </st><img src="image/1839.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfenced open=&quot;{&quot; close=&quot;}&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1352"/><st c="10679"/><st c="10693">, </st><span><st c="10695">and </st></span><span><img src="image/1840.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfenced open=&quot;{&quot; close=&quot;}&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1353"/><st c="10699"/></span><span><st c="10714">.</st></span></p>
			<p class="calibre3"><st c="10715">In the following </st><a id="_idIndexMarker834" class="pcalibre pcalibre1 calibre6"/><st c="10733">section, we will explore how to represent some of the most commonly used graphs in algorithms and discuss the complexities associated with each </st><span><st c="10877">representation method.</st></span></p>
			<h2 id="_idParaDest-175" class="calibre5"><a id="_idTextAnchor204" class="pcalibre pcalibre1 calibre6"/><st c="10899">Graphs representation</st></h2>
			<p class="calibre3"><st c="10921">Graphs can be </st><a id="_idIndexMarker835" class="pcalibre pcalibre1 calibre6"/><st c="10936">represented in several ways, each method being well suited to particular use cases depending on the graph structure and the type of operations needed. </st><st c="11087">In the following subsections, we will examine three common methods for graph representation and their key properties. </st><st c="11205">While evaluating each method, we will focus on three critical aspects of </st><span><st c="11278">their performance:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="11296">Space complexity</st></strong><st c="11313">: How much memory is required to store the graph using the </st><span><st c="11373">chosen representation</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="11394">The time complexity for accessing all neighbors of a node</st></strong><st c="11452">: The efficiency of retrieving all nodes that are directly connected (adjacent) to a </st><span><st c="11538">given node</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="11548">The time complexity for checking edge existence</st></strong><st c="11596">: The time required to determine whether an edge exists between two </st><span><st c="11665">specific nodes</st></span></li>
			</ul>
			<p class="calibre3"><st c="11679">By analyzing these complexities, we can better understand the strengths and limitations of each graph representation and how they apply to different </st><span><st c="11829">algorithmic tasks.</st></span></p>
			<h3 class="calibre8"><st c="11847">Adjacency matrix</st></h3>
			<p class="calibre3"><st c="11864">An </st><strong class="bold"><st c="11868">adjacency matrix</st></strong><st c="11884"> represents</st><a id="_idIndexMarker836" class="pcalibre pcalibre1 calibre6"/><st c="11895"> a graph </st><a id="_idIndexMarker837" class="pcalibre pcalibre1 calibre6"/><st c="11904">using a </st><img src="image/1841.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1354"/><st c="11912"/><st c="11914"> matrix, where </st><img src="image/1842.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1355"/><st c="11928"/><st c="11929"> is the number of nodes or vertices in the graph. </st><st c="11979">Each cell in the matrix at position </st><img src="image/1843.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1356"/><st c="12015"/><st c="12016"> indicates the presence (and possibly the weight) of an edge between node </st><img src="image/1844.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1357"/><st c="12090"/><st c="12091"> and node </st><img src="image/1845.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1358"/><st c="12101"/><st c="12102">. In an undirected graph, the adjacency matrix </st><img src="image/1650.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1359"/><st c="12149"/><st c="12150"> is symmetric, meaning that </st><img src="image/1847.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1360"/><st c="12178"/><st c="12179">’, where </st><img src="image/1656.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1361"/><st c="12188"/><em class="italic"><st c="12189">’</st></em><st c="12190"> represents the transpose of matrix </st><img src="image/1656.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1361"/><st c="12226"/><st c="12227">. This symmetry arises because the edges in an undirected graph have no direction, so </st><a id="_idIndexMarker838" class="pcalibre pcalibre1 calibre6"/><st c="12313">if there is an edge between node </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="12346"/><st c="12347"> and node </st><img src="image/1035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre799"/><st c="12357"/><st c="12358">, the relationship is mutual. </st><st c="12388">Therefore, both </st><img src="image/1852.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1362"/><st c="12404"/><st c="12406"> and </st><img src="image/1853.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1363"/><st c="12410"/><st c="12411"> will have the </st><span><st c="12426">same value.</st></span></p>
			<p class="calibre3"><st c="12437">For </st><a id="_idIndexMarker839" class="pcalibre pcalibre1 calibre6"/><st c="12442">unweighted, unsigned graphs, the adjacency matrix is a binary matrix, where each entry is either 0 or 1. </st><st c="12547">A value of 1 at </st><img src="image/1854.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;D&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1364"/><st c="12563"/><st c="12570"> indicates that there is an edge between vertices </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="12619"/><st c="12620"> and </st><img src="image/1035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre799"/><st c="12625"/><st c="12626">, and a 0 means no edge exists </st><span><st c="12657">between them.</st></span></p>
			<p class="calibre3"><span><strong class="bold"><st c="12670">Example 13.1</st></strong></span><span><st c="12683">:</st></span></p>
			<p class="calibre3"><st c="12685">Here is a matrix representing a digraph </st><span><st c="12725">with weights:</st></span></p>
			<p class="calibre3"><st c="12738">A --&gt; </st><span><st c="12745">B (2)</st></span></p>
			<p class="calibre3"><st c="12750">B --&gt; </st><span><st c="12757">C (3)</st></span></p>
			<p class="calibre3"><st c="12762">A --&gt; </st><span><st c="12769">C (4)</st></span></p>
			<p class="calibre3"><st c="12774">The adjacency matrix representing this simple graph is a </st><img src="image/1857.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre1365"/><st c="12832"/><st c="12838"> matrix </st><span><st c="12845">as follows:</st></span></p>
			<p class="calibre3"><img src="image/1858.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mtable columnspacing=&quot;0.8000em 0.8000em&quot; columnwidth=&quot;auto auto auto&quot; columnalign=&quot;center center center&quot; rowalign=&quot;baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1366"/><st c="12856"/></p>
			<p class="calibre3"><img src="image/1859.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mtable&gt;&lt;mml:mtr&gt;&lt;mml:mtd&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:mtd&gt;&lt;/mml:mtr&gt;&lt;mml:mtr&gt;&lt;mml:mtd&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;/mml:mtd&gt;&lt;/mml:mtr&gt;&lt;mml:mtr&gt;&lt;mml:mtd&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mtd&gt;&lt;/mml:mtr&gt;&lt;/mml:mtable&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mtable&gt;&lt;mml:mtr&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;/mml:mtr&gt;&lt;mml:mtr&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;/mml:mtr&gt;&lt;mml:mtr&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;mml:mtd&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mtd&gt;&lt;/mml:mtr&gt;&lt;/mml:mtable&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1367"/><st c="12858"/></p>
			<p class="calibre3"><st c="12859">It is obvious that the space complexity of this representation is </st><img src="image/1860.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1368"/><st c="12925"/><st c="12926">. Regardless of the number of edges, the adjacency matrix requires space proportional to the square of the number of vertices because it must account for every possible edge between all pairs of vertices. </st><st c="13131">This can be inefficient for large graphs, especially if the graph is sparse (i.e., has relatively few edges compared to the number of </st><span><st c="13265">possible edges).</st></span></p>
			<p class="calibre3"><st c="13281">In graphs, one of the operations is accessing all neighbors of a node in the graph. </st><st c="13366">Using adjacency matrix representation, the time complexity is </st><img src="image/1861.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1369"/><st c="13428"/><st c="13429">. To find all neighbors of a given node, we need to inspect all entries in the corresponding row (or column) of the matrix. </st><st c="13553">For a node </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="13564"/><st c="13565">, you scan the </st><img src="image/1863.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" class="calibre1370"/><st c="13580"/><st c="13584"> row to check which vertices have a direct edge from </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="13636"/><st c="13637">, which reminds us of a linear search algorithm in which we want to report all non-zero entries. </st><st c="13734">This operation requires examining </st><img src="image/1865.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1371"/><st c="13768"/><st c="13769"> entries, resulting in a time complexity of </st><img src="image/1866.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1372"/><st c="13813"/><st c="13814">, regardless of the number of actual neighbors the node has. </st><st c="13875">In contrast, checking whether an edge exists in the adjacency matrix representation has a time complexity of </st><span><st c="13984">O</st></span><span><st c="13985">(</st></span><span><st c="13986">1</st></span><span><st c="13987">)</st></span><st c="13988">, as we can directly access any edge in constant time. </st><st c="14043">Since the adjacency matrix</st><a id="_idIndexMarker840" class="pcalibre pcalibre1 calibre6"/><st c="14069"> is a two-dimensional array, checking whether an edge exists between node </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1324"/><st c="14143"/><st c="14144"> and </st><a id="_idIndexMarker841" class="pcalibre pcalibre1 calibre6"/><st c="14149">node </st><img src="image/1035.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1373"/><st c="14154"/><st c="14155"> is a direct access operation to the cell at position </st><img src="image/1869.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1374"/><st c="14209"/><st c="14210">. Simply check whether the value at </st><img src="image/1869.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1374"/><st c="14246"/><st c="14247"> is non-zero (for weighted graphs) or </st><img src="image/1871.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;r&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1375"/><st c="14285"/><st c="14286"> or </st><img src="image/1872.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre116"/><st c="14290"/><st c="14291"> (for </st><span><st c="14297">unweighted graphs).</st></span></p>
			<p class="callout-heading"><st c="14316">When should we use an adjacency matrix?</st></p>
			<p class="callout"><st c="14356">It is particularly useful when the graph is dense (i.e., the number of edges is close to </st><img src="image/1873.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" class="calibre1376"/><st c="14446"/><st c="14447">), as the high space requirement becomes less significant in such cases. </st><st c="14520">Additionally, if our algorithm needs constant-time edge existence checks, the adjacency matrix offers a clear advantage. </st><st c="14641">Lastly, the adjacency matrix is simple to implement, making it a practical choice for certain algorithms where ease of use is </st><span><st c="14767">a priority.</st></span></p>
			<h3 class="calibre8"><st c="14778">Adjacency list</st></h3>
			<p class="calibre3"><st c="14793">In </st><a id="_idIndexMarker842" class="pcalibre pcalibre1 calibre6"/><st c="14797">an </st><strong class="bold"><st c="14800">adjacency list</st></strong><st c="14814">, each node stores a list of its neighboring </st><a id="_idIndexMarker843" class="pcalibre pcalibre1 calibre6"/><st c="14859">nodes (or nodes it is connected to). </st><st c="14896">This is a more space-efficient representation, especially for sparse graphs. </st><st c="14973">The adjacency list for </st><em class="italic"><st c="14996">Example 13.1</st></em><st c="15008"> is </st><span><st c="15012">as follows:</st></span></p>
			<p class="calibre3"><st c="15023">A: </st><span><st c="15027">B(2), C(4)</st></span></p>
			<p class="calibre3"><span><st c="15037">B: C(3)</st></span></p>
			<p class="calibre3"><span><st c="15045">C: -</st></span></p>
			<p class="calibre3"><st c="15050">The adjacency list representation uses </st><img src="image/1874.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1377"/><st c="15090"/><st c="15099"> space, where </st><img src="image/1875.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1378"/><st c="15112"/><st c="15113"> is the number of edges. </st><st c="15138">This is generally more efficient for </st><span><st c="15175">sparse graphs.</st></span></p>
			<p class="calibre3"><st c="15189">Accessing the neighbors of a node (i.e., adjacent vertices) takes </st><img src="image/1876.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1379"/><st c="15256"/><st c="15257">, where </st><img src="image/1184.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre910"/><st c="15265"/><st c="15266"> is the degree of the node (the number of edges connected to the node). </st><st c="15338">In the worst case, this could be </st><img src="image/1878.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1380"/><st c="15371"/><st c="15374">, but for most practical applications, it’s much smaller. </st><st c="15432">In the preceding adjacency list, the nodes listed after the colon represent the neighbors, or adjacent nodes, of the node on the </st><span><st c="15561">left side.</st></span></p>
			<p class="calibre3"><st c="15571">To check </st><a id="_idIndexMarker844" class="pcalibre pcalibre1 calibre6"/><st c="15581">whether there is an edge between two specific vertices, you need to traverse the list of adjacent vertices. </st><st c="15689">This takes </st><img src="image/1879.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1381"/><st c="15700"/><st c="15701"> time, since we may need to scan through all neighbors of </st><a id="_idIndexMarker845" class="pcalibre pcalibre1 calibre6"/><st c="15759">the source node. </st><st c="15776">In the worst case, this is </st><img src="image/1880.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1382"/><st c="15803"/><st c="15806">, but typically it is smaller for </st><span><st c="15840">sparse graphs.</st></span></p>
			<p class="callout-heading"><st c="15854">When to use an adjacency list</st></p>
			<p class="callout"><st c="15884">An adjacency list is most effective when the graph is sparse – that is when the number of edges is much smaller than </st><img src="image/1881.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" class="calibre1383"/><st c="16002"/><st c="16003">. Since the space complexity is </st><img src="image/1882.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1384"/><st c="16035"/><st c="16045">, it is more memory-efficient for graphs with fewer edges. </st><st c="16104">Additionally, if our algorithm frequently needs to access all neighbors of a node, the adjacency list provides efficient </st><img src="image/1883.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1385"/><st c="16225"/><st c="16226"> access. </st><st c="16235">It is also beneficial for dynamic graphs where nodes and edges are frequently added or removed, as updating an adjacency list is straightforward and less costly in terms </st><span><st c="16405">of memory.</st></span></p>
			<h3 class="calibre8"><st c="16415">Edge list</st></h3>
			<p class="calibre3"><st c="16425">An </st><strong class="bold"><st c="16429">edge list</st></strong><st c="16438"> explicitly</st><a id="_idIndexMarker846" class="pcalibre pcalibre1 calibre6"/><st c="16449"> stores all the edges in a graph </st><a id="_idIndexMarker847" class="pcalibre pcalibre1 calibre6"/><st c="16482">along with their weights (if any). </st><st c="16517">This is useful when the graph is sparse and you need to work primarily with the edges. </st><st c="16604">The edge list in the </st><em class="italic"><st c="16625">Example 13.1</st></em><st c="16637"> graph is </st><span><st c="16647">as follows:</st></span></p>
			<p class="calibre3"><st c="16658">(A, </st><span><st c="16663">B, 2)</st></span></p>
			<p class="calibre3"><st c="16668">(A, </st><span><st c="16673">C, 4)</st></span></p>
			<p class="calibre3"><st c="16678">(B, </st><span><st c="16683">C, 3)</st></span></p>
			<p class="calibre3"><st c="16688">The edge list representation uses </st><img src="image/1884.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1386"/><st c="16723"/><st c="16724"> space. </st><st c="16732">This is efficient for very sparse graphs. </st><st c="16774">To access all neighbors of a node, the edge list does not directly store them, so finding all neighbors requires scanning the entire edge list, which has a worst-case time complexity of </st><img src="image/1885.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1387"/><st c="16960"/><st c="16961">. Likewise, checking whether an edge exists between two vertices also involves scanning the entire edge list, resulting in a time complexity </st><span><st c="17102">of </st></span><span><img src="image/1886.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1388"/><st c="17105"/></span><span><st c="17106">.</st></span></p>
			<p class="callout-heading"><st c="17107">When to use an edge list</st></p>
			<p class="callout"><st c="17132">An edge list is </st><a id="_idIndexMarker848" class="pcalibre pcalibre1 calibre6"/><st c="17149">ideal for very sparse graphs where we primarily need to work with the edges themselves rather than frequently accessing neighbors or checking edge existence. </st><st c="17307">It uses </st><img src="image/1887.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1389"/><st c="17315"/><st c="17320"> space, making it highly memory-efficient for graphs with few edges. </st><st c="17388">However, its primary limitation is that it is not efficient for operations such as finding all neighbors of a node or checking whether a specific edge exists, both of which require scanning through the entire list. </st><st c="17603">Therefore, edge lists are best suited for algorithms where working directly with the edges is the focus, such as in certain edge-centric algorithms such as Kruskal’s minimum spanning </st><span><st c="17786">tree algorithm.</st></span></p>
			<h2 id="_idParaDest-176" class="calibre5"><a id="_idTextAnchor205" class="pcalibre pcalibre1 calibre6"/><st c="17801">Traversing graphs</st></h2>
			<p class="calibre3"><strong class="bold"><st c="17819">Traversal</st></strong><st c="17829"> is a</st><a id="_idIndexMarker849" class="pcalibre pcalibre1 calibre6"/><st c="17834"> fundamental operation in graph algorithms, where the goal is to visit all nodes in a specific sequence. </st><st c="17939">The two most widely used graph traversal techniques are </st><strong class="bold"><st c="17995">depth-first search</st></strong><st c="18013"> (</st><strong class="bold"><st c="18015">DFS</st></strong><st c="18018">) and </st><strong class="bold"><st c="18025">breadth-first search</st></strong><st c="18045"> (</st><strong class="bold"><st c="18047">BFS</st></strong><st c="18050">). </st><st c="18054">In the sections that</st><a id="_idIndexMarker850" class="pcalibre pcalibre1 calibre6"/><st c="18074"> follow, we will explore both of these methods</st><a id="_idIndexMarker851" class="pcalibre pcalibre1 calibre6"/><st c="18120"> in detail, highlighting their processes, use cases, </st><span><st c="18173">and complexities.</st></span></p>
			<h3 class="calibre8"><st c="18190">DFS graph traversal</st></h3>
			<p class="calibre3"><st c="18210">DFS is a </st><a id="_idIndexMarker852" class="pcalibre pcalibre1 calibre6"/><st c="18220">graph traversal technique that explores as far along each</st><a id="_idIndexMarker853" class="pcalibre pcalibre1 calibre6"/><st c="18277"> branch or path as possible before backtracking. </st><st c="18326">It is typically implemented using recursion or a stack, and it works well in exploring deep structures or discovering specific paths in </st><span><st c="18462">a graph.</st></span></p>
			<p class="calibre3"><st c="18470">The idea behind DFS is to start at an arbitrary node (usually called the </st><em class="italic"><st c="18544">root</st></em><st c="18548">) and explore each branch of the graph as deeply as possible before moving on to the next branch. </st><st c="18647">DFS follows these </st><span><st c="18665">basic steps:</st></span></p>
			<ol class="calibre12">
				<li class="calibre13"><st c="18677">Visit the </st><span><st c="18688">starting node.</st></span></li>
				<li class="calibre13"><st c="18702">For each unvisited neighbor of the current node, perform a DFS on </st><span><st c="18769">that neighbor.</st></span></li>
				<li class="calibre13"><st c="18783">Repeat this process until all nodes reachable from the starting node </st><span><st c="18853">are visited.</st></span></li>
			</ol>
			<p class="calibre3"><st c="18865">Let’s </st><a id="_idIndexMarker854" class="pcalibre pcalibre1 calibre6"/><st c="18872">consider</st><a id="_idIndexMarker855" class="pcalibre pcalibre1 calibre6"/><st c="18880"> the graph in </st><span><em class="italic"><st c="18894">Figure 13</st></em></span><em class="italic"><st c="18903">.5</st></em><st c="18905"> with </st><span><st c="18911">six nodes.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1936" class="img---figure">
					<img src="image/B22248_13_5.jpg" alt="Figure 13.5: An example graph" class="calibre144"/><st c="18921"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="18923">Figure 13.5: An example graph</st></p>
			<p class="calibre3"><st c="18952">Starting the DFS at </st><em class="italic"><st c="18973">node A</st></em><st c="18979">, the traversal order would be this: A --&gt; B --&gt; D --&gt; E --&gt; F --&gt; C. </st><st c="19049">This traversal explores one path (branch) completely before moving on to </st><span><st c="19122">the next.</st></span></p>
			<p class="calibre3"><st c="19131">Here is a Python implementation of DFS using recursion. </st><st c="19188">First, we define a </st><span><st c="19207">simple graph:</st></span></p>
			<pre class="source-code"><st c="19220" class="calibre11">
# You will need first: pip install networkx matplotlib
import networkx as nx
import matplotlib.pyplot as plt
# Define the graph as an adjacency list
graph = {
    'A': ['B', 'C'],
    'B': ['D', 'E'],
    'C': ['B' , 'F'],
    'D': ['E'],
    'E': ['F'],
    'F': ['A']
}</st></pre>			<p class="calibre3"><st c="19468">The </st><a id="_idIndexMarker856" class="pcalibre pcalibre1 calibre6"/><st c="19473">following </st><a id="_idIndexMarker857" class="pcalibre pcalibre1 calibre6"/><st c="19483">code visualizes the </st><span><st c="19503">example graph:</st></span></p>
			<pre class="source-code"><st c="19517" class="calibre11">
# Visualize the graph
visualize_graph(G)
# Create a directed graph using NetworkX
G = nx.DiGraph()
# Add edges to the graph
for node, neighbors in graph.items():
    for neighbor in neighbors:
        G.add_edge(node, neighbor)
# Visualize the graph using NetworkX and Matplotlib
def visualize_graph(G):
    pos = nx.spring_layout(G)  # Positions for all nodes
    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=10, font_weight='bold')
    plt.title("Graph Visualization")
    plt.show()</st></pre>			<p class="calibre3"><st c="20013">Now, we </st><a id="_idIndexMarker858" class="pcalibre pcalibre1 calibre6"/><st c="20022">implement the DFS </st><span><st c="20040">traversal algorithm:</st></span></p>
			<pre class="source-code"><st c="20060" class="calibre11">
# DFS function (optional, same as before)
visited = set()
def dfs(node):
    if node not in visited:
        print(node)
        visited.add(node)
        for neighbor in graph[node]:
            dfs(neighbor)
# Start DFS at node 'A'
dfs('A')</st></pre>			<p class="calibre3"><st c="20263">Let’s examine</st><a id="_idIndexMarker859" class="pcalibre pcalibre1 calibre6"/> <span><st c="20277">the code:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="20287">The graph is represented as an </st><span><st c="20319">adjacency list</st></span></li>
				<li class="calibre13"><st c="20333">We use a </st><strong class="source-inline1"><st c="20343">visited</st></strong><st c="20350"> set to ensure that nodes are </st><span><st c="20380">not revisited</st></span></li>
				<li class="calibre13"><st c="20393">The </st><strong class="source-inline1"><st c="20398">dfs</st></strong><st c="20401"> function prints the current node, marks it as visited, and recursively calls itself on all </st><span><st c="20493">unvisited neighbors</st></span></li>
			</ul>
			<p class="calibre3"><st c="20512">For the given graph, the output will be </st><span><st c="20553">as follows:</st></span></p>
			<pre class="source-code">
<strong class="source-inline2"><st c="20564" class="calibre11">A, B, D, E, F, C</st></strong></pre>			<p class="calibre3"><st c="20581">DFS is more memory efficient compared to BFS, particularly in deep graphs. </st><st c="20657">This is because DFS only needs to keep track of the current path and backtracking information, while BFS must store all nodes at each level of the graph. </st><st c="20811">DFS is also beneficial for pathfinding, especially in scenarios where all possible paths need to be explored, such as maze-solving algorithms. </st><st c="20954">Additionally, DFS is </st><a id="_idIndexMarker860" class="pcalibre pcalibre1 calibre6"/><st c="20975">frequently used for topological sorting in </st><strong class="bold"><st c="21018">directed acyclic graphs</st></strong><st c="21041"> (</st><strong class="bold"><st c="21043">DAGs</st></strong><st c="21047">), a technique useful in scheduling tasks and </st><span><st c="21094">resolving dependencies.</st></span></p>
			<p class="calibre3"><st c="21117">However, DFS has some </st><a id="_idIndexMarker861" class="pcalibre pcalibre1 calibre6"/><st c="21140">limitations. </st><st c="21153">One major drawback is that DFS may not find the shortest path in an unweighted graph, as it could explore a deep path before reaching the solution, which might not be optimal. </st><st c="21329">Additionally, in very large or infinite graphs, DFS can get </st><a id="_idIndexMarker862" class="pcalibre pcalibre1 calibre6"/><st c="21389">stuck exploring long paths or cycles unless precautions, such as cycle detection, are in place. </st><st c="21485">In languages such as Python, which have a limit on recursion depth, using a recursive DFS can lead to stack overflow errors if the graph is particularly deep. </st><st c="21644">To avoid this, DFS can be implemented iteratively using an explicit stack instead of relying </st><span><st c="21737">on recursion.</st></span></p>
			<p class="calibre3"><st c="21750">The</st><a id="_idIndexMarker863" class="pcalibre pcalibre1 calibre6"/><st c="21754"> time complexity of DFS is </st><img src="image/1888.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1390"/><st c="21781"/><st c="21791">, where V. </st><st c="21802">This is because DFS visits every node and every edge in the graph once. </st><st c="21874">In a sparse graph where </st><img src="image/1889.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;≈&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1391"/><st c="21898"/><st c="21900">, the time complexity is close to </st><img src="image/1890.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1392"/><st c="21934"/><st c="21935">. On the other side, in a dense graph where </st><img src="image/1891.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mo&gt;≈&lt;/mml:mo&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;" class="calibre1393"/><st c="21979"/><st c="21980">, the time complexity </st><span><st c="22002">approaches </st></span><span><img src="image/1860.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1368"/><st c="22013"/></span><span><st c="22014">.</st></span></p>
			<p class="calibre3"><st c="22015">The space complexity </st><a id="_idIndexMarker864" class="pcalibre pcalibre1 calibre6"/><st c="22037">of DFS is </st><img src="image/1880.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1382"/><st c="22047"/><st c="22050"> in the worst case due to the depth of the recursion stack or the explicit stack used in the iterative version. </st><st c="22161">In a worst-case scenario, where the graph is a long linear chain, the stack could hold all </st><img src="image/1722.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1394"/><st c="22252"/> <span><st c="22253">nodes.</st></span></p>
			<p class="calibre3"><st c="22259">There are two </st><a id="_idIndexMarker865" class="pcalibre pcalibre1 calibre6"/><st c="22274">common variants of DFS: </st><strong class="bold"><st c="22298">pre-order DFS</st></strong><st c="22311">, which visits a node before exploring its neighbors (as seen in the earlier example), and </st><strong class="bold"><st c="22402">post-order DFS</st></strong><st c="22416">, which visits a node only after visiting all its neighbors. </st><st c="22477">In the </st><a id="_idIndexMarker866" class="pcalibre pcalibre1 calibre6"/><st c="22484">same graph (</st><span><em class="italic"><st c="22496">Figure 13</st></em></span><em class="italic"><st c="22506">.5</st></em><st c="22508">), if we perform a post-order DFS, the traversal will result in the following order: D --&gt; F --&gt; E --&gt; B --&gt; C --&gt; A. </st><st c="22627">These variants are useful in different scenarios, such as tree traversal and algorithms that require specific orderings of </st><span><st c="22750">node processing.</st></span></p>
			<p class="calibre3"><st c="22766">DFS has numerous applications in algorithm design, including its use in AI search algorithms. </st><st c="22861">For instance, DFS is employed in problems that require exploring all possible paths between nodes, such as solving puzzles or finding paths through mazes. </st><st c="23016">It is also highly effective for cycle detection in both directed and undirected graphs, helping to identify loops within</st><a id="_idIndexMarker867" class="pcalibre pcalibre1 calibre6"/><st c="23136"> the graph structure. </st><st c="23158">Additionally, DFS can be used to find all connected components in a graph, particularly in undirected graphs. </st><st c="23268">In DAGs, DFS plays a crucial role in topological sorting, which is essential for tasks such as scheduling and dependency resolution. </st><st c="23401">These diverse applications highlight the importance of DFS in various </st><span><st c="23471">computational problems.</st></span></p>
			<p class="calibre3"><st c="23494">In summary, DFS is a powerful and efficient graph traversal technique, especially useful for pathfinding and solving problems that require exploring all possibilities. </st><st c="23663">Although it doesn’t guarantee </st><a id="_idIndexMarker868" class="pcalibre pcalibre1 calibre6"/><st c="23693">the shortest path, it excels in scenarios where memory efficiency is critical or when dealing with deep structures. </st><st c="23809">The key trade-offs include potentially long search times for large graphs and the risk of stack overflow in deep recursion. </st><st c="23933">In the next section, we will explore the BFS </st><span><st c="23978">traversal approach.</st></span></p>
			<h3 class="calibre8"><st c="23997">BFS graph traversal</st></h3>
			<p class="calibre3"><strong class="bold"><st c="24017">BFS</st></strong><st c="24021"> is another</st><a id="_idIndexMarker869" class="pcalibre pcalibre1 calibre6"/><st c="24032"> graph traversal algorithm that explores nodes </st><a id="_idIndexMarker870" class="pcalibre pcalibre1 calibre6"/><st c="24079">level by level, starting from a given source node. </st><st c="24130">Unlike DFS, which goes as deep as possible into one branch before backtracking, BFS explores all neighbors of a node before moving on to the next level of neighbors. </st><st c="24296">This makes BFS particularly effective for finding the shortest path in </st><span><st c="24367">unweighted graphs.</st></span></p>
			<p class="calibre3"><st c="24385">The BFS algorithm starts at the root (or any arbitrary starting node) and explores all its neighbors first. </st><st c="24494">After visiting all neighbors at the current level, it proceeds to the next level, visiting the neighbors of those neighbors, and so on. </st><st c="24630">The traversal continues until all nodes reachable from the starting node have </st><span><st c="24708">been visited.</st></span></p>
			<p class="calibre3"><st c="24721">The core of BFS relies on using a queue data structure, which ensures that nodes are explored in the correct order (</st><strong class="bold"><st c="24838">first-in first-out</st></strong><st c="24857"> (</st><strong class="bold"><st c="24859">FIFO</st></strong><st c="24863">)).  </st><st c="24868">Let’s consider the graph in </st><span><em class="italic"><st c="24896">Figure 13</st></em></span><em class="italic"><st c="24905">.6</st></em><st c="24907"> with six nodes. </st><st c="24924">Starting the BFS at </st><em class="italic"><st c="24944">node A</st></em><st c="24950">, the traversal order would be A --&gt; B --&gt; C --&gt;D --&gt; E --&gt; F --&gt; C. </st><st c="25019">This traversal explores one path (branch) completely before moving on to </st><span><st c="25092">the next.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1944" class="img---figure">
					<img src="image/B22248_13_6.jpg" alt="Figure 13.6: An example graph for BFS traversal" class="calibre144"/><st c="25101"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="25103">Figure 13.6: An example graph for BFS traversal</st></p>
			<p class="calibre3"><st c="25150">Here is a </st><a id="_idIndexMarker871" class="pcalibre pcalibre1 calibre6"/><st c="25161">Python</st><a id="_idIndexMarker872" class="pcalibre pcalibre1 calibre6"/><st c="25167"> implementation of BFS using </st><span><st c="25196">a queue:</st></span></p>
			<pre class="source-code"><st c="25204" class="calibre11">
from collections import deque
# Graph represented as an adjacency list
graph = {
    'A': ['B', 'C'],
    'B': ['D', 'E'],
    'C': ['F'],
    'D': ['A'],
    'E': ['B','D'],
    'F': ['E','D']
}
# BFS function
def bfs(start_node):
    visited = set()           # Set to track visited nodes
    queue = deque([start_node])  # Initialize the queue with the starting node
    while queue:
        node = queue.popleft()  # Dequeue a node
        if node not in visited:
            print(node)
            visited.add(node)  # Mark it as visited
            queue.extend(graph[node])  # Enqueue all unvisited neighbors
# Start BFS at node 'A'
bfs('A')</st></pre>			<p class="calibre3"><st c="25752">This is </st><a id="_idIndexMarker873" class="pcalibre pcalibre1 calibre6"/><st c="25761">how</st><a id="_idIndexMarker874" class="pcalibre pcalibre1 calibre6"/><st c="25764"> the code works. </st><st c="25781">First, we represent the graph using an adjacency list. </st><st c="25836">Next, we implement the queue data structure, which is essential for the BFS algorithm. </st><st c="25923">Finally, we implement the BFS traversal </st><span><st c="25963">algorithm itself:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="25980">Graph representation</st></strong><st c="26001">: The graph is represented as an </st><span><st c="26035">adjacency list</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="26049">Queue</st></strong><st c="26055">: </st><strong class="source-inline1"><st c="26058">deque</st></strong><st c="26063"> is used to efficiently handle queue operations (enqueueing and </st><span><st c="26127">dequeueing nodes)</st></span></li>
				<li class="calibre13"><strong class="source-inline1"><st c="26144">bfs</st></strong><st c="26148">: Nodes are processed in the order they are dequeued, and their neighbors are added to the queue for </st><span><st c="26250">further exploration</st></span></li>
			</ul>
			<p class="calibre3"><st c="26269">For the given graph, the output will be </st><span><st c="26310">as follows:</st></span></p>
			<pre class="source-code"><st c="26321" class="calibre11">
A, B, C, D, E, F</st></pre>			<p class="calibre3"><st c="26338">BFS offers several advantages</st><a id="_idIndexMarker875" class="pcalibre pcalibre1 calibre6"/><st c="26368"> over DFS. </st><st c="26379">In an unweighted graph, BFS guarantees that the first time a node is reached, it is via the shortest path from the source node, making it ideal for pathfinding problems. </st><st c="26549">Additionally, BFS explores all nodes at the same level before moving on to the next level, which is particularly useful when all immediate neighbors need to be visited first, such as in finding the shortest route in transportation systems. </st><st c="26789">Furthermore, BFS is highly effective in identifying all connected components in an undirected graph, as it systematically explores all </st><span><st c="26924">reachable nodes.</st></span></p>
			<p class="calibre3"><st c="26940">However, BFS</st><a id="_idIndexMarker876" class="pcalibre pcalibre1 calibre6"/><st c="26953"> has its drawbacks. </st><st c="26973">It requires storing all nodes at the current level in memory, which can lead to significant memory consumption, particularly in graphs with large branching factors. </st><st c="27138">Additionally, BFS can be inefficient for graphs with deep structures, as it explores level by level. </st><st c="27239">In cases where the graph is deep but not very broad, DFS may be a more efficient alternative since it focuses on depth rather than breadth in </st><span><st c="27381">its exploration.</st></span></p>
			<p class="calibre3"><st c="27397">The time complexity of BFS is </st><img src="image/1895.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1395"/><st c="27428"/><st c="27437">, as each vertex and edge is processed exactly once during the traversal. </st><st c="27511">In contrast, the space complexity of BFS is </st><img src="image/1896.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1396"/><st c="27555"/><st c="27560">, since in the worst case, all nodes at a particular level could be stored in the queue simultaneously. </st><st c="27664">This becomes particularly significant in graphs with large branching factors or wide levels, where the memory requirements can </st><span><st c="27791">grow substantially.</st></span></p>
			<p class="calibre3"><st c="27810">BFS has two notable variants: </st><strong class="bold"><st c="27841">bidirectional BFS</st></strong><st c="27858"> and </st><strong class="bold"><st c="27863">multi-source BFS</st></strong><st c="27879">. Bidirectional BFS is </st><a id="_idIndexMarker877" class="pcalibre pcalibre1 calibre6"/><st c="27902">used to find the shortest path between two nodes. </st><st c="27952">It runs two BFS traversals simultaneously – one from the source node and </st><a id="_idIndexMarker878" class="pcalibre pcalibre1 calibre6"/><st c="28025">one from the destination node – until the two searches meet in the middle. </st><st c="28100">This approach reduces the search space significantly, making it faster than a traditional BFS in scenarios where the source and destination are far apart. </st><st c="28255">Multi-source BFS involves multiple starting points. </st><st c="28307">BFS is initiated from all the source nodes at the same time, allowing exploration from multiple origins simultaneously. </st><st c="28427">This variant is useful in scenarios where you need to explore paths from several locations, such as finding the shortest distance from multiple sources to a destination in </st><span><st c="28599">a graph.</st></span></p>
			<p class="calibre3"><st c="28607">BFS has a wide </st><a id="_idIndexMarker879" class="pcalibre pcalibre1 calibre6"/><st c="28623">range of applications, including its use in AI search strategies. </st><st c="28689">One of its key strengths is its ability to find the shortest path in unweighted graphs. </st><st c="28777">Since BFS explores all nodes at the same level before moving deeper, it guarantees that the first time a node is reached, it is via the shortest possible path. </st><st c="28937">This makes BFS ideal for pathfinding algorithms, such </st><a id="_idIndexMarker880" class="pcalibre pcalibre1 calibre6"/><st c="28991">as navigation systems or solving puzzles where all moves have </st><span><st c="29053">equal cost.</st></span></p>
			<p class="calibre3"><st c="29064">Let’s modify the BFS algorithm to find the shortest path between </st><span><st c="29130">two nodes:</st></span></p>
			<pre class="source-code"><st c="29140" class="calibre11">
def bfs_shortest_path(start_node, target_node):
    visited = set()
    queue = deque([[start_node]])  # Queue stores paths
    while queue:
        path = queue.popleft()  # Dequeue the first path
        node = path[-1]  # Get the last node from the path
        if node == target_node:
            return path  # Return the path when target is reached
        if node not in visited:
            visited.add(node)
            for neighbor in graph[node]:
                new_path = list(path)
                new_path.append(neighbor)
                queue.append(new_path)  # Enqueue the new path
    return None  # Return None if there is no path
# Find the shortest path between 'A' and 'F'
print(bfs_shortest_path('A', 'F'))</st></pre>			<p class="calibre3"><st c="29734">For the given graph, the </st><a id="_idIndexMarker881" class="pcalibre pcalibre1 calibre6"/><st c="29760">shortest path between </st><strong class="source-inline"><st c="29782">A</st></strong><st c="29783"> and </st><strong class="source-inline"><st c="29788">F</st></strong><st c="29789"> is </st><span><st c="29793">as follows:</st></span></p>
			<pre class="source-code"><st c="29804" class="calibre11">
 ['A', 'C', 'F']</st></pre>			<p class="calibre3"><st c="29820">Another </st><a id="_idIndexMarker882" class="pcalibre pcalibre1 calibre6"/><st c="29829">notable application of BFS is in undirected graphs. </st><st c="29881">BFS is particularly useful for identifying all nodes that are reachable from a given starting point. </st><st c="29982">By doing this, BFS can efficiently detect and label connected components, which is essential in network analysis and social </st><span><st c="30106">network mapping.</st></span></p>
			<p class="calibre3"><st c="30122">Additionally, BFS is widely used for level-order traversal in trees. </st><st c="30192">In this scenario, BFS visits all nodes at each depth level before progressing to the next, making it an ideal approach when the hierarchy or levels of the nodes matter, such as in organization charts, filesystem structures, or </st><span><st c="30419">hierarchical clustering.</st></span></p>
			<p class="calibre3"><st c="30443">Beyond these core applications, BFS is widely used in AI search algorithms, alongside DFS, as two major search techniques. </st><st c="30567">Additionally, BFS is employed in finding the minimum spanning tree and the shortest path in various </st><span><st c="30667">graph-related problems:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="30690">BFS in AI</st></strong><st c="30700">: BFS serves as the foundation for many AI search strategies, particularly those that require exploration of all possible states level by level, such as in game trees or </st><span><st c="30871">puzzle solving</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="30885">Finding the minimum spanning tree</st></strong><st c="30919">: In unweighted graphs, BFS can be used as a building block to find the minimum spanning tree by ensuring all nodes are visited in the shortest path order from </st><span><st c="31080">the source</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="31090">Network broadcast</st></strong><st c="31108">: In computer networks, BFS is used to simulate broadcast routing, where information must be sent to all nodes in the shortest possible time, making it crucial for network discovery protocols such as </st><strong class="bold"><st c="31309">Open Shortest Path </st></strong><span><strong class="bold"><st c="31328">First</st></strong></span><span><st c="31333"> (</st></span><span><strong class="bold"><st c="31335">OSPF</st></strong></span><span><st c="31339">)</st></span></li>
			</ul>
			<p class="calibre3"><st c="31341">These diverse </st><a id="_idIndexMarker883" class="pcalibre pcalibre1 calibre6"/><st c="31355">applications highlight the versatility of BFS, making it a fundamental tool in algorithm design and practical implementations across </st><span><st c="31488">various fields.</st></span></p>
			<p class="calibre3"><st c="31503">In summary, BFS is an essential graph traversal technique, particularly useful when the goal is to explore all nodes level by level or to find the shortest path in unweighted graphs. </st><st c="31687">While it is efficient in terms of time complexity, its higher memory requirements can be a drawback for graphs with large branching factors. </st><st c="31828">BFS’s guaranteed shortest-path property and its versatility in various algorithmic tasks make it a powerful tool in many </st><span><st c="31949">real-world applications.</st></span></p>
			<p class="calibre3"><st c="31973">Before moving </st><a id="_idIndexMarker884" class="pcalibre pcalibre1 calibre6"/><st c="31988">on to the next non-linear data structure, let’s conclude our discussion on graphs by summarizing their significance and applications in algorithm design. </st><st c="32142">Graphs are incredibly versatile structures that allow us to model and solve a wide range of problems in areas such as networking, social analysis, and AI. </st><st c="32297">They can represent complex relationships between entities, and through various algorithms such as BFS and DFS, we can efficiently traverse, search, and process graph data. </st><st c="32469">Graphs play a central role in critical applications such as pathfinding, network routing, cycle detection, and even </st><span><st c="32585">hierarchical problem-solving.</st></span></p>
			<p class="calibre3"><st c="32614">Their importance in algorithm design cannot be overstated, as they form the foundation for solving problems that involve connectivity, optimization, and search strategies in both theoretical and </st><span><st c="32810">practical fields.</st></span></p>
			<h1 id="_idParaDest-177" class="calibre5"><a id="_idTextAnchor206" class="pcalibre pcalibre1 calibre6"/><st c="32827">Trees</st></h1>
			<p class="calibre3"><st c="32833">A </st><strong class="bold"><st c="32836">tree</st></strong><st c="32840"> is a</st><a id="_idIndexMarker885" class="pcalibre pcalibre1 calibre6"/><st c="32845"> hierarchical, non-linear data structure that consists of nodes connected by edges. </st><st c="32929">Trees are widely used in various applications, such as organizing data, databases, network structures, and more. </st><st c="33042">A tree has a single root node and all other nodes are connected in a parent-child relationship. </st><st c="33138">The tree structure ensures that there are no cycles, and each child has exactly </st><span><st c="33218">one parent.</st></span></p>
			<p class="calibre3"><st c="33229">In this section, we will explore different types of trees, their properties, and how to represent trees and </st><a id="_idIndexMarker886" class="pcalibre pcalibre1 calibre6"/><st c="33338">discuss </st><a id="_idIndexMarker887" class="pcalibre pcalibre1 calibre6"/><st c="33346">two important types: </st><strong class="bold"><st c="33367">binary search trees</st></strong><st c="33386"> (</st><strong class="bold"><st c="33388">BSTs</st></strong><st c="33392">) and </st><span><strong class="bold"><st c="33399">red-black trees</st></strong></span><span><st c="33414">.</st></span></p>
			<h2 id="_idParaDest-178" class="calibre5"><a id="_idTextAnchor207" class="pcalibre pcalibre1 calibre6"/><st c="33415">Different types of trees and their properties</st></h2>
			<p class="calibre3"><st c="33461">Trees come in many types, each with unique characteristics suited for different applications. </st><st c="33556">Here are some of the most </st><span><st c="33582">common types:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="33595">General tree</st></strong><st c="33608">: A </st><a id="_idIndexMarker888" class="pcalibre pcalibre1 calibre6"/><st c="33613">general tree is a type of tree where any node can</st><a id="_idIndexMarker889" class="pcalibre pcalibre1 calibre6"/><st c="33662"> have an arbitrary number of children. </st><st c="33701">This type of tree can be used to represent hierarchical data, such as filesystems or organization charts. </st><span><em class="italic"><st c="33807">Figure 13</st></em></span><em class="italic"><st c="33816">.7</st></em><st c="33818"> illustrates an example of a </st><span><st c="33847">general tree.</st></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer1947" class="img---figure">
					<img src="image/B22248_13_7.jpg" alt="Figure 13.7: An example general tree" class="calibre144"/><st c="33860"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="33862">Figure 13.7: An example general tree</st></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="33898">Binary tree</st></strong><st c="33910">: A </st><a id="_idIndexMarker890" class="pcalibre pcalibre1 calibre6"/><st c="33915">binary tree is a type of tree where each node has a</st><a id="_idIndexMarker891" class="pcalibre pcalibre1 calibre6"/><st c="33966"> maximum of </st><a id="_idIndexMarker892" class="pcalibre pcalibre1 calibre6"/><st c="33978">two children, known as the </st><strong class="bold"><st c="34005">left child</st></strong><st c="34015"> and </st><a id="_idIndexMarker893" class="pcalibre pcalibre1 calibre6"/><st c="34020">the </st><strong class="bold"><st c="34024">right child</st></strong><st c="34035">. It is one of the most commonly used tree structures in computer science. </st><st c="34110">In </st><span><em class="italic"><st c="34113">Figure 13</st></em></span><em class="italic"><st c="34122">.7</st></em><st c="34124">, all subtrees rooted at </st><em class="italic"><st c="34149">nodes 1</st></em><st c="34156">, </st><em class="italic"><st c="34158">5</st></em><st c="34159">, and </st><em class="italic"><st c="34165">6</st></em><st c="34166"> are examples of </st><span><st c="34183">binary trees.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="34196">Full binary tree</st></strong><st c="34213">: A </st><a id="_idIndexMarker894" class="pcalibre pcalibre1 calibre6"/><st c="34218">binary tree is considered full if every node has either</st><a id="_idIndexMarker895" class="pcalibre pcalibre1 calibre6"/><st c="34273"> zero or two children. </st><st c="34296">No nodes have only one child. </st><st c="34326">In </st><span><em class="italic"><st c="34329">Figure 13</st></em></span><em class="italic"><st c="34338">.7</st></em><st c="34340">, the subtree rooted at </st><em class="italic"><st c="34364">node 5</st></em><st c="34370"> is a full </st><span><st c="34381">binary tree.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="34393">Complete binary tree</st></strong><st c="34414">: A</st><a id="_idIndexMarker896" class="pcalibre pcalibre1 calibre6"/><st c="34418"> complete binary tree is a </st><a id="_idIndexMarker897" class="pcalibre pcalibre1 calibre6"/><st c="34445">binary tree where all levels are fully filled except possibly the last, which must be filled from left to right. </st><st c="34558">A well-known complete binary tree is a heap structure, which will be discussed at the end of </st><span><st c="34651">this chapter.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="34664">Balanced binary tree</st></strong><st c="34685">: A</st><a id="_idIndexMarker898" class="pcalibre pcalibre1 calibre6"/><st c="34689"> tree is considered balanced if the </st><a id="_idIndexMarker899" class="pcalibre pcalibre1 calibre6"/><st c="34725">heights of the left and right subtrees of any node differ by no more than one. </st><st c="34804">Balanced trees are preferred because they ensure optimal performance for search, insertion, and deletion operations. </st><st c="34921">In </st><span><em class="italic"><st c="34924">Figure 13</st></em></span><em class="italic"><st c="34933">.8</st></em><st c="34935">, the binary tree is </st><span><st c="34956">fully balanced.</st></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer1948" class="img---figure">
					<img src="image/B22248_13_8.jpg" alt="Figure 13.8: A perfectly balanced binary tree" class="calibre144"/><st c="34971"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="34973">Figure 13.8: A perfectly balanced binary tree</st></p>
			<p class="calibre3"><span><em class="italic"><st c="35018">Figure 13</st></em></span><em class="italic"><st c="35028">.9</st></em><st c="35030"> illustrates a counterexample of a non-balanced binary tree. </st><st c="35091">In this tree, the height of the subtrees differs significantly, violating the balanced binary tree property, where the heights of the left and right subtrees of any node should differ by no more than one. </st><st c="35296">This imbalance can lead to inefficient operations such as searching, insertion, and deletion, as the tree structure begins to resemble a </st><span><st c="35433">linear chain.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1949" class="img---figure">
					<img src="image/B22248_13_9.jpg" alt="Figure 13.9: A counterexample of a non-balanced binary tree" class="calibre144"/><st c="35446"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="35448">Figure 13.9: A counterexample of a non-balanced binary tree</st></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="35507">AVL tree</st></strong><st c="35516">: An</st><a id="_idIndexMarker900" class="pcalibre pcalibre1 calibre6"/><st c="35521"> AVL tree (named after inventors Adelson-Velsky and Landis) is a self-balancing binary search tree (BST). </st><st c="35627">It </st><a id="_idIndexMarker901" class="pcalibre pcalibre1 calibre6"/><st c="35630">maintains a balance factor (the difference between the heights of the left and right subtrees) for every node, ensuring that the tree remains balanced after insertions </st><span><st c="35798">and deletions.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="35812">B-tree</st></strong><st c="35819">: A B-tree</st><a id="_idIndexMarker902" class="pcalibre pcalibre1 calibre6"/><st c="35830"> is a self-balancing tree data structure that maintains</st><a id="_idIndexMarker903" class="pcalibre pcalibre1 calibre6"/><st c="35885"> sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. </st><st c="35985">B-trees are commonly used in databases </st><span><st c="36024">and filesystems.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="36040">Red-black tree</st></strong><st c="36055">: A </st><a id="_idIndexMarker904" class="pcalibre pcalibre1 calibre6"/><st c="36060">red-black tree is another type of self-balancing BST. </st><st c="36114">Each </st><a id="_idIndexMarker905" class="pcalibre pcalibre1 calibre6"/><st c="36119">node in the tree is assigned a color (red or black) to ensure that the tree remains balanced, which guarantees better worst-case time complexity for insertions </st><span><st c="36279">and deletions.</st></span></li>
			</ul>
			<p class="calibre3"><st c="36293">Next, we will discuss two common tree representation methods: </st><strong class="bold"><st c="36356">linked representation</st></strong><st c="36377"> and </st><strong class="bold"><st c="36382">array representation</st></strong><st c="36402">. Each method offers different advantages and is suited for specific types of operations and tree structures. </st><st c="36512">By understanding both, we can choose the most efficient representation for a </st><span><st c="36589">given application.</st></span></p>
			<h2 id="_idParaDest-179" class="calibre5"><a id="_idTextAnchor208" class="pcalibre pcalibre1 calibre6"/><st c="36607">Tree representation</st></h2>
			<p class="calibre3"><st c="36627">Trees can be</st><a id="_idIndexMarker906" class="pcalibre pcalibre1 calibre6"/><st c="36640"> represented in several ways, each depending on the use case and complexity of the operations. </st><st c="36735">Let’s explore this </st><span><st c="36754">in detail.</st></span></p>
			<h3 class="calibre8"><st c="36764">Linked representation</st></h3>
			<p class="calibre3"><st c="36786">In the </st><a id="_idIndexMarker907" class="pcalibre pcalibre1 calibre6"/><st c="36794">linked representation of a binary tree, each node contains data and pointers (or references) to its left and right children. </st><st c="36919">This is a more flexible representation than the array representation, as it doesn’t require the tree to be a complete binary tree. </st><st c="37050">Instead, each node directly references its children, allowing for </st><span><st c="37116">irregular structures.</st></span></p>
			<p class="calibre3"><st c="37137">This </st><a id="_idIndexMarker908" class="pcalibre pcalibre1 calibre6"/><st c="37143">representation is commonly used for binary trees and BST, where the nodes can have arbitrary arrangements. </st><st c="37250">Each node in the tree is defined as a class or structure that holds a value and two pointers to its left and right </st><span><st c="37365">child nodes.</st></span></p>
			<p class="calibre3"><st c="37377">The following code is an implementation of a node in Python using the </st><span><st c="37448">linked representation:</st></span></p>
			<pre class="source-code"><st c="37470" class="calibre11">
# Definition of a TreeNode class in Python
class TreeNode:
    def __init__(self, key):
        self.key = key       # Node value
        self.left = None     # Pointer to left child
        self.right = None    # Pointer to right child
# Creating nodes and linking them to form a binary tree
root = TreeNode(10)          # Root node
root.left = TreeNode(5)      # Left child of root
root.right = TreeNode(20)    # Right child of root
# Adding more nodes to the tree
root.left.left = TreeNode(3) # Left child of node with value 5
root.left.right = TreeNode(7) # Right child of node with value 5
root.right.left = TreeNode(15) # Left child of node with value 20
root.right.right = TreeNode(25) # Right child of node with value 20
# Function to perform an in-order traversal of the tree
def inorder_traversal(node):
    if node:
        inorder_traversal(node.left)
        print(node.key, end=' ')
        inorder_traversal(node.right)
# In-order traversal of the tree
print("In-order Traversal:")
inorder_traversal(root)</st></pre>			<p class="calibre3"><st c="38405">Let’s</st><a id="_idIndexMarker909" class="pcalibre pcalibre1 calibre6"/><st c="38411"> explain </st><a id="_idIndexMarker910" class="pcalibre pcalibre1 calibre6"/><st c="38420">the many components of </st><span><st c="38443">the code:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="source-inline1"><st c="38452">TreeNode</st></strong><st c="38461">: Each node contains a value (</st><strong class="source-inline1"><st c="38492">key</st></strong><st c="38496">) and two pointers (</st><strong class="source-inline1"><st c="38517">left</st></strong><st c="38522"> and </st><strong class="source-inline1"><st c="38527">right</st></strong><st c="38532">), which reference the left and right </st><span><st c="38571">children, respectively</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="38593">Creating nodes</st></strong><st c="38608">: We create nodes and link them to form the structure of a </st><span><st c="38668">binary tree</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="38679">In-order traversal</st></strong><st c="38698">: The </st><strong class="source-inline1"><st c="38705">inorder_traversal</st></strong><st c="38722"> function recursively visits the left subtree, the root, and then the right subtree, printing the nodes in a sorted order for </st><span><st c="38848">a BST</st></span><a id="_idTextAnchor209" class="pcalibre pcalibre1 calibre6"/></li>
			</ul>
			<p class="calibre3"><st c="38853">The linked representation works for any type of binary tree, whether it is complete, balanced, or irregular. </st><st c="38963">This approach is especially memory efficient for sparse trees, as memory is only </st><a id="_idIndexMarker911" class="pcalibre pcalibre1 calibre6"/><st c="39044">allocated for the nodes that are actually present. </st><st c="39095">This eliminates the need for continuous memory allocation for non-existent nodes, unlike </st><span><st c="39184">array representation.</st></span></p>
			<p class="calibre3"><st c="39205">Additionally, the</st><a id="_idIndexMarker912" class="pcalibre pcalibre1 calibre6"/><st c="39223"> linked representation is more flexible for dynamic operations such as insertion, deletion, and traversal. </st><st c="39330">Since each node directly references its children, modifying the tree structure is straightforward and doesn’t require reordering or shifting elements, as would be needed in an array-based representation. </st><st c="39534">This makes it ideal for trees that grow or change frequently, such as </st><span><st c="39604">in BSTs.</st></span></p>
			<h3 class="calibre8"><st c="39612">Array representation</st></h3>
			<p class="calibre3"><st c="39633">This </st><a id="_idIndexMarker913" class="pcalibre pcalibre1 calibre6"/><st c="39639">method is commonly used for representing </st><a id="_idIndexMarker914" class="pcalibre pcalibre1 calibre6"/><st c="39680">complete binary trees, such as heap structures. </st><st c="39728">In this approach, a binary tree is stored as an array or list, where the root node is located at index </st><img src="image/1897.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre117"/><st c="39831"/><st c="39832">. For any node at index </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="39856"/><st c="39857">, its children are positioned </st><span><st c="39887">as follows:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="39898">The left child is located at </st><span><st c="39928">index </st></span><span><img src="image/1899.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1397"/><st c="39934"/></span></li>
				<li class="calibre13"><st c="39935">The right child is located at </st><span><st c="39965">index </st></span><span><img src="image/1900.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1397"/><st c="39971"/></span></li>
			</ul>
			<p class="calibre3"><st c="39972">This array-based representation is highly efficient for complete binary trees because it avoids the need for pointers to track the parent-child relationships. </st><st c="40131">It also allows for fast access to children or parents directly by calculating their indices. </st><st c="40224">Here’s a simple Python example demonstrating the array representation of a small complete </st><span><st c="40314">binary tree:</st></span></p>
			<pre class="source-code"><st c="40326" class="calibre11">
# Array representation of a complete binary tree
binary_tree = [10, 5, 20, 3, 7, 15, 25]
# Accessing elements
root = binary_tree[0]
left_child_of_root = binary_tree[2 * 0 + 1]  # index 1
right_child_of_root = binary_tree[2 * 0 + 2]  # index 2
# Display the values
print(f"Root: {root}")
print(f"Left Child of Root: {left_child_of_root}")
print(f"Right Child of Root: {right_child_of_root}")</st></pre>			<p class="calibre3"><st c="40715">This</st><a id="_idIndexMarker915" class="pcalibre pcalibre1 calibre6"/><st c="40720"> array-based structure is ideal for heaps, where</st><a id="_idIndexMarker916" class="pcalibre pcalibre1 calibre6"/><st c="40768"> insertion and deletion operations require efficient reordering to maintain the heap property. </st><st c="40863">The simplicity of the index-based parent-child relationships makes this representation fast and memory-efficient for complete </st><span><st c="40989">binary trees.</st></span></p>
			<h3 class="calibre8"><st c="41002">Parent array representation</st></h3>
			<p class="calibre3"><st c="41030">Another </st><a id="_idIndexMarker917" class="pcalibre pcalibre1 calibre6"/><st c="41039">way </st><a id="_idIndexMarker918" class="pcalibre pcalibre1 calibre6"/><st c="41043">to represent a tree is by storing the parent of each node in an array. </st><st c="41114">In this approach, each index of the array corresponds to a node, and the value at that index represents the parent of that node. </st><st c="41243">The root node is assigned a special value (commonly </st><strong class="source-inline"><st c="41295">-1</st></strong><st c="41297">) to indicate that it has </st><span><st c="41324">no parent.</st></span></p>
			<p class="calibre3"><st c="41334">This representation is particularly useful when we need to reconstruct the tree from parent-child relationships or when the tree is stored in such a way that direct access to child nodes is </st><span><st c="41525">not necessary.</st></span></p>
			<p class="calibre3"><st c="41539">Here is a simple Python implementation for representing a tree using a parent array. </st><st c="41625">The first part is a function to build the tree from a </st><span><st c="41679">parent array:</st></span></p>
			<pre class="source-code"><st c="41692" class="calibre11">
def build_tree(parent_array):
    n = len(parent_array)
    nodes = [None] * n
    root = None
    # Create tree nodes for each index
    for i in range(n):
        nodes[i] = TreeNode(i)
    # Assign parents to each node
    for i in range(n):
        if parent_array[i] == -1:
            root = nodes[i]  # This is the root node
        else:
            parent_node = nodes[parent_array[i]]
            if parent_node.left is None:
                parent_node.left = nodes[i]
            else:
                parent_node.right = nodes[i]
    return root</st></pre>			<p class="calibre3"><st c="42114">Next, we</st><a id="_idIndexMarker919" class="pcalibre pcalibre1 calibre6"/><st c="42123"> define</st><a id="_idIndexMarker920" class="pcalibre pcalibre1 calibre6"/><st c="42130"> the </st><span><strong class="source-inline"><st c="42135">TreeNode</st></strong></span><span><st c="42143"> class:</st></span></p>
			<pre class="source-code"><st c="42150" class="calibre11">
class TreeNode:
    def __init__(self, key):
        self.key = key
        self.left = None
        self.right = None</st></pre>			<p class="calibre3"><st c="42241">Finally, we build an example parent array, where </st><strong class="source-inline"><st c="42291">-1</st></strong><st c="42293"> represents </st><span><st c="42305">the root:</st></span></p>
			<pre class="source-code"><st c="42314" class="calibre11">
parent_array = [-1, 0, 0, 1, 1, 2, 2]
# Build the tree from the parent array
root = build_tree(parent_array)
# Function to perform an in-order traversal of the tree
def inorder_traversal(node):
    if node:
        inorder_traversal(node.left)
        print(node.key, end=' ')
        inorder_traversal(node.right)
# In-order traversal of the tree
print("In-order Traversal:")
inorder_traversal(root)</st></pre>			<p class="calibre3"><st c="42687">Let’s </st><a id="_idIndexMarker921" class="pcalibre pcalibre1 calibre6"/><st c="42694">explain the many components</st><a id="_idIndexMarker922" class="pcalibre pcalibre1 calibre6"/><st c="42721"> of </st><span><st c="42725">the code:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="42734">Parent array</st></strong><st c="42747">: The array represents the parent of each node. </st><st c="42796">For example, if </st><strong class="source-inline1"><st c="42812">parent_array[3] = 1</st></strong><st c="42831">, it means </st><em class="italic"><st c="42842">node 3</st></em><st c="42848"> has </st><em class="italic"><st c="42853">node 1</st></em><st c="42859"> as its parent. </st><st c="42875">The root node has the value </st><strong class="source-inline1"><st c="42903">-1</st></strong><st c="42905">, indicating it has </st><span><st c="42925">no parent.</st></span></li>
				<li class="calibre13"><strong class="source-inline1"><st c="42935">build_tree</st></strong><st c="42946">: We first create an array of nodes and then link each node to its parent using the parent array. </st><st c="43045">The nodes are connected either as the left or right child, depending </st><span><st c="43114">on availability.</st></span></li>
				<li class="calibre13"><strong class="source-inline1"><st c="43130">inorder_traversal</st></strong><st c="43148">: We perform an in-order traversal of the tree to visit the nodes in their </st><span><st c="43224">sorted order.</st></span></li>
			</ul>
			<p class="calibre3"><st c="43237">The parent array representation offers several advantages. </st><st c="43297">One significant benefit is its space efficiency. </st><st c="43346">Since this method only stores the parent-child relationships, it eliminates the need for additional pointers to left and right children, making it a compact structure. </st><st c="43514">This feature makes it particularly suitable for environments where memory </st><span><st c="43588">is limited.</st></span></p>
			<p class="calibre3"><st c="43599">Another advantage is its usefulness in reconstructing a tree from given parent-child relationships, such as those found in filesystems, organization charts, or other hierarchical structures. </st><st c="43791">This method allows for easy and efficient </st><span><st c="43833">tree reconstruction.</st></span></p>
			<p class="calibre3"><st c="43853">Additionally, it is</st><a id="_idIndexMarker923" class="pcalibre pcalibre1 calibre6"/><st c="43873"> efficient in applications where direct access to parent nodes is required. </st><st c="43949">Since each index in the array corresponds to a specific node and stores its parent, retrieving the parent of any node can be done in </st><span><st c="44082">constant time.</st></span></p>
			<p class="calibre3"><st c="44096">Lastly, the </st><a id="_idIndexMarker924" class="pcalibre pcalibre1 calibre6"/><st c="44109">parent array representation is well suited for cases where trees are stored in external memory. </st><st c="44205">It requires minimal data storage, which makes it particularly useful in databases or large-scale systems where the tree structure needs to be reconstructed on demand with</st><a id="_idTextAnchor210" class="pcalibre pcalibre1 calibre6"/><st c="44375">out taking up </st><span><st c="44390">excessive space.</st></span></p>
			<p class="calibre3"><st c="44406">This representation is helpful when working with static tree structures, especially in cases where storing the parent relationships alone suffices for the </st><span><st c="44562">intended operations.</st></span></p>
			<h2 id="_idParaDest-180" class="calibre5"><a id="_idTextAnchor211" class="pcalibre pcalibre1 calibre6"/><st c="44582">BSTs</st></h2>
			<p class="calibre3"><st c="44587">A </st><strong class="bold"><st c="44590">BST</st></strong><st c="44593"> is a </st><a id="_idIndexMarker925" class="pcalibre pcalibre1 calibre6"/><st c="44599">type of binary tree where the nodes are organized in a way that for every node, the left subtree contains only nodes with values less than the node, and the right subtree contains only nodes with values greater than the node. </st><st c="44825">This property makes BSTs efficient for search operations. </st><span><em class="italic"><st c="44883">Figure 13</st></em></span><em class="italic"><st c="44892">.10</st></em><st c="44895"> illustrates a simple BST. </st><st c="44922">The following are</st><a id="_idIndexMarker926" class="pcalibre pcalibre1 calibre6"/><st c="44939"> the properties of </st><span><st c="44958">a BST:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="44964">The left child contains values less than the </st><span><st c="45010">parent node</st></span></li>
				<li class="calibre13"><st c="45021">The right child contains values greater than the </st><span><st c="45071">parent node</st></span></li>
				<li class="calibre13"><st c="45082">In-order traversal of a BST produces a </st><span><st c="45122">sorted sequence</st></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer1954" class="img---figure">
					<img src="image/B22248_13_10.jpg" alt="Figur﻿e 13.10: An example BST" class="calibre144"/><st c="45137"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="45139">Figur</st><a id="_idTextAnchor212" class="pcalibre pcalibre1 calibre6"/><st c="45144">e 13.10: An example BST</st></p>
			<p class="calibre3"><st c="45168">Before exploring</st><a id="_idIndexMarker927" class="pcalibre pcalibre1 calibre6"/><st c="45185"> the operations of a BST, it is important to first understand how to traverse a BST. </st><st c="45270">In a BST, similar to graphs, traversal refers to the process of visiting and processing each node in the tree. </st><st c="45381">There are three common methods of traversal (or tree-walk): in-order, pre-order, and post-order. </st><st c="45478">Each traversal method follows a specific order to visit the nodes, and all of them have the same time complexity of </st><img src="image/995.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre773"/><st c="45594"/><st c="45595"> since each node is visited </st><span><st c="45623">exactly once.</st></span></p>
			<h3 class="calibre8"><st c="45636">In-order traversal</st></h3>
			<p class="calibre3"><strong class="bold"><st c="45655">In-order traversal</st></strong><st c="45674"> visits</st><a id="_idIndexMarker928" class="pcalibre pcalibre1 calibre6"/><st c="45681"> the nodes in the following order: left subtree, root, right subtree. </st><st c="45751">In a BST, an in-order traversal will visit the nodes in sorted order (ascending). </st><st c="45833">The in-order traversal steps are </st><span><st c="45866">as follows:</st></span></p>
			<ol class="calibre12">
				<li class="calibre13"><st c="45877">Traverse the </st><span><st c="45891">left subtree.</st></span></li>
				<li class="calibre13"><st c="45904">Visit the </st><span><st c="45915">root node.</st></span></li>
				<li class="calibre13"><st c="45925">Traverse the </st><span><st c="45939">right subtree.</st></span></li>
			</ol>
			<p class="calibre3"><st c="45953">For the BST shown in </st><span><em class="italic"><st c="45975">Figure 13</st></em></span><em class="italic"><st c="45984">.11</st></em><st c="45987">, we aim to perform an in-order traversal of </st><span><st c="46032">the tree.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1956" class="img---figure">
					<img src="image/B22248_13_11.jpg" alt="Figure 13.11: An example BST" class="calibre144"/><st c="46041"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="46043">Figure 13.11: An example BST</st></p>
			<p class="calibre3"><st c="46071">Here is the Python code for </st><span><st c="46100">in-order traversal:</st></span></p>
			<pre class="source-code"><st c="46119" class="calibre11">
# Definition of TreeNode class
class TreeNode:
    def __init__(self, key):
        self.key = key
        self.left = None
        self.right = None
# Function for in-order traversal
def inorder_traversal(node):
    if node:
        inorder_traversal(node.left)
        print(node.key, end=' ')
        inorder_traversal(node.right)</st></pre>			<p class="calibre3"><st c="46397">First, we build</st><a id="_idIndexMarker929" class="pcalibre pcalibre1 calibre6"/><st c="46413"> the BST using the following </st><span><st c="46442">Python code:</st></span></p>
			<pre class="source-code"><st c="46454" class="calibre11">
# Example: Build the BST
root = TreeNode(22)
root.left = TreeNode(35)
root.right = TreeNode(30)
root.left.left = TreeNode(5)
root.left.right = TreeNode(15)
root.right.left = TreeNode(25)
root.right.right = TreeNode(35)</st></pre>			<p class="calibre3"><st c="46673">Then, we call </st><strong class="source-inline"><st c="46688">inorder_traversal</st></strong><st c="46705"> to perform in-order </st><span><st c="46726">BST traversal:</st></span></p>
			<pre class="source-code"><st c="46740" class="calibre11">
# Perform in-order traversal
print("In-Order Traversal:")
inorder_traversal(root)</st></pre>			<p class="calibre3"><st c="46822">In-order traversal </st><a id="_idIndexMarker930" class="pcalibre pcalibre1 calibre6"/><st c="46842">generates </st><span><st c="46852">the following:</st></span></p>
			<pre class="source-code">
<strong class="source-inline2"><st c="46866" class="calibre11">5 10 15 20 25 30 35</st></strong></pre>			<h3 class="calibre8"><st c="46886">Pre-order traversal</st></h3>
			<p class="calibre3"><strong class="bold"><st c="46906">Pre-order traversal</st></strong><st c="46926"> visits </st><a id="_idIndexMarker931" class="pcalibre pcalibre1 calibre6"/><st c="46934">the nodes in the following order: root, left subtree, right subtree. </st><st c="47003">This method is useful for creating a copy of the tree or for printing the tree structure. </st><st c="47093">The pre-order traversal steps are </st><span><st c="47127">as follows:</st></span></p>
			<ol class="calibre12">
				<li class="calibre13"><st c="47138">Visit the </st><span><st c="47149">root node.</st></span></li>
				<li class="calibre13"><st c="47159">Traverse the </st><span><st c="47173">left subtree.</st></span></li>
				<li class="calibre13"><st c="47186">Traverse the </st><span><st c="47200">right subtree.</st></span></li>
			</ol>
			<p class="calibre3"><st c="47214">The pre-order traversal will visit the nodes in BST of </st><span><em class="italic"><st c="47270">Figure 13</st></em></span><em class="italic"><st c="47279">.11</st></em><st c="47282"> in the following order: </st><strong class="source-inline"><st c="47307">20, 10, 5, 15, 30, </st></strong><span><strong class="source-inline"><st c="47326">25, 35</st></strong></span><span><st c="47332">.</st></span></p>
			<p class="calibre3"><st c="47333">The following is the Python code for </st><span><st c="47371">pre-order traversal:</st></span></p>
			<pre class="source-code"><st c="47391" class="calibre11">
# Function for pre-order traversal
def preorder_traversal(node):
    if node:
        print(node.key, end=' ')
        preorder_traversal(node.left)
        preorder_traversal(node.right)
# Perform pre-order traversal
print("Pre-Order Traversal:")
preorder_traversal(root)</st></pre>			<h3 class="calibre8"><st c="47636">Post-order traversal</st></h3>
			<p class="calibre3"><strong class="bold"><st c="47657">Post-order traversal</st></strong><st c="47678"> visits</st><a id="_idIndexMarker932" class="pcalibre pcalibre1 calibre6"/><st c="47685"> the nodes in the following order: left subtree, right subtree, root. </st><st c="47755">This traversal is often used in applications such as tree deletion, where you must delete the children before deleting the parent node. </st><st c="47891">The post-order traversal steps are </st><span><st c="47926">as follows:</st></span></p>
			<ol class="calibre12">
				<li class="calibre13"><st c="47937">Traverse the </st><span><st c="47951">left subtree.</st></span></li>
				<li class="calibre13"><st c="47964">Traverse the </st><span><st c="47978">right subtree.</st></span></li>
				<li class="calibre13"><st c="47992">Visit the </st><span><st c="48003">root node.</st></span></li>
			</ol>
			<p class="calibre3"><st c="48013">For the example in </st><span><em class="italic"><st c="48033">Figure 13</st></em></span><em class="italic"><st c="48042">.11</st></em><st c="48045">, the post-order traversal will visit the nodes in the following order: </st><strong class="source-inline"><st c="48117">5, 15, 10, 25, 35, </st></strong><span><strong class="source-inline"><st c="48136">30, 20</st></strong></span><span><st c="48142">.</st></span></p>
			<p class="calibre3"><st c="48143">Here is the Python code for </st><span><st c="48172">post-order traversal:</st></span></p>
			<pre class="source-code"><st c="48193" class="calibre11">
# Function for post-order traversal
def postorder_traversal(node):
    if node:
        postorder_traversal(node.left)
        postorder_traversal(node.right)
        print(node.key, end=' ')
# Perform post-order traversal
print("Post-Order Traversal:")
postorder_traversal(root)</st></pre>			<p class="calibre3"><st c="48445">In summary, in-order traversal visits nodes in the sorted order (left, root, right) and is commonly used for</st><a id="_idIndexMarker933" class="pcalibre pcalibre1 calibre6"/><st c="48554"> extracting sorted data from BSTs. </st><st c="48589">Pre-order traversal visits nodes in the order (root, left, right), making it useful for copying the tree structure or printing it. </st><st c="48720">Post-order traversal visits nodes in the order (left, right, root) and is helpful for tasks such as tree deletion, where processing the child before the parent </st><span><st c="48880">is necessary.</st></span></p>
			<p class="calibre3"><st c="48893">In a BST, the main operations – insertion, deletion, and searching – rely on the tree structure and properties. </st><st c="49006">The efficiency of these operations depends heavily on whether the tree is balanced or not. </st><st c="49097">Let’s explore these operations </st><span><st c="49128">in detail.</st></span></p>
			<h3 class="calibre8"><st c="49138">The search operation in a BST</st></h3>
			<p class="calibre3"><st c="49168">Searching</st><a id="_idIndexMarker934" class="pcalibre pcalibre1 calibre6"/><st c="49178"> in a BST leverages the property that the left subtree contains values smaller than the current node and the right subtree contains values larger than the current node. </st><st c="49347">This allows us to effectively halve the search space with each step, similar to </st><span><st c="49427">binary search:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="49441">Average case (balanced tree)</st></strong><st c="49470">: In a balanced BST (such as the one shown in </st><span><em class="italic"><st c="49517">Figure 13</st></em></span><em class="italic"><st c="49526">.6</st></em><st c="49528">), the search</st><a id="_idIndexMarker935" class="pcalibre pcalibre1 calibre6"/><st c="49542"> operation takes </st><img src="image/1246.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1398"/><st c="49559"/><st c="49568"> time. </st><st c="49574">This is because the tree height is logarithmic relative to the number of nodes, and we reduce the search space at </st><span><st c="49688">each level.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="49699">Worst case (unbalanced tree)</st></strong><st c="49728">: If the BST is unbalanced, the search time complexity </st><a id="_idIndexMarker936" class="pcalibre pcalibre1 calibre6"/><st c="49784">can approach </st><img src="image/1201.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1399"/><st c="49797"/><st c="49798">, where the tree starts resembling a linked list. </st><st c="49848">In such cases, the tree height grows linearly with the number of nodes, making </st><span><st c="49927">searches inefficient.</st></span></li>
			</ul>
			<p class="calibre3"><st c="49948">For extreme cases, such as the skewed tree in </st><span><em class="italic"><st c="49995">Figure 13</st></em></span><em class="italic"><st c="50004">.12</st></em><st c="50007">, the search complexity reaches </st><img src="image/1904.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre979"/><st c="50039"/><st c="50040">, where every node has only one child, and the tree degenerates into a </st><span><st c="50111">linear structure.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1960" class="img---figure">
					<img src="image/B22248_13_12.jpg" alt="Figure 13.12: An example of extreme unbalanced BST" class="calibre144"/><st c="50128"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="50130">Figure 13.12: An example of extreme unbalanced BST</st></p>
			<p class="calibre3"><st c="50180">The following</st><a id="_idIndexMarker937" class="pcalibre pcalibre1 calibre6"/><st c="50194"> is a Python implementation of searching in a BST. </st><st c="50245">The first part is the definition of a </st><strong class="source-inline"><st c="50283">TreeNode</st></strong><st c="50291"> class for </st><span><st c="50302">the BST:</st></span></p>
			<pre class="source-code"><st c="50310" class="calibre11">
class TreeNode:
    def __init__(self, key):
        self.key = key
        self.left = None
        self.right = None</st></pre>			<p class="calibre3"><st c="50401">To build the BST, we implement the insertion operation using the </st><strong class="source-inline"><st c="50467">insert</st></strong><st c="50473"> function </st><span><st c="50483">as follows:</st></span></p>
			<pre class="source-code"><st c="50494" class="calibre11">
Function to insert a node in the BST
def insert(node, key):
    # If the tree is empty, return a new node
    if node is None:
        return TreeNode(key)
    # Otherwise, recur down the tree
    if key &lt; node.key:
        node.left = insert(node.left, key)
    else:
        node.right = insert(node.right, key)
    return node</st></pre>			<p class="calibre3"><st c="50776">The </st><strong class="source-inline"><st c="50781">search</st></strong><st c="50787"> operation</st><a id="_idIndexMarker938" class="pcalibre pcalibre1 calibre6"/><st c="50797"> is implemented </st><span><st c="50813">as follows:</st></span></p>
			<pre class="source-code"><st c="50824" class="calibre11">
# Function to search a key in the BST
def search(node, key):
    # Base case: the node is None (key not found) or the key matches the current node's key
    if node is None or node.key == key:
        return node
    # If the key is smaller than the node's key, search the left subtree
    if key &lt; node.key:
        return search(node.left, key)
    # Otherwise, search the right subtree
    return search(node.right, key)</st></pre>			<p class="calibre3"><st c="51208">Let’s create the root node and insert elements into </st><span><st c="51261">the BST:</st></span></p>
			<pre class="source-code"><st c="51269" class="calibre11">
root = None
keys = [20, 10, 30, 5, 15, 25, 35]
for key in keys:
    root = insert(root, key)</st></pre>			<p class="calibre3"><st c="51358">The following shows how to search a key </st><span><st c="51399">in BST:</st></span></p>
			<pre class="source-code"><st c="51406" class="calibre11">
search_key = 25
found_node = search(root, search_key)
# Output the result
if found_node:
    print(f"Key {search_key} found in the BST.")
else:
    print(f"Key {search_key} not found in the BST.")</st></pre>			<p class="calibre3"><st c="51595">Let’s explain the</st><a id="_idIndexMarker939" class="pcalibre pcalibre1 calibre6"/><st c="51613"> important parts of </st><span><st c="51633">the algorithm:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="source-inline1"><st c="51647">TreeNode</st></strong><st c="51656">: Each node in the BST contains a key (the value of the node), and references (</st><strong class="source-inline1"><st c="51736">left</st></strong><st c="51741"> and </st><strong class="source-inline1"><st c="51746">right</st></strong><st c="51751">) to its left and </st><span><st c="51770">right children.</st></span></li>
				<li class="calibre13"><strong class="source-inline1"><st c="51785">insert</st></strong><st c="51792">: The insert function inserts values into the BST. </st><st c="51844">It recursively traverses the tree and inserts the new node in the correct position based on the </st><span><st c="51940">BST property.</st></span></li>
				<li class="calibre13"><strong class="source-inline1"><st c="51953">search</st></strong><st c="51960">: The search function recursively looks for a given key. </st><st c="52018">If the current node’s key matches the key being searched, it returns that node. </st><st c="52098">Otherwise, it continues searching in the left or right subtree based on whether the key is smaller or larger than the current </st><span><st c="52224">node’s key.</st></span></li>
			</ul>
			<p class="calibre3"><st c="52235">The time complexity of searching in a BST depends on how balanced the tree is. </st><st c="52315">In the worst case, the complexity is </st><img src="image/1905.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1400"/><st c="52352"/><st c="52353">, where </st><img src="image/1906.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre1401"/><st c="52361"/><st c="52362"> is the depth of the BST. </st><st c="52388">In an extremely unbalanced case, where the BST essentially forms a linear structure, the time complexity becomes </st><img src="image/1907.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1402"/><st c="52501"/><st c="52502">. However, in a fully balanced BST, the time complexity is </st><img src="image/1908.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1403"/><st c="52561"/><st c="52569">, ensuring more </st><span><st c="52585">efficient searches.</st></span></p>
			<h3 class="calibre8"><st c="52604">The insertion operation in a BST</st></h3>
			<p class="calibre3"><st c="52637">The </st><strong class="bold"><st c="52642">insertion operation</st></strong><st c="52661"> in a </st><a id="_idIndexMarker940" class="pcalibre pcalibre1 calibre6"/><st c="52667">BST follows the same logic as searching. </st><st c="52708">Starting from the root, we compare the value to be inserted with the current node and move left if it’s smaller or right if it’s larger. </st><st c="52845">Onc</st><a id="_idTextAnchor213" class="pcalibre pcalibre1 calibre6"/><st c="52848">e we find an appropriate empty spot (</st><strong class="source-inline"><st c="52886">null</st></strong><st c="52891">), the new node is </st><span><st c="52911">inserted there.</st></span></p>
			<p class="calibre3"><st c="52926">Let’s briefly discuss the complexity of insertion in a BST: Similar to searching, the time complexity of insertion in a BST depends on its balance. </st><st c="53075">In the worst case, when the tree is highly unbalanced and resembles a linear structure, the time complexity is </st><img src="image/1909.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1404"/><st c="53186"/><st c="53187">, where </st><img src="image/322.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre279"/><st c="53195"/><st c="53196"> is the</st><a id="_idIndexMarker941" class="pcalibre pcalibre1 calibre6"/><st c="53203"> number of nodes. </st><st c="53221">In contrast, in a balanced BST, the time complexity is </st><img src="image/1908.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1403"/><st c="53276"/><st c="53284">, as the insertion operation involves traversing the </st><span><st c="53337">tree’s height:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="53351">Average case (balanced tree)</st></strong><st c="53380">: In a balanced BST, insertion takes </st><img src="image/1912.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1405"/><st c="53418"/><st c="53427"> time on</st><a id="_idTextAnchor214" class="pcalibre pcalibre1 calibre6"/><st c="53434"> average, as we are essentially performing a search to find the appropriate location to insert the </st><span><st c="53533">new node</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="53541">Worst case (unbalanced tree)</st></strong><st c="53570">: Similar to searching, if the BST is unbalanced, insertion time can degrade to </st><img src="image/49.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1406"/><st c="53651"/><st c="53668">, particularly if the values being inserted cause the tree to </st><span><st c="53730">become skewed</st></span></li>
			</ul>
			<p class="calibre3"><st c="53743">In the Python code provided for the search algorithm, the </st><strong class="source-inline"><st c="53802">insert</st></strong><st c="53808"> function is responsible for inserting nodes into the BST while maintaining the BST property. </st><st c="53902">It works recursively to find the correct position for the </st><span><st c="53960">new node.</st></span></p>
			<p class="calibre3"><st c="53969">Let’s see how the </st><strong class="source-inline"><st c="53988">insert</st></strong><st c="53994"> function works. </st><st c="54011">If the tree is empty (i.e., the current node is </st><strong class="source-inline"><st c="54059">None</st></strong><st c="54063">), the function creates a new node with the given key and returns it, effectively making it the root or a leaf. </st><st c="54176">If the key to be inserted is smaller than the current node’s key, the function recursively moves to the left subtree to find the appropriate position. </st><st c="54327">If the key to be inserted is larger than the current node’s key, it recursively moves to the right subtree. </st><st c="54435">Once the appropriate position is found, the new node is added as either the left or </st><span><st c="54519">right child.</st></span></p>
			<p class="calibre3"><st c="54531">Here is a simple Python code implementing insertion in </st><span><st c="54587">a BST:</st></span></p>
			<pre class="source-code"><st c="54593" class="calibre11">
# Function to insert a node in the BST
def insert(node, key):
    # If the tree is empty, return a new node
    if node is None:
        return TreeNode(key)
    # Otherwise, recur down the tree
    if key &lt; node.key:
        node.left = insert(node.left, key)
    else:
        node.right = insert(node.right, key)
    return node</st></pre>			<p class="calibre3"><st c="54877">For example, if we insert the values </st><strong class="source-inline"><st c="54915">20</st></strong><st c="54917">, </st><strong class="source-inline"><st c="54919">10</st></strong><st c="54921">, </st><strong class="source-inline"><st c="54923">30</st></strong><st c="54925">, </st><strong class="source-inline"><st c="54927">5</st></strong><st c="54928">, </st><strong class="source-inline"><st c="54930">15</st></strong><st c="54932">, </st><strong class="source-inline"><st c="54934">25</st></strong><st c="54936">, and </st><strong class="source-inline"><st c="54942">35</st></strong><st c="54944"> using this </st><strong class="source-inline"><st c="54956">insert</st></strong><st c="54962"> function, it will create the BST depicted in </st><span><em class="italic"><st c="55008">Figure 13</st></em></span><em class="italic"><st c="55017">.13</st></em><st c="55020">. </st></p>
			<div class="calibre2">
				<div id="_idContainer1970" class="img---figure">
					<img src="image/B22248_13_13.jpg" alt="Figure 13.13: The final BST representing [20, 10, 30, 5, 15, 25, 35]" class="calibre144"/><st c="55022"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="55023">Figure 13.13: The final BST representing [20, 10, 30, 5, 15, 25, 35]</st></p>
			<p class="calibre3"><st c="55091">The </st><a id="_idIndexMarker942" class="pcalibre pcalibre1 calibre6"/><st c="55096">insertion of the value </st><strong class="source-inline"><st c="55119">35</st></strong><st c="55121"> is highlighted in the tree. </st><st c="55150">When inserting </st><strong class="source-inline"><st c="55165">35</st></strong><st c="55167">, first, it is compared with the root node, </st><strong class="source-inline"><st c="55211">20</st></strong><st c="55213">. Since </st><strong class="source-inline"><st c="55221">35</st></strong><st c="55223"> is greater than </st><strong class="source-inline"><st c="55240">20</st></strong><st c="55242">, we move to the right subtree. </st><st c="55274">Next, </st><strong class="source-inline"><st c="55280">35</st></strong><st c="55282"> is compared with the node </st><strong class="source-inline"><st c="55309">30</st></strong><st c="55311">. Since </st><strong class="source-inline"><st c="55319">35</st></strong><st c="55321"> is greater than </st><strong class="source-inline"><st c="55338">30</st></strong><st c="55340">, it will be inserted as the right child of node </st><strong class="source-inline"><st c="55389">30</st></strong><st c="55391">. The key comparison process ensures that </st><strong class="source-inline"><st c="55433">35</st></strong><st c="55435"> is placed correctly in the BST according to the BST property, where values in the right subtree are greater than the </st><span><st c="55553">parent node.</st></span></p>
			<p class="calibre3"><st c="55565">As a summary, the </st><strong class="source-inline"><st c="55584">insert</st></strong><st c="55590"> function ensures that each new value is placed in the correct position in the tree by comparing it to the existing node values. </st><st c="55719">It maintains in the BST property that all values in the left subtree are smaller than the parent node, and all values in the right subtree </st><span><st c="55858">are larger.</st></span></p>
			<h3 class="calibre8"><st c="55869">The deletion operation in a BST</st></h3>
			<p class="calibre3"><st c="55901">In a BST, the </st><a id="_idIndexMarker943" class="pcalibre pcalibre1 calibre6"/><st c="55916">deletion operation is more complex than the insertion operation because we need to maintain the BST property after removing a node. </st><st c="56048">There are three possible cases to consider when deleting </st><span><st c="56105">a node:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="56112">Deleting a leaf node</st></strong><st c="56133">: A node with no children can be </st><span><st c="56167">directly removed.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="56184">Deleting a node with one child</st></strong><st c="56215">: The node is replaced by </st><span><st c="56242">its child.</st></span></li>
				<li class="calibre13"><strong class="bold"><st c="56252">Deleting a node with two children</st></strong><st c="56286">: The node is replaced by either its in-order predecessor (the largest node in the left subtree) or its in-order successor (the smallest node in the right subtree). </st><st c="56452">After replacement, the node from which the replacement came must also </st><span><st c="56522">be removed.</st></span></li>
			</ul>
			<p class="calibre3"><st c="56533">The</st><a id="_idIndexMarker944" class="pcalibre pcalibre1 calibre6"/><st c="56537"> following is the Python code that implements the deletion operation in a BST. </st><st c="56616">First, we must define the </st><strong class="source-inline"><st c="56642">TreeNode</st></strong><st c="56650"> class (refer to previous examples). </st><st c="56687">Next, we need to construct the tree using the </st><strong class="source-inline"><st c="56733">insert</st></strong><st c="56739"> function that was discussed earlier. </st><st c="56777">Next, we implement the </st><strong class="source-inline"><st c="56800">min_value_node</st></strong><st c="56814"> function to find the successor when a node </st><span><st c="56858">is deleted:</st></span></p>
			<pre class="source-code"><st c="56869" class="calibre11">
# Function to find the minimum value node in the right subtree (in-order successor)
def min_value_node(node):
    current = node
    while current.left is not None:
        current = current.left
    return current</st></pre>			<p class="calibre3"><st c="57064">Lastly, we have </st><strong class="source-inline"><st c="57081">delete_node</st></strong><st c="57092"> to implement the three cases of the deletion operation </st><span><st c="57148">in BSTs:</st></span></p>
			<pre class="source-code"><st c="57156" class="calibre11">
# Function to delete a node from the BST
def delete_node(root, key):
    # Base case: the tree is empty
    if root is None:
        return root
    # If the key to be deleted is smaller than the root's key, go to the left subtree
    if key &lt; root.key:
        root.left = delete_node(root.left, key)
    # If the key to be deleted is greater than the root's key, go to the right subtree
    elif key &gt; root.key:
        root.right = delete_node(root.right, key)
    # If key is equal to the root's key, this is the node to be deleted
    else:
        # Case 1: Node with only one child or no child
        if root.left is None:
            return root.right
        elif root.right is None:
            return root.left
        # Case 2: Node with two children
        # Get the in-order successor (smallest in the right subtree)
        temp = min_value_node(root.right)
        # Replace the current node's key with the in-order successor's key
        root.key = temp.key
        # Delete the in-order successor
        root.right = delete_node(root.right, temp.key)
    return root</st></pre>			<p class="calibre3"><st c="58081">The </st><a id="_idIndexMarker945" class="pcalibre pcalibre1 calibre6"/><st c="58086">following is an example of constructing a BST using the </st><strong class="source-inline"><st c="58142">insert</st></strong><st c="58148"> function and then deleting the node with the </st><span><st c="58194">value </st></span><span><strong class="source-inline"><st c="58200">30</st></strong></span><span><st c="58202">:</st></span></p>
			<pre class="source-code"><st c="58204" class="calibre11">
# Create a BST and insert values into it
root = None
keys = [20, 10, 30, 5, 15, 25, 35]
for key in keys:
    root = insert(root, key)
# Delete a node from the BST
delete_key = 30
root = delete_node(root, delete_key)
# Function to perform in-order traversal
def inorder_traversal(node):
    if node:
        inorder_traversal(node.left)
        print(node.key, end=' ')
        inorder_traversal(node.right)
# Perform in-order traversal after deletion
print("In-order Traversal after Deletion:")
inorder_traversal(root)</st></pre>			<p class="calibre3"><st c="58691">Let’s explain</st><a id="_idIndexMarker946" class="pcalibre pcalibre1 calibre6"/><st c="58705"> the example. </st><st c="58719">We first compare </st><em class="italic"><st c="58736">node 30</st></em><st c="58743"> with the root </st><em class="italic"><st c="58758">node 20</st></em><st c="58765">. Since 30 is greater than 20, we move to the right subtree. </st><st c="58826">We find </st><em class="italic"><st c="58834">node 30</st></em><st c="58841"> and notice that it has two children (</st><em class="italic"><st c="58879">nodes 25</st></em><st c="58888"> and </st><em class="italic"><st c="58893">35</st></em><st c="58895">). </st><st c="58899">We replace </st><em class="italic"><st c="58910">node 30</st></em><st c="58917"> with its in-order successor, </st><em class="italic"><st c="58947">node 35</st></em><st c="58954">, and then remove </st><em class="italic"><st c="58972">node 35</st></em><st c="58979"> from its original position. </st><span><em class="italic"><st c="59008">Figure 13</st></em></span><em class="italic"><st c="59017">.14</st></em><st c="59020"> demonstrates the BST after removing </st><span><em class="italic"><st c="59057">node 35</st></em></span><span><st c="59064">.</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1971" class="img---figure">
					<img src="image/B22248_13_14.jpg" alt="Figure 13.14: The BST in Figure 13.9 after removing 35" class="calibre144"/><st c="59065"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="59067">Figure 13.14: The BST in Figure 13.9 after removing 35</st></p>
			<p class="calibre3"><st c="59121">The time complexity of deletion in BSTs is </st><img src="image/1914.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1407"/><st c="59165"/><st c="59174"> on average, which occurs when the tree is balanced since we only need to traverse the tree’s height to locate and delete the node. </st><st c="59305">However, in the worst case, the time complexity is </st><img src="image/1011.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1408"/><st c="59356"/><st c="59357">, particularly when the tree is unbalanced and takes the form of a </st><span><st c="59424">linked list.</st></span></p>
			<p class="calibre3"><st c="59436">In the next section, we will explore heap structures, which play a crucial role in sorting algorithms and other applications requiring efficient </st><span><st c="59582">data management.</st></span></p>
			<h1 id="_idParaDest-181" class="calibre5"><a id="_idTextAnchor215" class="pcalibre pcalibre1 calibre6"/><st c="59598">Heaps</st></h1>
			<p class="calibre3"><st c="59604">A </st><strong class="bold"><st c="59607">heap</st></strong><st c="59611"> is a</st><a id="_idIndexMarker947" class="pcalibre pcalibre1 calibre6"/><st c="59616"> special type of binary tree that satisfies the heap property. </st><st c="59679">In a heap, the parent node always follows a specific order relation with respect to its children. </st><st c="59777">Heaps are commonly used in various algorithms, especially in sorting and priority queues, due to their e</st><a id="_idTextAnchor216" class="pcalibre pcalibre1 calibre6"/><st c="59881">fficient access to the minimum or </st><span><st c="59916">maximum element.</st></span></p>
			<p class="calibre3"><st c="59932">There are two main types of heaps, based on the order property </st><span><st c="59996">they follow:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><strong class="bold"><st c="60008">Max-heap</st></strong><st c="60017">: In a </st><a id="_idIndexMarker948" class="pcalibre pcalibre1 calibre6"/><st c="60025">max-heap, each node’s value is greater than or equal to the values of its children, with the largest element positioned at the root. </st><st c="60158">Max-heaps are commonly used in algorithms that need efficient access to the maximum element, such as heapsort and priority queue implementations. </st><st c="60304">In max-heap, the heap property is as </st><span><st c="60341">follows: </st></span><span><img src="image/1916.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;T&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;y&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;p&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;q&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;u&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;t&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;h&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;e&lt;/mi&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1409"/><st c="60350"/></span><ul class="calibre50"><li class="calibre13"><img src="image/1917.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;≥&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mfenced open=&quot;[&quot; close=&quot;]&quot;&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1410"/><st c="60370"/><st c="60390">(</st><span><st c="60391">left child)</st></span></li><li class="calibre13"><img src="image/1918.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;≥&lt;/mml:mo&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1411"/><st c="60402"/><st c="60419"> (right child), where </st><img src="image/1033.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre797"/><st c="60440"/><st c="60441"> is the array representation of </st><span><st c="60473">the heap</st></span></li></ul></li>
				<li class="calibre13"><strong class="bold"><st c="60481">Min-heap</st></strong><st c="60490">: In a min-heap, the </st><a id="_idIndexMarker949" class="pcalibre pcalibre1 calibre6"/><st c="60512">value of each node is less than or equal to the values of its children. </st><st c="60584">The smallest element is always at the root. </st><st c="60628">Min-heaps are commonly used in algorithms such as Dijkstra’s shortest path and Prim’s minimum spanning tree. </st><st c="60737">In this case, the heap property is as follows: For each node </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="60798"/><st c="60799">, this is </st><span><st c="60809">the case:</st></span><ul class="calibre50"><li class="calibre13"><img src="image/1921.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;≤&lt;/mml:mo&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1411"/><st c="60818"/><st c="60839"> (</st><span><st c="60840">left child)</st></span></li><li class="calibre13"><img src="image/1922.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;≤&lt;/mml:mo&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mfenced open=&quot;[&quot; close=&quot;]&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1411"/><st c="60851"/><st c="60869"> (</st><span><st c="60870">right child)</st></span></li></ul></li>
			</ul>
			<p class="calibre3"><st c="60882">Heaps are typically represented as complete binary trees stored in an array. </st><st c="60960">In a complete binary tree, this is </st><span><st c="60995">the case:</st></span></p>
			<ul class="calibre14">
				<li class="calibre13"><st c="61004">The root node is at </st><span><st c="61025">index 0</st></span></li>
				<li class="calibre13"><st c="61032">For a node at index </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="61053"/><st c="61054">, the left child is at index </st><img src="image/1899.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1397"/><st c="61083"/><st c="61084">, and the right child is at </st><span><st c="61112">index </st></span><span><img src="image/1900.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1397"/><st c="61118"/></span></li>
				<li class="calibre13"><st c="61119">The parent of a node at index </st><img src="image/701.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre553"/><st c="61149"/><st c="61150"> is located </st><span><st c="61162">at </st></span><span><img src="image/1927.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mtext&gt;floor&lt;/mml:mtext&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;/&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" class="calibre1412"/><st c="61165"/></span></li>
			</ul>
			<p class="calibre3"><st c="61182">This array representation allows heaps to be efficiently stored in memory without using pointers for the child nodes (see </st><span><em class="italic"><st c="61304">Figure 13</st></em></span><span><em class="italic"><st c="61313">.15</st></em></span><span><st c="61316">).</st></span></p>
			<div class="calibre2">
				<div id="_idContainer1986" class="img---figure">
					<img src="image/B22248_13_15.jpg" alt="Figure 13.15: An example max-heap" class="calibre144"/><st c="61319"/>
				</div>
			</div>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="61321">Figure 13.15: An example max-heap</st></p>
			<table id="table001-7" class="t---table">
				<colgroup class="calibre51">
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
					<col class="calibre52"/>
				</colgroup>
				<tbody class="calibre54">
					<tr class="t---table1">
						<td class="t---table2">
							<p class="calibre3"><span><strong class="bold"><st c="61354">Index</st></strong></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61360">1</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61362">2</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61363">3</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61364">4</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61365">5</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61366">6</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61367">7</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61368">8</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61369">9</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61370">10</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61372">11</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61375">12</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61378">13</st></span></p>
						</td>
					</tr>
					<tr class="t---table1">
						<td class="t---table2">
							<p class="calibre3"><span><strong class="bold"><st c="61381">node</st></strong></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61386">98</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61389">81</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61392">86</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61395">63</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61398">21</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61401">68</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61404">18</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61407">10</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61410">51</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61413">4</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61415">14</st></span></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><st c="61417">1</st></p>
						</td>
						<td class="t---table2">
							<p class="calibre3"><span><st c="61419">50</st></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption1" lang="en-US" xml:lang="en-US"><st c="61421">Figure 13.16: The array representation of the max-heap in Figure 13.15</st></p>
			<p class="calibre3"><st c="61492">Now that we have</st><a id="_idIndexMarker950" class="pcalibre pcalibre1 calibre6"/><st c="61509"> learned about the heap property and heap representation, let’s explore the operation </st><span><st c="61595">on heaps.</st></span></p>
			<h2 id="_idParaDest-182" class="calibre5"><a id="_idTextAnchor217" class="pcalibre pcalibre1 calibre6"/><st c="61604">Heap operations</st></h2>
			<p class="calibre3"><st c="61620">The </st><a id="_idIndexMarker951" class="pcalibre pcalibre1 calibre6"/><st c="61625">primary operations on heaps are </st><em class="italic"><st c="61657">insertion</st></em><st c="61666">, </st><em class="italic"><st c="61668">deletion</st></em><st c="61676">, and </st><em class="italic"><st c="61682">heapify</st></em><st c="61689"> (used for maintaining the heap property). </st><st c="61732">Each of these operations relies on the heap property to ensure that the structure remains a </st><span><st c="61824">valid heap.</st></span></p>
			<h3 class="calibre8"><st c="61835">Insertion in a heap</st></h3>
			<p class="calibre3"><st c="61855">To insert an element</st><a id="_idIndexMarker952" class="pcalibre pcalibre1 calibre6"/><st c="61876"> into a heap, we first add the element at the last position in the array (the end of the heap). </st><st c="61972">Then, we perform a </st><strong class="source-inline"><st c="61991">heapify-up</st></strong><st c="62001"> operation, which involves comparing the inserted element with its parent. </st><st c="62076">If the heap property is violated, we swap the two. </st><st c="62127">This process is repeated until the heap property </st><span><st c="62176">is restored.</st></span></p>
			<p class="calibre3"><st c="62188">Here is the Python code for insertion in </st><span><st c="62230">a max-heap:</st></span></p>
			<pre class="source-code"><st c="62241" class="calibre11">
def heapify_up(heap, index):
    parent = (index - 1) // 2
    if index &gt; 0 and heap[parent] &lt; heap[index]:
        # Swap the parent and current node
        heap[parent], heap[index] = heap[index], heap[parent]
        # Recursively heapify the parent node
        heapify_up(heap, parent)
def insert_max_heap(heap, element):
    heap.append(element)
    heapify_up(heap, len(heap) - 1)</st></pre>			<p class="calibre3"><st c="62582">The</st><a id="_idIndexMarker953" class="pcalibre pcalibre1 calibre6"/><st c="62586"> following is an example of building </st><span><st c="62623">a max-heap:</st></span></p>
			<pre class="source-code"><st c="62634" class="calibre11">
# Example usage
heap = []
insert_max_heap(heap, 20)
insert_max_heap(heap, 15)
insert_max_heap(heap, 30)
insert_max_heap(heap, 5)
insert_max_heap(heap, 40)
print("Heap after insertions:", heap)</st></pre>			<p class="calibre3"><st c="62827">The time complexity for insertion is </st><img src="image/1928.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1413"/><st c="62865"/><st c="62874">, as we may need to swap elements up the tree to restore the </st><span><st c="62935">heap property.</st></span></p>
			<h3 class="calibre8"><st c="62949">Deletion in a heap</st></h3>
			<p class="calibre3"><st c="62968">In a heap, deletion</st><a id="_idIndexMarker954" class="pcalibre pcalibre1 calibre6"/><st c="62988"> typically involves removing the root element (the maximum in a max-heap or the minimum in a min-heap). </st><st c="63092">The deletion process is performed in </st><span><st c="63129">three steps:</st></span></p>
			<ol class="calibre12">
				<li class="calibre13"><st c="63141">Replace the root element with the last element in </st><span><st c="63192">the array.</st></span></li>
				<li class="calibre13"><st c="63202">Remove the last element from </st><span><st c="63232">the array.</st></span></li>
				<li class="calibre13"><st c="63242">The process of heapifying down the root element involves comparing it with its children. </st><st c="63332">In cases where the heap property is violated, a swap occurs between the root and the largest child for a max-heap or the smallest child for a min-heap. </st><st c="63484">This continues until the heap property </st><span><st c="63523">is restored.</st></span></li>
			</ol>
			<p class="calibre3"><st c="63535">Here is a</st><a id="_idIndexMarker955" class="pcalibre pcalibre1 calibre6"/><st c="63545"> simple Python code for deletion in </st><span><st c="63581">a max-heap:</st></span></p>
			<pre class="source-code"><st c="63592" class="calibre11">
def heapify_down(heap, index):
    largest = index
    left = 2 * index + 1
    right = 2 * index + 2
    if left &lt; len(heap) and heap[left] &gt; heap[largest]:
        largest = left
    if right &lt; len(heap) and heap[right] &gt; heap[largest]:
        largest = right
    if largest != index:
        heap[index], heap[largest] = heap[largest], heap[index]
        heapify_down(heap, largest)
def delete_max_heap(heap):
    if len(heap) == 0:
        return None
    if len(heap) == 1:
        return heap.pop()
    root = heap[0]
    heap[0] = heap.pop()  # Move last element to the root
    heapify_down(heap, 0)  # Restore heap property
    return root</st></pre>			<p class="calibre3"><st c="64145">Let’s have an </st><a id="_idIndexMarker956" class="pcalibre pcalibre1 calibre6"/><st c="64160">example max-heap and delete the root </st><span><st c="64197">using </st></span><span><strong class="source-inline"><st c="64203">delete_max_heap</st></strong></span><span><st c="64218">:</st></span></p>
			<pre class="source-code"><st c="64220" class="calibre11">
heap = [40, 30, 20, 5, 15]
deleted = delete_max_heap(heap)
print("Heap after deletion of max element:", heap)</st></pre>			<p class="calibre3"><st c="64330">The heap after the deletion of a max element is </st><strong class="source-inline"><st c="64379">[30, 15, </st></strong><span><strong class="source-inline"><st c="64388">20, 5]</st></strong></span><span><st c="64394">.</st></span></p>
			<p class="calibre3"><st c="64395">The time complexity for deletion is </st><img src="image/1929.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1414"/><st c="64432"/><st c="64441">, as we may need to swap elements down the tree to restore the </st><span><st c="64504">heap property.</st></span></p>
			<h3 class="calibre8"><st c="64518">Heapify (building a heap)</st></h3>
			<p class="calibre3"><st c="64544">To build a </st><a id="_idIndexMarker957" class="pcalibre pcalibre1 calibre6"/><st c="64556">heap from an arbitrary array, we use the heapify process. </st><st c="64614">Starting from the first non-leaf node, we move up to the root, ensuring the heap property is maintained. </st><st c="64719">Consider the following Python implementation </st><span><st c="64764">of </st></span><span><strong class="source-inline"><st c="64767">heapify</st></strong></span><span><st c="64774">:</st></span></p>
			<pre class="source-code"><st c="64776" class="calibre11">
def heapify(heap, n, i):
    largest = i
    left = 2 * i + 1
    right = 2 * i + 2
    if left &lt; n and heap[left] &gt; heap[largest]:
        largest = left
    if right &lt; n and heap[right] &gt; heap[largest]:
        largest = right
    if largest != i:
        heap[i], heap[largest] = heap[largest], heap[i]
        heapify(heap, n, largest)</st></pre>			<p class="calibre3"><st c="65060">As we</st><a id="_idIndexMarker958" class="pcalibre pcalibre1 calibre6"/><st c="65066"> can see, the </st><strong class="source-inline"><st c="65080">heapify</st></strong><st c="65087"> function recursively calls itself to ensure that the heap property is maintained throughout the tree. </st><st c="65190">If a violation of the heap property is detected at any node, </st><strong class="source-inline"><st c="65251">heapify</st></strong><st c="65258"> continues down the tree, correcting the structure by comparing and swapping nodes as needed, until the property is </st><span><st c="65374">fully restored.</st></span></p>
			<p class="calibre3"><st c="65389">The following is a Python code to build a max-heap using the </st><strong class="source-inline"><st c="65451">heapify</st></strong> <span><st c="65458">recursive algorithm:</st></span></p>
			<pre class="source-code"><st c="65479" class="calibre11">
def build_max_heap(a):
    n = len(a)
    # Start from the first non-leaf node and heapify each node
    for i in range(n // 2 - 1, -1, -1):
        heapify(a, n, i)</st></pre>			<p class="calibre3"><st c="65625">The following is a simple example of a </st><span><strong class="source-inline"><st c="65665">build_max_heap</st></strong></span><span><st c="65679"> usage:</st></span></p>
			<pre class="source-code"><st c="65686" class="calibre11">
arr = [5, 15, 20, 30, 40]
build_max_heap(a)
print("Array after building max-heap:", a)</st></pre>			<p class="calibre3"><st c="65773">The </st><strong class="source-inline"><st c="65778">a</st></strong><st c="65779"> array representing the max-heap after building the max-heap is </st><strong class="source-inline"><st c="65843">[40, 30, 20, </st></strong><span><strong class="source-inline"><st c="65856">5, 15]</st></strong></span><span><st c="65862">.</st></span></p>
			<p class="calibre3"><st c="65863">The time complexity for building a heap is </st><img src="image/1930.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1415"/><st c="65907"/><st c="65908"> since each node requires at most </st><img src="image/1931.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1416"/><st c="65942"/><st c="65951"> swaps, but most nodes are near the bottom of the tree and need </st><span><st c="66014">fewer swaps.</st></span></p>
			<p class="calibre3"><st c="66026">Let’s explore a major application of heap </st><span><st c="66069">structures: heapsort.</st></span></p>
			<h2 id="_idParaDest-183" class="calibre5"><a id="_idTextAnchor218" class="pcalibre pcalibre1 calibre6"/><st c="66090">Heapsort</st></h2>
			<p class="calibre3"><strong class="bold"><st c="66099">Heapsort</st></strong><st c="66108"> is an </st><a id="_idIndexMarker959" class="pcalibre pcalibre1 calibre6"/><st c="66115">efficient comparison-based sorting algorithm that leverages the heap data structure, particularly the max-heap, to sort elements in </st><img src="image/1010.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1417"/><st c="66247"/><st c="66258"> time. </st><st c="66264">It works by first converting the input array into a max-heap and then repeatedly extracting the largest element (the root of the heap) to build the sorted output. </st><st c="66427">This process ensures that the elements are sorted in ascending order. </st><st c="66497">The following outlines </st><a id="_idIndexMarker960" class="pcalibre pcalibre1 calibre6"/><st c="66520">the steps involved in </st><span><st c="66542">performing heapsort:</st></span></p>
			<ol class="calibre12">
				<li class="calibre13"><st c="66562">Build a max-heap from the </st><span><st c="66589">input array.</st></span></li>
				<li class="calibre13"><st c="66601">Swap the root (maximum element) with the </st><span><st c="66643">last element.</st></span></li>
				<li class="calibre13"><st c="66656">Reduce the heap size by one and </st><strong class="source-inline1"><st c="66689">heapify</st></strong><st c="66696"> the </st><span><st c="66701">root element.</st></span></li>
				<li class="calibre13"><st c="66714">Repeat the process until the heap </st><span><st c="66749">is empty.</st></span></li>
			</ol>
			<p class="calibre3"><st c="66758">Here is the Python implementation </st><span><st c="66793">of heapsort:</st></span></p>
			<pre class="source-code"><st c="66805" class="calibre11">
def heapsort(arr):
    n = len(arr)
    build_max_heap(arr)  # Step 1: Build a max-heap
    for i in range(n - 1, 0, -1):
        arr[0], arr[i] = arr[i], arr[0]  # Step 2: Swap root with last element
        heapify(arr, i, 0)  # Step 3: Heapify the reduced heap</st></pre>			<p class="calibre3"><st c="67038">Let’s examine the heapsort algorithm in </st><span><st c="67079">an example:</st></span></p>
			<pre class="source-code"><st c="67090" class="calibre11">
a = [5, 15, 20, 30, 40]
heapsort(arr)
print("Sorted array:", arr)</st></pre>			<p class="calibre3"><st c="67156">The output will be </st><span><st c="67176">as follows:</st></span></p>
			<pre class="source-code">
<strong class="source-inline2"><st c="67187" class="calibre11">Sorted array: [5, 15, 20, 30, 40]</st></strong></pre>			<p class="calibre3"><st c="67221">The time</st><a id="_idIndexMarker961" class="pcalibre pcalibre1 calibre6"/><st c="67230"> complexity of heapsort is </st><img src="image/1084.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1418"/><st c="67257"/><st c="67268">, as building the heap takes </st><img src="image/1071.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre1419"/><st c="67297"/><st c="67298">, and each extraction of the maximum (in a max-heap) or minimum (in a min-heap) requires </st><img src="image/1047.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre810"/><st c="67387"/><st c="67396"> over </st><img src="image/1271.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:math&gt;" class="calibre967"/><st c="67401"/><st c="67402"> elements. </st><st c="67413">As discussed and demonstrated in </st><a href="B22248_06.xhtml#_idTextAnchor081" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><st c="67446">Chapter 6</st></em></span></a><st c="67455">, the time complexity of heapsort cannot be better than </st><img src="image/1937.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre1420"/><st c="67511"/><st c="67522"> because it is a comparison-based sorting algorithm, which imposes a lower bound on the time complexity for such algorithms. </st><st c="67646">Heapsort is an in-place sorting algorithm and its space complexity </st><span><st c="67713">is </st></span><span><img src="image/1046.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:math&gt;" class="calibre809"/><st c="67716"/></span><span><st c="67717">.</st></span></p>
			<p class="calibre3"><st c="67718">With the heap structure, we conclude our discussion on non-linear data structures. </st><st c="67802">This chapter has provided key highlights of this important class of data structures, but it is not meant to serve as a comprehensive replacement for a dedicated book on data structures. </st><st c="67988">It offers an overview, emphasizing their role in algorithm design, while more detailed exploration can be found in </st><span><st c="68103">specialized texts.</st></span></p>
			<h1 id="_idParaDest-184" class="calibre5"><a id="_idTextAnchor219" class="pcalibre pcalibre1 calibre6"/><st c="68121">Summary</st></h1>
			<p class="calibre3"><st c="68129">In this chapter, we explored the key concepts and applications of non-linear data structures, which are essential for designing efficient algorithms. </st><st c="68280">We began by discussing the general properties of non-linear structures, highlighting how they differ from linear data structures in terms of organization and access patterns. </st><st c="68455">Two major categories were covered in detail: graphs and trees. </st><st c="68518">Graphs were presented as versatile structures for modeling relationships, while trees provided a more hierarchical organization of data. </st><st c="68655">We examined different types of trees, such as BSTs, discussing their properties, operations, and use cases in </st><span><st c="68765">algorithm design.</st></span></p>
			<p class="calibre3"><st c="68782">The chapter concluded by focusing on heaps, a special form of binary tree that is commonly used in priority queues and sorting algorithms such as heapsort. </st><st c="68939">We covered how heaps are constructed, how the heap property is maintained through insertion, deletion, and heapify operations, and the role heaps play in sorting. </st><st c="69102">Overall, this chapter provided a foundational understanding of non-linear data structures and emphasized their significance in the efficient processing and manipulation of complex data relationships. </st><st c="69302">By the end of this chapter, our discussion of algorithms comes to a close. </st><st c="69377">However, in the next chapter, we will explore emerging trends and future directions in </st><span><st c="69464">algorithm development.</st></span></p>
			<h1 id="_idParaDest-185" class="calibre5"><a id="_idTextAnchor220" class="pcalibre pcalibre1 calibre6"/><st c="69486">References and further reading</st></h1>
			<ul class="calibre14">
				<li class="calibre13"> <em class="italic"><st c="69517">Introduction to Algorithms</st></em><st c="69544">. By Thomas H. </st><st c="69559">Cormen, Charles E. </st><st c="69578">Leiserson, Ronald L. </st><st c="69599">Rivest, and Clifford Stein. </st><st c="69627">Fourth Edition. </st><st c="69643">MIT </st><span><st c="69647">Press. </st><st c="69654">2022:</st></span><ul class="calibre50"><li class="calibre13"><em class="italic"><st c="69659">Chapter </st></em><span><em class="italic"><st c="69668">6</st></em></span><span><st c="69669">, </st></span><span><em class="italic"><st c="69671">Heapsort</st></em></span></li><li class="calibre13"><em class="italic"><st c="69679">Chapter 12</st></em><st c="69690">, </st><em class="italic"><st c="69692">Binary </st></em><span><em class="italic"><st c="69699">Search Trees</st></em></span></li><li class="calibre13"><em class="italic"><st c="69711">Chapter 22</st></em><st c="69722">, </st><em class="italic"><st c="69724">Elementary </st></em><span><em class="italic"><st c="69735">Graph Algorithms</st></em></span></li></ul></li>
				<li class="calibre13"><em class="italic"><st c="69751">Data Structures and Algorithm Analysis in C++.</st></em><st c="69798"> By Mark A. </st><st c="69810">Weiss. </st><st c="69817">Fourth Edition. </st><span><st c="69833">Pearson. </st><st c="69842">2012:</st></span><ul class="calibre50"><li class="calibre13"><em class="italic"><st c="69847">Chapter </st></em><span><em class="italic"><st c="69856">4</st></em></span><span><st c="69857">, </st></span><span><em class="italic"><st c="69859">Trees</st></em></span></li><li class="calibre13"><em class="italic"><st c="69864">Chapter 5</st></em><st c="69874">, </st><em class="italic"><st c="69876">Binary </st></em><span><em class="italic"><st c="69883">Search Trees</st></em></span></li><li class="calibre13"><em class="italic"><st c="69895">Chapter </st></em><span><em class="italic"><st c="69904">6</st></em></span><span><st c="69905">, </st></span><span><em class="italic"><st c="69907">Heaps</st></em></span></li><li class="calibre13"><em class="italic"><st c="69912">Chapter 9</st></em><st c="69922">, </st><span><em class="italic"><st c="69924">Graph Algorithms</st></em></span></li></ul></li>
				<li class="calibre13"><em class="italic"><st c="69940">Algorithms</st></em><st c="69951">. By R. </st><st c="69959">Sedgewick, K. </st><st c="69973">Wayne. </st><st c="69980">Fourth Edition. </st><span><st c="69996">Addison-Wesley. </st><st c="70012">2011.</st></span><ul class="calibre50"><li class="calibre13"><em class="italic"><st c="70017">Chapter 3</st></em><st c="70027">, </st><em class="italic"><st c="70029">Searching (Binary </st></em><span><em class="italic"><st c="70047">Search Trees)</st></em></span></li><li class="calibre13"><em class="italic"><st c="70060">Chapter 4</st></em><st c="70070">, </st><span><em class="italic"><st c="70072">Sorting (Heapsort)</st></em></span></li><li class="calibre13"><em class="italic"><st c="70090">Chapter </st></em><span><em class="italic"><st c="70099">5</st></em></span><span><st c="70100">, </st></span><span><em class="italic"><st c="70102">Graphs</st></em></span></li></ul></li>
			</ul>
		</div>
	<div id="charCountTotal" value="70108" class="calibre2"/></body></html>