- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine Learning vis-à-vis Mathematical Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having learned about the main components of mathematical optimization, which
    are decision variables, objective functions, and constraints, in the previous
    chapter, it is time to throw light on **machine learning** (**ML**) models, most
    of which can be cast as mathematical models. Humans make machines learn from huge
    amounts of historical data. ML models enhance the decision-making abilities of
    man and machine, exploiting the power of data and algorithms. There is almost
    always some optimization algorithm working in the background of most of these
    models.
  prefs: []
  type: TYPE_NORMAL
- en: The term ML was first popularized by Arthur L. Samuel in the 1950s, who was
    a pioneer in computer science and gaming. Data volume has increased by leaps and
    bounds since then, particularly in the last couple of decades, and making sense
    of huge amounts of data is beyond the scope of the human mind. Hence, ML stepped
    in and found its application in almost all domains to assist humans with the decision-making
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Learning problems in data science can be broadly classified into regression,
    classification, and clustering depending on the business problem or use case.
    Regression and classification use supervised algorithms to predict a target, usually
    called the dependent variable, the independent variables being called predictors.
    Clustering makes use of unsupervised learning algorithms where the target is unknown.
    It is worth mentioning that learning in all ML algorithms is not all about optimization,
    an example of which is supervised learning in **k-nearest neighbors** (**kNN**).
    ML is a predominantly predictive tool helping a business plan for the future,
    thereby being beneficial for its bottom line. Businesses also leverage ML in anomaly
    (or outlier) detection and recommendation systems. Strictly mathematical modeling,
    on the other hand, helps businesses make decisions in areas such as electricity
    distribution, employee scheduling, and inventory management.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some well-known algorithms used in ML models that employ constrained optimization
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Principal component** **analysis** (**PCA**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering with an expectation maximization algorithm (a Gaussian mixture model,
    for example)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support vector machines using the method of Lagrange multipliers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other ML algorithms that employ unconstrained optimization are **stochastic
    gradient descent** (**SGD**) in neural networks and batch gradient descent in
    deep learning (neural networks with numerous hidden layers between the input and
    output). Apart from these, there are genetic algorithms in evolutionary learning,
    which encompass both constrained and unconstrained optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: The main components of ML are representation, evaluation, and optimization.
    By representation, we essentially mean putting forth the knowledge and historical
    data statistically to find patterns, in other words, the formulation of a business
    problem to arrive at or estimate the solution. Next is the evaluation of the formulation,
    which we call the model, and fitting our data into and comparing it with known
    examples or data samples. Finally, the algorithm behind the model optimizes its
    weights and biases for a better fit with the data, and the optimization process
    iterates until a desired accuracy for the problem is attained. We will learn about
    PCA and gradient descent in the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: ML as a mathematical optimization problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML as a predictive tool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mathematical modeling as a prescriptive tool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML as mathematical optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML can be described as finding the unknown underlying (approximate) function
    that maps input examples to output examples. This is where the ML algorithm defines
    a parametrized mapping function and optimizes or minimizes the error in the function
    to find the values of its parameters. ML is function approximation along with
    function optimization. The function parameters are also called model coefficients.
    Each time we fit a model to a training dataset, we solve an optimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: Each ML algorithm makes different assumptions about the form of the mapping
    function, which in turn influences the type of optimization to be performed. ML
    is a function approximation method to optimally fit input data. It is particularly
    challenging when the data (the size or the number of examples) is limited. An
    ML algorithm must be chosen in a way that it most efficiently solves an optimization
    problem; for example, SGD is used for neural nets, while ordinary least squares
    and gradient descent are used for linear regression. When we deviate from the
    default algorithms, we need a good reason to do so. In mathematical optimization,
    a heuristic might sometimes be used to determine near-optimal solutions. This
    happens when the classical algorithms are too slow to even find an approximate
    solution or they fail to find an exact solution to the optimization problem. Examples
    of heuristics are a genetic algorithm and a simulated annealing algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Example 1 – regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An ML problem is framed as the learning of a mapping function (f) given input
    data (X) and output data (Y) such that Y = f(X). Given new input data, we should
    be able to map each datum onto (or predict) the output with our learned function,
    f. A prediction error is expected in general with noise in observed data and with
    a choice of learning algorithm that approximates the mapping function. Finding
    the set of inputs that results in the minimum error, cost, or loss is essentially
    solving the optimization problem. The choice of mapping function dictates the
    level of difficulty of optimization. The more biased or constrained the choice,
    the easier it is.
  prefs: []
  type: TYPE_NORMAL
- en: For example, linear regression is a constrained model. Using linear algebra,
    it can be solved analytically. The inputs to the mapping function in this case
    are the model coefficients. An optimization algorithm such as iterative local
    search can be used numerically but it is almost always less efficient than an
    analytical solution. A logistic regression (for a classification task) is a less
    constrained model, and an optimization algorithm is required in this case. The
    loss or error here is also called the logistic loss or cross-entropy. While a
    global search optimization algorithm can be used in both types of regression models,
    it is mostly less efficient than using either an analytical method or a local
    search method. An iterative global search (gradient descent, for example) is suitable
    when the search space or landscape is multimodal and nonlinear, as shown in *Figure
    2**.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: 3D landscape of unconstrained optimization space, where A is
    the current state](img/Figure_02_01_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: 3D landscape of unconstrained optimization space, where A is the
    current state'
  prefs: []
  type: TYPE_NORMAL
- en: Example 2 – neural network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A neural network is a flexible model and imposes very few constraints. A network
    typically has an input layer, a hidden layer (can be more than one), and an output
    layer of nodes, and the inputs to the mapping function are weighted to the input
    layer, as shown in *Figure 2**.2*. It is this mapping function that the supervised
    learning algorithm tries to best approximate.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2: The three essential, minimal layers in a network](img/Figure_02_02_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: The three essential, minimal layers in a network'
  prefs: []
  type: TYPE_NORMAL
- en: The deviation of predicted output from expected output is the error value, and
    this error or cost, shown in *Figure 2**.3*, is minimized while approximating
    the function during model training. A neural network requires an iterative global
    search algorithm. Gradient descent is the preferred method to optimize a neural
    network that has variants, namely, batch and mini-batch gradient descent and SGD.
    One of the most popular SGD algorithms is **Adaptive Moment Estimation** (**Adam**),
    which computes adaptive learning rates for each parameter of the function.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3: Minimization of cost function J(w) by gradient descent where
    w is the input (courtesy of Python Machine Learning by Sebastian Raschka)](img/Figure_02_03_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Minimization of cost function J(w) by gradient descent where w
    is the input (courtesy of Python Machine Learning by Sebastian Raschka)'
  prefs: []
  type: TYPE_NORMAL
- en: A gradient is a vector of partial derivatives (slope/curvature) of the function
    with respect to input variable values. The gradient descent algorithm, as the
    name suggests, requires the calculation of this gradient. The negative of the
    gradient of each input is followed downhill as the gradient points uphill, to
    lead to new values of the input. A step size is used to scale the gradient and
    control the change of input with respect to the gradient. This step size or increment
    is the learning rate, a hyper-parameter of the algorithm, and is the proportion
    in which network weights are updated. The process is repeated until the minimum
    of the function is located. Gradient descent is adapted to minimize the loss function
    of a predictive model, such as regression or classification. This adaptation results
    in SGD, as shown in *Figure 2**.4*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4: Gradient descent extension](img/Figure_02_04_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Gradient descent extension'
  prefs: []
  type: TYPE_NORMAL
- en: SGD is the extension of the gradient descent optimization algorithm, wherein
    the target function is considered to be the loss or error, such as mean squared
    error for regression and cross-entropy for classification. Since the gradients
    of the target function with respect to the inputs are noisy, and deterministic
    to the extent of probabilistic approximation only, the algorithm is referred to
    as “stochastic.” Due to the sparseness and noise in training data, the evaluated
    gradients have statistical noise. Generally speaking, SGD and its variants are
    still the most used optimization algorithms for ML as well as training deep learning
    (artificial neural network) models. The inputs to a neural network are the weights
    (model parameters) and the target function is the prediction error averaged over
    one batch, which is a subset of the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: A popular extension to SGD for the improvement of process efficiency, such as
    finding out the same (or better) loss in fewer iterations, is Adam. The Adam optimization
    method is computationally efficient, requires little memory, and is well suited
    for problems that are large in terms of size and features. The configuration parameters
    of Adam are the learning rate (step size), exponential decay rate (denoted by
    beta 1) for the mean (first moment) estimates, exponential decay rate (denoted
    by beta 2) for variance (second moment) estimates, and epsilon (very small number)
    to prevent any division by zero in the implementation. Larger values of learning
    rate (denoted by alpha) result in faster initial learning before an update and
    lower values of learning rate mean slower learning during the entire training.
    These parameters typically require very little tuning as they have intuitive interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: A major challenge in using SGD to train a multi-layer neural network is the
    gradient calculation for nodes in the hidden layer(s) of the network. It can be
    tackled by utilizing a specific technique from calculus called the chain rule,
    and an efficient algorithm that implements this rule is called backpropagation,
    which calculates the gradient of a loss function concerning the model variables.
    The first-order derivative of a function for a specific input variable value is
    the rate of change of the function with that variable, and when there are multiple
    input variables, the (partial) derivatives form a vector. For each weight in the
    network, backpropagation calculates the gradient, which is then used by the SGD
    optimization algorithm to update the weights. Backpropagation works backward from
    the output toward the input of the network, as shown in *Figure 2**.5*. It propagates
    the error in the predicted output to compute the gradient for each input variable,
    basically a backward flow of information from the cost function through the network.
    Backpropagation involves the recursive application of the chain rule, which is
    the calculation of the derivative of a sub-function given the known derivative
    of the parent function.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: Backpropagation in a neural network](img/Figure_02_05_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Backpropagation in a neural network'
  prefs: []
  type: TYPE_NORMAL
- en: A genetic algorithm does not utilize the structure of the model, meaning it
    does not require gradients. For problems in which we use neural network models,
    we need to optimize the model using gradients that are calculated with backpropagation.
    It is only fair to say that backpropagation is a part of the optimization process,
    the optimization algorithm being SGD.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have explored ML tasks such as regression, classification, and neural
    nets in the form of mathematical optimization problems, we shall learn about ML
    as a predictive modeling tool and how it is utilized in a few important domains.
  prefs: []
  type: TYPE_NORMAL
- en: ML – a predictive tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working through a predictive model involves optimization at multiple steps on
    top of optimally fitting the learning algorithm to the data. It involves transforming
    raw data into a form most appropriate for consumption in learning algorithms.
    An ML model has hyperparameters that can be configured to tailor it to a specific
    dataset. It is a standard practice to test a suite of hyper-parameters for a chosen
    ML algorithm, which is called hyper-parameter tuning or optimization. A grid search
    or random search algorithm is used for such tuning. *Figure 2**.6* shows the two
    search algorithm types. Grid search is more suitable for a quick search of hyperparameters
    and is known to perform well in general. You can also use Bayesian optimization
    for hyper-parameter tuning in some problems. We will learn about these optimization
    techniques in detail in the last part of the book.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6: Grid search (L) versus random search (R)](img/Figure_02_06_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Grid search (L) versus random search (R)'
  prefs: []
  type: TYPE_NORMAL
- en: An ML practitioner often performs a manual process for predictive model selection
    involving tasks such as data preparation, evaluating models, tuning them, and
    finally, choosing the best model for a given dataset. This can be framed as an
    optimization problem that can be solved with **automated machine learning** (**AutoML**)
    with little user intervention. The automated optimization approach to ML is also
    offered as a cloud product service by companies such as Google and Microsoft.
  prefs: []
  type: TYPE_NORMAL
- en: With or without a target variable in the input dataset, an ML algorithm becomes
    supervised or unsupervised learning, respectively. In reinforcement learning,
    certain behaviors are encouraged and others discouraged. The desired behavior
    is reinforced by rewards, which are gained through experiences from the environment.
    These three types of ML are shown in *Figure 2**.7*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7: The three kinds of ML – supervised learning, unsupervised learning,
    and reinforcement learning](img/Figure_02_07_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: The three kinds of ML – supervised learning, unsupervised learning,
    and reinforcement learning'
  prefs: []
  type: TYPE_NORMAL
- en: We will now talk about a few major domains where the ML model has safely secured
    its place as a predictive tool.
  prefs: []
  type: TYPE_NORMAL
- en: E-commerce
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ML models help retailers understand the buying behavior of customers and their
    preferences. From historical purchase patterns of customers and click-through
    rates of products, e-commerce companies effectively recommend products and offer
    to maximize their sales. Personalized recommendations help retailers retain their
    customer base, thus creating loyalty. The following link outlines the particular
    ways ML can be utilized in the e-commerce industry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://blog.shift4shop.com/machine-learning-ecommerce-industry](https://blog.shift4shop.com/machine-learning-ecommerce-industry)'
  prefs: []
  type: TYPE_NORMAL
- en: Sales and marketing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ML models are used in B2B marketing as well. Identifying and acquiring prospects
    with features similar to existing businesses is one use case of customer segmentation.
    Prioritizing known prospects and generating new leads based on the likelihood
    of customers taking action is achieved using lead-scoring algorithms. Companies
    can streamline their sales and marketing activities by being data-driven as well
    as algorithm-driven. Here are some ways sales and marketing have improved when
    driven by ML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://scinapse.ai/blog/11-ways-machine-learning-can-improve-marketing-and](https://scinapse.ai/blog/11-ways-machine-learning-can-improve-marketing-and)'
  prefs: []
  type: TYPE_NORMAL
- en: Cybersecurity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cyber-attacks may strike an organization at any time and cause serious harm;
    however, they can be predicted and prevented by ML algorithms. From processing
    both structured and unstructured data in a short time, real-time traffic can be
    analyzed to track unusual or anomalous patterns. Companies keep attacks at bay
    by analyzing these outlying points in the data. This also reduces the scope of
    human error stemming from the manual processing of massive volumes of data and
    enables humans to focus on strategizing the protection of the system from cyber-attacks.
    The following data-driven methods pointed out by Kaspersky are worth studying:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaspersky.com/enterprise-security/wiki-section/products/machine-learning-in-cybersecurity](https://www.kaspersky.com/enterprise-security/wiki-section/products/machine-learning-in-cybersecurity)'
  prefs: []
  type: TYPE_NORMAL
- en: Having explored how ML works as a predictive modeling tool in the industry,
    we will learn in the next section how mathematical modeling can be used as a prescriptive
    tool in different sectors.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical modeling – a prescriptive tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Businesses often make complex decisions about their course of action to achieve
    objectives with the help of mathematical modeling or heuristics. A mathematical
    model in this sense is a prescriptive analytical tool. Answering the “where” and
    “when” is as important as answering what happened in the past (descriptive analytics)
    and what could happen in the future (predictive analytics). If a business wants
    to drive decisions from data in addition to insights and future predictions, it
    has to use both predictive and prescriptive tools in an integrated fashion.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8: Mathematical optimization or mathematical modeling](img/Figure_02_08_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: Mathematical optimization or mathematical modeling'
  prefs: []
  type: TYPE_NORMAL
- en: We will have a look at examples from industry verticals wherein these work in
    tandem, resulting in higher productivity and profitability.
  prefs: []
  type: TYPE_NORMAL
- en: Finance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Financial services, including banks, rely on ML models as well as mathematical
    models to determine the right allocation of their investment portfolios. An ML
    model in the form of time-series forecasting helps with the prediction of asset
    performance, which in turn is channelled into applications leveraging a mathematical
    model. Based on the market movements and forecasts, the mathematical optimization
    application determines the optimal allocation. The best portfolio allocation also
    takes individual investment objectives and preferences into account. These mitigate
    risks and maximize risk-adjusted returns on investments.
  prefs: []
  type: TYPE_NORMAL
- en: Retail
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Leading retailers utilize ML models to forecast demand for products, especially
    high-selling ones in particular locations at given times. They feed these predictions
    into mathematical models to maximize profits and customer satisfaction. The mathematical
    optimization application, in this case, uses the forecast as input to generate
    optimal production, pricing, inventory and distribution planning, logistics, and
    warehousing, thereby making the best business decisions while minimizing operating
    costs. Supply chain management is a classic example of mathematical optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Energy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Governments and industry players are making high-stakes decisions on strategic
    investments in network infrastructure and resources as electric power is making
    a transition from being dependent on fossil fuels to renewables such as solar
    and wind. Organizations are utilizing ML models to predict future power demand
    and capacity needs. These forecasts are fed into mathematical models or mathematical
    optimization applications that generate optimal long-term investment planning
    and help in making decisions about strategic investments.
  prefs: []
  type: TYPE_NORMAL
- en: Digital advertising
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Search engine giants such as Google leverage ML (and deep learning) models to
    predict the products and services individuals will be interested in looking up,
    based on their prior search history and a few other factors. In addition, they
    utilize mathematical models to figure out the online advertisements that can be
    shown to individual users at certain times. Search engine giants use this optimization
    model to charge advertisers and maximize their revenue.
  prefs: []
  type: TYPE_NORMAL
- en: These domains have added mathematical modeling to their data science toolbox
    that handles complex, significant, and scalable business problems for greater
    value delivery. Other industries, such as telecommunications and cloud computing,
    also use both models to precisely assess long-term demand and capacity needs to
    make the best business decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced ML models as problems of mathematical optimization
    or mathematical programming. We found out that an end-to-end ML project is the
    sum of multiple small optimization problems. We also gained knowledge about how
    businesses can unlock the true value of data upon leveraging mathematical models
    (primarily driven by mathematical equations) in addition to ML (driven by data)
    models. We learned that an ML model is predominantly a predictive tool and a mathematical
    model is a prescriptive one.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter (which begins the next part of the book), we will take a
    meticulous look at a well-known algorithm called PCA, utilized in an unsupervised
    ML model fit to data with high dimensionality. It is a dimensionality reduction
    technique and one of the most tried and tested mathematical tools employing constrained
    optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Part 2:Mathematical Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you will learn some of the most tried and tested mathematical
    tools and algorithms. On the one hand, there are algorithms for data dimensionality
    reduction, optimization of machine learning models, and data classification, which
    are explored through Python code. On the other hand, there are algorithms that
    model the relationships between objects (data points) and estimate the current
    and future states of variables (unknown and immeasurable ones) of a dynamic system.
    There are also other algorithms that predict the next future state probabilistically
    from knowledge of the present state of a process, explained with simple examples
    and Python code.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B18943_03.xhtml#_idTextAnchor042), *Principal Component Analysis*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B18943_04.xhtml#_idTextAnchor053), *Gradient Descent*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18943_05.xhtml#_idTextAnchor064), *Support Vector Machine*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18943_06.xhtml#_idTextAnchor070), *Graph Theory*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18943_07.xhtml#_idTextAnchor081), *Kalman Filter*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18943_08.xhtml#_idTextAnchor087), *Markov Chain*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
