- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gradient Descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One optimization algorithm that lays the foundation for machine learning models
    is **gradient descent** (**GD**). GD is a simple and effective tool useful to
    train such models. Gradient descent, as the name suggests, involves “going downhill.”
    We choose a direction across a landscape and take whichever step gets us downhill.
    The step size depends on the slope (gradient) of the hill. In **machine learning**
    (**ML**) models, gradient descent estimates the error gradient, helping to minimize
    the cost function. Very few optimization methods are as computationally efficient
    as gradient descent. GD also lays the foundation for the optimization of deep
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: In problems where the parameters cannot be calculated analytically by use of
    linear algebra and must be searched by optimization, GD finds its best use. The
    algorithm works iteratively by moving in the direction of the steepest descent.
    At each iteration, the model parameters, such as coefficients in linear regression
    and weights in neural networks, are updated. The model continues to update its
    parameters until the cost function converges or reaches its minimum value (the
    bottom of the slope in *Figure 4**.1a*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1a: Gradient descent](img/Figure_04_01_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1a: Gradient descent'
  prefs: []
  type: TYPE_NORMAL
- en: The size of a step taken in each iteration is called the learning rate (a function
    derivative is scaled by the learning rate at each iteration). With a learning
    rate that is too low, the model may reach the maximum permissible number of iterations
    before reaching the bottom, whereas it may not converge or may diverge (the so-called
    exploding gradient problem) completely if the learning rate is too high. Selecting
    the most appropriate learning rate is crucial in achieving a model with the best
    possible accuracy, as seen in *Figure 4**.1b*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1b: Learning rates in gradient descent](img/Figure_04_02_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1b: Learning rates in gradient descent'
  prefs: []
  type: TYPE_NORMAL
- en: For GD to work, the objective or cost function must be differentiable (meaning
    the first derivative exists at each point in the domain of a univariate function)
    and convex (where two points on the function can be connected by a line segment
    without crossing). The second derivative of a convex function is always positive.
    Examples of convex and non-convex functions are shown in *Figure 4**.2*. GD is
    a first-order optimization algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2: Example of convex (L) and non-convex (R) function](img/Figure_04_03_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: Example of convex (L) and non-convex (R) function'
  prefs: []
  type: TYPE_NORMAL
- en: In a multivariate function, the gradient is a vector of derivatives in each
    direction in the domain. Such functions have saddle points (quasi-convex or semi-convex)
    where the algorithm may get stuck and obtaining a minimum is not guaranteed. This
    is where second-order optimization algorithms are brought in to escape the saddle
    point and reach the global minimum. The GD algorithm finds its use in control
    as well as mechanical engineering, apart from ML and DL. The following sections
    compare the algorithm with other optimization algorithms used in ML and **deep
    learning** (**DL**) models and specifically examines some commonly used gradient
    descent optimizers.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent variants
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient descent optimizers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient descent variants
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The workings of the gradient descent algorithm to optimize a simple linear regression
    model (*y = mx + c*) is elaborated with Python code in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Application of gradient descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Keeping the number of iterations the same, the algorithm is run for three different
    learning rates resulting in three models, hence three **MSE** (**mean squared
    error**) values. MSE is the calculated loss or cost function in linear regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Two other models are trained with two different learning rates, one higher
    and another lower than model 1, as seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Upon executing the code, the linear regression models obtained (*Figure 4**.3*)
    show how carefully the parameter (learning rate) should be chosen to attain optimal
    performance or the best accuracy of the ML model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3: Gradient descent for a linear regression model](img/Figure_04_04_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: Gradient descent for a linear regression model'
  prefs: []
  type: TYPE_NORMAL
- en: There are GD variants (*Figure 4**.4*) that differ in the data size used to
    compute the gradient of the objective function. A trade-off between the accuracy
    of the parameter (coefficient or weight) and the time taken to do it is made depending
    on the amount of data. The variants are **batch gradient descent** (**BGD**),
    **mini-batch gradient descent**, and **stochastic gradient descent** (**SGD**),
    which we will now discuss in the following subsection.
  prefs: []
  type: TYPE_NORMAL
- en: Mini-batch gradient descent and stochastic gradient descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BGD, also known as vanilla gradient descent, is simply gradient descent and
    computes the gradient for the entire training data to perform one update (in one
    step) and thus can be very slow. Common examples of ML models that are optimized
    using BGD are linear regression and logistic regression for smaller datasets.
  prefs: []
  type: TYPE_NORMAL
- en: For bigger datasets, we generally use mini-batch GD, which allows the splitting
    of training data into mini-batches that can be processed individually. After each
    mini-batch is processed, the parameters are updated and this continues until the
    entire dataset has iteratively been processed. One full cycle through the data
    is called an epoch. A number of steps are taken to reach the global minimum, which
    introduces some variance into the optimization process. This variant of GD is
    usually used for modeling problems where efficiency is as important as accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: SGD performs frequent parameter updates (for each training example) with a high
    level of variance that causes the cost function to fluctuate heavily. This enables
    it to jump to a new and potentially better local minimum. Upon slowly decreasing
    the learning rate, SGD shows convergence behavior similar to BGD. SGD is computationally
    faster than BGD as it considers one example at a time.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4: Gradient descent variants](img/Figure_04_05_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4: Gradient descent variants'
  prefs: []
  type: TYPE_NORMAL
- en: SGD is typically the algorithm of choice for training a neural network. A key
    challenge with SGD while minimizing the highly non-convex error functions common
    in neural networks is avoiding getting trapped in their numerous suboptimal local
    minima. These saddle points make it very hard for SGD to escape, as the gradient
    is close to zero in all dimensions. In the next section, we outline some GD optimizers
    that deal with such challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent optimizers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The optimizers discussed here are widely used to train DL models depending on
    the degree of the non-convexity of the error or cost function.
  prefs: []
  type: TYPE_NORMAL
- en: Momentum
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The momentum method uses a moving average gradient instead of a gradient at
    each time step and reduces the back-and-forth oscillations (fluctuations of the
    cost function) caused by SGD. This process focuses on the steepest descent path.
    *Figure 4**.5a* shows movement with no momentum by creating oscillations in SGD
    while *Figure 4**.5b* shows movement in the relevant direction by accumulating
    velocity with damped oscillations and closer to the optimum.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5a: SGD with no momentum](img/Figure_04_06_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5a: SGD with no momentum'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5b: SGD with momentum](img/Figure_04_07_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5b: SGD with momentum'
  prefs: []
  type: TYPE_NORMAL
- en: The momentum term reduces updates for dimensions whose gradients change directions
    and as a result, faster convergence is achieved.
  prefs: []
  type: TYPE_NORMAL
- en: Adagrad
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `adagrad` optimizer is used when dealing with sparse data as the algorithm
    performs small updates of parameters based on features that occur often. In `adagrad`,
    different or “adaptive” learning rates are used for every update at every time
    step (*Figure 4**.6*). The algorithm uses larger learning rates for infrequent
    features and smaller ones for more frequent features. The major advantage of using
    this optimizer is that the learning rate is not set manually. And when the learning
    rate shrinks to almost zero, the model gains no new knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6: Adagrad optimizer](img/Figure_04_08_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: Adagrad optimizer'
  prefs: []
  type: TYPE_NORMAL
- en: RMSprop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The RMSprop optimizer is similar to the `adagrad` optimizer and hence known
    as **leaky adagrad**, only it uses a different method for parameter updates. The
    RMSprop algorithm restricts oscillations in the vertical direction so that it
    can take larger steps in the horizontal direction (*Figure 4**.7*). The algorithm
    adaptively scales the learning rate in each dimension by using an exponentially
    weighted average of the gradient that allows it to focus on the most recent gradients.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7: RMSprop optimizer](img/Figure_04_09_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: RMSprop optimizer'
  prefs: []
  type: TYPE_NORMAL
- en: Adam
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **adaptive moment estimation** (**adam**) optimizer inherits the advantages
    of both the momentum and RMSprop optimization algorithms (*Figure 4**.8*). It
    combines the ideas of a moving average gradient and an adaptive learning rate.
    These two respectively represent the estimates of the first moment (mean) and
    second moment (variance) of the gradient of the cost function, hence the name.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8: Adam optimizer](img/Figure_04_10_B18943.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: Adam optimizer'
  prefs: []
  type: TYPE_NORMAL
- en: 'It has been empirically observed that the adam optimizer is effective and works
    better than SGD in practice. It has become the default optimizer of choice to
    train DL models. For further reading, check out the following MachineLearningMastery
    article: [https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about a foundational optimization algorithm and
    its variants used in training ML and DL models. An application of the optimization
    technique in Python to a linear regression problem was also elaborated on. Both
    the cost function and its gradient, and how to update the gradient to converge
    to the optimal point, are mathematical concepts every data scientist must understand
    thoroughly; optimizing a cost function is the basis of achieving an optimal model
    for a problem or predictions. Different ways can be used to estimate the gradients
    depending on the behavior of the cost function.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will explore another fundamental algorithm, known
    as **support vector machines** (**SVMs**). Although SVMs can be used for regression
    problems, they are more widely used for classification tasks.
  prefs: []
  type: TYPE_NORMAL
