["```py\nimport pandas as pd, numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nX, y = make_classification(n_samples = 10000, n_features = 2, n_informative = 2,\n                           n_redundant = 0, n_classes = 2,\n                           n_clusters_per_class = 1,\n                           weights = [0.98, 0.02], class_sep = 0.5, random_state = 0)\n#Dataset as pandas dataframe\ndf = pd.DataFrame({'feature1': X[:, 0], 'feature2': X[:, 1], 'target': y})\n#Split dataset into train and test subsets in the ratio 4:1\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n#Train SVM model with RBF\none_class_svm = OneClassSVM(nu = 0.01, kernel = 'rbf', gamma = 'auto').fit(X_train)\n#nu (specifies number of outliers) = 1% , gamma is a parameter for nonlinear kernels\nprediction = one_class_svm.predict(X_test)\nprediction = [1 if i == -1 else 0 for i in prediction] #outliers denoted by 1, inliers by 0\nprint(classification_report(y_test, prediction))\n```", "```py\n#Visualization of outliers\ndf_test = pd.DataFrame(X_test, columns = ['feature1', 'feature2'])\ndf_test['y_test'] = y_test\ndf_test['svm_predictions'] = prediction\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (16, 8))\nax1.set_title('Original Data')\nax1.scatter(df_test['feature1'], df_test['feature2'], c = df_test['y_test'])\nax2.set_title('One-Class SVM Prediction')\nax2.scatter(df_test['feature1'], df_test['feature2'], c = df_test['svm_predictions'])\n```"]