["```py\nimport pandas as pd\nfrom scipy.stats import loguniform\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV\ndataframe = pd.read_csv('sonar.csv')\ndata = dataframe.values\nX, y = data[:, :-1], data[:, -1]\n#Model\nmodel = LogisticRegression()\ncv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n#Define search space\nspace = dict()\nspace['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\nspace['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\nspace['C'] = loguniform(1e-5, 100)\nsearch = RandomizedSearchCV(model, space, n_iter = 500, scoring = 'accuracy',\n                            n_jobs = -1, cv = cv, random_state = 1)\nresult = search.fit(X, y)\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n```", "```py\nimport pandas as pd\nfrom scipy.stats import loguniform\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import RandomizedSearchCV\ndf = pd.read_csv('auto-insurance.csv')\ndata = df.values\nX, y = data[:, :-1], data[:, -1]\n#Model\nmodel = Ridge()\ncv = RepeatedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n#Define search space\nspace = dict()\nspace['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\nspace['alpha'] = loguniform(1e-5, 100)\nspace['fit_intercept'] = [True, False]\nspace['normalize'] = [True, False]\nsearch = RandomizedSearchCV(model, space, n_iter = 500, scoring =      'neg_mean_absolute_error', n_jobs = -1, cv = cv, random_state = 1)\nresult = search.fit(X, y)\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n```", "```py\nimport pandas as pd\nfrom scipy.stats import loguniform\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\ndataframe = pd.read_csv('sonar.csv')\ndata = dataframe.values\nX, y = data[:, :-1], data[:, -1]\n#Model\nmodel = LogisticRegression()\ncv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n#Define search space\nspace = dict()\nspace['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\nspace['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\nspace['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\nsearch = GridSearchCV(model, space, scoring = 'accuracy', n_jobs = -1, cv = cv)\nresult = search.fit(X, y)\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n```", "```py\nimport pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import GridSearchCV\ndf = pd.read_csv('auto-insurance.csv')\ndata = df.values\nX, y = data[:, :-1], data[:, -1]\n#Model\nmodel = Ridge()\ncv = RepeatedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n#Define search space\nspace = dict()\nspace['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\nspace['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\nspace['fit_intercept'] = [True, False]\nspace['normalize'] = [True, False]\nsearch = GridSearchCV(model, space, scoring = 'neg_mean_absolute_error', n_jobs = -1, cv = cv)\nresult = search.fit(X, y)\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n```", "```py\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom skopt.space import Integer\nfrom skopt.utils import use_named_args\nfrom skopt import gp_minimize\n#Generate classification dataset\nX, y = make_blobs(n_samples = 500, centers = 3, n_features = 2) ##3 class labels in data\n#Model kNN\nmodel = KNeighborsClassifier()\n#Define search space\nsearch_space = [Integer(1, 5, name = 'n_neighbors'), Integer(1, 2, name = 'p')]\n@use_named_args(search_space)\ndef evaluate_model(**params):\n    model.set_params(**params)\n    result = cross_val_score(model, X, y, cv = 5, n_jobs = -1, scoring = 'accuracy')\n    estimate = np.mean(result)\n    return 1.0 – estimate\n#Optimize\nresult = gp_minimize(evaluate_model, search_space)\nprint('Accuracy: %.3f' % (1.0 - result.fun))\nprint('Best Parameters: n_neighbors = %d, p = %d' % (result.x[0], result.x[1]))\n```", "```py\nfrom pulp import *\n#value per weight\nv = {'Sleeping bag': 4.17, 'Pillow': 5.13, 'Torch': 10.0, 'First Aid Kit': 8.0, 'Hand sanitiser': 2.0}\n#weight\nw = {'Sleeping bag': 1.2, 'Pillow': 0.39, 'Torch': 0.5, 'First Aid Kit': 0.5, 'Hand sanitiser': 0.5}\nlimit = 2.9\nitems = list(sorted(v.keys()))\n# Model\nm = LpProblem(\"Knapsack Problem\", LpMaximize)\n# Variables\nx = LpVariable.dicts('x', items, lowBound = 0, upBound = 1, cat = LpInteger)\n#Objective\nm += sum(v[i]*x[i] for i in items)\n#Constraint\nm += sum(w[i]*x[i] for i in items) <= limit\n#Optimize\nm.solve()\n#decision variables\nfor i in items:\n    print(\"%s = %f\" % (x[i].name, x[i].varValue))\n```", "```py\nx_First_Aid_Kit = 1.0\nx_Hand_sanitizer = 0.0\nx_Pillow = 1.0\nx_Sleeping_bag = 1.0\nx_Torch = 1.0\n```"]