<html><head></head><body>
<div id="_idContainer014" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor015" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.1.1">1</span></h1>
<h1 id="_idParaDest-16" class="calibre5"><a id="_idTextAnchor016" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.2.1">An Introduction to Genetic Algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">Drawing its inspiration from Charles Darwin’s theory of natural evolution, one of the most fascinating techniques for problem-solving is the algorithm family suitably named evolutionary computation. </span><span class="kobospan" id="kobo.3.2">Within this family, the most prominent and widely used branch is known as genetic algorithms. </span><span class="kobospan" id="kobo.3.3">This chapter is the beginning of your journey to mastering this extremely powerful, yet extremely </span><span><span class="kobospan" id="kobo.4.1">simple, technique.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.5.1">In this chapter, we will introduce genetic algorithms and their analogy to Darwinian evolution before diving into their basic principles of operation and their underlying theory. </span><span class="kobospan" id="kobo.5.2">We will then go over the differences between genetic algorithms and traditional ones and cover the advantages and limitations of genetic algorithms and their uses. </span><span class="kobospan" id="kobo.5.3">We will conclude by reviewing cases where the use of a genetic algorithm may </span><span><span class="kobospan" id="kobo.6.1">prove beneficial.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.7.1">In this introductory chapter, we will cover the </span><span><span class="kobospan" id="kobo.8.1">following topics:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.9.1">What are </span><span><span class="kobospan" id="kobo.10.1">genetic algorithms?</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.11.1">The theory behind </span><span><span class="kobospan" id="kobo.12.1">genetic algorithms</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.13.1">Differences between genetic algorithms and </span><span><span class="kobospan" id="kobo.14.1">traditional algorithms</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.15.1">Advantages and limitations of </span><span><span class="kobospan" id="kobo.16.1">genetic algorithms</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.17.1">When to use </span><span><span class="kobospan" id="kobo.18.1">genetic algorithms</span></span></li>
</ul>
<h1 id="_idParaDest-17" class="calibre5"><a id="_idTextAnchor017" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.19.1">What are genetic algorithms?</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.20.1">Genetic</span><a id="_idIndexMarker000" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.21.1"> algorithms are a family of search algorithms that are inspired by the principles of evolution in nature. </span><span class="kobospan" id="kobo.21.2">By imitating the process of natural selection and reproduction, genetic algorithms can produce high-quality solutions for various problems involving search, optimization, and learning. </span><span class="kobospan" id="kobo.21.3">At the same time, their analogy to natural evolution allows genetic algorithms to overcome some of the hurdles that are encountered by traditional search and optimization algorithms, especially for problems with a large number of parameters and complex </span><span><span class="kobospan" id="kobo.22.1">mathematical representations.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.23.1">In the rest of this section, we will review the basic ideas of genetic algorithms, as well as their analogy to the evolutionary processes transpiring </span><span><span class="kobospan" id="kobo.24.1">in nature.</span></span></p>
<h2 id="_idParaDest-18" class="calibre7"><a id="_idTextAnchor018" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.25.1">Darwinian evolution</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.26.1">Genetic algorithms</span><a id="_idIndexMarker001" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.27.1"> implement a simplified version of the Darwinian evolution that takes place in nature. </span><span class="kobospan" id="kobo.27.2">The principles of the Darwinian evolution theory can be summarized using the </span><span><span class="kobospan" id="kobo.28.1">following principles:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.29.1">The principle of variation</span></strong><span class="kobospan" id="kobo.30.1">: The traits (attributes) of individual specimens belonging to a population may vary. </span><span class="kobospan" id="kobo.30.2">As a result, the specimens differ from each other to some degree, for example, in their behavior </span><span><span class="kobospan" id="kobo.31.1">or appearance.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.32.1">The principle of inheritance</span></strong><span class="kobospan" id="kobo.33.1">: Some traits are consistently passed on from specimens to their offspring. </span><span class="kobospan" id="kobo.33.2">As a result, offspring resemble their parents more than they resemble </span><span><span class="kobospan" id="kobo.34.1">unrelated specimens.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.35.1">The principle of selection</span></strong><span class="kobospan" id="kobo.36.1">: Populations typically struggle for resources within their given environment. </span><span class="kobospan" id="kobo.36.2">The specimens possessing traits that are better adapted to the environment will be more successful at surviving and will also contribute more offspring to the </span><span><span class="kobospan" id="kobo.37.1">next generation.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.38.1">In other words, evolution maintains a population of individual specimens that vary from each other. </span><span class="kobospan" id="kobo.38.2">Those who are better adapted to their environment have a greater chance of surviving, breeding, and passing their traits to the next generation. </span><span class="kobospan" id="kobo.38.3">This way, as generations go by, species become more adapted to their environment and the challenges presented </span><span><span class="kobospan" id="kobo.39.1">to them.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.40.1">An important enabler of evolution is crossover or recombination – where offspring are created with a mix of their parents’ traits. </span><span class="kobospan" id="kobo.40.2">Crossover helps in maintaining the diversity of the population and in bringing together better traits over time. </span><span class="kobospan" id="kobo.40.3">In addition, mutations – random variations</span><a id="_idIndexMarker002" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.41.1"> in traits – can play a role in evolution by introducing changes that can result in a leap forward every once in </span><span><span class="kobospan" id="kobo.42.1">a while.</span></span></p>
<h2 id="_idParaDest-19" class="calibre7"><a id="_idTextAnchor019" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.43.1">The genetic algorithms analogy</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.44.1">Genetic algorithms</span><a id="_idIndexMarker003" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.45.1"> seek to find the optimal solution for a given problem, whereas Darwinian evolution maintains a population of individual specimens. </span><span class="kobospan" id="kobo.45.2">Genetic algorithms maintain a population of candidate solutions, called </span><strong class="bold"><span class="kobospan" id="kobo.46.1">individuals</span></strong><span class="kobospan" id="kobo.47.1">, for </span><a id="_idIndexMarker004" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.48.1">that given problem. </span><span class="kobospan" id="kobo.48.2">These candidate solutions are evaluated iteratively and used to create a new generation of solutions. </span><span class="kobospan" id="kobo.48.3">Those who are better at solving this problem have a greater chance of being selected and passing their qualities to the next generation of candidate solutions. </span><span class="kobospan" id="kobo.48.4">This way, as generations go by, candidate solutions get better at solving the problem </span><span><span class="kobospan" id="kobo.49.1">at hand.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.50.1">In the following sections, we will describe the various components of genetic algorithms that enable this analogy for </span><span><span class="kobospan" id="kobo.51.1">Darwinian evolution.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.52.1">Genotype</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.53.1">In nature, breeding, reproduction, and </span><a id="_idIndexMarker005" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.54.1">mutation are facilitated via the genotype – a collection of genes that are grouped into chromosomes. </span><span class="kobospan" id="kobo.54.2">If two specimens breed to create offspring, each chromosome of the offspring will carry a mix of genes from both parents. </span><span class="kobospan" id="kobo.54.3">Mimicking this concept, in the case of genetic algori</span><a id="_idTextAnchor020" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.55.1">thms, each individual is represented by a chromosome representing a collection of genes. </span><span class="kobospan" id="kobo.55.2">For example, a chromosome can be expressed as a binary string, where each bit represents a </span><span><span class="kobospan" id="kobo.56.1">single gene:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer008">
<span class="kobospan" id="kobo.57.1"><img alt="Figure 1.1: Simple binary-coded chromosome" src="image/B20851_01_1.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.58.1">Figure 1.1: Simple binary-coded chromosome</span></p>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.59.1">Figure 1</span></em></span><em class="italic"><span class="kobospan" id="kobo.60.1">.1</span></em><span class="kobospan" id="kobo.61.1"> shows an example of one such binary-coded chromosome, representing one </span><span><span class="kobospan" id="kobo.62.1">particular individual.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.63.1">Population</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.64.1">At any point in</span><a id="_idIndexMarker006" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.65.1"> time, genetic algorithms maintain a population of individuals – a collection of candidate solutions for the problem at hand. </span><a id="_idTextAnchor021" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.66.1">Since each individual is represented by some chromosome, this population of individuals can be seen as a collection of </span><span><span class="kobospan" id="kobo.67.1">such chromosomes:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer009">
<span class="kobospan" id="kobo.68.1"><img alt="Figure 1.2: The population of individuals represented by binary-coded chromosomes" src="image/B20851_01_2.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.69.1">Figure 1.2: The population of individuals represented by binary-coded chromosomes</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.70.1">The population continually represents the current generation and evolves when the current generation is replaced by a </span><span><span class="kobospan" id="kobo.71.1">new one.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.72.1">Fitness function</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.73.1">At each iteration of the</span><a id="_idIndexMarker007" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.74.1"> algorithm, the individuals are evaluated using a fitness function (also called the target function). </span><span class="kobospan" id="kobo.74.2">This is the function we seek to optimize or the problem we are attempting </span><span><span class="kobospan" id="kobo.75.1">to solve.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.76.1">Individuals who achieve a better fitness score represent better solutions and are more likely to be chosen to reproduce and be represented in the next generation. </span><span class="kobospan" id="kobo.76.2">Over time, the quality of the solutions improves, the fitness values increase, and the process can stop once a solution is found with a satisfactory </span><span><span class="kobospan" id="kobo.77.1">fitness value.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.78.1">Selection</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.79.1">After calculating</span><a id="_idIndexMarker008" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.80.1"> the fitness of every individual in the population, a selection process is used to determine which of the individuals in the population will get to reproduce and create the offspring that will form the </span><span><span class="kobospan" id="kobo.81.1">next generation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.82.1">This selection process is based on the fitness score of the individuals. </span><span class="kobospan" id="kobo.82.2">Those with higher score values are more likely to be chosen and pass their genetic material to the </span><span><span class="kobospan" id="kobo.83.1">next generation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.84.1">Individuals with low fitness values can still be chosen but with a lower probability. </span><span class="kobospan" id="kobo.84.2">This way, their genetic material is not completely excluded, maintaining </span><span><span class="kobospan" id="kobo.85.1">genetic diversity.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.86.1">Crossover</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.87.1">To create a pair of</span><a id="_idIndexMarker009" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.88.1"> new individuals, two parents are usually chosen from the current generation, and parts of their chromosomes are interchanged (crossed over) to create two new chromosomes representing the offspring. </span><span class="kobospan" id="kobo.88.2">This operation is called crossover </span><span><span class="kobospan" id="kobo.89.1">or recombination:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer010">
<span class="kobospan" id="kobo.90.1"><img alt="Figure 1.3: Crossover operation between two binary-coded chromosomes. " src="image/B20851_01_3.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.91.1">Figure 1.3: Crossover operation between two binary-coded chromosomes. </span></p>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.92.1">Source: </span><a href="https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg" class="calibre6 pcalibre pcalibre1"><span class="kobospan" id="kobo.93.1">https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg</span></a><span class="kobospan" id="kobo.94.1">. </span></p>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.95.1">Image by Yearofthedragon</span></p>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.96.1">Figure 1</span></em></span><em class="italic"><span class="kobospan" id="kobo.97.1">.3</span></em><span class="kobospan" id="kobo.98.1"> illustrates a simple crossover operation of creating two offspring from </span><span><span class="kobospan" id="kobo.99.1">two parents.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.100.1">Mutation</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.101.1">The purpose of the </span><a id="_idIndexMarker010" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.102.1">mutation operator is to refresh the population, introduce new patterns into the chromosomes, and encourage search in uncharted areas of the solution space periodically </span><span><span class="kobospan" id="kobo.103.1">and randomly.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.104.1">A mutation may manifest itself as a random change in a gene. </span><span class="kobospan" id="kobo.104.2">Mutations are implemented as random changes to one or more of the chromosome values; for example, flipping a bit in a </span><span><span class="kobospan" id="kobo.105.1">binary string:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer011">
<span class="kobospan" id="kobo.106.1"><img alt="Figure 1.4: Mutation operator applied to a binary-coded chromosome" src="image/B20851_01_4.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.107.1">Figure 1.4: Mutation operator applied to a binary-coded chromosome</span></p>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.108.1">Figure 1</span></em></span><em class="italic"><span class="kobospan" id="kobo.109.1">.4</span></em><span class="kobospan" id="kobo.110.1"> shows an example of the </span><span><span class="kobospan" id="kobo.111.1">mutation operation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.112.1">Now, let’s look at the theory behind </span><span><span class="kobospan" id="kobo.113.1">genetic algorithms.</span></span></p>
<h1 id="_idParaDest-20" class="calibre5"><a id="_idTextAnchor022" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.114.1">The theory behind genetic algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.115.1">The building-block </span><a id="_idIndexMarker011" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.116.1">hypothesis underlying genetic algorithms is that the optimal solution to the problem at hand is assembled of small building blocks, and as we bring more of these building blocks together, we get closer to this </span><span><span class="kobospan" id="kobo.117.1">optimal solution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.118.1">Individuals in the population who contain some of the desired building blocks are identified by their superior scores. </span><span class="kobospan" id="kobo.118.2">The repeated operations of selection and crossover result in better individuals conveying these building blocks to the next generations, while possibly combining them with other successful building blocks. </span><span class="kobospan" id="kobo.118.3">This creates genetic pressure, thus guiding the population toward having more and more individuals with the building blocks that form the </span><span><span class="kobospan" id="kobo.119.1">optimal solution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.120.1">As a result, each generation is better than the previous one and contains more individuals that are closer to the </span><span><span class="kobospan" id="kobo.121.1">optimal solution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.122.1">For example,  consider a population of four-digit binary strings where our goal is to find the string with the highest sum of digits. </span><span class="kobospan" id="kobo.122.2">This is known as the </span><strong class="bold"><span class="kobospan" id="kobo.123.1">OneMax</span></strong><span class="kobospan" id="kobo.124.1"> problem and will be discussed in more detail later in this book. </span><span class="kobospan" id="kobo.124.2">In this scenario, the digit 1 appearing at any of the four possible digit positions will be a good building block. </span><span class="kobospan" id="kobo.124.3">As the algorithm progresses, it will identify solutions that have these building blocks and bring them together. </span><span class="kobospan" id="kobo.124.4">Each generation will have more individuals with 1 value in various positions, ultimately leading to the string 1111, which incorporates all the desired building blocks. </span><span class="kobospan" id="kobo.124.5">This process is illustrated in the </span><span><span class="kobospan" id="kobo.125.1">following figure:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer012">
<span class="kobospan" id="kobo.126.1"><img alt="Figure 1.5: Demonstration of a crossover operation bringing the building blocks of the optimal solution together" src="image/B20851_01_5.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.127.1">Figure 1.5: Demonstration of a crossover operation bringing the building blocks of the optimal solution together</span></p>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.128.1">Figure 1</span></em></span><em class="italic"><span class="kobospan" id="kobo.129.1">.5</span></em><span class="kobospan" id="kobo.130.1"> demonstrates how two individuals that are good solutions for this problem (each has three 1 values) create an offspring that is the best possible solution (four 1 bits – that is, the</span><a id="_idIndexMarker012" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.131.1"> offspring on the right-hand side) when the crossover operation brings the desired building blocks of both </span><span><span class="kobospan" id="kobo.132.1">parents together.</span></span></p>
<h2 id="_idParaDest-21" class="calibre7"><a id="_idTextAnchor023" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.133.1">The schema theorem</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.134.1">A more </span><a id="_idIndexMarker013" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.135.1">formal expression of the building-block</span><a id="_idIndexMarker014" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.136.1"> hypothesis is </span><strong class="bold"><span class="kobospan" id="kobo.137.1">Holland’s schema theorem</span></strong><span class="kobospan" id="kobo.138.1">, also called</span><a id="_idIndexMarker015" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.139.1"> the </span><strong class="bold"><span class="kobospan" id="kobo.140.1">fundamental theorem of </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.141.1">genetic algorithms</span></strong></span><span><span class="kobospan" id="kobo.142.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.143.1">This theorem refers to schemata (the plural of schema), which are patterns (or templates) that can be found within chromosomes. </span><span class="kobospan" id="kobo.143.2">Each schema represents a subset of chromosomes that have a certain similarity </span><span><span class="kobospan" id="kobo.144.1">among them.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.145.1">For example, if binary strings of length four represent the set of chromosomes, the schema </span><em class="italic"><span class="kobospan" id="kobo.146.1">1*01</span></em><span class="kobospan" id="kobo.147.1"> represents all those chromosomes that have a 1 in the leftmost position, 01 in the rightmost two positions, and either a 1 or a 0 in the second from the left position, since</span><a id="_idIndexMarker016" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.148.1"> the * represents a </span><span><strong class="bold"><span class="kobospan" id="kobo.149.1">wildcard</span></strong></span><span><span class="kobospan" id="kobo.150.1"> value.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.151.1">For each schema, we can assign </span><span><span class="kobospan" id="kobo.152.1">two measurements:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.153.1">Order</span></strong><span class="kobospan" id="kobo.154.1">: The number of digits that are fixed (</span><span><span class="kobospan" id="kobo.155.1">not wildcards)</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.156.1">Defining length</span></strong><span class="kobospan" id="kobo.157.1">: The distance between the two furthermost </span><span><span class="kobospan" id="kobo.158.1">fixed digits</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.159.1">The following</span><a id="_idIndexMarker017" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.160.1"> table provides several examples of four-digit binary schemata and </span><span><span class="kobospan" id="kobo.161.1">their measurements:</span></span></p>
<table class="no-table-style" id="table001-1">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.162.1">Schema</span></strong></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.163.1">Order</span></strong></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.164.1">Defining Length</span></strong></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.165.1">1101</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.166.1">4</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.167.1">3</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.168.1">1*01</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.169.1">3</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.170.1">3</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.171.1">*101</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.172.1">3</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.173.1">2</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.174.1">*1*1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.175.1">2</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.176.1">2</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.177.1">**01</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.178.1">2</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.179.1">1</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.180.1">1***</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.181.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.182.1">0</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.183.1">****</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.184.1">0</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.185.1">0</span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.186.1">Table 1.1: Examples of four-digit binary schemata and their corresponding measurements</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.187.1">Each chromosome in the population corresponds to multiple schemata in the same way that a given string matches regular expressions. </span><span class="kobospan" id="kobo.187.2">Chromosome 1101, for example, corresponds to every schemata that </span><a id="_idTextAnchor024" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.188.1">appears in this table since it matches each of the patterns they represent. </span><span class="kobospan" id="kobo.188.2">If this chromosome has a higher score, it is more likely to survive the selection operation, along with all the schemata it represents. </span><span class="kobospan" id="kobo.188.3">As this chromosome gets crossed over with another, or as it gets mutated, some of the schemata will survive and others will disappear. </span><span class="kobospan" id="kobo.188.4">The schemata of low order and short defining length are the ones more likely </span><span><span class="kobospan" id="kobo.189.1">to survive.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.190.1">Consequentially, the schema theorem states that the frequency of schemata of low order, short defining length, and above-average fitness increases exponentially in frequency in successive generations. </span><span class="kobospan" id="kobo.190.2">In other words, the smaller, simpler building blocks that represent the attributes that make a solution better will become increasingly present in the population as the genetic algorithm progresses. </span><span class="kobospan" id="kobo.190.3">We will look at the difference </span><a id="_idIndexMarker018" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.191.1">between genetic and traditional algorithms in the </span><span><span class="kobospan" id="kobo.192.1">next section.</span></span></p>
<h1 id="_idParaDest-22" class="calibre5"><a id="_idTextAnchor025" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.193.1">Differences from traditional algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.194.1">There are</span><a id="_idIndexMarker019" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.195.1"> several important differences </span><a id="_idIndexMarker020" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.196.1">between genetic algorithms and traditional search and optimization algorithms, such as </span><span><span class="kobospan" id="kobo.197.1">gradient-based algorithms.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.198.1">The key distinguishing factors are </span><span><span class="kobospan" id="kobo.199.1">as follows:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.200.1">Maintaining a population </span><span><span class="kobospan" id="kobo.201.1">of solutions</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.202.1">Using a genetic representation of </span><span><span class="kobospan" id="kobo.203.1">the solutions</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.204.1">Utilizing the outcome of a </span><span><span class="kobospan" id="kobo.205.1">fitness function</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.206.1">Exhibiting a </span><span><span class="kobospan" id="kobo.207.1">probabilistic behavior</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.208.1">We will describe these factors in greater detail in the </span><span><span class="kobospan" id="kobo.209.1">following sections.</span></span></p>
<h2 id="_idParaDest-23" class="calibre7"><a id="_idTextAnchor026" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.210.1">Population-based</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.211.1">The genetic search</span><a id="_idIndexMarker021" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.212.1"> is conducted over a population of candidate solutions (individuals) rather than a single candidate. </span><span class="kobospan" id="kobo.212.2">At any point in the search, the algorithm retains a set of individuals that form the current generation. </span><span class="kobospan" id="kobo.212.3">Each iteration of the genetic algorithm creates the next generation </span><span><span class="kobospan" id="kobo.213.1">of individuals.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.214.1">In contrast, most other search algorithms maintain a single solution and iteratively modify it in search of the best solution. </span><span class="kobospan" id="kobo.214.2">The gradient descent algorithm, for example, iteratively moves the current solution in the direction of the steepest descent, which is defined by the </span><a id="_idIndexMarker022" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.215.1">negative of the given </span><span><span class="kobospan" id="kobo.216.1">function’s gradient.</span></span></p>
<h2 id="_idParaDest-24" class="calibre7"><a id="_idTextAnchor027" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.217.1">Genetic representation</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.218.1">Instead of</span><a id="_idIndexMarker023" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.219.1"> operating directly on candidate solutions, genetic algorithms operate on their representations (or coding), often referred to </span><a id="_idIndexMarker024" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.220.1">as </span><strong class="bold"><span class="kobospan" id="kobo.221.1">chromosomes</span></strong><span class="kobospan" id="kobo.222.1">. </span><span class="kobospan" id="kobo.222.2">An example of a simple chromosome is a fixed-length </span><span><span class="kobospan" id="kobo.223.1">binary string.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.224.1">These chromosomes allow us to facilitate the genetic operations of crossover and mutation. </span><span class="kobospan" id="kobo.224.2">Crossover is implemented by interchanging chromosome parts between two parents, while mutation is implemented by modifying parts of </span><span><span class="kobospan" id="kobo.225.1">the chromosome.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.226.1">A side effect of the use of genetic representation is decoupling the search from the original problem domain. </span><span class="kobospan" id="kobo.226.2">Genetic algorithms are not aware of what the chromosomes represent and do not attempt to </span><span><span class="kobospan" id="kobo.227.1">interpret them.</span></span></p>
<h2 id="_idParaDest-25" class="calibre7"><a id="_idTextAnchor028" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.228.1">Fitness function</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.229.1">The fitness function </span><a id="_idIndexMarker025" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.230.1">represents the problem we would like to solve. </span><span class="kobospan" id="kobo.230.2">The objective of genetic algorithms is to find the individuals that yield the highest score when this function is calculated </span><span><span class="kobospan" id="kobo.231.1">for them.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.232.1">Unlike many of the traditional search algorithms, genetic algorithms only consider the value that’s obtained by the fitness function and do not rely on derivatives or any other information. </span><span class="kobospan" id="kobo.232.2">This makes them suitable for handling functions that are hard or impossible to </span><span><span class="kobospan" id="kobo.233.1">mathematically differentiate.</span></span></p>
<h2 id="_idParaDest-26" class="calibre7"><a id="_idTextAnchor029" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.234.1">Probabilistic behavior</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.235.1">While many of the</span><a id="_idIndexMarker026" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.236.1"> traditional algorithms are deterministic, the rules that are used by genetic algorithms to advance from one generation to the next </span><span><span class="kobospan" id="kobo.237.1">are probabilistic.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.238.1">For example, when selecting the individuals that will be used to create the next generation, the probability of selecting a given individual increases with the individual’s fitness, but there is still a random element in making that choice. </span><span class="kobospan" id="kobo.238.2">Individuals with low score values can still be chosen as well, although with a </span><span><span class="kobospan" id="kobo.239.1">lower probability.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.240.1">The mutation is probability-driven as well, usually occurs with low likelihood, and makes changes at one or more random location(s) in </span><span><span class="kobospan" id="kobo.241.1">the chromosome.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.242.1">The crossover operator can also have a probabilistic element. </span><span class="kobospan" id="kobo.242.2">In some variations of genetic algorithms, the crossover will only occur at a certain probability. </span><span class="kobospan" id="kobo.242.3">If no crossover takes place, both parents are duplicated into the next generation </span><span><span class="kobospan" id="kobo.243.1">without change.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.244.1">Despite the probabilistic nature of this process, the genetic-algorithm-based search is not random; instead, it uses the random aspect to direct the search toward areas in the search space </span><a id="_idIndexMarker027" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.245.1">where there is a better chance to improve the results. </span><span class="kobospan" id="kobo.245.2">Now, let’s look at the advantages of </span><span><span class="kobospan" id="kobo.246.1">genetic algorithms.</span></span></p>
<h1 id="_idParaDest-27" class="calibre5"><a id="_idTextAnchor030" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.247.1">Advantages of genetic algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.248.1">The unique </span><a id="_idIndexMarker028" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.249.1">characteristics of genetic algorithms that we discussed in the previous sections provide several advantages over traditional </span><span><span class="kobospan" id="kobo.250.1">search algorithms.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.251.1">The main advantages of genetic algorithms are </span><span><span class="kobospan" id="kobo.252.1">as follows:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.253.1">Global </span><span><span class="kobospan" id="kobo.254.1">optimization capability</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.255.1">Can handle problems with a complex </span><span><span class="kobospan" id="kobo.256.1">mathematical representation</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.257.1">Can handle problems that lack </span><span><span class="kobospan" id="kobo.258.1">mathematical representation</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.259.1">Resilience </span><span><span class="kobospan" id="kobo.260.1">to noise</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.261.1">Support for parallelism and </span><span><span class="kobospan" id="kobo.262.1">distributed processing</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.263.1">Suitable for </span><span><span class="kobospan" id="kobo.264.1">continuous learning</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.265.1">We will cover each of these in the </span><span><span class="kobospan" id="kobo.266.1">upcoming sections.</span></span></p>
<h2 id="_idParaDest-28" class="calibre7"><a id="_idTextAnchor031" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.267.1">Global optimization</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.268.1">In many cases, optimization problems have local maxima and minima points; these represent solutions that are better than those around them, but not the </span><span><span class="kobospan" id="kobo.269.1">best overall.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.270.1">The following figure illustrates the differences between global and local maximum and </span><span><span class="kobospan" id="kobo.271.1">minimum points:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer013">
<span class="kobospan" id="kobo.272.1"><img alt="Figure 1.6: The global and local maxima and minima of a function. " src="image/B20851_01_6.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.273.1">Figure 1.6: The global and local maxima and minima of a function. </span></p>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.274.1">Source: </span><a href="https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg" class="calibre6 pcalibre pcalibre1"><span class="kobospan" id="kobo.275.1">https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg</span></a><span class="kobospan" id="kobo.276.1">.</span><a id="_idTextAnchor032" class="calibre6 pcalibre pcalibre1"/> </p>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.277.1">Image by KSmrq</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.278.1">Most traditional</span><a id="_idIndexMarker029" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.279.1"> search and optimization algorithms, and particularly those that are gradient-based, are prone to getting stuck in a local maximum rather than finding the global one. </span><span class="kobospan" id="kobo.279.2">This is because, in the vicinity of a local maximum, any small change will degrade </span><span><span class="kobospan" id="kobo.280.1">the score.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.281.1">Genetic algorithms, on the other hand, are less sensitive to this phenomenon and are more likely to find the global maximum. </span><span class="kobospan" id="kobo.281.2">This is due to the use of a population of candidate solutions r</span><a id="_idTextAnchor033" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.282.1">ather than a single one, and the crossover and mutation operations that will, in many cases, result in candidate solutions that are distant from the previous ones. </span><span class="kobospan" id="kobo.282.2">This is true so long as we manage to maintain the diversity of the population and avoid </span><strong class="bold"><span class="kobospan" id="kobo.283.1">premature convergence</span></strong><span class="kobospan" id="kobo.284.1">, as we</span><a id="_idIndexMarker030" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.285.1"> will mention in the </span><span><span class="kobospan" id="kobo.286.1">next section.</span></span></p>
<h2 id="_idParaDest-29" class="calibre7"><a id="_idTextAnchor034" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.287.1">Handling complex problems</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.288.1">Since genetic algorithms only require the outcome of the fitness function for each individual and are not concerned with other aspects of the fitness function, such as derivatives, they can be used for problems with complex mathematical representations or functions that are hard or impossible </span><span><span class="kobospan" id="kobo.289.1">to differentiate.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.290.1">Other complex cases where genetic algorithms excel include problems with a large number of parameters and problems with a mix of parameter types – for example, a combination of continuous and </span><span><span class="kobospan" id="kobo.291.1">discrete parameters.</span></span></p>
<h2 id="_idParaDest-30" class="calibre7"><a id="_idTextAnchor035" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.292.1">Handling a lack of mathematical representation</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.293.1">Genetic algorithms can be used for problems that lack mathematical representation altogether. </span><span class="kobospan" id="kobo.293.2">One such case of particular interest is when the fitness score is based on human opinion. </span><span class="kobospan" id="kobo.293.3">Imagine, for example, that we want to find the most attractive color palette to be used on a website. </span><span class="kobospan" id="kobo.293.4">We can try different color combinations and ask users to rate the attractiveness of the site. </span><span class="kobospan" id="kobo.293.5">We can apply genetic algorithms to search for the best scoring combination while using this opinion-based score as the fitness function’s outcome. </span><span class="kobospan" id="kobo.293.6">The genetic algorithm will operate as usual, even though the fitness function lacks any mathematical</span><a id="_idIndexMarker031" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.294.1"> representation and there is no way to calculate the score directly from a given </span><span><span class="kobospan" id="kobo.295.1">color combination.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.296.1">As we will see in the next chapter, genetic algorithms can even deal with cases where </span><a id="_idTextAnchor036" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.297.1">the score of each individual cannot be obtained, so long as we have a way to compare two individuals and determine which of them is better. </span><span class="kobospan" id="kobo.297.2">An example of this is a machine learning algorithm that drives a car in a simulated race. </span><span class="kobospan" id="kobo.297.3">A genetic-algorithm-based search can optimize and tune the machine learning algorithm by having different versions of it compete against each other to determine which version </span><span><span class="kobospan" id="kobo.298.1">is better.</span></span></p>
<h2 id="_idParaDest-31" class="calibre7"><a id="_idTextAnchor037" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.299.1">Resilience to noise</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.300.1">Some problems present noisy behavior. </span><span class="kobospan" id="kobo.300.2">This means that, even for similar input parameter values, the output value may be somewhat different every time it’s measured. </span><span class="kobospan" id="kobo.300.3">This can happen, for example, when the data that’s being used is being read from sensor outputs, or in cases where the score is based on human opinion, as was discussed in the </span><span><span class="kobospan" id="kobo.301.1">previous section.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.302.1">While this kind of behavior can throw off many traditional search algorithms, genetic algorithms are generally resilient to it thanks to the repetitive operation of reassembling and reevaluating </span><span><span class="kobospan" id="kobo.303.1">the individuals.</span></span></p>
<h2 id="_idParaDest-32" class="calibre7"><a id="_idTextAnchor038" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.304.1">Parallelism</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.305.1">Genetic algorithms lend themselves well to parallelization and distributed processing. </span><span class="kobospan" id="kobo.305.2">Fitness is calculated indep</span><a id="_idTextAnchor039" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.306.1">endently for each individual, which means all the individuals in the population can be </span><span><span class="kobospan" id="kobo.307.1">evaluated concurrently.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.308.1">In addition, the operations of selection, crossover, and mutation can each be performed concurrently on individuals and pairs of individuals in </span><span><span class="kobospan" id="kobo.309.1">the population.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.310.1">This makes genetic algorithms natural candidates for distributed as well as </span><span><span class="kobospan" id="kobo.311.1">cloud-based implementation.</span></span></p>
<h2 id="_idParaDest-33" class="calibre7"><a id="_idTextAnchor040" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.312.1">Continuous learning</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.313.1">In nature, evolution never stops. </span><span class="kobospan" id="kobo.313.2">As the environmental conditions change, the population will adapt to them. </span><span class="kobospan" id="kobo.313.3">Similarly, genetic algorithms can operate continuously in an ever-changing environment, and at any point in time, the best current solution can be fetched </span><span><span class="kobospan" id="kobo.314.1">and used.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.315.1">For this to be effective, the changes in the environment need to be slow concerning the generation </span><a id="_idIndexMarker032" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.316.1">turnaround rate of the genetic-algorithm-based search. </span><span class="kobospan" id="kobo.316.2">Now that we’ve covered the advantages of genetic algorithms, let’s look at </span><span><span class="kobospan" id="kobo.317.1">the limitations.</span></span></p>
<h1 id="_idParaDest-34" class="calibre5"><a id="_idTextAnchor041" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.318.1">Limitations of genetic algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.319.1">To get the most out </span><a id="_idIndexMarker033" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.320.1">of genetic algorithms, we need to be aware of their limitations and </span><span><span class="kobospan" id="kobo.321.1">potential pitfalls.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.322.1">The limitations of genetic algorithms are </span><span><span class="kobospan" id="kobo.323.1">as follows:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.324.1">The need for </span><span><span class="kobospan" id="kobo.325.1">special definitions</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.326.1">The need for </span><span><span class="kobospan" id="kobo.327.1">hyperparameter tuning</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.328.1">Computationally </span><span><span class="kobospan" id="kobo.329.1">intensive operations</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.330.1">The risk of </span><span><span class="kobospan" id="kobo.331.1">premature convergence</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.332.1">No </span><span><span class="kobospan" id="kobo.333.1">guaranteed solution</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.334.1">We will cover each of these in the </span><span><span class="kobospan" id="kobo.335.1">upcoming sections.</span></span></p>
<h2 id="_idParaDest-35" class="calibre7"><a id="_idTextAnchor042" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.336.1">Special definitions</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.337.1">When applying genetic algorithms to a given problem, we need to create a suitable representation for them – define the fitness function and the chromosome structure, as well as the selection, crossover, and mutation operators that will work for this problem. </span><span class="kobospan" id="kobo.337.2">This can often prove to be challenging </span><span><span class="kobospan" id="kobo.338.1">and time-consuming.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.339.1">Luckily, genetic algorithms have already been applied to countless different types of problems, and many of these definitions have been standardized. </span><span class="kobospan" id="kobo.339.2">This book covers numerous types of real-life problems and the way they can be solved using genetic algorithms. </span><span class="kobospan" id="kobo.339.3">Use this as guidance whenever you are challenged by a </span><span><span class="kobospan" id="kobo.340.1">new problem.</span></span></p>
<h2 id="_idParaDest-36" class="calibre7"><a id="_idTextAnchor043" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.341.1">Hyperparameter tuning</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.342.1">The behavior of genetic algorithms is controlled by a set of hyperparameters, such as the population size and mutation rate. </span><span class="kobospan" id="kobo.342.2">When applying genetic algorithms to the problem at </span><a id="_idIndexMarker034" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.343.1">hand, there are no exact rules for making </span><span><span class="kobospan" id="kobo.344.1">these choices.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.345.1">However, this is the case for virtually all search and optimization algorithms. </span><span class="kobospan" id="kobo.345.2">After going over the examples in this book and doing some experimentation of your own, you will be able to make sensible choices for </span><span><span class="kobospan" id="kobo.346.1">these values.</span></span></p>
<h2 id="_idParaDest-37" class="calibre7"><a id="_idTextAnchor044" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.347.1">Computationally intensive</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.348.1">Operating on (potentially large) populations and the repetitive nature of genetic algorithms can be computationally intensive, as well as time-consuming, before a good result </span><span><span class="kobospan" id="kobo.349.1">is reached.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.350.1">These can be alleviated with a good choice of hyperparameters, implementing parallel processing, and</span><a id="_idTextAnchor045" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.351.1"> in some cases, caching the </span><span><span class="kobospan" id="kobo.352.1">intermediate results.</span></span></p>
<h2 id="_idParaDest-38" class="calibre7"><a id="_idTextAnchor046" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.353.1">Premature convergence</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.354.1">If the fitness of one individual is much higher than the rest of the population, it may be duplicated enough that it takes over the entire population. </span><span class="kobospan" id="kobo.354.2">This can lead to the genetic algorithm getting prematurely stuck in a local maximum, instead of finding the </span><span><span class="kobospan" id="kobo.355.1">global one.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.356.1">To prevent this from occurring, it is important to maintain the diversity of the population. </span><span class="kobospan" id="kobo.356.2">Various ways to maintain diversity will be discussed in the </span><span><span class="kobospan" id="kobo.357.1">next chapter.</span></span></p>
<h2 id="_idParaDest-39" class="calibre7"><a id="_idTextAnchor047" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.358.1">No guaranteed solution</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.359.1">The use of genetic algorithms does not guarantee that the global maximum for the problem at hand will </span><span><span class="kobospan" id="kobo.360.1">be found.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.361.1">However, this is almost the case for any search and optimization algorithm, unless it is an analytical solution for a particular type </span><span><span class="kobospan" id="kobo.362.1">of problem.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.363.1">Generally, genetic algorithms, when used appropriately, are known to provide good solutions</span><a id="_idIndexMarker035" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.364.1"> within a reasonable amount of time. </span><span class="kobospan" id="kobo.364.2">Now, let’s look at a few use cases for </span><span><span class="kobospan" id="kobo.365.1">genetic algorithms.</span></span></p>
<h1 id="_idParaDest-40" class="calibre5"><a id="_idTextAnchor048" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.366.1">Use cases for genetic algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.367.1">Based on the </span><a id="_idIndexMarker036" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.368.1">material we covere</span><a id="_idTextAnchor049" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.369.1">d in the previous sections, genetic algorithms are best suited for the following types </span><span><span class="kobospan" id="kobo.370.1">of problems:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.371.1">Problems with complex mathematical representation</span></strong><span class="kobospan" id="kobo.372.1">: Since genetic algorithms only require the outcome of the fitness function, they can be used for problems with target functions that are hard or impossible to differentiate (such as planning and schedulin</span><a id="_idTextAnchor050" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.373.1">g), problems with a large number of parameters (such as image reconstruction), and problems with a mix of parameter types (such as </span><span><span class="kobospan" id="kobo.374.1">hyperparameter optimization).</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.375.1">Problems with no mathematical representation</span></strong><span class="kobospan" id="kobo.376.1">: Genetic algorithms don’t require a mathematical representation of the problem, so long as a score value can be obtained, or a method is available to compare two solutions. </span><span class="kobospan" id="kobo.376.2">This can be useful, for example, when solving reinforcement learning tasks or optimizing the architecture of a deep </span><span><span class="kobospan" id="kobo.377.1">learning model.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.378.1">Problems involving a noisy environment</span></strong><span class="kobospan" id="kobo.379.1">: Genetic algorithms are resilient to conditions where data may not be consistent, such as information originating from sensor output or human-based scoring; for example, choosing the best color palette for a website based on customers’ feedback and </span><span><span class="kobospan" id="kobo.380.1">usage patterns.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.381.1">Problems involving an environment that changes over time</span></strong><span class="kobospan" id="kobo.382.1">: Genetic algorithms can respond to slow changes in the environment by continuously creating new generations that will adapt to these changes. </span><span class="kobospan" id="kobo.382.2">Revisiting the website color palette example mentioned previously, the customers’ favorite colors may change over time as per fashion trends. </span><span class="kobospan" id="kobo.382.3">On the other hand, when a problem has a known and specialized way of being solved, using an existing traditional </span><a id="_idIndexMarker037" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.383.1">or analytic method is likely to be a more </span><span><span class="kobospan" id="kobo.384.1">efficient choice.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.385.1">With that, we’ve come to the end of </span><span><span class="kobospan" id="kobo.386.1">this chapter.</span></span></p>
<h1 id="_idParaDest-41" class="calibre5"><a id="_idTextAnchor051" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.387.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.388.1">In this chapter, we started by introducing genetic algorithms, their analogy to Darwinian evolution, and their basic principles of operation, including the use of population, genotype, the fitness function, and the genetic operators of selection, crossover, </span><span><span class="kobospan" id="kobo.389.1">and mutation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.390.1">Then, we covered the theory underlying genetic algorithms by going over the building-block hypothesis and the schema theorem and illustrating how genetic algorithms work by bringing together superior, small building blocks to create the </span><span><span class="kobospan" id="kobo.391.1">best solutions.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.392.1">Next, we went over the differences between genetic algorithms and traditional ones, such as maintaining a population of solutions and using a genetic representation of </span><span><span class="kobospan" id="kobo.393.1">those solutions.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.394.1">We continued by covering the strengths of genetic algorithms, including their capacity for global optimization, handling problems with complex or non-existent mathematical representations, and resilience to noise, followed by their weaknesses, including the need for special definitions and hyperparameter tuning, as well as the risk of </span><span><span class="kobospan" id="kobo.395.1">premature convergence.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.396.1">We concluded by going over the cases where the use of a genetic algorithm may prove beneficial, such as in mathematically complex problems and optimization tasks in a noisy or </span><span><span class="kobospan" id="kobo.397.1">ever-changing environment.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.398.1">In the next chapter, we will delve deeper into the key components and the implementation details of genetic algorithms in preparation for the following chapters, where we will use them to code solutions for various types </span><span><span class="kobospan" id="kobo.399.1">of problems.</span></span></p>
<h1 id="_idParaDest-42" class="calibre5"><a id="_idTextAnchor052" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.400.1">Further reading</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.401.1">For more information on what we covered in this chapter, please refer to </span><em class="italic"><span class="kobospan" id="kobo.402.1">Introduction to Genetic Algorithms</span></em><span class="kobospan" id="kobo.403.1">, from the book </span><em class="italic"><span class="kobospan" id="kobo.404.1">Hands-On Artificial Intelligence for IoT</span></em><span class="kobospan" id="kobo.405.1">, by Amita Kapoor, January 2019, available </span><span><span class="kobospan" id="kobo.406.1">at </span></span><span><span class="kobospan" id="kobo.407.1">https:</span></span><a href="https://subscription.packtpub.com/book/data/9781788836067/1" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.408.1">//subscription.packtpub.com/book/big_data_and_business_intelligence/9781788836067</span></span></a><span><span class="kobospan" id="kobo.409.1">.</span></span></p>
</div>
</body></html>