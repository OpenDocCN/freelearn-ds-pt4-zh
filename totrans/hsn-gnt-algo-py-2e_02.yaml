- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An Introduction to Genetic Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Drawing its inspiration from Charles Darwin’s theory of natural evolution, one
    of the most fascinating techniques for problem-solving is the algorithm family
    suitably named evolutionary computation. Within this family, the most prominent
    and widely used branch is known as genetic algorithms. This chapter is the beginning
    of your journey to mastering this extremely powerful, yet extremely simple, technique.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will introduce genetic algorithms and their analogy to Darwinian
    evolution before diving into their basic principles of operation and their underlying
    theory. We will then go over the differences between genetic algorithms and traditional
    ones and cover the advantages and limitations of genetic algorithms and their
    uses. We will conclude by reviewing cases where the use of a genetic algorithm
    may prove beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this introductory chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What are genetic algorithms?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The theory behind genetic algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differences between genetic algorithms and traditional algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages and limitations of genetic algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to use genetic algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are genetic algorithms?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Genetic algorithms are a family of search algorithms that are inspired by the
    principles of evolution in nature. By imitating the process of natural selection
    and reproduction, genetic algorithms can produce high-quality solutions for various
    problems involving search, optimization, and learning. At the same time, their
    analogy to natural evolution allows genetic algorithms to overcome some of the
    hurdles that are encountered by traditional search and optimization algorithms,
    especially for problems with a large number of parameters and complex mathematical
    representations.
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of this section, we will review the basic ideas of genetic algorithms,
    as well as their analogy to the evolutionary processes transpiring in nature.
  prefs: []
  type: TYPE_NORMAL
- en: Darwinian evolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Genetic algorithms implement a simplified version of the Darwinian evolution
    that takes place in nature. The principles of the Darwinian evolution theory can
    be summarized using the following principles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The principle of variation**: The traits (attributes) of individual specimens
    belonging to a population may vary. As a result, the specimens differ from each
    other to some degree, for example, in their behavior or appearance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The principle of inheritance**: Some traits are consistently passed on from
    specimens to their offspring. As a result, offspring resemble their parents more
    than they resemble unrelated specimens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The principle of selection**: Populations typically struggle for resources
    within their given environment. The specimens possessing traits that are better
    adapted to the environment will be more successful at surviving and will also
    contribute more offspring to the next generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In other words, evolution maintains a population of individual specimens that
    vary from each other. Those who are better adapted to their environment have a
    greater chance of surviving, breeding, and passing their traits to the next generation.
    This way, as generations go by, species become more adapted to their environment
    and the challenges presented to them.
  prefs: []
  type: TYPE_NORMAL
- en: An important enabler of evolution is crossover or recombination – where offspring
    are created with a mix of their parents’ traits. Crossover helps in maintaining
    the diversity of the population and in bringing together better traits over time.
    In addition, mutations – random variations in traits – can play a role in evolution
    by introducing changes that can result in a leap forward every once in a while.
  prefs: []
  type: TYPE_NORMAL
- en: The genetic algorithms analogy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Genetic algorithms seek to find the optimal solution for a given problem, whereas
    Darwinian evolution maintains a population of individual specimens. Genetic algorithms
    maintain a population of candidate solutions, called **individuals**, for that
    given problem. These candidate solutions are evaluated iteratively and used to
    create a new generation of solutions. Those who are better at solving this problem
    have a greater chance of being selected and passing their qualities to the next
    generation of candidate solutions. This way, as generations go by, candidate solutions
    get better at solving the problem at hand.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will describe the various components of genetic
    algorithms that enable this analogy for Darwinian evolution.
  prefs: []
  type: TYPE_NORMAL
- en: Genotype
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In nature, breeding, reproduction, and mutation are facilitated via the genotype
    – a collection of genes that are grouped into chromosomes. If two specimens breed
    to create offspring, each chromosome of the offspring will carry a mix of genes
    from both parents. Mimicking this concept, in the case of genetic algorithms,
    each individual is represented by a chromosome representing a collection of genes.
    For example, a chromosome can be expressed as a binary string, where each bit
    represents a single gene:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1: Simple binary-coded chromosome](img/B20851_01_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.1: Simple binary-coded chromosome'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1**.1* shows an example of one such binary-coded chromosome, representing
    one particular individual.'
  prefs: []
  type: TYPE_NORMAL
- en: Population
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At any point in time, genetic algorithms maintain a population of individuals
    – a collection of candidate solutions for the problem at hand. Since each individual
    is represented by some chromosome, this population of individuals can be seen
    as a collection of such chromosomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2: The population of individuals represented by binary-coded chromosomes](img/B20851_01_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: The population of individuals represented by binary-coded chromosomes'
  prefs: []
  type: TYPE_NORMAL
- en: The population continually represents the current generation and evolves when
    the current generation is replaced by a new one.
  prefs: []
  type: TYPE_NORMAL
- en: Fitness function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At each iteration of the algorithm, the individuals are evaluated using a fitness
    function (also called the target function). This is the function we seek to optimize
    or the problem we are attempting to solve.
  prefs: []
  type: TYPE_NORMAL
- en: Individuals who achieve a better fitness score represent better solutions and
    are more likely to be chosen to reproduce and be represented in the next generation.
    Over time, the quality of the solutions improves, the fitness values increase,
    and the process can stop once a solution is found with a satisfactory fitness
    value.
  prefs: []
  type: TYPE_NORMAL
- en: Selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After calculating the fitness of every individual in the population, a selection
    process is used to determine which of the individuals in the population will get
    to reproduce and create the offspring that will form the next generation.
  prefs: []
  type: TYPE_NORMAL
- en: This selection process is based on the fitness score of the individuals. Those
    with higher score values are more likely to be chosen and pass their genetic material
    to the next generation.
  prefs: []
  type: TYPE_NORMAL
- en: Individuals with low fitness values can still be chosen but with a lower probability.
    This way, their genetic material is not completely excluded, maintaining genetic
    diversity.
  prefs: []
  type: TYPE_NORMAL
- en: Crossover
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To create a pair of new individuals, two parents are usually chosen from the
    current generation, and parts of their chromosomes are interchanged (crossed over)
    to create two new chromosomes representing the offspring. This operation is called
    crossover or recombination:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3: Crossover operation between two binary-coded chromosomes. ](img/B20851_01_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.3: Crossover operation between two binary-coded chromosomes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg](https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg).'
  prefs: []
  type: TYPE_NORMAL
- en: Image by Yearofthedragon
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1**.3* illustrates a simple crossover operation of creating two offspring
    from two parents.'
  prefs: []
  type: TYPE_NORMAL
- en: Mutation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The purpose of the mutation operator is to refresh the population, introduce
    new patterns into the chromosomes, and encourage search in uncharted areas of
    the solution space periodically and randomly.
  prefs: []
  type: TYPE_NORMAL
- en: 'A mutation may manifest itself as a random change in a gene. Mutations are
    implemented as random changes to one or more of the chromosome values; for example,
    flipping a bit in a binary string:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4: Mutation operator applied to a binary-coded chromosome](img/B20851_01_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4: Mutation operator applied to a binary-coded chromosome'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1**.4* shows an example of the mutation operation.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at the theory behind genetic algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The theory behind genetic algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The building-block hypothesis underlying genetic algorithms is that the optimal
    solution to the problem at hand is assembled of small building blocks, and as
    we bring more of these building blocks together, we get closer to this optimal
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Individuals in the population who contain some of the desired building blocks
    are identified by their superior scores. The repeated operations of selection
    and crossover result in better individuals conveying these building blocks to
    the next generations, while possibly combining them with other successful building
    blocks. This creates genetic pressure, thus guiding the population toward having
    more and more individuals with the building blocks that form the optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, each generation is better than the previous one and contains more
    individuals that are closer to the optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider a population of four-digit binary strings where our goal
    is to find the string with the highest sum of digits. This is known as the **OneMax**
    problem and will be discussed in more detail later in this book. In this scenario,
    the digit 1 appearing at any of the four possible digit positions will be a good
    building block. As the algorithm progresses, it will identify solutions that have
    these building blocks and bring them together. Each generation will have more
    individuals with 1 value in various positions, ultimately leading to the string
    1111, which incorporates all the desired building blocks. This process is illustrated
    in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5: Demonstration of a crossover operation bringing the building
    blocks of the optimal solution together](img/B20851_01_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.5: Demonstration of a crossover operation bringing the building blocks
    of the optimal solution together'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1**.5* demonstrates how two individuals that are good solutions for
    this problem (each has three 1 values) create an offspring that is the best possible
    solution (four 1 bits – that is, the offspring on the right-hand side) when the
    crossover operation brings the desired building blocks of both parents together.'
  prefs: []
  type: TYPE_NORMAL
- en: The schema theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A more formal expression of the building-block hypothesis is **Holland’s schema
    theorem**, also called the **fundamental theorem of** **genetic algorithms**.
  prefs: []
  type: TYPE_NORMAL
- en: This theorem refers to schemata (the plural of schema), which are patterns (or
    templates) that can be found within chromosomes. Each schema represents a subset
    of chromosomes that have a certain similarity among them.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if binary strings of length four represent the set of chromosomes,
    the schema *1*01* represents all those chromosomes that have a 1 in the leftmost
    position, 01 in the rightmost two positions, and either a 1 or a 0 in the second
    from the left position, since the * represents a **wildcard** value.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each schema, we can assign two measurements:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Order**: The number of digits that are fixed (not wildcards)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Defining length**: The distance between the two furthermost fixed digits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following table provides several examples of four-digit binary schemata
    and their measurements:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Schema** | **Order** | **Defining Length** |'
  prefs: []
  type: TYPE_TB
- en: '| 1101 | 4 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 1*01 | 3 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| *101 | 3 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| *1*1 | 2 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| **01 | 2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1*** | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| **** | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1.1: Examples of four-digit binary schemata and their corresponding measurements'
  prefs: []
  type: TYPE_NORMAL
- en: Each chromosome in the population corresponds to multiple schemata in the same
    way that a given string matches regular expressions. Chromosome 1101, for example,
    corresponds to every schemata that appears in this table since it matches each
    of the patterns they represent. If this chromosome has a higher score, it is more
    likely to survive the selection operation, along with all the schemata it represents.
    As this chromosome gets crossed over with another, or as it gets mutated, some
    of the schemata will survive and others will disappear. The schemata of low order
    and short defining length are the ones more likely to survive.
  prefs: []
  type: TYPE_NORMAL
- en: Consequentially, the schema theorem states that the frequency of schemata of
    low order, short defining length, and above-average fitness increases exponentially
    in frequency in successive generations. In other words, the smaller, simpler building
    blocks that represent the attributes that make a solution better will become increasingly
    present in the population as the genetic algorithm progresses. We will look at
    the difference between genetic and traditional algorithms in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Differences from traditional algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several important differences between genetic algorithms and traditional
    search and optimization algorithms, such as gradient-based algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key distinguishing factors are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining a population of solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a genetic representation of the solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing the outcome of a fitness function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exhibiting a probabilistic behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will describe these factors in greater detail in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Population-based
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The genetic search is conducted over a population of candidate solutions (individuals)
    rather than a single candidate. At any point in the search, the algorithm retains
    a set of individuals that form the current generation. Each iteration of the genetic
    algorithm creates the next generation of individuals.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, most other search algorithms maintain a single solution and iteratively
    modify it in search of the best solution. The gradient descent algorithm, for
    example, iteratively moves the current solution in the direction of the steepest
    descent, which is defined by the negative of the given function’s gradient.
  prefs: []
  type: TYPE_NORMAL
- en: Genetic representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of operating directly on candidate solutions, genetic algorithms operate
    on their representations (or coding), often referred to as **chromosomes**. An
    example of a simple chromosome is a fixed-length binary string.
  prefs: []
  type: TYPE_NORMAL
- en: These chromosomes allow us to facilitate the genetic operations of crossover
    and mutation. Crossover is implemented by interchanging chromosome parts between
    two parents, while mutation is implemented by modifying parts of the chromosome.
  prefs: []
  type: TYPE_NORMAL
- en: A side effect of the use of genetic representation is decoupling the search
    from the original problem domain. Genetic algorithms are not aware of what the
    chromosomes represent and do not attempt to interpret them.
  prefs: []
  type: TYPE_NORMAL
- en: Fitness function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The fitness function represents the problem we would like to solve. The objective
    of genetic algorithms is to find the individuals that yield the highest score
    when this function is calculated for them.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike many of the traditional search algorithms, genetic algorithms only consider
    the value that’s obtained by the fitness function and do not rely on derivatives
    or any other information. This makes them suitable for handling functions that
    are hard or impossible to mathematically differentiate.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic behavior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While many of the traditional algorithms are deterministic, the rules that are
    used by genetic algorithms to advance from one generation to the next are probabilistic.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when selecting the individuals that will be used to create the
    next generation, the probability of selecting a given individual increases with
    the individual’s fitness, but there is still a random element in making that choice.
    Individuals with low score values can still be chosen as well, although with a
    lower probability.
  prefs: []
  type: TYPE_NORMAL
- en: The mutation is probability-driven as well, usually occurs with low likelihood,
    and makes changes at one or more random location(s) in the chromosome.
  prefs: []
  type: TYPE_NORMAL
- en: The crossover operator can also have a probabilistic element. In some variations
    of genetic algorithms, the crossover will only occur at a certain probability.
    If no crossover takes place, both parents are duplicated into the next generation
    without change.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the probabilistic nature of this process, the genetic-algorithm-based
    search is not random; instead, it uses the random aspect to direct the search
    toward areas in the search space where there is a better chance to improve the
    results. Now, let’s look at the advantages of genetic algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of genetic algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The unique characteristics of genetic algorithms that we discussed in the previous
    sections provide several advantages over traditional search algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main advantages of genetic algorithms are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Global optimization capability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can handle problems with a complex mathematical representation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can handle problems that lack mathematical representation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resilience to noise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for parallelism and distributed processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suitable for continuous learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will cover each of these in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Global optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many cases, optimization problems have local maxima and minima points; these
    represent solutions that are better than those around them, but not the best overall.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates the differences between global and local maximum
    and minimum points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6: The global and local maxima and minima of a function. ](img/B20851_01_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.6: The global and local maxima and minima of a function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg](https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg).'
  prefs: []
  type: TYPE_NORMAL
- en: Image by KSmrq
  prefs: []
  type: TYPE_NORMAL
- en: Most traditional search and optimization algorithms, and particularly those
    that are gradient-based, are prone to getting stuck in a local maximum rather
    than finding the global one. This is because, in the vicinity of a local maximum,
    any small change will degrade the score.
  prefs: []
  type: TYPE_NORMAL
- en: Genetic algorithms, on the other hand, are less sensitive to this phenomenon
    and are more likely to find the global maximum. This is due to the use of a population
    of candidate solutions rather than a single one, and the crossover and mutation
    operations that will, in many cases, result in candidate solutions that are distant
    from the previous ones. This is true so long as we manage to maintain the diversity
    of the population and avoid **premature convergence**, as we will mention in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Handling complex problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since genetic algorithms only require the outcome of the fitness function for
    each individual and are not concerned with other aspects of the fitness function,
    such as derivatives, they can be used for problems with complex mathematical representations
    or functions that are hard or impossible to differentiate.
  prefs: []
  type: TYPE_NORMAL
- en: Other complex cases where genetic algorithms excel include problems with a large
    number of parameters and problems with a mix of parameter types – for example,
    a combination of continuous and discrete parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Handling a lack of mathematical representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Genetic algorithms can be used for problems that lack mathematical representation
    altogether. One such case of particular interest is when the fitness score is
    based on human opinion. Imagine, for example, that we want to find the most attractive
    color palette to be used on a website. We can try different color combinations
    and ask users to rate the attractiveness of the site. We can apply genetic algorithms
    to search for the best scoring combination while using this opinion-based score
    as the fitness function’s outcome. The genetic algorithm will operate as usual,
    even though the fitness function lacks any mathematical representation and there
    is no way to calculate the score directly from a given color combination.
  prefs: []
  type: TYPE_NORMAL
- en: As we will see in the next chapter, genetic algorithms can even deal with cases
    where the score of each individual cannot be obtained, so long as we have a way
    to compare two individuals and determine which of them is better. An example of
    this is a machine learning algorithm that drives a car in a simulated race. A
    genetic-algorithm-based search can optimize and tune the machine learning algorithm
    by having different versions of it compete against each other to determine which
    version is better.
  prefs: []
  type: TYPE_NORMAL
- en: Resilience to noise
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some problems present noisy behavior. This means that, even for similar input
    parameter values, the output value may be somewhat different every time it’s measured.
    This can happen, for example, when the data that’s being used is being read from
    sensor outputs, or in cases where the score is based on human opinion, as was
    discussed in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: While this kind of behavior can throw off many traditional search algorithms,
    genetic algorithms are generally resilient to it thanks to the repetitive operation
    of reassembling and reevaluating the individuals.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Genetic algorithms lend themselves well to parallelization and distributed processing.
    Fitness is calculated independently for each individual, which means all the individuals
    in the population can be evaluated concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the operations of selection, crossover, and mutation can each be
    performed concurrently on individuals and pairs of individuals in the population.
  prefs: []
  type: TYPE_NORMAL
- en: This makes genetic algorithms natural candidates for distributed as well as
    cloud-based implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In nature, evolution never stops. As the environmental conditions change, the
    population will adapt to them. Similarly, genetic algorithms can operate continuously
    in an ever-changing environment, and at any point in time, the best current solution
    can be fetched and used.
  prefs: []
  type: TYPE_NORMAL
- en: For this to be effective, the changes in the environment need to be slow concerning
    the generation turnaround rate of the genetic-algorithm-based search. Now that
    we’ve covered the advantages of genetic algorithms, let’s look at the limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of genetic algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get the most out of genetic algorithms, we need to be aware of their limitations
    and potential pitfalls.
  prefs: []
  type: TYPE_NORMAL
- en: 'The limitations of genetic algorithms are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The need for special definitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The need for hyperparameter tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computationally intensive operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The risk of premature convergence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No guaranteed solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will cover each of these in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Special definitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When applying genetic algorithms to a given problem, we need to create a suitable
    representation for them – define the fitness function and the chromosome structure,
    as well as the selection, crossover, and mutation operators that will work for
    this problem. This can often prove to be challenging and time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, genetic algorithms have already been applied to countless different
    types of problems, and many of these definitions have been standardized. This
    book covers numerous types of real-life problems and the way they can be solved
    using genetic algorithms. Use this as guidance whenever you are challenged by
    a new problem.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The behavior of genetic algorithms is controlled by a set of hyperparameters,
    such as the population size and mutation rate. When applying genetic algorithms
    to the problem at hand, there are no exact rules for making these choices.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is the case for virtually all search and optimization algorithms.
    After going over the examples in this book and doing some experimentation of your
    own, you will be able to make sensible choices for these values.
  prefs: []
  type: TYPE_NORMAL
- en: Computationally intensive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Operating on (potentially large) populations and the repetitive nature of genetic
    algorithms can be computationally intensive, as well as time-consuming, before
    a good result is reached.
  prefs: []
  type: TYPE_NORMAL
- en: These can be alleviated with a good choice of hyperparameters, implementing
    parallel processing, and in some cases, caching the intermediate results.
  prefs: []
  type: TYPE_NORMAL
- en: Premature convergence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the fitness of one individual is much higher than the rest of the population,
    it may be duplicated enough that it takes over the entire population. This can
    lead to the genetic algorithm getting prematurely stuck in a local maximum, instead
    of finding the global one.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent this from occurring, it is important to maintain the diversity of
    the population. Various ways to maintain diversity will be discussed in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: No guaranteed solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The use of genetic algorithms does not guarantee that the global maximum for
    the problem at hand will be found.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is almost the case for any search and optimization algorithm,
    unless it is an analytical solution for a particular type of problem.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, genetic algorithms, when used appropriately, are known to provide
    good solutions within a reasonable amount of time. Now, let’s look at a few use
    cases for genetic algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for genetic algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Based on the material we covered in the previous sections, genetic algorithms
    are best suited for the following types of problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Problems with complex mathematical representation**: Since genetic algorithms
    only require the outcome of the fitness function, they can be used for problems
    with target functions that are hard or impossible to differentiate (such as planning
    and scheduling), problems with a large number of parameters (such as image reconstruction),
    and problems with a mix of parameter types (such as hyperparameter optimization).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Problems with no mathematical representation**: Genetic algorithms don’t
    require a mathematical representation of the problem, so long as a score value
    can be obtained, or a method is available to compare two solutions. This can be
    useful, for example, when solving reinforcement learning tasks or optimizing the
    architecture of a deep learning model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Problems involving a noisy environment**: Genetic algorithms are resilient
    to conditions where data may not be consistent, such as information originating
    from sensor output or human-based scoring; for example, choosing the best color
    palette for a website based on customers’ feedback and usage patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Problems involving an environment that changes over time**: Genetic algorithms
    can respond to slow changes in the environment by continuously creating new generations
    that will adapt to these changes. Revisiting the website color palette example
    mentioned previously, the customers’ favorite colors may change over time as per
    fashion trends. On the other hand, when a problem has a known and specialized
    way of being solved, using an existing traditional or analytic method is likely
    to be a more efficient choice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, we’ve come to the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started by introducing genetic algorithms, their analogy
    to Darwinian evolution, and their basic principles of operation, including the
    use of population, genotype, the fitness function, and the genetic operators of
    selection, crossover, and mutation.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we covered the theory underlying genetic algorithms by going over the
    building-block hypothesis and the schema theorem and illustrating how genetic
    algorithms work by bringing together superior, small building blocks to create
    the best solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we went over the differences between genetic algorithms and traditional
    ones, such as maintaining a population of solutions and using a genetic representation
    of those solutions.
  prefs: []
  type: TYPE_NORMAL
- en: We continued by covering the strengths of genetic algorithms, including their
    capacity for global optimization, handling problems with complex or non-existent
    mathematical representations, and resilience to noise, followed by their weaknesses,
    including the need for special definitions and hyperparameter tuning, as well
    as the risk of premature convergence.
  prefs: []
  type: TYPE_NORMAL
- en: We concluded by going over the cases where the use of a genetic algorithm may
    prove beneficial, such as in mathematically complex problems and optimization
    tasks in a noisy or ever-changing environment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will delve deeper into the key components and the implementation
    details of genetic algorithms in preparation for the following chapters, where
    we will use them to code solutions for various types of problems.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For more information on what we covered in this chapter, please refer to *Introduction
    to Genetic Algorithms*, from the book *Hands-On Artificial Intelligence for IoT*,
    by Amita Kapoor, January 2019, available at https:[//subscription.packtpub.com/book/big_data_and_business_intelligence/9781788836067](https://subscription.packtpub.com/book/data/9781788836067/1).
  prefs: []
  type: TYPE_NORMAL
