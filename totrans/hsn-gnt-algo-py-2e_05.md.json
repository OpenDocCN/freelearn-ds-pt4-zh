["```py\npip install -r /path/to/requirements.txt\n```", "```py\npip install deap\n```", "```py\nfrom deap import creator\ncreator.create(\"Developer\", Employee,\\\n                position=\"Developer\", \\\n                programmingLanguages=set)\n```", "```py\nclass Developer(Employee):\n    position = \"Developer\"\n    def __init__(self):\n        self.programmingLanguages = set()\n```", "```py\ncreator.create(\"creator.FitnessMax class that extends the base.Fitness class, with the weights class attribute initialized to a value of (1.0,).\nImportant note\nNote the trailing comma in the **weights** definition when a single weight is defined. The comma is required because **weights** is a **tuple**.\nThe strategy of this `FitnessMax` class is to *maximize* the fitness values of the single-objective solutions throughout the genetic algorithm. Conversely, if we have a single-objective problem where we need to find a solution that *minimizes* the fitness value, we can use the following definition to create the appropriate minimizing strategy:\n\n```", "```py\n\n We can also define a class with a strategy for optimizing more than one objective, and with varying degrees of importance:\n\n```", "```py\n>, <, >=, <=, ==, !=\n```", "```py\ncreator.create(\"Individual\", list, \\\n                fitness=creator.FitnessMax)\n```", "```py\ndef sumOfTwo(a, b):\n    return a + b\n```", "```py\nfrom deap import base\ntoolbox= base.Toolbox()\ntoolbox.register(\"register() toolbox function is the desired name (or alias) for the new operator. The second argument is the existing function to be customized. Then, each additional (optional) argument is automatically passed to the customized function whenever we call the new operator. For example, look at this definition:\n\n```", "```py\n\n Calling the preceding function is equivalent to calling this:\n\n```", "```py\n\n This is because the `b` argument has been fixed to a value of `5` by the definition of the `incrementByFive` operator.\nCreating genetic operators\nIn many cases, the `Toolbox` class is used to customize existing functions from the `tools` module. The `tools` module contains numerous handy functions related to the genetic operations of *selection*, *crossover*, and *mutation*, as well as initialization utilities.\nFor example, the following code defines three aliases that will be later used as genetic operators:\n\n```", "```py\n\n The three aliases are defined as follows:\n\n*   **select** is registered as an alias to the existing **tools** function, **selTournament()**, with the **tournsize** argument set to **3**. This creates a **toolbox.select** operator that performs *tournament selection* with a tournament size of 3.\n*   **mate** is registered as an alias to the existing **tools** function, **cxTwoPoint()**. This results in a **toolbox.mate** operator that performs *two-point crossover*.\n*   **mutate** is registered as an alias to the existing **tools** function, **mutFlipBit**, with the **indpb** argument set to **0.02**, providing a **toolbox.mutate** operator that performs *flip-bit mutation* with 0.02 as the probability for each attribute to be flipped.\n\nThe `tools` module provides implementations of various genetic operators, including several of the ones we mentioned in the previous chapter.\n`selection.py` file. Some of them are as follows:\n\n*   **selRoulette()** implements **roulette** **wheel selection**\n*   **selStochasticUniversalSampling()** implements **Stochastic Universal** **Sampling** (**SUS**)\n*   **selTournament()** implements **tournament selection**\n\n`crossover.py` file:\n\n*   **cxOnePoint()** implements **single-point crossover**\n*   **cxUniform()** implements **uniform crossover**\n*   **cxOrdered()** implements **ordered** **crossover** (**OX1**)\n*   **cxPartialyMatched()** implements **partially matched** **crossover** (**PMX**)\n\nA couple of the `mutation.py` file are as follows:\n\n*   **mutFlipBit()** implements **flip-bit mutation**\n*   **mutGaussian()** implements **normally** **distributed mutation**\n\nCreating the population\nThe `init.py` file of the `tools` module contains several functions that can be useful for creating and initializing the population for the genetic algorithm. One particularly useful function is `initRepeat()`, which accepts three arguments:\n\n*   The container type in which we would like to put the resulting objects\n*   The function that’s used to generate objects that will be put into the container\n*   The number of objects we want to generate\n\nFor example, the following line of code will produce a list of 30 random numbers between 0 and 1:\n\n```", "```py\ndef zeroOrOne():\n    return random.randint(0, 1)\nrandomList = tools.initRepeat(list, toolbox, as follows:\n\n```", "```py\ndef someFitnessCalculationFunction(individual):\n    return _some_calculation_of_the_fitness\ntoolbox.register(\"evaluate\",someFitnessCalculationFunction() calculates the fitness for any given individual, while evaluate is registered as its alias.\nWe are finally ready to put our knowledge to use and solve our first problem using a genetic algorithm written with DEAP. We’ll do this in the next section.\nThe OneMax problem\nThe OneMax (or One-Max) problem is a simple optimization task that is often used as the *Hello World* of genetic algorithm frameworks. We will use this problem for the rest of this chapter to demonstrate how DEAP can be used to implement a genetic algorithm.\nThe OneMax task is to find the binary string of a given length that maximizes the sum of its digits. For example, the OneMax problem of length 5 will consider candidates such as the following:\n\n*   10010 (sum of digits = 2)\n*   01110 (sum of digits = 3)\n*   11111 (sum of digits = 5)\n\nObviously (to us), the solution to this problem is always the string that comprises all 1s. However, the genetic algorithm does not have this knowledge and needs to blindly look for the solution using its genetic operators. If the algorithm does its job, it will find this solution, or at least one close to it, within a reasonable amount of time.\nThe DEAP framework’s documentation uses the OneMax problem as its introductory example ([https://github.com/DEAP/deap/blob/master/examples/ga/onemax.py](https://github.com/DEAP/deap/blob/master/examples/ga/onemax.py)). In the following sections, we will describe our version of DEAP’s OneMax example.\nSolving the OneMax problem with DEAP\nIn the previous chapter, we mentioned several choices that need to be made when solving a problem using the genetic algorithm approach. As we tackle the OneMax problem, we will make these choices in a series of steps. In the chapters to follow, we will keep using the same series of steps as we apply the genetic algorithms approach to various types of problems.\nChoosing the chromosome\nSince the OneMax problem deals with binary strings, the choice of chromosome is easy – each individual will be represented with a binary string that directly represents a candidate solution. In the actual Python implementation, this will be implemented as a list containing integer values of either 0 or 1\\. The length of the chromosome matches the size of the OneMax problem. For example, for a OneMax problem of size 5, the 10010 individual will be represented by `[1, 0, 0,` `1, 0]`.\nCalculating the fitness\nSince we want to find the individual with the largest sum of digits, we are going to use the `FitnessMax` strategy. As each individual is represented by a list of integer values of either 0 or 1, the fitness value will be directly calculated as the sum of the elements in the list – for example, `sum([1, 0, 0, 1, 0]) =` `2`.\nChoosing the genetic operators\nNow, we need to decide on the genetic operators to be used – *selection*, *crossover*, and *mutation*. In the previous chapter, we examined several different types of each of these operators. Choosing these genetic operators is not an exact science, and we can usually experiment with several choices. But while selection operators can typically work with any chromosome type, the crossover and mutation operators we choose need to match the chromosome type we use; otherwise, they could produce invalid chromosomes.\nFor the selection operator, we can start with *tournament* selection because it is simple and efficient. Later, we can experiment with other selection strategies, such as *roulette wheel* selection and *SUS*.\nFor the *crossover* operator, either the *single-point* or *two-point* crossover operator will be suitable as the result of crossing over two binary strings using these methods will produce a valid binary string.\nThe *mutation* operator can be the simple *flip-bit* mutation, which works well for binary strings.\nSetting the stopping condition\nIt is always a good idea to put a limit on the number of generations to guarantee that the algorithm doesn’t run forever. This gives us one stopping condition.\nIn addition, since we happen to know the best solution for the OneMax problem – a binary string with all 1s, and a fitness value equal to the length of the individual – we can use that as a second stopping condition.\nImportant note\nFor a real-world problem, we typically don’t have this kind of knowledge in advance.\nIf either of these conditions is met – that is, the number of generations reaches the limit *or* the best solution is found – the genetic algorithm will stop.\nImplementing with DEAP\nPutting it all together, we can finally start coding our solution to the OneMax problem using the DEAP framework.\nThe complete program containing the code snippets shown in this section can be found here: [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_03/01_OneMax_long.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_03/01_OneMax_long.py).\nSetting up\nBefore we start the actual genetic algorithm flow, we need to set things up. The DEAP framework has quite a distinct way of doing this, as shown in the rest of this section:\n\n1.  We start by importing the essential modules of the DEAP framework, followed by a couple of useful utilities:\n\n    ```", "```py\n\n     2.  Next, we must declare a few constants that set the parameters for the problem and control the behavior of the genetic algorithm:\n\n    ```", "```py\n\n     3.  One important aspect of the genetic algorithm is the use of probability, which introduces a random element to the behavior of the algorithm. However, when experimenting with the code, we may want to be able to run the same experiment several times and get repeatable results. To accomplish this, we must set the random **seed** function to a constant number of some value, as shown in the following code snippet:\n\n    ```", "```py\n\nTip\nAt some point, you may decide to remove these lines of code, so separate runs could produce somewhat different results.\n\n1.  As we saw earlier in this chapter, the **Toolbox** class is one of the main utilities provided by the DEAP framework, enabling us to register new functions (or operators) that customize existing functions using pre-set arguments. Here, we’ll use it to create the **zeroOrOne** operator, which customizes the **random.randomint(a, b)** function. This function normally returns a random integer, **N**, such that **a ≤ N ≤ b**. By fixing the two arguments, **a** and **b**, to the values **0** and **1**, the **zeroOrOne** operator will randomly return either **0** or **1** when it’s called later in the code. The following code snippet defines the **toolbox** variable, and then uses it to register the **zeroOrOne** operator:\n\n    ```", "```py\n\n     2.  Next, we need to create the **Fitness** class. Since we only have one objective here – the sum of digits – and our goal is to maximize it, we’ll choose the **FitnessMax** strategy and use a **weights** tuple with a single positive weight, as shown in the following code snippet:\n\n    ```", "```py\n\n     3.  in DEAP, the convention is to use a class called **Individual** to represent each of the population’s individuals. This class is created with the help of the **creator** tool. In our case, **list** serves as the base class, which is used as the individual’s chromosome. The class is augmented with the **fitness** attribute, initialized to the **FitnessMax** class that we defined earlier:\n\n    ```", "```py\n\n     4.  Next, we must register the `zeroOrOne` operator are integers with random values of `0` or `1`, the resulting `individualCreator` operator will fill an `Individual` instance with 100 randomly generated values of `0` or `1`:\n\n    ```", "```py\n\n     5.  Lastly, we must register the `initRepeat` – the number of objects we want to generate – is not given here. This means that when using the `populationCreator` operator, this argument will be expected and used to determine the number of individuals that are created – in other words, the population size:\n\n    ```", "```py\n\n     6.  To facilitate the fitness calculation (or **evaluation**, in DEAP terminology), we must define a standalone function that accepts an instance of the **Individual** class and returns the fitness for it. Here, we defined a function named **oneMaxFitness** that computes the number of 1s in the individual. Since the individual is essentially a list with values of either **1** or **0**, the Python **sum()** function can be used for this purpose:\n\n    ```", "```py\n\nTip\nAs mentioned previously, fitness values in DEAP are represented as tuples, and therefore a comma needs to follow when a single value is returned.\n\n1.  Next, we must define the evaluate operator as an alias to the **oneMaxfitness()** function we defined earlier. As you will see later, using the **evaluate** alias to calculate the fitness is a DEAP convention:\n\n    ```", "```py\n    toolbox.register(\"select\",tools.selTournament,\\\n                      tournsize=3)\n    toolbox.register(\"mate\", tools.cxOnePoint)\n    toolbox.register(\"mutate\", tools.mutFlipBit,\\\n                      indpb=1.0/ONE_MAX_LENGTH)\n    ```", "```py\n\nWe are finally done with our settings and definitions. Now, we’re ready to start the genetic flow, as described in the next section.\nEvolving the solution\nThe genetic flow is implemented in the `main()` function, as described in the following steps:\n\n1.  We start the flow by creating the initial population using the **populationCreator** operator we defined earlier, and then using the **POPULATION_SIZE** constant as the argument for this operator. The **generationCounter** variable, which will be used later, is initialized here as well:\n\n    ```", "```py\n\n     2.  To calculate the fitness for each individual in the initial population, we can use the Python **map()** function to apply the **evaluate** operator to each item in the population. As the **evaluate** operator is an alias for the **oneMaxFitness()** function, the resulting **iterable** consists of the calculated fitness tuple of each individual. It is then converted into a **list** type of tuples:\n\n    ```", "```py\n\n     3.  Since the items of **fitnessValues** match those in the population (which is a list of individuals), we can use the **zip()** function to combine them and assign the matching fitness tuple to each individual:\n\n    ```", "```py\n\n     4.  Next, since we have single-objective fitness, we must extract the first value out of each fitness to gather statistics:\n\n    ```", "```py\n\n     5.  The statistics that are collected will be the max fitness value and the mean (average) fitness value for each generation. Two lists will be used for this purpose. Let’s create them:\n\n    ```", "```py\n\n     6.  We are finally ready for the main loop of the genetic flow. At the top of the loop, we have the stopping conditions. As we decided earlier, one stopping condition will be set by putting a limit on the number of generations, and the other will be set by detecting that we have reached the best solution (a binary string containing all 1s):\n\n    ```", "```py\n\n     7.  The generation counter is updated next. It is used by the stopping condition, as well as the **print** statements we will see soon:\n\n    ```", "```py\n\n     8.  At the heart of the genetic algorithm are the *genetic operators*, which are applied next. The first is the *selection* operator, which can be applied using the **toolbox.select** operator we defined as the *tournament selection* earlier. Since we already set the tournament size when the operator was defined, we only need to send the population and its length as arguments now:\n\n    ```", "```py\n\n     9.  The selected individuals, now residing in a list called **offspring**, must be cloned so that we can apply the next genetic operators without affecting the original population:\n\n    ```", "```py\n\nImportant note\nDespite the name **offspring**, these are still clones of individuals from the previous generation, and we still need to mate them using the **crossover** operator to create the actual offspring.\n\n1.  The next genetic operator is **crossover**. It was defined as the **toolbox.mate** operator earlier, and is aliasing a single-point crossover. We use Python extended slices to pair every even-indexed item of the **offspring** list with the one following it. Then, we utilize the **random()** function to flip a coin using the *crossover probability* set by the **P_CROSSOVER** constant. This will decide if the pair of individuals will be crossed over or remain intact. Lastly, we delete the fitness values of the children since they have been modified and their existing fitness values are no longer valid:\n\n    ```", "```py\n\nImportant note\nThe **mate** function takes two individuals as arguments and modifies them in place, meaning they don’t need to be reassigned.\n\n1.  The final genetic operator to be applied is the *mutation*, which we registered earlier as the **toolbox.mutate** operator, and was set to be a *flip-bit* mutation operation. Iterating over all **offspring** items, the mutation operator will be applied at the probability set by the mutation probability constant, **P_MUTATION**. If the individual gets mutated, we must delete its fitness value (if it exists). This value could have carried over with the individual from the previous generation, and after mutation, it is no longer correct and needs to be recalculated:\n\n    ```", "```py\n\n     2.  Individuals that were not crossed over or mutated remained intact, and therefore their existing fitness values, which were already calculated in a previous generation, don’t need to be calculated again. The rest of the individuals will have this value empty. Now, we must find those fresh individuals using the **Fitness** class’ **valid** property, then calculate the new fitness for them similarly to how to did the original calculation for fitness values:\n\n    ```", "```py\n\n     3.  Now that the genetic operators are done, it is time to replace the old population with the new one:\n\n    ```", "```py\n\n     4.  Before we continue to the next round, the current fitness values are collected to allow for statistical gathering. Since the fitness value is a (single element) tuple, we need to select the **[****0]** index:\n\n    ```", "```py\n\n     5.  The max and mean fitness values are then found, at which point their values get appended to the statistics accumulators and a summary line is printed out:\n\n    ```", "```py\n\n     6.  In addition, we must locate the index of the (first) best individual using the max fitness value we just found and print this individual out:\n\n    ```", "```py\n\n     7.  Once a stopping condition is activated and the genetic algorithm flow concludes, we can use the statistics accumulators to plot a couple of graphs using the **matplotlib** library. We can use the following code snippet to draw a graph illustrating the progress of the best and average fitness values throughout the generations:\n\n    ```", "```py\n\nWe are finally ready to test our first genetic algorithm – let’s run it to find out if it finds the OneMax solution.\nRunning the program\nWhen running the program described in the previous sections, we get the following output:\n\n```", "```py\n\n As you can see, after 40 generations, an *all-1* solution was found, which yielded a fitness of 100 and stopped the genetic flow. The *average fitness*, which started at a value of around 53, ended at a value close to 100.\nThe graph that’s plotted by `matplotlib` is shown here:\n![Figure 3.1: Stats of the program solving the OneMax problem](img/B20851_03_1.jpg)\n\nFigure 3.1: Stats of the program solving the OneMax problem\nThis plot illustrates how max fitness (the red line) increases over generations with incremental leaps, while the average fitness (the green line) keeps progressing smoothly.\nNow that we’ve solved the OneMax problem using the DEAP framework, let’s move on to the next section and find out how we can make our code more concise.\nUsing built-in algorithms\nThe DEAP framework comes with several built-in evolutionary algorithms provided by the `algorithms` module. One of them, `eaSimple`, implements the genetic algorithm flow we have been using, and can replace most of the code we had in the main method. Other useful DEAP objects, `Statistics` and `Logbook`, can be used for statistics gathering and printing, as we will soon see.\nThe program described in this section implements the same solution to the OneMax problem as the program discussed in the previous section but with less code. The only differences can be found in the `main` method. We will describe these differences in the following code snippets.\nThe complete program can be found here: [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_03/02_OneMax_short.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_03/02_OneMax_short.py).\nThe Statistics object\nThe first change we will make is in the way statistics are being gathered. To this end, we will now take advantage of the `tools.Statistics` class provided by DEAP. This utility enables us to create a `statistics` object using a key argument, which is a function that will be applied to the data on which the statistics are computed:\n\n1.  Since the data we plan to provide is the population of each generation, we’ll set the key function to one that extracts the fitness value(s) from each individual:\n\n    ```", "```py\n\n     2.  We can now register various functions that can be applied to these values at each step. In our example, we only use the **max** and **mean** NumPy functions, but others (such as **min** and **std**) can be registered as well:\n\n    ```", "```py\n\nAs we will see soon, the collected statistics will be returned in an object called `logbook` at the end of the run.\nThe algorithm\nNow, it’s time for the actual flow. This is done with a single call to the `algorithms.eaSimple` method, one of the built-in evolutionary algorithms provided by the `algorithms` module of DEAP. When we call the method, we provide it with `population`, `toolbox`, and the `statistics` object, among other parameters:\n\n```", "```py\n\n The `algorithms.eaSimple` method assumes that we previously used `toolbox` to register the following operators – `evaluate`, `select`, `mate`, and `mutate` – something we did when we created the original program. The stopping condition here is set by the value of `ngen`, which specifies the number of generations to run the algorithm for.\nThe logbook\nWhen the flow is done, the algorithm returns two objects – the final population and a `logbook` object containing the statistics that were collected. We can now extract the desired statistics from the logbook using the `select()` method so that we can use them for plotting, as we did previously:\n\n```", "```py\n\n We are now ready to run this slimmer version of the program.\nRunning the program\nWhen running the program with the same parameter values and settings that we used previously, the printouts will be as follows:\n\n```", "```py\n\n These printouts are automatically generated by the `algorithms.eaSimple` method, according to the way we defined the `statistics` object sent to it, as the `verbose` argument was set to `True`.\nThe results are numerically similar to what we saw in the previous program, with two differences:\n\n*   There is a printout for generation 0; this was not included in the previous program.\n*   The genetic flow here continues to the 50th generation as this was the only stopping condition. In the previous program, there was an additional stopping condition that stopped the flow at the 40th generation since the best solution (that we happened to know beforehand) was reached.\n\nWe can observe the same behavior in the new graph plot. This graph is similar to the one we saw before but it continues to the 50th generation, even though the best result was already reached at the 40th generation:\n![Figure 3.2: Stats of the program solving the OneMax problem using the built-in algorithm](img/B20851_03_2.jpg)\n\nFigure 3.2: Stats of the program solving the OneMax problem using the built-in algorithm\nConsequently, starting at the 40th generation, the value of the best fitness (the red line) no longer changes, while the average fitness (the green line) keeps climbing until it almost reaches the same max value. This means that by the end of this run, nearly all individuals are identical to the best one.\nAdding the hall of fame feature\nOne additional feature of the built-in `algorithms.eaSimple` method is the `tools` module, the `HallOfFame` class can be used to retain the best individuals that ever existed in the population during the evolution, even if they have been lost at some point due to selection, crossover, or mutation. The hall of fame is continuously sorted so that the first element is the first individual that has the best fitness value ever seen.\nThe complete program containing the code snippets shown in this section can be found here: [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_03/03_OneMax_short_hof.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_03/03_OneMax_short_hof.py).\nTo add the hall of fame functionality, let’s make a few modifications to the previous program:\n\n1.  We start by defining a constant for the number of individuals we want to keep in the hall of fame. We will add this line to the constant definition section:\n\n    ```", "```py\n\n     2.  Just before calling the **eaSimple** algorithm, we’ll create the **HallOfFame** object with that size:\n\n    ```", "```py\n\n     3.  The **HallOfFame** object is sent as an argument to the **eaSimple** algorithm, which internally updates it during the run of the genetic algorithm flow:\n\n    ```", "```py\n\n     4.  When the algorithm is done, we can use the **HallOfFame** object’s **items** attribute to access the list of individuals who were inducted into the hall of fame:\n\n    ```", "```py\n\n    The printed results look as follows – the best individual consists of all 1s, followed by various individuals that have a 0 value in various locations:\n\n    ```", "```py\n\n     5.  The best individual is the same one that was printed first previously:\n\n    ```", "```py\n\n     6.  From now on, we will use these features – the **statistics** object and **logbook**, the built-in **eaSimple** algorithm, and **HallOfFame** – in all the programs we create.\n\nNow that we’ve learned how to use the inbuilt algorithms, we’ll experiment with them to find their differences and find the best algorithm for various uses.\nExperimenting with the algorithm’s settings\nWe can now experiment with the various settings and definitions we placed into the program and observe any changes in their behavior and results.\nIn each of the following subsections, we’ll start from the original program settings and make one or more changes. You are encouraged to experiment with making your own modifications, as well as combining several modifications to be made to the same program.\nBear in mind that the effects of changes we make may be specific to the problem at hand – a simple *OneMax*, in our case – and may be different for other types of problems.\nPopulation size and number of generations\nWe will start our experimentation by making modifications to the **population size** and the number of generations used by the genetic algorithm:\n\n1.  The size of the population is determined by the **POPULATION_SIZE** constant. We will start by increasing the value of this constant from 200 to 400:\n\n    ```", "```py\n\n    This modification accelerates the genetic flow. The best solution is now found after 22 generations, as shown in the following figure:\n\n![Figure 3.3: Stats of the program solving the OneMax problem after increasing the population size to 400](img/B20851_03_3.jpg)\n\nFigure 3.3: Stats of the program solving the OneMax problem after increasing the population size to 400\n\n1.  Next, we will try reducing the population size to 100:\n\n    ```", "```py\n\n     2.  This modification slows down the convergence of the algorithm, which will no longer reach the best possible value after 50 generations:\n\n![Figure 3.4: Stats of the program solving the OneMax problem after decreasing the population size to 100](img/B20851_03_4.jpg)\n\nFigure 3.4: Stats of the program solving the OneMax problem after decreasing the population size to 100\n\n1.  To compensate, let’s try increasing the value of **MAX_GENERATIONS** to 80:\n\n    ```", "```py\n\n     2.  We find that the best solution is now reached after 68 generations:\n\n![Figure 3.5: Stats of the program solving the OneMax problem after increasing the number of generations to 80](img/B20851_03_5.jpg)\n\nFigure 3.5: Stats of the program solving the OneMax problem after increasing the number of generations to 80\nThis behavior is typical of genetic-algorithm-based solutions – increasing the population will require fewer generations to reach a solution. However, the computational and memory requirements increase with the population size, and we typically aspire to find a moderate population size that will provide a solution within a reasonable amount of time.\nCrossover operator\nLet’s reset our changes and go back to the original settings (50 generations, population size 200). We are now ready to experiment with the **crossover** operator, which is responsible for creating offspring from parent individuals.\nChanging the crossover type from a `mate` operator as follows:\n\n```", "```py\n\n The algorithm now finds the best solution after only 27 generations:\n![Figure 3.6: Stats of the program solving the OneMax problem after switching to a two-point crossover](img/B20851_03_6.jpg)\n\nFigure 3.6: Stats of the program solving the OneMax problem after switching to a two-point crossover\nThis behavior is typical of genetic algorithms that utilize binary string representation as two-point crossover provides a more versatile way to combine two parents and mix their genes in comparison to the single-point crossover.\nMutation operator\nWe will now reset our changes again as we get ready to experiment with the **mutation** operator, which is responsible for introducing random modifications to offspring:\n\n1.  We will start by increasing the value of the **P_MUTATION** constant to **0.9**. This results in the following plot:\n\n![Figure 3.7: Stats of the program solving the OneMax problem after increasing the mutation probability to 0.9](img/B20851_03_7.jpg)\n\nFigure 3.7: Stats of the program solving the OneMax problem after increasing the mutation probability to 0.9\nThe results may seem surprising at first as increasing the mutation rate typically causes the algorithm to behave erratically, while here, the effect is seemingly unnoticeable. However, recall that there is another mutation-related parameter in our algorithm, `indpb`, which is an argument of the specific mutation operator we used here – `mutFlipBit`:\n\n```", "```py\n    toolbox.register(\"mutate\", tools.mutFlipBit, \\\n        indpb=10.0/ONE_MAX_LENGTH)\n    ```", "```py\n    toolbox.register(\"select\", tools.selTournament, tournsize=2)\n    ```", "```py\n    toolbox.register(\"select\", tools.selTournament, tournsize=100)\n    ```", "```py\n    P_MUTATION = 0.01\n    ```", "```py\n    P_MUTATION = 0.001\n    ```", "```py\n    MAX_GENERATIONS = 50\n    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n    ```", "```py\ntoolbox.register(\"select\", tools.selRoulette)\n```", "```py\n\n```", "```py\n\n```", "```py\n\n```", "```py\n\n```"]