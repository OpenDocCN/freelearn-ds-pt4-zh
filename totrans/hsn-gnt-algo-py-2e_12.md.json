["```py\nfrom sklearn import datasets\ndata = datasets.load_iris()\nX = data['data']\ny = data['target']\n```", "```py\n    if round(params[1]) <= 0:\n        hiddenLayerSizes = round(params[0]),\n    elif round(params[2]) <= 0:\n        hiddenLayerSizes = (round(params[0]),\n                            round(params[1]))\n    elif round(params[3]) <= 0:\n        hiddenLayerSizes = (round(params[0]),\n                            round(params[1]),\n                            round(params[2]))\n    else:\n        hiddenLayerSizes = (round(params[0]),\n                            round(params[1]),\n                            round(params[2]),\n                            round(params[3]))\n    ```", "```py\n    hiddenLayerSizes = self.convertParams(params)\n    self.classifier = MLPClassifier(\n        hidden_layer_sizes=hiddenLayerSizes)\n    ```", "```py\n    cv_results = model_selection.cross_val_score(self.classifier,\n                                    self.X,\n                                    self.y,\n                                    cv=self.kfold,\n                                    scoring='accuracy')\n    return cv_results.mean()\n    ```", "```py\n    # [hidden_layer_layer_1_size, hidden_layer_2_size\n    #  hidden_layer_3_size, hidden_layer_4_size]\n    BOUNDS_LOW =  [ 5,  -5, -10, -20]\n    BOUNDS_HIGH = [15,  10,  10,  10]\n    ```", "```py\n    test = mlp_layers_test.MlpLayersTest(RANDOM_SEED)\n    ```", "```py\n    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n    ```", "```py\n    for i in range(NUM_OF_PARAMS):\n        toolbox.register(\"layer_size_attribute_\" + str(i),\n                          random.uniform,\n                          BOUNDS_LOW[i],\n                          BOUNDS_HIGH[i])\n    ```", "```py\n    layer_size_attributes = ()\n    for i in range(NUM_OF_PARAMS):\n        layer_size_attributes = layer_size_attributes + \\\n        (toolbox.__getattribute__(\"layer_size_attribute_\" + \\\n            str(i)),)\n    ```", "```py\n    toolbox.register(\"individualCreator\",\n                      tools.initCycle,\n                      creator.Individual,\n                      layer_size_attributes,\n                      n=1)\n    ```", "```py\n    def classificationAccuracy(individual):\n        return test.getAccuracy(individual),\n    toolbox.register(\"evaluate\", classificationAccuracy)\n    ```", "```py\n    toolbox.register(\"select\",\n                      tools.selTournament,\n                      tournsize=2)\n    toolbox.register(\"mate\",\n                      tools.cxSimulatedBinaryBounded,\n                      low=BOUNDS_LOW,\n                      up=BOUNDS_HIGH,\n                      eta=CROWDING_FACTOR)\n    toolbox.register(\"mutate\",\n                      tools.mutPolynomialBounded,\n                      low=BOUNDS_LOW,\n                      up=BOUNDS_HIGH,\n                      eta=CROWDING_FACTOR,\n                      indpb=1.0 / NUM_OF_PARAMS)\n    ```", "```py\n    population, logbook = elitism.eaSimpleWithElitism(population,\n        toolbox,\n        cxpb=P_CROSSOVER,\n        mutpb=P_MUTATION,\n        ngen=MAX_GENERATIONS,\n        stats=stats,\n        halloffame=hof,\n        verbose=True)\n    ```", "```py\ngen nevals max avg\n0 20 0.666667 0.416333\n1 17 0.693333 0.487\n2 15 0.76 0.537333\n3 14 0.76 0.550667\n4 17 0.76 0.568333\n5 17 0.76 0.653667\n6 14 0.76 0.589333\n7 15 0.76 0.618\n8 16 0.866667 0.616667\n9 16 0.866667 0.666333\n10 16 0.866667 0.722667\n- Best solution is: 'hidden_layer_sizes'=(15, 5, 8) , accuracy = 0.8666666666666666\n```", "```py\n    activation = ['tanh', 'relu', 'logistic', 'identity'][floor(params[4])]\n    solver = ['sgd', 'adam', 'lbfgs'][floor(params[5])]\n    alpha = params[6]\n    learning_rate = ['constant', 'invscaling',\n        'adaptive'][floor(params[7])]\n    ```", "```py\n    hiddenLayerSizes, activation, solver, alpha, learning_rate = \\\n        self.convertParams(params)\n    self.classifier = MLPClassifier(\n        random_state=self.randomSeed,\n        hidden_layer_sizes=hiddenLayerSizes,\n        activation=activation,\n        solver=solver,\n        alpha=alpha,\n        learning_rate=learning_rate)\n    ```", "```py\n# 'hidden_layer_sizes': first four values\n# 'activation'        : 0..3.99\n# 'solver'            : 0..2.99\n# 'alpha'             : 0.0001..2.0\n# 'learning_rate'     : 0..2.99\nBOUNDS_LOW =  [ 5,  -5, -10, -20, 0,     0,     0.0001, 0]\nBOUNDS_HIGH = [15,  10,  10,  10, 3.999, 2.999, 2.0,    2.999]\n```", "```py\ngen     nevals  max     avg\n0       20      0.94    0.605667\n1       15      0.94    0.667\n2       16      0.94    0.848667\n3       17      0.94    0.935\n4       17      0.94    0.908667\n5       15      0.94    0.936\n6       15      0.94    0.889667\n7       16      0.94    0.938333\n8       17      0.946667        0.938333\n9       13      0.946667        0.938667\n10      15      0.946667        0.940667\n- Best solution is:\n'hidden_layer_sizes'=(7, 4, 6)\n'activation'='tanh'\n'solver'='lbfgs'\n'alpha'=1.2786182334834102\n'learning_rate'='constant'\n=> accuracy =  0.9466666666666667\n```"]