<html><head></head><body>
<div id="_idContainer145" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-274"><a id="_idTextAnchor326" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.1.1">13</span></h1>
<h1 id="_idParaDest-275" class="calibre5"><a id="_idTextAnchor327" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.2.1">Accelerating Genetic Algorithms – the Power of Concurrency</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">This chapter delves into the use of concurrency, with a special focus on multiprocessing, as a means to boost the performance of genetic algorithms. </span><span class="kobospan" id="kobo.3.2">We will explore both built-in Python functionalities and an external library to achieve </span><span><span class="kobospan" id="kobo.4.1">this enhancement.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.5.1">The chapter starts by highlighting the potential benefits of applying </span><strong class="bold"><span class="kobospan" id="kobo.6.1">concurrency</span></strong><span class="kobospan" id="kobo.7.1"> to genetic algorithms. </span><span class="kobospan" id="kobo.7.2">We then proceed to put this theory into practice by experimenting with various </span><strong class="bold"><span class="kobospan" id="kobo.8.1">multiprocessing</span></strong><span class="kobospan" id="kobo.9.1"> approaches </span><a id="_idIndexMarker795" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.10.1">to a CPU-intensive version of the well-known One-Max problem. </span><span class="kobospan" id="kobo.10.2">This enables us to gauge the extent of performance improvements achievable through </span><span><span class="kobospan" id="kobo.11.1">these techniques.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.12.1">By the end of this chapter, you will be able to do </span><span><span class="kobospan" id="kobo.13.1">the following:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.14.1">Understand why genetic algorithms can be computationally intensive </span><span><span class="kobospan" id="kobo.15.1">and time-consuming</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.16.1">Recognize why genetic algorithms are well-suited for </span><span><span class="kobospan" id="kobo.17.1">concurrent execution</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.18.1">Implement a CPU-intensive version of the One-Max problem, which we have </span><span><span class="kobospan" id="kobo.19.1">previously explored</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.20.1">Learn how to use Python’s built-in multiprocessing module to accelerate the genetic </span><span><span class="kobospan" id="kobo.21.1">algorithm process</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.22.1">Become familiar with the SCOOP library and learn how to integrate it with the DEAP framework to further enhance the efficiency of </span><span><span class="kobospan" id="kobo.23.1">genetic algorithms</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.24.1">Experiment with both methods and gain insights into the application of multiprocessing to the problem </span><span><span class="kobospan" id="kobo.25.1">at hand</span></span></li>
</ul>
<h1 id="_idParaDest-276" class="calibre5"><a id="_idTextAnchor328" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.26.1">Technical requirements</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.27.1">In this chapter, we will use Python 3 with the following </span><span><span class="kobospan" id="kobo.28.1">supporting libraries:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.29.1">deap</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.30.1">numpy</span></strong></span></li>
<li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.31.1">scoop</span></strong><span class="kobospan" id="kobo.32.1"> – introduced in </span><span><span class="kobospan" id="kobo.33.1">this chapter</span></span></li>
</ul>
<p class="callout-heading"><span class="kobospan" id="kobo.34.1">Important note</span></p>
<p class="callout"><span class="kobospan" id="kobo.35.1">If you use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.36.1">requirements.txt</span></strong><span class="kobospan" id="kobo.37.1"> file we provide (see </span><a href="B20851_03.xhtml#_idTextAnchor091" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.38.1">Chapter 3</span></em></span></a><span class="kobospan" id="kobo.39.1">), these libraries are already included in </span><span><span class="kobospan" id="kobo.40.1">your environment.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.41.1">The programs that will be used in this chapter can be found in this book’s GitHub repository at </span><a href="https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_13" class="calibre6 pcalibre pcalibre1"><span class="kobospan" id="kobo.42.1">https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_13</span></a><span class="kobospan" id="kobo.43.1">. </span></p>
<p class="calibre3"><span class="kobospan" id="kobo.44.1">Check out the following video to see the Code in Action: </span></p>
<p class="calibre3"><a href="https://packt.link/OEBOd" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.45.1">https://packt.link/OEBOd</span></span></a></p>
<h1 id="_idParaDest-277" class="calibre5"><a id="_idTextAnchor329" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.46.1">Long runtimes in real-world genetic algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.47.1">The example programs we’ve explored so far, while addressing practical problems, were intentionally designed to converge quickly to a reasonable solution. </span><span class="kobospan" id="kobo.47.2">However, in the context of real-world applications, the use of genetic algorithms often proves to be highly time-consuming due to the </span><a id="_idIndexMarker796" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.48.1">way they operate – exploring the solution space by considering a diverse set of potential solutions. </span><span class="kobospan" id="kobo.48.2">The main factors affecting the running time of a typical genetic algorithm are </span><span><span class="kobospan" id="kobo.49.1">as follows:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.50.1">The number of generations</span></strong><span class="kobospan" id="kobo.51.1">: Genetic algorithms operate through a series of generations, each involving the evaluation, selection, and manipulation of </span><span><span class="kobospan" id="kobo.52.1">the population.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.53.1">The population size</span></strong><span class="kobospan" id="kobo.54.1">: Genetic algorithms maintain a population of potential solutions; more complex problems typically require larger populations. </span><span class="kobospan" id="kobo.54.2">This increases the number of individuals that need evaluation, selection, and manipulation in </span><span><span class="kobospan" id="kobo.55.1">each generation.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.56.1">Fitness evaluation</span></strong><span class="kobospan" id="kobo.57.1">: The fitness of each individual in the population must be evaluated to determine how well it solves the problem. </span><span class="kobospan" id="kobo.57.2">Depending on the complexity of the fitness function or the nature of the optimization problem, the evaluation process</span><a id="_idIndexMarker797" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.58.1"> can be both computationally expensive </span><span><span class="kobospan" id="kobo.59.1">and time-consuming.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.60.1">Genetic operations</span></strong><span class="kobospan" id="kobo.61.1">: Selection is used to choose pairs of individuals that will serve as parents for each new generation. </span><span class="kobospan" id="kobo.61.2">Crossover and mutation are applied to each of these pairs and, depending on the algorithm’s design, can be computationally intensive, especially when dealing with complex data structures. </span><span class="kobospan" id="kobo.61.3">In practice, however, the duration of the fitness function often dominates the time consumed </span><span><span class="kobospan" id="kobo.62.1">per individual.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.63.1">One obvious way to mitigate the long running times of genetic algorithms is the use of parallelization, as we will explore further in the </span><span><span class="kobospan" id="kobo.64.1">following section.</span></span></p>
<h1 id="_idParaDest-278" class="calibre5"><a id="_idTextAnchor330" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.65.1">Parallelizing genetic algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.66.1">Within a single generation, genetic algorithms can be considered </span><strong class="bold"><span class="kobospan" id="kobo.67.1">embarrassingly parallelizable</span></strong><span class="kobospan" id="kobo.68.1"> – they can be effortlessly divided into multiple independent tasks, with minimal or no dependency or</span><a id="_idIndexMarker798" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.69.1"> interaction between them. </span><span class="kobospan" id="kobo.69.2">This is because the fitness evaluation and manipulation of individuals in the population are typically independent tasks. </span><span class="kobospan" id="kobo.69.3">Each individual’s fitness is evaluated based on its own characteristics, and genetic operators (crossover and mutation) are applied independently to pairs of individuals. </span><span class="kobospan" id="kobo.69.4">This independence allows for the straightforward parallel execution of </span><span><span class="kobospan" id="kobo.70.1">these tasks.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.71.1">Two parallelization methods – </span><strong class="bold"><span class="kobospan" id="kobo.72.1">multithreading</span></strong><span class="kobospan" id="kobo.73.1"> and </span><strong class="bold"><span class="kobospan" id="kobo.74.1">multiprocessing</span></strong><span class="kobospan" id="kobo.75.1"> – come to mind, as we will explore in the </span><span><span class="kobospan" id="kobo.76.1">following subsections.</span></span></p>
<h2 id="_idParaDest-279" class="calibre7"><a id="_idTextAnchor331" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.77.1">Multithreading</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.78.1">Multithreading is a concurrent execution </span><a id="_idIndexMarker799" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.79.1">model that allows multiple threads to exist within the same process, sharing the same resources, such as memory space, but running independently. </span><span class="kobospan" id="kobo.79.2">Each thread represents a separate flow of control, allowing a program to execute multiple </span><span><span class="kobospan" id="kobo.80.1">tasks concurrently.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.81.1">In a multithreaded environment, threads can be thought of as lightweight processes that share the same address space. </span><span class="kobospan" id="kobo.81.2">Multithreading is particularly beneficial for tasks that can be divided into </span><a id="_idIndexMarker800" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.82.1">smaller, independent units of work, enabling efficient use of available resources and enhancing responsiveness. </span><span class="kobospan" id="kobo.82.2">This is illustrated by the </span><span><span class="kobospan" id="kobo.83.1">following diagram:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer140">
<span class="kobospan" id="kobo.84.1"><img alt="Figure 13.1: Multiple threads running concurrently within a single process" src="image/B20851_13_1.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.85.1">Figure 13.1: Multiple threads running concurrently within a single process</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.86.1">However, multithreading in Python faces some limitations that impact its effectiveness for our use case. </span><span class="kobospan" id="kobo.86.2">A major </span><a id="_idIndexMarker801" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.87.1">factor is the </span><strong class="bold"><span class="kobospan" id="kobo.88.1">Global Interpreter Lock</span></strong><span class="kobospan" id="kobo.89.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.90.1">GIL</span></strong><span class="kobospan" id="kobo.91.1">) in CPython, the standard implementation of Python. </span><span class="kobospan" id="kobo.91.2">The GIL is a </span><strong class="bold"><span class="kobospan" id="kobo.92.1">mutex</span></strong><span class="kobospan" id="kobo.93.1"> (mutually exclusive lock) that</span><a id="_idIndexMarker802" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.94.1"> protects access to Python objects, preventing multiple native threads from executing Python bytecodes at the same time. </span><span class="kobospan" id="kobo.94.2">As a result, the benefits of multithreading are primarily seen in I/O-bound tasks, as we will explore in the following chapter. </span><span class="kobospan" id="kobo.94.3">For computation-intensive tasks that don’t frequently release the GIL, common in many numerical computations, multithreading may not provide the expected performance improvements. </span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.95.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.96.1">Discussions within the Python community and ongoing research suggest that the limitations imposed by the GIL may be lifted in a future version of Python, potentially enhancing </span><span><span class="kobospan" id="kobo.97.1">multithreading efficiency.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.98.1">Fortunately, the approach described next is a highly </span><span><span class="kobospan" id="kobo.99.1">viable option.</span></span></p>
<h2 id="_idParaDest-280" class="calibre7"><a id="_idTextAnchor332" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.100.1">Multiprocessing</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.101.1">Multiprocessing is a concurrent computing paradigm that involves the simultaneous execution of multiple processes within a</span><a id="_idIndexMarker803" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.102.1"> computer system. </span><span class="kobospan" id="kobo.102.2">In contrast to multithreading, multiprocessing allows for the creation of independent processes, each with its dedicated memory space. </span><span class="kobospan" id="kobo.102.3">These processes can run concurrently on different CPU cores or processors, making it a powerful technique to parallelize tasks and capitalize on modern multi-core architectures, as illustrated in the </span><span><span class="kobospan" id="kobo.103.1">following diagram:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer141">
<span class="kobospan" id="kobo.104.1"><img alt="Figure 13.2: Multiple processes running concurrently on separate cores" src="image/B20851_13_2.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.105.1">Figure 13.2: Multiple processes running concurrently on separate cores</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.106.1">Operating independently, each process avoids limitations associated with shared memory models, such as the GIL in Python. </span><span class="kobospan" id="kobo.106.2">Multiprocessing proves particularly effective for CPU-bound tasks, commonly encountered in genetic algorithms, where the computational workload can be divided into </span><span><span class="kobospan" id="kobo.107.1">parallelizable units.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.108.1">As multiprocessing seems to be a viable way to enhance the performance of genetic algorithms, we will explore</span><a id="_idIndexMarker804" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.109.1"> its implementation throughout the remainder of this chapter, using a new version of the OneMax problem as </span><span><span class="kobospan" id="kobo.110.1">our benchmark.</span></span></p>
<h1 id="_idParaDest-281" class="calibre5"><a id="_idTextAnchor333" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.111.1">Back to the OneMax problem</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.112.1">In </span><a href="B20851_03.xhtml#_idTextAnchor091" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.113.1">Chapter 3</span></em></span></a><span class="kobospan" id="kobo.114.1">, </span><em class="italic"><span class="kobospan" id="kobo.115.1">Using the DEAP Framework</span></em><span class="kobospan" id="kobo.116.1">, we utilized the OneMax problem as the “Hello World” of genetic algorithms. </span><span class="kobospan" id="kobo.116.2">As a quick recap, the objective is to discover the binary string of a specified length that maximizes</span><a id="_idIndexMarker805" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.117.1"> the sum of its digits. </span><span class="kobospan" id="kobo.117.2">For instance, when dealing with a OneMax problem of length 5, candidate solutions such as 10010 (sum of digits = 2) and 01110 (sum of digits = 3) are considered, ultimately leading to the optimal solution of 11111 (sum of digits = </span><span><span class="kobospan" id="kobo.118.1">5).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.119.1">While, in </span><a href="B20851_03.xhtml#_idTextAnchor091" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.120.1">Chapter 3</span></em></span></a><span class="kobospan" id="kobo.121.1">, we used a problem length of 100, a population size of 200, and 50 generations, here we will tackle a significantly scaled-down version, having a length of 10, a population size of 20, and only 5 generations. </span><span class="kobospan" id="kobo.121.2">The reasons for this adjustment will become </span><span><span class="kobospan" id="kobo.122.1">apparent shortly.</span></span></p>
<h2 id="_idParaDest-282" class="calibre7"><a id="_idTextAnchor334" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.123.1">A baseline benchmark program</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.124.1">The initial version of this </span><a id="_idIndexMarker806" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.125.1">Python program is </span><strong class="source-inline"><span class="kobospan" id="kobo.126.1">01_one_max_start.py</span></strong><span class="kobospan" id="kobo.127.1">, available </span><span><span class="kobospan" id="kobo.128.1">at </span></span><a href="https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/01_one_max_start.py" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.129.1">https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/01_one_max_start.py</span></span></a><span><span class="kobospan" id="kobo.130.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.131.1">The main functionality of this program is outlined </span><span><span class="kobospan" id="kobo.132.1">as follows:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.133.1">Candidate solutions are represented using a list of integers, with values 0 </span><span><span class="kobospan" id="kobo.134.1">and 1.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.135.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.136.1">oneMaxFitness()</span></strong><span class="kobospan" id="kobo.137.1"> function calculates the fitness by summing the elements of </span><span><span class="kobospan" id="kobo.138.1">the list:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.139.1">
def oneMaxFitness(individual):
    return </span><strong class="bold1"><span class="kobospan1" id="kobo.140.1">sum(individual)</span></strong><span class="kobospan1" id="kobo.141.1">, # return a tuple
toolbox.register("evaluate", </span><strong class="bold1"><span class="kobospan1" id="kobo.142.1">oneMaxFitness</span></strong><span class="kobospan1" id="kobo.143.1">)</span></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.144.1">For genetic operators, we employ </span><em class="italic"><span class="kobospan" id="kobo.145.1">tournament selection</span></em><span class="kobospan" id="kobo.146.1"> with a tournament size of 4, </span><em class="italic"><span class="kobospan" id="kobo.147.1">single-point crossover</span></em><span class="kobospan" id="kobo.148.1">, and </span><span><em class="italic"><span class="kobospan" id="kobo.149.1">flip-bit mutation</span></em></span><span><span class="kobospan" id="kobo.150.1">.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.151.1">The </span><em class="italic"><span class="kobospan" id="kobo.152.1">elitist</span></em><span class="kobospan" id="kobo.153.1"> approach is applied, utilizing the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.154.1">elitism.eaSimpleWithElitism()</span></strong></span><span><span class="kobospan" id="kobo.155.1"> function.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.156.1">The program’s runtime</span><a id="_idIndexMarker807" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.157.1"> duration is measured using </span><strong class="source-inline1"><span class="kobospan" id="kobo.158.1">time.time()</span></strong><span class="kobospan" id="kobo.159.1"> function calls, surrounding the invocation of the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.160.1">main()</span></strong></span><span><span class="kobospan" id="kobo.161.1"> function:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.162.1">
if __name__ == "__main__":
    </span><strong class="bold1"><span class="kobospan1" id="kobo.163.1">start</span></strong><span class="kobospan1" id="kobo.164.1"> = time.time()
    main()
    </span><strong class="bold1"><span class="kobospan1" id="kobo.165.1">end</span></strong><span class="kobospan1" id="kobo.166.1"> = time.time()
print(f"Elapsed time = {(</span><strong class="bold1"><span class="kobospan1" id="kobo.167.1">end - start)</span></strong><span class="kobospan1" id="kobo.168.1">:.2f} seconds")</span></pre></li> </ol>
<p class="calibre3"><span class="kobospan" id="kobo.169.1">Running the program yields the </span><span><span class="kobospan" id="kobo.170.1">following output:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.171.1">
gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
</span><strong class="bold1"><span class="kobospan1" id="kobo.172.1">Elapsed time = 0.00 seconds</span></strong></pre> <p class="calibre3"><span class="kobospan" id="kobo.173.1">The output indicates that the program achieved the optimal solution of 1111111111 by the 5th generation, completing its run in less than 10 milliseconds (considering only the first two decimal digits of the </span><span><span class="kobospan" id="kobo.174.1">elapsed time).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.175.1">Another noteworthy detail, which will play a part in subsequent experiments, is the number of fitness evaluations carried out at each generation. </span><span class="kobospan" id="kobo.175.2">The relevant values can be found in the second column from the left, </span><strong class="source-inline"><span class="kobospan" id="kobo.176.1">nevals</span></strong><span class="kobospan" id="kobo.177.1">. </span><span class="kobospan" id="kobo.177.2">Despite a population size of 20, there are typically fewer than 20 evaluations per generation. </span><span class="kobospan" id="kobo.177.3">This is because the algorithm skips the fitness function if it has already been calculated for a similar individual. </span><span class="kobospan" id="kobo.177.4">Summing the </span><a id="_idIndexMarker808" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.178.1">values in this column, we find that the total number of fitness evaluations executed during the program’s run amounts </span><span><span class="kobospan" id="kobo.179.1">to 95.</span></span></p>
<h1 id="_idParaDest-283" class="calibre5"><a id="_idTextAnchor335" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.180.1">Simulating computational intensity</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.181.1">As mentioned earlier, the most computationally intensive task in a genetic algorithm is often the fitness evaluation of</span><a id="_idIndexMarker809" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.182.1"> individuals. </span><span class="kobospan" id="kobo.182.2">To simulate this aspect, we will now intentionally extend the execution time of our </span><span><span class="kobospan" id="kobo.183.1">fitness function.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.184.1">This modification is implemented in the Python program, </span><strong class="source-inline"><span class="kobospan" id="kobo.185.1">02_one_max_busy.py</span></strong><span class="kobospan" id="kobo.186.1">, available </span><span><span class="kobospan" id="kobo.187.1">at </span></span><a href="https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/02_one_max_busy.py" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.188.1">https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/02_one_max_busy.py</span></span></a><span><span class="kobospan" id="kobo.189.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.190.1">This program is based on the previous one, with the </span><span><span class="kobospan" id="kobo.191.1">following modifications:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.192.1">A </span><strong class="source-inline1"><span class="kobospan" id="kobo.193.1">busy_wait()</span></strong><span class="kobospan" id="kobo.194.1"> function is added. </span><span class="kobospan" id="kobo.194.2">This function exercises an empty loop for a specified duration (</span><span><span class="kobospan" id="kobo.195.1">in seconds):</span></span><pre class="source-code"><span class="kobospan1" id="kobo.196.1">
def busy_wait(</span><strong class="bold1"><span class="kobospan1" id="kobo.197.1">duration</span></strong><span class="kobospan1" id="kobo.198.1">):
    current_time = time.time()
    while (time.time() &lt; current_time + </span><strong class="bold1"><span class="kobospan1" id="kobo.199.1">duration</span></strong><span class="kobospan1" id="kobo.200.1">):
        pass</span></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.201.1">The original fitness function is updated to incorporate a call to the </span><strong class="source-inline1"><span class="kobospan" id="kobo.202.1">busy_wait()</span></strong><span class="kobospan" id="kobo.203.1"> function before calculating the sum of </span><span><span class="kobospan" id="kobo.204.1">the digits:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.205.1">
def oneMaxFitness(individual):
    </span><strong class="bold1"><span class="kobospan1" id="kobo.206.1">busy_wait(DELAY_SECONDS)</span></strong><span class="kobospan1" id="kobo.207.1">
    return sum(individual), # return a tuple</span></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.208.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.209.1">DELAY_SECONDS</span></strong><span class="kobospan" id="kobo.210.1"> constantis added, and its value is set </span><span><span class="kobospan" id="kobo.211.1">to 3:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.212.1">
      </span><strong class="bold1"><span class="kobospan1" id="kobo.213.1">DELAY_SECONDS</span></strong><span class="kobospan1" id="kobo.214.1"> = 3</span></pre></li> </ol>
<p class="calibre3"><span class="kobospan" id="kobo.215.1">Running the modified program yields the </span><span><span class="kobospan" id="kobo.216.1">following output:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.217.1">
gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
</span><strong class="bold1"><span class="kobospan1" id="kobo.218.1">Elapsed time = 285.01 seconds</span></strong></pre> <p class="calibre3"><span class="kobospan" id="kobo.219.1">As anticipated, the output</span><a id="_idIndexMarker810" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.220.1"> of the modified program is identical to that of the original, with the notable exception of the elapsed time, which has significantly increased to approximately </span><span><span class="kobospan" id="kobo.221.1">285 seconds.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.222.1">This duration makes perfect sense; as highlighted in the previous section, there are 95 executions of the fitness function throughout the program’s run (the sum of the values in the </span><strong class="source-inline"><span class="kobospan" id="kobo.223.1">nevals</span></strong><span class="kobospan" id="kobo.224.1"> column). </span><span class="kobospan" id="kobo.224.2">With each execution now taking an additional 3 seconds, the anticipated additional time is calculated as 95 times 3 seconds, totaling </span><span><span class="kobospan" id="kobo.225.1">285 seconds.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.226.1">While examining these results, let’s also establish the theoretical limit, or the best-case scenario we can aim for. </span><span class="kobospan" id="kobo.226.2">As indicated in the output, the execution of our benchmark genetic algorithm involves six “rounds” of fitness calculations – one for the initial generation (“generation zero”) and one for each of the five subsequent generations. </span><span class="kobospan" id="kobo.226.3">The best achievable time in the context of perfect concurrency within each generation is 3 seconds, equal to the duration of a single fitness evaluation. </span><span class="kobospan" id="kobo.226.4">Therefore, the optimal result we could theoretically achieve would be 18 seconds, calculated as 6 times 3 seconds </span><span><span class="kobospan" id="kobo.227.1">per round.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.228.1">With this theoretical limit in mind, we can now proceed to explore the application of multiprocessing to </span><span><span class="kobospan" id="kobo.229.1">our benchmark.</span></span></p>
<h1 id="_idParaDest-284" class="calibre5"><a id="_idTextAnchor336" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.230.1">Multiprocessing using the Pool class</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.231.1">In Python, the </span><strong class="source-inline"><span class="kobospan" id="kobo.232.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.233.1"> module provides a convenient mechanism to parallelize operations across </span><a id="_idIndexMarker811" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.234.1">multiple processes. </span><span class="kobospan" id="kobo.234.2">With the </span><strong class="source-inline"><span class="kobospan" id="kobo.235.1">Pool</span></strong><span class="kobospan" id="kobo.236.1"> class, a pool of</span><a id="_idIndexMarker812" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.237.1"> worker processes is created, allowing tasks to be distributed </span><span><span class="kobospan" id="kobo.238.1">among them.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.239.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.240.1">Pool</span></strong><span class="kobospan" id="kobo.241.1"> class abstracts away the details of managing individual processes by providing the </span><strong class="source-inline"><span class="kobospan" id="kobo.242.1">map</span></strong><span class="kobospan" id="kobo.243.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.244.1">apply</span></strong><span class="kobospan" id="kobo.245.1"> methods. </span><span class="kobospan" id="kobo.245.2">Conversely, the DEAP framework makes it very easy to utilize this abstraction. </span><span class="kobospan" id="kobo.245.3">All operations specified in the </span><strong class="source-inline"><span class="kobospan" id="kobo.246.1">toolbox</span></strong><span class="kobospan" id="kobo.247.1"> module are internally executed via a default </span><strong class="source-inline"><span class="kobospan" id="kobo.248.1">map</span></strong><span class="kobospan" id="kobo.249.1"> function. </span><span class="kobospan" id="kobo.249.2">Replacing this map with the </span><strong class="source-inline"><span class="kobospan" id="kobo.250.1">map</span></strong><span class="kobospan" id="kobo.251.1"> from the </span><strong class="source-inline"><span class="kobospan" id="kobo.252.1">Pool</span></strong><span class="kobospan" id="kobo.253.1"> class means that these operations, including fitness evaluations, are now distributed among the worker processes in </span><span><span class="kobospan" id="kobo.254.1">the pool.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.255.1">Let’s illustrate this by incorporating multiprocessing into our previous program. </span><span class="kobospan" id="kobo.255.2">This modification is implemented in the </span><strong class="source-inline"><span class="kobospan" id="kobo.256.1">03_one_max_pool.py</span></strong><span class="kobospan" id="kobo.257.1"> Python program, available </span><span><span class="kobospan" id="kobo.258.1">at </span></span><a href="https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/03_one_max_pool.py" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.259.1">https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/03_one_max_pool.py</span></span></a><span><span class="kobospan" id="kobo.260.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.261.1">Only a few modifications are required, as </span><span><span class="kobospan" id="kobo.262.1">outlined here:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.263.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.264.1">multiprocessing</span></strong> <span><span class="kobospan" id="kobo.265.1">is imported:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.266.1">
import multiprocessing</span></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.267.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.268.1">map</span></strong><span class="kobospan" id="kobo.269.1"> method of a </span><strong class="source-inline1"><span class="kobospan" id="kobo.270.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.271.1"> class instance is registered as the </span><strong class="source-inline1"><span class="kobospan" id="kobo.272.1">map</span></strong><span class="kobospan" id="kobo.273.1"> function to be used by DEAP’s </span><span><span class="kobospan" id="kobo.274.1">toolbox module:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.275.1">
toolbox.register("</span><strong class="bold1"><span class="kobospan1" id="kobo.276.1">map</span></strong><span class="kobospan1" id="kobo.277.1">", </span><strong class="bold1"><span class="kobospan1" id="kobo.278.1">pool.map</span></strong><span class="kobospan1" id="kobo.279.1">)</span></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.280.1">The genetic algorithm flow, implemented in the </span><strong class="source-inline1"><span class="kobospan" id="kobo.281.1">main()</span></strong><span class="kobospan" id="kobo.282.1"> function, now runs under a </span><strong class="source-inline1"><span class="kobospan" id="kobo.283.1">with</span></strong><span class="kobospan" id="kobo.284.1"> statement that manages the creation and cleanup of the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.285.1">multiprocessing.Pool</span></strong></span><span><span class="kobospan" id="kobo.286.1"> instance:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.287.1">
def </span><strong class="bold1"><span class="kobospan1" id="kobo.288.1">main()</span></strong><span class="kobospan1" id="kobo.289.1">:
    </span><strong class="bold1"><span class="kobospan1" id="kobo.290.1">with multiprocessing.Pool() as pool:</span></strong><span class="kobospan1" id="kobo.291.1">
        toolbox.register("map", pool.map)
        # create initial population (generation 0):
        population = toolbox.populationCreator(
            n=POPULATION_SIZE)
        ...</span></pre></li> </ol>
<p class="calibre3"><span class="kobospan" id="kobo.292.1">Running the modified program</span><a id="_idIndexMarker813" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.293.1"> on a four-core computer yields the</span><a id="_idIndexMarker814" class="calibre6 pcalibre pcalibre1"/> <span><span class="kobospan" id="kobo.294.1">following output:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.295.1">
gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
</span><strong class="bold1"><span class="kobospan1" id="kobo.296.1">Elapsed time = 78.49 seconds</span></strong></pre> <p class="calibre3"><span class="kobospan" id="kobo.297.1">As anticipated, the output remains</span><a id="_idIndexMarker815" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.298.1"> identical to that of the original program, while the duration is significantly shorter compared to the </span><span><span class="kobospan" id="kobo.299.1">previous one.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.300.1">Important note</span></p>
<p class="callout"><span class="kobospan" id="kobo.301.1">The running time of this program may vary across different computers and even in successive runs on the same machine. </span><span class="kobospan" id="kobo.301.2">As discussed earlier, the optimal result for this benchmark is around 18 seconds. </span><span class="kobospan" id="kobo.301.3">If your computer already approaches this theoretical limit, you can make the benchmark program more CPU-intensive by doubling (or more, if needed) the population size. </span><span class="kobospan" id="kobo.301.4">Remember to adjust all versions of our benchmark program, both in this chapter and the next, to reflect the new </span><span><span class="kobospan" id="kobo.302.1">population size.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.303.1">Given the use of a four-core computer, you might expect the duration to be precisely one-quarter of the previous one. </span><span class="kobospan" id="kobo.303.2">However, in this case, we can see that the ratio between the durations is approximately 3.6 (≈285/79), falling short of the </span><span><span class="kobospan" id="kobo.304.1">expected 4.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.305.1">Several factors contribute to us not fully realizing the time-saving potential. </span><span class="kobospan" id="kobo.305.2">A significant factor is the presence of overhead associated with the parallelization process, introducing an additional computational burden when dividing tasks among multiple processes and coordinating </span><span><span class="kobospan" id="kobo.306.1">their </span></span><span><a id="_idIndexMarker816" class="calibre6 pcalibre pcalibre1"/></span><span><span class="kobospan" id="kobo.307.1">execution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.308.1">Moreover, the granularity</span><a id="_idIndexMarker817" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.309.1"> of the tasks plays a role. </span><span class="kobospan" id="kobo.309.2">While the fitness function consumes most of the processing time, smaller tasks such as the genetic operators of crossover and mutation may encounter a scenario where the overhead of parallelization outweighs </span><span><span class="kobospan" id="kobo.310.1">the benefits.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.311.1">Additionally, certain parts of the algorithm, such as handling the hall-of-fame and calculating statistics, are </span><a id="_idIndexMarker818" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.312.1">not parallelized. </span><span class="kobospan" id="kobo.312.2">This limitation restricts the extent to which parallelization can </span><span><span class="kobospan" id="kobo.313.1">be exploited.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.314.1">To illustrate the last point, let’s examine a snapshot of the Activity Monitor application on a Mac while the program </span><span><span class="kobospan" id="kobo.315.1">is running:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer142">
<span class="kobospan" id="kobo.316.1"><img alt="Figure 13.3: Activity Monitor showing the four genetic algorithm processes in action" src="image/B20851_13_3.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.317.1">Figure 13.3: Activity Monitor showing the four genetic algorithm processes in action</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.318.1">As expected, the four Python processes handling the multiprocessor program are heavily utilized, although not at 100%. </span><span class="kobospan" id="kobo.318.2">This prompts the question, can we “squeeze” more out of the CPUs at our disposal and further reduce the duration of the program’s run? </span><span class="kobospan" id="kobo.318.3">In the following section, we will explore </span><span><span class="kobospan" id="kobo.319.1">this possibility.</span></span></p>
<h2 id="_idParaDest-285" class="calibre7"><a id="_idTextAnchor337" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.320.1">Increasing the number of processes</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.321.1">Since the four CPUs at our disposal were</span><a id="_idIndexMarker819" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.322.1"> not utilized at 100%, a question arises: can we further increase utilization by employing more than four </span><span><span class="kobospan" id="kobo.323.1">concurrent processes?</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.324.1">When we created the instance of the </span><strong class="source-inline"><span class="kobospan" id="kobo.325.1">Pool</span></strong><span class="kobospan" id="kobo.326.1"> class by calling </span><strong class="source-inline"><span class="kobospan" id="kobo.327.1">multiprocessing.Pool()</span></strong><span class="kobospan" id="kobo.328.1"> without any arguments, the number of processes created defaulted to the number of CPUs available – four, in our case. </span><span class="kobospan" id="kobo.328.2">However, we can use the optional </span><strong class="source-inline"><span class="kobospan" id="kobo.329.1">processes</span></strong><span class="kobospan" id="kobo.330.1"> argument to set the desired number of processes, </span><span><span class="kobospan" id="kobo.331.1">as follows:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.332.1">
multiprocessing.Pool(processes=&lt;number of processes&gt;)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.333.1">For our next experiment, we will utilize this option to vary the number of processes and compare the resulting</span><a id="_idIndexMarker820" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.334.1"> durations. </span><span class="kobospan" id="kobo.334.2">This is implemented in the Python </span><strong class="source-inline"><span class="kobospan" id="kobo.335.1">04_one_max_pool_loop.py</span></strong><span class="kobospan" id="kobo.336.1"> program, available </span><span><span class="kobospan" id="kobo.337.1">at </span></span><a href="https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/04_one_max_pool_loop.py" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.338.1">https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/04_one_max_pool_loop.py</span></span></a><span><span class="kobospan" id="kobo.339.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.340.1">This program introduces a few modifications to the previous one, as </span><span><span class="kobospan" id="kobo.341.1">outlined here:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.342.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.343.1">main()</span></strong><span class="kobospan" id="kobo.344.1"> function is renamed </span><strong class="source-inline1"><span class="kobospan" id="kobo.345.1">run()</span></strong><span class="kobospan" id="kobo.346.1">, as we are going to run it several times. </span><span class="kobospan" id="kobo.346.2">It now accepts an </span><span><span class="kobospan" id="kobo.347.1">argument, </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.348.1">num_processes</span></strong></span><span><span class="kobospan" id="kobo.349.1">.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.350.1">The instantiation of the </span><strong class="source-inline1"><span class="kobospan" id="kobo.351.1">Pool</span></strong><span class="kobospan" id="kobo.352.1"> object echoes this argument to create a process pool of the </span><span><span class="kobospan" id="kobo.353.1">requested size:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.354.1">
with multiprocessing.Pool(processes=</span><strong class="bold1"><span class="kobospan1" id="kobo.355.1">num_processes</span></strong><span class="kobospan1" id="kobo.356.1">) as pool:</span></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.357.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.358.1">plot_graph()</span></strong><span class="kobospan" id="kobo.359.1"> function is added to help illustrate </span><span><span class="kobospan" id="kobo.360.1">the results.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.361.1">The code launching the program, found at the bottom of the file, now creates a loop, calling the </span><strong class="source-inline1"><span class="kobospan" id="kobo.362.1">run()</span></strong><span class="kobospan" id="kobo.363.1"> function multiple times, with the </span><strong class="source-inline1"><span class="kobospan" id="kobo.364.1">num_processes</span></strong><span class="kobospan" id="kobo.365.1"> argument incrementing from 1 to 20. </span><span class="kobospan" id="kobo.365.2">Additionally, it collects the resulting durations in a </span><span><span class="kobospan" id="kobo.366.1">list, </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.367.1">run_times</span></strong></span><span><span class="kobospan" id="kobo.368.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.369.1">
    run_times = []
    for </span><strong class="bold1"><span class="kobospan1" id="kobo.370.1">num_processes</span></strong><span class="kobospan1" id="kobo.371.1"> in </span><strong class="bold1"><span class="kobospan1" id="kobo.372.1">range(1, 21)</span></strong><span class="kobospan1" id="kobo.373.1">:
        start = time.time()
        </span><strong class="bold1"><span class="kobospan1" id="kobo.374.1">run(num_processes)</span></strong><span class="kobospan1" id="kobo.375.1">
        end = time.time()
        run_time = end – start
        </span><strong class="bold1"><span class="kobospan1" id="kobo.376.1">run_times.append(run_time)</span></strong></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.377.1">At the end of the loop, the values in the </span><strong class="source-inline1"><span class="kobospan" id="kobo.378.1">run_times</span></strong><span class="kobospan" id="kobo.379.1"> list to draw two plots, with the aid </span><a id="_idIndexMarker821" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.380.1">of the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.381.1">plot_graph()</span></strong></span><span><span class="kobospan" id="kobo.382.1"> function:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.383.1">
plot_graph(1, run_times, "Number of Processes", 
    "Run Time (seconds)", hr=33)
plot_graph(2, [1/rt for rt in run_times], "Number of Processes", 
    "(1 / Run Time)", "orange")</span></pre></li> </ol>
<p class="calibre3"><span class="kobospan" id="kobo.384.1">Before we continue to describe the results of this experiment, keep in mind that the actual figures may vary between different computers. </span><span class="kobospan" id="kobo.384.2">As a result, your specific results may differ somewhat. </span><span class="kobospan" id="kobo.384.3">Nevertheless, the main observations should </span><span><span class="kobospan" id="kobo.385.1">hold true.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.386.1">Running this program on our four-core computer yields the </span><span><span class="kobospan" id="kobo.387.1">following output:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.388.1">
num_processes = 1
gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Number of Processes = 1 =&gt; Run time = 286.62 seconds
num_processes = 2
gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Number of Processes = 2 =&gt; Run time = 151.75 seconds
...
</span><span class="kobospan1" id="kobo.388.2">num_processes = 20
gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Number of Processes = 20 =&gt; Run time = 33.30 seconds</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.389.1">In addition, two plots are</span><a id="_idIndexMarker822" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.390.1"> generated. </span><span class="kobospan" id="kobo.390.2">The first plot, displayed in the following figure, illustrates the runtimes of the program for different numbers of processes. </span><span class="kobospan" id="kobo.390.3">As anticipated, the runtime consistently decreased as the number of processes increased, surpassing the capacity of the four available CPUs. </span><span class="kobospan" id="kobo.390.4">Notably, the improvements became marginal beyond </span><span><span class="kobospan" id="kobo.391.1">eight processes:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer143">
<span class="kobospan" id="kobo.392.1"><img alt="Figure 13.4: The durations of the program run over the different numbers of processes" src="image/B20851_13_4.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.393.1">Figure 13.4: The durations of the program run over the different numbers of processes</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.394.1">The dashed red line in this plot represents the shortest duration achieved in our test – about 31 seconds. </span><span class="kobospan" id="kobo.394.2">For </span><a id="_idIndexMarker823" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.395.1">the sake of comparison, let's recall the theoretical limit in this test: with 6 rounds of fitness calculations at 3 seconds each, the best possible result is </span><span><span class="kobospan" id="kobo.396.1">18 seconds.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.397.1">The second plot, shown in the following figure, depicts the reciprocal of the duration (or 1/duration), representing the “speed” of the program, across different numbers </span><span><span class="kobospan" id="kobo.398.1">of processes:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer144">
<span class="kobospan" id="kobo.399.1"><img alt="Figure 13.5: The durations of the program run over the different numbers of processes" src="image/B20851_13_5.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.400.1">Figure 13.5: The durations of the program run over the different numbers of processes</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.401.1">This plot reveals that the program’s speed increases almost linearly with the addition of up to eight processes, but the rate of increase slows beyond this point. </span><span class="kobospan" id="kobo.401.2">Notably, the graph shows a significant </span><a id="_idIndexMarker824" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.402.1">performance improvement when moving from 15 to 16 processes, a trend also observable in the </span><span><span class="kobospan" id="kobo.403.1">previous plot.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.404.1">The performance gains observed when the number of processes exceeds the number of available physical CPU cores, a phenomenon known as “oversubscription,” can be linked to various factors. </span><span class="kobospan" id="kobo.404.2">These include task </span><a id="_idIndexMarker825" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.405.1">overlapping, I/O and wait times, multithreading, hyper-threading, and optimizations by the operating system. </span><span class="kobospan" id="kobo.405.2">The marked performance boost from 15 to 16 processes might be influenced by the computer’s hardware architecture and the operating system’s process scheduling strategies. </span><span class="kobospan" id="kobo.405.3">Additionally, the specific structure of the program’s workload, as indicated by the fact that 3 out of 6 rounds of fitness calculations involved exactly 16 fitness evaluations (as shown in the </span><strong class="source-inline"><span class="kobospan" id="kobo.406.1">nevals</span></strong><span class="kobospan" id="kobo.407.1"> column), could also contribute to this increase. </span><span class="kobospan" id="kobo.407.2">It’s important to note that these effects can differ, based on the computer’s architecture and the nature of the problems </span><span><span class="kobospan" id="kobo.408.1">being solved.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.409.1">The takeaway from this experiment is the importance of experimenting with various process counts to find the optimal configuration for your program. </span><span class="kobospan" id="kobo.409.2">Fortunately, you don’t need to rerun your </span><a id="_idIndexMarker826" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.410.1">entire genetic algorithm each time – a few generations should be enough to compare and figure out the </span><span><span class="kobospan" id="kobo.411.1">best setup.</span></span></p>
<h1 id="_idParaDest-286" class="calibre5"><a id="_idTextAnchor338" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.412.1">Multiprocessing using the SCOOP library</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.413.1">Another approach to introduce </span><a id="_idIndexMarker827" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.414.1">multiprocessing is by utilizing </span><strong class="bold"><span class="kobospan" id="kobo.415.1">SCOOP</span></strong><span class="kobospan" id="kobo.416.1">, a Python library designed to parallelize and distribute code execution across multiple processes. </span><strong class="bold"><span class="kobospan" id="kobo.417.1">SCOOP</span></strong><span class="kobospan" id="kobo.418.1">, which stands for </span><strong class="bold"><span class="kobospan" id="kobo.419.1">Simple COncurrent Operations in Python</span></strong><span class="kobospan" id="kobo.420.1">, provides a</span><a id="_idIndexMarker828" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.421.1"> straightforward interface for parallel computing in Python, which we’ll </span><span><span class="kobospan" id="kobo.422.1">explore </span></span><span><a id="_idIndexMarker829" class="calibre6 pcalibre pcalibre1"/></span><span><span class="kobospan" id="kobo.423.1">shortly.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.424.1">Applying SCOOP to a DEAP-based program is quite similar to using the </span><strong class="source-inline"><span class="kobospan" id="kobo.425.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.426.1"> module, as demonstrated by the Python </span><strong class="source-inline"><span class="kobospan" id="kobo.427.1">05_one_max_scoop.py</span></strong><span class="kobospan" id="kobo.428.1"> program, available </span><span><span class="kobospan" id="kobo.429.1">at </span></span><a href="https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/05_one_max_scoop.py" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.430.1">https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_13/05_one_max_scoop.py</span></span></a><span><span class="kobospan" id="kobo.431.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.432.1">This program requires only a couple of modifications to the original non-multiprocessing version of the </span><strong class="source-inline"><span class="kobospan" id="kobo.433.1">02_one_max_busy.py</span></strong><span class="kobospan" id="kobo.434.1"> program; these are </span><span><span class="kobospan" id="kobo.435.1">outlined here:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.436.1">Import SCOOP’s </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.437.1">futures</span></strong></span><span><span class="kobospan" id="kobo.438.1"> module:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.439.1">
from scoop import </span><strong class="bold1"><span class="kobospan1" id="kobo.440.1">futures</span></strong></pre></li> <li class="calibre11"><span class="kobospan" id="kobo.441.1">Register the </span><strong class="source-inline1"><span class="kobospan" id="kobo.442.1">map</span></strong><span class="kobospan" id="kobo.443.1"> method of SCOOP’s </span><strong class="source-inline1"><span class="kobospan" id="kobo.444.1">futures</span></strong><span class="kobospan" id="kobo.445.1"> module as the “map” function to be used by DEAP’s </span><span><span class="kobospan" id="kobo.446.1">toolbox module:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.447.1">
toolbox.register("</span><strong class="bold1"><span class="kobospan1" id="kobo.448.1">map</span></strong><span class="kobospan1" id="kobo.449.1">", </span><strong class="bold1"><span class="kobospan1" id="kobo.450.1">futures.map</span></strong><span class="kobospan1" id="kobo.451.1">)</span></pre></li> </ol>
<p class="calibre3"><span class="kobospan" id="kobo.452.1">And that’s it! </span><span class="kobospan" id="kobo.452.2">However, launching this program requires using SCOOP as the main module, via the </span><span><span class="kobospan" id="kobo.453.1">following command:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.454.1">
python3 </span><strong class="bold1"><span class="kobospan1" id="kobo.455.1">-m scoop</span></strong><span class="kobospan1" id="kobo.456.1"> 05_one_max_scoop.py</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.457.1">Running this program on the same four-core computer yields the </span><span><span class="kobospan" id="kobo.458.1">following output:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.459.1">
SCOOP 0.7 2.0 on darwin using Python 3.11.1
Deploying 4 worker(s) over 1 host(s).
</span><span class="kobospan1" id="kobo.459.2">Worker distribution:
127.0.0.1: 3 + origin
Launching 4 worker(s) using /bin/zsh.
</span><span class="kobospan1" id="kobo.459.3">gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
</span><strong class="bold1"><span class="kobospan1" id="kobo.460.1">Elapsed time = 78.24 seconds</span></strong></pre> <p class="calibre3"><span class="kobospan" id="kobo.461.1">The output starts by </span><a id="_idIndexMarker830" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.462.1">providing details about the distribution of the</span><a id="_idIndexMarker831" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.463.1"> program across four workers; this is followed by the familiar genetic algorithm progress information seen in all the programs so far. </span><span class="kobospan" id="kobo.463.2">Unsurprisingly, the program duration reported in the last line closely resembles the one reported by the </span><strong class="source-inline"><span class="kobospan" id="kobo.464.1">03_one_max_pool.py</span></strong><span class="kobospan" id="kobo.465.1"> program, as both programs employed four </span><span><span class="kobospan" id="kobo.466.1">concurrent processes.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.467.1">However, we have seen that “oversubscription” (i.e., using more concurrent processes than the number of available cores) could yield better results. </span><span class="kobospan" id="kobo.467.2">Luckily, SCOOP enables us to control the number of processes, or “workers,” via a command-line argument. </span><span class="kobospan" id="kobo.467.3">Let’s run the program again but, this time, use </span><span><span class="kobospan" id="kobo.468.1">16 workers:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.469.1">
python3 -m scoop </span><strong class="bold1"><span class="kobospan1" id="kobo.470.1">-n 16</span></strong><span class="kobospan1" id="kobo.471.1"> 05_one_max_scoop.py</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.472.1">The resulting output is </span><span><span class="kobospan" id="kobo.473.1">as follows:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.474.1">
SCOOP 0.7 2.0 on darwin using Python 3.11.1
Deploying 16 worker(s) over 1 host(s).
</span><span class="kobospan1" id="kobo.474.2">Worker distribution:
127.0.0.1: 15 + origin
Launching 16 worker(s) using /bin/zsh.
</span><span class="kobospan1" id="kobo.474.3">gen     nevals  max     avg
0       20      7       4.35
1       14      7       6.1
2       16      9       6.85
3       16      9       7.6
4       16      9       8.45
5       13      10      8.9
Best Individual =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
</span><strong class="bold1"><span class="kobospan1" id="kobo.475.1">Elapsed time = 22.41 seconds</span></strong></pre> <p class="calibre3"><span class="kobospan" id="kobo.476.1">The output may sometimes include SCOOP warnings such as </span><strong class="source-inline"><span class="kobospan" id="kobo.477.1">Lost track of future</span></strong><span class="kobospan" id="kobo.478.1"> or </span><strong class="source-inline"><span class="kobospan" id="kobo.479.1">Received an unexpected future</span></strong><span class="kobospan" id="kobo.480.1">. </span><span class="kobospan" id="kobo.480.2">These </span><a id="_idIndexMarker832" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.481.1">warnings indicate communication issues, related</span><a id="_idIndexMarker833" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.482.1"> to resource constraints caused by oversubscription. </span><span class="kobospan" id="kobo.482.2">Despite these warnings, SCOOP is generally capable of recovering and successfully reproducing the </span><span><span class="kobospan" id="kobo.483.1">expected results.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.484.1">A few more experiments reveal that we could achieve times as low as 20 seconds when using SCOOP with process counts of 20 and above. </span><span class="kobospan" id="kobo.484.2">This marks a significant improvement over the 31 seconds we managed with the </span><strong class="source-inline"><span class="kobospan" id="kobo.485.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.486.1"> module for the </span><span><span class="kobospan" id="kobo.487.1">same problem.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.488.1">This enhancement might stem from SCOOP’s distinct approach to parallelization. </span><span class="kobospan" id="kobo.488.2">For instance, its dynamic task allocation could be more effective than the static method used by </span><strong class="source-inline"><span class="kobospan" id="kobo.489.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.490.1">. </span><span class="kobospan" id="kobo.490.2">Additionally, SCOOP might handle the overhead of process management more efficiently and could be better at scheduling tasks on the available cores. </span><span class="kobospan" id="kobo.490.3">However, this doesn’t mean SCOOP will always have the upper hand over </span><strong class="source-inline"><span class="kobospan" id="kobo.491.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.492.1">. </span><span class="kobospan" id="kobo.492.2">It’s wise to try out both methods and see how they perform with your specific algorithm and problem. </span><span class="kobospan" id="kobo.492.3">The good news is that switching between the two is </span><span><span class="kobospan" id="kobo.493.1">relatively simple.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.494.1">Having said that, it’s important to </span><a id="_idIndexMarker834" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.495.1">mention that SCOOP offers a key feature that sets</span><a id="_idIndexMarker835" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.496.1"> it apart from </span><strong class="source-inline"><span class="kobospan" id="kobo.497.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.498.1"> – </span><strong class="bold"><span class="kobospan" id="kobo.499.1">distributed computing</span></strong><span class="kobospan" id="kobo.500.1">. </span><span class="kobospan" id="kobo.500.2">This feature allows for parallel processing </span><a id="_idIndexMarker836" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.501.1">across multiple machines. </span><span class="kobospan" id="kobo.501.2">We will briefly explore this capability in the </span><span><span class="kobospan" id="kobo.502.1">following section.</span></span></p>
<h2 id="_idParaDest-287" class="calibre7"><a id="_idTextAnchor339" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.503.1">Distributed computing with SCOOP</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.504.1">SCOOP not only supports multiprocessing on a single machine but also enables distributed computing across</span><a id="_idIndexMarker837" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.505.1"> multiple interconnected nodes. </span><span class="kobospan" id="kobo.505.2">This functionality can be configured in one of </span><span><span class="kobospan" id="kobo.506.1">two ways:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.507.1">Using the </span></strong><strong class="source-inline1"><span class="kobospan" id="kobo.508.1">--hostfile</span></strong><strong class="bold"><span class="kobospan" id="kobo.509.1"> parameter</span></strong><span class="kobospan" id="kobo.510.1">: This parameter should be followed by the name of a file containing a list of hosts. </span><span class="kobospan" id="kobo.510.2">The format for each line in this file is </span><strong class="source-inline1"><span class="kobospan" id="kobo.511.1">&lt;hostname or IP address&gt; &lt;num_of_processes&gt;</span></strong><span class="kobospan" id="kobo.512.1">, where each line specifies a host and the corresponding number of processes to run on </span><span><span class="kobospan" id="kobo.513.1">that host.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.514.1">Using the </span></strong><strong class="source-inline1"><span class="kobospan" id="kobo.515.1">--hosts</span></strong><strong class="bold"><span class="kobospan" id="kobo.516.1"> parameter</span></strong><span class="kobospan" id="kobo.517.1">: This option requires a list of hostnames. </span><span class="kobospan" id="kobo.517.2">Each hostname should be listed as many times as the number of processes you intend to run on </span><span><span class="kobospan" id="kobo.518.1">that host.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.519.1">For more detailed information and practical examples, you are encouraged to consult SCOOP’s </span><span><span class="kobospan" id="kobo.520.1">official documentation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.521.1">A different approach to extending beyond the limitations of a single machine will be explored in the </span><span><span class="kobospan" id="kobo.522.1">next chapter.</span></span></p>
<h1 id="_idParaDest-288" class="calibre5"><a id="_idTextAnchor340" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.523.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.524.1">In this chapter, you were introduced to the concept of applying concurrency to genetic algorithms via multiprocessing, a natural strategy to alleviate their computationally intensive nature. </span><span class="kobospan" id="kobo.524.2">Two main approaches were demonstrated – using Python’s built-in </span><strong class="source-inline"><span class="kobospan" id="kobo.525.1">multiprocessing.Pool</span></strong><span class="kobospan" id="kobo.526.1"> class and the SCOOP library. </span><span class="kobospan" id="kobo.526.2">We employed a CPU-intensive version of the familiar One-Max problem as a benchmark, through which several insights were gained. </span><span class="kobospan" id="kobo.526.3">The final part of the chapter addressed the potential of using the SCOOP library for </span><span><span class="kobospan" id="kobo.527.1">distributed computing.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.528.1">In the next chapter, we will take the idea of concurrency to the next level by employing a client-server model. </span><span class="kobospan" id="kobo.528.2">This approach will utilize both multiprocessing and multithreading, ultimately leveraging the power of cloud computing to further </span><span><span class="kobospan" id="kobo.529.1">enhance performance.</span></span></p>
<h1 id="_idParaDest-289" class="calibre5"><a id="_idTextAnchor341" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.530.1">Further reading</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.531.1">For more information on the topics that were covered in this chapter, refer to the </span><span><span class="kobospan" id="kobo.532.1">following resources:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.533.1">Advanced Python Programming: Build high performance, concurrent, and multi-threaded apps with Python using proven design patterns</span></em><span class="kobospan" id="kobo.534.1"> by Dr. </span><span class="kobospan" id="kobo.534.2">Gabriele Lanaro, Quan Nguyen, and Sakis Kasampalis, </span><span><span class="kobospan" id="kobo.535.1">February 2019</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.536.1">SCOOP framework </span><span><span class="kobospan" id="kobo.537.1">documentation: </span></span><a href="https://scoop.readthedocs.io/en/latest/" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.538.1">https://scoop.readthedocs.io/en/latest/</span></span></a></li>
<li class="calibre11"><span class="kobospan" id="kobo.539.1">Python multiprocessing module </span><span><span class="kobospan" id="kobo.540.1">documentation: </span></span><a href="https://docs.python.org/3/library/multiprocessing.html" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.541.1">https://docs.python.org/3/library/multiprocessing.html</span></span></a></li>
</ul>
</div>
</body></html>