["```py\npip install Pillow\n```", "```py\npip install opencv-python\n```", "```py\nimage = Image.new('RGB', (width, height))\ndraw = 'RGB' and 'RGBA' are the values for the mode argument. The 'RGB' value indicates three 8-bit values per pixel – one for each of the colors of red (R), green (G), and blue (B). The 'RGBA' value adds a fourth 8-bit value (A) representing the *alpha* (opacity) level of the drawings to be added. The combination of an RGB base image and an RGBA drawing will allow us to draw polygons of varying degrees of transparency on top of a black background.\nNow, we can add a polygon to the base image by using the `ImageDraw` class’s `polygon` function, as shown in the following example. The following statement will draw a triangle on the image:\n\n```", "```py\n\n The following list explains the `polygon` function arguments in more detail:\n\n*   The **(x1, y1)**, **(x2, y2)**, and **(x3, y3)** tuples represent the triangle’s three vertices. Each tuple contains the *x, y* coordinates of the corresponding vertex within the image.\n*   **red**, **green**, and **blue** are integer values in the range of [0, 255], each representing the intensity of the corresponding color of the polygon.\n*   **Alp~ha** is an integer value in the range of [0, 255], representing the opacity value of the polygon (a lower value means more transparency).\n\nNote\nTo draw a polygon with more vertices, we would need to add more (x i, y i) tuples to the list.\nUsing the `polygon` function repetitively, we can add more and more polygons, all drawn onto the same image and possibly overlapping each other, as shown in the following figure:\n![Figure 15.1: A plot of overlapping polygons with varying colors and opacity values](img/B20851_15_1.jpg)\n\nFigure 15.1: A plot of overlapping polygons with varying colors and opacity values\nOnce we draw an image using polygons, we need to compare it to the reference image, as described in the next subsection.\nMeasuring the difference between images\nSince we would like to construct an image that is as similar as possible to the original one, we need a way to evaluate the similarity or the difference between the two given images. The most common method to evaluate the similarity between images is the pixel-based **mean squared error** (**MSE**), which involves conducting a pixel-by-pixel comparison. This requires, of course, that both images are of the same dimensions. The MSE metric can be calculated as follows:\n\n1.  Calculate the square of the difference between each pair of matching pixels from both images. Since each pixel in the drawing is represented using three separate values – red, green, and blue – the difference for each pixel is calculated across these three dimensions.\n2.  Compute the sum of all these squares.\n3.  Divide the sum by the total number of pixels.\n\nWhen both images are represented using the OpenCV (cv2) library, which essentially represents an image as a numeric array, this calculation can be performed in a straightforward manner as follows:\n\n```", "```py\n\n When the two images are identical, the MSE value will be zero. Consequently, minimizing this metric can be used as the objective of our algorithm, which will be further discussed in the next section.\nUsing genetic algorithms to reconstruct images\nAs we discussed previously, our goal in this experiment is to use a familiar image as a reference and create a second image, as similar as possible to the reference, using a collection of overlapping polygons of varying colors and transparencies. Using the genetic algorithms approach, each candidate solution is a set of such polygons, and evaluating the solution is carried out by creating an image using these polygons and comparing it to the reference image.\nAs usual, the first decision we need to make is how these solutions are represented. We will discuss this in the next subsection.\nSolution representation and evaluation\nAs we mentioned previously, our solution consists of a set of polygons within the image boundaries. Each polygon has its own color and transparency. Drawing such a polygon using the Pillow library requires the following arguments:\n\n*   A list of tuple, [(x 1, y 1), (x 2, y 2), … , (x n, y n)], representing the vertices of the polygon. Each tuple contains the *x, y* coordinates of the corresponding vertex within the image. Therefore, the values of the *x* coordinates are in the range [0, image width – 1], while the values of the *y* coordinates are in the range [0, image height – 1].\n*   Three integer values in the range of [0, 255], representing the *red*, *green*, and *blue* components of the polygon’s color.\n*   An additional integer value in the range of [0, 255], representing the *alpha* – or opacity – value of the polygon.\n\nThis means that for each polygon in our collection, we will need [2 × (polygo n − size) + 4] parameters. A *triangle*, for example, will require 10 parameters (2x3+4), while a *hexagon* will require 16 parameters (2x6+4). Consequently, a collection of triangles will be represented using a list in the following format, where every 10 parameters represent a single triangle:\n[x 11, y 11, x 12, y 12, x 13, y 13, r 1, g 1, b 1, alph a 1, x 21, y 21, x 22, y 22, x 23, y 23, r 2, g 2, b 2, alph a 2, …]\nTo simplify this representation, we will use float numbers in the range of [0, 1] for each of the parameters. Before drawing the polygons, we will expand each parameter accordingly so that it fits within its required range – image width and height for the coordinates of the vertices and [0, 255] for the colors and opacity values.\nUsing this representation, a collection of 50 triangles will be represented as a list of 500 float values between 0 and 1, like so:\n\n```", "```py\n\n Evaluating a given solution means dividing this long list into “chunks” representing individual polygons – in the case of triangles, each chunk will have a length of 10\\. Then, we need to create a new, blank image and draw the various polygons from the list on top of it, one by one.\nFinally, the difference between the resulting image and the original (reference) image needs to be calculated. As discussed in the previous section, this will be done using the pixel-based MSE.\nThis (somewhat elaborate) score evaluation procedure is implemented by a Python class, which will be described in the next subsection.\nPython problem representation\nTo encapsulate the image reconstruction challenge, we’ve created a Python class called `ImageTest`. This class is contained in the `image_test.py` file, which is located at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_15/image_test.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_15/image_test.py).\nThe class is initialized with two parameters: the path of the file containing the reference image and the number of vertices of the polygons that are being used to construct the image. The class provides the following public methods:\n\n*   **polygonDataToImage()**: Accepts the list containing the polygon data we discussed in the previous subsection, divides this list into chunks representing individual polygons, and creates an image containing these polygons by drawing the polygons one by one onto a blank image.\n*   **getDifference()**: Accepts polygon data, creates an image containing these polygons, and calculates the difference between this image and the reference image using the *MSE* method.\n*   **blur()**: Accepts an image in PIL format, converts it to OpenCV (cv2) format, and then applies Gaussian blurring. The intensity of the blur is determined by the **BLUR_KERNEL_SIZE** constant.\n*   **plotImages()**: For visual comparison purposes, creates a side-by-side plot of three images:\n    *   The reference image (to the left)\n    *   The given, polygon-reconstructed image (to the right)\n    *   A blurred version of the reconstructed image (in the middle)\n*   **saveImage()**: Accepts polygon data, creates an image containing these polygons, creates a side-by-side plot of this image next to the reference image, and saves the plot in a file.\n\nDuring the run of the genetic algorithm, the `saveImage()` method will be called every 100 generations in order to save a side-by-side image comparison representing a snapshot of the reconstruction process. Calling this method will be carried out by a callback function, as described in the next subsection.\nGenetic algorithm implementation\nTo reconstruct a given image with a set of semi-transparent overlapping polygons using a genetic algorithm, we’ve created a Python program called `01_reconstruct_with_polygons.py`, which is located at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_15/01_reconstruct_with_polygons.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_15/01_reconstruct_with_polygons.py).\nSince we are using a list of floats to represent a solution – the polygons’ vertices, colors, and transparency values – this program is very similar to the function optimization programs we saw in [*Chapter 6*](B20851_06.xhtml#_idTextAnchor197)*, Optimizing Continuous Functions*, such as the one we used for the *Eggholder* *function*’s optimization.\nThe following steps describe the main parts of this program:\n\n1.  We start by setting the problem-related constant values. **POLYGON_SIZE** determines the number of vertices for each polygon, while **NUM_OF_POLYGONS** determines the total number of polygons that will be used to create the reconstructed image:\n\n    ```", "```py\n\n     2.  After setting the genetic algorithm constants, we continue by creating an instance of the **ImageTest** class, which will allow us to create images from polygons and compare these images to the reference image, as well as save snapshots of our progress:\n\n    ```", "```py\n\n     3.  Next, we set the upper and lower boundaries for the float values we will be searching for. As we mentioned previously, we will use float values for all our parameters and set them all to the same range, between 0.0 and 1.0, for convenience. When evaluating a solution, the values will be expanded to their actual range, and converted into integers when needed:\n\n    ```", "```py\n\n     4.  Since our goal is to minimize the difference between the images – the reference image and the one we are creating using polygons – we define a single objective, *minimizing* fitness strategy:\n\n    ```", "```py\n\n     5.  Now, we need to create a helper function that will create random real numbers that are uniformly distributed within a given range. This function assumes that the range is the same for every dimension, as is the case in our solution:\n\n    ```", "```py\n\n     6.  Next, we use the preceding function to create an operator that randomly returns a list of floats, all in the desired range of [0, 1]:\n\n    ```", "```py\n\n     7.  This is followed by defining an operator that fills up an individual instance using the preceding operator:\n\n    ```", "```py\n\n     8.  Then, we instruct the genetic algorithm to use the **getDiff()** method for fitness evaluation. This, in turn, calls the **getDifference()** method of the **ImageTest** instance. As a reminder, this method, which we described in the previous subsection, accepts an individual representing a list of polygons, creates an image containing these polygons, and calculates the difference between this image and the reference image using the *MSE* method:\n\n    ```", "```py\n\n     9.  It’s time to choose our genetic operators. For the selection operator, we will use *tournament selection* with a tournament size of 2\\. As we saw in [*Chapter 4*](B20851_04.xhtml#_idTextAnchor155)*, Combinatorial Optimization*, this selection scheme works well in conjunction with the *elitist approach* that we plan to utilize here as well:\n\n    ```", "```py\n\n     10.  As for the *crossover* operator (aliased with **mate**) and the *mutation* operator (**mutate**), since our solution representation is a list of floats bounded to a range, we will use the specialized continuous bounded operators provided by the DEAP framework – **cxSimulatedBinaryBounded** and **mutPolynomialBounded**, respectively – which we first saw in [*Chapter 6*](B20851_06.xhtml#_idTextAnchor197)*, Optimizing* *Continuous Functions*:\n\n    ```", "```py\n\n     11.  As we have done multiple times before, we will use the *elitist approach*, where the **hall of fame** (**HOF**) members – the current best individuals – are always passed untouched to the next generation. However, this time, we’re going to add a new feature to this implementation – a *callback function* that will be used to save the image every 100 generations (we will discuss this callback in more detail in the next subsection):\n\n    ```", "```py\n\n     12.  At the end of the run, we print the best solution and use the **plotImages()** function to show a side-by-side visual comparison to the reference image:\n\n    ```", "```py\n\n     13.  In addition, we have employed the multiprocessing method of using a process pool, as demonstrated and tested in [*Chapter 13*](B20851_13.xhtml#_idTextAnchor326)*, Accelerating Genetic Algorithms: The Power of Concurrency*. This approach is a straightforward way to accelerate the execution of our algorithm. It simply involves adding the following lines to encapsulate the call to **eaSimpleWithElitismAndCallback()**:\n\n    ```", "```py\n\nBefore we look at the results, let’s discuss the implementation of the callback function.\nAdding a callback to the genetic run\nTo be able to save the best current image every 100 generations, we need to introduce a modification to the main genetic loop. As you may recall, toward the end of [*Chapter 4*](B20851_04.xhtml#_idTextAnchor155)*, Combinatorial Optimization*, we already made one modification to `deap`’s simple genetic algorithm main loop that allowed us to introduce the *elitist approach*. To be able to introduce that change, we created the `eaSimpleWithElitism()` method, which is contained in a file called `elitism.py`. This method was a modified version of the DEAP framework’s `eaSimple()` method, which is contained in the `algorithms.py` file. We modified the original method by adding the elitism functionality, which takes the members of the HOF – the current best individuals – and passes them untouched to the next generation at every iteration of the loop. Now, for the purpose of implementing a callback, we will introduce another small modification and change the name of the method to `eaSimpleWithElitismAndCallback()`. We will also rename the file containing it to `elitism_and_callback.py`.\nThere are two parts to this modification, as follows:\n\n1.  The first part of the modification consists of adding an argument called **callback** to the main-loop method:\n\n    ```", "```py\n\n    This new argument represents an external function that will be called after each iteration.\n\n     2.  The other part is within the method. Here, the callback function is called after the new generation has been created and evaluated. The current generation number and the current best individual are passed to the callback as arguments:\n\n    ```", "```py\n\nBeing able to define a callback function that will be called after each generation may prove useful in various situations. To take advantage of it here, we’ll define the `saveImage()` function back in our `01_reconstruct_with_polygons.py` program. We will use it to save a side-by-side image of the current best image and the reference image, every 100 generations, as follows:\n\n1.  We use the *modulus* (**%**) operator to activate the method only once every 100 generations:\n\n    ```", "```py\n\n     2.  If this is one of these generations, we create a folder for the images if one does not exist. The folder’s name references the polygon size and the number of polygons – for example, **run-3-100** or **run-6-50**, under the **images/results/** path:\n\n    ```", "```py\n\n     3.  Next, we save the image of the best current individual in that folder. The name of the image contains the number of generations that have been passed – for example, **after-300-generations.png**:\n\n    ```", "```py\n\nWe are finally ready to run this algorithm with reference images and check out the results.\nImage reconstruction results\nTo test our program, we will use a section of the famous Mona Lisa portrait by *Leonardo da Vinci*, considered the most well-known painting in the world, as seen here:\n![Figure 15.2: Head crop of the Mona Lisa painting](img/B20851_15_2.jpg)\n\nFigure 15.2: Head crop of the Mona Lisa painting\nSource: [https://commons.wikimedia.org/wiki/File:Mona_Lisa_headcrop.jpg](https://commons.wikimedia.org/wiki/File:Mona_Lisa_headcrop.jpg)\nArtist: Leonardo da Vinci. Licensed under Creative Commons CC0 1.0: [https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/)\nBefore proceeding with the program, it’s important to note that the extensive polygon data and complex image processing operations involved make the running time for our genetic image reconstruction experiments significantly longer than other programs tested earlier in this book. These experiments could take several hours each to complete.\nWe will begin our image reconstruction using 100 triangles as the polygons:\n\n```", "```py\n\n The algorithm will run for 5,000 generations with a population size of 200\\. As discussed earlier, a side-by-side image comparison is saved every 100 generations. At the end of the run, we can review these saved images to observe the evolution of the reconstructed image.\nThe following figure showcases various milestones from the resulting side-by-side saved images. As mentioned before, the middle image in each row presents a blurred version of the reconstructed image. This blurring aims to soften the sharp corners and straight lines that are typical of polygon-based reconstructions, creating an effect akin to squinting when viewing the image:\n![Figure 15.3: Milestone results of Mona Lisa reconstruction using 100 triangles](img/B20851_15_3.jpg)\n\nFigure 15.3: Milestone results of Mona Lisa reconstruction using 100 triangles\nThe end result bears a close resemblance to the original image and can be readily recognized as the Mona Lisa.\nReducing the triangle count\nIt is reasonable to assume that the results would be even better when increasing the number of triangles. But what if we wanted to *minimize* this number? If we reduce the number of triangles to 20, we might still be able to tell that this is the Mona Lisa, as the following results show:\n![Figure 15.4: Results of Mona Lisa reconstruction using 20 triangles and MSE](img/B20851_15_4.jpg)\n\nFigure 15.4: Results of Mona Lisa reconstruction using 20 triangles and MSE\nHowever, when the triangle count is further reduced to 15, the results are no longer recognizable, as seen here:\n![Figure 15.5: Results of Mona Lisa reconstruction using 15 triangles and MSE](img/B20851_15_5.jpg)\n\nFigure 15.5: Results of Mona Lisa reconstruction using 15 triangles and MSE\nA possible way to improve these results is described in the next subsection.\nBlurring the fitness\nSince the reconstruction becomes significantly cruder when the triangle count is low, perhaps we can improve this result by basing the fitness on the similarity between the original image and the *blurred version* of the reconstructed image, which is less crude. To try this out, we’ve created a slightly modified version of the original Python program, called `02_reconstruct_with_polygons_blur.py`, which is located at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_15/02_reconstruct_with_polygons_blur.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_15/02_reconstruct_with_polygons_blur.py).\nThe modifications are highlighted as follows:\n\n1.  The image comparison results of this program are saved into a separate directory called **blur**.\n2.  The fitness function calculation now includes an optional argument, **blur=True**, when calling the **getDifference()** function. Consequently, this function will call **getMseBlur()** instead of the original **getMse()**. The **getMseBlur()** function blurs the given image before calculating the MSE:\n\n    ```", "```py\n\nThe results of running this program for 20 triangles are shown in the following figure:\n![Figure 15.6: Results of Mona Lisa reconstruction using 20 triangles and MSE with blur](img/B20851_15_6.jpg)\n\nFigure 15.6: Results of Mona Lisa reconstruction using 20 triangles and MSE with blur\nMeanwhile, the results for 15 triangles are shown here:\n![Figure 15.7: Results of Mona Lisa reconstruction using 15 triangles and MSE with blur](img/B20851_15_7.jpg)\n\nFigure 15.7: Results of Mona Lisa reconstruction using 15 triangles and MSE with blur\nThe resulting images appear more recognizable, which makes this method a potentially viable way to achieve a lower polygon count.\nOther experiments\nThere are many variations that you can explore. One straightforward variation is increasing the number of vertices in the polygons. We anticipate more accurate results from this approach, as the shapes become more versatile. However, it’s important to note that the size of the individual polygons grows, which typically necessitates a larger population and/or more generations to achieve reasonable results.\nAnother interesting variation is to apply the “blur” fitness, previously used to minimize the number of polygons, to a large polygon count. This approach might lead to a somewhat “erratic” reconstruction, which is then smoothed by the blur function. The following result illustrates this, using 100 hexagons with 400 individuals and 5,000 generations, employing the “blur” MSE-based fitness:\n![Figure 15.8: Results of Mona Lisa reconstruction using 100 hexagons and MSE with blur](img/B20851_15_8.jpg)\n\nFigure 15.8: Results of Mona Lisa reconstruction using 100 hexagons and MSE with blur\nThere are many other possibilities and combinations to experiment with, such as the following:\n\n*   Increasing the number of polygons\n*   Changing the population size and the number of generations\n*   Using non-polygonal shapes (such as circles or ellipses) or regular shapes (such as squares or equilateral triangles)\n*   Using different types of reference images (including paintings, drawings, photos, and logos)\n*   Opting for grayscale images instead of colored ones\n\nHave fun creating and experimenting with your own variations!\nSummary\nIn this chapter, you were introduced to the popular concept of reconstructing existing images with overlapping, semi-transparent polygons. You explored various image processing libraries in Python, learning how to programmatically create images from scratch using polygons and calculate the difference between two images. Subsequently, we developed a genetic algorithm-based program to reconstruct a segment of a famous painting using polygons and explored several variations in the process. We also discussed numerous possibilities for further experimentation.\nIn the next chapter, we will describe and demonstrate several problem-solving techniques related to genetic algorithms, as well as other biologically inspired computational algorithms.\nFurther reading\nFor more information about the topics that were covered in this chapter, please refer to the following resources:\n\n*   *Hands-On Image Processing with Python*, Sandipan Dey, November 30, 2018\n*   *Grow Your Own* *Picture*: [https://chriscummins.cc/s/genetics](https://chriscummins.cc/s/genetics)\n*   *Genetic Programming: Evolution of Mona* *Lisa*: [https://rogerjohansson.blog/2008/12/07/genetic-programming-evolution-of-mona-lisa/](https://rogerjohansson.blog/2008/12/07/genetic-programming-evolution-of-mona-lisa/)\n\n```"]