- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Other Evolutionary and Bio-Inspired Computation Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will broaden your horizons and discover several new problem-solving
    and optimization techniques related to genetic algorithms. Three different techniques
    of this extended family – **genetic programming**, **NeuroEvolution of Augmenting
    Topologies** (**NEAT**), and **particle swarm optimization** – will be then demonstrated
    through the implementation of problem-solving Python programs. Finally, we will
    provide a brief overview of several other related computation paradigms.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The evolutionary computation family of algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the concepts of **genetic programming** and how they differ from
    genetic algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using genetic programming to solve the **even parity** **check** problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the concepts of **NEAT** and how they differ from genetic algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using NEAT to solve the even parity check problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the concepts of particle swarm optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using particle swarm optimization to optimize **Himmelblau’s function**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the principles behind several other evolutionary and **biologically**
    **inspired techniques**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start this chapter by unveiling the extended family of **evolutionary
    computation** and discussing the main characteristics shared by its members.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will be using Python 3 alongside the following supporting
    libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '**deap**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**numpy**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**networkx**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**neatpy** – introduced in this chapter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pygame**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If you’re using the **requirements.txt** file we’ve provided (see [*Chapter
    3*](B20851_03.xhtml#_idTextAnchor091)), these libraries will already be in your
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: The programs that will be used in this chapter can be found in this book’s GitHub
    repository at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_16](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_16).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/OEBOd](https://packt.link/OEBOd).'
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary computation and bio-inspired computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we have covered the problem-solving technique known as
    *genetic algorithms* and applied it to numerous types of problems, including **combinatorial
    optimization**, **constraint satisfaction,** and **continuous function optimization**,
    as well as to **machine learning** and **artificial intelligence**. However, as
    we mentioned in [*Chapter 1*](B20851_01.xhtml#_idTextAnchor015), *An Introduction
    to Genetic Algorithms*, genetic algorithms are just one branch within a larger
    family of algorithms called **evolutionary computation**. This family consists
    of various related problem-solving and optimization techniques, all of which draw
    inspiration from Charles Darwin’s theory of natural evolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main characteristics that are shared by these techniques are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The starting point is an initial set (**population**) of candidate solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The candidate solutions (**individuals**) are updated iteratively to create
    new generations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a new generation involves removing less successful individuals (**selection**),
    as well as introducing small random changes (**mutations**) to some individuals.
    Other operators, such as interaction with other individuals (**crossover**), may
    also be applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a result, as generations go by, the **fitness** of the population increases;
    in other words, the candidate solutions become better at solving the problem at
    hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More broadly, since evolutionary computation techniques are based on various
    biological systems or behaviors, they generally overlap with the algorithm family
    known as **bio-inspired computing**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following sections, we will cover some of the most frequently used members
    of evolutionary computation and bio-inspired computing – some will be covered
    in greater detail, while the others will only be mentioned briefly. We will start
    by providing a detailed account of a fascinating technique that allows us to evolve
    actual computer programs: **genetic programming**.'
  prefs: []
  type: TYPE_NORMAL
- en: Genetic programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Genetic programming is a special form of genetic algorithm – that is, the technique
    we have been applying throughout this book. In this special case, the candidate
    solutions – or individuals – that we are evolving to find the best one for our
    purpose are computer programs, hence the name. In other words, when we apply genetic
    programming, we evolve *computer programs* to find a program that will excel at
    performing a particular task.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may recall, genetic algorithms use a representation of the candidate
    solutions, often referred to as a *chromosome*. This representation is subject
    to genetic operators, namely *selection*, *crossover*, and *mutation*. Applying
    these operators to the current generation results in a new generation of solutions
    that is expected to produce better results than its predecessor. In most of the
    problems we have looked at so far, this representation was a list (or an array)
    of values of a certain type, such as integers, Booleans, or floats. To represent
    a *program*, however, we typically use a *tree structure*, as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.1: Tree structure representation of a simple program](img/B20851_16_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.1: Tree structure representation of a simple program'
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [https://commons.wikimedia.org/wiki/File:Genetic_Program_Tree.png](https://commons.wikimedia.org/wiki/File:Genetic_Program_Tree.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by Baxelrod.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tree structure depicted in the preceding diagram represents the calculation
    shown underneath the tree. This calculation is equivalent to a short program (or
    a function) that accepts two arguments, *X* and *Y*, and returns a certain output
    based on their values. To create and evolve such tree structures, we need to define
    two different sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Terminals**, or the *leaves* of the tree. These are arguments and the constant
    values that can be used in the tree. In our example, **X** and **Y** are arguments,
    while **2.2**, **11**, and **7** are constants. Constants can also be generated
    randomly, within a certain range, when a tree is created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Primitives**, or the *internal nodes* of the tree. These are functions (or
    operators) that accept one or more arguments and generate a single output value.
    In our example, **+**, **-**, *****, and **÷** are primitives that accept two
    arguments, while **cos** is a primitive that accepts a single argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In [*Chapter 2*](B20851_02.xhtml#_idTextAnchor053), *Understanding the Key
    Components of Genetic Algorithms*, we demonstrated how the genetic operator of
    *single-point crossover* operates on binary-valued lists. The crossover operation
    created two offspring from two parents by cutting out a part of each parent and
    swapping the detached parts between the parents. Similarly, a crossover operator
    for the tree representation may detach a *subtree* (a branch or a group of branches)
    from each parent and swap the detached branches between the parents to create
    offspring trees, as demonstrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.2: Crossover operation between two tree structures representing
    programs](img/B20851_16_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.2: Crossover operation between two tree structures representing programs'
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [https://commons.wikimedia.org/wiki/File:GP_crossover.png](https://commons.wikimedia.org/wiki/File:GP_crossover.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by U-ichi
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the two parents on the top row have subtrees that have been
    swapped between them to create the two offspring in the second row. The swapped
    subtrees are marked by the rectangles surrounding them.
  prefs: []
  type: TYPE_NORMAL
- en: Along the same lines, the *mutation* operator, which intends to introduce random
    changes to a single individual, can be implemented by picking a subtree within
    the candidate solution and replacing it with a randomly generated one.
  prefs: []
  type: TYPE_NORMAL
- en: The **deap** library, which we have been using throughout this book, provides
    inherent support for genetic programming. In the next section, we will implement
    a simple genetic programming example using this library.
  prefs: []
  type: TYPE_NORMAL
- en: Genetic programming example – even parity check
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For our example, we will use genetic programming to create a program that implements
    an even parity check. In this task, the possible values of the inputs are 0 or
    1\. The output value should be 1 if the number of the inputs with the value 1
    is odd, thereby producing a total even number of 1 values; otherwise, the output
    value should be 0\. The following table lists the various possible combinations
    of input values for the case of three inputs, along with the matching even parity
    output values:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **in_0** | **in_1** | **in_2** | **Even Parity** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 16.1: Truth table of even parity as a function of three inputs'
  prefs: []
  type: TYPE_NORMAL
- en: This kind of table is often referred to as the *truth table* of the operation
    at hand. As evident from this truth table, one reason that the parity check is
    often used as a benchmark is that any single change in the input values will result
    in a change to the output value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The parity check can also be represented using logic gates, such as `AND`,
    `OR`, `NOT`, and exclusive `OR` (`XOR`). While the `NOT` gate accepts a single
    input and inverts it, each of the three other gate types accepts two inputs. For
    the respective output to be 1, the `AND` gate requires both inputs to be 1, the
    `OR` gate requires at least one of them to be 1, and the `XOR` gate requires that
    exactly one of them is 1, as shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **in_0** | **in_1** | **AND** | **OR** | **XOR** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 16.2: Truth tables of AND, OR and XOR operations of two inputs'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many possible ways to implement the three-input parity check using
    logic gates. The simplest way to do this is by using two `XOR` gates, as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.3: A three-input even parity check implemented using two XOR gates](img/B20851_16_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.3: A three-input even parity check implemented using two XOR gates'
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will use genetic programming to create a small program
    that implements an even parity check using the `AND`, `OR`, `NOT`, and `XOR` logic
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: Genetic programming implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To evolve a program that implements the even parity check logic, we’ve created
    a genetic programming-based Python program called `01_gp_even_parity.py` at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/01_gp_even_parity.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/01_gp_even_parity.py).
  prefs: []
  type: TYPE_NORMAL
- en: Since genetic programming is a special case of genetic algorithms, much of this
    program will look familiar to you if you have gone over the programs we presented
    in earlier chapters of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps describe the main parts of this program:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by setting the problem-related constant values. Here, **NUM_INPUTS**
    determines the number of inputs for the even parity checker. We will use a value
    of **3** for simplicity; however, larger values can be set as well. The **NUM_COMBINATIONS**
    constant represents the number of possible combinations of values for the inputs,
    which is analogous to the number of rows in the truth table we saw earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is followed by the familiar genetic algorithm constants we have seen numerous
    times before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'However, genetic programming requires several additional constants that refer
    to the tree representation of the candidate solutions. These are defined in the
    following code. We will see how they are used as we examine the rest of this program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we calculate the *truth table* of the even parity check so that we can
    use it as a reference when we need to check the accuracy of a given candidate
    solution. The **parityIn** matrix represents the input columns of the truth table,
    while the **parityOut** vector represents the output column. The Python **itertools.product()**
    function is an elegant replacement for nested **for** loops that would be otherwise
    required to iterate over all the combinations of input values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, it is time to create the set of *primitives* – that is, the operators
    that will be used in our evolved programs. The first declaration creates a set
    using the following three arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The name of the program to be generated using the primitives from the set (here,
    we called it **main**)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of inputs to the program
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The prefix to be used when naming the inputs (optional)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These three arguments are used to create the following primitive set:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we fill the primitive set with the various functions (or operators) that
    will be used as the building blocks of the program. For each operator, we will
    use a reference to the function that implements it and the number of arguments
    it expects. Although we could define our own functions for this purpose, in this
    case, we’re making use of the existing Python **operator** module, which contains
    numerous useful functions, including the logical operators we need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following definitions set the *terminal* values to be used. As we mentioned
    earlier, these are constants that can be used as input values for the tree. In
    our case, it makes sense to use **0** and **1** as values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Since our goal is to create a program that implements the truth table of the
    *even parity check*, we will attempt to minimize the difference between the program’s
    output and the known output values. For this purpose, we will define a single
    objective – that is, minimizing the fitness strategy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will create the **Individual** class, based on the **PrimitiveTree**
    class provided by the **deap** library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To help us construct an individual in the population, we will create a helper
    function that will generate random trees using the primitive set we defined earlier.
    Here, we’re making use of the **genFull()** function offered by **deap** and providing
    it with the primitive set, as well as with the values for defining the minimum
    and maximum height of the generated trees:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is followed by defining two operators, the first of which creates an individual
    instance using the preceding helper operator. The other generates a list of such
    individuals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create an operator to *compile* a given primitive tree into Python
    code using the **compile()** function offered by **deap**. Consequently, we’ll
    use this compile operator in a function we’ll create, called **parityError()**.
    For a given individual – a tree representing an expression – this function counts
    the number of rows in the truth table for which the result of the calculation
    differs from the expected one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must instruct the genetic programming algorithm to use the **getCost()**
    function for fitness evaluation. This function returns the parity error we just
    saw in tuple form that’s required by the underlying evolutionary algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It’s time to choose our genetic operators, starting with the *selection* operator
    (aliased with **select**). For genetic programming, this operator is typically
    the same *tournament selection* we have been using throughout this book. Here,
    we’re using it with a tournament size of **2**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As for the *crossover* operator (aliased with **mate**), we will use the specialized
    genetic programming **cxOnePoint()** operator that’s provided by **deap**. Since
    the evolving programs are represented by trees, this operator takes two parent
    trees and exchanges sections of them to create two valid offspring trees:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next is the *mutation* operator, which introduces random changes to an existing
    tree. The mutation is defined in two stages. First, we specify a helper operator
    that utilizes the specialized genetic programming **genGrow()** function, provided
    by **deap**. This operator creates a subtree within the limits defined by the
    two constants. Then, we define the mutation operator itself (aliased with **mutate**).
    This operator utilizes DEAP’s **mutUniform()** function, which randomly replaces
    a subtree in a given tree with a random one that was generated using the helper
    operator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To prevent individuals in the population from growing into overly large trees,
    potentially containing an excessive number of primitives, we need to introduce
    *bloat control* measures. We can do this using DEAP’s **staticLimit()** function,
    which imposes a tree height restriction on the results of the *crossover* and
    *mutation* operations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The program’s main loop is very similar to the ones we saw in earlier chapters.
    After creating the initial population, defining the statistics measurements, and
    creating the HOF object, we call the evolutionary algorithm. Like we’ve done multiple
    times before, we must apply the *elitist approach*, where the HOF members – the
    current best individuals – are always passed untouched to the next generation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'At the end of the run, we print the best solution, as well as the height of
    the tree that’s being used to represent it, and its length – that is, the total
    number of operators contained in the tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The last thing we need to do is plot a graphic illustration of the tree representing
    the best solution. To that end, we must utilize the graph and networks library
    known as *NetworkX* (**nx**), which we introduced in [*Chapter 5*](B20851_05.xhtml#_idTextAnchor177),
    *Constraint Satisfaction*. We start by calling the **graph()** function provided
    by **deap**, which breaks down the individual tree into the nodes, edges, and
    labels that are required for the graph, and then create the graph using the appropriate
    **networkx** functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we draw the nodes, edges, and labels. Since the layout of this graph
    is not a classic hierarchical tree, we must distinguish the top node by coloring
    it red and enlarging it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When running this program, we get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Since this is a simple problem, the fitness has quickly reached the minimum
    value of 0, which means we were able to find a solution that correctly reproduces
    the *even parity check* truth table. However, the resulting expression, which
    consists of 19 elements and four levels in the hierarchy, seems overly complex.
    This is illustrated by the following plot that was produced by the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.4: A plot representing the parity check solution that was found
    by the initial program](img/B20851_16_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.4: A plot representing the parity check solution that was found by
    the initial program'
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, the red node in the graph represents the top of
    the program’s tree, which maps to the first `XOR` operation in the expression.
  prefs: []
  type: TYPE_NORMAL
- en: The reason for this relatively complex graph is that there is no advantage to
    using simpler expressions. So long as they fall within the imposed limitation
    of tree height, the expressions that are evaluated incur no penalty for complexity.
    In the next subsection, we will attempt to change this situation by making a small
    modification to the program in the hope of achieving the same outcome – the implementation
    of the even parity check – but with a simpler solution.
  prefs: []
  type: TYPE_NORMAL
- en: Simplifying the solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the implementation we have just seen, there were measures in place to restrict
    the size of the trees that represent the candidate solutions. However, the best
    solution we found seems overly complex. One way to pressure the algorithm into
    producing simpler results is to impose a small cost penalty for complexity. This
    penalty should be small enough that it refrains from favoring simpler solutions
    that fail to solve the problem. Rather, it should serve as a tie-breaker between
    two good solutions, so the simpler of the two will be preferred. This approach
    has been implemented in the `02_gp_even_parity_reduced.py` Python program, which
    is located at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/02_gp_even_parity_reduced.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/02_gp_even_parity_reduced.py).
  prefs: []
  type: TYPE_NORMAL
- en: 'This program is nearly identical to the previous one, except for a couple of
    small changes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main change was introduced to the *cost function*, which the algorithm
    seeks to minimize. To the original calculated error, a small penalty measure was
    added that depends on the height of the tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The only other change was at the end of the run, after printing the best solution
    that was found. Here, in addition to printing the fitness value, we print the
    actual *parity error* that was obtained, without the penalty that’s present in
    the fitness:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'By running this modified version, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding output, we can tell that, after five generations, the algorithm
    was able to find a solution that correctly reproduces the even parity check truth
    table since the fitness value at that point was nearly 0\. However, as the algorithm
    kept running, the tree height was reduced from four (a penalty of `0.04`) to two
    (a penalty of `0.02`). As a result, the best solution is very simple and consists
    of only five elements – the three inputs and two `XOR` operators. The solution
    we found represents the simplest known solution that we saw earlier, which consists
    of two `XOR` gates. This is illustrated by the following plot, which was produced
    by the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.5: A plot representing the parity check solution that was found
    by the modified program](img/B20851_16_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.5: A plot representing the parity check solution that was found by
    the modified program'
  prefs: []
  type: TYPE_NORMAL
- en: While genetic programming is considered a subset of genetic algorithms, the
    next section describes a more specialized form of evolutionary computation – one
    that is dedicated to creating neural network architectures.
  prefs: []
  type: TYPE_NORMAL
- en: NEAT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 9*](B20851_09.xhtml#_idTextAnchor257), *Architecture Optimization
    of Deep Learning Networks*, we demonstrated how a simple genetic algorithm can
    be used to find the best architecture of a feed-forward neural network (also known
    as **multilayer perceptron** or **MLP**) for a particular task. To do that, we
    limited ourselves to three hidden layers and coded each network using a fixed-size
    chromosome that had placeholders for each of the layers, where a 0 or a negative
    value meant that the layer did not exist.
  prefs: []
  type: TYPE_NORMAL
- en: Taking this idea further, **NEAT** is an evolutionary technique dedicated to
    creating neural networks more flexibly and incrementally and was created in 2002
    by *Kenneth Stanley* and *Risto Miikkulainen*.
  prefs: []
  type: TYPE_NORMAL
- en: NEAT starts with small, simple neural networks and allows them to evolve by
    adding and modifying neurons and connections over generations. Rather than using
    a fixed-size chromosome, NEAT represents solutions as *directed graphs* that directly
    map into artificial neural networks, where nodes represent neurons, and connections
    between nodes represent synapses. This allows NEAT to evolve not only the weights
    of the connections but also the network’s structure itself, including adding and
    removing neurons and connections.
  prefs: []
  type: TYPE_NORMAL
- en: NEAT’s *crossover* operator is designed specifically for neural networks. It
    aligns and combines matching neurons and connections from parent networks while
    maintaining unique ‘innovation’ identifiers. To enable this kind of matching,
    the history of genes is tracked by the use of a **global innovation number**,
    which increases as new genes are added.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, NEAT employs a **speciation** mechanism that groups individuals
    (neural networks) into species based on their structural similarity. This grouping
    encourages competition *within* species rather than *between* species. This mechanism
    helps ensure that innovations have a chance to thrive within their respective
    niches before being subjected to intense competition.
  prefs: []
  type: TYPE_NORMAL
- en: NEAT (along with other related neuroevolutionary techniques) has been applied
    in many areas, including financial forecasting, drug discovery, evolving art,
    electronic circuit design, and robotics; however, it is most commonly found in
    *reinforcement learning* applications, such as game playing.
  prefs: []
  type: TYPE_NORMAL
- en: NEAT example – even parity check
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will illustrate using the NEAT technique by solving the same three-input
    *even parity check* problem we used in the previous section to demonstrate genetic
    programming. Here, we’ll employ NEAT to create a feed-forward neural network implementation
    of the same parity check function.
  prefs: []
  type: TYPE_NORMAL
- en: In regards to neural networks, the even parity check, also known as **the XOR
    problem**, is known to be impossible for a single perceptron to implement as it
    forms a pattern that cannot be separated by a single line or a simple linear function.
    To capture this non-linearity, the minimal required network consists of, in addition
    to the input and output layers, a hidden layer of two neurons. In the next subsection,
    we will set out to see if NEAT can find this minimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: NEAT implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To evolve a neural network that implements the even parity check logic using
    the NEAT technique, we’ve created a Python program called `03_neat_even_parity.py`
    at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/03_neat_even_parity.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/03_neat_even_parity.py).
  prefs: []
  type: TYPE_NORMAL
- en: Python NEAT library
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are several capable Python libraries available that implement the NEAT
    technique, most notably the **NEAT-Python** library. However, for our example,
    we will be using the lightweight **neatpy** library, owing to its conciseness
    and ease of use. This library can be installed (if not already present) using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, the **PyGame** library is required for visualizing the progress
    of the solution. If it’s not been installed yet, it can be added using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Program
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following steps describe the main parts of this program:'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the genetic programming example, we’ll start by setting the problem-related
    constant values. **NUM_INPUTS** determines the number of inputs for the even parity
    checker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since we would like to save an image with the best solution’s network structure
    at the end of the program, let’s make sure a folder for it has been created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we must set up the graphical display for the real-time “animation” of
    the algorithm’s progress by using the functionality of the *PyGame* library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we must set several options for the NEAT algorithm that will be used:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of inputs for our network (which would be identical to **NUM_INPUTS**).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of outputs (1, in our case).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Population size (150, in our example).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A fitness threshold. If the best solution surpasses this value, the algorithm
    considers the problem as solved and stops. As the best fitness possible is equal
    to the number of rows in the truth table (indicating we got the correct results
    for all rows), we must set the threshold to a value just under that:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we must calculate **parityIn** and **parityOut** while implementing the
    inputs and outputs of the desired parity check, similar to what we did in the
    genetic programming example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, it’s time to define **parityScore()**, the function that evaluates a given
    neural network (represented by the **nn** parameter). Since the score needs to
    be positive, we’ll start from the maximum score, and then subtract the square
    of the difference between each expected network output and the actual (float)
    value produced by the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In addition, the score includes a small penalty term for each node in the network,
    giving smaller architectures an advantage:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Coming up next is another utility function, **draw_current()**. It draws the
    architecture (nodes and connections) of the current best solution by calling the
    **neatpy** library’s **draw_brain_pygame()**; in addition, it illustrates the
    *speciation* mechanism by drawing the current status of species using the **draw_species_bar_pygame()**
    function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After creating the initial **population**, we get to the main loop of the NEAT
    algorithm. Thanks to the simplicity of the **neatpy** library, this loop is very
    concise. It starts by scoring the current population, as is the usual case for
    evolutionary algorithms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The main loop continues by calling the library’s **epoch()** function, which
    performs a single NEAT evolutionary step, resulting in a new population. Then,
    it prints out the current population and draws the current best individual, as
    well as the speciation status, by calling **draw_current()**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the loop exits, the results are printed, the truth table is checked, and
    the latest drawing is saved to an image file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When running the program, the drawing containing the visualizations of the
    network and the speciation appears and updates itself at each generation, thereby
    creating an “animated” view of the status. The following figure contains four
    “snapshots” of the drawing that were captured during the run:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 16.6: Stages in the evolution of the NEAT solution for the three-input
    even parity check problem](img/B20851_16_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.6: Stages in the evolution of the NEAT solution for the three-input
    even parity check problem'
  prefs: []
  type: TYPE_NORMAL
- en: These snapshots demonstrate how the network starts with only the input and output
    layer nodes and a single species, then develops numerous species, followed by
    the addition of a single hidden layer node, and then a second one.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of the run, the program saves one last snapshot as an image under
    the `images` folder. This looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.7: The final stage in the evolution of the NEAT solution for the
    three-input even parity check problem](img/B20851_16_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.7: The final stage in the evolution of the NEAT solution for the
    three-input even parity check problem'
  prefs: []
  type: TYPE_NORMAL
- en: In the drawings, the white circles represent the nodes of the network, except
    for the top left circle, which is used to represent the *bias* values of the hidden
    and output layer nodes. The blue edges represent connections of positive weight
    (or a positive bias value), while the orange edges represent negative weights
    (or bias values). Unlike traditional MLPs, the networks created by the NEAT algorithm
    can have connections that “skip” a layer, such as the orange edge connecting the
    bottom input node directly to the output node, as well as intra-layer connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'The printed output of the program indicates that the best network that was
    found was able to solve the problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the best architecture that was found included a single hidden
    layer of two nodes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will examine another biologically inspired, population-based
    algorithm. However, this algorithm deviates from using the familiar genetic operators
    of selection, crossover, and mutation, and instead utilizes a different set of
    rules to modify the population at each generation – welcome to the world of swarm
    behavior!
  prefs: []
  type: TYPE_NORMAL
- en: Particle swarm optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Particle swarm optimization** (**PSO**) draws its inspiration from natural
    groupings of individual organisms, such as flocks of birds or schools of fish,
    generally referred to as *swarms*. The organisms interact within the swarm without
    central supervision, working together toward a common goal. This observed behavior
    gave rise to a computational method that can solve or optimize a given problem
    by using a group of candidate solutions, represented by *particles* analogous
    to organisms in a swarm. The particles move in the search space, looking for the
    best solution, and their movement is governed by simple rules that involve their
    position and *velocity* (directional speed).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The PSO algorithm is iterative, and in each iteration, every particle’s position
    gets evaluated, and its best location so far, as well as the best location within
    the entire group of particles, are updated if necessary. Then, each particle’s
    velocity is updated according to the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: The particle’s current speed and direction of movement – representing *inertia*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The particle’s best position found so far (local best) – representing *cognitive
    force*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entire group’s best position found so far (global best) – representing *social
    force*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is followed by an update to the particle’s position, based on the newly
    calculated velocity.
  prefs: []
  type: TYPE_NORMAL
- en: This iterative process continues until some stopping condition, such as the
    *iterations limit*, is met. At this point, the group’s current best position is
    taken as the solution by the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: This simple yet efficient process will be illustrated in detail in the next
    section, where we will go over a program that optimizes a function using the PSO
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: PSO example – function optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For demonstration purposes, we will use the PSO algorithm to find the minimum
    location(s) of *Himmelblau’s function*, a commonly used benchmark that we previously
    optimized using genetic algorithms in [*Chapter 6*](B20851_06.xhtml#_idTextAnchor197),
    *Optimizing Continuous Functions*. This function can be depicted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.8: Himmelblau’s function](img/B20851_16_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.8: Himmelblau’s function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [https://commons.wikimedia.org/wiki/File:Himmelblau_function.svg](https://commons.wikimedia.org/wiki/File:Himmelblau_function.svg)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by Morn the Gorn.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a reminder, the function can be mathematically expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: f(x, y) = (x 2 + y − 11) 2 + (x + y 2 − 7) 2
  prefs: []
  type: TYPE_NORMAL
- en: 'It has four global minima, evaluating to 0, indicated by the blue areas in
    the plot. These are located at the following coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '*x=3.0, y=2.0*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x=−2.805118, y=3.131312*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x=−3.779310, y=−3.283186*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x=3.584458, y=−1.848126*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For our example, we will attempt to find any one of these minima.
  prefs: []
  type: TYPE_NORMAL
- en: Particle swarm optimization implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To locate a minimum of *Himmelblau’s function* using particle swarm optimization,
    we’ve created a Python program called `04_pso_himmelblau.py` at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/04_pso_himmelblau.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_16/04_pso_himmelblau.py).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps describe the main parts of this program:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by setting various constants that will be used throughout the program.
    First, we have the *dimensionality* of the problem at hand – **2**, in our case
    – which, in turn, determines the dimensionality of the *location* and *velocity*
    of each particle. Next comes the population size – the total number of particles
    in the swarm – and the number of generations, or iterations, of running the algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is followed by several additional constants that affect how the particles
    are created and updated. We will see how they play their roles as we examine the
    rest of the program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Since our goal is to locate a minimum in *Himmelblau’s function*, we need to
    define a single objective – that is, minimizing the fitness strategy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: creator.create("Particle",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: np.ndarray,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: fitness=creator.FitnessMin,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: speed=None,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: best=None)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To help us construct an individual particle in the population, we need to define
    a helper function that will create and initialize a random particle. We will use
    the **numpy** library’s **random.uniform()** function to randomly generate the
    location and speed arrays of the new particle, within the given boundaries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This function is used in the definition of the operator that creates a particle
    instance. This, in turn, is used by the population creation operator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next comes the method that serves as the heart of the algorithm, `ndarray` type
    are *two- dimensional* in our case, and the calculations are performed element-wise,
    one per dimension.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The updated particle speed is effectively a combination of the particle’s original
    speed (representing *inertia*), the particle’s best-known location (*cognitive
    force*), and the best-known location of the entire population (*social force*):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The **updateParticle()** method continues by making sure that the new speed
    does not exceed the preset limits and updates the location of the particles using
    the updated speed. As we mentioned previously, both **location** and **speed**
    are of the **ndarray** type and have separate components for each dimension:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must register the **updateParticle()** method as a toolbox operator
    that will be in the main loop later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We still need to define the function to be optimized – *Himmelblau’s function*,
    in our case – and register it as the fitness evaluation operator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we’re finally at the **main()** method, we can start it by creating
    the population of particles:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before starting the algorithm’s main loop, we need to create the **stats**
    object, to calculate the population’s statistics, and the **logbook** object,
    to record the statistics at every iteration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The program’s main loop contains an external loop that iterates over the generations/update
    cycles. Within each iteration, there are two secondary loops, each iterating over
    all the particles in the population. The first loop, which can be seen in the
    following code, evaluates each particle against the function to be optimized and
    updates the *local best* and the *global best* if necessary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The second inner loop calls the **update** operator. As we saw previously,
    this operator updates the speed and the location of the particle using a combination
    of *inertia*, *cognitive force*, and *social force*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'At the end of the outer loop, we record the statistics for the current generation
    and print them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the outer loop is done, we print the information for the best location
    that was recorded during the run. This is considered the solution that the algorithm
    has found for the problem at hand:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'By running this program, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: These results indicate that the algorithm was able to locate one of the minima,
    around x=−3.77 and y=−3.28\. Looking at the stats we recorded along the way, we
    can see that the best result was achieved at generation 480\. It is also evident
    that the particles move around quite a bit and, during the run, oscillate about
    the best result.
  prefs: []
  type: TYPE_NORMAL
- en: To find the other minimum locations, you can rerun the algorithm with a different
    random seed. You can also penalize the solutions in the areas around the previously
    found minima, just like we did with *Simionescu’s function* in [*Chapter 6*](B20851_06.xhtml#_idTextAnchor197),
    *Optimizing Continuous Functions*. Another approach could be using multiple simultaneous
    swarms to locate several minima in the same run – you are encouraged to try this
    on your own (see the *Further reading* section for more information).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will briefly review several more members of the extended
    evolutionary computation family.
  prefs: []
  type: TYPE_NORMAL
- en: Other related techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Besides the techniques we have covered so far, numerous other problem-solving
    and optimization techniques draw their inspiration from the Darwinian evolution
    theory, as well as from various biological systems and behaviors. The following
    subsections briefly describe several more of these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Evolution strategies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Evolution strategies** (**ES**) are a kind of genetic algorithm that emphasizes
    *mutation* rather than *crossover* as the evolutionary facilitator. The mutation
    is adaptive, and its strength is learned over the generations. The selection operator
    in ES is always based on *rank* rather than on actual fitness values. A simple
    version of this technique is called *(1 + 1)*. It includes only two individuals
    – a parent and its mutated offspring. The best of them continue to be the parent
    of the next mutated offspring. In the more general case, called *(1 + λ)*, there
    is one parent and λ mutated offspring, and the best of the offspring continues
    to be the parent of the next λ offspring. Some newer variations of the algorithm
    include more than one parent, as well as a *crossover* operator.'
  prefs: []
  type: TYPE_NORMAL
- en: Differential evolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Differential evolution** (**DE**) is a specialized variant of genetic algorithms
    that’s used to optimize real-valued functions. DE differs from genetic algorithms
    in the following aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: The DE population is always represented as a collection of real-valued vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of replacing the entire current generation with a new generation, DE
    keeps iterating over the population, modifying one individual at a time, or keeping
    the original individual if it’s better than its modified version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The traditional *crossover* and *mutation* operators are replaced by specialized
    ones, thereby modifying the value of the current individual using the values of
    three other individuals that are chosen at random.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ant colony optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Ant colony optimization** (**ACO**) algorithms are inspired by the way certain
    species of ants locate food. The ants start by wandering randomly, and when any
    of them locates food, they go back to their colony while depositing pheromones
    along the way, marking the path for other ants. Other ants finding food at the
    same location will reinforce the trail by depositing their own pheromones. The
    pheromone marks fade away over time, giving the shorter paths and the paths that
    are traveled more often an advantage.'
  prefs: []
  type: TYPE_NORMAL
- en: ACO algorithms use artificial ants that move about in the search space looking
    for the location of the best solutions. The “ants” keep track of their locations
    and the candidate solutions they have found along the way. This information is
    used by the ants of the subsequent iterations so that they can find better solutions.
    These algorithms are often combined with the *local search* method, which is activated
    after locating an area of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial immune systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Artificial immune systems** (**AIS**) draw their inspiration from the characteristics
    of adaptive immune systems found in mammals. These systems are capable of identifying
    and learning new threats, as well as applying the acquired knowledge and responding
    faster the next time a similar threat is detected.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recent AIS can be used in various machine learning and optimization tasks,
    and generally belong to one of the following three subfields:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Clonal selection**: This involves imitating the process by which the immune
    system selects the best cell to recognize and eliminate an antigen that enters
    the body. The cell is chosen out of a pool of pre-existing cells with varying
    specificities, and once chosen, it is cloned to create a population of cells that
    eliminates the invading antigen. This paradigm is typically applied to optimization
    and pattern recognition tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Negative selection**: This follows a process that identifies and deletes
    cells that may attack self-tissues. These algorithms are typically used in anomaly
    detection tasks, where normal patterns are used to “negatively” train filters
    that will then be able to detect anomalous patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Immune network algorithms**: This is inspired by the theory that suggests
    that the immune system is regulated using special types of antibodies that bind
    to other antibodies. In this type of algorithm, antibodies represent nodes in
    a network and the learning process involves creating or removing edges between
    the nodes, resulting in an evolving network graph structure. These algorithms
    are typically used in non-supervised machine learning tasks, as well as in the
    fields of control and optimization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial life
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rather than being a branch of evolutionary computation, **artificial life**
    (**ALife**) is a broader field that involves systems and processes that imitate
    natural life in different ways, such as computer simulations and robotic systems.
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary computation can be viewed as an application of ALife, where the
    population seeking to optimize a certain fitness function is a metaphor for organisms
    searching for food. The niching and sharing mechanisms, which we described in
    [*Chapter 2*](B20851_02.xhtml#_idTextAnchor053), *Understanding the Key Components
    of Genetic Algorithms*, draw directly from the food metaphor.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main branches of ALife are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Soft**: Represents software-based (digital) simulation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hard**: Represents hardware-based (physical) robotics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wet**: Represents biochemical-based manipulation or synthetic biology'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ALife can also be viewed as the bottom-up counterpart to artificial intelligence
    since ALife typically builds on the biological environment, mechanisms, and structures
    rather than high-level cognition.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you were introduced to the extended family of *evolutionary
    computation* and some of the common characteristics of its members. Then, we used
    *genetic programming* – a special case of genetic algorithms – to implement the
    *even parity check* task using Boolean logic building blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we created a neural network implementation of the same even parity check
    task by utilizing the NEAT technique.
  prefs: []
  type: TYPE_NORMAL
- en: This was followed by creating a program that utilized the *particle swarm optimization*
    technique to optimize *Himmelblau’s function*.
  prefs: []
  type: TYPE_NORMAL
- en: We concluded this chapter with a brief overview of several other related problem-solving
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Now that this book has come to its end, I wanted to thank you for taking this
    journey with me while going through the various aspects and use cases of genetic
    algorithms and evolutionary computation. I hope that you found this book interesting
    as well as thought-provoking. As this book demonstrated, genetic algorithms and
    their related techniques can be applied to a plethora of tasks in virtually any
    computation and engineering field, including – very likely – the ones you are
    currently involved with. Remember, all that is required for the genetic algorithm
    to start crunching a problem is a way to represent a solution and a way to evaluate
    a solution – or compare two solutions. Since this is the age of artificial intelligence
    and cloud computing, you will find that genetic algorithms lend themselves well
    to both and can be a powerful tool in your arsenal when you’re approaching a new
    challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information, please refer to the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Genetic Programming: bio-inspired machine* *learning*: [http://geneticprogramming.com/tutorial/](http://geneticprogramming.com/tutorial/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Artificial Intelligence for Big Data*, by Manish Kumar and Anand Deshpande,
    May 21, 2018'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hands-On Neuroevolution with Python*, by Iaroslav Omelianenko, December 24,
    2019'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Multimodal optimization using particle swarm optimization algorithms*: CEC
    2015 competition on single objective multi-niche optimization: [https://ieeexplore.ieee.org/document/7257009](https://ieeexplore.ieee.org/document/7257009)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
