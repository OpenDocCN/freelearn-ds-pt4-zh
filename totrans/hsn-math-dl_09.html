<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Feedforward Neural Networks</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we covered linear neural networks, which have proven to be effective for problems such as regression and so are widely used in the industry. However, we also saw that they have their limitations and are unable to work effectively on higher-dimensional problems.</p>
<p>In this chapter, we will take an in-depth look at the <strong>multilayer perceptron</strong> (<strong>MLP</strong>), a type of <strong>feedforward neural network</strong> (<strong>FNN</strong>). We will start by taking a look at how biological neurons process information, then we will move onto mathematical models of biological neurons. The <strong>artificial neural networks</strong> (<strong>ANNs</strong>) we will study in this book are made up of mathematical models of biological neurons (we will learn more about this shortly). Once we have built a foundation, we will move on to understanding how MLPs—which are the FNNs—work and their involvement with deep learning.</p>
<p>What FNNs allow us to do is approximate a function that maps input to output and this can be used in a variety of tasks, such as predicting the price of a house or a stock or determining whether or not an event will occur.</p>
<p>The following topics are covered in this chapter:</p>
<ul>
<li>Understanding biological neural networks</li>
<li>Comparing the perceptron and the McCulloch-Pitts neuron</li>
<li>MLPs</li>
<li>Training neural networks</li>
<li>Deep neural networks</li>
</ul>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Understanding biological neural networks</h1>
                </header>
            
            <article>
                
<p>The human brain is capable of some remarkable feats—it performs very complex information processing. The neurons that make up our brains are very densely connected and perform in parallel with others. These biological neurons receive and pass signals to other neurons through the connections (synapses) between them. These synapses have strengths associated with them and increasing or weakening the strength of the connections between neurons is what facilitates our learning and allows us to continuously learn and adapt to the dynamic environments we live in.</p>
<p>As we know, the brain consists of neurons—in fact, according to recent studies, it is estimated that the human brain contains roughly 86 billion neurons. That is a lot of neurons and a whole lot more connections. A very large number of these neurons are used simultaneously every day to allow us to carry out a variety of tasks and be functional members of society.<span> </span><span>Neurons by themselves are said to be quite slow, but it</span> is this large-scale parallel operation that gives our brains its extraordinary capability. </p>
<p>The following is a diagram of a biological neuron:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-949 image-border" src="Images/2ed8f991-d8d2-4c8d-bedb-1386771c801d.png" style="width:54.83em;height:27.42em;"/></p>
<p>As you can see from the preceding diagram, each neuron has three main components—the body, an axon, and many dendrites. The synapses connect the axon of one neuron to the dendrites of other neurons and determine the weight of the information that is received from other neurons. Only when the sum of the weighted inputs to the neuron exceeds a certain threshold does the neuron fire (activate); otherwise, it is at rest. This communication between neurons is done through electrochemical reactions, involving potassium, sodium, and chlorine (which we will not go into as it is beyond the scope of this book; however, if this interests you, there is a lot of literature you can find on it).</p>
<p>The reason we are looking at biological neurons is that the neurons and neural networks we will be learning about and developing in this book are largely biologically inspired. If we are trying to develop artificial intelligence, where better to learn than <span>from</span><span> </span><span>actual intelligence?</span></p>
<p>Since the goal of this book is to teach you how to develop ANNs on computers, it is relatively important that we take a look at the differences between the computational power of our brains as opposed to computers. </p>
<p>Computers have a significant advantage over our brains as they can perform roughly 10 billion operations per second, whereas the human brain can only perform around 800 operations per second. However, the brain requires roughly 10 watts to operate, which is 10 times less than what a computer requires. Another advantage that computers have is their precision; they can perform operations millions of times more accurately. Lastly, computers perform operations sequentially and cannot deal with data they have not been programmed to deal with, but the brain performs operations in parallel and is well equipped to deal with new data.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Comparing the perceptron and the McCulloch-Pitts neuron</h1>
                </header>
            
            <article>
                
<p>In this section, we will cover two mathematical models of biological neurons—the <strong>McCulloch-Pitts</strong><span> (</span><strong>MP</strong><span>)</span> neuron and Rosenblatt's perceptron—which create the foundation for neural networks.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The MP neuron</h1>
                </header>
            
            <article>
                
<p>The MP neuron was created in 1943 by Warren McCulloch and Walter Pitts. It was modeled after the biological neuron and is the first mathematical model of a biological neuron. It was created primarily for classification tasks. The MP neuron takes as input binary values and outputs a binary value based on a threshold value. If the sum of the inputs is greater than the threshold, then the neuron outputs <kbd>1</kbd> (if it is under the threshold, it outputs <kbd>0</kbd>). In the following diagram, we can see what a basic neuron with three inputs and one output looks like:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-950 image-border" src="Images/46f43996-76b7-40b2-9fcf-a3e8c0a66941.png" style="width:20.25em;height:11.17em;"/></p>
<p>As you can see, this isn't entirely dissimilar to the biological neuron we saw earlier.</p>
<p>Mathematically, we can write this as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/4fed4244-c23d-4d05-a473-4d82d7431cbe.png" style="width:10.25em;height:2.75em;"/></p>
<p>Here,<span> <em>x<sub>i</sub></em> = <kbd>0</kbd> or <kbd>1</kbd>.</span></p>
<p>We can think of this as outputting Boolean answers; that is, <kbd>true</kbd> or <kbd>false</kbd> (or <kbd>yes</kbd> or <kbd>no</kbd>).</p>
<p>While the MP neuron may look simple, it has the ability to model any logic function, such as <kbd>OR</kbd>, <kbd>AND</kbd>, and <kbd>NOT</kbd>; but it is unable to classify the <kbd>XOR</kbd> function. Additionally, i<span>t does not have the ability to learn, so the threshold (<em>b</em>) needs to be adjusted analytically to fit our data.</span></p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Perceptron</h1>
                </header>
            
            <article>
                
<p>The perceptron model, created by Frank Rosenblatt in 1958, is an improved version of the MP neuron and can take any real value as input. Each input is then multiplied by a real-valued weight. If the sum of the weighted inputs is greater than the threshold, then the output is <kbd>1</kbd>, and if it is below the threshold, then the output is <kbd>0</kbd>. The following diagram illustrates a basic perceptron model:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-562 image-border" src="Images/1feb9992-9a74-441f-90d7-9319a5c58453.png" style="width:22.83em;height:12.92em;"/></p>
<p>This model shares a lot of similarities with the MP neuron, but it is more similar to the biological neuron.</p>
<p>Mathematically, we can write this as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/eabb472d-f1e6-4d0b-ba24-91da720f7cad.png" style="width:12.75em;height:3.08em;"/></p>
<p>Here, <sub><img class="fm-editor-equation" src="Images/abe9bae6-e784-4fd1-b427-4eb016761781.png" style="width:4.42em;height:1.50em;"/></sub>.</p>
<p>Sometimes, we rewrite the perceptron equation in the following form:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/6db254bd-9049-4af9-bed8-a0e63848161b.png" style="width:13.08em;height:3.17em;"/></p>
<p>The following diagram shows how the <span>perceptron </span>equation will look like:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-952 image-border" src="Images/320b5a92-8882-41fe-917a-50f3c47904f1.png" style="width:24.17em;height:17.58em;"/></p>
<p>Here, <sub><img class="fm-editor-equation" src="Images/22c4d4ac-b870-4c16-bc5a-d53df9a04aa6.png" style="width:3.92em;height:1.33em;"/></sub> and <sub><img class="fm-editor-equation" src="Images/056f6b67-7dff-452e-aa0e-352cf607637c.png" style="width:4.58em;height:1.25em;"/></sub>. This prevents us from having to hardcode the threshold, which makes the threshold a learnable parameter instead of something we have to manually adjust (as is the case with the MP neuron).</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Pros and cons of the MP neuron and perceptron</h1>
                </header>
            
            <article>
                
<p>The advantage the perceptron model has over the MP neuron is that it is able to learn through error correction and it linearly separates the problem using a hyperplane, so anything that falls below the hyperplane is <kbd>0</kbd> and anything above it is <kbd>1</kbd>. This error correction allows the perceptron to adjust the weights and move the position of the hyperplane so that it can properly classify the data.</p>
<p>Earlier, we mentioned that the perceptron learns to linearly classify a problem—but what exactly does it learn? Does it learn the nature of the question that is asked? No. It learns the effect of the input on the output. <em>So, the greater the weight associated with a certain input, the greater its impact on the prediction (classification). </em></p>
<p>The update for the weights (learning) happens as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/40e6f30f-a89f-4952-ae9f-8d37a3dde434.png" style="width:9.00em;height:1.25em;"/></p>
<p>Here, <em>δ</em> = expected value – predicted value.</p>
<p>We could also add a learning rate (<sub><img class="fm-editor-equation" src="Images/b3ec0dca-3cfe-45b8-ba4c-97f0f728a4cf.png" style="width:4.83em;height:1.25em;"/></sub>) if we want to speed up the learning; so, the update will be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/801f9c62-f4a2-4ad9-87df-e292a6e5e2ef.png" style="width:9.75em;height:1.33em;"/></p>
<p>During these updates, the perceptron calculates the distance of the hyperplane from the points to be classified and adjusts itself to find the best position that it can perfectly linearly classify the two target classes. So, it maximally separates both points on either side, which we can see in the following plot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1202 image-border" src="Images/47d7de84-900c-4b21-8635-e037cbe4f383.png" style="width:26.75em;height:17.83em;"/></p>
<p>What is even more fascinating about this is that because of the aforementioned learning rule, the perceptron is guaranteed to converge when given a finite number of updates and so will work on any binary classification task.</p>
<p>But alas, the perceptron is not perfect either and it also has limitations. As it is a linear classifier, it is unable to deal with nonlinear problems, which makes up the majority of the problems we usually wish to develop solutions for.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">MLPs</h1>
                </header>
            
            <article>
                
<p>As mentioned, both the MP neuron and perceptron models are unable to deal with nonlinear problems. To combat this issue, modern-day perceptrons use an activation function that introduces nonlinearity to the output.</p>
<p>The perceptrons (neurons, but we will mostly refer to them as <strong>nodes</strong> going forward) we will use are of the following form:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/c7e24253-38b4-46c3-af8b-368270efcc83.png" style="width:10.17em;height:3.42em;"/></p>
<p>Here,<span> <em>y</em></span> is the output, <em>φ</em> is a nonlinear activation function, <em>x<sub>i</sub></em> is the inputs to the unit, <em>w<sub>i</sub></em> is the weights, and <em>b</em> is the bias. This improved version of the perceptron looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-981 image-border" src="Images/fbda6328-f94d-4726-a9c2-156876ef5b39.png" style="width:33.92em;height:24.58em;"/></p>
<p>In the preceding diagram, the activation function is generally the sigmoid function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/d31b4c77-65c0-4313-a34f-ed9189ce7367.png" style="width:11.25em;height:3.17em;"/></p>
<p>What the sigmoid activation function does is squash all the output values into the<span> <kbd>(0, 1)</kbd> </span><span>range</span><span>. The sigmoid activation function is largely </span><span>used</span><span> </span><span>for historical purposes since the developers of the earlier neurons focused on thresholding. When gradient-based learning was introduced, the sigmoid function turned out to be the best choice.</span></p>
<p>An MLP is the simplest type of FNN. It is basically a lot of nodes combined together and the computation is carried out sequentially. The network looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-982 image-border" src="Images/9ed4f81b-6ef0-47d0-abd4-f29af3de7bf8.png" style="width:36.17em;height:19.75em;"/></p>
<div class="packt_infobox">An FNN is essentially a directed acyclic graph; that is, the connections are always moving in one direction. There are no connections that feed the outputs back into the network. </div>
<p>As you can see from the preceding diagram, the nodes are arranged in layers and the nodes in each layer are connected to each of the neurons in the next layer. However, there aren't any connections between nodes in the same layer. We refer to networks such as this as being fully connected.</p>
<p>The first layer is referred to as the input layer, the last layer is referred to as the output layer, and all the layers in between are called hidden layers. The number of nodes in the output layer depends on the type of problem we build our MLP for. It is important that you remember that the inputs to and outputs from layers are not the same as the inputs to and outputs from the network. </p>
<p>You may also notice that in the preceding architecture, there is only one unit in the output layer. This is generally the case when we have a regression or binary classification task. So, if we want our network to be able to detect multiple classes, then our output layer will have <em>K</em> nodes, where <em>K</em> is the number of classes. </p>
<div class="packt_tip packt_infobox">Note that the depth of the network is the number of layers it has and the width is the number of nodes in a layer<span>. </span></div>
<p>However, what makes neural networks so powerfully effective, and the reason we are studying them, is that they are universal function approximators. The universal approximation theorem states that "<q>a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate continuous functions on compact subsets of <img class="fm-editor-equation" src="Images/1f059592-7ad0-46d4-89f1-9c34a491c915.png" style="width:1.92em;height:1.42em;"/>, under mild assumptions on the activation function.</q>" What this means is that if the hidden layer contains a specific number of neurons, then our neural network can reasonably approximate any known function.</p>
<div class="packt_infobox">You will notice that it is unclear exactly how many neurons are needed in the hidden layer for it to be able to approximate any function. This could vary greatly, depending on the function we want it to learn.</div>
<p><span>By now, you might be thinking that if MLPs have been around since the late 1960s, why has it taken nearly 50 years for them to take off and be used as widely as they are today? This is because the computing power that was available 50 years ago was nowhere near as powerful as what is available today, nor was the same amount of data that is available now available back then. So, because of the lack of results that MLPs were able to achieve back then, they faded into obscurity. Because of this, as well as the universal approximation theorem, researchers at the time hadn't looked deeper than into a couple of layers.</span></p>
<p>Let's break the model down and see how it works.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Layers</h1>
                </header>
            
            <article>
                
<p>We know now that MLPs (and so FNNs) are made of three different kinds of layers—input, hidden, and output. We also know what a single neuron looks like. Let's now mathematically explore MLPs and how they work.</p>
<p>Suppose we have an MLP with<span> </span><img class="fm-editor-equation" src="Images/d94ac979-7201-4477-80eb-3dd96760aa3f.png" style="width:3.75em;height:1.33em;"/><span> </span><span>input</span><span> (where</span><span> </span><img style="font-size: 1em;width:3.17em;height:1.17em;" class="fm-editor-equation" src="Images/da399926-f0d2-4ca9-a852-de9c9d2b5785.png"/><span>), <em>L</em></span><span> layers, <em>N</em></span><span> neurons in each layer, an activation function</span><span> </span><span><sub><img class="fm-editor-equation" src="Images/b7b71384-b2f7-4c6f-9348-6b7bb274e79c.png" style="width:5.50em;height:1.33em;"/></sub></span><span>, and the network output, <em>y</em></span><span>. The MLP looks as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-947 image-border" src="Images/24293b6e-1760-42d5-813a-77d6b949fb16.png" style="width:26.17em;height:18.58em;"/></p>
<p>As you can see, this network has four inputs—the first hidden layer has five nodes, the second hidden layer has three nodes, the third hidden layer has five nodes, and there is one node for the output. Mathematically, we can write this as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/1d1d4d07-243c-42ee-bd77-db5cb042f6d7.png" style="width:14.67em;height:14.75em;"/></p>
<p>Here, <sub><img class="fm-editor-equation" src="Images/a99c32c3-e4c0-4b0d-a607-67feeb0586c6.png" style="width:1.58em;height:1.83em;"/></sub> is the <em>i<sup>th</sup></em> node in the <em>l<sup>th</sup></em> layer, <sub><img class="fm-editor-equation" src="Images/49bdaee9-222a-428a-8b5d-a06e1c30b442.png" style="width:1.42em;height:1.50em;"/></sub> is an activation function for the<span> <em>l</em></span><span><em><sup>th</sup></em> layer</span>, <em>x<sub>j</sub></em> is the <em>j<sup>th</sup></em> input to the network, <sub><img class="fm-editor-equation" src="Images/2090f186-37fd-445d-b5a1-10d0b59368da.png" style="width:1.50em;height:2.00em;"/></sub> is the bias for <span>the <em>i</em></span><span><em><sup>th</sup></em> node in the <em>l</em></span><span><em><sup>th</sup></em> layer, and <sub><img class="fm-editor-equation" src="Images/35365769-aa9c-4837-9481-8096a06f8480.png" style="width:2.08em;height:2.25em;"/></sub> is the directed weight that connects the <em>j<sup>th</sup></em> node in the <em>l–1<sup>st</sup></em> layer to the <em>i<sup>th</sup></em> node in the <em>l<sup>th</sup></em> layer. </span></p>
<p>Before we move forward, let's take a look at the preceding equations. From them, we can easily observe that each hidden node depends on the weights from the previous layer. If you take a pencil and draw out the network (or use your fingers to trace the connections), you will notice that the deeper we get into the network, the more complex the relationship nodes in the later hidden layers have with those in the earlier layers. </p>
<p>Now that you have an idea of how each neuron is computed in an MLP, you might have realized that explicitly writing out the computation on each node in each layer can be a daunting task. So, let's rewrite the preceding equation in a cleaner and simpler manner. We generally do not express neural networks in terms of the computation that happens on each node. We instead express them in terms of layers and because each layer has multiple nodes, we can write the previous equations in terms of vectors and matrices. The previous equations can now be written as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/8261ea86-c6a6-4edc-b0be-de27390d03cd.png" style="width:14.67em;height:10.00em;"/></p>
<p>This is a whole lot simpler to follow.</p>
<div class="mce-root packt_infobox">Remember from <a href="6a34798f-db83-4a32-9222-06ba717fc809.xhtml">Chapter 2</a>, <em>Linear Algebra</em>, that when you multiply a vector or matrix with a scalar value, the scalar value is applied to all the entries. </div>
<p>For the networks we want to build, the input more than likely will not be a vector, as it is in the preceding examples; it will be a matrix, so we can then rewrite it as follows:</p>
<p style="padding-left: 180px"><img class="aligncenter size-full wp-image-1291 image-border" src="Images/2b2e05de-f12e-409f-bb52-d383fbb0be89.png" style="width:18.83em;height:10.83em;"/></p>
<p>Here, <span class="packt_screen">X</span> is the matrix containing all the data we want to train our model on, <span class="packt_screen">H</span><sup>[l]</sup> contains the hidden nodes at each layer for all the data samples, and everything else is the same as it was earlier. </p>
<p>If you have been paying attention, you will have noticed that the order of the multiplication taking place in the matrix is different than what took place earlier. Why do you think that is? (I'll give you a hint—transpose.)</p>
<p>You should now have a decent, high-level understanding of how neural networks are constructed. Let's now lift up the hood and take a look at what is going on underneath. We know from the previous equations that neural networks are comprised of a series of matrix multiplications and matrix additions and scalar multiplications. Since we are now dealing with vectors and matrices, their dimensions are important because if they don't line up properly, we can't multiply and add them. </p>
<p>Let's view the preceding MLP in its full matrix form. (To keep things simple, we will go through it layer by layer and we will use the second form since our input is in vector form.) To simplify the view and to properly understand what is happening, we will now denote <img class="fm-editor-equation" src="Images/ca351150-a3f6-4865-963e-7ee02f9b96da.png" style="width:9.67em;height:1.42em;"/> and <sub><img class="fm-editor-equation" src="Images/62411681-fe78-4517-bee2-413408f0ed74.png" style="width:7.92em;height:2.25em;"/></sub>.</p>
<p>Calculate <em>z<sup>[1]</sup></em> as follows:</p>
<p style="padding-left: 120px"><img class="aligncenter size-full wp-image-1218 image-border" src="Images/bedf5dd0-6d85-47b3-a534-7b9d61fc79c6.png" style="width:30.67em;height:14.75em;"/></p>
<p class="CDPAlignLeft CDPAlign">Calculate <em>h<sup>[1]</sup></em>  as follows:</p>
<p style="padding-left: 120px"><img class="aligncenter size-full wp-image-1290 image-border" src="Images/c63f4068-7687-4f18-bf31-7f525f49e4b0.png" style="width:20.83em;height:13.83em;"/></p>
<p class="CDPAlignLeft CDPAlign">Calculate<span> <em>z<sup>[2]</sup></em></span> as follows:</p>
<p style="padding-left: 120px"><img class="aligncenter size-full wp-image-1289 image-border" src="Images/2ede43e9-b1e2-4853-acab-4852ba7b9340.png" style="width:33.92em;height:13.42em;"/></p>
<p class="CDPAlignLeft CDPAlign">Calculate<span> <em>h<sup>[2]</sup></em></span> as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/c65fd29b-e5c2-4f09-a629-55a199e1c46d.png" style="width:10.92em;height:8.25em;"/></p>
<p class="CDPAlignLeft CDPAlign">Calculate<span> <em>z<sup>[3]</sup></em></span> as follows:</p>
<p style="padding-left: 120px"><img class="aligncenter size-full wp-image-1288 image-border" src="Images/4eef0a30-7d90-4f5f-bcfa-dfa210079eed.png" style="width:29.50em;height:15.83em;"/></p>
<p class="CDPAlignLeft CDPAlign">Calculate<span> <em>h<sup>[3]</sup></em></span> as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/4511cb88-0b8a-410e-ba8a-43da43868ac0.png" style="width:10.92em;height:12.67em;"/></p>
<p class="CDPAlignLeft CDPAlign">Calculate<span> <em>z<sup>[4]</sup></em></span> as follows:</p>
<p style="padding-left: 90px"><img class="aligncenter size-full wp-image-1287 image-border" src="Images/e798ced7-1c46-48d6-9c68-aadfa57c6889.png" style="width:38.58em;height:16.58em;"/></p>
<p class="CDPAlignLeft CDPAlign">Calculate<span> <em><strong>y</strong></em></span> as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/424fa6be-32b2-4d38-999f-e13ffa5c8bc0.png" style="width:10.92em;height:5.58em;"/></p>
<p>There we have it. Those are all the operations that take place in our MLP. </p>
<div class="packt_infobox packt_tip">I have slightly tweaked the preceding notation by putting <sub><img class="fm-editor-equation" src="Images/6269823e-af7e-4a18-b7ac-49cd77c585ed.png" style="width:2.00em;height:2.33em;"/></sub> in brackets and writing <em>y</em> as a vector, even though it is clearly a scalar. This was only done to keep the flow and to avoid changing the notation. <em>y</em> is a vector if we use the <em>k</em>-class classification (giving us multiple output neurons). </div>
<p>Now, if you think back to <a href="6a34798f-db83-4a32-9222-06ba717fc809.xhtml">Chapter 2</a>, <em>Linear Algebra</em>, where we did matrix multiplication, we learned that when a matrix or vector is multiplied by another matrix with differing dimensions, then the resulting matrix or vector is of a different shape (except, of course, when we multiply by the identity matrix). We call this mapping because our matrix maps points in one space to points in another space. Keeping this in mind, let's take a look again at the operations that were carried out in our MLP. From this, we can deduce that our neural network maps our input vector from one Euclidean space to our output vector in another Euclidean space. </p>
<p>Using this observation, we can generalize and write the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/32adc558-0a11-49ed-9097-85e4291b0b22.png" style="width:8.67em;height:1.33em;"/></p>
<p>Here, <sub><img class="fm-editor-equation" src="Images/0b1e6f17-8765-410b-8f0e-8764a5481669.png" style="width:1.17em;height:1.17em;"/></sub> is our MLP, <sub><img class="fm-editor-equation" src="Images/d4d6931d-2030-4b68-8c7f-82d126da64e7.png" style="width:1.67em;height:1.00em;"/></sub> is the number of nodes in the dimension of the input layer, <sub><img class="fm-editor-equation" src="Images/5c4afa24-34e8-41be-9565-176e8bf53239.png" style="width:1.83em;height:1.00em;"/></sub> is the number of nodes in the output layer, and <em>L</em> is the total number of layers.</p>
<p>However, there are a number of matrix multiplications that take place in the preceding network and each has different dimensions, which tells us that a sequence of mappings takes place (from one layer to the next). </p>
<p>We can then write the mappings individually, as follows:</p>
<p style="padding-left: 90px"><img class="aligncenter size-full wp-image-1348 image-border" src="Images/461302a4-1d57-4d82-a5a0-cf6d12ea57a9.png" style="width:36.83em;height:1.67em;"/></p>
<p>Here, each <em>f<sup>i</sup></em> value maps the <em>l<sup>th</sup></em> layer to the <em>l+1<sup>st</sup></em> layer. To make sure we have covered all of our bases,<span> </span><img class="fm-editor-equation" src="Images/c90c9a0b-7e57-426e-ba83-d952c0292587.png" style="width:8.50em;height:1.50em;"/> and<span> </span><img class="fm-editor-equation" src="Images/58a84bec-44f5-4c0a-ac8c-8b2c9b24651d.png" style="width:5.08em;height:1.42em;"/>. </p>
<p>Now, we can summarize our MLP in the following equation:</p>
<p style="padding-left: 60px"><img class="aligncenter size-full wp-image-1286 image-border" src="Images/79a27b1a-f32a-41e2-85a8-e1b0f1480971.png" style="width:44.83em;height:10.08em;"/></p>
<p>With that done, we can now move on to the next subsection where we will understand activation functions.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Activation functions</h1>
                </header>
            
            <article>
                
<p>We have mentioned activation functions a few times so far and we introduced one of them as well—the sigmoid activation function. However, this isn't the only activation function that we use in neural networks. In fact, it is an active area of research, and today, there are many different types of activation functions. They can be classified into two types—linear and non-linear. We will focus on the latter because they are differentiable and this property is very important for us when we train neural networks.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Sigmoid</h1>
                </header>
            
            <article>
                
<p>To start, we will take a look at sigmoid since we've already encountered it. The sigmoid function is written as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/65343faf-854d-42ef-b64e-62a778b610be.png" style="width:8.33em;height:3.00em;"/></p>
<p>The function looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-983 image-border" src="Images/d904765c-afb9-4ec4-a8bc-71d32c02a4ee.png" style="width:36.33em;height:28.92em;"/></p>
<p>The sigmoid activation function takes the sum of the weighted inputs and bias as input and compresses the value into the<span> <kbd>(0, 1)</kbd> range.</span></p>
<p>Its derivative is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/b02c4eb1-3e11-4dd7-b385-45cbe316d190.png" style="width:19.42em;height:2.92em;"/></p>
<p>The derivative will look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-984 image-border" src="Images/fbc8a1ff-d0f2-423a-affc-e76fcd497b49.png" style="width:37.17em;height:15.50em;"/></p>
<p>This activation function is usually used in the output layer for predicting a probability-based output. We avoid using it in the hidden layers of deep neural networks because it leads to what is known as the vanishing gradient problem. When the value of <em>x</em> is either greater than <kbd>2</kbd> or less than <kbd>-2</kbd>, then the output of the sigmoid function is very close to <kbd>1</kbd> or <kbd>0</kbd>, respectively. This hinders the network's ability to learn or slows it down drastically. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Hyperbolic tangent</h1>
                </header>
            
            <article>
                
<p>Another activation function used instead of the sigmoid is the hyperbolic tangent (<em>tanh</em>). It is written as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/29a6dbcc-29d9-48dd-8ce1-5dd8eee8612c.png" style="width:9.25em;height:3.00em;"/></p>
<p>The function looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-985 image-border" src="Images/c34fe00f-f828-46e6-acd4-0bba19b8686a.png" style="width:33.33em;height:20.50em;"/></p>
<p>The <kbd>tanh</kbd> function squashes all the output values into the<span> <kbd>(-1, 1)</kbd> range. Its derivative is as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/a78c193d-d87d-4b24-8dbd-245871bc6541.png" style="width:9.50em;height:2.83em;"/></p>
<p>The derivative looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-986 image-border" src="Images/611ab700-5c35-47a8-ae99-da0ee9ce946e.png" style="width:33.75em;height:15.92em;"/></p>
<p>From the preceding graph you can tell that the <kbd>tanh</kbd> function is zero-centered, which allows us to model values that are very positive, very negative, or neutral. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Softmax</h1>
                </header>
            
            <article>
                
<p>The softmax activation function normalizes a vector containing <em>K</em> elements into a probability distribution over the <em>K</em> elements. For this reason, it is generally used in the output layer to predict the probability of it being one of the classes.</p>
<p>The softmax function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/078e746d-755c-49e1-ad8e-eb385d1bd08a.png" style="width:8.17em;height:3.00em;"/></p>
<p>Its derivative can be found using the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/4bea56c6-9781-4b10-8394-5e5853583f38.png" style="width:16.08em;height:3.25em;"/></p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Rectified linear unit</h1>
                </header>
            
            <article>
                
<p><strong>Rectified linear unit</strong> (<strong>ReLU</strong>) is one of the most widely used activation functions because it is more computationally efficient than the activation functions we have already seen; therefore, it allows the network to train a lot faster and so converge more quickly.  </p>
<p>The ReLU function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/c8f560b9-eeda-4c48-9b5a-02ced40f9feb.png" style="width:14.92em;height:2.75em;"/></p>
<p>The function looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-987 image-border" src="Images/abefcb80-ff62-440c-a9b2-b194a6a3b7e0.png" style="width:26.08em;height:14.08em;"/></p>
<p>As you can see, all the negative values for <em>x</em> are clipped off and turn into <kbd>0</kbd>. It may surprise you to know that even though this looks like a linear function, it has a derivative that is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/50b76861-ee1f-4b43-93ea-a958ad18ec33.png" style="width:10.00em;height:2.75em;"/></p>
<p>The derivative looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-988 image-border" src="Images/b4686eec-9555-4d48-b6d4-515c8688ba4a.png" style="width:31.83em;height:15.42em;"/></p>
<p>This, too, faces some problems in training—particularly, the dying ReLU problem. This occurs when the input values are negative and this hinders learning because we cannot differentiate <kbd>0</kbd>. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Leaky ReLU</h1>
                </header>
            
            <article>
                
<p>Leaky ReLU is a modification of the ReLU function that we saw in the previous section and it not only enables the network to learn faster but it is also more balanced as it helps deal with vanishing gradients. </p>
<p>The leaky ReLU function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/1a63e576-a013-457c-b768-b511947fca9c.png" style="width:21.58em;height:3.17em;"/></p>
<p>The function looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-989 image-border" src="Images/4d8475c2-09b7-4ab2-9f40-07f8719824a4.png" style="width:31.75em;height:15.92em;"/></p>
<p>As you can see, the difference here is that the negative values of <em>x</em> that were clipped off before are now rescaled to <img class="fm-editor-equation" src="Images/fe6ed447-d293-4927-8093-23183b8cb1af.png" style="width:3.33em;height:1.25em;"/>, which overcomes the dying ReLU problem. The derivative of this activation function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/e7b04e0f-b2e7-4f90-8da3-de579d948f75.png" style="width:11.42em;height:2.75em;"/></p>
<p>The derivative looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-990 image-border" src="Images/c33ce17c-74ce-4b21-98aa-3f6a08ca261d.png" style="width:29.75em;height:14.83em;"/></p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Parametric ReLU</h1>
                </header>
            
            <article>
                
<p><strong>Parametric ReLU</strong> (<strong>PReLU</strong>) is a variation of the leaky ReLU activation function and has similar performance improvements to it, except that here, the parameters are learnable whereas before they were not.</p>
<p>The PReLU function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/d29916bd-ccbb-42a3-b1f8-bf7ab4f3ed13.png" style="width:11.33em;height:3.17em;"/></p>
<p>The function looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-991 image-border" src="Images/a26d887b-874d-4131-972b-c714c0c2625b.png" style="width:32.75em;height:16.58em;"/></p>
<p>The derivative is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/ea942e7c-4a0a-4453-8bbe-66e5b96e55de.png" style="width:11.92em;height:3.08em;"/></p>
<p>The derivative looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-992 image-border" src="Images/6903a6f6-6f11-4383-a04c-2a3b1234fdd9.png" style="width:32.08em;height:16.08em;"/></p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Exponential linear unit</h1>
                </header>
            
            <article>
                
<p><strong>Exponential linear unit</strong> (<strong>ELU</strong>) is another variation of the leaky ReLU activation function, where instead of having a straight line for all cases of <img class="fm-editor-equation" src="Images/e0e33eee-fef0-45c8-9c61-885d9b83f959.png" style="width:3.42em;height:1.25em;"/>, it is a log curve.</p>
<p>The ELU activation function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/12b5ff24-5b55-422f-a554-2fccbc506809.png" style="width:11.67em;height:2.50em;"/></p>
<p>The function looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-993 image-border" src="Images/13d45385-b514-4f7b-a22e-2925ce8343c2.png" style="width:29.67em;height:18.42em;"/></p>
<p>The derivative of this activation function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/c5bb5a77-8275-4ed0-9868-6bfdf38b94a5.png" style="width:14.75em;height:2.92em;"/></p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The loss function</h1>
                </header>
            
            <article>
                
<p>The loss function is a very critical part of neural networks and their training. They give us a means of calculating the error of a network after a forward pass has been computed. This error compares the neural network output with the target output that was specified in the training data. </p>
<p>There are two errors in particular that are of concern to us—the local error and the global error. The local error is the difference between the output expected of a neuron and its actual output. The global error, however, is the total error (the sum of all the local errors) and it tells us how well our network is performing on the training data.</p>
<p>There are a number of methods that we use in practice and each has its own use cases, advantages, and disadvantages. Conventionally, the loss function is referred to as the cost function and is denoted as <em>J(θ)</em> (or, equivalently, <em>J(W,b)</em>).</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Mean absolute error</h1>
                </header>
            
            <article>
                
<p><strong>Mean absolute error</strong> (<strong>MAE</strong>) is the same as the L1 loss we saw in <a href="719fc119-9e7a-4fce-be04-eb1e49bed753.xhtml">Chapter 3</a>, <em>Probability and Statistics</em>, and it looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/d0621604-a42a-4f1a-a340-cfee0baf3b8a.png" style="width:12.67em;height:3.17em;"/></p>
<p>Here, <em>N</em><span> is the number of samples in our training dataset. </span></p>
<p>What we are doing here is calculating the absolute distance between the prediction and the true value and averaging over the sum of the errors. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Mean squared error</h1>
                </header>
            
            <article>
                
<p><strong>Mean squared error</strong> (<strong>MSE</strong>) is one of the most commonly used loss functions, especially for regression tasks (it takes in a vector and outputs a scalar). It calculates the square of the difference between the output and the expected output. It looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/975006bd-f561-4375-8b79-780d31b47f91.png" style="width:14.58em;height:3.58em;"/></p>
<p>Here, <em>N</em> is the number of samples in our training dataset. </p>
<p>In the preceding equation, we calculate the square of the L2 norm.<span> </span><span>Intuitively, we should be able to tell that when <sub><img class="fm-editor-equation" src="Images/6ede8b8e-9f4b-4a57-9be8-409aa2efd1aa.png" style="width:3.25em;height:1.42em;"/></sub></span><span> , the error is</span> 0, and the larger the distance between the points, the larger the error.<span> </span>The reason we use this is that it always outputs a positive value and by squaring the distance between the output and expected output, it allows us to differentiate between small and large errors with greater ease and correct them. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Root mean squared error</h1>
                </header>
            
            <article>
                
<p><strong>Root mean squared error</strong> (<strong>RMSE</strong>) is simply the square root of the preceding MSE function and it looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/852bea1b-21f1-4452-913a-00c654336837.png" style="width:14.17em;height:3.67em;"/></p>
<p>The reason we use this is that it scales back the MSE function to the scale it was originally at before we squared the errors, which gives us a better idea of the error with respect to the target(s).</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The Huber loss</h1>
                </header>
            
            <article>
                
<p>The Huber loss looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/f4bdc492-ee0d-4da4-9caa-b13cf5c69164.png" style="width:21.92em;height:3.67em;"/></p>
<p>Here, ε is a constant term that we can configure. The smaller it is, the more insensitive the loss is to large errors and outliers, and the larger it is, the more sensitive the loss is to large errors and outliers. </p>
<p>Now, if you look closely, you should notice that when ε is very small, the Huber loss is similar to MAE, but when it is very large, it is similar to MSE.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cross entropy</h1>
                </header>
            
            <article>
                
<p>Cross entropy loss is used mostly when we have a binary classification problem; that is, where the network outputs either 1 or 0.</p>
<p>Suppose we are given a training dataset, <sub><img class="fm-editor-equation" src="Images/89873e28-1e09-4bbf-a107-d969446d59c2.png" style="width:16.08em;height:1.58em;"/></sub> and <sub><img class="fm-editor-equation" src="Images/d21a5ae5-3daf-47d5-bf91-2871160d90d7.png" style="width:5.42em;height:1.42em;"/></sub>. We can then write this in the following form:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/e66a7df7-8d7a-44d0-ade2-1bb56a78564f.png" style="width:6.83em;height:1.50em;"/></p>
<p>Here, <em>θ</em> is the parameters of the network (weights and biases). We can express this in terms of a Bernoulli distribution, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/29d4cb2b-be80-4664-965b-7dfa4bf1a434.png" style="width:18.67em;height:1.83em;"/></p>
<p>The probability, given the entire dataset, is then as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/f3f8a931-1ad0-4460-a978-83b0a96478f8.png" style="width:34.75em;height:3.75em;"/></p>
<p>If we take its negative-log likelihood, we get the following:</p>
<p>                       <img src="Images/42581895-dccc-430f-98fa-f1bd6b524fa9.png" style="width:33.92em;height:4.25em;"/></p>
<p>So, we have the following:</p>
<p>                              <img src="Images/be5d8e99-7a02-44cd-9d97-b26ddd07e808.png" style="width:27.83em;height:4.42em;"/></p>
<p>Cross entropy is also used when we have more than two classes. This is known as <strong>multiclass cross entropy</strong>. Suppose we have <em>K</em> output units, then, we would calculate the loss for each class and then sum them together, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/5bbf3b40-e925-4231-91b6-09f8522ec81e.png" style="width:8.83em;height:3.92em;"/></p>
<p>Here, <sub><img class="fm-editor-equation" src="Images/1ec5fd38-ea69-4982-bc7d-e79cd01d8667.png" style="width:2.25em;height:1.83em;"/></sub> is the probability that observation (<em>i</em>) belongs to class <em>k</em>.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Kullback-Leibler divergence</h1>
                </header>
            
            <article>
                
<p><strong>Kullback-Leibler</strong><span> </span><span>(</span><span>KL</span><span>)</span><strong> divergence</strong><span> measures the divergence of two probability distributions,</span> <em>p</em><span> and</span> <em>q</em><span>. It looks as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/73a11d7b-8708-41af-bbab-82d8c5fc26ad.png" style="width:16.33em;height:3.08em;"/> </p>
<p>So, when <em>p(x)=q(x)</em>, the KL divergence value is 0 at all points. This is usually used in generative models.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Jensen-Shannon divergence</h1>
                </header>
            
            <article>
                
<p>Like the KL divergence, the <strong>Jensen-Shannon</strong> (<strong>JS</strong>) divergence measures how similar two probability distributions are; however, it is smoother. The following equation represents the JS divergence:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/ec2e7ec1-cfcf-4c33-8cd5-307053b2dfe2.png" style="width:22.83em;height:2.58em;"/></p>
<p>This behaves a lot better than KL divergence when <em>p(x)</em> and <em>q(x)</em> are both small.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Backpropagation</h1>
                </header>
            
            <article>
                
<p>Now that we know how the forward passes are computed in MLPs, as well as how to best initialize them and calculate the loss of the network, it is time for us to learn about backpropagation—a method that allows us to calculate the gradient of the network using the information from the loss function. This is where our knowledge of multivariable calculus and partial derivatives comes in handy. </p>
<p><span>If you recall, this network is fully connected, which means all the nodes in each layer are connected to—and so have an impact on—the next layer. It is for this reason that in backpropagation we take the derivative of the loss with respect to the weights of the layer closest to the output, then the one before that, and so on, until we reach the first layer. If you don't yet understand this, don't worry. </span>We will go through backpropagation in detail and use the network from earlier as an example. We will assume that the activation function is sigmoid and our loss function is cross entropy. We will first calculate the derivative of the loss (<sub><img class="fm-editor-equation" src="Images/b3c63103-f3cb-42be-84d8-237d3b9f1ba4.png" style="width:0.83em;height:0.92em;"/></sub>) with respect to <em>W<sup>[4]</sup></em>, which looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/5971378d-f9e5-44ed-bfff-00e5806d6bb6.png" style="width:19.50em;height:2.33em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/74578a41-447c-4c30-9ac3-17dc423088e6.png" style="width:38.50em;height:2.42em;"/></p>
<p><img class="aligncenter size-full wp-image-1285 image-border" src="Images/fbf77b44-2541-4e37-b7d7-78b0629a59f6.png" style="width:50.33em;height:2.58em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/84e2b8f4-2a9f-485c-a166-30ee953c792f.png" style="width:31.17em;height:2.50em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/2f2a92d2-a163-42b7-ba81-52ac4ac6ce80.png" style="width:15.42em;height:2.25em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/732afee6-3253-4cca-ba9c-14258bb9b268.png" style="width:4.58em;height:1.42em;"/></p>
<p>With that, we have finished computing the first derivative. As you can see, it takes quite a bit of work, and calculating the derivative for each layer can be a very time-consuming process. So, instead, we can make use of the chain rule from calculus.</p>
<p>For simplicity, let's say <sub><img class="fm-editor-equation" src="Images/a8629f59-6322-4371-9765-a8886500192e.png" style="width:9.33em;height:1.25em;"/></sub> and <sub><img class="fm-editor-equation" src="Images/ca778ea0-b62b-4a10-b82b-b7983efea97d.png" style="width:6.67em;height:1.58em;"/></sub> and assume that <sub><img class="fm-editor-equation" src="Images/d67fa046-f726-435b-a2a2-1457433eadef.png" style="width:3.08em;height:1.17em;"/></sub>. Now, if we want to calculate the gradient of the loss with respect to <em>W<sup>[2]</sup></em>, we get the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/593b0c14-ca82-419c-90e9-b4523b2154f6.png" style="width:23.67em;height:3.08em;"/></p>
<p>We can rewrite this as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/444ad371-8e2f-4897-90df-4ec18c0f615e.png" style="width:23.00em;height:2.75em;"/></p>
<p>Suppose we do want to find the partial of the loss with respect to <em>b<sup>[4]</sup></em>; this looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/0f02076f-6afa-4cc7-b5d4-b80104251477.png" style="width:11.50em;height:3.17em;"/></p>
<p>Before we move on to the next section, pay close attention to the preceding derivative, <sub><img class="fm-editor-equation" src="Images/0b1d4d1d-0fa9-4744-b002-edcc2ea7c9a3.png" style="width:2.17em;height:1.83em;"/></sub>. If you look back to earlier on in the <em>Layers</em> section, <sub><img class="fm-editor-equation" src="Images/e03583c2-1673-49bb-acc8-47b9f00164e9.png" style="width:7.42em;height:1.42em;"/></sub> were all vectors and matrices. This is still true. Because we are again dealing with vectors and matrices, it is important that their dimensions line up.</p>
<p>We know that <img class="fm-editor-equation" src="Images/54559173-808e-482d-bfb0-53c473fad4bc.png" style="width:7.33em;height:2.83em;"/>, but what about the others? I will leave this to you as an exercise to determine whether or not the other is correct and if it is not, how would you change the order to ensure it is?</p>
<p>If you're feeling very confident in your math abilities and are up for a challenge, I encourage you to try finding the derivative, <sub><img class="fm-editor-equation" src="Images/06d785f2-0ebb-4e1a-9f28-25e3989dd48b.png" style="width:2.83em;height:3.25em;"/></sub>.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Training neural networks</h1>
                </header>
            
            <article>
                
<p>Now that we have an understanding of backpropagation and how gradients are computed, you might be wondering what purpose it serves and what it has to do with training our MLP. If you will recall from <a href="3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml">Chapter 1</a>, <em>Vector Calculus</em>, when we covered partial derivatives, we learned that we can use partial derivatives to check the impact that changing one parameter can have on the output of a function. When we use the first and second derivatives to plot our graphs, we can analytically tell what the local and global minima and maxima are. However, it isn't as straightforward as that in our case as our model doesn't know where the optima is or how to get there; so, instead, we use backpropagation with the gradient descent as a guide to help us get to the (hopefully global) minima.</p>
<p>In <a href="feeeb2a4-650e-445a-8f97-8c0ebb2538eb.xhtml">Chapter 4</a>, <em>Optimization</em>, we learned about gradient descent and how we iteratively move from one point on the function to a lower point on the function that is in the direction of the local/global minima by taking a step in the direction of the negative of the gradient. We expressed it in the following form:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/2d7750e6-5c01-45c1-8a47-3f2aeb580569.png" style="width:11.00em;height:1.42em;"/></p>
<p>However, for neural networks, the update rule for the weights, in this case, is written as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/4d12e7fe-323f-4fd8-adcc-a9f01f783955.png" style="width:8.92em;height:2.75em;"/></p>
<p>Here, <em>θ</em> = <em>(W,b)</em>.</p>
<p>As you can see, while this does look similar, it isn't the optimization we have learned. Our goal here is to minimize the total loss of the network and update our weights accordingly. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Parameter initialization</h1>
                </header>
            
            <article>
                
<p>In <a href="feeeb2a4-650e-445a-8f97-8c0ebb2538eb.xhtml">Chapter 4</a>, <em>Optimization</em>, we mentioned that before we start optimizing, we need an initial (starting) point, which is the purpose of initialization. This is an extremely important part of training neural networks because as mentioned earlier on in this chapter, neural networks have a lot of parameters—often, well over tens of millions—which means that finding the point in the weight space that minimizes our loss can be very time consuming and challenging (because the weight space is non-convex; that is, there are lots of local minima and saddle points).</p>
<p>For this reason, finding a good initial point is important because it makes it easier to get to the optima and reduce the training time, as well as reducing the chances of our weights either vanishing or exploding. Let's now explore the various ways that we can initialize our weights and biases.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">All zeros</h1>
                </header>
            
            <article>
                
<p>As the name suggests, here we set the initial weights and biases of our model to be zeros. I don't recommend doing this because, as you may have guessed, this means that all the neurons in our model are dead. In fact, this is the very problem we want to avoid when training our network. </p>
<p>Let's see what happens anyway. For the sake of simplicity, let's suppose we have the following linear classifier:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/64678005-0a60-463a-b72c-2e0bbf92bff7.png" style="width:14.67em;height:3.50em;"/></p>
<p>If the weights are initialized as 0, then our output is always 0, which means we lost all the information that was part of our training data and the network that we put so much effort into building learns nothing.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Random initialization</h1>
                </header>
            
            <article>
                
<p>One way of initializing our weights to be non-zero is to use random initialization and for this, we could use one of two distributions—the normal distribution or the uniform distribution. </p>
<p>To initialize our parameters using the normal distribution, we have to specify the mean and the standard deviation. Usually, we choose a mean of 0 and a standard deviation of 1. To initialize using the uniform distribution, we usually use the<span> </span><span>[-1, 1]</span><span> range (where there is an equal probability of any value in the range being picked). </span></p>
<p>While this gives us weights that we can use in training, it is very slow and has previously resulted in vanishing and exploding gradients in deep networks, resulting in mediocre performance.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Xavier initialization</h1>
                </header>
            
            <article>
                
<p>As we have seen, if our weights are too small, then they vanish, which results in dead neurons and, conversely, if our weights are too big, we get exploding gradients. We want to avoid both scenarios, which means we need the weights to be initialized just right so that our network can learn what it needs to.</p>
<p>To tackle this problem, Xavier Glorot and Yoshua Bengio created a normalized initialization method (generally referred to as Xavier initialization). It is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/457d8e0b-c3d7-4d87-b136-0e25d3a09732.png" style="width:16.17em;height:2.83em;"/></p>
<p>Here, <em>n<sub>k</sub></em> is the number of neurons in layer <em>k</em>. </p>
<p>But why does this work better than randomly initializing our network? The idea is that we want to maintain the variance as we propagate through subsequent layers. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The data</h1>
                </header>
            
            <article>
                
<p>As you will know by now, what we are trying to build here are networks that can learn to map an input to an output. For our network to be able to do this, it needs to be fed data—and lots of it. Therefore, it is important for us to know what the data should look like. </p>
<p>Let's suppose we have a classification or regression task. Our data will then take the following form:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/d26f3546-527b-4ce8-889d-7fbe1ac0af4a.png" style="width:16.08em;height:1.58em;"/></p>
<p>Here, we assume the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/1be36326-723b-4d59-b4bc-b2160f8f5a5b.png" style="width:7.58em;height:1.42em;"/></p>
<p>As you can see, each sample in the dataset has the input (<em>x<sub>i</sub></em>) and a corresponding output/target (<em>y<sub>i</sub></em>). However, depending on the task, our output will look a bit different. In regression, our output can take on any real value, whereas in classification, it must be one of the classes we can predict.</p>
<p>Our data (<em>x</em>), as you may expect, contains all the various information we want to use to predict our target variables (<em>y</em>) and this, of course, depends on the problem. As an example, let's take the Boston Housing dataset, which is a regression task. It contains the following features:</p>
<ul>
<li>The per-capita crime rate by town</li>
<li>The proportion of residential land zoned for lots over 25,000 square feet</li>
<li>The proportion of non-retail business acres per town</li>
<li>The Charles River dummy variable (1 if tract bounds river and 0 if not)</li>
<li>The nitric oxide concentration value (parts per 10 million)</li>
<li>The average number of rooms per dwelling</li>
<li>The proportion of owner-occupied units built before 1940</li>
<li>The weighted distances to five Boston employment centers</li>
<li>The index of accessibility to radial highways</li>
<li>The full-value property tax rate per $10,000</li>
<li>The pupil-to-teacher ratio by town</li>
<li>The proportion of African Americans by town</li>
<li>The percentage of the population that is of a lower status</li>
</ul>
<p>The target variable is the median value of owner-occupied homes in $1,000.</p>
<p>All the data is numerical (since the machines don't really read or know what those labels mean, but they do know how to parse numbers). </p>
<p>Now, let's look at a classification problem—since we are trying to predict which class our data belongs to, the target will become a vector instead of a scalar (as it is in the preceding dataset), where the dimension of the target vector will be the number of categories. But how do we represent this target vector? </p>
<p>Suppose we have a dataset of images with the corresponding target labels:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/7d724ddb-33aa-4f14-9bc0-858c4cd46694.png" style="width:23.08em;height:1.42em;"/></p>
<p>As you can see, each label has a digit assigned to it and during training, our network could mistake these for trainable parameters, which we obviously would want to avoid. Instead, we can one-hot encode this, thereby turning the label vector into the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/0088e534-5123-4a3b-ad07-723176a09347.png" style="width:10.42em;height:6.08em;"/></p>
<p>Great! Now we know what is in a dataset and how datasets are structured. But what now? We split the dataset into training, testing, and validation sets. How we split the data into the three respective sets depends largely on how much data we have. In the case of deep learning, w<span>e will, more often than not, be dealing with very large datasets; that is, millions to tens of millions of samples.</span></p>
<p>As a rule of thumb, we generally select 80-90% of the dataset to train our network, and the remaining 10-20% is split into two portions—the validation and test sets. The validation set is used during training to determine whether our network has overfit or underfit to the data and the test set is used at the end to check how well our model generalizes to unseen data.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deep neural networks</h1>
                </header>
            
            <article>
                
<p>Now, it's time to get into the really fun stuff (and what you picked up this book for)—deep neural networks. The depth comes from the number of layers in the neural network and for an FNN to be considered deep, it must have more than 10 hidden layers. A number of today's state-of-the-art FNNs have well over 40 layers. Let's now explore some of the properties of deep FNNs and get an understanding of why they are so powerful.</p>
<p><span>If you recall, earlier on we came across the universal approximation theorem, which stated that an MLP with a single hidden layer could approximate any function. But if that is the case, why do we need deep neural networks? Simply put, the capacity of a neural network increases with each hidden layer (and the brain has a deep structure). What this means is that deeper networks have far greater expressiveness than shallower networks. This is something we came across earlier when learning about MLPs. We saw that by adding hidden layers, we were able to create a network that was able to learn to solve a problem that a linear neural network was not able to. </span></p>
<p>Additionally, deeper networks are preferred over wider networks, not because they improve the overall performance, but because networks with more hidden layers (but less width) have much fewer parameters than wider networks with fewer hidden layers.</p>
<p>Let's suppose we have two networks—one that is wide and one that is deep. Both networks have 20 inputs and 6 output nodes. Let's calculate the total number of parameters for both layers; that is, the number of connections between all the layers and biases.</p>
<p>Our wide neural network has two hidden layers, each with 1,024 neurons. The total number of parameters is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/dee8c6bc-e85c-4a0b-a207-5b43642263dc.png" style="width:36.33em;height:1.33em;"/></p>
<p>Our deep neural network has 12 hidden layers, each with 150 neurons. The total number of parameters is as follows:</p>
<p style="padding-left: 90px"><img class="aligncenter size-full wp-image-1221 image-border" src="Images/fcca0a2a-0630-4eda-9e99-502be89e3da5.png" style="width:33.67em;height:1.33em;"/></p>
<p>As you can see, the deeper network has less than half the parameters that the wider network does. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we first <span>learned</span><span> </span><span>about a simple FNN, known as the MLP, and broke it down into its individual components to get a deeper understanding of how they work and are constructed. We then extended these concepts to further our understanding of deep neural networks. You should now have intimate knowledge of how FNNs work and understand how various models are constructed, as well as understand how to build and possibly improve them for yourself. </span></p>
<p>Let's now move on to the next chapter, where we will learn how to improve our neural networks so that they generalize better on unseen data.</p>


            </article>

            
        </section>
    </div></body></html>