- en: Transfer and Meta Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have studied a variety of neural networks and, as we
    have seen, each of them has its own strengths and weaknesses with regard to a
    variety of tasks. We have also learned that deep learning architectures require
    a large amount of training data because of their size and their large number of
    trainable parameters. As you can imagine, for a lot of the problems that we want
    to build models for, it may not be possible to collect enough data, and even if
    we are able to do so, this would be very difficult and time-consuming—perhaps
    even costly—to carry out. One way to combat this is to use generative models to
    create synthetic data (something we encountered in [Chapter 8](326a1ff5-cbf9-4318-9d85-8896cd47d0cd.xhtml),
    *Regularization*) that is generated from a small dataset that we collect for our
    task.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will cover two topics that have recently grown in popularity
    and are likely to continue to be more widely used in the field (and rightfully
    so). They are known as **transfer learning** and **meta learning**. The difference
    between them is that transfer learning is where we try to use what one model has
    learned to try and solve another different—but similar—problem, whereas meta learning
    is where we try to create models that can learn to learn new concepts. The literature
    on transfer learning is very sparse and it is a more hacky practice; we have mostly
    introduced it because it is important to understand the differences between transfer
    and meta learning since they are similar but quite different and are often confused.
    However, the focus of this chapter is meta learning. We will dive deeper into
    their distinctions as we progress through the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meta learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We humans have an amazing ability to learn, and then we take what we have learned
    and apply the knowledge to different types of tasks. The more closely related
    the new task is to tasks we already know, the easier it is for us to solve the
    new task. Basically, we never really have to start from scratch when learning
    something new.
  prefs: []
  type: TYPE_NORMAL
- en: However, neural networks aren't afforded this same luxury; they need to be trained
    from scratch for each individual task we want to apply them to. As we have seen
    in previous chapters, neural networks are very good at learning how to do one
    thing very well, and because they only learn what lies within an interpolation
    of the distribution they have been trained to recognize, they are unable to generalize
    their knowledge to deal with tasks beyond what they have encountered in the training
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, deep neural networks can require tens of millions of data samples
    in order to learn the latent patterns in the data before they are able to perform
    well. For this reason, researchers in the field created transfer learning—a way
    to transfer what one neural network has learned to another neural network, essentially
    bootstrapping the learning process. This is very handy when we have a project
    that we want to build or a hypothesis that we would like to test but we don't
    have the resources (such as GPUs, enough data, and so on) to build and train a
    network from scratch. Instead, we can use an existing model that works on a similar
    task and leverage it for our own task.
  prefs: []
  type: TYPE_NORMAL
- en: Let's think back to [Chapter 9](2c830a26-9964-47fb-8d69-904e4f087b95.xhtml),
    *Convolutional Neural Networks*, for a moment. The architectures we saw all had
    an input layer that took in images of a certain size (*h* × *w* × *c*), and then
    we had multiple convolutional layers followed by an optional pooling (or subsampling)
    layer. Toward the end of the network, we unrolled the feature map into a fully
    connected layer, and then the output layer had as many nodes as classes we wanted
    to detect. We also learned that **Convolutional Neural Networks** (**CNNs**) can
    extract their own features and each layer learns different kinds or levels of
    features. The layers closer to the input learn very granular features, such as
    edges, curves, color blobs, and so on, while the layers closer to the output learn
    larger features, such as eyes, ears, tails, mouths, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: What we can do is take an existing trained CNN and remove the last few layers
    (that is, the fully connected layers and the output layer) and treat this CNN
    as a feature extractor for the new dataset we are building a model for. Alternatively,
    what we could also do is use an existing trained CNN for a new problem by fine-tuning
    it on the new dataset we want to create a CNN for. We can do this by freezing
    the earlier layers (since they learn very granular or generic features) and fine-tuning
    the latter layers using backpropagation so that the CNN learns more complex features
    that are specific to the new dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get into the details of transfer learning, it is important that we
    have a clear understanding of it. We will use the definition given by Zhuang et
    al; but before that, let's revisit the definitions of a domain and a task.
  prefs: []
  type: TYPE_NORMAL
- en: A **domain**, [![](img/ecdb812d-9f63-4cc4-936a-a46ebdc8f667.png)], is composed
    of two parts; that is, a feature space, [![](img/b22a0031-59f3-49d7-aff3-f1f1ceeb885d.png)]
    , and a marginal distribution, *P(X)*. In other words, [![](img/f4c39005-71bd-4ce1-bd3c-37a3690dd64f.png)],
    where *X* denotes a data sample, which is defined as [![](img/5d9c50e3-d537-4b5a-ad6b-a6e55c947d22.png)].
  prefs: []
  type: TYPE_NORMAL
- en: A **task**, [![](img/646485a7-7078-432b-a0ad-210e59a18fe7.png)], consists of
    a label space, [![](img/6cc27b75-27bf-4f72-b71f-519a01fb5d58.png)], and a mapping
    function, *f*; that is, [![](img/49c753da-aa11-4cfb-9a48-e42c55ba50f3.png)]. The
    mapping function (our model) is an implicit one that is expected to be learned
    from the sample data.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of transfer learning, we have two distinct domains and tasks—each
    corresponding to a source and a target—where our goal is to transfer what a model
    has learned in the source domain to a model in the target domain in order to improve
    its overall performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go further into the details of this, there are four concepts that
    are important for us to understand. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The feature space of the target domain, [![](img/0a72c0f6-3a96-4143-8842-bbff752b8afd.png)],
    and the source domain, [![](img/c00984a3-9026-4749-a016-872fe956bf77.png)], are
    not the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The label space of the target domain, [![](img/d75d33b8-41c3-4f7b-a4d8-ec055aa56d6e.png)],
    and source domain, [![](img/e85c128c-f81f-4cc4-a81d-db2c97b521e5.png)], are not
    the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Domain adaptation—this is where the marginal probabilities of the target domain,
    *P(X[t])*, and the source domain, *P(X[s])*, are not equal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The conditional probabilities of the target domain, *P(Y[t]*|*X[t])*, and the
    source domain, *P(Y[s]*|*X[s])*, are not equal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can imagine, there are some limitations here as to what can be done.
    You cannot use just any pre-trained model of arbitrary size on another task. Consideration
    of the type of pre-trained network to use largely depends on whether the dataset
    we have for our task is similar to the one that the pre-trained model was trained
    on, and on the size of the dataset available to us for the current task at hand.
    For example, if we have an object detection task, we cannot use a pre-trained
    GAN or RNN for it since they are meant for different tasks. Additionally, if the
    model has been trained on images to recognize various farm animals, it will not
    perform well on a new task that wants our network to recognize the make and model
    of aircraft and cars.
  prefs: []
  type: TYPE_NORMAL
- en: Meta learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Meta learning—also known as **learning to learn**—is another fascinating topic
    within deep learning and is considered by many to be a promising path toward **Artificial
    General Intelligence** (**AGI**). For those of you who do not know what AGI is,
    it is when artificial intelligence reaches the capacity to understand and learn
    to do any type of intelligent task that a human is capable of doing, which is
    the goal of artificial intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Deep neural networks, as we know, are very data-hungry and require a lot of
    training time (depending on the size of the model), which can sometimes be several
    weeks, whereas humans are able to learn new concepts and skills a lot faster and
    more efficiently. For example, as kids, we can quickly learn to tell the difference
    between a donkey, a horse, and a zebra with absolute certainty after only seeing
    them once or a handful of times; however, a neural network would likely need a
    few hundred thousand to 1 million data samples to be able to learn to differentiate
    between the three classes to expert-level accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to meta learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The question we are trying to answer with meta learning is whether we can create
    a model that can learn as we do—that is, learn new concepts and skills to deal
    with new tasks with only a handful of training samples. So, in a nutshell, we
    want to find similarities between what we have learned and use this to learn to
    do new tasks faster. A good meta learning model is one that is trained on a number
    of tasks and has been optimized to perform well on them, as well as on tasks that
    it has not been trained on.
  prefs: []
  type: TYPE_NORMAL
- en: The deep neural networks that we have seen throughout this book so far all required
    millions of data samples, sometimes even several hundreds of millions. However,
    in meta learning, we want our model to learn using only a few samples; we refer
    to this as few-shot learning.
  prefs: []
  type: TYPE_NORMAL
- en: The problem of learning using only a few data samples is known as **few-shot
    learning** or **k-shot learning** (where *k* is the number of data samples for
    each class of the dataset). Suppose we have an image recognition problem with
    three classes—a donkey, a horse, and a zebra. If each class has 10 samples, then
    this is referred to as 10-shot learning. However, if each class has only 1 sample,
    then this is 1-shot learning. There could also be another interesting case where
    we have no data samples, which is known as **zero-shot learning**. (That's right,
    we can train a neural network without any data... just kidding! We use metadata
    instead; we'll learn about this soon.)
  prefs: []
  type: TYPE_NORMAL
- en: If we have multiple classes in our dataset and we want to carry out few-shot
    learning, this is known as **n-way k-shot learning**, where *n* is the number
    of classes. In our case, we have 3 classes and 10 samples for each, so we are
    carrying out 3-way 10-shot learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the preceding tasks will have an associated dataset, [![](img/3e14a459-4b46-4b59-866d-8e77f94da3fb.png)]
    (consisting of the data samples and the respective labels). As we know, our model,
    *f*, has trainable parameters, θ, so we can represent the model as learning the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89747e70-3e01-413a-a86f-6b50a854f36b.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, [![](img/f5251024-813f-45c1-9aa3-98df285bcdd1.png)].
  prefs: []
  type: TYPE_NORMAL
- en: For meta learning, we split our dataset into two portions—a support set, *S*,
    and a query set, *B*—such that [![](img/8da431f6-b85f-49ef-8f3c-68f33e00970b.png)].
    Then, we take a subset of the [![](img/f59a5a73-2b47-4d9b-9d2a-add6ce005c24.png)]
    labels, such that [![](img/ea8599d6-798e-4210-883c-15641271b9e4.png)]. We then
    train our model on the support set while testing on the query set, which we do
    in an episodic fashion. The support set is built through sampling from each of
    the classes of [![](img/5179ede3-ae6b-42fd-9ca4-6162de594436.png)] and the prediction
    set is built similarly using other samples from the same dataset. By using this
    method, our model gradually learns to learn from smaller datasets. We then calculate
    the loss of the model and optimize it using backpropagation using the training
    set, exactly as we did before.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective now looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/657b0bb3-059c-4fc1-8571-18726fdcc388.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, this is somewhat similar to transfer learning, except it goes
    a step further by optimizing to perform well over several tasks instead of just
    one.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three types of meta learning approaches used in practice, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Model-based
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metric-based
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization-based
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model-based meta learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In model-based meta learning, we want to create a model that is able to learn
    and update its parameters quickly using only a handful of training steps. We can
    do this internally (within the model) or externally (using another model). Let's
    now explore some of the methods.
  prefs: []
  type: TYPE_NORMAL
- en: Memory-augmented neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the name suggests, **Memory-Augmented Neural Networks** (**MANNs**) are augmented
    using external memory (a storage buffer), which makes it easier for the model
    to learn and retain new information so as to not forget it later on. One of the
    approaches that is used is training a **Neural Turing Machine** (**NTM**) to learn
    a learning algorithm by altering the training setup and memory retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: 'To adapt an NTM for meta learning, we need it to be able to encode information
    related to new tasks quickly, while also ensuring that the stored information
    can be accessed quickly. The way this works is we pass the information at the
    present time step and the corresponding label at the next time step, which forces
    the network to retain information for longer. So, at each time step, the network
    receives the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/211c364a-ba91-46e3-bfc7-12476389d646.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the following diagram, we can observe what the network looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c70726a-25f5-408f-aafc-2cacea4955a3.png)'
  prefs: []
  type: TYPE_IMG
- en: By providing the label later, the network is forced to memorize information
    so that when it is given the label, it can look back and recall the data to make
    a prediction. To ensure the model is best suited for meta learning, the reading
    and writing mechanisms have also been altered.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reading works using content similarity, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ef80545a-3c43-4f8a-8908-d46fede66f9f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, [![](img/b48b2175-5db5-4b09-ba4d-766caeb7cf3a.png)], *k[t]* is a key feature
    vector output by the controller at the *t^(th)* time step, [![](img/813aced3-fc3d-442b-a971-17473301f348.png)]
    is a read weight over *N* elements calculated through the cosine similarity between
    each of the rows in memory, *k[t]* and *r[t]* are the sum of the weighted memory
    records, and *M[t]* is the memory matrix (while *M[t](i)* is its *i^(th)* row).
  prefs: []
  type: TYPE_NORMAL
- en: Now, to write to memory, we use **Least Recently Used Access** (**LRUA**), which
    writes new information to the location where either the **Least Recently Used**
    (**LRU**) memory or **Most Frequently Used** (**MRU**) memory is stored. The reasoning
    for this is that by replacing the LRU memory, we will be able to maintain information
    that is used more frequently, and once the MRU memory is retrieved, it likely
    won't be needed for a while, so we can write over it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We compute LRUA using the following equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/aa17376c-21bd-4235-9e8b-eccdb52733a3.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/7905aa3d-1592-4b46-924a-9d88122cffc2.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/8518df2d-27ee-4355-b34c-b2fb3f41a7bb.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/4c4e5760-0ea9-46d8-b78b-89cc6bace217.png)], where [![](img/faa1a309-c2b8-457b-ae46-14d8b529ccae.png)]
    is the *n^(th)* smallest element in [![](img/73327a01-6ae7-41bb-a471-698181df4224.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the last update equations, when the LRU memory is set to 0, each of the
    rows in memory is updated using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/335ec747-d88d-443f-9596-c4e864759e77.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have seen how meta learning can work using external memory to learn
    new information by overriding the information it hasn't used in a while, we will
    move on to another model-based meta learning approach, which uses its internal
    architecture to rapidly learn new information.
  prefs: []
  type: TYPE_NORMAL
- en: Meta Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Meta Networks** (**MetaNet**) is an architecture created to generalize across
    tasks quickly; it uses fast weights to do so. The reason they are called fast
    weights is that instead of using gradient descent to update weights as we normally
    do, we use a neural network to predict the weights for another neural network.
    The weights the other neural network generates are referred to as fast weights,
    while the weights that rely on gradient descent are referred to as slow weights.
    The effect of this is that it supports meta-level continual learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, you can see the overall architecture of MetaNet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7fa791b8-5de8-42b9-a0f7-2655055f620e.png)'
  prefs: []
  type: TYPE_IMG
- en: MetaNet is comprised of two components—a meta learner, which learns an embedding
    function, *f[θ]*, to help determine the similarity between two data inputs and
    verify whether both inputs belong to the same class, and a base learner, *g[φ]*,
    which carries out the actual learning. As you can see in the preceding diagram,
    both the fast weights and the slow weights are summed together and input back
    into the model. Both the meta learner and the base learner have their own respective
    fast weights.
  prefs: []
  type: TYPE_NORMAL
- en: This requires two neural networks—*F[w]* (an LSTM whose inputs are the embedding
    loss of *f*) and *G[v]* (an ANN)—each of which outputs the fast weights for *f[θ]*
    and *g[φ]*. The fast weights corresponding to *f[θ]* and *g[θ]* are *θ^** and
    *φ^**, respectively. The difference between the two is that the input to *F[w]*
    is the gradient of the embedding loss of *f*, while *G[v]* learns using the gradients
    of the loss of *g*.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this means we have to learn four different sets of parameters
    [![](img/73ea5643-3927-46cd-8e40-e3cd9150e7be.png)]. To train our networks, we
    make use of two datasets—a training set, [![](img/65ca0144-fc10-4a84-9d09-3075799f9a69.png)],
    and a support set, [![](img/e1370139-fef0-403c-b8fa-6f85fda53800.png)].
  prefs: []
  type: TYPE_NORMAL
- en: 'The overall training of this network can be broken down into three distinct
    parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Acquiring the meta information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating the fast weights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the slow weights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We start by creating a sequence of tasks, each of which has a training set and
    a support set, and randomly sample *T* input pairs, [![](img/b644ea5c-647b-4f8b-b430-88e2669a1375.png)]
    and [![](img/dc36b543-4375-4d44-bd45-a5c1928eb437.png)], from the support—where
    *T < N*—and then calculate the cross-entropy loss for the embeddings for the verification
    task.
  prefs: []
  type: TYPE_NORMAL
- en: We then compute the fast weights for the task level, [![](img/6f5ca367-b136-481a-8879-5e1e95c0cb03.png)].
    Once this is complete, we compute the fast weights at the example level, [![](img/2184f5e9-dd5e-4d11-9f92-10c0165f6a8c.png)],
    from the support set and update the *i^(th)* location of the value memory, *M*,
    (for the meta learned) with [![](img/255a91ae-6744-4a88-8790-84ad258c6c36.png)].
    Then, we encode the sampled point from the support set into the task space with
    fast and slow weights using [![](img/6ae3456b-c75c-4095-b43a-01b6f93e13a4.png)],
    which is updated at the *i**^(th)* location of the key memory, *R* (for the base
    learner).
  prefs: []
  type: TYPE_NORMAL
- en: Once this is done, we sample from the test set and encode them into the task
    space using [![](img/9b120196-d062-405e-8e32-c9d25799e747.png)], then we calculate
    the cosine similarity to find out how similar the memory index and the input embedding
    are.
  prefs: []
  type: TYPE_NORMAL
- en: Metric-based meta learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Metric-based meta learning uses a concept similar to what is used in clustering,
    where we try to learn the distance between objects. This is similar to kernel
    density estimation, where we use a kernel function, *k[θ]*, to calculate weight
    or how similar two samples are, then find the predicted probability over the labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/618676bb-4cec-49c6-bf99-1d1e4fdf8b74.png)'
  prefs: []
  type: TYPE_IMG
- en: This class of meta learning algorithms explicitly learns the embedding of the
    data to create optimal kernels.
  prefs: []
  type: TYPE_NORMAL
- en: Prototypical networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prototypical networks are a type of meta learning algorithm used for few-shot
    learning. The way this works is we use an encoding function, *f[θ]*, to encode
    each of the *D*-dimensional inputs into an *M*-dimensional vector. This prototype
    vector is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9f9e78df-2a8c-48d9-99dc-af47d9385d78.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is the case for each class of ![](img/8d1f81cb-e366-4365-8a2d-1f1b8791fe61.png).
    We then calculate the distance, [![](img/2b5615fc-8936-4ea1-8b31-ee759df5c7af.png)],
    between the embedding of the test data and the prototype vector, then use it to
    calculate the probability distribution over the classes, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bcef8ca0-3935-4db0-8f89-a8d15711ebd2.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *d[φ]* is the distance function, but φ must be differentiable.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following diagram, we can see the prototypical network compute the few-shot
    prototypes and the zero-shot prototypes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1944b16-bc7f-49b2-b7ea-a60d4a135481.png)'
  prefs: []
  type: TYPE_IMG
- en: Siamese neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Siamese neural network is an architecture that is comprised of two identical
    neural networks with shared weights, and their parameters are trained to determine
    the similarity between two data samples using a distance metric on the embeddings.
    This architecture has proven to be effective for one-shot image classification
    where the network learns to tell whether or not two images belong to the same
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following diagram, we can see that the network takes in two images and
    each passes through an identical CNN (*f[θ]*) to generate feature vectors (the
    embeddings):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a32043c8-2695-4fd3-957f-78a0771b9db0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the embeddings are calculated, we can then calculate the distance between
    the two embeddings, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c80bb938-b24c-4384-b671-45cdf7023a03.png)'
  prefs: []
  type: TYPE_IMG
- en: The output from the distance is passed through a **multilayer perceptron** (**MLP**)
    with a sigmoid function to compute the probability of whether the two inputs belong
    to the same class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the labels for the image are binary (*1* for yes and *0* for no), we
    calculate the loss using cross-entropy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7a0a1901-b47c-4488-88c7-f120b4133533.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We calculate the probability of which class it belongs to using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d97572b-37a9-4c70-b133-e11ac9cccc61.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *S* is a support set, *x* is a test image, *c(x)* is the label corresponding
    to the image, and [![](img/ff769b17-331c-4e89-bd96-283fa7cd35f0.png)] is the class
    prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization-based meta learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 7](e1f37008-1ad5-49f6-a229-4d6249c2d7e3.xhtml), *Feedforward Neural
    Networks*, we covered backpropagation and gradient descent as a way to optimize
    the parameters of our model to reduce the loss; but we also saw that it is quite
    slow and requires a lot of training samples and so a lot of compute power. To
    overcome this, we use optimization-based meta learning, where we learn the optimization
    process. But how do we do that?
  prefs: []
  type: TYPE_NORMAL
- en: Long Short-Term Memory meta learners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's think back to when we learned about gradient-based optimization for a
    moment. What happened there? We started at an initial point in the parameter space
    and then calculated the gradient and took a step toward the local/global minima,
    then repeated these steps. In gradient descent, with momentum, we used the history
    of previous updates to guide the next one. If you think about it carefully, this
    is slightly similar to RNNs and **Long Short-Term Memory** (**LSTM**), so we can
    just replace the entire process of gradient descent with an RNN. This approach
    is known as **learning to learn by gradient descent**. The reasoning behind this
    name is that we train RNNs using gradient descent and then we use the RNN to perform
    the gradient descent. In this scenario, we call the RNN the optimizer and the
    base model the optimizee.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we know, vanilla RNNs have their problems (vanishing gradient), so here,
    we are going to cover optimizing the model using LSTM cells. But first, let''s
    revisit how parameter optimization works. It looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c259c7a-a1f0-4b27-a1d8-1e62e88532c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s compare this with the updates in an LSTM cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0544de67-fda1-4930-ad5c-e82b1aa82b38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, [![](img/18ee349b-ac5d-4582-a8ca-0876d8d06400.png)], [![](img/3808b60a-c4d3-496c-95d3-294dec9ef860.png)],
    [![](img/7a9dcafe-d986-42c7-bbd4-e869a633c650.png)] and [![](img/fc5efa4d-a79f-4646-a901-15931f8b6f52.png)].
    However, the forget gate and input gate do not have to be fixed; they can be learned
    so that we can adapt them for other tasks. The calculations for the forget gate,
    input gate, candidate layer, and memory state now become the following, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/315de60a-48ff-4fcb-acf0-df63a9a6aba1.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/ade581b4-4231-4cbe-ae54-26c6197f1ab0.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/72bb6f71-baf3-45cc-b7a3-23b5052555e6.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/e4400363-463d-4b9f-a9c7-dbbb8f2646a3.png)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following diagram, we can see how the LSTM meta learner is structured:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e36128a-2683-4530-afbe-16076f0cd6be.png)'
  prefs: []
  type: TYPE_IMG
- en: 'During the training process, we want to try and mimic what will happen during
    the testing process, and during training, we sample a dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/349cd6dc-8852-486f-8093-cf36818bfeb1.png)'
  prefs: []
  type: TYPE_IMG
- en: Following this, we sample from [![](img/e79f6f58-c0f9-49f0-ad80-26f4f71b7a26.png)]
    to update the parameters of the model by a total number of *T* iterations and
    calculate the loss with respect to the weights of the base model (θ), as well
    as feeding the loss, gradients, and meta learner parameter (φ) to the optimizer
    (meta learner). The meta learner will then output the new cell state, which we
    use to update the parameters of the base model.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have completed *T* iterations, we can expect to have found an optimal
    parameter for the base model. To test the goodness of *θ[T]* and update the parameters
    of the meta learner, we find the loss on the test data with respect to *θ[T]*,
    then find the gradients of the test loss with respect to φ, to perform updates
    to φ for *N* iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Model-agnostic meta learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Model-Agnostic Meta Learning** (**MAML**) is an optimization algorithm that
    can work on any type of neural network that is trained using gradient descent.
    Suppose we have a model, *f*, with parameters, θ, and a task, *τ[i]*, that has
    a corresponding dataset [![](img/301eb65d-08ff-4919-9f71-33809910f9eb.png)]. Then,
    we can make updates to the model using a single or several gradient descent steps.
    A single step in this algorithm works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b665474-9a7f-4d7f-a503-5260f6559108.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding step learns to optimize a single task, but we would like to optimize
    multiple tasks. So, we can change the task to find the optimal parameters over
    multiple tasks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de93df36-ea22-4b2c-b23e-74b709a8517a.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *L^((0))* is the loss corresponding to the initial training batch and
    *L^((1))* is the loss for the next training batch.
  prefs: []
  type: TYPE_NORMAL
- en: This looks pretty similar to the gradient descent we know, so what's special
    about it? What this is doing is learning the parameters associated with other
    tasks and attempting to learn the best initial parameters to use for the next
    task to reduce the training time. However, this uses second-order optimization,
    which is a bit more computationally intensive, so instead, we can use a first-order
    method, which is more feasible. This method is known as **First-Order Model-Agnostic
    Meta Learning** (**FOMAML**). Let's see the difference between the two in the
    following calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a case where we perform *n* gradient descent steps, where *n
    ≥ 1*. Our starting point is *θ[meta]* and the steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b6fa45f1-2c0e-4d24-92ea-640cf8d84e0b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once *n* steps are computed, we sample the next batch and perform updates over
    it. This then becomes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de6c4eac-2fd2-41b2-be9c-552c01fa4b81.png)![](img/e451043a-95d5-47e7-94d5-a9f0b3768b6c.png)'
  prefs: []
  type: TYPE_IMG
- en: Here,[![](img/f0929297-80a7-4429-844c-0ca4a737d1b1.png)].
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the gradient in FOMAML is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f1a9cb83-f2b3-4c45-8284-0162d4755e78.png)'
  prefs: []
  type: TYPE_IMG
- en: Congratulations—you have now completed this chapter on transfer learning and
    meta learning!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered two very fascinating areas within the field of deep
    learning—transfer learning and meta learning—both of which hold the promise of
    furthering the field of not only deep learning but also artificial intelligence
    by enabling neural networks to learn additional tasks and generalize over unseen
    distributions. We explored several meta learning approaches, including model-based,
    metric-based, and optimization-based, and explored how they differ.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about geometric deep learning.
  prefs: []
  type: TYPE_NORMAL
