["```py\nimport numpy as np \n\ndef elimination_matrix( \n    A: np.ndarray, \n    step: int, \n): \n    #x0022;\"/span> \n    Computes the step-th elimination matrix and its inverse. \n\n    Args: \n        A (np.ndarray): The matrix of shape (n, n) for which \n            the LU decomposition is being computed. \n        step (int): The current step of elimination, an integer \n            between 1 and n-1 \n\n    Returns: \n        elim_mtx (np.ndarray): The step-th elimination matrix \n            of shape (n, n) \n        elim_mtx_inv (np.ndarray): The inverse of the \n            elimination matrix of shape (n, n) \n    #x0022;\"/span> \n\n    n = A.shape[0] \n    elim_mtx = np.eye(n) \n    elim_mtx_inv = np.eye(n) \n\n    if 0 /span> step /span> n: \n        a = A[:, step-1]/A[step-1, step-1] \n        elim_mtx[step:, step-1] = -a[step:] \n        elim_mtx_inv[step:, step-1] = a[step:] \n\n    return elim_mtx, elim_mtx_inv\n```", "```py\ndef LU(A: np.ndarray): \n    #x0022;\"/span> \n    Computes the LU factorization of a square matrix A. \n\n    Args: \n        A (np.ndarray): A square matrix of shape (n, n) to be factorized. \n            It must be non-singular (invertible) for the \n            decomposition to work. \n\n    Returns: \n        L (np.ndarray): A lower triangular matrix of shape (n, n) \n            with ones on the diagonal. \n        U (np.ndarray): An upper triangular matrix of shape (n, n). \n    #x0022;\"/span> \n\n    n = A.shape[0] \n    L = np.eye(n) \n    U = np.copy(A) \n\n    for step in range(1, n): \n        elim_mtx, elim_mtx_inv = elimination_matrix(U, step=step) \n        U = np.matmul(elim_mtx, U) \n        L = np.matmul(L, elim_mtx_inv) \n\n    return L, U\n```", "```py\nA = 10*np.random.rand(4, 4) - 5 \nA\n```", "```py\narray([[-4.61990165, -3.97616553, -1.34258661,  0.50835913], \n      [-2.39491833, -2.3919011 , -1.3266581 ,  2.8658852 ], \n      [ 4.32658116,  0.43607725,  4.41630776, -4.46731714], \n      [-0.68329877,  4.76659965, -1.13602896, -2.12305592]])\n```", "```py\nL, U = LU(A) \n\nprint(f/span>Lower:\\n{L}\\n\\nUpper:\\n{U}\"\n```", "```py\nLower: \n[[  1\\.          0\\.          0\\.          0\\.       ] \n [  0.51839163   1\\.          0\\.          0\\.       ] \n [ -0.93650936   9.94174964   1\\.          0\\.       ] \n [  0.14790331 -16.19246049  -1.18248523   1\\.       ]] \n\nUpper: \n[[-4.61990165e+00 -3.97616553e+00 -1.34258661e+00  5.08359130e-01] \n [ 0.00000000e+00 -3.30690182e-01 -6.30672445e-01  2.60235608e+00] \n [ 0.00000000e+00  0.00000000e+00  9.42895038e+00 -2.98632067e+01] \n [ 1.11022302e-16 -8.88178420e-16  1.77635684e-15  4.62750317e+00]]\n```", "```py\nnp.allclose(np.matmul(L, U), A)\n```", "```py\nTrue\n```", "```py\ndef invert_lower_triangular_matrix(L: np.ndarray): \n    #x0022;\"/span> \n    Computes the inverse of a lower triangular matrix. \n\n    Args: \n        L (np.ndarray): A square lower triangular matrix of shape (n, n). \n                        It must have non-zero diagonal elements for the \n                        inversion to succeed. \n\n    Returns: \n        np.ndarray: The inverse of the lower triangular matrix L, with \n                        shape (n, n). \n    #x0022;\"/span> \n    n = L.shape[0] \n    G = np.eye(n) \n    D = np.copy(L) \n\n    for step in range(1, n): \n        elim_mtx, _ = elimination_matrix(D, step=step) \n        G = np.matmul(elim_mtx, G) \n        D = np.matmul(elim_mtx, D) \n\n    D_inv = np.eye(n)/np.diagonal(D)   # NumPy performs this operation elementwise \n\n    return np.matmul(D_inv, G)\n```", "```py\ndef invert(A: np.ndarray): \n    #x0022;\"/span> \n    Computes the inverse of a square matrix using its LU decomposition. \n\n    Args: \n        A (np.ndarray): A square matrix of shape (n, n). The matrix must be \n                        non-singular (invertible) for the inversion to succeed. \n\n    Returns: \n        np.ndarray: The inverse of the input matrix A, with shape (n, n). \n    #x0022;\"/span> \n    L, U = LU(A) \n    L_inv = invert_lower_triangular_matrix(L) \n    U_inv = invert_lower_triangular_matrix(U.T).T \n    return np.matmul(U_inv, L_inv)\n```", "```py\nA = np.random.rand(3, 3) \nA_inv = invert(A) \n\nprint(f/span>A:\\n{A}\\n\\nA^{-1}:\\n{A_inv}\\n\\nAA^{-1}:\\n{np.matmul(A, A_inv)}\"\n```", "```py\nA: \n[[0.17180745 0.79269571 0.36879642] \n [0.37772174 0.94712553 0.55310582] \n [0.93418085 0.38813821 0.51581695]] \n\nA^{-1}: \n[[  9.14230036  -8.87123133   2.97602074] \n [ 10.74480189  -8.5427258    1.47801811] \n [-24.64252111  22.49459369  -4.56327945]] \n\nAA^{-1}: \n[[ 1.00000000e+00 -1.37050081e-15  1.56962305e-17] \n [-4.06841165e-16  1.00000000e+00 -4.50714074e-16] \n [ 1.26848123e-14 -1.04564970e-14  1.00000000e+00]]\n```", "```py\nfor _ in range(1000): \n    n = np.random.randint(1, 10) \n    A = np.random.rand(n, n) \n    A_inv = invert(A) \n    if not np.allclose(np.matmul(A, A_inv), np.eye(n), atol=1e-5): \n        print(\"/span>Test failed.\"\n```", "```py\nA = np.random.rand(3, 3) \nA_inv = np.linalg.inv(A) \n\nprint(f/span>A:\\n{A}\\n\\nNumPy’s A^{-1}:\\n{A_inv}\\n\\nAA^{-1}:\\n{np.matmul(A, A_inv)}\"\n```", "```py\nA: \n[[0.08503998 0.31186637 0.71032538] \n [0.48973954 0.77358354 0.96303592] \n [0.31250848 0.14359491 0.05593863]] \n\nNumPy’s A^{-1}: \n[[ 2.13348825 -1.89861153  5.59470678] \n [-6.14268693  4.87769374 -5.97239945] \n [ 3.84931433 -1.91423645  1.95236829]] \n\nAA^{-1}: \n[[ 1.00000000e+00 -1.86546922e-16  2.74435800e-16] \n [-1.62367293e-16  1.00000000e+00  9.21871975e-17] \n [-1.41854334e-18  3.64838601e-17  1.00000000e+00]]\n```", "```py\nfrom timeit import timeit \n\nn_runs = 100 \nsize = 100 \nA = np.random.rand(size, size) \n\nt_inv = timeit(lambda: invert(A), number=n_runs) \nt_np_inv = timeit(lambda: np.linalg.inv(A), number=n_runs) \n\nprint(f/span>Our invert:              \\t{t_inv} s \nprint(f/span>NumPy’s invert:          \\t{t_np_inv} s \nprint(f/span>Performance improvement: \\t{t_inv/t_np_inv} times faster\n```", "```py\nOur invert:                    14.586225221995846 s \nNumPy’s invert:                0.46499890399718424 s \nPerformance improvement:       31.368300218798304 times faster\n```", "```py\n#x0022;\"/span> \nSGETRI computes the inverse of a matrix using the LU factorization \ncomputed by SGETRF. \n\nThis method inverts U and then computes inv(A) by solving the system \ninv(A)*L = inv(U) for inv(A). \n #x0022;\"/span>\n```", "```py\ndef det(A: np.ndarray): \n    #x0022;\"/span> \n    Recursively computes the determinant of a square matrix A. \n\n    Args: \n        A (np.ndarray): A square matrix of shape (n, n) for which the \n        determinant is to be calculated. \n\n    Returns: \n        float: The determinant of matrix A. \n\n    Raises: \n        ValueError: If A is not a square matrix. \n    #x0022;\"/span> \n\n    n, m = A.shape \n\n    # making sure that A is a square matrix \n    if n != m: \n        raise ValueError(\"/span>A must be a square matrix.\" \n\n    if n == 1: \n        return A[0, 0] \n\n    else: \n        return sum([(-1)**j*A[0, j]*det(np.delete(A[1:], j, axis=1)) for j in range(n)])\n```", "```py\nA = np.array([[1, 2], \n              [3, 4]]) \ndet(A)    # should be -2\n```", "```py\nnp.int64(-2)\n```", "```py\nfrom timeit import timeit \n\nA = np.random.rand(10, 10) \nt_det = timeit(lambda: det(A), number=1) \n\nprint(f/span>The time it takes to compute the determinant of a 10 x 10 matrix: {t_det} seconds\n```", "```py\nThe time it takes to compute the determinant of a 10 x 10 matrix: \n63.98369195000123 seconds\n```", "```py\ndef fast_det(A: np.ndarray): \n    #x0022;\"/span> \n    Computes the determinant of a square matrix using LU decomposition. \n\n    Args: \n        A (np.ndarray): A square matrix of shape (n, n) for which the determinant \n                         needs to be computed. The matrix must be non-singular (invertible). \n\n    Returns: \n        float: The determinant of the matrix A. \n    #x0022;\"/span> \n    L, U = LU(A) \n    return np.prod(np.diag(U))\n```", "```py\nA = np.random.rand(10, 10) \n\nt_fast_det = timeit(lambda : fast_det(A), number=1) \nprint(f/span>The time it takes to compute the determinant of a 10 x 10 matrix: {t_fast_det} seconds\n```", "```py\nThe time it takes to compute the determinant of a 10 x 10 matrix: \n0.0008458310039713979 seconds\n```", "```py\nprint(f/span>Recursive determinant:   \\t{t_det} s \nprint(f/span>LU determinant:          \\t{t_fast_det} s \nprint(f/span>Performance improvement: \\t{t_det/t_fast_det} times faster\n```", "```py\nRecursive determinant:         63.98369195000123 s \nLU determinant:                0.0008458310039713979 s \nPerformance improvement:       75645.95250065446 times faster\n```", "```py\n[2, 0, 1]\n```"]