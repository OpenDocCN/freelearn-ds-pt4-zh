<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8"/>
  <meta name="generator" content="pandoc"/>
  <title>ch012.xhtml</title>
  <style>
  </style>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
</head>
<body epub:type="bodymatter">
<section id="eigenvalues-and-eigenvectors" class="level2 chapterHead">
<h1 class="chapterHead"><span class="titlemark"><span class="cmss-10x-x-109">6</span></span><br/>
<span id="x1-1050007"></span><span class="cmss-10x-x-109">Eigenvalues and Eigenvectors</span></h1>
<p><span class="cmss-10x-x-109">So far, we have seen three sides of linear transformations: functions, matrices, and transforms that distort the grid of the underlying vector space. In the Euclidean plane, we saw some examples (</span><span class="cmssi-10x-x-109">Section </span><a href="ch010.xhtml#linear-transformations-in-the-euclidean-plane"><span class="cmssi-10x-x-109">4.3</span></a><span class="cmss-10x-x-109">) that shed some light on the geometric nature of them.</span></p>
<p><span class="cmss-10x-x-109">Following this line of thought, let’s consider the linear transformation given by the matrix</span></p>
<div style="display: flex; justify-content: space-between; align-items: center; max-width: 600px;" class="equation math-display">
  <div class="math-display">
    <img src="../media/equation_(12).png" alt="L(U,V ) = {f : U → V | f is linear}" width="150"/>
  </div>
  <div style="padding-left: 1em; ">
    <!-- Label goes here, e.g. (4.2) -->6.1
  </div>
</div>
<p><span class="cmss-10x-x-109">Since the columns of </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">are the images of the standard basis vectors </span><span class="cmbx-10x-x-109">e</span><sub><span class="cmr-8">1</span></sub> = (1<span class="cmmi-10x-x-109">,</span>0) <span class="cmss-10x-x-109">and </span><span class="cmbx-10x-x-109">e</span><sub><span class="cmr-8">2</span></sub> = (0<span class="cmmi-10x-x-109">,</span>1)<span class="cmss-10x-x-109">, we can visualize the effect of </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">on </span><span class="cmssi-10x-x-109">Figure </span><a href="#"><span class="cmssi-10x-x-109">6.1</span></a><span class="cmss-10x-x-109">. (Check </span><span class="cmssi-10x-x-109">Section </span><a href="ch010.xhtml#linear-transformations-and-matrices"><span class="cmssi-10x-x-109">4.1.1</span></a> <span class="cmss-10x-x-109">if you don’t recall this fact.)</span></p>
<p><span class="cmss-10x-x-109">This seems to shear, stretch, and rotate the entire grid. However, there are special directions along which </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">is simply a stretching. For instance, consider the vector </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub> = (1<span class="cmmi-10x-x-109">,</span>1)<span class="cmss-10x-x-109">. By a simple calculation, you can verify that </span><span class="cmmi-10x-x-109">A</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub> = 3<span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">Because of the linearity, this means that if a vector </span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">is in</span> span(<span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub>)<span class="cmss-10x-x-109">, its image under </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">is </span>3<span class="cmbx-10x-x-109">x</span><span class="cmss-10x-x-109">.</span></p>
<div class="minipage">
<p><img src="../media/file578.png" width="384" alt="PIC"/> <span id="x1-105001r1"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 7.1: Images of the standard basis vectors under the linear transformation given by </span><span class="cmmi-10x-x-109">A</span> </span>
</div>
<p><span class="cmss-10x-x-109">Another one is </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">2</span></sub> = (<span class="cmsy-10x-x-109">−</span>1<span class="cmmi-10x-x-109">,</span>1)<span class="cmss-10x-x-109">, where we have </span><span class="cmmi-10x-x-109">A</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">2</span></sub> = <span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">2</span></sub><span class="cmss-10x-x-109">. Thus, any </span><span class="cmbx-10x-x-109">x </span><span class="cmsy-10x-x-109">∈</span> span(<span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">2</span></sub>) <span class="cmss-10x-x-109">is left in place.</span></p>
<p><span class="cmss-10x-x-109">If we select </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">2</span></sub> <span class="cmss-10x-x-109">as our base, the matrix of this transformation is</span></p>
<div class="math-display">
<img src="../media/file579.png" class="math-display" alt=" ⌊ ⌋ Au ,u = ⌈3 0⌉ , 1 2 0 1 "/>
</div>
<p><span class="cmss-10x-x-109">that is, </span><span class="cmmi-10x-x-109">A</span><sub><span class="cmbx-8">u</span><sub><span class="cmr-6">1</span></sub><span class="cmmi-8">,</span><span class="cmbx-8">u</span><sub><span class="cmr-6">2</span></sub></sub> <span class="cmss-10x-x-109">is diagonal.</span></p>
<div class="minipage">
<p><img src="../media/file580.png" width="170" alt="PIC"/> <span id="x1-105002r2"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 7.2: Images of </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub> = (1<span class="cmmi-10x-x-109">,</span>1) <span class="cmss-10x-x-109">and </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">2</span></sub> = (<span class="cmsy-10x-x-109">−</span>1<span class="cmmi-10x-x-109">,</span>1) <span class="cmss-10x-x-109">under the linear transformation given by </span><span class="cmmi-10x-x-109">A</span> </span>
</div>
<p><span class="cmss-10x-x-109">We love diagonal matrices in practice because multiplication with a diagonal matrix is much faster, as it requires </span><span class="cmmi-10x-x-109">O</span>(<span class="cmmi-10x-x-109">n</span>) <span class="cmss-10x-x-109">operations, opposed to </span><span class="cmmi-10x-x-109">O</span>(<span class="cmmi-10x-x-109">n</span><sup><span class="cmr-8">2</span></sup>)<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">Is this a general phenomena? Are these even useful? The answer is yes to both questions. What we have just seen is formalized by the concept of </span><span class="cmssi-10x-x-109">eigenvalues </span><span class="cmss-10x-x-109">and </span><span class="cmssi-10x-x-109">eigenvectors</span><span class="cmss-10x-x-109">. The terminology originates from the german word “eigen” meaning “own,” resulting in one of the ugliest naming conventions in mathematics.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-105003r23"></span> <span class="cmbx-10x-x-109">Definition 23.</span> </span><span class="cmbx-10x-x-109">(Eigenvalues and eigenvectors)</span></p>
<p>Let <span class="cmmi-10x-x-109">f </span>: <span class="cmmi-10x-x-109">V </span><span class="cmsy-10x-x-109">→ </span><span class="cmmi-10x-x-109">V </span>be an arbitrary linear transformation. We say that the <span class="cmmi-10x-x-109">λ</span> scalar and the <span class="cmbx-10x-x-109">x </span><span class="cmsy-10x-x-109">∈</span><span class="cmmi-10x-x-109">V </span><span class="cmsy-10x-x-109">∖{</span><span class="cmbx-10x-x-109">0</span><span class="cmsy-10x-x-109">} </span>nonzero vector is an eigenvalue-eigenvector pair of <span class="cmmi-10x-x-109">f </span>if <span class="cmmi-10x-x-109">f</span>(<span class="cmbx-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">λ</span><span class="cmbx-10x-x-109">x </span>holds.</p>
</div>
<section id="eigenvalues-of-matrices" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_88"><span class="titlemark"><span class="cmss-10x-x-109">6.1 </span></span> <span id="x1-1060007.1"></span><span class="cmss-10x-x-109">Eigenvalues of matrices</span></h2>
<p><span class="cmss-10x-x-109">Although we</span> <span id="dx1-106001"></span><span class="cmss-10x-x-109">have formally defined</span> <span id="dx1-106002"></span><span class="cmss-10x-x-109">eigenvalues and eigenvectors for</span><span id="dx1-106003"></span> <span class="cmss-10x-x-109">linear transformations, we often talk about them in context of matrices. (Because, as we have seen, matrices and linear transformations are two faces of the same coin.) Let’s start by translating the definition into the language of matrices.</span></p>
<p><span class="cmss-10x-x-109">If </span><span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">is a matrix, </span><span class="cmssi-10x-x-109">Definition </span><a href="ch012.xhtml#x1-105003r23"><span class="cmssi-10x-x-109">23</span></a> <span class="cmss-10x-x-109">translates to the following: the scalar </span><span class="cmmi-10x-x-109">λ </span><span class="cmss-10x-x-109">and the vector </span><span class="cmbx-10x-x-109">x </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">∖{</span><span class="cmbx-10x-x-109">0</span><span class="cmsy-10x-x-109">} </span><span class="cmss-10x-x-109">is an eigenvalue-eigenvector pair of the </span><span class="cmssi-10x-x-109">matrix </span><span class="cmss-10x-x-109">if</span></p>
<div style="display: flex; justify-content: space-between; align-items: center; max-width: 600px;" class="math-display">
  <div class="math-display">
    A<strong>x</strong> = λ<strong>x</strong>
  </div>
  <div class="equation-label">(6.2)</div>
</div>

<p><span class="cmss-10x-x-109">holds. This can be simplified: as the linear transformation </span><span class="cmbx-10x-x-109">x</span>→<span class="cmmi-10x-x-109">λ</span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">corresponds to the matrix </span><span class="cmmi-10x-x-109">λI</span><span class="cmss-10x-x-109">, (</span><a href="ch012.xhtml#eigenvalues-of-matrices"><span class="cmss-10x-x-109">6.2</span></a><span class="cmss-10x-x-109">) is equivalent to</span></p>
<div style="display: flex; justify-content: space-between; align-items: center; max-width: 600px;" class="math-display">
  <div class="math-display">
    (A − λI)<strong>x</strong> = <strong>0</strong>
  </div>
  <div class="equation-label">(6.3)</div>
</div>

<p><span class="cmss-10x-x-109">If you recall </span><span class="cmssi-10x-x-109">Chapter </span><a href="ch010.xhtml#linear-transformations"><span class="cmssi-10x-x-109">4</span></a><span class="cmss-10x-x-109">, </span><span class="cmssi-10x-x-109">Section </span><a href="ch010.xhtml#linear-transformations-and-matrices"><span class="cmssi-10x-x-109">4.1.1</span></a><span class="cmss-10x-x-109">, where we learned how matrices arise from linear transformations, you might ask the question: won’t the eigenvalues depend on the choice of the matrix?</span></p>
<p><span class="cmss-10x-x-109">The following theorem states that this is not the case: the eigenvalues of a linear transformation and its matrices are the same.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-106004r36"></span> <span class="cmbx-10x-x-109">Theorem 36.</span> </span><span class="cmbxti-10x-x-109">(Eigenvalues of similar matrices)</span></p>
<p><span class="cmti-10x-x-109">Let </span><span class="cmmi-10x-x-109">A,B </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmti-10x-x-109">be two similar matrices, that is, suppose that there exists an invertible </span><span class="cmmi-10x-x-109">T </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmti-10x-x-109">such that </span><span class="cmmi-10x-x-109">B </span>= <span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmmi-10x-x-109">AT</span><span class="cmti-10x-x-109">. Then, if </span><span class="cmmi-10x-x-109">A</span><span class="cmbx-10x-x-109">x </span>= <span class="cmmi-10x-x-109">λ</span><span class="cmbx-10x-x-109">x </span><span class="cmti-10x-x-109">holds for some scalar </span><span class="cmmi-10x-x-109">λ </span><span class="cmti-10x-x-109">and vector </span><span class="cmbx-10x-x-109">x </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span></sup><span class="cmti-10x-x-109">,</span></p>
<p><span class="cmti-10x-x-109">then</span></p>
<img src="../media/file582.png" class="math-display" width="150" alt=" ′ ′ Bx = λx "/>

<p><span class="cmti-10x-x-109">holds for some </span><span class="cmbx-10x-x-109">x</span><sup><span class="cmsy-8">′</span></sup><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span></sup> <span class="cmti-10x-x-109">as well.</span></p>
</div>
<div id="tcolobox-172" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. </span><span class="cmss-10x-x-109">Let’s massage the eigenvalue (</span><a href="ch012.xhtml#eigenvalues-of-matrices"><span class="cmss-10x-x-109">6.3</span></a><span class="cmss-10x-x-109">) a bit! We have</span></p>
<div class="math-display">
<img src="../media/file583.png" class="math-display" alt=" −1 (A − λI)x = (A − λT T )x = T (T−1AT − λI)T −1x = 0. "/>
</div>
<p><span class="cmss-10x-x-109">Since </span><span class="cmmi-10x-x-109">T </span><span class="cmss-10x-x-109">is invertible, </span><span class="cmmi-10x-x-109">T</span><span class="big">[</span>(<span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmmi-10x-x-109">AT </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>)<span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmbx-10x-x-109">x</span><span class="big">]</span> = <span class="cmbx-10x-x-109">0 </span><span class="cmss-10x-x-109">can only happen if </span>(<span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmmi-10x-x-109">AT </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>)<span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmmi-10x-x-109">x </span>= <span class="cmbx-10x-x-109">0</span><span class="cmss-10x-x-109">. (Recall the relation of the kernel and invertibility in </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch010.xhtml#x1-70003r20"><span class="cmssi-10x-x-109">20</span></a><span class="cmss-10x-x-109">.) This looks almost like (</span><a href="ch012.xhtml#eigenvalues-of-matrices"><span class="cmss-10x-x-109">6.3</span></a><span class="cmss-10x-x-109">), just a bit more complicated. Let</span> <span id="dx1-106005"></span><span class="cmss-10x-x-109">me use some suggestive parentheses to highlight the similarities:</span></p>
<div class="math-display">
<img src="../media/file586.png" class="math-display" alt=" −1 − 1 [T AT − λI ][T x] = 0. "/>
</div>
<p><span class="cmss-10x-x-109">So, with the selection </span><span class="cmbx-10x-x-109">x</span><sup><span class="cmsy-8">′</span></sup> = <span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmbx-10x-x-109">x</span><span class="cmss-10x-x-109">, we have</span></p>

<img src="../media/file587.png" class="math-display" width="150" alt=" −1 ′ ′ T AT x = λx , "/>
<p><span class="cmss-10x-x-109">which is what we had to show.</span></p>
</div>
</div>
<p><span class="cmss-10x-x-109">In other words, the eigenvalues of similar matrices are the same. Consequently, we can talk about the eigenvalues of </span><span class="cmssi-10x-x-109">matrices</span><span class="cmss-10x-x-109">, not just linear transformations. The above theorem implies that the eigenvalues of a transformation and its corresponding matrix are the same. Moreover, the eigenvalues of the matrix don’t depend on the choice of basis.</span></p>
<p><span class="cmss-10x-x-109">To be more precise, suppose that </span><span class="cmmi-10x-x-109">A </span>: <span class="cmmi-10x-x-109">U </span><span class="cmsy-10x-x-109">→</span><span class="cmmi-10x-x-109">U </span><span class="cmss-10x-x-109">is a linear transformation and </span><span class="cmmi-10x-x-109">P,Q </span><span class="cmss-10x-x-109">are bases of </span><span class="cmmi-10x-x-109">U</span><span class="cmss-10x-x-109">. The matrix of </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">in some basis </span><span class="cmmi-10x-x-109">S </span><span class="cmss-10x-x-109">is denoted by </span><span class="cmmi-10x-x-109">A</span><sub><span class="cmmi-8">Q</span></sub><span class="cmss-10x-x-109">. We know that there is a transformation matrix </span><span class="cmmi-10x-x-109">T </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">such that</span></p>

<img src="../media/file588.png" class="math-display" width="150" alt=" −1 AQ = T AP T. "/>

<p><span class="cmss-10x-x-109">So, the eigenvalues are the same.</span></p>
<p><span class="cmss-10x-x-109">All of</span> <span id="dx1-106006"></span><span class="cmss-10x-x-109">the above begs the question: how do we actually find eigenvalues? Let’s talk about this next.</span></p>
</section>
<section id="finding-eigenvalueeigenvector-pairs" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_89"><span class="titlemark"><span class="cmss-10x-x-109">6.2 </span></span> <span id="x1-1070007.2"></span><span class="cmss-10x-x-109">Finding eigenvalue-eigenvector pairs</span></h2>
<p><span class="cmss-10x-x-109">Even though the</span> <span id="dx1-107001"></span><span class="cmss-10x-x-109">definition of eigenvalue-eigenvector pairs is easy to understand given the geometric interpretation we just saw, it does not give us any tools to find them in practice. Using them to get simpler representations of matrices is one thing, but we are stuck at square one without a method to find them.</span></p>
<p><span class="cmss-10x-x-109">First, let’s focus on the eigenvalues. Suppose that for some </span><span class="cmmi-10x-x-109">λ</span><span class="cmss-10x-x-109">, there is a nonzero vector </span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">such that </span><span class="cmmi-10x-x-109">A</span><span class="cmbx-10x-x-109">x </span>= <span class="cmmi-10x-x-109">λ</span><span class="cmbx-10x-x-109">x</span><span class="cmss-10x-x-109">. The transformation defined by </span><span class="cmbx-10x-x-109">x </span><span class="cmsy-10x-x-109">→</span><span class="cmmi-10x-x-109">λ</span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">is a linear one, and its matrix is diagonal:</span></p>
<div class="math-display">
<img src="../media/file589.png" class="math-display" alt=" ⌊ λ 0 ... 0⌋ ⌊ x ⌋ | | | 1| || 0 λ ... 0|| || x2|| λx = || .. .. .. ..|| || .. || , ⌈ . . . .⌉ ⌈ . ⌉ 0 0 ... λ xn "/>
</div>
<p><span class="cmss-10x-x-109">where the matrix with </span><span class="cmmi-10x-x-109">λ</span><span class="cmss-10x-x-109">-s in the diagonal is </span><span class="cmmi-10x-x-109">λI</span><span class="cmss-10x-x-109">, that is, </span><span class="cmmi-10x-x-109">λ </span><span class="cmss-10x-x-109">times the identity matrix.</span></p>
<p><span class="cmss-10x-x-109">Because linear transformations can be added and subtracted (as we saw in </span><span class="cmssi-10x-x-109">Section </span><a href="ch010.xhtml#matrix-operations-revisited"><span class="cmssi-10x-x-109">4.1.2</span></a><span class="cmss-10x-x-109">), the defining equation </span><span class="cmmi-10x-x-109">A</span><span class="cmbx-10x-x-109">x </span>= <span class="cmmi-10x-x-109">λ</span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">is equivalent to</span></p>
<img src="../media/file590.png" class="math-display" width="150" alt="(A − λI)x = 0, "/>

<p><span class="cmss-10x-x-109">where </span><span class="cmmi-10x-x-109">I </span><span class="cmss-10x-x-109">denotes the identity transformation, as defined by equation (4.3). In other words, the transformation </span><span class="cmmi-10x-x-109">A</span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI </span><span class="cmss-10x-x-109">maps a nonzero vector to </span><span class="cmbx-10x-x-109">0</span><span class="cmss-10x-x-109">, meaning that it is not invertible, as </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch010.xhtml#x1-70003r20"><span class="cmssi-10x-x-109">20</span></a> <span class="cmss-10x-x-109">implies. We can characterize this with determinants: we need to find all </span><span class="cmmi-10x-x-109">λ</span><span class="cmss-10x-x-109">-s such that</span></p>
<div class="">
<img src="../media/file591.png" class="math-display" width="150" alt="det(A − λI ) = 0. "/>
</div>
<p><span class="cmss-10x-x-109">We can summarize the above findings in the following theorem.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-107002r37"></span> <span class="cmbx-10x-x-109">Theorem 37.</span> </span></p>
<p><span class="cmti-10x-x-109">Let </span><img src="../media/file592.png" class="math" alt="A : U → U "/> <span class="cmti-10x-x-109">be an arbitrary linear transformation. Then </span><img src="../media/file593.png" class="math" alt="λ "/> <span class="cmti-10x-x-109">is its eigenvalue if and only if</span></p>
<div class="math-disply">
<img src="../media/file594.png" class="math-display" alt="det(A − λI ) = 0. " width="150"/>
</div>
</div>
<p><span class="cmss-10x-x-109">Although we are one step closer, finding eigenvalues based on this still seems complicated. In the following, we are going to see what</span> det(<span class="cmmi-10x-x-109">A</span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>) <span class="cmss-10x-x-109">really is and how we can find the solutions of</span> det(<span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>) = 0 <span class="cmss-10x-x-109">in practice.</span></p>
<p><span class="cmss-10x-x-109">Before going into the generalities, let’s revisit the example (</span><a href="ch012.xhtml#eigenvalues-and-eigenvectors"><span class="cmss-10x-x-109">6.1</span></a><span class="cmss-10x-x-109">). There, we have</span></p>
<div class="math-display">
<img src="../media/file595.png" class="math-display" alt=" | | | | det(A − λI) = ||2 − λ 1 || || 1 2− λ|| = (2 − λ)2 − 1 = λ2 − 4λ + 3. "/>
</div>
<p><span class="cmss-10x-x-109">To find</span> <span id="dx1-107003"></span><span class="cmss-10x-x-109">the eigenvalues, we have to solve the quadratic equation</span></p>
<div class="math-diplay">
<img src="../media/file596.png" class="math-display" alt="λ2 − 4λ + 3 = 0, " width="150"/>
</div>
<p><span class="cmss-10x-x-109">which we can do easily. Recall that the solutions of any quadratic equation </span><span class="cmmi-10x-x-109">ax</span><sup><span class="cmr-8">2</span></sup> + <span class="cmmi-10x-x-109">bx </span>+ <span class="cmmi-10x-x-109">c </span>= 0 <span class="cmss-10x-x-109">are</span></p>
<div class="math-display">
<img src="../media/file597.png" class="math-display" alt=" √ 2------- x1,2 = − b-±--b-−-4ac. 2a "/>
</div>
<p><span class="cmss-10x-x-109">Applying this, we have </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub> = 3 <span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">2</span></sub> = 1 <span class="cmss-10x-x-109">as solutions. There are no other ones, so </span>1 <span class="cmss-10x-x-109">and </span>3 <span class="cmss-10x-x-109">are the only two eigenvalues for </span><span class="cmmi-10x-x-109">A</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">Let’s see what happens in the general case!</span></p>
<section id="the-characteristic-polynomial" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_90"><span class="titlemark"><span class="cmss-10x-x-109">6.2.1 </span></span> <span id="x1-1080007.2.1"></span><span class="cmss-10x-x-109">The characteristic polynomial</span></h3>
<p><span class="cmss-10x-x-109">As the example above suggests, if</span> <span id="dx1-108001"></span><span class="cmss-10x-x-109">the underlying vector space </span><span class="cmmi-10x-x-109">U </span><span class="cmss-10x-x-109">is </span><span class="cmmi-10x-x-109">n</span><span class="cmss-10x-x-109">-dimensional, that is, </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">is an </span><span class="cmmi-10x-x-109">n </span><span class="cmsy-10x-x-109">×</span><span class="cmmi-10x-x-109">n </span><span class="cmss-10x-x-109">matrix,</span> det(<span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>) <span class="cmss-10x-x-109">is an </span><span class="cmmi-10x-x-109">n</span><span class="cmss-10x-x-109">-th degree polynomial in </span><span class="cmmi-10x-x-109">λ</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">To see this, let’s write</span> det(<span class="cmmi-10x-x-109">A</span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>) <span class="cmss-10x-x-109">explicitly in terms of matrices. With this in mind, we have</span></p>
<div class="math-display">
<img src="../media/file598.png" class="math-display" alt=" | | |a − λ a ... a | ||11 12 1n || || a21 a22 − λ ... a2n || det(A − λI) = || .. .. .. .. ||. || . . . . || | an1 an2 ... ann − λ | "/>
</div>
<p><span class="cmss-10x-x-109">If you consider the formula to calculate the determinant given by (</span><a href="ch010.xhtml#x1-81006r20"><span class="cmss-10x-x-109">4.12</span></a><span class="cmss-10x-x-109">), you can see that every term is a polynomial. Depending on how many fixed points </span><span class="cmmi-10x-x-109">σ </span><span class="cmss-10x-x-109">has (that is, points where </span><span class="cmmi-10x-x-109">σ</span>(<span class="cmmi-10x-x-109">i</span>) = <span class="cmmi-10x-x-109">i</span><span class="cmss-10x-x-109">), the degree of this polynomial varies between </span>0 <span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">n</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">(Alternatively, you can see that</span> det(<span class="cmmi-10x-x-109">A</span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>) <span class="cmss-10x-x-109">is a polynomial of degree </span><span class="cmmi-10x-x-109">n </span><span class="cmss-10x-x-109">by using the recursive formula (</span><a href="ch010.xhtml#x1-81009r21"><span class="cmss-10x-x-109">4.13</span></a><span class="cmss-10x-x-109">) and applying induction.)</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-108002r24"></span> <span class="cmbx-10x-x-109">Definition 24.</span> </span><span class="cmbx-10x-x-109">(Characteristic polynomial of matrices)</span></p>
<p>Let <span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> be an arbitrary matrix. The polynomial</p>
<div class="math-displa">
<img src="../media/file599.png" width="150" class="math-display" alt="p(λ) = det(A − λI) "/>
</div>
<p>is called the <span class="cmti-10x-x-109">characteristic polynomial </span>of <span class="cmmi-10x-x-109">A</span>.</p>
</div>
<p><span class="cmss-10x-x-109">The roots of the</span> <span id="dx1-108003"></span><span class="cmss-10x-x-109">characteristic polynomial are the eigenvalues. If </span><span class="cmmi-10x-x-109">U </span><span class="cmss-10x-x-109">is an </span><span class="cmmi-10x-x-109">n</span><span class="cmss-10x-x-109">-dimensional complex vector space (that is, the set of scalars is </span><span class="msbm-10x-x-109">ℂ</span><span class="cmss-10x-x-109">), the fundamental theorem of algebra (</span><span class="cmssi-10x-x-109">Theorem </span><a href="ch038.xhtml#x1-385002r156"><span class="cmssi-10x-x-109">156</span></a><span class="cmss-10x-x-109">) guarantees that</span> det(<span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>) = 0 <span class="cmss-10x-x-109">has exactly </span><span class="cmmi-10x-x-109">n </span><span class="cmss-10x-x-109">roots.</span></p>
<p><span class="cmss-10x-x-109">As a consequence, every matrix </span><span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℂ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">has at least one eigenvalue. Note that roots can have higher algebraic multiplicity. For instance, the characteristic polynomial for the matrix</span></p>
<img src="../media/file600.png" class="math-display" alt=" ⌊ ⌋ | 1 0 0| B = | 0 1 0| ⌈ ⌉ 0 0 2 " width="150"/>
<p><span class="cmss-10x-x-109">is </span>(1 <span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λ</span>)<sup><span class="cmr-8">2</span></sup>(2 <span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λ</span>)<span class="cmss-10x-x-109">. So, its roots are </span>1 <span class="cmss-10x-x-109">(with algebraic multiplicity </span>2<span class="cmss-10x-x-109">) and</span> 2<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">If we restrict ourselves to real matrices and real vector spaces, the existence of eigenvalues and eigenvectors are not guaranteed. For instance, consider</span></p>
<img src="../media/file601.png" width="150" class="math-display" alt=" ⌊ ⌋ 0 − 1 C = ||1 0 ||. ⌈ ⌉ "/>
<p><span class="cmss-10x-x-109">Its characteristic polynomial is </span><span class="cmmi-10x-x-109">λ</span><sup><span class="cmr-8">2</span></sup> + 1<span class="cmss-10x-x-109">, which doesn’t have any real roots, only complex ones: </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub> = <span class="cmmi-10x-x-109">i </span><span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">2</span></sub> = <span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">i</span><span class="cmss-10x-x-109">. Mathematically speaking, if we want to stay within the confines of real vector spaces, </span><span class="cmmi-10x-x-109">C </span><span class="cmss-10x-x-109">has no eigenvalues. However, we are here to do machine learning, not algebra. Thus, we are going to be a bit imprecise and treat real matrices as complex ones. We don’t often need complex numbers to describe mathematical models of a dataset, but they frequently appear during the analysis of matrices.</span></p>
</section>
<section id="finding-eigenvectors" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_91"><span class="titlemark"><span class="cmss-10x-x-109">6.2.2 </span></span> <span id="x1-1090007.2.2"></span><span class="cmss-10x-x-109">Finding eigenvectors</span></h3>
<p><span class="cmss-10x-x-109">When an</span> <span id="dx1-109001"></span><span class="cmss-10x-x-109">eigenvalue </span><span class="cmmi-10x-x-109">λ </span><span class="cmss-10x-x-109">is identified, we can set out to find the corresponding eigenvectors; that is, vectors </span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">where </span>(<span class="cmmi-10x-x-109">A</span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>)<span class="cmbx-10x-x-109">x </span>= <span class="cmbx-10x-x-109">0</span><span class="cmss-10x-x-109">. In more precise terms, we are looking for</span> ker(<span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λI</span>)<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">As we have mentioned before in </span><span class="cmssi-10x-x-109">Section </span><a href="ch010.xhtml#the-kernel-and-the-image"><span class="cmssi-10x-x-109">4.1.4</span></a><span class="cmss-10x-x-109">, the kernel of any linear transformation is a subspace. As it might be more than one-dimensional, identifying it often involves an implicit description like </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">1</span></sub> + <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">2</span></sub> = 0<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">Let’s check what happens with our recurring example</span></p>
<img src="../media/file602.png" width="150" class="math-display" alt=" ⌊ ⌋ 2 1 A = ⌈ ⌉ . 1 2 "/>
<p><span class="cmss-10x-x-109">Previously, we have seen that </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub> = 3 <span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">2</span></sub> = 1 <span class="cmss-10x-x-109">are the eigenvalues. To identify the corresponding eigenvectors for, say, </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub><span class="cmss-10x-x-109">, we have to find </span><span class="cmssi-10x-x-109">all </span><span class="cmss-10x-x-109">solutions for the linear equation </span>(<span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">I</span>)<span class="cmbx-10x-x-109">x </span>= <span class="cmbx-10x-x-109">0</span><span class="cmss-10x-x-109">. Expanding this, we have</span></p>
<img src="../media/file603.png" width="150" class="math-display" alt="− x1 + x2 = 0 x1 − x2 = 0. "/>
<p><span class="cmss-10x-x-109">Both equations imply that all </span><span class="cmbx-10x-x-109">x </span>= (<span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,x</span><sub><span class="cmr-8">2</span></sub>) <span class="cmss-10x-x-109">are solutions where </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">1</span></sub> = <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">2</span></sub><span class="cmss-10x-x-109">.</span></p>
</section>
</section>
<section id="eigenvectors-eigenspaces-and-their-bases" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_92"><span class="titlemark"><span class="cmss-10x-x-109">6.3 </span></span> <span id="x1-1100007.3"></span><span class="cmss-10x-x-109">Eigenvectors, eigenspaces, and their bases</span></h2>
<div class="newtheorem">
<p><span class="head"> <span id="x1-110001r25"></span> <span class="cmbx-10x-x-109">Definition 25.</span> </span><span class="cmbx-10x-x-109">(Eigenspaces)</span></p>
<p>Let <span class="cmmi-10x-x-109">f </span>: <span class="cmmi-10x-x-109">V </span><span class="cmsy-10x-x-109">→</span><span class="cmmi-10x-x-109">V </span>be an arbitrary linear transformation, and <span class="cmmi-10x-x-109">λ </span>its eigenvalue. The subspace of eigenvectors defined by</p>
<img src="../media/file604.png" class="math-display" alt="Uλ = {x : Ax = λx} " width="150"/>
<p>is called the <span class="cmti-10x-x-109">eigenspace </span>of <span class="cmmi-10x-x-109">λ</span>.</p>
</div>
<p><span class="cmss-10x-x-109">Eigenspaces play an</span> <span id="dx1-110002"></span><span class="cmss-10x-x-109">important role in understanding the structure of linear transformations. First, we note that a linear transformation </span><span class="cmssi-10x-x-109">keeps its eigenspaces invariant</span><span class="cmss-10x-x-109">. (That is, if </span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">is in the </span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span></sub> <span class="cmss-10x-x-109">eigenspace, then </span><span class="cmmi-10x-x-109">f</span>(<span class="cmbx-10x-x-109">x</span>) <span class="cmsy-10x-x-109">∈</span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span></sub> <span class="cmss-10x-x-109">as well.) This property makes it possible for us to restrict linear transformations to their eigenspaces.</span></p>
<p><span class="cmss-10x-x-109">To illustrate the concept of eigenspaces, let’s revisit the already familiar matrix</span></p>
<img src="../media/file605.png" width="150" class="math-display" alt=" ⌊ ⌋ 2 1 A = ⌈ ⌉ 1 2 "/>
<p><span class="cmss-10x-x-109">one more time. Its eigenvalues are </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub> = 3 <span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">2</span></sub> = 1<span class="cmss-10x-x-109">, and by solving the equation</span> (<span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">I</span>)<span class="cmbx-10x-x-109">x </span>= <span class="cmbx-10x-x-109">0</span><span class="cmss-10x-x-109">, we get that the eigenspace of </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub> <span class="cmss-10x-x-109">is</span></p>
<div class="math-display">
<img src="../media/file606.png" class="math-display" alt="U = {x ∈ ℝ2 : x = x }. λ1 1 2 "/>
</div>
<p><span class="cmss-10x-x-109">Similarly, you can check that </span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmr-6">2</span></sub></sub> = <span class="cmsy-10x-x-109">{</span><span class="cmbx-10x-x-109">x </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmr-8">2</span></sup> : <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">1</span></sub> = <span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">2</span></sub><span class="cmsy-10x-x-109">}</span><span class="cmss-10x-x-109">. (If you go back to </span><span class="cmssi-10x-x-109">Figure 6.2</span><span class="cmss-10x-x-109">, you can visualize </span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmr-6">1</span></sub></sub> <span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmr-6">2</span></sub></sub><span class="cmss-10x-x-109">.)</span></p>
<p><span class="cmss-10x-x-109">Eigenspaces are not</span> <span id="dx1-110003"></span><span class="cmss-10x-x-109">necessarily one-dimensional. For instance, consider one of the the previous examples</span></p>
<div class="math-display">
<img src="../media/file607.png" class="math-display" alt=" ⌊ ⌋ 1 0 0 || || B = ⌈0 1 0⌉ , 0 0 2 "/>
</div>
<p><span class="cmss-10x-x-109">with two eigenvalues </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub> = 1 <span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">2</span></sub> = 2<span class="cmss-10x-x-109">. Substituting </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmr-8">1</span></sub> <span class="cmss-10x-x-109">back into the equation and solving for </span>(<span class="cmmi-10x-x-109">B </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">I</span>)<span class="cmbx-10x-x-109">x </span>= 0 <span class="cmss-10x-x-109">for </span><span class="cmbx-10x-x-109">x</span><span class="cmss-10x-x-109">, we obtain that</span></p>
<div class="math-display">
<img src="../media/file608.png" class="math-display" alt="U = {x ∈ ℝ3 : x = 0}, λ1 3 "/>
</div>
<p><span class="cmss-10x-x-109">which is simply the plane determined by the first two axes.</span></p>
<p><span class="cmss-10x-x-109">The structure of eigenspaces determines whether or not we can diagonalize the matrix </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">with a change of basis (</span><span class="cmssi-10x-x-109">Section </span><a href="ch010.xhtml#change-of-basis"><span class="cmssi-10x-x-109">4.2</span></a><span class="cmss-10x-x-109">) transformation </span>Λ = <span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmmi-10x-x-109">AU</span><span class="cmss-10x-x-109">. The following general theorem establishes this connection.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-110004r38"></span> <span class="cmbx-10x-x-109">Theorem 38.</span> </span><span class="cmbxti-10x-x-109">(Diagonalization and eigenspaces)</span></p>
<p><span class="cmti-10x-x-109">Let </span><span class="cmmi-10x-x-109">f </span>: <span class="cmmi-10x-x-109">V </span><span class="cmsy-10x-x-109">→ </span><span class="cmmi-10x-x-109">V </span><span class="cmti-10x-x-109">be a linear transformation, let </span><span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈ </span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmti-10x-x-109">be its matrix in some basis, and let </span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><span class="cmti-10x-x-109">1</span><span class="cmmi-8">,…,U</span></sub><span class="cmsy-10x-x-109">{</span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmmi-8">k</span></sub><span class="cmsy-10x-x-109">} </span><span class="cmti-10x-x-109">be the eigenspaces of </span><span class="cmmi-10x-x-109">f</span><span class="cmti-10x-x-109">. The following are equivalent.</span></p>
<p><span class="cmti-10x-x-109">(a) There is a matrix </span><span class="cmmi-10x-x-109">T </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmti-10x-x-109">such that</span></p>
<img src="../media/file609.png" class="math-display" alt=" −1 Λ = T AT, " width="150"/>
<p><span class="cmti-10x-x-109">where </span>Λ <span class="cmti-10x-x-109">is a diagonal matrix.</span></p>
<p><span class="cmti-10x-x-109">(b) There is a basis </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,…,</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">n</span></sub> <span class="cmti-10x-x-109">for </span><span class="cmmi-10x-x-109">V </span><span class="cmti-10x-x-109">that can be selected from the eigenvectors of </span><span class="cmmi-10x-x-109">f</span><span class="cmti-10x-x-109">.</span></p>
<p><span class="cmti-10x-x-109">(c) </span><span class="cmmi-10x-x-109">V </span><span class="cmti-10x-x-109">can be written as the direct sum of the eigenspaces, that is,</span></p>
<img src="../media/file610.png" class="math-display" alt="V = Uλ1 + ⋅⋅⋅+ Uλk. " width="150"/>
</div>
<p><span class="cmss-10x-x-109">(Note that </span><span class="cmmi-10x-x-109">k</span><span class="cmss-10x-x-109">, the number of eigenspaces, is not necessarily </span><span class="cmmi-10x-x-109">n</span><span class="cmss-10x-x-109">.)</span></p>
<div id="tcolobox-173" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. (a)</span> ⇒ <span class="cmssi-10x-x-109">(b). </span><span class="cmss-10x-x-109">If </span><img src="../media/file612.png" class="math" alt="A "/> <span class="cmss-10x-x-109">is the matrix of </span><img src="../media/file613.png" class="math" alt="f "/> <span class="cmss-10x-x-109">in some basis, then a similarity transformation is equivalent to a change of basis.</span></p>
<p><span class="cmss-10x-x-109">That is, the new matrix </span>Λ = <span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmmi-10x-x-109">AT </span><span class="cmss-10x-x-109">is the matrix of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">in a different basis, say </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,…,</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">n</span></sub><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">If </span>Λ <span class="cmss-10x-x-109">is diagonal, it can be</span> <span id="dx1-110005"></span><span class="cmss-10x-x-109">written in the form</span></p>
<div class="math-display">
<img src="../media/file614.png" class="math-display" alt=" ⌊ ⌋ |λ1 0 ... 0 | || 0 λ2 ... 0 || Λ = | . . . .| . |⌈ .. .. .. ..|⌉ 0 0 ... λ n "/>
</div>
<p><span class="cmss-10x-x-109">(Note that the </span><span class="cmmi-10x-x-109">λ</span><sub><span class="cmmi-8">i</span></sub><span class="cmss-10x-x-109">-s are not necessarily mutually different.) Thus,</span> Λ<span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">i</span></sub> = <span class="cmmi-10x-x-109">λ</span><sub><span class="cmmi-8">i</span></sub><span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">i</span></sub><span class="cmss-10x-x-109">, meaning that </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,…,</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">n</span></sub> <span class="cmss-10x-x-109">is a basis from the eigenvectors of </span><span class="cmmi-10x-x-109">f</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmssi-10x-x-109">(b)</span> ⇒ <span class="cmssi-10x-x-109">(a). </span><span class="cmss-10x-x-109">If </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,…,</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">n</span></sub> <span class="cmss-10x-x-109">is a basis from the eigenvectors of </span><span class="cmmi-10x-x-109">f</span><span class="cmss-10x-x-109">, then its matrix </span>Λ <span class="cmss-10x-x-109">in that basis is diagonal. Thus, </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">is similar to </span>Λ<span class="cmss-10x-x-109">, which is what we had to show.</span></p>
<p><span class="cmssi-10x-x-109">(b)</span> ⇒ <span class="cmssi-10x-x-109">(c). </span><span class="cmss-10x-x-109">By definition, the direct sum (</span><span class="cmssi-10x-x-109">Definition </span><a href="ch007.xhtml#x1-29004r6"><span class="cmssi-10x-x-109">6</span></a><span class="cmss-10x-x-109">) of the eigenspaces contains all linear combinations of the form</span></p>
<div class="math-display">
<img src="../media/file617.png" class="math-display" alt=" n x = ∑ xu . i i i=1 "/>
</div>
<p><span class="cmss-10x-x-109">Since </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,…,</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">n</span></sub> <span class="cmss-10x-x-109">is a basis, </span><span class="cmmi-10x-x-109">V </span>= <span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmr-6">1</span></sub></sub> + ⋅⋅⋅ + <span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmmi-6">k</span></sub></sub> <span class="cmss-10x-x-109">holds.</span></p>
<p><span class="cmssi-10x-x-109">(c)</span> ⇒ <span class="cmssi-10x-x-109">(b). </span><span class="cmss-10x-x-109">From each eigenspace </span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmmi-6">i</span></sub></sub><span class="cmss-10x-x-109">, we can select a basis. Due to the construction of </span><span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmmi-6">i</span></sub></sub><span class="cmss-10x-x-109">, its basis will consist of eigenvectors.</span></p>
<p><span class="cmss-10x-x-109">Since </span><span class="cmmi-10x-x-109">V </span>= <span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmr-6">1</span></sub></sub> + ⋅⋅⋅ + <span class="cmmi-10x-x-109">U</span><sub><span class="cmmi-8">λ</span><sub><span class="cmmi-6">k</span></sub></sub><span class="cmss-10x-x-109">, the union of of such bases </span><span class="cmbx-10x-x-109">u</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,…,</span><span class="cmbx-10x-x-109">u</span><sub><span class="cmmi-8">n</span></sub> <span class="cmss-10x-x-109">will be a basis for </span><span class="cmmi-10x-x-109">V </span><span class="cmss-10x-x-109">.</span></p>
</div>
</div>
<p><span class="cmss-10x-x-109">Even though this theorem does not give us any useful recipes on how to diagonalize a matrix, it provides us with an extremely valuable insight: diagonalization is equivalent to finding an eigenvector basis. This is not always possible, but when it is, we are cooking with gas.</span></p>
<p><span class="cmss-10x-x-109">In the next chapter, we will take a deep dive into this topic, providing multiple ways to simplify matrices. If our journey in linear algebra is akin to a mountain climb, we will reach the peak soon.</span></p>
</section>
<section id="summary5" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_93"><span class="titlemark"><span class="cmss-10x-x-109">6.4 </span></span> <span id="x1-1110007.4"></span><span class="cmss-10x-x-109">Summary</span></h2>
<p><span class="cmss-10x-x-109">In this chapter, we’ve veered into the theory side of math once again. This time, it was about </span><span class="cmssi-10x-x-109">eigenvalues </span><span class="cmss-10x-x-109">and </span><span class="cmssi-10x-x-109">eigenvectors </span><span class="cmss-10x-x-109">of a matrix, that is, scalars </span><span class="cmmi-10x-x-109">λ </span><span class="cmss-10x-x-109">and vectors </span><span class="cmbx-10x-x-109">x </span><span class="cmss-10x-x-109">for which</span></p>
<div class="math-display">
<img src="../media/file621.png" class="math-display" alt=" n×n Ax = λx, A ∈ ℝ "/>
</div>
<p><span class="cmss-10x-x-109">hold.</span></p>
<p><span class="cmss-10x-x-109">Just like most mathematical objects, this might seem daunting at first, but geometrically, this means that in the direction </span><span class="cmbx-10x-x-109">x</span><span class="cmss-10x-x-109">, the linear transformation </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">is the same as a stretching by </span><span class="cmmi-10x-x-109">λ</span><span class="cmss-10x-x-109">. In practice, we can find eigenvectors by solving the so-called </span><span class="cmssi-10x-x-109">characteristic equation</span></p>
<div class="math-displa">
<img src="../media/file622.png" width="150" class="math-display" alt="det(A − λI) = 0 "/>
</div>
<p><span class="cmss-10x-x-109">for </span><span class="cmmi-10x-x-109">λ</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">What are eigenvalues used for? There are tons of applications, but one stands out: according to </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch012.xhtml#x1-110004r38"><span class="cmssi-10x-x-109">38</span></a><span class="cmss-10x-x-109">, if you can build a basis from the eigenvectors of the matrix </span><span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup><span class="cmss-10x-x-109">, then you can find a </span><span class="cmmi-10x-x-109">T </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">such that </span><span class="cmmi-10x-x-109">T</span><sup><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmmi-10x-x-109">AT </span><span class="cmss-10x-x-109">is diagonal. This process is extremely useful. For one, multiplication with diagonal matrices is fast and simple, and we prefer to do it whenever we can. For another, diagonalization reveals a ton about the internal structure of the underlying linear transformation.</span></p>
<p><span class="cmss-10x-x-109">We’ve left this chapter with a multitude of questions. How do we find eigenvalues? What kind of matrices are diagonalizable? If a matrix is diagonalizable, how can we find such a form?</span></p>
<p><span class="cmss-10x-x-109">We’ll answer all of these in the next chapter. Be warned: we are approaching the pinnacle of linear algebra. The next chapter might be our heaviest one yet. Just like the final stretch before reaching the peaks of Mount Everest. However, you have my total confidence. If you are here, you can climb it.</span></p>
<p><span class="cmss-10x-x-109">Let’s go!</span></p>
</section>
<section id="problems5" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_94"><span class="titlemark"><span class="cmss-10x-x-109">6.5 </span></span> <span id="x1-1120007.5"></span><span class="cmss-10x-x-109">Problems</span></h2>
<p><span class="cmssbx-10x-x-109">Problem 1. </span><span class="cmss-10x-x-109">Compute the eigenvalues of the matrices</span></p>
<div class="math-display">
<img src="../media/file623.png" class="math-display" alt=" ⌊ ⌋ ⌊ ⌋ | 4 1 − 1| | 2 1 1| A = |⌈ 1 3 1 |⌉ , B = |⌈ 1 2 1|⌉, − 1 1 2 1 1 2 "/>
</div>
<p><span class="cmss-10x-x-109">and find an eigenvector for every eigenvalue.</span></p>
<p><span class="cmssbx-10x-x-109">Problem 2. </span><span class="cmss-10x-x-109">Let </span><span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">be an upper or lower triangular matrix. Show that the eigenvalues of </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">are its diagonal elements.</span></p>
<p><span class="cmssbx-10x-x-109">Problem 3. </span><span class="cmss-10x-x-109">Let </span><span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">be a square matrix. Show that</span></p>
<img src="../media/file624.png" class="math-display" alt="det(A − λI ) " width="150"/>
<p><span class="cmss-10x-x-109">is a polynomial of degree </span><span class="cmmi-10x-x-109">n </span><span class="cmss-10x-x-109">in </span><span class="cmmi-10x-x-109">λ</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">This is the characteristic polynomial that we have talked about, and we have even mentioned this fact. However, we omitted the proof, so here’s your chance to fill the gap.</span></p>
<p><span class="cmssbx-10x-x-109">Problem 4. </span><span class="cmss-10x-x-109">Let </span><span class="cmmi-10x-x-109">A </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">n</span></sup><span class="cmss-10x-x-109">, </span><span class="cmmi-10x-x-109">B </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">×</span><span class="cmmi-8">m</span></sup><span class="cmss-10x-x-109">, and </span><span class="cmmi-10x-x-109">C </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><sup><span class="cmmi-8">m</span><span class="cmsy-8">×</span><span class="cmmi-8">m</span></sup> <span class="cmss-10x-x-109">arbitrary matrices, and we define the so-called </span><span class="cmssi-10x-x-109">block matrix</span></p>
<div class="math-display">
<img src="../media/file625.png" class="math-display" alt=" ⌊ ⌋ ⌈A B ⌉ (n+m )× (n+m ) D = 0 C ∈ ℝ . "/>
</div>
<p><span class="cmss-10x-x-109">Show that if </span><span class="cmmi-10x-x-109">λ </span><span class="cmss-10x-x-109">is an eigenvalue of </span><span class="cmmi-10x-x-109">A </span><span class="cmss-10x-x-109">or an eigenvalue of </span><span class="cmmi-10x-x-109">B</span><span class="cmss-10x-x-109">, then it’s also an eigenvalue of </span><span class="cmmi-10x-x-109">C</span><span class="cmss-10x-x-109">.</span></p>
</section>
<section id="join-our-community-on-discord6" class="level3 likesectionHead">
<h2 class="likesectionHead sigil_not_in_toc" id="sigil_toc_id_95"><span id="x1-113000"></span><span class="cmss-10x-x-109">Join our community on Discord</span></h2>
<p><span class="cmss-10x-x-109">Read this book alongside other users, Machine Learning experts, and the author himself. Ask questions, provide solutions to other readers, chat with the author via Ask Me Anything sessions, and much more. Scan the QR code or visit the link to join the community.</span> <a href="https://packt.link/math" class="url"><span class="cmtt-10x-x-109">https://packt.link/math</span></a></p>
<p><img src="../media/file1.png" width="85" alt="PIC"/></p>
</section>
</section>
</body>
</html>