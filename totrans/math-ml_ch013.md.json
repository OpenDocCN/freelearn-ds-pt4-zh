["```py\nimport numpy as np \ndef power_iteration( \n    A: np.ndarray, \n    n_max_steps: int = 100000, \n    convergence_threshold: float = 1e-10, \n    x_init: np.ndarray = None, \n    normalize: bool = False \n): \n    #x0022;\"/span> \n    Performs the power iteration method to find an approximation of the dominant eigenvector \n    of a square matrix. \n\n    Parameters \n    ---------- \n    A : np.ndarray \n        A square matrix whose dominant eigenvector is to be computed. \n    n_max_steps : int, optional \n        The maximum number of iterations to perform. Default is 100000\\. \n    convergence_threshold : float, optional \n        The convergence threshold for the difference between successive approximations. \n        Default is 1e-10\\. \n    x_init : np.ndarray, optional \n        The initial guess for the eigenvector. If None, a random vector is used. \n        Default is None. \n    normalize : bool, optional \n        If True, the resulting vector is normalized to unit length. Default is False. \n\n    Returns \n    ------- \n    np.ndarray \n        The approximate dominant eigenvector of the matrix ‘A‘. \n\n    Raises \n    ------ \n    ValueError \n        If the input matrix ‘A‘ is not square. \n    #x0022;\"/span> \n\n    n, m = A.shape \n\n    # checking the validity of the input \n    if n != m: \n        raise ValueError(\"/span>the matrix A must be square \n\n    # reshaping or defining the initial vector \n    if x_init is not None: \n        x = x_init.reshape(-1, 1) \n    else: \n        x = np.random.normal(size=(n, 1)) \n\n    # performing the iteration \n    for step in range(n_max_steps): \n        x_transformed = A @ x    # applying the transform \n        x_new = x_transformed / np.linalg.norm(x_transformed, ord=np.inf)    # scaling the result \n\n        # quantifying the difference between the new and old vector \n        diff = np.linalg.norm(x - x_new) \n        x = x_new \n\n        # stopping the iteration in case of convergence \n        if diff /span> convergence_threshold: \n            break \n\n    # normalizing the result if required \n    if normalize: \n        return x / np.linalg.norm(x) \n\n    return x\n```", "```py\nA = np.array([[2, 1], [1, 2]]) \nu_1 = power_iteration(A, normalize=True) \nu_1\n```", "```py\narray([[0.70710678], \n      [0.70710678]])\n```", "```py\nA @ u_1 / u_1\n```", "```py\narray([[3.], \n      [3.]])\n```", "```py\ndef get_orthogonal_complement_projection(u: np.ndarray): \n    #x0022;\"/span> \n    Compute the projection matrix onto the orthogonal complement of the vector u. \n\n    This function returns a projection matrix P such that for any vector v, \n    P @ v is the projection of v onto the subspace orthogonal to u. \n\n    Parameters \n    ---------- \n    u : np.ndarray \n        A 1D or 2D array representing the vector u. It will be reshaped to a column vector. \n\n    Returns \n    ------- \n    np.ndarray \n        The projection matrix onto the orthogonal complement of u. This matrix \n        has shape (n, n), where n is the length of u. \n    #x0022;\"/span> \n\n    u = u.reshape(-1, 1) \n    n, _ = u.shape \n    return np.eye(n) - u @ u.T / np.linalg.norm(u, ord=2)**2\n```", "```py\ndef find_eigenvectors(A: np.ndarray, x_init: np.ndarray): \n    #x0022;\"/span> \n    Find the eigenvectors of the matrix A using the power iteration method. \n\n    This function computes the eigenvectors of the matrix A by iteratively \n    applying the power iteration method and projecting out previously found \n    eigenvectors to find orthogonal eigenvectors. \n\n    Parameters \n    ---------- \n    A : np.ndarray \n        A square matrix of shape (n, n) for which eigenvectors are to be computed. \n\n    x_init : np.ndarray \n        A 1D array representing the initial vector used for the power iteration. \n\n    Returns \n    ------- \n    List[np.ndarray] \n        A list of eigenvectors, each represented as a 1D numpy array of length n. \n    #x0022;\"/span> \n\n    n, _ = A.shape \n    eigenvectors = [] \n\n    for _ in range(n): \n        ev = power_iteration(A, x_init=x_init) \n        proj = get_orthogonal_complement_projection(ev) \n        x_init = proj @ x_init \n        x_init = x_init / np.linalg.norm(x_init, ord=np.inf) \n        eigenvectors.append(ev) \n\n    return eigenvectors\n```", "```py\nA = np.array([[2.0, 1.0], [1.0, 2.0]]) \nx_init = np.random.rand(2, 1) \nfind_eigenvectors(A, x_init)\n```", "```py\n[array([[1.], \n       [1.]]), \n array([[ 1.], \n       [-1.]])]\n```", "```py\ndef diagonalize_symmetric_matrix(A: np.ndarray, x_init: np.ndarray): \n    #x0022;\"/span> \n    Diagonalize a symmetric matrix A using its eigenvectors. \n\n    Parameters \n    ---------- \n    A : np.ndarray \n        A symmetric matrix of shape (n, n) to be diagonalized. The matrix should \n        be square and symmetric. \n\n    x_init : np.ndarray \n        A 1D array representing the initial guess for the power iteration. \n\n    Returns \n    ------- \n    Tuple[np.ndarray, np.ndarray] containing: \n        - U : np.ndarray \n            A matrix of shape (n, n) whose columns are the normalized eigenvectors \n            of A. \n        - np.ndarray \n            A diagonal matrix (n, n) of the eigenvalues of A, computed as U @ A @ U.T. \n    #x0022;\"/span> \n\n    eigenvectors = find_eigenvectors(A, x_init) \n    U = np.hstack(eigenvectors) / np.linalg.norm(np.hstack(eigenvectors), axis=0, ord=2) \n    return U, U @ A @ U.T \n\ndiagonalize_symmetric_matrix(A, x_init)\n```", "```py\n(array([[ 0.70710678,  0.70710678], \n       [ 0.70710678, -0.70710678]]), \n array([[ 3.00000000e+00, -3.57590301e-11], \n       [-3.57589164e-11,  1.00000000e+00]]))\n```", "```py\ndef projection_coeff(x: np.ndarray, to: np.ndarray): \n    #x0022;\"/span> \n    Compute the scalar coefficient for the projection of vector x onto vector to. \n\n    Parameters \n    ---------- \n    x : np.ndarray \n        A 1D array representing the vector onto which the projection is computed. \n\n    to : np.ndarray \n        A 1D array representing the vector onto which x is being projected. \n\n    Returns \n    ------- \n    float \n        The scalar coefficient representing the projection of x onto to. \n    #x0022;\"/span> \n    return np.dot(x, to)/np.dot(to, to)\n```", "```py\nfrom typing import List\n\ndef projection(x: np.ndarray, to: List[np.ndarray], return_coeffs: bool = True):\n    \"\"\"\n    Computes the orthogonal projection of a vector `x` onto the subspace \n    spanned by a set of vectors `to`.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        A 1D array representing the vector to be projected onto the subspace.\n\n    to : List[np.ndarray]\n        A list of 1D arrays, each representing a vector spanning the subspace\n        onto which `x` is projected.\n\n    return_coeffs : bool, optional, default=True\n        If True, the function returns the list of projection coefficients.\n        If False, only the projected vector is returned.\n\n    Returns\n    -------\n    Tuple[np.ndarray, List[float]] or np.ndarray\n        - If `return_coeffs` is True, returns a tuple where the first element\n        is the projected vector and\n          the second element is a list of the projection coefficients\n          for each vector in `to`.\n        - If `return_coeffs` is False, returns only the projected vector.\n    \"\"\"\n\n    p_x = np.zeros_like(x)\n    coeffs = []\n\n    for e in to:\n        coeff = projection_coeff(x, e)\n        coeffs.append(coeff)\n        p_x += coeff*e\n\n    if return_coeffs:\n        return p_x, coeffs\n    else:\n        return p_x\n```", "```py\ndef QR(A: np.ndarray): \n    #x0022;\"/span> \n    Computes the QR decomposition of matrix A using the Gram-Schmidt \n    orthogonalization process. \n\n    Parameters \n    ---------- \n    A : np.ndarray \n        A 2D array of shape (n, m) representing the matrix to be decomposed. \n        The matrix A should have full column rank for a valid QR decomposition. \n\n    Returns \n    ------- \n    Tuple[np.ndarray, np.ndarray] \n        - Q : np.ndarray \n            An orthogonal matrix of shape (n, m), whose columns are orthonormal. \n        - R : np.ndarray \n            An upper triangular matrix of shape (m, m), representing the coefficients of the \n            linear combinations of the columns of A. \n    #x0022;\"/span> \n    n, m = A.shape \n\n    A_columns = [A[:, i] for i in range(A.shape[1])] \n    Q_columns, R_columns = [], [] \n\n    Q_columns.append(A_columns[0]) \n    R_columns.append([1] + (m-1)*[0]) \n\n    for i, a in enumerate(A_columns[1:]): \n        p, coeffs = projection(a, Q_columns, return_coeffs=True) \n        next_q = a - p \n        next_r = coeffs + [1] + max(0, m - i - 2)*[0] \n\n        Q_columns.append(next_q) \n        R_columns.append(next_r) \n\n    # assembling Q and R from its columns \n    Q, R = np.array(Q_columns).T, np.array(R_columns).T \n\n    # normalizing Q’s columns \n    Q_norms = np.linalg.norm(Q, axis=0) \n    Q = Q/Q_norms \n    R = np.diag(Q_norms) @ R \n    return Q, R\n```", "```py\nA = np.random.rand(3, 3) \nQ, R = QR(A)\n```", "```py\nnp.allclose(A, Q @ R)\n```", "```py\nTrue\n```", "```py\nnp.allclose(Q.T @ Q, np.eye(3))\n```", "```py\nTrue\n```", "```py\nnp.allclose(R, np.triu(R))\n```", "```py\nTrue\n```", "```py\ndef QR_algorithm(A: np.ndarray, n_iter: int = 1000): \n    #x0022;\"/span> \n    Computes the QR algorithm to find the eigenvalues of a matrix A. \n\n    Parameters \n    ---------- \n    A : np.ndarray \n        A square matrix of shape (n, n) for which the eigenvalues are to be computed. \n\n    n_iter : int, optional, default=1000 \n        The number of iterations to run the QR algorithm. \n        More iterations may lead to more accurate results, \n        but the algorithm typically converges quickly. \n\n    Returns \n    ------- \n    np.ndarray \n        A matrix that has converged, where the diagonal elements are the eigenvalues of the \n        original matrix A. \n        The off-diagonal elements should be close to zero. \n    #x0022;\"/span> \n\n    for _ in range(n_iter): \n        Q, R = QR(A) \n        A = R @ Q \n\n    return A\n```", "```py\nA = np.array([[2.0, 1.0], [1.0, 2.0]]) \nQR_algorithm(A)\n```", "```py\narray([[3.00000000e+00, 2.39107046e-16], \n      [0.00000000e+00, 1.00000000e+00]])\n```", "```py\nA = np.array([[0.0, 1.0], [1.0, 0.0]]) \nQR_algorithm(A)\n```", "```py\narray([[0., 1.], \n      [1., 0.]])\n```"]