- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functions
  prefs: []
  type: TYPE_NORMAL
- en: '”Mathematicians are like Frenchmen: whatever you say to them they translate
    into their own language and forthwith it is something entirely different.”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — Johann Wolfgang von Goethe
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It’s time we tackle the next big subject of machine-learning-math: functions
    and calculus. What do we have to do with functions?'
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve seen before, a predictive model is nothing but a multivariate parametric
    function. Linear regression? Ax. Logistic regression? σ(Ax). Neural networks?
    A sequence of σ(Ax)-s, and a multitude of other layers.
  prefs: []
  type: TYPE_NORMAL
- en: But it’s not just the description of models, it’s fitting them to the data.
    Say, for a simple linear regression model, “training” is minimizing the mean squared
    error; that is, finding
  prefs: []
  type: TYPE_NORMAL
- en: '![ n 1-∑ 2 argmina,b∈ℝn (axi + b − yi), i=1 ](img/file851.png)'
  prefs: []
  type: TYPE_IMG
- en: where x[i] is the training data, and y[i] is the ground truth. This is done
    via differentiation, one of humanity’s most essential inventions. (Whether we
    can call mathematical discoveries inventions is a matter of constant debate.)
  prefs: []
  type: TYPE_NORMAL
- en: For a function f(x), its derivative at x[0] is defined by
  prefs: []
  type: TYPE_NORMAL
- en: '![f ′(x0) = lim f-(x)−-f(x0), x→x0 x − x0 ](img/file852.png)'
  prefs: []
  type: TYPE_IMG
- en: 'describing the rate of change in terms of x . There’s a lot to unravel: what
    is that strange lim[x→x[0]] symbol? What do the ratio ![f(x)−f(x0)- x−x0](img/file853.png)
    represent? We’ll get to all of it in due time. The gist is, differentiation is
    the driving force of gradient descent, the number one algorithm for training neural
    networks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But it does not end here either. Differentiation has an equally important counterpart:
    integration. The formula'
  prefs: []
  type: TYPE_NORMAL
- en: '![∫ b f(x)dx a ](img/file854.png)'
  prefs: []
  type: TYPE_IMG
- en: is called the integral of f(x), describing the signed area under its graph.
    Integration is not as prevalent in practice, but it’s an essential tool for theory.
    For instance, half of probability theory is built around it. Say, the famous expected
    value is defined in terms of an integral; as are several notable probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next couple of chapters, we’ll dive deep into calculus, the theory of
    univariate functions. Why? Because even though machine learning is multivariate,
    the ideas we develop here will serve as the foundations for all the math to come.
    Let’s get to work!
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Functions in theory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Everyone has an intuitive understanding of what functions are. At one point
    or another, all of us have encountered this concept. For most of us, a function
    is a curve drawn with a continuous line onto a representation of the Cartesian
    coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file855.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: Definitely looks like a function'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in mathematics, intuitions can often lead us to false conclusions.
    Often, there is a difference between what something is and how you think about
    it – what your mental models are. To give an example from a real-life scenario
    in machine learning, consider the following piece of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Suppose that you wrote this function, and it is in your codebase somewhere.
    Depending on our needs, we might think of it as cross-entropy loss, but in reality,
    this is a 579-character-long string in the Python language, eventually processed
    by an interpreter. However, when working with it, we often use a mental model
    that compacts this information into easily usable chunks, like the three words
    cross-entropy loss. When we reason about high-level processes like training a
    neural network, abstractions such as this allow us to move further and step bigger.
  prefs: []
  type: TYPE_NORMAL
- en: But sometimes, things don’t go our way. When this function throws an error and
    crashes the computations, cross-entropy loss will not cut it. Then, it is time
    to unravel the definition and put everything under a magnifying glass. What could
    have hindered your thinking before is now essential.
  prefs: []
  type: TYPE_NORMAL
- en: These principles are also true for theory, not just for practice. Mathematics
    is a balancing act between logical precision and a clear understanding, two often
    contradicting objectives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go back to our starting point: functions in a mathematical sense. One
    possible mental model, as mentioned, is a curve drawn with a continuous line.
    It allows us to reason about functions visually and intuitively answer some questions.
    However, this particular mental model can go very wrong.'
  prefs: []
  type: TYPE_NORMAL
- en: To give an example, does Figure 9.2 depict a function?
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file856.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: Is this a function?'
  prefs: []
  type: TYPE_NORMAL
- en: Even though this curve is drawn with a continuous line, this is not a function,
    as there are values with multiple images, which cannot happen. To avoid confusion
    later, we have to build the foundations of our discussion if we were to talk about
    mathematical objects. In this chapter, our goal is to establish a basic dictionary
    to properly understand the objects we are working with in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.1 The mathematical definition of a function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s dive straight into the deep water and see the exact mathematical definition
    of functions! (Don’t worry if you don’t understand it for the first read. I’ll
    explain everything in detail. This is the usual experience when encountering a
    definition for the first time.)
  prefs: []
  type: TYPE_NORMAL
- en: Definition 35\. (Functions)
  prefs: []
  type: TYPE_NORMAL
- en: Let X and Y be two sets. The subset f ⊆X ×Y is a function if for every x ∈X,
    there is at most one y ∈Y such that (x,y) ∈f.
  prefs: []
  type: TYPE_NORMAL
- en: (The set X ×Y denotes the Cartesian product of X and Y . If you are not familiar
    with the concept, check out Appendix C.)
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we introduce the notation
  prefs: []
  type: TYPE_NORMAL
- en: '![f : X → Y, ](img/file857.png)'
  prefs: []
  type: TYPE_IMG
- en: which is short for f is a function from X to Y .
  prefs: []
  type: TYPE_NORMAL
- en: Note that X and Y can be any set. In the examples we encounter, these are usually
    the set of real numbers or vectors, but there is no such restriction.
  prefs: []
  type: TYPE_NORMAL
- en: To visualize the definition, we can draw two sets and arrows pointing from elements
    of X to elements of Y . Each element (x,y) ∈f represents an arrow, pointing from
    x to y.
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file858.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: A function, as arrows between two sets'
  prefs: []
  type: TYPE_NORMAL
- en: The only criteria is that there can be at most one arrow starting from any x
    ∈X. This is why Figure 9.2 is not a function.
  prefs: []
  type: TYPE_NORMAL
- en: Defining a function as a subset is mathematically precise but very low level.
    To be more useful, we can introduce an abstraction by defining functions with
    formulas, such as
  prefs: []
  type: TYPE_NORMAL
- en: '![f : ℝ → ℝ, x ↦→ x2, ](img/file859.png)'
  prefs: []
  type: TYPE_IMG
- en: or simply f(x) = x² in short. This is how most of us think about functions when
    working with them.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are familiar with the definition, we should get to know some of
    the most basic structural properties of functions.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.2 Domain and image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We saw that, in essence, functions are arrows between sets. At this point, we
    don’t know anything useful about them. When is a function invertible? How can
    we find their minima and maxima? Why should we even care? Probably you have a
    bunch of questions here. Slowly but surely, we will cover all of these.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first steps in our journey are concerned with the sets from which arrows
    start and point. There are two important sets in a function’s life: its domain
    and image.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition 36\. (Domain and image of functions)
  prefs: []
  type: TYPE_NORMAL
- en: 'Let f : X →Y be a function. The sets'
  prefs: []
  type: TYPE_NORMAL
- en: '![domf := {x ∈ X : there is an y ∈ Y such that f(x) = y} ⊆ X ](img/file860.png)'
  prefs: []
  type: TYPE_IMG
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '![im f := {y ∈ Y : there is an x ∈ X such that f(x) = y} ⊆ Y ](img/file861.png)'
  prefs: []
  type: TYPE_IMG
- en: are respectively called the domain and image of f.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the domain is the subset of X where arrows start; the image
    is the subset of Y where arrows point.
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file862.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.4: The domain and image of a function'
  prefs: []
  type: TYPE_NORMAL
- en: Why is this important? For one, these are directly related to the invertibility
    of a function. If you consider the ”points and arrows” mental representation,
    inverting a function is as simple as flipping the direction of the arrows. When
    can we do it? In some cases, doing this might not even result in a function, as
    Figure 9.5 shows.
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file863.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5: This function is not invertible, as reversing the arrows doesn’t
    give a well-defined function'
  prefs: []
  type: TYPE_NORMAL
- en: To put the study of functions on top of solid theoretical foundations, we introduce
    the concept of injective, surjective and bijective functions.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 37\. (Surjective, injective, and bijective functions)
  prefs: []
  type: TYPE_NORMAL
- en: 'Let f : X →Y be an arbitrary function.'
  prefs: []
  type: TYPE_NORMAL
- en: (a) f is injective if for every y ∈Y there is at most one x ∈X such that f(x)
    = y. (We often say that an injective f is a one-to-one function.)
  prefs: []
  type: TYPE_NORMAL
- en: (b) f is surjective if for every y ∈Y there is an x ∈X such that f(x) = y. (We
    often say that a surjective f maps X onto Y .)
  prefs: []
  type: TYPE_NORMAL
- en: (c) f is bijective if it is injective and surjective.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of arrows, injectivity means that every element of the image has at
    most one arrow pointing to it, while surjectivity is that every element indeed
    has at least one arrow. When both are satisfied, we have a bijective function,
    one that can be inverted properly. When the inverse f^(−1) exists, it is unique.
    Both f^(−1) ∘f and f ∘f^(−1) equal to the identity function in their respective
    domains.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see some concrete examples! For instance,
  prefs: []
  type: TYPE_NORMAL
- en: '![f : ℝ → ℝ, f(x) = x2 ](img/file864.png)'
  prefs: []
  type: TYPE_IMG
- en: is not injective nor surjective. (Ponder on this a bit if you don’t understand
    it right away. It helps if you draw a figure.)
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file865.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6: Injective, surjective, and bijective functions'
  prefs: []
  type: TYPE_NORMAL
- en: On the contrary,
  prefs: []
  type: TYPE_NORMAL
- en: '![ 3 g : ℝ → ℝ, g(x) = x ](img/file866.png)'
  prefs: []
  type: TYPE_IMG
- en: is both, so it is bijective and invertible with inverse g^(−1)(x) = x^(1∕3).
  prefs: []
  type: TYPE_NORMAL
- en: Invertible functions behave nicely, and from a certain perspective, they are
    much better to work with.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.3 Operations with functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Functions, just like numbers, have operations defined on them. Two numbers can
    be multiplied and added together, but can you do the same with functions? Without
    any difficulty, they can be added together and multiplied with a scalar as
  prefs: []
  type: TYPE_NORMAL
- en: '![(f + g)(x) := f(x)+ g(x ), (cf)(x) := cf(x), ](img/file867.png)'
  prefs: []
  type: TYPE_IMG
- en: where c is some scalar.
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file868.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.7: Composing functions'
  prefs: []
  type: TYPE_NORMAL
- en: Another essential operation is composition. Let’s consider the famous logistic
    regression for a minute! The estimator itself is defined by
  prefs: []
  type: TYPE_NORMAL
- en: '![f(x) = σ(ax + b), ](img/file869.png)'
  prefs: []
  type: TYPE_IMG
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '![σ(x) = ---1--- 1 + e−x ](img/file870.png)'
  prefs: []
  type: TYPE_IMG
- en: 'is the sigmoid function. The estimator f(x) is the composition of two functions:
    l(x) = ax + b and the sigmoid function, so'
  prefs: []
  type: TYPE_NORMAL
- en: '![f(x) = σ(l(x)). ](img/file871.png)'
  prefs: []
  type: TYPE_IMG
- en: As σ maps ℝ onto [0,1], we can think about f(x) as the probability that x belongs
    to the positive class.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.7 shows the points-and-arrows illustration of function composition.
  prefs: []
  type: TYPE_NORMAL
- en: To give one more example, a neural network with several hidden layers is just
    the composition of a bunch of functions. The output of each layer is fed into
    the next one, which is exactly how composition is defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, if f : Y →Z and g : X →Y are two functions, then their composition
    is formally defined by'
  prefs: []
  type: TYPE_NORMAL
- en: '![f ∘ g : X → Z, x ↦→ f (g(x )). ](img/file872.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that in (f ∘g)(x) = f(g(x)), the function g is applied first. The order
    of application is often a point of confusion, so keep this in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Remark 8\. (Function addition as composition)
  prefs: []
  type: TYPE_NORMAL
- en: Given the functions
  prefs: []
  type: TYPE_NORMAL
- en: '![f : X → ℝ, g : X → ℝ, ](img/file873.png)'
  prefs: []
  type: TYPE_IMG
- en: we can define their sum by
  prefs: []
  type: TYPE_NORMAL
- en: '![(f + g)(x) := f(x)+ g(x ). ](img/file874.png)'
  prefs: []
  type: TYPE_IMG
- en: Believe it or not, this is yet another form of function composition. Why? Define
    the function add by
  prefs: []
  type: TYPE_NORMAL
- en: '![add : X × X → ℝ, add(x1,x2) = x1 + x2\. ](img/file875.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we can write addition as
  prefs: []
  type: TYPE_NORMAL
- en: '![(f + g )(x) = add(f(x),g(x)). ](img/file876.png)'
  prefs: []
  type: TYPE_IMG
- en: Composition is an extremely powerful tool. In fact, so powerful that given a
    small set of cleverly defined building blocks, “almost every function” can be
    obtained as the composition of these blocks. (I put “almost every function” in
    quotes because if we want to stay mathematically precise here, long detours are
    needed. To keep ourselves focused, let’s allow ourselves to be a little hand-wavy
    here.)
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.4 Mental models of functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have seen that functions are defined as arrows drawn between elements
    of two sets. This, although being mathematically rigorous, does not give us useful
    mental models to reason about them. As you’ll surely see by the end of our journey,
    in mathematics, the key is often to find the right way to look at things.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding functions, one of the most common and useful mental models is their
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'If f : ℝ →ℝ is a function mapping a real number to a real number, we can visualize
    it using its graph, defined by'
  prefs: []
  type: TYPE_NORMAL
- en: '![graph(f) := {(x,f(x)) : x ∈ ℝ }. ](img/file877.png)'
  prefs: []
  type: TYPE_IMG
- en: This set of points can be drawn in the two-dimensional plane. For instance,
    in the case of the famous rectified linear unit (ReLU)
  prefs: []
  type: TYPE_NORMAL
- en: '![ ( |{ ReLU (x ) = 0 if x <0 |( x if 0 ≤ x, ](img/file878.png)'
  prefs: []
  type: TYPE_IMG
- en: the graph looks like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![PIC](img/file879.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.8: Graph of the ReLU function'
  prefs: []
  type: TYPE_NORMAL
- en: Although identifying functions with their graphs can be useful, it is not generalizable
    for more complex mappings. Visualizing it is challenging if the function’s domain
    and image are not the set of real numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file880.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.9: Functions as a transformation of the space. Here, the vectors of
    the space are rotated around the origin'
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with neural networks, probably the best way to think about functions
    (that is, layers in this context) is as transformations of the underlying feature
    space. A simple example is a rotation in the two-dimensional Euclidean plane,
    as Figure 9.9 shows.
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file881.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.10: Examplar applications of image transformations available in Albumenations'
  prefs: []
  type: TYPE_NORMAL
- en: Image transformations provide a set of more complex examples. You rarely think
    about image blur as a transformation between spaces, but this is the case. After
    all, an image is just a huge vector in some vector space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Image operations as transformations, as done by the Albumentations ( [https://albumentations.ai/](https://albumentations.ai/))
    library. Source of the image: Albumentations: Fast and Flexible Image Augmentations
    by Alexander Buslaev, Vladimir I. Iglovikov, Eugene Khvedchenya, Alex Parinov,
    Mikhail Druzhinin and Alexandr A. Kalinin ( [https://www.mdpi.com/2078-2489/11/2/125](https://www.mdpi.com/2078-2489/11/2/125)).'
  prefs: []
  type: TYPE_NORMAL
- en: In essence, a neural network is simply a stack of transformations, each taking
    its input from the output of the previous one. As you’ll see, what makes them
    special is that the transformations are not hand-engineered but learned from the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 Functions in practice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our study of functions, we started from arrows between sets and ended up
    with mental models such as formulas and graphs. For pure mathematical purposes,
    these models are perfectly enough to conduct thorough investigations. However,
    once we leave the realm of theory and start putting things into practice, we must
    think about how functions are represented in programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, functions are defined using a straightforward syntax. For instance,
    this is how the square(x) = x² function can be implemented.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The result is an object of type function. (In Python, everything is an object.)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Functions are called using the () operator.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Python is well-known for its simplicity, and functions are no exception. However,
    this doesn’t mean that they are limited in features – quite the contrary: you
    can achieve a lot with the clever use of functions.'
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.1 Operations on functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three operations that we want to do on functions: composition, addition,
    multiplication. The easiest way is to call the functions themselves and fall back
    to the operations defined for the number types. To see an example, let’s implement
    the cube(x) = x³ function and add/multiply/compose it with square.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: However, there is a major problem. If you take another look at the function
    operations, you can notice that they take functions and return functions. For
    instance, the composition is defined by
  prefs: []
  type: TYPE_NORMAL
- en: '![compose : f,g ↦→ (x ↦→ f(g(x))) , ◟-----◝◜----◞ the composed function ](img/file882.png)'
  prefs: []
  type: TYPE_IMG
- en: with a function as a result. We did no such thing by simply passing the return
    value to the outer function. There is no function object to represent the composition.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, functions are first-class objects, meaning that we can pass them
    to other functions and return them from functions. (This is an absolutely fantastic
    feature, but if this is the first time you’ve encountered this, it might take
    some time to get used to.)
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we can implement the compose function above by using the first-class function
    feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Addition and multiplication can be done just like this. (They are even assigned
    as an exercise problem Section [9.4](ch017.xhtml#problems8).)
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.2 Functions as callable objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The standard way of doing function definitions is not a good fit for an application
    that is essential for us: parametrized functions. Think about the case of linear
    functions of the form ax + b, where a and b are parameters. On the first try,
    we can do something like this.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Passing the parameters as arguments seems to work, but there are serious underlying
    issues. For instance, functions can have a lot of parameters. Even if we compact
    parameters into multidimensional arrays, we might need to deal with dozens of
    such arrays. Passing them around manually is error-prone, and we usually have
    to work with multiple functions. For example, neural networks are composed of
    several layers. Each layer is a parameterized function, and their composition
    yields a predictive model.
  prefs: []
  type: TYPE_NORMAL
- en: We can solve this issue by applying the classical object-oriented principle
    of encapsulation, implementing functions as callable objects. In Python, we can
    do this by implementing the magic __call__ method for the class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This way, we can store, access, and modify the parameters using attributes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Since there can be a lot of parameters, we should implement a method that collects
    them together in a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Interactivity is one of the most useful features of Python. In practice, we
    frequently find ourselves working in the REPL, inspecting objects and calling
    functions by hand. We often add a concise string representation for our classes
    for these situations.
  prefs: []
  type: TYPE_NORMAL
- en: By default, printing a Linear instance results in a cryptic message.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This is not very useful. Besides the class name and its location in the memory,
    we haven’t received any information. We can change this by implementing the __repr__
    method responsible for returning the string representation for our object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This looks much better! Adding a pretty string representation seems like a small
    thing, but this can go a long way when doing machine learning engineering in the
    trenches.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.3 Function base class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Linear class that we have just seen is only the tip of the iceberg. There
    are hundreds of function families that are used in machine learning. We’ll implement
    many of them eventually, and to keep the interfaces consistent, we are going to
    add a base class from which all others will be inherited.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: With this, we can implement functions and function families in the following
    way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Even though we haven’t implemented the parameters method for the Sigmoid class,
    it is inherited from the base class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: For now, let’s keep the base class as simple as possible. During the course
    of this book, we’ll progressively enhance the Function base class to cover all
    the methods a neural network and its layers need. (For instance, gradients.)
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.4 Composition in the object-oriented way
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recall how we did function composition (in Section [9.2.1](ch017.xhtml#operations-on-functions))
    when working with plain Python functions? Syntactically, that can work with our
    Function class as well, although there is a huge issue: the return value is not
    a Function type.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This kind of composition doesn’t inherit the interface we need.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'To fix the issue, we implement function composition as a child of the Function
    base class. Recall that composition is a function, taking two functions as input
    and returning one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![compose : f, g ↦→ (◟x-↦→-f◝(g◜-(x-)))◞ . the composed function ](img/file889.png)'
  prefs: []
  type: TYPE_IMG
- en: Keeping this in mind, this is how we can do composition.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: (Note that due to how composition is defined, we iterate through the list of
    functions in the reverse order. That’s because (f ∘g)(x) = f(g(x)), we apply g
    first.)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This way, we get to keep the Function interface.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 9.3 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we’ve learned what functions really are, I bet your world is a bit
    shaken. Functions as graphs drawn with continuous lines, sure. Maybe even expressions
    like f(x) = x² + 1\. But functions as dots and arrows?
  prefs: []
  type: TYPE_NORMAL
- en: Surprisingly, the dot-and-arrow representation is the closest to the true definition.
    Graphs and expressions come after that. This is what we’ve learned in this chapter,
    and by now, I feel like a magician. I’ve shown you mathematical objects and revealed
    that, deep inside, they are not what you think. We did this with vectors, matrices,
    and now, with functions.
  prefs: []
  type: TYPE_NORMAL
- en: Along with the “what’s behind the curtain?” tricks, putting theory into practice
    also became an established pattern for us. So, we’ve used object-oriented Python
    to get a taste of what a function is like.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll turn our lenses to an even higher level of magnification. For us,
    the most important functions map numbers to numbers. But what’s a number? Even
    in programming languages, we have several different number types, like int-s,
    float-s, double-s, and so on. These are deeply rooted in math, and familiarity
    with the structure of numbers is a must for every developer and engineer.
  prefs: []
  type: TYPE_NORMAL
- en: See you in the next chapter!
  prefs: []
  type: TYPE_NORMAL
- en: 9.4 Problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Problem 1\. Which of these functions are injective, surjective, or bijective?
    Find the inverse of bijective functions.
  prefs: []
  type: TYPE_NORMAL
- en: '(a) f : ℝ → (0,∞), x→e^x (b) g : ℝ → [0,∞), x→x² (c) h : [0,∞) → [0,∞), x→x²
    (d) sin : ℝ → [0,1], x→sin(x) (e) tan : ℝ →ℝ, x→tan(x),'
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem 2\. Find a function f : ℝ →ℝ such that (f ∘f)(x) = −x.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem 3\. Can any real function g : ℝ →ℝ be obtained as g = f ∘f for some
    f : ℝ →ℝ?'
  prefs: []
  type: TYPE_NORMAL
- en: Problem 4\. Following the example of the composition Section [9.2.1](ch017.xhtml#operations-on-functions),
    implement
  prefs: []
  type: TYPE_NORMAL
- en: the add function, taking f and g, returning f + g,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the mul function, taking f and g, returning fg,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and the div function, taking f and g, returning f∕g.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file1.png)'
  prefs: []
  type: TYPE_IMG
