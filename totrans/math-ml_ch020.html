<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8"/>
  <meta name="generator" content="pandoc"/>
  <title>ch020.xhtml</title>
  <style>
  </style>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
</head>
<body epub:type="bodymatter">
<section id="differentiation" class="level2 chapterHead">
<h1 class="chapterHead"><span class="titlemark"><span class="cmss-10x-x-109">12</span></span><br/>
<span id="x1-19700014"></span><span class="cmss-10x-x-109">Differentiation</span></h1>
<blockquote class="packt_quote">
<p><span class="cmssi-10x-x-109">I turn with terror and horror from this lamentable scourge of continuous functions with no derivatives.</span></p>
<div class="flushright">
<p><span class="cmss-10x-x-109">— Charles Hermite</span></p>
</div>
</blockquote>
<p><span class="cmss-10x-x-109">In the history of science, a few milestones are as significant as inventing the wheel. Even among these, differentiation is a highlight. With the invention of calculus, Newton created mechanics as we know it. Differentiation</span> <span id="dx1-197001"></span><span class="cmss-10x-x-109">is all over science and engineering, and as it turns out, it’s a key component of machine learning as well.</span></p>
<p><span class="cmss-10x-x-109">Why? Because of optimization! As it turns out, the extremal points of a function can be characterized in terms of their derivative, and these extremal points can be iteratively found via gradient descent.</span></p>
<p><span class="cmss-10x-x-109">In this chapter, we’ll learn what differentiation is, what its origins are, and most importantly, how to use it in practice. Let’s go!</span></p>
<section id="differentiation-in-theory" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_173"><span class="titlemark"><span class="cmss-10x-x-109">12.1 </span></span> <span id="x1-19800014.1"></span><span class="cmss-10x-x-109">Differentiation in theory</span></h2>
<p><span class="cmss-10x-x-109">Instead of jumping straight into the mathematical definition, let’s start our discussion with a straightforward example: a point-like object moving along a straight line. Its movement is fully described by the time-distance plot (</span><span class="cmssi-10x-x-109">Figure </span><a href="#"><span class="cmssi-10x-x-109">12.1</span></a><span class="cmss-10x-x-109">), which shows its distance from the starting point at a given time.</span></p>
<div class="minipage">
<p><img src="../media/file1145.png" width="369" alt="PIC"/> <span id="x1-198001r1"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.1: Time-distance plot of our moving object</span> </span>
</div>
<p><span class="cmss-10x-x-109">Our goal is to calculate the object’s velocity at a given time. In high school, we learned that</span></p>
<div class="math-display">
<img src="../media/file1146.png" class="math-display" alt=" distance average velocity = -time---. "/>
</div>
<p><span class="cmss-10x-x-109">To put</span> <span id="dx1-198002"></span><span class="cmss-10x-x-109">this into a quantitative form, if </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">t</span>) <span class="cmss-10x-x-109">denotes the time-distance function, and </span><span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">/span&gt;<span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">2</span></sub> <span class="cmss-10x-x-109">are two arbitrary points in time, then</span> </span></p>
<div class="math-displa">
<img src="../media/file1147.png" width="450" class="math-display" alt="average velocity between t and t = f-(t2)−--f(t1). 1 2 t2 − t1 "/>
</div>
<p><span class="cmss-10x-x-109">Expressions like</span> <img src="../media/file1148.png" class="frac" data-align="middle" alt="f(t2t2)−−ft(1t1)-"/> <span class="cmss-10x-x-109">are called </span><span class="cmssi-10x-x-109">differential quotients</span><span class="cmss-10x-x-109">. Note</span> <span id="dx1-198003"></span><span class="cmss-10x-x-109">that if the object moves backwards, the average velocity is negative. (As opposed to </span><span class="cmssi-10x-x-109">speed</span><span class="cmss-10x-x-109">, which is always positive. Velocity is speed and direction.)</span></p>
<p><span class="cmss-10x-x-109">The average velocity has a simple geometric interpretation: if you replace the object’s motion with a constant velocity motion moving with that average, you’ll end up at exactly the same place. In graphical terms, this is equivalent of connecting </span>(<span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">1</span></sub><span class="cmmi-10x-x-109">,f</span>(<span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">1</span></sub>)) <span class="cmss-10x-x-109">and </span>(<span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">2</span></sub><span class="cmmi-10x-x-109">,f</span>(<span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">2</span></sub>)) <span class="cmss-10x-x-109">with a single line.</span></p>
<p><span class="cmss-10x-x-109">The average velocity is just the slope of this line. This is visualized by </span><span class="cmssi-10x-x-109">Figure </span><a href="#"><span class="cmssi-10x-x-109">12.2</span></a><span class="cmss-10x-x-109">.</span></p>
<div class="minipage">
<p><img src="../media/file1149.png" width="456" alt="PIC"/> <span id="x1-198004r2"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.2: Average velocity between </span><span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">1</span></sub> <span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">t</span><sub><span class="cmr-8">2</span></sub> </span>
</div>
<p><span class="cmss-10x-x-109">Given this, we can calculate the exact velocity at a single time point</span><span id="dx1-198005"></span> <span class="cmmi-10x-x-109">t</span><span class="cmss-10x-x-109">, which we’ll denote with </span><span class="cmmi-10x-x-109">v</span>(<span class="cmmi-10x-x-109">t</span>)<span class="cmss-10x-x-109">. The idea is simple: the average speed in the small time-interval between </span><span class="cmmi-10x-x-109">t </span><span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">t </span>+ Δ<span class="cmmi-10x-x-109">t </span><span class="cmss-10x-x-109">should get closer and closer to </span><span class="cmmi-10x-x-109">v</span>(<span class="cmmi-10x-x-109">t</span>) <span class="cmss-10x-x-109">if </span>Δ<span class="cmmi-10x-x-109">t </span><span class="cmss-10x-x-109">is small enough. (</span>Δ<span class="cmmi-10x-x-109">t </span><span class="cmss-10x-x-109">can be negative as well.)</span></p>
<p><span class="cmss-10x-x-109">So,</span></p>
<div class="math-display">
  <span>
    v(t) = lim<sub>Δt → 0</sub> <span style="white-space: nowrap;">(f(t + Δt) - f(t)) / Δt</span>,
  </span>
  <span class="math-label" style="float: right; margin-left: 1em;">(12.1)</span>
</div>

<p><span class="cmss-10x-x-109">if the above limit exists. </span><span class="cmssi-10x-x-109">Figure </span><a href="#"><span class="cmssi-10x-x-109">12.3</span></a> <span class="cmss-10x-x-109">illustrates the limit defined by (</span><a href="#"><span class="cmss-10x-x-109">12.1</span></a><span class="cmss-10x-x-109">). There, we can see that as </span>Δ<span class="cmmi-10x-x-109">t </span><span class="cmss-10x-x-109">gets closer and closer to </span>0<span class="cmss-10x-x-109">, the slope of the line connecting</span> (<span class="cmmi-10x-x-109">t,f</span>(<span class="cmmi-10x-x-109">t</span>)) <span class="cmss-10x-x-109">to </span>(<span class="cmmi-10x-x-109">t </span>+ Δ<span class="cmmi-10x-x-109">t,f</span>(<span class="cmmi-10x-x-109">t </span>+ Δ<span class="cmmi-10x-x-109">t</span>)) <span class="cmss-10x-x-109">gets closer and closer to the slope of the tangent.</span></p>
<div class="minipage">
<p><img src="../media/file1151.png" width="456" alt="PIC"/> <span id="x1-198006r3"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.3: Approximating the speed at </span><span class="cmmi-10x-x-109">t</span> </span>
</div>
<p><span class="cmss-10x-x-109">Following our geometric intuition, we see that </span><span class="cmmi-10x-x-109">v</span>(<span class="cmmi-10x-x-109">t</span>) <span class="cmss-10x-x-109">is simply the slope of the tangent line of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">at </span><span class="cmmi-10x-x-109">t</span><span class="cmss-10x-x-109">. Keeping this in mind, we are ready to introduce the formal definition.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-198007r54"></span> <span class="cmbx-10x-x-109">Definition 54.</span> </span><span class="cmbx-10x-x-109">(Differentiability)</span></p>
<p>Let <span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→</span><span class="msbm-10x-x-109">ℝ </span>be an arbitrary function. We say that <span class="cmmi-10x-x-109">f </span>is <span class="cmti-10x-x-109">differentiable </span>at <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub> <span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ </span>if the limit</p>
<div class="math-display">
<img src="../media/file1152.png" class="math-display" alt="-df-(x0) = lim f(x)-−-f(x0) dx x→x0 x − x0 "/>
</div>
<p>exists. If so, this is called the <span class="cmti-10x-x-109">derivative </span>of <span class="cmmi-10x-x-109">f </span>at <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>.</p>
</div>
<p><span class="cmss-10x-x-109">In other words, if </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">describes a time-distance function of a moving object, then the derivative is simply its velocity.</span></p>
<p><span class="cmss-10x-x-109">Similar to</span> <span id="dx1-198008"></span><span class="cmss-10x-x-109">continuity, differentiability is a local</span> <span id="dx1-198009"></span><span class="cmss-10x-x-109">property. However, we’ll be more interested in functions that are differentiable (almost) everywhere. In those cases, the derivative is a function, often denoted with </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>)<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">Sometimes it is confusing that </span><span class="cmmi-10x-x-109">x </span><span class="cmss-10x-x-109">can denote the variable of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">and the exact point where the derivative is taken. Here is a quick glossary of terms to clarify the difference between derivative and derivative function.</span></p>
<ul>
<li><img src="../media/file1153.png" width="20" data-align="middle" alt="df- dx"/>(<span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>)<span class="cmss-10x-x-109">: derivative of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">with respect to the variable </span><span class="cmmi-10x-x-109">x </span><span class="cmss-10x-x-109">at the point </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmss-10x-x-109">. This is a </span><span class="cmssi-10x-x-109">scalar</span><span class="cmss-10x-x-109">, also denoted with </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>)<span class="cmss-10x-x-109">.</span></li>
<li><img src="../media/file1154.png" width="20" data-align="middle" alt="df- dx"/><span class="cmss-10x-x-109">: derivative function of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">with respect to the variable </span><span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">. This is a </span><span class="cmssi-10x-x-109">function</span><span class="cmss-10x-x-109">, also denoted with </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup><span class="cmss-10x-x-109">.</span></li>
</ul>
<div class="newtheorem">
<p><span class="head"> <span id="x1-198010r9"></span> <span class="cmbx-10x-x-109">Remark 9.</span> </span><span class="cmbx-10x-x-109">(Variables in the limit)</span></p>
<p>Don’t let the change in notation from <span class="cmmi-10x-x-109">t </span>and <span class="cmmi-10x-x-109">t </span>+ Δ<span class="cmmi-10x-x-109">t </span>to <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub> and <span class="cmmi-10x-x-109">x </span>confuse you; the limit that defines the derivative means exactly the same as before:</p>
<div class="math-display">
<img src="../media/file1155.png" class="math-display" alt=" f(x0 + h)− f(x0) f(x)− f(x0) lhim→0 -------h---------= xli→mx0 ---x−--x----. 0 "/>
</div>
<p>Also note that</p>
<div class="math-display">
<img src="../media/file1156.png" class="math-display" alt="lim f(x)−-f(x0)-= lim f(x0)−--f(x). x→x0 x− x0 x→x0 x0 − x "/>
</div>
<p>On occasion, we might even use <span class="cmmi-10x-x-109">x </span>and <span class="cmmi-10x-x-109">y </span>instead of <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub> and <span class="cmmi-10x-x-109">x</span>, writing</p>
<div class="math-display">
<img src="../media/file1157.png" class="math-display" alt=" ′ f-(x-)−-f(y) f (x) = yli→mx x − y "/>
</div>
<p>We’ll use whichever is more convenient.</p>
</div>
<p><span class="cmss-10x-x-109">Let’s see some examples!</span></p>
<p><span class="cmssbx-10x-x-109">Example 1. </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">. For any </span><span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">, we have</span></p>
<div class="math-display">
<img src="../media/file1158.png" class="math-display" alt="lim f(x)−-f(y)-= lim x-−-y = 1. y→x x − y y→x x − y "/>
</div>
<p><span class="cmss-10x-x-109">Thus, </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">x </span><span class="cmss-10x-x-109">is differentiable everywhere and its derivative is the constant function </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) = 1<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmssbx-10x-x-109">Example 2. </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">x</span><sup><span class="cmr-8">2</span></sup><span class="cmss-10x-x-109">. Here, we have</span></p>
<div class="math-display">
<img src="../media/file1159.png" class="math-display" alt=" f(x)− f (y ) x2 − y2 lim -----------= lim ------- y→x x− y y→x x − y (x-−-y)(x+-y) = yli→mx x − y = yli→mx x + y = 2x. "/>
</div>
<p><span class="cmss-10x-x-109">So, </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">x</span><sup><span class="cmr-8">2</span></sup> <span class="cmss-10x-x-109">is differentiable everywhere and </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) = 2<span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">. Later, when talking about elementary functions, we’ll see the general case </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">x</span><sup><span class="cmmi-8">k</span></sup><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmssbx-10x-x-109">Example 3. </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">jxj </span><span class="cmss-10x-x-109">at </span><span class="cmmi-10x-x-109">x </span>= 0<span class="cmss-10x-x-109">. For this, we have</span></p>
<div class="math-display">
<img src="../media/file1160.png" class="math-display" alt="lim f(0)−-f-(y-)= lim |y|. y→0 0− y y→0 y "/>
</div>
<p><span class="cmss-10x-x-109">Since</span></p>
<div class="math-display">
<img src="../media/file1161.png" class="math-display" alt=" ( |{ 1 if y &gt;0, |y|-= y |( − 1 if y &lt;0, "/>
</div>
<p><span class="cmss-10x-x-109">this limit </span><span class="cmssi-10x-x-109">does not exist</span><span class="cmss-10x-x-109">, as it is illustrated on </span><span class="cmssi-10x-x-109">Figure </span><a href="#"><span class="cmssi-10x-x-109">12.4</span></a><span class="cmss-10x-x-109">. This is our first example of a</span> <span id="dx1-198011"></span><span class="cmss-10x-x-109">non-differentiable function. However, </span><span class="cmmi-10x-x-109">jxj </span><span class="cmss-10x-x-109">is differentiable everywhere else.</span></p>
<p><span class="cmss-10x-x-109">It is worth drawing a picture here to enhance our understanding of differentiability. Recall that the value of the derivative at a given point equals the slope of the tangent line to the function’s graph.</span></p>
<p><span class="cmss-10x-x-109">Since </span><span class="cmmi-10x-x-109">jxj </span><span class="cmss-10x-x-109">has a sharp corner at </span>0<span class="cmss-10x-x-109">, the tangent line is not well-defined.</span></p>
<div class="minipage">
<p><img src="../media/file1162.png" width="456" alt="PIC"/> <span id="x1-198012r4"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.4: Tangent planes of </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">jxj </span><span class="cmss-10x-x-109">at </span>0 </span>
</div>
<p><span class="cmss-10x-x-109">Differentiability means no sharp corners in the graph, so differentiable functions are</span> <span id="dx1-198013"></span><span class="cmss-10x-x-109">often called </span><span class="cmssi-10x-x-109">smooth</span><span class="cmss-10x-x-109">. This is one reason we prefer differentiable functions: the rate of change is tractable.</span></p>
<p><span class="cmss-10x-x-109">Next, we’ll see an equivalent definition of differentiability, involving local approximation with a linear function. From this perspective, differentiability means manageable behavior: no wrinkles, corners, or sharp changes in value.</span></p>
<section id="equivalent-forms-of-differentiation" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_174"><span class="titlemark"><span class="cmss-10x-x-109">12.1.1 </span></span> <span id="x1-19900014.1.1"></span><span class="cmss-10x-x-109">Equivalent forms of differentiation</span></h3>
<p><span class="cmss-10x-x-109">To </span><span class="cmssi-10x-x-109">really </span><span class="cmss-10x-x-109">understand derivatives and differentiation, we are</span><span id="dx1-199001"></span> <span class="cmss-10x-x-109">going to take a look at it from another point of view: local linear approximations.</span></p>
<p><span class="cmss-10x-x-109">Approximation is a very natural idea in mathematics. Say, have you ever thought about what happens when you punch</span> sin(2<span class="cmmi-10x-x-109">.</span>18) <span class="cmss-10x-x-109">into a calculator? We cannot express the function</span> sin <span class="cmss-10x-x-109">with finitely many additions and multiplications, so we have to </span><span class="cmssi-10x-x-109">approximate </span><span class="cmss-10x-x-109">it. In practice, we use functions of the form</span></p>
<div class="math-display">
<img src="../media/file1163.png" class="math-display" alt="p(x) = p0 + p1x+ ⋅⋅⋅+ pnxn, "/>
</div>
<p><span class="cmss-10x-x-109">which, can be evaluated easily. These are called </span><span class="cmssi-10x-x-109">polynomials</span><span class="cmss-10x-x-109">, and they are just a finite combination of additions and multiplications.</span></p>
<p><span class="cmss-10x-x-109">Can we just replace functions with polynomials to make computations easier? (Even at the cost of perfect precision.)</span></p>
<p><span class="cmss-10x-x-109">It turns out that we can, and differentiation is one way to do so. In essence, the derivative desribes the best </span><span class="cmssi-10x-x-109">local approximation with a linear function</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">The following theorem makes this clear.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-199002r77"></span> <span class="cmbx-10x-x-109">Theorem 77.</span> </span><span class="cmbxti-10x-x-109">(Differentiation as a local linear approximation)</span></p>
<p><span class="cmti-10x-x-109">Let </span><span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→</span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">be an arbitrary function. The following are equivalent.</span></p>
<p><span class="cmti-10x-x-109">(a) </span><span class="cmmi-10x-x-109">f </span><span class="cmti-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmti-10x-x-109">.</span></p>
<p><span class="cmti-10x-x-109">(b) there is an </span><span class="cmmi-10x-x-109">α </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">such that</span></p>
<div class="math-display">
  <span>
    f(x) = f(x₀) + α(x − x₀) + o(|x − x₀|) <i>as</i> x → x₀.
  </span>
  <span class="math-label" style="float: right; margin-left: 1em;">(12.2)</span>
</div>

</div>
<p><span class="cmss-10x-x-109">Recall</span> <span id="dx1-199003"></span><span class="cmss-10x-x-109">that the small O notation (see </span><span class="cmssi-10x-x-109">Definition </span><a href="ch019.xhtml#x1-190013r52"><span class="cmssi-10x-x-109">52</span></a><span class="cmss-10x-x-109">) means that the function is an order of magnitude smaller around </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub> <span class="cmss-10x-x-109">than the function </span><span class="cmsy-10x-x-109">|</span><span class="cmmi-10x-x-109">x </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmsy-10x-x-109">|</span><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">If exists, the </span><span class="cmmi-10x-x-109">α </span><span class="cmss-10x-x-109">in the above theorem is the derivative </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>)<span class="cmss-10x-x-109">. In other words, </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) <span class="cmss-10x-x-109">can be locally written as</span></p>
<div class="math-display">
  <span>
    f(x<sub>0</sub>) + f′(x<sub>0</sub>)(x − x<sub>0</sub>) + o(|x − x<sub>0</sub>|).
  </span>
  <span class="math-label" style="float: right; margin-left: 1em;">(12.3)</span>
</div>

<div id="tcolobox-241" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. </span><span class="cmss-10x-x-109">To show the equivalence of two statements, we have to prove that differentiation implies the desired property and vice versa. Although this might seem complicated, it is straightforward and entirely depends on how functions can be written as their limit plus an error term (</span><span class="cmssi-10x-x-109">Theorem </span><a href="ch019.xhtml#x1-191002r71"><span class="cmssi-10x-x-109">71</span></a><span class="cmss-10x-x-109">).</span></p>
<p><span class="cmssi-10x-x-109">(a)</span> ⇒ <span class="cmssi-10x-x-109">(b)</span><span class="cmss-10x-x-109">. The existence of the limit</span></p>
<div class="math-display">
<img src="../media/file1165.png" class="math-display" alt=" f-(x)−-f(x0) ′ lxi→mx0 x − x0 = f (x0) "/>
</div>
<p><span class="cmss-10x-x-109">implies that we can write the slope of the approximating tangent in the form</span></p>
<div class="math-display">
<img src="../media/file1166.png" class="math-display" alt="f(x) − f(x0) ′ ---x-−-x----= f(x0) + error(x), 0 "/>
</div>
<p><span class="cmss-10x-x-109">where</span> lim<sub><span class="cmmi-8">x</span><span class="cmsy-8">→</span><span class="cmmi-8">x</span><sub><span class="cmr-6">0</span></sub></sub>error(<span class="cmmi-10x-x-109">x</span>) = 0<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">With some simple algebra, we obtain</span></p>
<div class="math-display">
<img src="../media/file1167.png" class="math-display" alt="f(x) = f (x0 )+ f′(x0)(x − x0)+ error(x)(x − x0). "/>
</div>
<p><span class="cmss-10x-x-109">Since the error term tends to zero as </span><span class="cmmi-10x-x-109">x </span><span class="cmss-10x-x-109">goes to </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmss-10x-x-109">,</span> error(<span class="cmmi-10x-x-109">x</span>)(<span class="cmmi-10x-x-109">x </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>) = <span class="cmmi-10x-x-109">o</span>(<span class="cmsy-10x-x-109">|</span><span class="cmmi-10x-x-109">x </span><span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmsy-10x-x-109">|</span>)<span class="cmss-10x-x-109">, which is what we wanted to show.</span></p>
<p><span class="cmssi-10x-x-109">(b)</span> ⇒ <span class="cmssi-10x-x-109">(a)</span><span class="cmss-10x-x-109">. Now, repeat what we did in the previous part, just in reverse order. We can rewrite</span></p>
<div class="math-display">
<img src="../media/file1169.png" class="math-display" alt="f (x) = f (x0) + α(x − x0)+ o(|x− x0|) "/>
</div>
<p><span class="cmss-10x-x-109">in the form</span></p>
<div class="math-display">
<img src="../media/file1170.png" class="math-display" alt="f(x)−-f-(x0) x− x = α + o(1), 0 "/>
</div>
<p><span class="cmss-10x-x-109">which, according to what we have used before, implies that</span></p>
<div class="math-display">
<img src="../media/file1171.png" class="math-display" alt=" "/>
</div>
<p><span class="cmss-10x-x-109">So, </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub> <span class="cmss-10x-x-109">and its derivative is </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>) = <span class="cmmi-10x-x-109">α</span><span class="cmss-10x-x-109">.</span></p>
</div>
</div>
<p><span class="cmss-10x-x-109">One huge advantage of this form is that it will be easily generalized to</span><span id="dx1-199004"></span> <span class="cmss-10x-x-109">multivariate functions. Even though we are far from it, we can get a glimpse. Multivariate functions map </span><span class="cmssi-10x-x-109">vectors </span><span class="cmss-10x-x-109">to scalars, so the ratio</span></p>
<div class="math-display">
<img src="../media/file1172.png" class="math-display" alt="f(x)-−-f(x0), x,x0 ∈ ℝn x − x0 "/>
</div>
<p><span class="cmss-10x-x-109">is not even defined. (Since we can’t divide with a vector.) However, the expression</span></p>
<div class="math-display">
<img src="../media/file1173.png" class="math-display" alt="f (x ) = f (x0 )+ ∇f (x0)T(x− x0)+ o(∥x − x0∥) "/>
</div>
<p><span class="cmss-10x-x-109">makes perfect sense, since </span><span class="cmsy-10x-x-109">∇</span><span class="cmmi-10x-x-109">f</span>(<span class="cmbx-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>)<sup><span class="cmmi-8">T</span></sup> (<span class="cmbx-10x-x-109">x </span><span class="cmsy-10x-x-109">−</span><span class="cmbx-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>) <span class="cmss-10x-x-109">is a scalar. Here, </span><span class="cmsy-10x-x-109">∇</span><span class="cmmi-10x-x-109">f</span>(<span class="cmbx-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>) <span class="cmss-10x-x-109">denotes the </span><span class="cmssi-10x-x-109">gradient </span><span class="cmss-10x-x-109">of </span><span class="cmmi-10x-x-109">f</span><span class="cmss-10x-x-109">, that is, the multivariable version of derivatives. </span><span class="cmsy-10x-x-109">∇</span><span class="cmmi-10x-x-109">f</span>(<span class="cmbx-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>) <span class="cmss-10x-x-109">is an n-dimensional vector. Don’t worry if you are not familiar with this notation, we’ll cover everything in due time. The take-home message is that this alternative definition will be more convenient for us in the future.</span></p>
<p><span class="cmss-10x-x-109">Another advantage of the locally-best-approximation mindset is that </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch020.xhtml#x1-199002r77"><span class="cmssi-10x-x-109">77</span></a> <span class="cmss-10x-x-109">can be generalized to higher derivatives.</span></p>
<p><span class="cmss-10x-x-109">Check out the following theorem.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-199005r78"></span> <span class="cmbx-10x-x-109">Theorem 78.</span> </span><span class="cmbxti-10x-x-109">(Taylor’s theorem)</span></p>
<p><span class="cmti-10x-x-109">Let </span><span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→</span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">function that is </span><span class="cmmi-10x-x-109">n </span><span class="cmti-10x-x-109">times differentiable at </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmti-10x-x-109">. Then</span></p>
<div class="math-display">
<img src="../media/file1174.png" class="math-display" alt=" ∑n f(k)(x0) f (x ) = -------(x − x0)k + o(|x− x0|n) k=0 k! "/>
</div>
<p><span class="cmti-10x-x-109">holds, where </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmr-8">(</span><span class="cmmi-8">k</span><span class="cmr-8">)</span></sup>(<span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>) <span class="cmti-10x-x-109">denotes the </span><span class="cmmi-10x-x-109">k</span><span class="cmti-10x-x-109">-th derivative of </span><span class="cmmi-10x-x-109">f </span><span class="cmti-10x-x-109">at </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmti-10x-x-109">.</span></p>
</div>
<p><span class="cmss-10x-x-109">(Note that the zeroth derivative </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmr-8">(0)</span></sup> <span class="cmss-10x-x-109">equals to </span><span class="cmmi-10x-x-109">f</span><span class="cmss-10x-x-109">.)</span></p>
<p><span class="cmss-10x-x-109">In other words, </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch020.xhtml#x1-199005r78"><span class="cmssi-10x-x-109">78</span></a> <span class="cmss-10x-x-109">says that if </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">is differentiable enough times, it can be written as a polynomial plus a small error term. For infinitely differentiable functions, Taylor’s theorem</span> <span id="dx1-199006"></span><span class="cmss-10x-x-109">gives rise to the famous Taylor expansion.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-199007r55"></span> <span class="cmbx-10x-x-109">Definition 55.</span> </span><span class="cmbx-10x-x-109">(Taylor expansion)</span></p>
<p>Let <span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→ </span><span class="msbm-10x-x-109">ℝ </span>be a function that is differentiable at <span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub> infinitely many times. The series defined by</p>
<div class="math-display">
<img src="../media/file1175.png" class="math-display" alt=" ∞ (k) f(x) ∼ ∑ f---(x0)(x− x )k k! 0 k=0 "/>
</div>
<p>is called the <span class="cmti-10x-x-109">Taylor expansion of </span><span class="cmmi-10x-x-109">f </span><span class="cmti-10x-x-109">around </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub>.</p>
</div>
<p><span class="cmss-10x-x-109">To give you an example, as </span>(<span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup>)<sup><span class="cmsy-8">′</span></sup> = <span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup><span class="cmss-10x-x-109">, the Taylor expansion of </span><span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup> <span class="cmss-10x-x-109">around </span>0 <span class="cmss-10x-x-109">is</span></p>
<div class="math-dispay">
<img src="../media/file1176.png" width="150" class="math-display" alt=" ∞ ex = ∑ 1-xk. k! k=0 "/>
</div>
<p><span class="cmss-10x-x-109">Note that the equality sign is not an accident: the Taylor expansion of</span><span id="dx1-199008"></span> <span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup> <span class="cmss-10x-x-109">equals </span><span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup><span class="cmss-10x-x-109">! (This is not always the case.) Now we see why </span><span class="cmmi-10x-x-109">e </span>= <span class="cmex-10x-x-109">∑</span> <sub><span class="cmmi-8">k</span><span class="cmr-8">=0</span></sub><sup><span class="cmsy-8">∞</span></sup><img src="../media/file1177.png" class="math" data-align="middle" alt="1k!"/><span class="cmss-10x-x-109">, as we hinted earlier when discussing sequences and series.</span></p>
<p><span class="cmss-10x-x-109">In other words,</span></p>
<div class="math-disply">
<img src="../media/file1178.png" width="150" class="math-display" alt=" x ∑n 1 k e ≈ k!x , k=0 "/>
</div>
<p><span class="cmss-10x-x-109">meaning that on any interval</span> [ <span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">α,α</span>] <span class="cmss-10x-x-109">and for any arbitrarily small </span><span class="cmmi-10x-x-109">𝜀/span&gt;0<span class="cmss-10x-x-109">,</span> </span></p>
<div class="math-dispay">
<img src="../media/file1179.png" width="150" class="math-display" alt=" ∑n |ex − -1xk| &lt;𝜀 k=0k! "/>
</div>
<p><span class="cmss-10x-x-109">holds if </span><span class="cmmi-10x-x-109">n </span><span class="cmss-10x-x-109">is large enough. In practice, this polynomial is evaluated to approximate the value of </span><span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup><span class="cmss-10x-x-109">.</span></p>
</section>
<section id="differentiation-and-continuity" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_175"><span class="titlemark"><span class="cmss-10x-x-109">12.1.2 </span></span> <span id="x1-20000014.1.2"></span><span class="cmss-10x-x-109">Differentiation and continuity</span></h3>
<p><span class="cmss-10x-x-109">As the following</span> <span id="dx1-200001"></span><span class="cmss-10x-x-109">theorem states, differentiation is a more strict condition than continuity.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-200002r79"></span> <span class="cmbx-10x-x-109">Theorem 79.</span> </span></p>
<p><span class="cmti-10x-x-109">Differentiable functions are continuous.</span></p>
<p><span class="cmti-10x-x-109">If </span><span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→</span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">a</span><span class="cmti-10x-x-109">, it is also continuous there.</span></p>
</div>
<div id="tcolobox-242" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. </span><span class="cmss-10x-x-109">We’ll use </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch020.xhtml#x1-199002r77"><span class="cmssi-10x-x-109">77</span></a> <span class="cmss-10x-x-109">to prove the result. With the general form (</span><a href="ch020.xhtml#x1-199002r77"><span class="cmss-10x-x-109">12.2</span></a><span class="cmss-10x-x-109">), we have</span></p>

<img src="../media/file1180.png" class="math-display" alt=" lim f (x) = lim (f(x )+ f′(x )(x− x ) + o(|x − x |)) = f(x ), x→x0 x→x0 0 0 0 0 0 " width="400"/>

<p><span class="cmss-10x-x-109">which shows the continuity of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">at </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub><span class="cmss-10x-x-109">.</span></p>
</div>
</div>
<p><span class="cmss-10x-x-109">Note that the previous theorem is not true the other way around: a function can be continuous, but not differentiable. (As the example </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">jxj </span><span class="cmss-10x-x-109">at </span><span class="cmmi-10x-x-109">x </span>= 0 <span class="cmss-10x-x-109">shows.)</span></p>
<p><span class="cmss-10x-x-109">This can be taken to the extremes: there are functions that are continuous everywhere but differentiable nowhere. One of the first examples was provided by Weierstrass (from the </span><a href="#"><span class="cmss-10x-x-109">Bolzano-Weierstrass theorem</span></a><span class="cmss-10x-x-109">). The function itself is defined by the infinite sum</span></p>
<div class="math-display">
<img src="../media/file1181.png" class="math-display" alt=" ∑∞ W (x) = ancos(bnπx), n=0 "/>
</div>
<p><span class="cmss-10x-x-109">where </span><span class="cmmi-10x-x-109">a </span><span class="cmsy-10x-x-109">∈ </span>(0<span class="cmmi-10x-x-109">,</span>1)<span class="cmss-10x-x-109">, </span><span class="cmmi-10x-x-109">b </span><span class="cmss-10x-x-109">is a positive odd integer, and </span><span class="cmmi-10x-x-109">ab/span&gt;1 + 3<span class="cmmi-10x-x-109">π∕</span>2<span class="cmss-10x-x-109">.</span> </span></p>
<p><span class="cmss-10x-x-109">I agree, this definition feels totally random, and you are probably wondering: how did the author come up with it? To get a grip on this function, imagine this as the superposition of cosine waves with smaller and smaller amplitude but higher and higher frequency. Remember that differentiation implies “no sharp corners”? This definition puts a sharp corner at every point on the real line.</span></p>
<p><span class="cmss-10x-x-109">Its graph is a fractal curve with self-similarity, as illustrated below.</span></p>
<div class="minipage">
<p><img src="../media/file1182.png" width="584" alt="PIC"/> <span id="x1-200003r5"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.5: Graph of the Weierstrass function. Source: </span> <a href="https://en.wikipedia.org/wiki/Weierstrass_function" class="url"><span class="cmtt-10x-x-109">https://en.wikipedia.org/wiki/Weierstrass_function</span></a> </span>
</div>
<p><span class="cmss-10x-x-109">Examples such as this inspired the opening quote of the section:</span></p>
<blockquote class="packt_quote">
<p><span class="cmssi-10x-x-109">I turn with terror and horror from this lamentable scourge of continuous functions with no derivatives. </span><span class="cmss-10x-x-109">— Charles Hermite</span></p>
</blockquote>
<p><span class="cmss-10x-x-109">19th-century mathematicians certainly did not think much about nondifferentiable functions. However, there are much more of them than</span><span id="dx1-200004"></span> <span class="cmss-10x-x-109">differentiable ones. We won’t go into the details, but amongst all continuous functions, the set of ones that are differentiable at at least one point is </span><span class="cmssi-10x-x-109">meagre</span><span class="cmss-10x-x-109">. Meagre is a proper technical term for sets, and although we don’t need to know what it means exactly, its name implies that it is extremely small.</span></p>
<p><span class="cmss-10x-x-109">Now that we understand what the derivative is, it’s time to put theory into practice. How do we compute derivatives, and how do we work with them in machine learning? We’ll see in the next section.</span></p>
</section>
</section>
<section id="differentiation-in-practice" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_176"><span class="titlemark"><span class="cmss-10x-x-109">12.2 </span></span> <span id="x1-20100014.2"></span><span class="cmss-10x-x-109">Differentiation in practice</span></h2>
<p><span class="cmss-10x-x-109">During our first encounter with differentiation, we saw that computing derivatives by the definition</span></p>
<div class="math-display">
<img src="../media/file1183.png" class="math-display" alt="f′(x0) = lim f(x0)−-f-(x-) x→x0 x0 − x "/>
</div>
<p><span class="cmss-10x-x-109">can be really hard in practice if we encounter convoluted functions such as </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = cos(<span class="cmmi-10x-x-109">x</span>)sin(<span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup>)<span class="cmss-10x-x-109">. Similar to convergent sequences and limits, using the definition of differentiation won’t get us far—the complexity piles on fast. So, we have to find ways to decompose the complexity into its fundamental building blocks.</span></p>
<section id="rules-of-differentiation" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_177"><span class="titlemark"><span class="cmss-10x-x-109">12.2.1 </span></span> <span id="x1-20200014.2.1"></span><span class="cmss-10x-x-109">Rules of differentiation</span></h3>
<p><span class="cmss-10x-x-109">First, we’ll look at</span> <span id="dx1-202001"></span><span class="cmss-10x-x-109">the simplest of operations: scalar multiplication, addition, multiplication, and division.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-202002r80"></span> <span class="cmbx-10x-x-109">Theorem 80.</span> </span><span class="cmbxti-10x-x-109">(Rules of differentiation)</span></p>
<p><span class="cmti-10x-x-109">Let </span><span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→ </span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">and </span><span class="cmmi-10x-x-109">g </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→ </span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">be two arbitrary functions and let </span><span class="cmmi-10x-x-109">x </span><span class="cmsy-10x-x-109">∈ </span><span class="msbm-10x-x-109">ℝ</span><span class="cmti-10x-x-109">. Suppose that both </span><span class="cmmi-10x-x-109">f </span><span class="cmti-10x-x-109">and </span><span class="cmmi-10x-x-109">g </span><span class="cmti-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">x</span><span class="cmti-10x-x-109">. Then</span></p>
<p><span class="cmti-10x-x-109">(a) </span>(<span class="cmmi-10x-x-109">cf</span>)<sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">cf</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) <span class="cmti-10x-x-109">for all </span><span class="cmmi-10x-x-109">c </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><span class="cmti-10x-x-109">,</span></p>
<p><span class="cmti-10x-x-109">(b) </span>(<span class="cmmi-10x-x-109">f </span>+ <span class="cmmi-10x-x-109">g</span>)<sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) + <span class="cmmi-10x-x-109">g</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>)<span class="cmti-10x-x-109">,</span></p>
<p><span class="cmti-10x-x-109">(c) </span>(<span class="cmmi-10x-x-109">fg</span>)<sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>)<span class="cmmi-10x-x-109">g</span>(<span class="cmmi-10x-x-109">x</span>) + <span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>)<span class="cmmi-10x-x-109">g</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) <span class="cmti-10x-x-109">(the product rule),</span></p>
<p><span class="cmti-10x-x-109">(d) </span><span class="big">(</span><img src="../media/file1185.png" class="math" data-align="middle" alt="f g"/><span class="big">)</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) = <img src="../media/file1187.png" width="150" data-align="middle" alt="f′(x)g(x)−-f(x)g′(x) g(x)2"/> <span class="cmti-10x-x-109">if </span><span class="cmmi-10x-x-109">g</span>(<span class="cmmi-10x-x-109">x</span>)<span class="cmmi-10x-x-109">≠</span>0 <span class="cmti-10x-x-109">(the quotient rule).</span></p>
</div>
<div id="tcolobox-243" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. (a) </span><span class="cmss-10x-x-109">and </span><span class="cmssi-10x-x-109">(b) </span><span class="cmss-10x-x-109">is a direct consequence of the </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch019.xhtml#x1-190011r70"><span class="cmssi-10x-x-109">70</span></a><span class="cmss-10x-x-109">.</span></p>
<p><span class="cmss-10x-x-109">To show </span><span class="cmssi-10x-x-109">(c)</span><span class="cmss-10x-x-109">, we have to do a bit of algebra:</span></p>

<img src="../media/file1188.png" class="math-display" alt="lim f(x)g(x)−-f-(y)g(y)-= lim f(x)g(x)−--f(y)g-(x-)+-f(y)g(x)−-f-(y)g(y)- y→x x − y x→y x − y f(x)g(x)− f(y)g (x ) f(y)g(x)− f (y)g (y) = lyim→x -------x−--y-------+ lxi→my -------x−-y-------- = lim [f(x)−-f(y)g(x)]+ f (y ) lim g(x)−-g(y)- y→x x − y x→y x − y = f′(x)g(x)+ f(x)g′(x), " width="450"/>
<p><span class="cmss-10x-x-109">from which </span><span class="cmssi-10x-x-109">(c) </span><span class="cmss-10x-x-109">follows.</span></p>
<p><span class="cmss-10x-x-109">For </span><span class="cmssi-10x-x-109">(d)</span><span class="cmss-10x-x-109">, we are going to start with the special case of </span>(1<span class="cmmi-10x-x-109">∕g</span>)<sup><span class="cmsy-8">′</span></sup><span class="cmss-10x-x-109">. We have</span></p>
<div class="math-display">
<img src="../media/file1189.png" class="math-display" alt=" g1(x) − g1(y) 1 g(y)− g (x ) lyim→x --x-−-y---= lyim→x g(x)g(y)---x−--y--- ′ = − g-(x-), g(x)2 "/>
</div>
<p><span class="cmss-10x-x-109">from which the general case follows by applying </span><span class="cmssi-10x-x-109">(c) </span><span class="cmss-10x-x-109">to </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">and </span>1<span class="cmmi-10x-x-109">∕g</span><span class="cmss-10x-x-109">.</span></p>
</div>
</div>
<p><span class="cmss-10x-x-109">There is one operation which we haven’t covered in the previous theorem: function composition. In the study of neural networks, composition plays an essential role. Each layer can be thought of as a function, which are composed together to form the entire network.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-202003r81"></span> <span class="cmbx-10x-x-109">Theorem 81.</span> </span><span class="cmbxti-10x-x-109">(Chain rule/Leibniz rule)</span></p>
<p><span class="cmti-10x-x-109">Let </span><span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ</span>→<span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">and </span><span class="cmmi-10x-x-109">g </span>: <span class="msbm-10x-x-109">ℝ</span>→<span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">be two arbitrary functions and let </span><span class="cmmi-10x-x-109">x </span><span class="cmsy-10x-x-109">∈ </span><span class="msbm-10x-x-109">ℝ</span><span class="cmti-10x-x-109">. Suppose that </span><span class="cmmi-10x-x-109">g </span><span class="cmti-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">x </span><span class="cmti-10x-x-109">and </span><span class="cmmi-10x-x-109">f </span><span class="cmti-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">g</span>(<span class="cmmi-10x-x-109">x</span>)<span class="cmti-10x-x-109">. Then</span></p>
<div class="math-display">
<img src="../media/file1192.png" class="math-display" alt=" ′ ′ ′ (f ∘g) (x) = f (g(x))g(x) "/>
</div>
<p><span class="cmti-10x-x-109">holds.</span></p>
</div>
<div id="tcolobox-244" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. </span><span class="cmss-10x-x-109">First, we</span> <span id="dx1-202004"></span><span class="cmss-10x-x-109">rewrite the differential quotient into the following form:</span></p>
<img src="../media/file1193.png" class="math-display" alt="lim f(g(x))−-f(g(y)) = lim f(g(x))−-f(g(y))g(x)-−-g(y) y→x x − y y→x g(x)− g(y) x − y f(g(x))− f(g(y)) g(x) − g(y) = lyim→x ---g(x)−-g(y)---xli→my ---x-−-y---. " width="450"/>
<p><span class="cmss-10x-x-109">Because </span><span class="cmmi-10x-x-109">g </span><span class="cmss-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">, it is also continuous there, so</span> lim<sub><span class="cmmi-8">y</span><span class="cmsy-8">→</span><span class="cmmi-8">x</span></sub><span class="cmmi-10x-x-109">g</span>(<span class="cmmi-10x-x-109">y</span>) = <span class="cmmi-10x-x-109">g</span>(<span class="cmmi-10x-x-109">x</span>)<span class="cmss-10x-x-109">. So, the first term can be rewritten as</span></p>

<img src="../media/file1194.png" class="math-display" alt="lim f(g(x-))-−-f(g(y))= lim f(y)−-f(g(x))-= f′(g(x)). y→x g(x) − g(y) y→g (x) y − g(x) " width="450"/>
<p><span class="cmss-10x-x-109">Since </span><span class="cmmi-10x-x-109">g </span><span class="cmss-10x-x-109">is differentiable at </span><span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">, the second term is </span><span class="cmmi-10x-x-109">g</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>)<span class="cmss-10x-x-109">. Thus, we have</span></p>
<div class="math-display">
<img src="../media/file1195.png" class="math-display" alt="lim f-(g(x-))-−-f(g(y))= f ′(g(x))g′(x), y→x x − y "/>
</div>
<p><span class="cmss-10x-x-109">which is what we had to show.</span></p>
</div>
</div>
<p><span class="cmss-10x-x-109">As neural networks are just huge composed functions, their derivative</span><span id="dx1-202005"></span> <span class="cmss-10x-x-109">is calculated with the repeated application of the chain rule. (Although the derivatives of its layers are vectors and matrices since they are multivariable functions.)</span></p>
</section>
<section id="derivatives-of-elementary-functions" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_178"><span class="titlemark"><span class="cmss-10x-x-109">12.2.2 </span></span> <span id="x1-20300014.2.2"></span><span class="cmss-10x-x-109">Derivatives of elementary functions</span></h3>
<p><span class="cmss-10x-x-109">Following the already familiar pattern, now we calculate the derivatives</span><span id="dx1-203001"></span> <span class="cmss-10x-x-109">for the most important class: elementary functions. There are a few that we will</span> <span id="dx1-203002"></span><span class="cmss-10x-x-109">encounter all the time, like in the mean squared error, cross-entropy, Kullback-Leibler divergence, etc.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-203003r82"></span> <span class="cmbx-10x-x-109">Theorem 82.</span> </span><span class="cmbxti-10x-x-109">(Derivatives of elementary functions)</span></p>
<p><span class="cmti-10x-x-109">(a)</span> (<span class="cmmi-10x-x-109">x</span><sup><span class="cmr-8">0</span></sup>)<sup><span class="cmsy-8">′</span></sup> = 0 <span class="cmti-10x-x-109">and</span> (<span class="cmmi-10x-x-109">x</span><sup><span class="cmmi-8">n</span></sup>)<sup><span class="cmsy-8">′</span></sup> = <span class="cmmi-10x-x-109">nx</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmti-10x-x-109">, where </span><span class="cmmi-10x-x-109">n </span><span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℤ </span><span class="cmsy-10x-x-109">∖ </span>0<span class="cmti-10x-x-109">,</span></p>
<p><span class="cmti-10x-x-109">(b) </span>(sin<span class="cmmi-10x-x-109">x</span>)<sup><span class="cmsy-8">′</span></sup> = cos<span class="cmmi-10x-x-109">x </span><span class="cmti-10x-x-109">and </span>(cos<span class="cmmi-10x-x-109">x</span>)<sup><span class="cmsy-8">′</span></sup> = <span class="cmsy-10x-x-109">−</span>sin<span class="cmmi-10x-x-109">x</span><span class="cmti-10x-x-109">,</span></p>
<p><span class="cmti-10x-x-109">(c)</span> (<span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup>)<sup><span class="cmsy-8">′</span></sup> = <span class="cmmi-10x-x-109">e</span><sup><span class="cmmi-8">x</span></sup><span class="cmti-10x-x-109">,</span></p>
<p><span class="cmti-10x-x-109">(d) </span>(log <span class="cmmi-10x-x-109">x</span>)<sup><span class="cmsy-8">′</span></sup> = <img src="../media/file1196.png" class="math" data-align="middle" alt="1 x"/><span class="cmti-10x-x-109">.</span></p>
</div>
<p><span class="cmss-10x-x-109">You don’t necessarily have to know how to prove these. I’ll include the proof of </span><span class="cmssi-10x-x-109">(a)</span><span class="cmss-10x-x-109">, but feel free to skip it, especially if this is your first encounter with calculus. What you have to remember, though, are the derivatives themselves. (However, I’ll refer back to this part when necessary.)</span></p>
<div id="tcolobox-245" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. (a) </span><span class="cmss-10x-x-109">It is easy to see that for </span><span class="cmmi-10x-x-109">n </span>= 0<span class="cmss-10x-x-109">, the derivative</span> (<span class="cmmi-10x-x-109">x</span><sup><span class="cmr-8">0</span></sup>)<sup><span class="cmsy-8">′</span></sup> = 0<span class="cmss-10x-x-109">. The case </span><span class="cmmi-10x-x-109">n </span>= 1 <span class="cmss-10x-x-109">is also simple: calculating the differential quotient shows that </span>(<span class="cmmi-10x-x-109">x</span>)<sup><span class="cmsy-8">′</span></sup> = 1<span class="cmss-10x-x-109">. For the case </span><span class="cmmi-10x-x-109">n </span><span class="cmsy-10x-x-109">≥ </span>2<span class="cmss-10x-x-109">, we are going to employ a small trick. Writing out the differential quotient for </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">x</span><sup><span class="cmmi-8">n</span></sup><span class="cmss-10x-x-109">, we obtain</span></p>
<div class="math-diplay">
<img src="../media/file1197.png" width="75" class="math-display" alt=" n n x--−-y- , x − y "/>
</div>
<p><span class="cmss-10x-x-109">which we want to simplify. If you don’t have a lot of experience in math, it might seem like magic, but </span><span class="cmmi-10x-x-109">x</span><sup><span class="cmmi-8">n</span></sup> <span class="cmsy-10x-x-109">−</span><span class="cmmi-10x-x-109">y</span><sup><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">can be written as</span></p>
<div class="math-isplay">
<img src="../media/file1198.png" width="450" class="math-display" alt="xn − yn = (x− y )(xn− 1 + xn− 2y + ⋅⋅⋅+ xyn− 2 + yn−1) n−1 ∑ n− 1− k k = (x− y ) x y . k=0 "/>
</div>
<p><span class="cmss-10x-x-109">This can be seen easily by calculating the product:</span></p>
<div class="math-dislay">
<img src="../media/file1199.png" width="450" class="math-display" alt=" n∑−1 n−1−k k n n−1 n−1 (x − y) x y .= x + [x y + ⋅⋅⋅+ xy ] k=0 − [xn− 1y + ⋅⋅⋅+ xyn− 1]− yn = xn − yn. "/>
</div>
<p><span class="cmss-10x-x-109">Thus, we have</span></p>
<div class="math-display">
<img src="../media/file1200.png" class="math-display" alt=" ∑ xn-−-yn (x-−-y)--nk−=01xn−1−kyk- liy→mx x− y = xli→my x− y n∑−1 = lim xn−1−kyk y→x k=0 = nxn −1. "/>
</div>
<p><span class="cmss-10x-x-109">So,</span> (<span class="cmmi-10x-x-109">x</span><sup><span class="cmmi-8">n</span></sup>)<sup><span class="cmsy-8">′</span></sup> = <span class="cmmi-10x-x-109">nx</span><sup><span class="cmmi-8">n</span><span class="cmsy-8">−</span><span class="cmr-8">1</span></sup><span class="cmss-10x-x-109">. With this and the rules of differentiation, we can calculate the derivative of any polynomial </span><span class="cmmi-10x-x-109">p</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmex-10x-x-109">∑</span> <sub><span class="cmmi-8">k</span><span class="cmr-8">=0</span></sub><sup><span class="cmmi-8">n</span></sup><span class="cmmi-10x-x-109">p</span><sub><span class="cmmi-8">k</span></sub><span class="cmmi-10x-x-109">x</span><sup><span class="cmmi-8">k</span></sup> <span class="cmss-10x-x-109">as</span></p>
<div class="math-disly">
<img src="../media/file1201.png" width="150" class="math-display" alt=" ′ ∑n k−1 p(x) = kpkx . k=1 "/>
</div>
<p><span class="cmss-10x-x-109">The case </span><span class="cmmi-10x-x-109">n/span&gt;0 <span class="cmss-10x-x-109">follows from </span><span class="cmmi-10x-x-109">x</span><sup><span class="cmsy-8">−</span><span class="cmmi-8">n</span></sup> = 1<span class="cmmi-10x-x-109">∕x</span><sup><span class="cmmi-8">n</span></sup> <span class="cmss-10x-x-109">using the rules of differentiation.</span> </span></p>
</div>
</div>
<p><span class="cmss-10x-x-109">With these rules under our belt, we can calculate the derivatives for some of</span> <span id="dx1-203004"></span><span class="cmss-10x-x-109">the most famous activation functions.</span></p>
<p><span class="cmss-10x-x-109">The most classical one, the </span><span class="cmssi-10x-x-109">sigmoid </span><span class="cmss-10x-x-109">function is defined by</span></p>
<div class="math-dispay">
<img src="../media/file1202.png" width="150" class="math-display" alt=" ---1--- σ(x) = 1+ e− x. "/>
</div>
<p><span class="cmss-10x-x-109">Since it is an elementary function, it is differentiable everywhere. To calculate its derivative, we can use the quotient rule:</span></p>
<div style="display: flex; justify-content: space-between; align-items: center; max-width: 600px;" class="equation math-display">
  <div class="math-display">
    <img src="../media/file1203.png" alt="L(U,V ) = {f : U → V | f is linear}" width="150"/>
  </div>
  <div style="padding-left: 1em; ">
    <!-- Label goes here, e.g. (4.2) -->(12.4)
  </div>
</div>

<p><span class="cmss-10x-x-109">Now that we have the sigmoid and its derivative, let’s plot them together!</span></p>
<div id="tcolobox-246" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbo-content">
<pre class="lstinputlisting"><code>def sigmoid(x): 
    return 1/(1 + np.exp(-x)) 
 
def sigmoid_prime(x): 
    return sigmoid(x) - sigmoid(x)**2</code></pre>
</div>
</div>
<div id="tcolobox-247" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>import numpy as np 
import matplotlib.pyplot as plt 
 
xs = np.linspace(-10, 10, 1000) 
 
with plt.style.context("/span&gt;seaborn-v0_8": 
    plt.title("/span&gt;Sigmoid and its derivative 
    plt.plot(xs, [sigmoid(x) for x in xs], label="/span&gt;Sigmoid 
    plt.plot(xs, [sigmoid_prime(x) for x in xs], label="/span&gt;Sigmoid prime 
    plt.legend() 
    plt.tight_layout() 
    plt.show()</code></pre>
</div>
</div>
<div class="minipage">
<p><img src="../media/file1204.png" width="569" alt="PIC"/> <span id="x1-203022r6"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.6: Sigmoid and its derivative</span> </span>
</div>
<p><span class="cmss-10x-x-109">Another</span> <span id="dx1-203023"></span><span class="cmss-10x-x-109">popular activation function is the </span><span class="cmssi-10x-x-109">ReLU</span><span class="cmss-10x-x-109">, defined by</span></p>
<div class="math-dsplay">
<img src="../media/file1205.png" width="150" class="math-display" alt=" ( |{x if x &gt;0, ReLU (x) = |(0 otherwise. "/>
</div>
<p><span class="cmss-10x-x-109">Let’s plot its graph first!</span></p>
<div id="tcolobox-248" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>def relu(x): 
    if x /span&gt; 0: 
        return x 
    else: 
        return 0</code></pre>
</div>
</div>
<div id="tcolobox-249" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>xs = np.linspace(-5, 5, 1000) 
 
with plt.style.context("/span&gt;seaborn-v0_8": 
    plt.title("/span&gt;Graph of the ReLU function 
    plt.plot(xs, [relu(x) for x in xs], label="/span&gt;ReLU 
    plt.legend() 
    plt.tight_layout() 
    plt.show()</code></pre>
</div>
</div>
<div class="minipage">
<p><img src="../media/file1206.png" width="584" alt="PIC"/> <span id="x1-203037r7"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.7: Graph of the ReLU function</span> </span>
</div>
<p><span class="cmss-10x-x-109">By looking at it, we</span> <span id="dx1-203038"></span><span class="cmss-10x-x-109">can suspect that it is not differentiable at </span>0<span class="cmss-10x-x-109">. Indeed, since</span></p>
<div class="math-display">
<img src="../media/file1207.png" class="math-display" alt=" (| ReLU (x) − ReLU (0) { 1 if x &gt;0, ---------x--------- = | ( 0 if x &lt;0, "/>
</div>
<p><span class="cmss-10x-x-109">the limit of the differential quotient doesn’t exist.</span></p>
<p><span class="cmss-10x-x-109">However, besides </span>0<span class="cmss-10x-x-109">, it is differentiable and</span></p>
<div class="math-display">
<img src="../media/file1208.png" class="math-display" alt=" (| ′ {1 if x &gt;0, ReLU (x) = | (0 if x &lt;0. "/>
</div>
<p><span class="cmss-10x-x-109">Even though ReLU is not differentiable at </span>0<span class="cmss-10x-x-109">, this is not a problem in practice. When performing backpropagation, it is extremely unlikely that</span> ReLU<sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) <span class="cmss-10x-x-109">will receive </span>0 <span class="cmss-10x-x-109">as its input. Even if this is the case, the derivative can be artificially extended to</span><span id="dx1-203039"></span> <span class="cmss-10x-x-109">zero by defining it as </span>0<span class="cmss-10x-x-109">.</span></p>
</section>
<section id="higherorder-derivatives" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_179"><span class="titlemark"><span class="cmss-10x-x-109">12.2.3 </span></span> <span id="x1-20400014.2.3"></span><span class="cmss-10x-x-109">Higher-order derivatives</span></h3>
<p><span class="cmss-10x-x-109">One last thing</span> <span id="dx1-204001"></span><span class="cmss-10x-x-109">to do before we</span><span id="dx1-204002"></span> <span class="cmss-10x-x-109">move on is to talk about higher-order derivatives. Because derivatives are </span><span class="cmssi-10x-x-109">functions</span><span class="cmss-10x-x-109">, it is a completely natural idea to calculate the </span><span class="cmssi-10x-x-109">derivative of derivatives</span><span class="cmss-10x-x-109">. As we will see when studying the basics of optimization in </span><span class="cmssi-10x-x-109">Chapter 14</span><span class="cmss-10x-x-109">, the second derivatives contain quite a lot of essential information regarding minima and maxima.</span></p>
<p><span class="cmss-10x-x-109">The </span><span class="cmmi-10x-x-109">n</span><span class="cmss-10x-x-109">-th derivative of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">is denoted with </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmr-8">(</span><span class="cmmi-8">n</span><span class="cmr-8">)</span></sup><span class="cmss-10x-x-109">, where </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmr-8">(0)</span></sup> = <span class="cmmi-10x-x-109">f</span><span class="cmss-10x-x-109">. There are a few rules regarding them that are worth keeping in mind. Although, we have to note that a derivative function is not always differentiable, as the example</span></p>
<div class="math-display">
<img src="../media/file1209.png" class="math-display" alt=" ( | { 0 if x &lt;0, f (x) = |( 2 x otherwise "/>
</div>
<p><span class="cmss-10x-x-109">shows. Now, about those rules regarding higher-order derivatives.</span></p>
<div class="newtheorem">
<p><span class="head"> <span id="x1-204003r83"></span> <span class="cmbx-10x-x-109">Theorem 83.</span> </span></p>
<p><span class="cmti-10x-x-109">Let </span><span class="cmmi-10x-x-109">f </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→</span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">and </span><span class="cmmi-10x-x-109">g </span>: <span class="msbm-10x-x-109">ℝ </span><span class="cmsy-10x-x-109">→</span><span class="msbm-10x-x-109">ℝ </span><span class="cmti-10x-x-109">be two arbitrary functions.</span></p>
<p><span class="cmti-10x-x-109">(a) </span>(<span class="cmmi-10x-x-109">f </span>+ <span class="cmmi-10x-x-109">g</span>)<sup><span class="cmr-8">(</span><span class="cmmi-8">n</span><span class="cmr-8">)</span></sup> = <span class="cmmi-10x-x-109">f</span><sup><span class="cmr-8">(</span><span class="cmmi-8">n</span><span class="cmr-8">)</span></sup> + <span class="cmmi-10x-x-109">g</span><sup><span class="cmr-8">(</span><span class="cmmi-8">n</span><span class="cmr-8">)</span></sup></p>
<p><span class="cmti-10x-x-109">(b) </span>(<span class="cmmi-10x-x-109">fg</span>)<sup><span class="cmr-8">(</span><span class="cmmi-8">n</span><span class="cmr-8">)</span></sup> = <span class="cmex-10x-x-109">∑</span> <sub><span class="cmmi-8">k</span><span class="cmr-8">=0</span></sub><sup><span class="cmmi-8">n</span></sup><img src="../media/file1210.png" alt="(n) k" width="15"/><span class="cmmi-10x-x-109">f</span><sup><span class="cmr-8">(</span><span class="cmmi-8">n</span><span class="cmsy-8">−</span><span class="cmmi-8">k</span><span class="cmr-8">)</span></sup><span class="cmmi-10x-x-109">g</span><sup><span class="cmr-8">(</span><span class="cmmi-8">k</span><span class="cmr-8">)</span></sup></p>
</div>
<div id="tcolobox-250" class="tcolorbox proofbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-content">
<p><span class="cmssi-10x-x-109">Proof. (a) </span><span class="cmss-10x-x-109">trivially follows from the linearity of differentiation.</span></p>
<p><span class="cmss-10x-x-109">Regarding </span><span class="cmssi-10x-x-109">(b)</span><span class="cmss-10x-x-109">, we are going to use proof by induction. For </span><span class="cmmi-10x-x-109">n </span>= 1<span class="cmss-10x-x-109">, the statement simply says that </span>(<span class="cmmi-10x-x-109">fg</span>)<sup><span class="cmsy-8">′</span></sup> = <span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup><span class="cmmi-10x-x-109">g </span>+ <span class="cmmi-10x-x-109">fg</span><sup><span class="cmsy-8">′</span></sup><span class="cmss-10x-x-109">, as we have seen before.</span></p>
<p><span class="cmss-10x-x-109">Now, we assume that it is true for </span><span class="cmmi-10x-x-109">n </span><span class="cmss-10x-x-109">and deduce the </span><span class="cmmi-10x-x-109">n </span>+ 1 <span class="cmss-10x-x-109">case. For this, we have</span></p>
<img src="../media/file1211.png" class="math-display" alt=" ∑n ( ) (fg)(n+1) = ((fg)(n))′ = n (f(n−k)g(k))′ k=0 k ∑n ( ) = n [f(n−k+1)g(k) + f(n−k)g(k+1)] k=0 k ∑n ( ) ∑n ( ) = n f(n− k+1)g (k) + n f(n−k)g(k+1) k=0 k k=0 k ( ) n ( ) n− 1( ) ( ) = n f (n+1)g + [∑ n f(n+1−k)g(k)]+ [∑ n f(n−k)g(k+1)]+ n fg(n+1). 0 k k n k=1 k=0 " width="650"/>

<p><span class="cmss-10x-x-109">First, we note that</span> <img width="15" src="../media/file1212.png" alt="( ) n 0"/> = <img src="../media/file1213.png" width="15" alt="( ) n+1 0"/> = 1 <span class="cmss-10x-x-109">and</span> <img src="../media/file1214.png" width="15" alt="( ) n n"/> = <img width="15" src="../media/file1215.png" alt="( ) n+1 n+1"/> = 1<span class="cmss-10x-x-109">. Second, the recursive relation for binomial coefficients says that</span></p>
<div class="math-display">
<img src="../media/file1216.png" class="math-display" alt="( ) ( ) ( ) n+ 1 = n + n . k k k − 1 "/>
</div>
<p><span class="cmss-10x-x-109">With a simple reindexing, we have</span></p>
<div class="math-display">
<img src="../media/file1217.png" class="math-display" alt="n−1( ) n ( ) ∑ n f(n− k)g(k+1) = ∑ n f(n+1−k)g (k), k k − 1 k=0 k=1 "/>
</div>
<p><span class="cmss-10x-x-109">so we can join the two sums together and obtain</span></p>
<div class="math-dispay">
<img src="../media/file1218.png" width="550" class="math-display" alt=" ( ) n ( ) ( ) ( ) (fg)(n+1) = n + 1 f(n+1)g + ∑ [ n + n f(n+1−k)g(k)]+ n+ 1 fg(n+1) 0 k k − 1 n+ 1 ( ) k=1 n∑+1 n + 1 (n+1−k) (k) = k f g , k=0 "/>
</div>
<p><span class="cmss-10x-x-109">which is what we had to show.</span></p>
</div>
</div>
</section>
<section id="extending-the-function-base-class" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_180"><span class="titlemark"><span class="cmss-10x-x-109">12.2.4 </span></span> <span id="x1-20500014.2.4"></span><span class="cmss-10x-x-109">Extending the Function base class</span></h3>
<p><span class="cmss-10x-x-109">Now that we</span> <span id="dx1-205001"></span><span class="cmss-10x-x-109">have several tools under our belt to calculate derivatives, it’s time to think about implementations. Since we have our own </span><span class="cmtt-10x-x-109">Function </span><span class="cmss-10x-x-109">base class (</span><span class="cmssi-10x-x-109">Section </span><a href="ch017.xhtml#function-base-class"><span class="cmssi-10x-x-109">9.2.3</span></a><span class="cmss-10x-x-109">), a natural idea is to implement the derivative as a method. This is a simple solution that is in line with object-oriented principles as well, so we should go for it!</span></p>
<div id="tcolobox-251" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>class Function: 
    def __init__(self): 
        pass 
 
    def __call__(self, *args, **kwargs): 
        pass 
 
    # new interface element for 
    # computing the derivative 
    def prime(self): 
        pass 
 
    def parameters(self): 
        return dict()</code></pre>
</div>
</div>
<p><span class="cmss-10x-x-109">To see a concrete example, let’s revisit the sigmoid function, whose derivative is given by (</span><a href="ch020.xhtml"><span class="cmss-10x-x-109">12.4</span></a><span class="cmss-10x-x-109">):</span></p>
<div class="math-display">
<img src="../media/file1219.png" class="math-display" alt=" ′ σ (x) = σ(x)(1− σ (x )). "/>
</div>
<div id="tcolobox-252" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>class Sigmoid(Function): 
    def __call__(self, x): 
        return 1/(1 + np.exp(-x)) 
 
    def prime(self, x): 
        return self(x) - self(x)**2</code></pre>
</div>
</div>
<p><span class="cmss-10x-x-109">Simple implementation, powerful functionality. Now that we have the</span><span id="dx1-205022"></span> <span class="cmss-10x-x-109">derivatives covered, let’s move towards calculating the derivative of more complex functions!</span></p>
</section>
<section id="the-derivative-of-compositions" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_181"><span class="titlemark"><span class="cmss-10x-x-109">12.2.5 </span></span> <span ></span><span class="cmss-10x-x-109">The derivative of compositions</span></h3>
<p><span class="cmss-10x-x-109">At this point, I have probably emphasized the importance of function compositions and the chain rule (</span><span class="cmssi-10x-x-109">Theorem </span><a href="ch020.xhtml#x1-202003r81"><span class="cmssi-10x-x-109">81</span></a><span class="cmss-10x-x-109">) dozens of times. We have finally reached a point when we are ready to</span><span id="dx1-206001"></span> <span class="cmss-10x-x-109">implement a simple neural network and compute its derivative! (Of course, our methods will be far more refined in the end, but still, this is a milestone.)</span></p>
<p><span class="cmss-10x-x-109">How can we calculate the derivative for a composition of </span><span class="cmmi-10x-x-109">n </span><span class="cmss-10x-x-109">functions?</span></p>
<p><span class="cmss-10x-x-109">To see the pattern, let’s map out the first few cases. For </span><span class="cmmi-10x-x-109">n </span>= 2<span class="cmss-10x-x-109">, we have the good old chain rule</span></p>
<div class="math-display">
<img src="../media/file1220.png" class="math-display" alt=" ′ ′ ′ (f2(f1(x))) = f2(f1(x))⋅f1(x). "/>
</div>
<p><span class="cmss-10x-x-109">For </span><span class="cmmi-10x-x-109">n </span>= 3<span class="cmss-10x-x-109">, we have</span></p>
<div class="math-disply">
<img src="../media/file1221.png" width="450" class="math-display" alt="(f (f (f (x))))′ = f ′(f (f (x ))) ⋅f′(f (x))⋅f ′(x). 3 2 1 3 2 1 2 1 1 "/>
</div>
<p><span class="cmss-10x-x-109">Among the multitude of parentheses, we can notice a pattern. First, we should calculate the value of the composed function </span><span class="cmmi-10x-x-109">f</span><sub><span class="cmr-8">3</span></sub> <span class="cmsy-10x-x-109">∘</span><span class="cmmi-10x-x-109">f</span><sub><span class="cmr-8">2</span></sub> <span class="cmsy-10x-x-109">∘</span><span class="cmmi-10x-x-109">f</span><sub><span class="cmr-8">1</span></sub> <span class="cmss-10x-x-109">at </span><span class="cmmi-10x-x-109">x </span><span class="cmss-10x-x-109">while storing the intermediate results, then pass these to the appropriate derivatives and take the product of the</span><span id="dx1-206002"></span> <span class="cmss-10x-x-109">result.</span></p>
<div id="tcolobox-253" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>class Composition(Function): 
    def __init__(self, *functions): 
        self.functions = functions 
 
    def __call__(self, x): 
        for f in self.functions: 
            x = f(x) 
 
        return x 
 
    def prime(self, x): 
        forward_pass = [x] 
 
        for f in self.functions: 
            try: 
                x = f(x) 
                forward_pass.append(x) 
            except ValueError as e: 
                print(f/span&gt;Error in function {f}: {e}" 
                return np.nan 
 
        forward_pass.pop()    # removing the last element, as we won’t need it 
 
        derivative = np.prod([f.prime(x) for f, x in zip(self.functions, forward_pass)]) 
 
        return derivative</code></pre>
</div>
</div>
<p><span class="cmss-10x-x-109">To see if our implementation works, we should test it on a simple test case, say for</span></p>
<div class="math-dispay">
<img src="../media/file1222.png" width="150" class="math-display" alt="f1(x) = 2x, f2(x) = 3x, f3(x) = 4x. "/>
</div>
<p><span class="cmss-10x-x-109">The derivative of</span> <span id="dx1-206029"></span><span class="cmss-10x-x-109">the composition </span>(<span class="cmmi-10x-x-109">f</span><sub><span class="cmr-8">3</span></sub> <span class="cmsy-10x-x-109">∘</span><span class="cmmi-10x-x-109">f</span><sub><span class="cmr-8">2</span></sub> <span class="cmsy-10x-x-109">∘</span><span class="cmmi-10x-x-109">f</span><sub><span class="cmr-8">1</span></sub>)(<span class="cmmi-10x-x-109">x</span>) = 24<span class="cmmi-10x-x-109">x </span><span class="cmss-10x-x-109">should be constant</span> 24<span class="cmss-10x-x-109">.</span></p>
<div id="tcolobox-254" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>class Linear(Function): 
    def __init__(self, a, b): 
        self.a = a 
        self.b = b 
 
    def __call__(self, x): 
        return self.a*x + self.b 
 
    def prime(self, x): 
        return self.a 
 
    def parameters(self): 
        return {"/span&gt;a self.a, /span&gt;b self.b}</code></pre>
</div>
</div>
<div id="tcolobox-255" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>f = Composition(Linear(2, 0), Linear(3, 0), Linear(4, 0)) 
 
xs = np.linspace(-10, 10, 1000) 
ys = [f.prime(x) for x in xs] 
 
with plt.style.context("/span&gt;seaborn-v0_8": 
    plt.title("/span&gt;The derivative of f(x) = 24x 
    plt.plot(xs, ys, label="/span&gt;f prime 
    plt.legend() 
    plt.tight_layout() 
    plt.show()</code></pre>
</div>
</div>
<div class="minipage">
<p><img src="../media/file1223.png" width="484" alt="PIC"/> <span id="x1-206054r8"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.8: The derivative of </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = 24<span class="cmmi-10x-x-109">x</span> </span>
</div>
<p><span class="cmss-10x-x-109">Success! Even though we’re only dealing with single-variable functions for now, our </span><span class="cmtt-10x-x-109">Composition </span><span class="cmss-10x-x-109">is going to be the skeleton for neural networks.</span></p>
</section>
<section id="numerical-differentiation" class="level4 subsectionHead">
<h3 class="subsectionHead" id="sigil_toc_id_182"><span class="titlemark"><span class="cmss-10x-x-109">12.2.6 </span></span> <span id="x1-20700014.2.6"></span><span class="cmss-10x-x-109">Numerical differentiation</span></h3>
<p><span class="cmss-10x-x-109">So far, we</span> <span id="dx1-207001"></span><span class="cmss-10x-x-109">have seen that in the cases when at least some formula is available for the function in question, we can apply the rules of differentiation (see </span><span class="cmssi-10x-x-109">Theorem </span><a href="ch020.xhtml#x1-202002r80"><span class="cmssi-10x-x-109">80</span></a><span class="cmss-10x-x-109">) to obtain the derivative.</span></p>
<p><span class="cmss-10x-x-109">However, in practice, this is often not the case. For instance, think about the case when the function represents a recorded audio signal. If we can’t compute the derivative exactly, a natural idea is to </span><span class="cmssi-10x-x-109">approximate </span><span class="cmss-10x-x-109">it, that is, provide an estimate that is sufficiently close to the real value.</span></p>
<p><span class="cmss-10x-x-109">For the sake of example, suppose that we don’t know the exact formula of our function to be differentiated, which is secretly the good old sine function.</span></p>
<pre class="lstinputlisting"><code>def f(x):
    return np.sin(x)</code></pre>
<div class="math-display">
<p class="normal">Recall that, by definition, the derivative is given by
</p>
<img src="../media/file1226.png" class="math-display" alt="f′(x ) = lim f(x-+-h)−-f(x). h→0 h "/>
</div>
<p><span class="cmss-10x-x-109">Since we can’t take limits inside a computer (as computers can’t deal with infinity), the second best thing to do is to approximate this by</span></p>
<div class="math-display">
<img src="../media/file1227.png" class="math-display" alt=" f (x + h) − f(x) Δhf (x ) =-------h-------, "/>
</div>
<p><span class="cmss-10x-x-109">where </span><span class="cmmi-10x-x-109">h/span&gt;0 <span class="cmss-10x-x-109">is an arbitrarily small but fixed quantity. </span>Δ<sub><span class="cmmi-8">h</span></sub><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) <span class="cmss-10x-x-109">is called the </span><span class="cmssi-10x-x-109">forward difference quotient</span><span class="cmss-10x-x-109">. In theory, </span>Δ<sub><span class="cmmi-8">h</span></sub><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) <span class="cmsy-10x-x-109">≈</span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) <span class="cmss-10x-x-109">holds when </span><span class="cmmi-10x-x-109">h </span><span class="cmss-10x-x-109">is sufficiently small. Let’s see how they perform!</span> </span></p>
<div id="tcolobox-456" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>def delta(f, h, x): 
    return (f(x + h) - f(x))/h 
 
def f_prime(x): 
    return np.cos(x)</code></pre>
</div>
</div>
<div id="tcolobox-257" class="tcolorbox">
<div class="tcolorbox-title">

</div>
<div class="tcolorbox-contnt">
<pre class="lstinputlisting"><code>hs = [3.0, 1.0, 0.1] 
xs = np.linspace(-5, 5, 100) 
f_prime_ys = [f_prime(x) for x in xs] 
 
with plt.style.context("/span&gt;seaborn-v0_8": 
    _colormap = plt.cm.hot_r 
    plt.figure(figsize=(10, 5)) 
    plt.title("/span&gt;Approximating the derivative with finite differences 
 
    true_color = _colormap(0.99)  # Get a fixed color for the true derivative 
    for i, h in enumerate(hs): 
        ys = [delta(f, h, x) for x in xs] 
        blend_ratio = 1 - (len(hs) - i) / len(hs)  # Progressively blend closer to the true color 
        approx_color = _colormap(blend_ratio) 
        plt.plot(xs, ys, label=f/span&gt;h = {h}" color=approx_color) 
 
    plt.plot(xs, f_prime_ys, label="/span&gt;the true derivative color=true_color, linewidth=2) 
    plt.legend() 
    plt.tight_layout() 
    plt.show()</code></pre>
</div>
</div>
<div class="minipage">
<p><img src="../media/file1228.png" width="569" alt="PIC"/> <span id="x1-207029r9"></span></p>
<span class="id"><span class="cmss-10x-x-109">Figure 12.9: Approximating the derivative with finite differences</span> </span>
</div>
<p><span class="cmss-10x-x-109">Although the </span>Δ<sub><span class="cmmi-8">h</span></sub><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) <span class="cmss-10x-x-109">functions </span><span class="cmssi-10x-x-109">seem </span><span class="cmss-10x-x-109">to be close </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>)<span class="cmss-10x-x-109">, when </span><span class="cmmi-10x-x-109">h </span><span class="cmss-10x-x-109">is small, there is a plethora of potential issues.</span></p>
<p><span class="cmss-10x-x-109">For one, </span>Δ<sub><span class="cmmi-8">h</span></sub><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <img src="../media/file1229.png" width="75" data-align="middle" alt="f(x+h)−-f(x) h"/> <span class="cmss-10x-x-109">only approximates</span> <span id="dx1-207030"></span><span class="cmss-10x-x-109">the derivative from the right of </span><span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">, as </span><span class="cmmi-10x-x-109">h/span&gt;0<span class="cmss-10x-x-109">. To solve this, one might use the </span><span class="cmssi-10x-x-109">backward difference quotient</span> </span></p>
<div class="math-display">
<img src="../media/file1230.png" class="math-display" alt="∇hf (x ) = f-(x-)−-f(x-−-h), h "/>
</div>
<p><span class="cmss-10x-x-109">but that seem to have the same problems. The crux of the issue is that if </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">is differentiable at some </span><span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">, then</span></p>
<div class="math-display">
<img src="../media/file1231.png" class="math-display" alt="f(x+--h)−-f(x)-≈ f-(x)−-f(x-−-h), h h "/>
</div>
<p><span class="cmss-10x-x-109">but only if </span><span class="cmmi-10x-x-109">h </span><span class="cmss-10x-x-109">is very small, and the “good enough” choice for </span><span class="cmmi-10x-x-109">h </span><span class="cmss-10x-x-109">can vary from point to point.</span></p>
<p><span class="cmss-10x-x-109">A middle ground is provided by the so-called symmetric difference quotients, defined by</span></p>
<div class="math-display">
<img src="../media/file1232.png" class="math-display" alt=" f(x + h)− f (x − h) δhf(x) = --------2h--------, h ∈ (0,∞ ), "/>
</div>
<p><span class="cmss-10x-x-109">which is the average of forward and backward differences: </span><span class="cmmi-10x-x-109">δ</span><sub><span class="cmmi-8">h</span></sub><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <img src="../media/file1233.png" class="frac" data-align="middle" alt="Δhf(x)+-∇hf(x)- 2"/><span class="cmss-10x-x-109">. These three approximators are</span> <span id="dx1-207031"></span><span class="cmss-10x-x-109">called </span><span class="cmssi-10x-x-109">finite differences</span><span class="cmss-10x-x-109">. With their repeated</span><span id="dx1-207032"></span> <span class="cmss-10x-x-109">application, we can approximate higher-order derivatives as well.</span></p>
<p><span class="cmss-10x-x-109">Even though symmetric differences are provably better, the approximation errors can still be significantly amplified in the long run.</span></p>
<p><span class="cmss-10x-x-109">All things considered, we are not going to use finite differences for machine learning in practice. However, as we’ll see, the gradient descent method is simply a forward difference approximation of a special differential equation.</span></p>
</section>
</section>
<section id="summary11" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_183"><span class="titlemark"><span class="cmss-10x-x-109">12.3 </span></span> <span id="x1-20800014.3"></span><span class="cmss-10x-x-109">Summary</span></h2>
<p><span class="cmss-10x-x-109">This chapter taught us about </span><span class="cmssi-10x-x-109">differentiation</span><span class="cmss-10x-x-109">, the key component of optimizing functions. Yes, even functions with millions of variables.</span></p>
<p><span class="cmss-10x-x-109">Even though we focused on univariate functions (for now), we managed to build a deep understanding of differentiation. For instance, we’ve learned that the derivative</span></p>
<div class="math-display">
<img src="../media/file1234.png" class="math-display" alt="f′(x) = lim f-(x-)−-f(y) y→x x − y "/>
</div>
<p><span class="cmss-10x-x-109">describes the slope of the tangent line drawn to the graph of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">at </span><span class="cmmi-10x-x-109">x</span><span class="cmss-10x-x-109">, which describes the velocity if </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">is the trajectory of a one-dimensional motion. From the perspective of physics, the derivative describes the rate of change.</span></p>
<p><span class="cmss-10x-x-109">However, from the perspective of mathematics, differentiation offers much more than the rate of change: we’ve seen that a differentiable function can be written in the form</span></p>
<div class="math-display">
<img src="../media/file1235.png" class="math-display" alt="f (x ) = f(x0) + f′(x0)(x − x0)+ o(|x− x0|) "/>
</div>
<p><span class="cmss-10x-x-109">around some </span><span class="cmmi-10x-x-109">x</span><sub><span class="cmr-8">0</span></sub> <span class="cmsy-10x-x-109">∈</span><span class="msbm-10x-x-109">ℝ</span><span class="cmss-10x-x-109">. In other words, locally speaking, a differentiable function is a linear part plus a small error term. Unlike the limit-of-quotients definition, this will generalize for multiple variables without an issue. Moreover, we can apply a similar idea to obtain the so-called Taylor expansion</span></p>
<div class="math-display">
<img src="../media/file1236.png" class="math-display" alt=" ∑n f (k)(x0) f(x) = --------(x− x0 )k + o(|x − x0|n), k=0 k! "/>
</div>
<p><span class="cmss-10x-x-109">allowing us to approximate transcendental functions like</span> log <span class="cmmi-10x-x-109">x,</span>sin<span class="cmmi-10x-x-109">x,</span>cos<span class="cmmi-10x-x-109">x,e</span><sup><span class="cmmi-8">x</span></sup> <span class="cmss-10x-x-109">with polynomials.</span></p>
<p><span class="cmss-10x-x-109">In addition to the theory, we also learned about computing derivatives in practice.</span></p>
<p><span class="cmss-10x-x-109">This is done by either 1) decomposing complex functions into their building blocks, then calculating the derivative using the rules</span></p>
<div class="math-display">
<img src="../media/file1237.png" class="math-display" alt=" ′ ′ (cf) (x) = cf (x), (f + g)′(x) = f ′(x)+ g′(x), (fg)′(x) = f ′(x)g(x)+ f (x )g ′(x), (f ∘g)′(x) = f ′(g(x))g′(x), "/>
</div>
<p><span class="cmss-10x-x-109">or 2) approximating the derivative with finite differences like</span></p>
<div class="math-display">
<img src="../media/file1238.png" class="math-display" alt=" f (x + h) − f(x) Δhf (x ) =---------------, h "/>
</div>
<p><span class="cmss-10x-x-109">where </span><span class="cmmi-10x-x-109">h/span&gt;0 <span class="cmss-10x-x-109">is a small constant. The former method is the foundation of backpropagation, while the latter lies at the heart of gradient descent. These are the methods that truly enable training huge neural networks.</span> </span></p>
<p><span class="cmss-10x-x-109">Now that we understand differentiation, it’s time to talk about its counterpart: integration. Let’s go!</span></p>
</section>
<section id="problems11" class="level3 sectionHead">
<h2 class="sectionHead" id="sigil_toc_id_184"><span class="titlemark"><span class="cmss-10x-x-109">12.4 </span></span> <span id="x1-20900014.4"></span><span class="cmss-10x-x-109">Problems</span></h2>
<p><span class="cmssbx-10x-x-109">Problem 1. </span><span class="cmss-10x-x-109">Calculate the derivative of the</span> tanh(<span class="cmmi-10x-x-109">x</span>) <span class="cmss-10x-x-109">function defined by</span></p>
<div class="math-display">
<img src="../media/file1239.png" class="math-display" alt=" ex − e− x tanh(x) = -x---−-x. e + e "/>
</div>
<p><span class="cmssbx-10x-x-109">Problem 2. </span><span class="cmss-10x-x-109">Define the function</span></p>
<div class="math-display">
<img src="../media/file1240.png" class="math-display" alt=" ( |{ 0 if x &lt;0, f(x) = |( x2 otherwise. "/>
</div>
<p><span class="cmss-10x-x-109">Find the derivative of </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>)<span class="cmss-10x-x-109">. Is </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(<span class="cmmi-10x-x-109">x</span>) <span class="cmss-10x-x-109">differentiable everywhere?</span></p>
<p><span class="cmssbx-10x-x-109">Problem 3. </span><span class="cmss-10x-x-109">Define the function</span></p>
<div class="math-display">
<img src="../media/file1241.png" class="math-display" alt=" ( | { x2 if x ∈ ℚ, f (x ) = |( 2 − x otherwise. "/>
</div>
<p><span class="cmss-10x-x-109">Show that</span></p>
<p><span class="cmssi-10x-x-109">(a) </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">is differentiable at </span>0<span class="cmss-10x-x-109">, and </span><span class="cmmi-10x-x-109">f</span><sup><span class="cmsy-8">′</span></sup>(0) = 0<span class="cmss-10x-x-109">, </span><span class="cmssi-10x-x-109">(b) </span><span class="cmss-10x-x-109">and </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">is nowhere else differentiable.</span></p>
<p><span class="cmssbx-10x-x-109">Problem 4. </span><span class="cmss-10x-x-109">Calculate the derivatives of the following functions.</span></p>
<p><span class="cmssi-10x-x-109">(a) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">e</span><sup><span class="cmsy-8">−</span><img src="../media/file1242.png" class="math" data-align="middle" alt=" 2 x2-"/></sup> <span class="cmssi-10x-x-109">(b) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">x</span><sup><span class="cmr-8">2</span></sup><span class="cmmi-10x-x-109">e</span><sup><span class="cmr-8">sin </span><span class="cmmi-8">x</span></sup> <span class="cmssi-10x-x-109">(c) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = sin(cos<span class="cmmi-10x-x-109">x</span><sup><span class="cmr-8">2</span></sup>) <span class="cmssi-10x-x-109">(d) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <img src="../media/file1243.png" class="frac" data-align="middle" alt="x2+1 x2−-1"/></p>
<p><span class="cmssbx-10x-x-109">Problem 5. </span><span class="cmss-10x-x-109">Find the Taylor expansion of the following functions around</span> 0<span class="cmss-10x-x-109">.</span></p>
<p><span class="cmssi-10x-x-109">(a) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = sin<span class="cmmi-10x-x-109">x </span><span class="cmssi-10x-x-109">(b) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = cos<span class="cmmi-10x-x-109">x </span><span class="cmssi-10x-x-109">(c) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = log <span class="cmmi-10x-x-109">x </span><span class="cmssi-10x-x-109">(d) </span><span class="cmmi-10x-x-109">f</span>(<span class="cmmi-10x-x-109">x</span>) = <span class="cmmi-10x-x-109">e</span><sup><span class="cmsy-8">{</span><span class="cmss-8">-x</span></sup>2<span class="cmsy-10x-x-109">}</span></p>
<p><span class="cmssbx-10x-x-109">Problem 6. </span><span class="cmss-10x-x-109">Find the Taylor expansion of the function</span></p>
<div class="math-display">
<img src="../media/file1244.png" class="math-display" alt=" ( |{ − 12 f(x) = e x if x ⁄= 0, |( 0 if x = 0. "/>
</div>
<p><span class="cmss-10x-x-109">around </span>0<span class="cmss-10x-x-109">. Is the Taylor expansion of </span><span class="cmmi-10x-x-109">f </span><span class="cmss-10x-x-109">equal to </span><span class="cmmi-10x-x-109">f</span><span class="cmss-10x-x-109">?</span></p>
</section>
<section id="join-our-community-on-discord12" class="level3 likesectionHead">
<h2 class="likesectionHead sigil_not_in_toc" id="sigil_toc_id_185"><span id="x1-210000"></span><span class="cmss-10x-x-109">Join our community on Discord</span></h2>
<p><span class="cmss-10x-x-109">Read this book alongside other users, Machine Learning experts, and the author himself. Ask questions, provide solutions to other readers, chat with the author via Ask Me Anything sessions, and much more. Scan the QR code or visit the link to join the community.</span> <a href="https://packt.link/math" class="url"><span class="cmtt-10x-x-109">https://packt.link/math</span></a></p>
<p><img src="../media/file1.png" width="85" alt="PIC"/></p>
</section>
</section>
</body>
</html>