["```py\nfrom sklearn.datasets import load_digits\n```", "```py\ndigits = load_digits()\n```", "```py\nprint(type(digits))\nprint(digits)\n```", "```py\nprint(digits.images.shape)\n```", "```py\nindices = []\nfor i in range(10):\n    for j in digits.target:\n        if i==j:\n            indices.append(j)\n            break\nprint(indices)\n```", "```py\nimport matplotlib.pyplot as plt\nplt.scatter(list(range(200)),digits.target[:200])\nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\n\nnrows, ncols = 2, 5\nplt.figure(figsize=(6,3))\n\nfor i in range(ncols * nrows):\n    ax = plt.subplot(nrows, ncols, i + 1)\n    ax.imshow(digits.images[i],cmap='gray_r')\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(digits.target[i])\n```", "```py\nfrom sklearn.manifold import TSNE\n```", "```py\nimport numpy as np\nX = np.vstack([digits.data[digits.target==i]for i in range(10)])\ny = np.hstack([digits.target[digits.target==i] for i in range(10)])\n```", "```py\n#Here we run tSNE with 250 iterations and time it\n%%timeit\ntsne_iter_250 = TSNE(init='pca',method='exact',n_components=2,n_iter=250).fit_transform(X)\n```", "```py\n#We import the pandas and matplotlib libraries\nimport pandas as pd\nimport matplotlib\nmatplotlib.style.use('seaborn')\n#Here we plot the tSNE results in a reduced two-dimensional space\ndf = pd.DataFrame(tsne_iter_250)\nplt.scatter(df[0],df[1],c=y,cmap=matplotlib.cm.get_cmap('tab10'))\nplt.show()\n```", "```py\n#Here we run tSNE for 2000 iteractions\ntsne_iter_2000 = TSNE(init='pca',method='exact',n_components=2,n_iter=2000).fit_transform(X)\n#Here we plot the figure\ndf2 = pd.DataFrame(tsne_iter_2000)\nplt.scatter(df2[0],df2[1],c=y,cmap=matplotlib.cm.get_cmap('tab10'))\nplt.show()\n```", "```py\n# Import sklearn models for preprocessing input data\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import LabelBinarizer\n\n# Import the necessary Keras libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.callbacks import History \n\n# Randomize and split data into training dataset with right format to feed to Keras\nlb = LabelBinarizer()\nX = np.expand_dims(digits.images.T, axis=0).T\ny = lb.fit_transform(digits.target)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n\n# Start a Keras sequential model\nmodel = Sequential()\n\n# Set input format shape as (batch, height, width, channels)\nK.set_image_data_format('channels_last') # inputs with shape (batch, height, width, channels)\n\nmodel.add(Convolution2D(filters=4,kernel_size=(3,3),padding='same',input_shape=(8,8,1),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# Drop out 5% of training data in each batch\nmodel.add(Flatten())\nmodel.add(Dropout(0.05))\nmodel.add(Dense(10, activation= 'softmax'))\n\n# Set variable 'history' to store callbacks to track the validation loss\nhistory = History()\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Fit the model and save the callbacks of validation loss and accuracy to 'history'\nmodel.fit(X_train,y_train, epochs=100, batch_size= 128, callbacks=[history])\n```", "```py\nprint(history.history.keys())\n```", "```py\nimport pandas as pd\nimport matplotlib\nmatplotlib.style.use('seaborn')\n\n# Here plots the loss function graph along Epochs\npd.DataFrame(history.history['loss']).plot()\nplt.legend([])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Validation loss across 100 epochs',fontsize=20,fontweight='bold')\nplt.show()\n\n# Here plots the percentage of accuracy along Epochs\npd.DataFrame(history.history['acc']).plot()\nplt.legend([])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy loss across 100 epochs',fontsize=20,fontweight='bold')\nplt.show()\n```", "```py\ny_test1 = model.predict(X_test)\ny_test1 = lb.fit_transform(np.round(y_test1))\ny_test1 = np.argmax(y_test1, axis=1)\ny_test = np.argmax(y_test, axis=1)\n```", "```py\nimport numpy as np\nmislabeled_indices = np.arange(len(y_test))[y_test!=y_test1]\ntrue_labels = np.asarray([y_test[i] for i in mislabeled_indices])\npredicted_labels = np.asarray([y_test1[i] for i in mislabeled_indices])\nprint(mislabeled_indices)\nprint(true_labels)\nprint(predicted_labels)\n```", "```py\n[  1   8  56  97 117 186 188 192 198 202 230 260 291 294 323 335 337]\n[9 7 8 2 4 4 2 4 8 9 6 9 7 6 8 8 1]\n[3 9 5 0 9 1 1 9 1 3 0 3 8 8 1 3 2]\n```", "```py\nmislabeled_digit_counts = [len(true_labels[true_labels==i]) for i in range(10)]\n```", "```py\n# Calculate the ratio of mislabeled samples\ntotal_digit_counts = [len(y_test[y_test==i]) for i in range(10)]\nmislabeled_ratio = [mislabeled_digit_counts[i]/total_digit_counts[i] for i in range(10)]\n\npd.DataFrame(mislabeled_ratio).plot(kind='bar')\nplt.xticks(rotation=0)\nplt.xlabel('Digit')\nplt.ylabel('Mislabeled ratio')\nplt.legend([])\nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\nnrows, ncols = 2, 5\nplt.figure(figsize=(6,3))\nfor i in range(ncols * nrows):\n    j = mislabeled_indices[i]\n    ax = plt.subplot(nrows, ncols, i + 1)\n    ax.imshow(X_test[j].reshape(8,8),cmap='gray_r')\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(y_test1[j],color='red')\n    plt.xlabel(y_test[j],color='green')\nplt.show()\n```"]