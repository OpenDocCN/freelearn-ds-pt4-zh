- en: Integrating Programming Languages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After 14 chapters full of Tableau functionality and exercises, what are we
    still missing? Correct, the one feature that opens a whole new universe of opportunities:
    programming integration! If you need a function that isn’t covered natively by
    Tableau’s calculated fields and you know how to code it, you can fall back on
    programming integrations. To be precise, two languages are supported: R and Python.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine the following scenario: you deal with a financial dataset and want
    to add an options pricing formula to your Tableau dashboard. You look up the formula
    and see that you have all the required variables, like strike price, stock price,
    and volatility, but you also need a probability density function, which you can’t
    find in Tableau. In this case, you can fall back to the programming integration
    and run the calculation in R or Python and send back the output—great, isn’t it?
    Now imagine a second scenario: you’re working on a sentiment analysis project.
    You could calculate the sentiment in Python outside of Tableau and then use the
    output as input for your model, but wouldn’t it be great if you could have it
    all in Tableau? Well, you can by using the programming tool integration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Integrating programming languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R installation and integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing R functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python installation and integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Python functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating programming languages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How does integration empower Tableau? It happens through calculated fields.
    Tableau dynamically interfaces with Rserve or TabPy to pass values and receive
    results. And Tableau Prep Builder also has R and Python integration as we saw
    in *Chapter 3*, *Using Tableau Prep Builder*! So, let’s not waste any time and
    jump right in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Basic Tableau-to-R and Tableau-to-Python integration is quite simple: the view
    shows data based on a calculated field, with the help of which Tableau pushes
    data to Rserve or TabPy respectively and then retrieves the results via a table
    calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.1: Tableau external services'
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, whether you are viewing a workbook on Tableau Desktop or via Tableau
    Server, if you wish to run R and Python calculations, then Rserve or TabPy must
    be accessible.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a proper understanding of the integration, let’s also look at the Tableau/R
    workflow as an example. The terms used in the following diagram, which you may
    be unfamiliar with, will be explained throughout this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.2: Tableau/R workflow'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot can be used likewise for Python. Let’s begin with R
    since it was the first available integration.
  prefs: []
  type: TYPE_NORMAL
- en: R installation and integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To adequately understand how Tableau and R work together, it’s important to
    grasp the big picture. To facilitate that understanding, we’ll cover high-level
    concepts and information in this section before delving into calculated fields
    and R scripting details.
  prefs: []
  type: TYPE_NORMAL
- en: Installing R is typically not difficult, but it does involve more than simply
    double-clicking on an executable. To successfully connect Tableau with R, you
    will need to make sure that permissions are correctly set and that various components—some
    required and some that are just nice to have—are correctly implemented. We will
    cover the basics, review a couple of the typical challenges faced during installation,
    and provide troubleshooting guidance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to install R:'
  prefs: []
  type: TYPE_NORMAL
- en: Download R by visiting [http://www.r-project.org/](http://www.r-project.org/),
    click on the **download R** hyperlink, and choose a CRAN mirror. Note that R works
    best in a Linux or Unix environment; however, to learn R and begin working with
    Tableau/R functionality to complete the exercises in this chapter, installing
    the Windows version is adequate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install R by double-clicking on the downloaded executable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open R.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Various issues may arise when installing R. For example, you may experience
    problems due to insufficient permissions for the R working directory. This issue
    may first become evident when attempting to install R packages. To rectify the
    problem, determine the working directory in R with the `getwd()` function. Next,
    either change the working directory via `setwd()` or, at the operating system
    level—whichever you feel more comfortable with—set the appropriate read and execute
    permissions for the working directory.
  prefs: []
  type: TYPE_NORMAL
- en: Issues can also arise due to security system and port configuration problems.
    By default, Tableau will connect to Rserve via port `6311`. Alternatively, within
    Tableau, you can specify a different port when connecting to R.
  prefs: []
  type: TYPE_NORMAL
- en: The documentation at [http://www.r-project.org/](http://www.r-project.org/)
    provides detailed information regarding overcoming a variety of installation challenges.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although not required, RStudio Desktop provides a better user interface than
    the default R GUI that installs with R. RStudio includes a console that features
    intelligent code completion (that is, IntelliSense), a workspace browser that
    provides easy access to files, packages, and help, a data viewer, and much more
    all within a single, unified environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.3: RStudio'
  prefs: []
  type: TYPE_NORMAL
- en: The open-source edition of RStudio is sufficient for many uses. You can download
    the application via [https://posit.co/download/rstudio-desktop/](https://posit.co/download/rstudio-desktop/).
    Just choose for yourself which one you like better out of the Desktop and R GUI
    versions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open R:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.4: R GUI'
  prefs: []
  type: TYPE_NORMAL
- en: 'To establish a connection with Tableau, you will need to start Rserve. Technically,
    Rserve is a separate package; however, by default, it is installed with R:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To make sure that the Rserve package is installed, within R, enter the following
    command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Several packages should be listed, including RServe. If for some reason the
    Rserve package did not install with your instance of R, you can do so via:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To start `Rserve`, enter `library(Rserve); Rserve()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The semicolon (`;`) represents a new line of code in R:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.5: Rserve initialization'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have successfully installed R and started Rserve, you are ready
    to connect Tableau to R. Within Tableau, select **Help** | **Settings and Performance**
    | **Manage Analytics Extension Connection…**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.6: Analytics Extension'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Manage Analytics Extensions Connection** screen will open; select **RServe**.
    The default settings in the following screenshot will work for most local installations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.7: Analytics Extensions connection'
  prefs: []
  type: TYPE_NORMAL
- en: While integrating Tableau with R doesn’t require any interaction with an R interface,
    you will probably want to try out your R code in a GUI, such as R GUI or RStudio,
    before embedding the code into Tableau. This will allow you to take advantage
    of useful accompanying features relevant to the R language, such as help, examples,
    and sample datasets tailored to R. Note that the calculated field editor in Tableau
    simply acts as a pass-through for R code and does not provide any support.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing R functionality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have successfully connected Tableau with R, let’s write some code
    in Tableau to invoke R. Within Tableau, open the **Calculated Field Editor**.
    Notice the class of functions beginning with `SCRIPT_`, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.8: SCRIPT_ functions'
  prefs: []
  type: TYPE_NORMAL
- en: The `SCRIPT_` functions are used by Tableau to invoke R. The function names
    communicate the data type of the returned results; `SCRIPT_REAL` returns float
    values, `SCRIPT_BOOL` returns true or false values, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax of a `SCRIPT_` function is represented in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.9: R script syntax'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding example code calculates the average profit, but we will get to
    more examples in the next sections. Let’s start by reproducing Tableau functionality
    using the R integration and hence prove that R is working properly.
  prefs: []
  type: TYPE_NORMAL
- en: Reproducing native Tableau functionality in R
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For our first exercise, we will use the `AVG`, `MEDIAN`, and `STDEV` functions
    in Tableau and compare the results with the `mean`, `median`, and `sd` R functions.
    This will allow you to practice the `SCRIPT_` functions, begin to understand R
    syntax, and compare the results generated by Tableau with those generated by R.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to [https://public.tableau.com/profile/marleen.meier/](https://public.tableau.com/profile/marleen.meier/)
    to locate and download the workbook associated with this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the `median | mean | sd` worksheet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `Superstore` data source.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the following Tableau-centric calculations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Tab Avg`: `WINDOW_AVG(SUM(Sales))`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tab Median`: `WINDOW_MEDIAN(SUM(Sales))`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tab Stdev`: `WINDOW_STDEV(SUM(Sales))`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Place the **Region** dimension on the **Rows** shelf and **Sales** on the **Text**
    shelf.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Double-click on **Tab Avg**, **Tab Median**, and **Tab Stdev**. They will now
    appear on the **Measures Values** shelf:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.10: Testing R'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure R is installed, connected, and running as per the instructions in
    the *R installation and integration* section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you haven’t installed the `Rserve` package yet, type `install.packages("Rserve")`
    into your R interface to install the `Rserve` package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, type `library(Rserve); Rserve()` into the R interface. You may see the
    following error:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this case, type `Rserve(args = "--no-save")`. R requires you to make a choice
    of saving, not saving, or a combination (vanilla) after your session ends (not
    saving is my preferred option but the other two will work too).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Connect R to Tableau as demonstrated in the *R installation and integration*
    section. After you have done so, return to Tableau and click the **Test Connection**
    button to see if it works:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.11: Testing R connection'
  prefs: []
  type: TYPE_NORMAL
- en: Click **OK** to close the windows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the following R-centric calculations in Tableau. Note that R functions
    (such as `mean`) are case-sensitive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`R` `-` `mean`: `SCRIPT_INT("mean(.arg1)", SUM(Sales))`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`R` `-` `median`: `SCRIPT_REAL ("median(.arg1)", SUM(Sales))`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`R` `-` `sd`: `SCRIPT_INT("sd(.arg1)", SUM(Sales))`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Place each of the R-calculated fields on the **Measure Values** shelf and arrange
    them so that the same types of calculations are next to each other but alternating
    Tableau and R-centric; for example, **Tab Avg** then **R – mean** then **Tab Median**
    then **R – median** and so on. Since `SCRIPT_` functions are categorized as table
    calculations (more on that later), be sure that each instance of the R-calculated
    fields as well as the Tableau-calculated fields use **Compute Using** set to **Table
    (Down)**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.12: Tableau versus R output'
  prefs: []
  type: TYPE_NORMAL
- en: Observe that the Tableau and R functions show identical results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that `INT` has been replaced with `REAL` in the median calculations, demonstrating
    that, as the names suggest, `SCRIPT_REAL` uses float values and `SCRIPT_INT` uses
    integers. In the case of the median, the `SCRIPT_INT` function results in a rounding
    difference – try it out and see for yourself!
  prefs: []
  type: TYPE_NORMAL
- en: This was our very first exercise with R integration—easy, right? The purpose
    of this exercise was mainly to show you that the R calculation works and therefore
    we compared three of the same calculations, each one calculated by Tableau as
    well as R. Or in other words, replicating Tableau functionality to prove that
    the R integration works as expected. The next exercise will be something that
    we can’t do with Tableau’s built-in functionality (as of the time of writing).
    We are going to calculate a regression analysis with more than two variables.
  prefs: []
  type: TYPE_NORMAL
- en: Using R for regression calculations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Succinctly stated, regression analysis is a technique for estimating variable
    relationships. There are several types of regression analyses, the most popular
    of which is linear regression. As demonstrated in the following screenshot, linear
    regression estimates a line that best fits the data and is a built-in function
    in Tableau.
  prefs: []
  type: TYPE_NORMAL
- en: 'You only need two measures on **Rows** and **Columns** as well as a dimension
    to partition the points in your view. Then, you go to **Analysis** and drag the
    **Trend Line** onto your screen and select **Linear**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.13: Scatterplot'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that this screenshot is from Tableau. You can access it by clicking on
    the **Scatterplot** worksheet in the workbook associated with this chapter. It’s
    a simple scatterplot with trend lines turned on. Trend lines, in Tableau, default
    to linear but also include logarithmic, exponential, and polynomial options, which
    are all examples of regression analysis. By accessing **Worksheet** | **Export**
    | **Data** in a visualization utilizing a trend line, you can generate an **Access**
    database with predictions and residuals for marks on the view. But this is a tedious
    process and does not give a robust, dynamic solution for implementing more vigorous
    uses of linear regression. Using R provides much more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear regression may use single or multiple variables. Single-variable equations
    are great for learning, but multiple-variable equations are typically necessary
    for real-world applications. The following exercise includes multiple-variable
    equations. Our goal for this exercise is to determine how closely a linear regression
    model of **Profit** fits `COUNT(Quantity)`, `SUM(Sales)`, and `AVG(Discount)`:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `Regression` worksheet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `Superstore` data source.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Build the basic layout by placing **Profit** on the **Columns** shelf and **State**
    on the **Rows** shelf and filtering to **Top 10** by **Sum** of **Profit** by
    placing **State** on the **Filters** shelf as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.14: Filter top 10'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a calculated field entitled `Profit_Expected` utilizing the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The details of this function will be explained shortly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a calculated field entitled `% Diff` that calculates the percent difference
    between `SUM`(`Profit`) and `Profit_Expected`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a calculated field entitled `Profit_Expected (residuals)` to return
    the difference between `SUM`**(**`Profit`**)** and `Profit_Expected` in terms
    of dollars:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Place **Profit_Expected** on the **Columns** shelf, next to **Profit**. Then,
    click on either one and enable **Dual Axis**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on one axis and select **Synchronize Axis**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **SUM(Profit)** section on the **Marks** card, move **% Diff** onto the
    **Color** shelf. Select the **Red-Black Diverging** palette as well as `2` **Steps**
    in **Stepped Color**. This way, all positive values will be black and all negative
    ones red. Make sure that **Bar** is selected as the view type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.15: Color coding'
  prefs: []
  type: TYPE_NORMAL
- en: From the menu, select **Analysis** | **Stack Marks** | **Off**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Profit_Expected** section on the **Marks** card, move **Profit_Expected
    (residuals)**, **% Diff**, and **Profit_Expected** to the **Label** shelf. Make
    sure that **Gantt Bar** is selected as the view type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Double-check that all table calculations (indicated by the triangle sign: **Profit_Expected
    (residuals)**, **% Diff**, and **Profit_Expected**) are using **State** for the
    computation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.16: Compute using'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Label** and the three dots in the **Text** section and edit the
    label to your liking:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.17: Expected profits'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adjust the size of the **Bar** and **Gantt Bar** as desired and observe the
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.18: Regression'
  prefs: []
  type: TYPE_NORMAL
- en: The visualization in *Figure 15.18* shows a comparison of the actual profit,
    the expected profit, and the difference between the two. This calculation is especially
    helpful in retail markets but also in financial planning for any company.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve completed the exercise, let’s take a moment to consider some
    of the code we used in this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `SCRIPT_REAL` | This Tableau function calls the R engine and returns a float
    value. |'
  prefs: []
  type: TYPE_TB
- en: '| `"x <- lm(.arg1 ~ .arg2 +.arg3+.arg4); x$residuals"` | This is an R expression
    that houses a variable, a function, and an argument, and then returns predicted
    values. |'
  prefs: []
  type: TYPE_TB
- en: '| `x <-` | This is the variable to be populated by the subsequent R function.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `lm(.arg1 ~ .arg2 + .arg3 +.arg4)` | This R function is used to fit linear
    models. It can be used to return regression based on variables provided by the
    argument.The information in the parentheses is called an argument and is used
    to fit the model. Specifically, the response is to the left of the tilde (`~`),
    and the model is to the right. Thus, this is a multi-variable linear regression
    where `.arg1 =` `SUM(Profit)`, `.arg2 = COUNT(Quantity)`, `.arg3 = SUM(Sales)`,
    and `.arg4 = AVG(Discount)`. In English, the argument could be read as `SUM(Profit)`,
    and is modeled as the combined terms of `COUNT(Quantity)`, `SUM(Sales)`, and `AVG(Discount)`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `x$fitted` | The `lm` function returns many values as part of its model object,
    including coefficients, residuals, rank, and fitted values. `x$fitted` is referencing
    the fitted values generated as a result of passing data to the model. |'
  prefs: []
  type: TYPE_TB
- en: '| `", SUM(Profit), COUNT(Quantity), SUM(Sales) , AVG(Discount))` | These are
    the parameters used to populate the `.arg#` variables. Note that the double-quote
    (`"`) designates the end of the code passed to R, and the comma (`,`) designates
    the second half of the Tableau function, that is, the expression. |'
  prefs: []
  type: TYPE_TB
- en: After having successfully implemented the regression, we will now investigate
    a different statistical method that is often used to differentiate between subsets
    within a dataset, called clustering.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering in Tableau using R
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Clustering is used to select smaller subsets of data with members sharing similar
    characteristics from a larger dataset. As an example, consider a marketing scenario.
    You have a large customer base to which you plan to send advertising material;
    however, cost prohibits you from sending material to every customer. Clustering
    the dataset will return groupings of customers with similar characteristics. You
    can then survey the results and choose a target group.
  prefs: []
  type: TYPE_NORMAL
- en: Major methods for clustering include hierarchical and *k*-means. Hierarchical
    clustering is more thorough and thus more time-consuming. It generates a series
    of models that range from *1*, which includes all data points, to *n*, where each
    data point is an individual model. *k*-means clustering is a quicker method in
    which the user or another function defines the number of clusters. For example,
    a user may choose to create four clusters from a dataset of a thousand members.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clustering capabilities are included with Tableau. You can find this functionality
    under the **Analytics** tab. The clustering implementation in Tableau is based
    on four pillars:'
  prefs: []
  type: TYPE_NORMAL
- en: Solid methodology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeatable results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick processing time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ease of use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be sure to check out more details here ([https://help.tableau.com/current/pro/desktop/en-us/clustering.htm](https://help.tableau.com/current/pro/desktop/en-us/clustering.htm))
    and the tab **Clustering (Tableau native)** in the accompanying solutions workbook.
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous ways the Tableau development team could have approached clustering.
    R, for instance, provides many different clustering packages that use different
    approaches. A Tableau author may have good reason to choose one of these different
    approaches. For example, clustering results are always identical when using the
    native Tableau clustering capabilities. But they do not have to be. By using R
    for clustering, the underlying data and the view may remain unchanged, yet clustering
    could differ with each refresh because the function will stop at the best result
    (local minimum) before it has seen the whole dataset. The trade-off between using
    a so-called local minimum versus a global minimum for performance has been proven
    to be worth it. But depending on the order of numbers, the local minimum can differ
    each time you run the function. This could be advantageous to you if looking for
    edge cases where marks may switch between clusters. The following example explores
    such a case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal in this exercise is to create four clusters out of the countries of
    the world based on birth rate and infant mortality rate:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `Cluster (R)` worksheet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `World Indicators` data source (this dataset ships with Tableau and
    can be found under **Saved Data Sources**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the initial view by placing **Infant Mortality Rate** on the **Columns**
    shelf, **Birth Rate** on the **Rows** shelf, and **Country/Region** on the **Details**
    shelf.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Right-click on each axis and select **Logarithmic** and deselect **Include
    Zero**. This will spread the data points more uniformly and will help make the
    visualization more aesthetically pleasing and easier to read:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B18435_15_19.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 15.19: Clustering'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a calculated field named `Cluster` with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The details of this code will be explained at the end of this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Drag the **Cluster** field you just created to the **Detail** and the **Color**
    shelves. Note that the Rserve engine throws an error:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B18435_15_20.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 15.20: Error handling'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is because nulls exist in the underlying dataset. For example, the data
    does not include the **Infant Mortality Rate** for *Puerto Rico*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you encounter this error with other measures, the same solution applies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To rectify the error, drag an instance of **Infant** **Mortality Rate** onto
    the **Filters** shelf. Within the **Filter** dialog box, select the values as
    shown to remove all values below `0.01`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Graphical user interface, application'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Description automatically generated](img/B18435_15_21.png)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 15.21: Filter'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Make sure that you set **Cluster** to **Discrete** and **Compute Using** |
    **Country/Region** to avoid another error: *error in k-means (m, 4, nstart = 5):
    more cluster centers than distinct data points*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The resulting view should look like the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Chart, scatter chart'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B18435_15_22.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 15.22: Clustering'
  prefs: []
  type: TYPE_NORMAL
- en: Press *F5* and observe that the clustering changes with each refresh.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we’ve completed the exercise, let’s take a moment to consider some
    of the code we saw:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `SCRIPT_REAL` | This Tableau functions calls the R engine and returns a float
    value. |'
  prefs: []
  type: TYPE_TB
- en: '| `"m <- cbind(.arg1, .arg2); kmeans(m,4,nstart=1)$cluster"` | This is the
    R expression that houses a variable, a function, and an argument, and then returns
    clusters. |'
  prefs: []
  type: TYPE_TB
- en: '| `m <-` | This is the variable to be populated by the subsequent R function.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `cbind` | This R function combines the following `.arg#` variables into columns.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `(.arg1, .arg2)` | The variables within the parentheses are referred to as
    an argument. Each variable contains vector information. Specifically, `.arg1 =
    AVG( [Infant Mortality Rate] )` and `.arg2 = AVG([Birth Rate])`. |'
  prefs: []
  type: TYPE_TB
- en: '| `kmeans(m,4,nstart=1)$cluster"` | `kmeans` declares the method of clustering.
    `m` contains the vector created by the `cbind` argument. The `4` integer declares
    the number of clusters. `nstart` declares the number of random sets. |'
  prefs: []
  type: TYPE_TB
- en: '| `", AVG( [Infant Mortality Rate] ), AVG([Birth Rate]))` | These are the parameters
    used to populate the `.arg#` variables. Note that the double-quote (`"`) designates
    the end of the code passed to R, and the comma (`,`) designates the second half
    of the Tableau function, that is, the expression. |'
  prefs: []
  type: TYPE_TB
- en: What did we achieve? Well, we were able to categorize the countries in our dataset
    into four subgroups, based on life expectancy. We show the results of the clustering
    on a scatterplot with the two measures, infant mortality, and birth rate. This
    way, we can indirectly analyze four measures at the same time, which in this case
    are **Infant Mortality Rate**, **Birth Rate**, **Country/Region**, and **Life
    Expectancy**. The R clustering is based on a *k*-means approach, which differs
    from the Tableau default clustering and can be adjusted to any approach that it
    is possible to execute in R.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to check out the world of quantiles.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing quantiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quantiles are often considered synonymous with quartiles. They are not. Quantiles
    are the sets that make up an evenly divided population of values. A quartile is
    a type of quantile—as is a quintile, a tercile, and a decile, for example. To
    understand how quantiles evenly divide a population of values, imagine multiplying
    a population by 1/4, 2/4, 3/4, and 4/4, and you get 4 quartiles. To get quintiles,
    you multiply the population by 1/5, 2/5, 3/5, 4/5, 5/5, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tableau allows you to view quantiles by right-clicking on an axis and choosing
    **Add Reference Line** | **Distribution** | **Computation** | **Quantiles**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.23: Terciles'
  prefs: []
  type: TYPE_NORMAL
- en: But you can also change the number of tiles to 4, 5, or any other number to
    create quartiles, quintiles, and so on. The functionality of quantiles thus accessed,
    however, is quite limited. Primarily, this is because reference lines do not generate
    measures that can be placed on shelves. This limits the visualization options.
    Generating quantiles via R greatly expands those options.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal for this exercise is to create *n* quantiles through R to view the
    customer distribution by sales. We will further expand the exercise by creating
    parameters that restrict the number of members in the total dataset to a given
    percentile range. Finally, we will fine-tune the visualization by adding jittering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s have a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `Quantiles` worksheet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `Superstore` data source.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the view type to **Shape** on the **Marks**card.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Drag **Sales** to the **Rows** shelf, **Customer Name** to the **Details**
    shelf, and **Region** to the **Color** shelf:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.24: Quantiles'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create and display a parameter entitled `Number of quantiles` with the following
    settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.25: Quantile parameter'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the created parameter and select **Show Parameter**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a calculated field entitled `Quantiles` with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The details of this code will be explained at the end of this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Right-click on the newly created calculated field `Quantiles` and select **Convert**
    **to Discrete**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create and display two parameters, **Select Percentile Bottom Range** and **Select
    Percentile Top Range**. Use the following settings for both:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.26: Percentile parameter'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on both newly created parameters and select **Show Parameter**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a calculated field entitled `Percentile` with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Drag **Quantiles** to the **Columns** shelf and set **Compute Using** to **Customer
    Name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag **Percentile** to the **Filters** shelf, click **OK**, then set **Compute
    Using** to **Customer Name**. Open the filter again and select the value **True**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So, let’s recapture what we have done so far. We plotted the sales values per
    region, then we added an R script that creates quantiles out of the sales dot
    cloud. We also created a parameter that lets us select how many quantiles we want
    to see in the view since we learned that quantiles don’t always have to be quartiles
    but could also be terciles or quintiles, or more.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next up we will see this view in action, and we will add jittering.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You may wish to add these additional steps to further enhance the visualization.
    To utilize jittering, create an index calculated field, `Index()`, and place that
    field on the **Columns** shelf. Set **Compute Using** to **Customer Name**. Be
    sure to deselect **Show Header** so **Index** does not display in the view.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Right-click on each axis and select **Logarithmic** and deselect **Include
    Zero**. You should see the following on your screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.27: Quantiles dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, you can see that we decided to show four quantiles
    (utilizing the **Number of quantiles** parameter), which as such are called quartiles.
    By adding the `Index()` function to columns, we were able to divide the quantiles
    into each of the four components. One conclusion from this dashboard could be
    that, in each of the four quantiles, the West region has the highest sales figures,
    and the South region has the lowest. However, the Central and South regions come
    remarkably close to each other in the third quantile. Based on this information,
    we could do some further analysis on what is going on in those regions specifically
    and why the Central region’s sales decreased in that quantile compared to the
    other regions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve completed the exercise, let’s take a moment to consider some
    of the code we looked at in this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `SCRIPT_REAL` | This Tableau function calls the R engine and returns a float
    value. |'
  prefs: []
  type: TYPE_TB
- en: '| `x <- .arg1;` | `x` is the variable on which we’ll create quantiles. The
    variable, in this case, is `[Sales]`. |'
  prefs: []
  type: TYPE_TB
- en: '| `y <- .arg2[1];` | This variable sets the quantile count. `[1]` forces a
    single number to be set and not a vector. |'
  prefs: []
  type: TYPE_TB
- en: '| `m <- c(1:y)/y;` | `m` distributes probabilities evenly from `1:y`. |'
  prefs: []
  type: TYPE_TB
- en: '| `n <- length(x);` | This sets the size of the loops. The loops are discussed
    below. |'
  prefs: []
  type: TYPE_TB
- en: '| `z <- c(1:n); for (i in c(1:n)) z[i] = 0;` | `z` sets the initial response
    vector by setting everything to 0. |'
  prefs: []
  type: TYPE_TB
- en: '| `for (j in c(1:y)) for (i in c(1:n)) z[i] = if (x[i] <= quantile(x,m)[j]
    && z[i] == 0 ) j else z[i];` | For each quantile, we go through the `z` vector,
    and for each entry, we test whether the value of `x` is less than the upper limit
    of that quantile. If `x` has previously been set, we leave it. Otherwise, `z[i]`
    = that quantile (`j`). |'
  prefs: []
  type: TYPE_TB
- en: In this exercise, you saw that by using R, a Tableau default functionality such
    as clustering can be extended and will give your dashboard users more freedom
    to answer new questions that come up while using the dashboard because it will
    be possible for them to change, for example, parameters and see the visualization
    changing. Now that we’ve learned about a few possible R use cases, it is time
    to discuss something worth your attention, the performance challenges that come
    along with using programming integrations with Tableau.
  prefs: []
  type: TYPE_NORMAL
- en: Performance challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: R scripts are table calculations. Like all table calculations, this means that
    you can only utilize fields that are on your view. Also, it’s important that you
    set partitioning and addressing correctly; otherwise, you may receive unexpected
    results.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Introducing quantiles* section, you may have noticed that the greater
    the number of quantiles set with the **Number of quantiles** parameter, the longer
    it takes the results to display. This is because R runs the loops in the **Quantile**
    calculated field one iteration for each quantile. For example, if the **Number
    of quantiles** parameter is set to **1**, the loop is instigated only once. If
    it is set to **2**, it runs twice, and so forth. The rule of thumb is that R code
    is executed once for every partition. The more partitions, the slower the performance.
    Therefore, when using R code, reduce the number of partitions whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'This was the R part of this chapter. I hope you enjoyed it and that it has
    given you the inspiration to produce your own ideas to extend the functionality
    we have shared so far. We will now continue with the other very well-known programming
    language: Python. Luckily for us, Tableau also has an integration layer with Python.'
  prefs: []
  type: TYPE_NORMAL
- en: Python installation and integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Python is an interpreted programming language and is very well known for its
    readability. The first release was in 1991, so quite some time ago (longer than
    most people would guess), and it was developed by Guido van Rossum. TabPy is an
    external service that will allow you to connect Python and Tableau—similar to
    Rserve. By using TabPy, you will be able to parse fields from your Tableau dashboard
    to Python, execute a calculation, and send back the result as a newly calculated
    field to Tableau. Or you can also call functions that you implemented in Python,
    again in a calculated field. A more extensive article on TabPy can be found here:
    [https://tableaumagic.com/tableau-and-python-an-introduction](https://tableaumagic.com/tableau-and-python-an-introduction).'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python is typically not difficult, but it does involve more than
    simply double-clicking on an executable. To successfully connect Tableau with
    Python, you might have to install some libraries and execute comments on the command
    line. The following paragraphs will guide you through this process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way to install Python is by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download, for example, Anaconda with the Python 3.10 version: [https://www.anaconda.com](https://www.anaconda.com).
    Any other Python interpreter will work too.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To integrate Python and Tableau, some additional steps are needed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Open, for example, Jupyter Notebook within Anaconda and write:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Alternatively, execute the following command on the command line or Terminal
    (for Mac) in your Python directory:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Navigate to the directory where `TabPy` has been installed via the command
    line or Terminal (for Mac) and type `tabpy` into the command line or Terminal
    interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.28: Starting TabPy'
  prefs: []
  type: TYPE_NORMAL
- en: You are now connected to the `tabpy` server, which must remain open while running
    Tableau and Python combined.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you encounter any other issues with TabPy, for example, version incompatibilities,
    a quick Google search will go a long way.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open Tableau, select **Help** | **Settings and Performance** | **Manage Analytics
    Extension Connection**, select `localhost` for **Server****,** and enter `9004`
    for **Port**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B18435_15_29.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 15.29: Analytics Extension connection'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the previous screenshot, it is possible to set up usernames,
    passwords, and SSL if you have any security concerns or for a bigger enterprise-wide
    rollout.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on **Test Connection** and you should see the following popup:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.30: Testing the analytics extension'
  prefs: []
  type: TYPE_NORMAL
- en: 'The full documentation on how to get TabPy up and running can be found at [https://github.com/tableau/TabPy](https://github.com/tableau/TabPy).
    If you don’t want to or cannot install TabPy on your machine, Tableau also offers
    a Docker container that will install the latest version of TabPy. You can find
    more information here: [https://hub.docker.com/r/emhemh/tabpy/](https://hub.docker.com/r/emhemh/tabpy/).'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Python functionality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just like R, TabPy makes use of the `SCRIPT_` functions in Tableau. In the
    next sections, we will practice working with TabPy and will look at multiple use
    cases. Tableau calculations using TabPy look very similar to R’s. For TabPy, it
    is important to add a `return` statement to the calculated field and notice that
    arguments are noted with an underscore instead of a dot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.31: Python TabPy syntax'
  prefs: []
  type: TYPE_NORMAL
- en: This will be manifested in the next exercises; we will first investigate random
    number generators.
  prefs: []
  type: TYPE_NORMAL
- en: Random and random normal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Many calculations are easily accessible via the calculated fields, others via
    the table calculations—and then there are some hidden functions. Hidden because
    those are not (yet) fully supported or tested; therefore, use them with care.
    If you tried to find the function `Random`, for example, you would not be able
    to. But you can still use the `Random()` function, as can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B18435_15_32.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 15.32: Random'
  prefs: []
  type: TYPE_NORMAL
- en: Another option is using TabPy to get the `Random` function. We will look at
    random as well as random normal with the variables `mu` and `sigma`. This will
    let us draw random numbers from a distribution, a method often used in statistics
    and quantitative modeling, among other areas, to simulate, reproduce, or calculate
    probabilities; `mu` and `sigma` are the mean and standard deviation defining the
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Generating random numbers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Perform the following steps to create a dot cloud of random variables with
    a specific underlying distribution, defined by the mean and standard deviation:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an Excel sheet with one `Index` column and rows with the numbers 1-1,000\.
    This is needed to have an initial dataset with the number of rows we want to use
    for the random number generator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the file and connect Tableau to this Excel sheet. You should see one imported
    measure called **Index** (just like the header in your Excel file).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect Tableau to Python as described in *Python installation and integration*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a calculated field called `Random`, which should look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Drag **Index** to **Rows** and **Random** to **Columns**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Disable **Aggregate Measures** on the **Analysis** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.33: Random visualized'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding screenshot, you can see the 1,000 random data points. Let’s
    consider some of the code used in this exercise that allowed us to generate this
    visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `SCRIPT_REAL` | This Tableau function calls the Python engine and returns
    a float value. |'
  prefs: []
  type: TYPE_TB
- en: '| `"from numpy import random as rd` | In this part of the code, we need the
    Python library `numpy`, and from that library, we need the module `random`, which
    we will load with the shorter name `rd`. |'
  prefs: []
  type: TYPE_TB
- en: '| `return` | This command is simply needed to return a value. |'
  prefs: []
  type: TYPE_TB
- en: '| `rd.random(_arg1[0]).tolist()"` | In this step, we call the module `rd` that
    we imported before. From the `rd` module, we retrieve the `random` function. The
    `_arg1[0]` is needed to activate the function given a certain value. And lastly,
    we put all the retrieved values in a list of values by adding `.tolist()`. |'
  prefs: []
  type: TYPE_TB
- en: '| `SIZE()` | This is the value that will be replacing `_arg1` and `_arg1` is
    required by the `random` function. We use `SIZE()` to fulfill the requirement
    because it will return the number of rows in the partition and is sufficient to
    get a random number back from the function. |'
  prefs: []
  type: TYPE_TB
- en: We got exactly 1,000 numbers because our initial Excel sheet had 1,000 rows.
    By using calculated fields, you can add columns to a data frame but no rows. Therefore,
    we need a data source that will provide us with the data schema. In the next section,
    we will learn how to specify a random number drawn from a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Random normal
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, let’s reproduce a random variable with a normal distribution. This technique
    is often used in statistical modeling to calculate probabilities. The random normal
    values can be used instead of or in addition to observations you already collected.
    Once we know how to use a normal distribution, you can extend this knowledge and
    create other distributions in Tableau as well:'
  prefs: []
  type: TYPE_NORMAL
- en: Reuse the workbook from the previous exercise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `Random Normal` calculated field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Place **Random Normal** on **Columns** and **Index** on **Rows**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Disable **Aggregate Measures** on the **Analysis** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select a **Marks** type of **Circle**. You can now see a plot with the 1,000
    data points normally distributed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.34: Normal distribution visualized'
  prefs: []
  type: TYPE_NORMAL
- en: 'To give your users more flexibility, you can also add parameters to your view
    that interact with the Python integration. For example, create the following two
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B18435_15_35.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 15.35: The sigma and mu parameters'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, create a calculated field called`Random Normal Param` like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the parameter control to your view so your users can decide which variables
    they want to pass to Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.36: Final normal distribution worksheet'
  prefs: []
  type: TYPE_NORMAL
- en: Compared to our prior visualization with the normal distribution, you can see
    in the preceding screenshot that by changing the `mu` parameter to 10, we change
    the mean to 10 and thus can move the whole dot cloud in any direction. With the
    random number being available in Tableau, you can, for example, visualize a Monte
    Carlo simulation, which is used in many real-life applications because it can
    model possible probability outcomes and thus helps interested parties understand
    the impact of risk and uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: 'More information on how to calculate a Monte Carlo simulation in Tableau can
    be found here – [https://jacksontwo.com/exploring-python-tableau](https://jacksontwo.com/exploring-python-tableau)
    – and more general Monte Carlo content can be found here: [https://www.ibm.com/topics/monte-carlo-simulation](https://www.ibm.com/topics/monte-carlo-simulation).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on, let’s again consider some of the key lines of code that were
    used in this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `SCRIPT_REAL` | This Tableau function calls the Python engine and returns
    a float value. |'
  prefs: []
  type: TYPE_TB
- en: '| `"from numpy import random as rd` | In this part of the code, we need the
    Python library `numpy`, and from that library, we need the module `random`, which
    we will load with the shorter name `rd`. |'
  prefs: []
  type: TYPE_TB
- en: '| `mu, sigma = _arg2,_arg3` | This part defines that we will refer to `mu`
    and `sigma` with `_arg2` and `_arg3`. |'
  prefs: []
  type: TYPE_TB
- en: '| `return` | This command is simply needed to return a value. |'
  prefs: []
  type: TYPE_TB
- en: '| `rd.normal(mu, sigma, _arg1[0])).tolist()` | In this step, we call the module
    `rd` that we imported before. From the `rd` module, we retrieve the `random` function.
    The `_arg1[0]` is needed to activate the function given a certain value. Optional
    values are `mu` and `sigma`. This time, we will use those two as well. And lastly,
    we put all the retrieved values in a list of values by adding `.tolist()`. |'
  prefs: []
  type: TYPE_TB
- en: '| `SIZE(), [mu], [sigma]` | This is the value that will be replacing `_arg1`,
    `_arg2`, and `_arg3`. Just like before, we use `SIZE()` to activate the function.
    The optional values `mu` and `sigma` will be pointing to the parameter we created
    before. |'
  prefs: []
  type: TYPE_TB
- en: After finishing the first two exercises with TabPy, we learned how we can use
    a random number in Tableau. Next, we changed the random number to a random number
    drawn from a normal distribution and added parameters to the dashboard such that
    the user can change `mu` and `sigma` of the normal distribution. Of course, you
    can change the function in TabPy to other distributions as well.
  prefs: []
  type: TYPE_NORMAL
- en: The next topic is more advanced. We will use TabPy to execute a sentiment analysis
    on newspaper headlines from 2003 to 2021.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating sentiment analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Alongside machine learning and artificial intelligence, another term is being
    used increasingly: **Natural Language Processing** (**NLP**). This is the process
    of machines understanding words and their meaning. Sentiment analysis falls into
    this category; the technique has different flavors but one of them is to measure
    polarity, that is, whether the speaker has a positive or negative opinion. Use
    cases are, for example, datasets of reviews, tweets, comments, plots, lyrics,
    and so on. Let’s have a look!'
  prefs: []
  type: TYPE_NORMAL
- en: 'This exercise is based on the idea of Brit Cava, who used the Makeover Monday
    data from the top 100 songs’ lyrics to try out the Tableau-Python integration.
    You can find the blog post here: [https://www.tableau.com/about/blog/2016/12/using-python-sentiment-analysis-tableau-63606](https://www.tableau.com/about/blog/2016/12/using-python-sentiment-analysis-tableau-63606).
    Let’s reproduce it with this Australian Broadcasting Corporation dataset containing
    one million news headlines: [https://www.kaggle.com/datasets/therohk/million-headlines](https://www.kaggle.com/datasets/therohk/million-headlines).'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `Sentiment` `Analysis` tab in the workbook associated with the
    chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect to the `Headlines` data source.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect Tableau to Python.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `Sentiment Score` calculated field. The formatting, for example, indented
    text, is important:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `Color Coding` calculated field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Place **publish_date** on the **Rows** shelf, as well as **MONTH(publish_date).**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Put **Sentiment Score** on **Columns**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add **Color Coding** to the **Color** shelf. And **headline_text** to **Details**.
    Lastly, drag an average line from the **Analytics** pane on the view (**Per Cell**):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.37: Sentiment Score'
  prefs: []
  type: TYPE_NORMAL
- en: 'Limit the data as needed, considering the performance of your PC. I am showing
    2019-2021 and only Jan, Feb, Nov, and Dec to compare the differences between the
    beginning and end of the years:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.38: Worksheet'
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have loaded the dataset and created a Python calculation that uses
    a pre-trained sentiment analyzer that tells us if a headline is written negative
    or positive. In the preceding figure, we brought everything together, and you
    can see that in every month in 2021, the negative news is dominating, with February
    being the worst (an average score of -10.45) and December being the most positive
    (an average score of -0.14). We will continue now with a check on what the news
    is most often reporting about.
  prefs: []
  type: TYPE_NORMAL
- en: 'To know the topics that were most often discussed in the ABC news, we must
    count the words used. Perhaps there is a way to do this in Tableau, by splitting
    the **headline_text** field into one word each, pivoting and counting but it will
    surely be a tedious process. And there are enough libraries out there to remove
    things like stop words and reduce words to their core, for example, horse = horses.
    Therefore, we will deploy another model. Please follow the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `Start` parameter. This one will help us later to define the period
    we want to search in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.39: Start'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, create an `End` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.40: End'
  prefs: []
  type: TYPE_NORMAL
- en: Show both parameters on a new tab in your Tableau workbook called `most common
    words`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.41: Worksheet'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you will have to write code in your Python IDE of choice (e.g., Jupyter
    Notebook). For now, copy the following code. The explanation will follow at the
    end of this section (don’t forget to change the location in this line `df = pd.read_csv(''abcnews-date-text.csv'')`
    to exactly where your copy of the file is located:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Since the indentation is especially important, here is a screenshot of how
    it should look; you can also see that I specified the location of the `abcnews`
    file to be ‘`/Users/marleenmeier/Downloads/abcnews-date-text.csv`'' since my file
    is located there:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Text'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Description automatically generated with medium confidence](img/B18435_15_42.png)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 15.42: Code'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now run the Python script.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Go back to the most common words tab in your Tableau dashboard and create the
    following calculated field `common words`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can also use the `SCRIPT_STR` function like we did in the previous exercise,
    but for deployed TabPy models, Tableau provides this easier syntax of `MODEL_EXTENSION`
    functions too.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Drag **common words** into the **Rows** and see your first results; between
    January 2014 and December 2015, the word *new* appeared 4,909 times in the headlines
    of ABC news, *police* 4,307 times, and *man* 4,171 times. You see the top 3 because
    it is specified as such in the code, which we will check out in a bit. You can,
    however, change it to any number!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Play with the **Start** and **End** dates and see what happens! Here are two
    more examples; also notice the word count itself, the top 1 word in 2020 (*coronavirus*,
    8,383 times) was used two times more often than the top 1 word between 2014 and
    2015 (*new*, 4,909 times):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.43: Words II'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.44: Words III'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to continue working on this, you could add the top N as a model
    input parameter, as well as the sentiment score if you wanted to see the top N
    for a specific sentiment only.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, we were able to show that Tableau can analyze text data for
    its sentiment, something we have not seen before. To do so, we needed to connect
    Tableau with Python, which is possible by using the external service TabPy. Python
    can make use of libraries such as `nltk.sentiment`—which we used in this case.
    A thorough description of this package can be found here: [https://www.nltk.org/api/nltk.sentiment.html](https://www.nltk.org/api/nltk.sentiment.html).
    There are many other libraries for sentiment analysis but `nltk` is used a lot
    for demonstration purposes and learning. Feel free to try other libraries as well!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s demystify some of the new code instances we included in this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `SCRIPT_REAL` | This Tableau function calls the Python engine and returns
    a float value. |'
  prefs: []
  type: TYPE_TB
- en: '| `from nltk.sentiment import SentimentIntensityAnalyzer` | In this part of
    the code, we need the Python library `nltk`, and from that library, we need the
    module `sentiment` from which we will load the function `SentimentIntensityAnalyzer`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `scores = []``text = _arg1``sid = SentimentIntensityAnalyzer()``ss = sid.polarity_scores(word)`
    | This part defines that our `_arg1` will be called `text`, `scores` will be an
    empty list (and filled later in the code), `sid` will refer to the `SentimentIntensityAnalyzer`
    function, and lastly, `ss` will be the reference to the scores per word. |'
  prefs: []
  type: TYPE_TB
- en: '| `scores.append(ss[''compound''])` | In this step, we will fill the empty
    `scores` table with the polarity scores. |'
  prefs: []
  type: TYPE_TB
- en: '| `return scores` | Here, we are returning the now-filled `scores` table as
    output to Tableau. |'
  prefs: []
  type: TYPE_TB
- en: '| `ATTR([Dialog])` | Our `_arg1` is specified as the field `Dialog` from the
    Tableau workbook. |'
  prefs: []
  type: TYPE_TB
- en: '| `from tabpy.tabpy_tools.client import Client``client = Client(''http://localhost:9004/'')`
    | In this part of the code, we connect Tableau to the Python instance. |'
  prefs: []
  type: TYPE_TB
- en: '| `import pandas as pd``import nltk``from nltk.corpus import stopwords``from
    nltk.tokenize import word_tokenize``from nltk.probability import FreqDist``from
    nltk.sentiment import SentimentIntensityAnalyzer` | Here we load all the required
    libraries. |'
  prefs: []
  type: TYPE_TB
- en: '| `df = pd.read_csv(''abcnews-date-text.csv'')``df[''publish_date''] = pd.to_datetime(df[''publish_date''],
    format=''%Y%m%d'')` | Next, we read the `abcnews` file. |'
  prefs: []
  type: TYPE_TB
- en: '| `_arg1 = pd.to_datetime(_arg1, format=''%Y-%m-%d'')[0]``_arg2 = pd.to_datetime(_arg2,
    format=''%Y-%m-%d'')[0]``df = df.set_index(''publish_date'')` | Then, we must
    convert the input into a readable format for our model. |'
  prefs: []
  type: TYPE_TB
- en: '| `scores = []``filtered_sentence = []` | This part is to create two lists
    that we will fill in the `for` loop. |'
  prefs: []
  type: TYPE_TB
- en: '| `in_range_df = df[df.index.isin(pd.date_range(_arg1, _arg2))]` | Now we will
    filter the data to be between our start and end date. |'
  prefs: []
  type: TYPE_TB
- en: '| `stop_words = set(stopwords.words(''english''))``text = in_range_df[''headline_text'']`
    | Luckily, English stop words are available at our disposal; we are loading them
    in this step. |'
  prefs: []
  type: TYPE_TB
- en: '| `for row in range(0, len(in_range_df)):``text = in_range_df[''headline_text''][row]``word_tokens
    = word_tokenize(text)``for w in word_tokens:``if w not in stop_words: filtered_sentence.append(w)`
    | In this part of the code, we are converting the remaining headers into a token,
    which is needed to calculate the frequency, and finally, the non-stop-word words
    will be stored in the `filtered_sentence` list. |'
  prefs: []
  type: TYPE_TB
- en: '| `fdist = FreqDist(filtered_sentence)` | By using one of the libraries, we
    loaded in the beginning, we can now ask to retrieve the frequency for each word.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `most_common_words = fdist.most_common(3)``return str(most_common_words)`
    | And since we have the frequency now, we can load the most often-used words.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `client.deploy(''common_words'', common_words,''Retrieves the most common
    words'', override = True)` | Lastly, we will deploy the model such that we can
    call it from Tableau Desktop. |'
  prefs: []
  type: TYPE_TB
- en: We have seen embedded Python code now; you create a calculated field and use
    fields from your dataset as input. But what if you wanted to use a large model
    with many lines of code and many different variables, or upfront training of your
    model? Would this exceed TabPy’s capabilities? No! Because next to embedded code,
    we are also able to write Python scripts outside of Tableau.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying models with TabPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At times, your script will just be too long to be used in a calculated field,
    or you’ll need upfront training on a different dataset or an extended dataset
    rather than the one you have in Tableau. In this case, we can use TabPy in a slightly
    different way. You can write a model outside of Tableau—in Python and deploy it
    to Tableau such that you can call it from within the desktop.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the upcoming example, we will build a recommender system that predicts the
    likelihood of a Pima woman having diabetes when inputting 7 parameters (age, BMI,
    pregnancies, blood pressure, glucose, insulin, and skin thickness). The dataset
    is from a 1988 study by *J.W. Smith, J.E. Everhart, W.C. Dickson, W.C. Knowler,
    and R.S. Johannes*, accessible at the following link: [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin with the code in the Jupyter Notebook or your preferred **Integrated
    Development Environment** (**IDE**). Please follow along with the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start the code by importing the `tabpy` client, which is needed to establish
    a Python-Tableau connection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we import all the libraries and data needed. Make sure to replace the
    dataset name with the full path of your file location (for example, `H:/Documents/Diabetes.csv`
    instead of `Diabetes.csv`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we split the dataset into four; two test datasets that will help us check
    how accurate our model is, as well as two training datasets to train the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are interested in more detail and the math behind this code, please check
    [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we will load the `GradientBoosting` model from `sklearn` and fit our
    data; then; we can immediately visualize the score, which can be interpreted as
    the percentage of the total that our model predicted the correct value for:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: And this is the full code in Jupyter:![Graphical user interface, text
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Description automatically generated](img/B18435_15_45.png)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 15.45: Python script'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To conclude this first phase, our model predicted the right outcome in 72.08%
    of cases, either having diabetes or not having diabetes. This is a fairly good
    result. To further improve it, we could add more data (in terms of rows), extend
    our input variables (in terms of columns), or create new features like ratios
    between variables (hidden information could be emphasized this way). But for now,
    we can continue working with the model, because eventually, we want to predict
    the likelihood as a percentage of someone having diabetes. Let’s switch over to
    Tableau:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We won’t need a dataset for this exercise because all our data lives in the
    Jupyter Notebook. In Tableau, you can just select one randomly, as we won’t use
    it. In a new Tableau worksheet called `Diabetes`, create the following seven parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_46.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.46: Age and BloodPressure parameters'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.47: BMI and Insulin parameters'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.48: SkinThickness and Glucose parameters'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18435_15_49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.49: The Pregnancies parameter'
  prefs: []
  type: TYPE_NORMAL
- en: 'After you have created all seven parameters, select all of them and click **Show
    Parameter**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.50: Show Parameter'
  prefs: []
  type: TYPE_NORMAL
- en: 'Please go back to Jupyter now and execute the two last missing pieces of code
    that will create a function to call our model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And lastly, the line that will deploy the function to TabPy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This looks as follows in Jupyter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.51: Deploying the function'
  prefs: []
  type: TYPE_NORMAL
- en: To check if your model has been deployed, type `https://localhost:9004/endpoints`
    in your browser. This will list all the models that have been deployed to TabPy
    on your machine:![](img/B18435_15_52.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 15.52: Deploying the function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go back to Tableau and double-check if the connection to TabPy is still active.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a calculated field called `Diabetes predictor` like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see here that since we did all the coding in Python, we only tell Tableau
    to return a TabPy query called `diabetes_predictor`, then add all the *n* references
    to variables that are required for the function, and lastly add `['response']`
    at the end.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Or, since deployed models on TabPy also support the functions `MODEL_EXTENSION_BOOL`,
    `MODEL_EXTENSION_INT`, `MODEL_EXTENSION_REAL`, and `MODEL_EXTENSION_STR`, you
    can also use this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The second code is a bit shorter and more intuitive; however, both work!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now place the field **Diabetes predictor**on the **Text** shelf and observe
    the outcome:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_53.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.53: Interactive TabPy Diabetes worksheet'
  prefs: []
  type: TYPE_NORMAL
- en: 'By sliding the parameters to the left and right, you will see that the likelihood
    of diabetes changes. The calculated field sends the data of the parameters via
    TabPy to Python, where your data will be fitted to the model. And the result will
    be sent back, and you can see it. Of course, you can build a whole dashboard around
    it. Examples can be found on the Tableau website: [https://www.tableau.com/about/blog/2017/1/building-advanced-analytics-applications-tabpy-64916](https://www.tableau.com/about/blog/2017/1/building-advanced-analytics-applications-tabpy-64916).'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn more about the Python language itself, a good source of
    information is, for example, [https://www.w3schools.com/python/default.asp](https://www.w3schools.com/python/default.asp).
    The web page will, step by step, guide you through the Python syntax. But Tableau
    makes it even easier because a set of functions has already been written for you.
  prefs: []
  type: TYPE_NORMAL
- en: Predeployed TabPy functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Not everyone likes to program outside of Tableau and that’s why Tableau has
    produced a set of widely used, pre-deployed functions you can use out of the box.
    You will still need to execute one line of code, once! But that is all you need
    to do in Python itself. The available functions are ANOVA, T-test, sentiment analysis,
    and PCA but Tableau has mentioned on multiple occasions that more functions might
    be coming soon. You can find the documentation here: [https://tableau.github.io/TabPy/docs/tabpy-tools.html](https://tableau.github.io/TabPy/docs/tabpy-tools.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'But let’s walk through the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In your Jupyter Notebook, execute `tabpy-deploy-models` and see that the four
    functions are installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18435_15_54.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.54: Deploying TabPy default models'
  prefs: []
  type: TYPE_NORMAL
- en: You can double-check this by typing `http://localhost:9004/endpoints` in your
    browser, where you should see all deployed models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'And that’s it; calling the function in a calculated field in Tableau is now
    as easy as the following (using `ttest` as an example function being called):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'I challenge you to compare the Sentiment Score from the TabPy default deployed
    model with the one we created: do they differ? And if so, how?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From Python, you can connect directly to, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot ([https://www.tableau.com/solutions/datarobot](https://www.tableau.com/solutions/datarobot))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataiku ([https://www.dataiku.com/partners/tableau/](https://www.dataiku.com/partners/tableau/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MATLAB ([https://www.mathworks.com/products/reference-architectures/tableau.html](https://www.mathworks.com/products/reference-architectures/tableau.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are all paid third-party tools that help make your data analysis easier.
    And if you can make a connection from R and Python to another external tool, you
    can also leverage that capability back to Tableau via Rserve and TabPy, respectively.
    If you are interested in this type of connection or if you want to refresh the
    topic of deploying functions, you can check out this video – [https://youtu.be/0BN_Y2CxdYY](https://youtu.be/0BN_Y2CxdYY)
    – in which Nathan Mannheimer, a former product manager for advanced analytics
    at Tableau, explains everything we have discussed as well.
  prefs: []
  type: TYPE_NORMAL
- en: What are your personal goals with programming integration? If you have a great
    idea, feel free to share it with the Tableau community.
  prefs: []
  type: TYPE_NORMAL
- en: Honing your R and Python skills
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some of you might feel overwhelmed by using code and are looking for a simpler
    way to learn before using R or Python in Tableau. The website [www.geeksforgeeks.org](http://www.geeksforgeeks.org)
    introduces you to both and lets you practice on-site programming without any installation.
  prefs: []
  type: TYPE_NORMAL
- en: Einstein Discovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are a Salesforce user and bought the Einstein Discovery license, you
    can use another out-of-the-box set of models. AI-driven models ship with Einstein
    Discovery and can be integrated with Tableau workflows. This combination can be
    leveraged to generate powerful insights for your Salesforce data. You can, for
    example, forecast sales from data in Salesforce and load it directly into Tableau,
    then share those insights on your known Tableau Server instance and hence keep
    all dashboards in one place. Since Salesforce and Tableau are both part of the
    Salesforce suite, I wanted to mention this; however, it is also yet another kind
    of software that requires additional licenses, and therefore I decided not to
    go in-depth on its use (indeed, with what you’ve learned in this chapter you can
    replicate much of the functionality with none of the additional cost). If you
    are interested in learning more, I recommend you check out the following page
    and subpages on tableau.com: [https://www.tableau.com/products/einstein-discovery](https://www.tableau.com/products/einstein-discovery).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter just scratched the surface regarding the options of working with
    R and Python. After finishing this chapter, you should now be able to connect
    to Python and R from Tableau and recognize and write the basic syntax for both
    programming languages in Tableau. Most importantly, you are now skilled enough
    to leverage the power of R and Python functions in Tableau from a simple mean
    calculation to regressions, all the way to implementing your own machine learning
    model. Although we covered the installation, integration, and workflow, as well
    as some of the more popular functions and use cases, there is much more to explore.
    In fact, the possibilities of Tableau’s programming integration remain largely
    uncharted territory in the BI community.
  prefs: []
  type: TYPE_NORMAL
- en: The intrepid in data visualization are pushing the envelope, but there is much
    to be done. For those readers looking to enhance their career options, expertise
    in both packages could offer great advantages. And there is more to come!
  prefs: []
  type: TYPE_NORMAL
- en: 'During the Tableau Conference 2023, the company sent a clear message, Tableau
    will continue to develop its advanced analytics and AI capabilities. Newly announced
    products like Tableau GPT and, with it, Tableau Pulse make me feel impatient for
    the amazing features to come. Find a summary of what to expect here: [https://www.tableau.com/blog/data-innovations-tableau-conference-2023](https://www.tableau.com/blog/data-innovations-tableau-conference-2023).'
  prefs: []
  type: TYPE_NORMAL
- en: While the next chapter is sadly the last chapter of this book, we’ve still got
    time to explore another hot topic. Alongside advanced analytics, data governance
    is an increasingly useful area to explore. Regulations and increasing data security
    risks force companies to put more emphasis on well-structured guidelines and quality
    checks. We will introduce you to the other side of Tableau in *Chapter 16*, *Developing
    Data Governance Practices*.
  prefs: []
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask questions to the author, and learn about new releases – follow the QR code
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/tableau](https://packt.link/tableau)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code2044012316175764640.png)'
  prefs: []
  type: TYPE_IMG
