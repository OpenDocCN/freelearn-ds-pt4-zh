<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer212" class="IMG---Figure">
			<h1 id="_idParaDest-250" class="chapter-number"><a id="_idTextAnchor432"/>11</h1>
			<h1 id="_idParaDest-251"><a id="_idTextAnchor433"/>Unsupervised Machine Learning on Network Data</h1>
			<p>Welcome to another exciting chapter exploring network science and data science together. In the last chapter, we used supervised ML to train a model that was able to detect the revolutionaries from the book <em class="italic">Les Miserables</em>, using graph features alone. In this chapter, we are going to explore unsupervised ML and how it can also be useful in graph analysis as well as node classification with <span class="No-Break">supervised ML.</span></p>
			<p>The order these two chapters have been written in was intentional. I wanted you to learn how to create your own training data using graphs rather than being reliant on embeddings from unsupervised ML. The reason for this is important: when you rely on embeddings, you lose the ability to interpret why ML models have been classified the way that they have. You lose interpretability and explainability. The classifier essentially works as a black box, no matter which model you use. I wanted to show you the interpretable and explainable <span class="No-Break">approach first.</span></p>
			<p>In this chapter, we will be using a Python library <a id="_idIndexMarker756"/>called <strong class="bold">Karate Club</strong>. The library is excellent for use in both community detection and the creation of graph embeddings using graph ML. However, there is no way to gain insights into what exactly the model found useful when using this approach. So, I saved it for last. It can still be very effective if you don’t mind the loss <span class="No-Break">of interpretability.</span></p>
			<p>This is going to be a fun chapter, as we will be pulling so many things from this book together. We will create a graph, create training data, do community detection, create graph embeddings, do some network visualization, and even do some node classification using supervised ML. If you started the book by reading this chapter, this will all probably look like magic. If you have been following along since <a href="B17105_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, this should all make sense and be easy <span class="No-Break">to understand.</span></p>
			<h1 id="_idParaDest-252"><a id="_idTextAnchor434"/>Technical requirements</h1>
			<p>In this chapter, we will be using the Python libraries NetworkX, pandas, scikit-learn, and Karate Club. Other than Karate Club, these libraries should be installed by now, so they should be ready for your use. The steps for installing Karate Club are included in this chapter. If other libraries are not installed, you can install Python libraries with <span class="No-Break">the following:</span></p>
			<pre class="source-code">
pip install &lt;library name&gt;</pre>
			<p>For instance, to install NetworkX, you would <span class="No-Break">do this:</span></p>
			<pre class="source-code">
pip install networkx</pre>
			<p>In <a href="B17105_04.xhtml#_idTextAnchor158"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, we also introduced the <strong class="source-inline">draw_graph()</strong> function, which uses both NetworkX and <strong class="source-inline">scikit-network</strong>. You will need that code anytime that we do network visualization. Keep <span class="No-Break">it handy!</span></p>
			<p>All the code is available from the GitHub <span class="No-Break">repo: </span><a href="https://github.com/PacktPublishing/Network-Science-with-Python"><span class="No-Break">https://github.com/PacktPublishing/Network-Science-with-Python</span></a><span class="No-Break">.</span><a id="_idTextAnchor435"/></p>
			<h1 id="_idParaDest-253"><a id="_idTextAnchor436"/>What is unsupervised ML?</h1>
			<p>In books<a id="_idIndexMarker757"/> and courses about ML, it is often explained that there are three different kinds: supervised learning, unsupervised learning, and reinforcement learning. Sometimes, combinations will be explained, such as semi-supervised learning. With supervised learning, we provide data (X) and an answer (y), and the model learns to make predictions. With unsupervised learning, we provide data (X), but no answer (y) is given. The goal is for the model to learn to identify patterns and characteristics of the data by itself, and then we use those patterns and characteristics for something else. For instance, we can use unsupervised ML to automatically learn the characteristics of a graph and convert those characteristics into embeddings that we can use in supervised ML prediction tasks. In this situation, an unsupervised ML algorithm is given a graph (G), and it generates embeddings that will serve as the training data (X) that will be used to be able to <span class="No-Break">predict answers.</span></p>
			<p>In short, the goal of unsupervised ML is to identify patterns in data. Often, we call these patterns clusters, but this is not limited to clustering. Creating embeddings is not clustering. However, with embeddings, a complex network has been reduced to a few numeric features that ML will be better able <span class="No-Break">to use.</span></p>
			<p>In this chapter, you’ll see firsthand what that actually looks like, as well as the pros and cons of this approach. This is not all positive. There are some less-than-desirable side effects to using embeddings as <span class="No-Break">training data<a id="_idTextAnchor437"/>.</span></p>
			<h1 id="_idParaDest-254"><a id="_idTextAnchor438"/>Introducing Karate Club</h1>
			<p>I’m going to<a id="_idIndexMarker758"/> showcase a Python library that we have touched on previously in this book: Karate Club. I mentioned it briefly in previous chapters, but now we are going to actually use it. I purposefully held off on going into detail before now, because I wanted to teach core approaches to working with networks before showing seemingly easy approaches to extracting communities and embeddings from networks using ML. This is because there are some undesirable side effects to using network embeddings rather than metrics extracted from a network. I will get into that in a bit. For now, I want to introduce this awesome, performant, and reliable <span class="No-Break">Python library.</span></p>
			<p>Karate Club’s documentation (<a href="https://karateclub.readthedocs.io/en/latest/">https://karateclub.readthedocs.io/en/latest/</a>) gives a clear and <a id="_idIndexMarker759"/>concise explanation of what the <span class="No-Break">library does:</span></p>
			<p class="author-quote">Karate Club is an unsupervised machine learning extension library for NetworkX. It builds on other open source linear algebra, machine learning, and graph signal processing libraries such as NumPy, SciPy, Gensim, PyGSP, and Scikit-learn. Karate Club consists of state-of-the-art methods to do unsupervised learning on graph-structured data. To put it simply, it is a Swiss Army knife for small-scale graph mining research.</p>
			<p>Two things should stand out from this paragraph: <em class="italic">unsupervised machine learning</em> and <em class="italic">graph</em>. You can think of Karate Club simply as unsupervised learning for graphs. The outputs of Karate Club can then be used with other libraries for <span class="No-Break">actual prediction.</span></p>
			<p>There are so many cool approaches to unsupervised learning stacked into Karate Club that it is a real thrill to learn about them. You can learn about them at <a href="https://karateclub.readthedocs.io/en/latest/modules/root.html">https://karateclub.readthedocs.io/en/latest/modules/root.html</a>. The thing that I love the most is that the documentation links to the original research papers that were written about the algorithms. This allows you to really get to know the processes behind unsupervised ML models. To pick out models to use for this chapter, I read seven research papers, and I loved every moment <span class="No-Break">of it.</span></p>
			<p>Another nice<a id="_idIndexMarker760"/> thing about this library is that the outputs are standardized across models. The embeddings generated by one model will be like the embeddings generated by another model. This means that you can easily experiment with different approaches for embeddings, and see how they affect models used for classification. We will do exactly that in <span class="No-Break">this chapter.</span></p>
			<p>Finally, I’ve never seen community detection as simple as I have with Karate Club. Using NetworkX or other libraries for Louvain community detection can take a little work to set up. Using <strong class="bold">Scalable Community Detection</strong> (<strong class="bold">SCD</strong>) from Karate Club, you can go from<a id="_idIndexMarker761"/> a graph to identified communities in very few lines of code. It’s <span class="No-Break">so clean.</span></p>
			<p>If you want to learn more about Karate Club and graph machine learning, I recommend the book <em class="italic">Graph Machine Learning</em>. You can pick up a copy at <a href="https://www.amazon.com/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/">https://www.amazon.com/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/</a>. The book goes into much greater detail on Karate Club’s capabilities than this chapter will be able to. It is also a good follow-up book to read after this book, as this book teaches the fundamentals of interacting with networks using Python, and <em class="italic">Graph Machine Learning</em> takes this knowledge a <span class="No-Break">step furt<a id="_idTextAnchor439"/>her.</span></p>
			<h1 id="_idParaDest-255"><a id="_idTextAnchor440"/>Network science options</h1>
			<p>It is<a id="_idIndexMarker762"/> important to know that you do not <em class="italic">need</em> to use ML to work with graphs. ML can just be useful. There is also a blurry line between what is and isn’t ML. For instance, I would consider any form of community detection to be unsupervised ML, as these algorithms are capable of automatically identifying communities that exist in a network. By that definition, we could consider some of the approaches offered by NetworkX unsupervised ML, but they are not given the same level of attention in the data science community, because they are not explicitly called graph ML. There is a level of hype to be <span class="No-Break">aware of.</span></p>
			<p>I am saying this because I want you to keep in mind that there are approaches that you have already learned that can eliminate the need to use what is advertised as graph ML. For instance, you can use Louvain to identify communities, or even just connected components. You can use PageRank to identify hubs – you don’t need embeddings for that. You can use <strong class="source-inline">k_corona(0)</strong> to identify isolates – you don’t need ML at all for that. You can chain together several graph features into training data, like we did in the last chapter. You don’t <em class="italic">need</em> to use Karate Club to create embeddings, and you <em class="italic">shouldn’t</em> use Karate Club embeddings if you are interested in any kind of <span class="No-Break">model interpretability.</span></p>
			<p>Remember<a id="_idIndexMarker763"/> what you have learned in this book for interrogating and dissecting networks. Use what is in this chapter as a shortcut or if the science behind what you are doing is already figured out. Embeddings can be a nice shortcut, but any model using these embeddings will become a non-interpretable <span class="No-Break">black box.</span></p>
			<p>My recommendation: use network science approaches (in NetworkX) rather than Karate Club when possible, but be aware of Karate Club and that it can be useful. This suggestion isn’t due to any disdain for Karate Club. It’s because I find the insights I can extract from models to be illuminating, and almost nothing is worth losing those insights to me. For instance, what characteristics allow a model to predict bots and <span class="No-Break">artificial amplification?</span></p>
			<p>Loss of interpretability means that you won’t be able to understand your model’s behavior. This is never a good thing. This is not a dig at approaches that decompose graphs into embeddings, or the research around those approaches; it is just worth knowing that certain approaches can lead to a total loss of interpretability of <span class="No-Break">model be<a id="_idTextAnchor441"/>havior.</span></p>
			<h1 id="_idParaDest-256"><a id="_idTextAnchor442"/>Uses of unsupervised ML on network data</h1>
			<p>If you <a id="_idIndexMarker764"/>take a look at the Karate Club website, you will probably notice that the two approaches to unsupervised ML fall into two categories: identifying communities or creating embeddings. Unsupervised ML can be useful for creating embeddings not just for nodes, but also for edges or for <span class="No-Break">whole <a id="_idTextAnchor443"/>graphs.</span></p>
			<h2 id="_idParaDest-257"><a id="_idTextAnchor444"/>Community detection</h2>
			<p>Community detection <a id="_idIndexMarker765"/>is the easiest to understand. The goal of using a community detection algorithm is to<a id="_idIndexMarker766"/> identify the communities of nodes that exist in a network. You can think of communities as clusters or clumps of nodes that interact with each other in some way. In social network analysis, this is called community detection, because it is literally about identifying communities in a social network. However, community detection can be useful outside of social network analysis involving people. Maybe it helps to think of a graph as just a social network of things that somehow interact. Websites interact. Countries and cities interact. People interact. There are communities of countries and cities that interact (allies and enemies). There are communities of websites that interact. There are communities of people that interact. It’s just about identifying groups of things <span class="No-Break">that interact.</span></p>
			<p>We <a id="_idIndexMarker767"/>discuss community detection in <a href="B17105_09.xhtml#_idTextAnchor364"><span class="No-Break"><em class="italic">Chapter 9</em></span></a> of this book. If you haven’t yet read that, I encourage you to go back to that chapter to learn more <span class="No-Break">about it.</span></p>
			<p>Here is an<a id="_idIndexMarker768"/> example community to refresh <span class="No-Break">your memory:</span></p>
			<div>
				<div id="_idContainer180" class="IMG---Figure">
					<img src="image/B17105_11_001.jpg" alt="Figure 11.1 – Community from Les Miserables" width="1650" height="947"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – Community from Les Miserables</p>
			<p>Looking at this community, we can see that it is tightly knit. Each member is connected with every other member of the community. Other communities are more <span class="No-Break">sparsely<a id="_idTextAnchor445"/> connected.</span></p>
			<h2 id="_idParaDest-258"><a id="_idTextAnchor446"/>Graph embeddings</h2>
			<p>I like to<a id="_idIndexMarker769"/> think about graph embeddings <a id="_idIndexMarker770"/>as a translation of a complex network into a data format that mathematical models will be better able to use. For instance, if you use a graph edge list or a NetworkX graph (G) with Random Forest, nothing is going to happen. The model will have no way of using the input data for anything. In order to make use of these models, we need to deconstruct graphs into a more usable format. In the previous chapter on supervised machine learning, we converted a graph into training data in <span class="No-Break">this format:</span></p>
			<div>
				<div id="_idContainer181" class="IMG---Figure">
					<img src="image/B17105_11_002.jpg" alt="Figure 11.2 – Hand-crafted graph training data" width="998" height="578"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2 – Hand-crafted graph training data</p>
			<p>We also included a <strong class="bold">label</strong>, which is the answer that an ML model will learn from. After this, we tacked on the adjacency matrix for each node, so that the classification model would also learn from <span class="No-Break">network connections.</span></p>
			<p>As you can see, it’s easy for us to know what the features are in this training data. First, we have a node’s degrees, then its clustering, the number of triangles, its betweenness and closeness centrality, and finally, its <span class="No-Break">PageRank score.</span></p>
			<p>With <a id="_idIndexMarker771"/>embeddings, all <a id="_idIndexMarker772"/>of the information in a graph is deconstructed into a series of embeddings. If you read the article behind the model, you can get an understanding of what is happening in the process, but by the time the embeddings are created, it’s really not super interpretable. This is what embeddings <span class="No-Break">look like:</span></p>
			<div>
				<div id="_idContainer182" class="IMG---Figure">
					<img src="image/B17105_11_003.jpg" alt="Figure 11.3 – Unsupervised ML graph embeddings" width="1650" height="471"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – Unsupervised ML graph embeddings</p>
			<p>Sweet, we’ve converted a graph into 1,751 columns <span class="No-Break">of… what?</span></p>
			<p>Still, these embeddings are useful and can be fed directly to supervised ML models for prediction, and the predictions can be quite useful, even if the model and data are not <span class="No-Break">very interpretable.</span></p>
			<p>But what can these embeddings be used for? They’re just a whole bunch of columns of numeric data with no description. How can that be useful? Well, there are two downstream uses, one involving more unsupervised ML for clustering, and another using supervised ML <span class="No-Break">for cl<a id="_idTextAnchor447"/>assification.</span></p>
			<h3>Clustering</h3>
			<p>In <strong class="bold">clustering</strong>, your <a id="_idIndexMarker773"/>goal is to identify clusters, clumps, or groups of things that look or behave similarly. With both the hand-crafted training data and the Karate Club-generated embeddings, clustering is possible. Both of these datasets can be fed to a clustering algorithm (such as K-means) to identify <a id="_idIndexMarker774"/>similar nodes, for example. There are implications to using any model, though, so spend time learning about the models you are interested in using. For instance, to use K-means, you have to specify the number of clusters that you expect to exist in the data, and that is practically <span class="No-Break">never known.</span></p>
			<p>Getting back to the <strong class="bold">Keep it Simple</strong> (<strong class="bold">KISS</strong>) approach, though, stacking math upon math upon math just to get a result that you could have gotten simply by knowing the right network approach is extremely wasteful. If you just wanted to identify clusters, you could have used a community detection algorithm, <strong class="source-inline">k_corona</strong>, looked at the connected components, or sorted nodes by PageRank. If you are using ML, you should first ask yourself whether there is a network-based approach to this that eliminates t<a id="_idTextAnchor448"/>he need <span class="No-Break">for ML.</span></p>
			<h3>Classification</h3>
			<p>With<a id="_idIndexMarker775"/> classification, your goal is to predict something. In a social network, you might want to predict who will eventually become friends, who might like to become friends, who might click on an advertisement, or who might want to buy a product. If you can make these predictions, you can automate recommendations and ad placement. Or, you might want to identify fraud, artificial amplification, or abuse. If you can make these predictions, you can automatically quarantine what looks like bad behavior, and automate the fielding of responding to these kinds <span class="No-Break">of cases.</span></p>
			<p>Classification usually gets the most attention in ML. It deserves the glory. With classification, we can prevent spam from ruining our inboxes and productivity, we can automatically translate text from one language into another, and we can prevent malware from ruining our infrastructure and allowing criminals to take advantage of us. Classification can literally make the world a better and safer place when used well <span class="No-Break">and responsibly.</span></p>
			<p>In the previous chapter, we invented a fun game called “Spot the Revolutionary.” The same game could be played in real life with different purposes. You could automatically spot the influencer, spot the fraudulent behavior, spot the malware, or spot the cyber attack. Not all classifiers are deadly serious. Some classifiers help us learn more about the world around us. For instance, if you are using hand-crafted training data rather than embeddings, you could train a model to predict bot-like behavior, and then you could learn what features the model found most useful in identifying bots. For instance, maybe the fact that a bot account was created two days ago, has<a id="_idIndexMarker776"/> done zero tweets, has done 2,000 retweets, and already has 15,000 followers could have something to do with it. A model trained on embeddings might tell you that embedding number 72 was useful, which <span class="No-Break">means nothing.</span></p>
			<p>Alright, enough talk. Let’s get to coding and see all of this in action. For the rest of this chapter, we will be using Karate<a id="_idTextAnchor449"/> <span class="No-Break">Club approaches.</span></p>
			<h1 id="_idParaDest-259"><a id="_idTextAnchor450"/>Constructing a graph</h1>
			<p>Before <a id="_idIndexMarker777"/>we can do anything, we need a graph to play with. As with the last chapter, we will make use of the NetworkX <em class="italic">Les Miserables</em> graph, <span class="No-Break">for familiarity.</span></p>
			<p>First, we’ll create the graph and remove the additional fields that we <span class="No-Break">don’t need:</span></p>
			<pre class="source-code">
import networkx as nx
import pandas as pd
G = nx.les_miserables_graph()
df = nx.to_pandas_edgelist(G)[['source', 'target']] # dropping 'weight'
G = nx.from_pandas_edgelist(df)
G_named = G.copy()
G = nx.convert_node_labels_to_integers(G, first_label=0, ordering='default', label_attribute=None)
nodes = G_named.nodes</pre>
			<p>If you look closely, I’ve included two lines of code that create a <strong class="source-inline">G_named</strong> graph as a copy of G, and have converted node labels on graph G to numbers for use in Karate Club a bit later in this chapter. This is a required step for working with <span class="No-Break">Karate Club.</span></p>
			<p>Let’s visualize graph G for a <span class="No-Break">sanity check:</span></p>
			<pre class="source-code">
draw_graph(G, node_size=4, edge_width=0.2)</pre>
			<p>This produces the following graph. We are not including node labels, so it will just be dots and lines (nodes <span class="No-Break">and edges).</span></p>
			<div>
				<div id="_idContainer183" class="IMG---Figure">
					<img src="image/B17105_11_004.jpg" alt="Figure 11.4 – Les Miserables network" width="1407" height="1012"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.4 – Les Miserables network</p>
			<p>This<a id="_idIndexMarker778"/> looks as expected. Each node has a label, but we are not <span class="No-Break">showing them.</span></p>
			<p>I have also created some training data with labels. The data is included in the <strong class="source-inline">/data</strong> section of the GitHub repo accompanying <span class="No-Break">this book:</span></p>
			<pre class="source-code">
train_data = 'data/clf_df.csv'
clf_df = pd.read_csv(train_data).set_index('index')</pre>
			<p>The process of creating the training data is a bit involved and was explained in the previous chapter, so please use those steps to learn how to do this manually. For this chapter, you can just use the CSV file to save time. Let’s check that the data <span class="No-Break">looks correct:</span></p>
			<pre class="source-code">
clf_df.head()</pre>
			<div>
				<div id="_idContainer184" class="IMG---Figure">
					<img src="image/B17105_11_005.jpg" alt="Figure 11.5 – Hand-crafted training data" width="1068" height="328"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.5 – Hand-crafted training data</p>
			<p>In this<a id="_idIndexMarker779"/> chapter, only one of the models will use the hand-crafted training data as input, but we will use the labels with our embeddings. I’ll show how a <span class="No-Break">bit later.</span></p>
			<p>With the graph and the training data, we are set <span class="No-Break">to continue.</span></p>
			<h1 id="_idParaDest-260"><a id="_idTextAnchor451"/>Community detection in action</h1>
			<p>With community detection, our<a id="_idIndexMarker780"/> obvious goal is to identify the communities that exist in a network. I explained various approaches in <a href="B17105_09.xhtml#_idTextAnchor364"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, <em class="italic">Community Detection</em>. In this chapter, we will make use of two Karate Club algorithms: SCD <span class="No-Break">and EgoNetSplitter.</span></p>
			<p>For this chapter, and in general, I tend to gravitate toward models that can scale well. If a model or algorithm is only useful on a tiny network, I’ll avoid it. Real networks are large, sparse, and complicated. I don’t think I’ve ever seen something that doesn’t scale well that is actually better than algorithms that do. This is especially true in community detection. The best algorithms do scale well. My least favorite do not<a id="_idTextAnchor452"/> scale well <span class="No-Break">at all.</span></p>
			<h2 id="_idParaDest-261"><a id="_idTextAnchor453"/>SCD</h2>
			<p>The <a id="_idIndexMarker781"/>first community<a id="_idIndexMarker782"/> detection algorithm I want to showcase is SCD. You can find the documentation and journal article about the model <span class="No-Break">at </span><a href="https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.community_detection.non_overlapping.scd.SCD"><span class="No-Break">https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.community_detection.non_overlapping.scd.SCD</span></a><span class="No-Break">.</span></p>
			<p>This model claims <a id="_idIndexMarker783"/>to be much faster than the most accurate state-of-the-art community detection solutions while retaining or even exceeding their quality. It also claims to be able to handle graphs with billions of edges, which means that it can be useful with real-world networks. It claims to perform better than Louvain, the fastest community <span class="No-Break">detection algorithm.</span></p>
			<p>Those are<a id="_idIndexMarker784"/> some bold claims. Louvain is extremely useful for community detection for a few reasons. First, it is very fast and useful on large networks. Second, the Python implementation is simple to work with. So, we already know that Louvain is fast and easy to work with. How much better is this? Let’s try <span class="No-Break">it out:</span></p>
			<ol>
				<li>First, make sure you have Karate Club installed on your computer. You can do so with a simple <strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install karateclub</strong></span><span class="No-Break">.</span></li>
				<li>Now, let’s use the model. First, start with the imports. You need <span class="No-Break">these two:</span><pre class="source-code">
from karateclub.community_detection.non_overlapping.scd import SCD</pre><pre class="source-code">
import numpy as np</pre></li>
				<li>Now that we have those, getting the communities for our graph is as simple as 1, <span class="No-Break">2, 3:</span><pre class="source-code">
model = SCD()</pre><pre class="source-code">
model.fit(G)</pre><pre class="source-code">
clusters = model.get_memberships()</pre></li>
			</ol>
			<p>We first instantiate SCD, then we fit the graph to SCD, and then we get the cluster memberships for each node. Karate Club models are this simple to work with. You need to read the articles to know what is happening under <span class="No-Break">the hood.</span></p>
			<ol>
				<li value="4">What do the clusters look like? If we print the <strong class="source-inline">clusters</strong> variable, we should <span class="No-Break">see this:</span><pre class="source-code">
{0: 34,</pre><pre class="source-code">
 1: 14,</pre><pre class="source-code">
 2: 14,</pre><pre class="source-code">
 3: 14,</pre><pre class="source-code">
 4: 33,</pre><pre class="source-code">
 5: 32,</pre><pre class="source-code">
 6: 31,</pre><pre class="source-code">
 7: 30,</pre><pre class="source-code">
 8: 29,</pre><pre class="source-code">
 9: 28,</pre><pre class="source-code">
 10: 11,</pre><pre class="source-code">
…</pre><pre class="source-code">
}</pre></li>
			</ol>
			<p>Node zero is in cluster 34, nodes 1-3 are in cluster 14, node 4 is in cluster 33, and <span class="No-Break">so forth.</span></p>
			<ol>
				<li value="5">Next, we <a id="_idIndexMarker785"/>shove the<a id="_idIndexMarker786"/> clusters into a <strong class="source-inline">numpy</strong> array so that we can use the data with our named nodes to more easily determine what nodes belong to <span class="No-Break">what clusters:</span><pre class="source-code">
clusters = np.array(list(clusters.values()))</pre></li>
			</ol>
			<p>The <strong class="source-inline">clusters</strong> variable will now look <span class="No-Break">like this:</span></p>
			<pre class="source-code">
<strong class="bold">array([34, 14, 14, 14, 33, 32, 31, 30, 29, 28, 11, 27, 13, 26, 25, 24,  7,</strong>
<strong class="bold">       15, 15,  4, 15,  9, 11,  6, 23, 35, 11, 11, 11, 11, 11, 36,  9,  1,</strong>
<strong class="bold">        4,  4,  1,  1,  1, 15, 15, 15, 15, 37,  7,  7,  7,  7,  7,  7,  7,</strong>
<strong class="bold">        6, 15, 15, 22, 17, 21, 15,  4, 20, 17,  1,  1, 19, 19,  1,  1,  1,</strong>
<strong class="bold">        1,  1,  1,  2,  2,  1,  0, 18, 16])</strong></pre>
			<ol>
				<li value="6">Then, we<a id="_idIndexMarker787"/> create a <span class="No-Break"><strong class="source-inline">cluster</strong></span><span class="No-Break"> DataFrame:</span><pre class="source-code">
cluster_df = pd.DataFrame({'node':nodes, 'cluster':clusters})</pre><pre class="source-code">
cluster_df.head(10)</pre></li>
			</ol>
			<p>This gives <a id="_idIndexMarker788"/>us the <span class="No-Break">following output:</span></p>
			<div>
				<div id="_idContainer185" class="IMG---Figure">
					<img src="image/B17105_11_006.jpg" alt="Figure 11.6 – SCD cluster DataFrame" width="331" height="559"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.6 – SCD cluster DataFrame</p>
			<p>Great. This is much easier to understand in this format. We now have actual people nodes as well as the community that they <span class="No-Break">belong to.</span></p>
			<ol>
				<li value="7">Let’s find the largest communities by <span class="No-Break">node membership:</span><pre class="source-code">
title = 'Clusters by Node Count (SCD)'</pre><pre class="source-code">
cluster_df['cluster'].value_counts()[0:10].plot.barh(title=title).invert_yaxis()</pre></li>
			</ol>
			<p>This<a id="_idIndexMarker789"/> gives us <span class="No-Break">the</span><span class="No-Break"><a id="_idIndexMarker790"/></span><span class="No-Break"> following:</span></p>
			<div>
				<div id="_idContainer186" class="IMG---Figure">
					<img src="image/B17105_11_007.jpg" alt="Figure 11.7 – SCD communities by node count" width="1436" height="964"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.7 – SCD communities by node count</p>
			<ol>
				<li value="8">Community 1 is the largest, with 13 members, followed by community 15, which has 10 members. Let’s examine both <span class="No-Break">of these:</span><pre class="source-code">
check_cluster = 1</pre><pre class="source-code">
community_nodes = cluster_df[cluster_df['cluster']==check_cluster]['node'].to_list()</pre><pre class="source-code">
G_comm = G_named.subgraph(community_nodes)</pre><pre class="source-code">
draw_graph(G_comm, show_names=True, node_size=5)</pre></li>
			</ol>
			<p>This <a id="_idIndexMarker791"/>gives us <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer187" class="IMG---Figure">
					<img src="image/B17105_11_008.jpg" alt="Figure 11.8 – SCD community 1" width="1612" height="1064"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.8 – SCD community 1</p>
			<p>This<a id="_idIndexMarker792"/> is excellent. This is a clear community of highly connected nodes. This is a densely connected community. Not all nodes are equally well connected. Some nodes are more central <span class="No-Break">than others.</span></p>
			<ol>
				<li value="9">Let’s look at <span class="No-Break">community 15:</span><pre class="source-code">
check_cluster = 15</pre><pre class="source-code">
community_nodes = cluster_df[cluster_df['cluster']==check_cluster]['node'].to_list()</pre><pre class="source-code">
G_comm = G_named.subgraph(community_nodes)</pre><pre class="source-code">
draw_graph(G_comm, show_names=True, node_size=5)</pre></li>
			</ol>
			<p>The <span class="No-Break">results follow:</span></p>
			<div>
				<div id="_idContainer188" class="IMG---Figure">
					<img src="image/B17105_11_009.jpg" alt="Figure 11.9 – SCD community 15" width="1520" height="1066"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.9 – SCD community 15</p>
			<p>This is <a id="_idIndexMarker793"/>another <a id="_idIndexMarker794"/>high-quality community extraction. All nodes are connected to other nodes in the community. Some nodes are more central <span class="No-Break">than others.</span></p>
			<ol>
				<li value="10">Let’s look at one <span class="No-Break">more community:</span><pre class="source-code">
check_cluster = 7</pre><pre class="source-code">
community_nodes = cluster_df[cluster_df['cluster']==check_cluster]['node'].to_list()</pre><pre class="source-code">
G_comm = G_named.subgraph(community_nodes)</pre><pre class="source-code">
draw_graph(G_comm, show_names=True, node_size=5)</pre></li>
			</ol>
			<p>We get <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer189" class="IMG---Figure">
					<img src="image/B17105_11_010.jpg" alt="Figure 11.10 – SCD community 7" width="1574" height="1056"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.10 – SCD community 7</p>
			<p>This is<a id="_idIndexMarker795"/> another high-quality<a id="_idIndexMarker796"/> community extraction. All nodes in the community are connected. In this case, this is quite a pleasing visualization to look at, as all nodes are equally connected. It is quite symmetric <span class="No-Break">and beautiful.</span></p>
			<p>The <em class="italic">Les Miserables</em> network is tiny, so naturally, the SCD model was able to train on it <span class="No-Break">essentially instantly.</span></p>
			<p>One thing that I do like about this approach is that the setup is simpler than the approaches I explained in <a href="B17105_09.xhtml#_idTextAnchor364"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>. I can go from a graph to communities in no time and with very little code. The fact that this can supposedly scale to networks with billions of edges is incredible, if true. <a id="_idTextAnchor454"/>It is fast, clean, <span class="No-Break">and useful.</span></p>
			<h3>EgoNetSplitter</h3>
			<p>The <a id="_idIndexMarker797"/>next model we will test for community <a id="_idIndexMarker798"/>detection is named EgoNetSplitter. You can learn about it <span class="No-Break">here: </span><a href="https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.community_detection.overlapping.ego_splitter.EgoNetSplitter"><span class="No-Break">https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.community_detection.overlapping.ego_splitter.EgoNetSplitter</span></a><span class="No-Break">.</span></p>
			<p>In Jupyter, if you <em class="italic">Shift</em> + <em class="italic">Tab</em> into the model instantiation code, you can read <span class="No-Break">about it:</span></p>
			<p class="author-quote">The tool first creates the ego-nets of nodes. A persona-graph is created which is clustered by the Louvain method. The resulting overlapping cluster memberships are stored as a dictionary.</p>
			<p>So, this model creates ego networks, then uses Louvain for clustering, and then overlapping memberships are stored as a dictionary. It’s an interesting approach and different from other approaches, so I thought it’d be neat to test it out and see how it performs. The steps are slightly different from those <span class="No-Break">with SCD:</span></p>
			<ol>
				<li value="1">To begin, let’s get the model <span class="No-Break">in place:</span><pre class="source-code">
from karateclub.community_detection.overlapping.ego_splitter import EgoNetSplitter</pre><pre class="source-code">
model = EgoNetSplitter()</pre><pre class="source-code">
model.fit(G)</pre><pre class="source-code">
clusters = model.get_memberships()</pre><pre class="source-code">
clusters = np.array(list(clusters.values()))</pre><pre class="source-code">
clusters = [i[0] for i in clusters] # needed because put clusters into an array of arrays</pre></li>
				<li>This gets us our clusters. Then, creating our <strong class="source-inline">cluster</strong> DataFrame and doing visualizations follows the same code as <span class="No-Break">with SCD:</span><pre class="source-code">
cluster_df = pd.DataFrame({'node':nodes, 'cluster':clusters})</pre></li>
				<li>Let’s check community membership <span class="No-Break">by count:</span><pre class="source-code">
title = 'Clusters by Node Count (EgoNetSplitter)'</pre><pre class="source-code">
cluster_df['cluster'].value_counts()[0:10].plot.barh(title=title).invert_yaxis()</pre></li>
			</ol>
			<p>We get <a id="_idIndexMarker799"/>the <span class="No-Break">following output:</span></p>
			<div>
				<div id="_idContainer190" class="IMG---Figure">
					<img src="image/B17105_11_011.jpg" alt="Figure 11.11 – EgoNetSplitter communities by node count" width="776" height="476"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.11 – EgoNetSplitter communities by node count</p>
			<p>Already, the results look different from SCD. This should <span class="No-Break">be interesting.</span></p>
			<ol>
				<li value="4">Let’s <a id="_idIndexMarker800"/>take a look to see what is different. Clusters 7 and 1 are the largest, so let’s take a look at <span class="No-Break">those two:</span><pre class="source-code">
check_cluster = 7</pre><pre class="source-code">
community_nodes = cluster_df[cluster_df['cluster']==check_cluster]['node'].to_list()</pre><pre class="source-code">
G_comm = G_named.subgraph(community_nodes)</pre><pre class="source-code">
draw_graph(G_comm, show_names=True, node_size=5)</pre></li>
			</ol>
			<p>This will draw our <span class="No-Break">ego network.</span></p>
			<div>
				<div id="_idContainer191" class="IMG---Figure">
					<img src="image/B17105_11_012.jpg" alt="Figure 11.12 – EgoNetSplitter community 7" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.12 – EgoNetSplitter community 7</p>
			<p>I don’t like <a id="_idIndexMarker801"/>that. I don’t believe that the <a id="_idIndexMarker802"/>nodes on the left should be a part of the same community as the nodes that are connected to the densely connected nodes on the right. Personally, I don’t find this to be as useful as <span class="No-Break">SCD’s results.</span></p>
			<ol>
				<li value="5">Let’s take a look at the next most <span class="No-Break">populated cluster:</span><pre class="source-code">
check_cluster = 1</pre><pre class="source-code">
community_nodes = cluster_df[cluster_df['cluster']==check_cluster]['node'].to_list()</pre><pre class="source-code">
G_comm = G_named.subgraph(community_nodes)</pre><pre class="source-code">
draw_graph(G_comm, show_names=True, node_size=5)</pre></li>
			</ol>
			<p><span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.13</em> shows the <span class="No-Break">resulting output.</span></p>
			<div>
				<div id="_idContainer192" class="IMG---Figure">
					<img src="image/B17105_11_013.jpg" alt="Figure 11.13 – EgoNetSplitter community 1" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.13 – EgoNetSplitter community 1</p>
			<p>Once again, we <a id="_idIndexMarker803"/>are seeing similar <a id="_idIndexMarker804"/>behavior, where one node has been included in the network that really should not be. <strong class="bold">MotherPlutarch</strong> might be connected to <strong class="bold">Mabeuf</strong>, but she really has nothing to do with the other people in <span class="No-Break">the community.</span></p>
			<ol>
				<li value="6">Let’s take a final look at the <span class="No-Break">next community:</span><pre class="source-code">
check_cluster = 5</pre><pre class="source-code">
community_nodes = cluster_df[cluster_df['cluster']==check_cluster]['node'].to_list()</pre><pre class="source-code">
G_comm = G_named.subgraph(community_nodes)</pre><pre class="source-code">
draw_graph(G_comm, show_names=True, node_size=5)</pre></li>
			</ol>
			<p>The code produces the <span class="No-Break">following output:</span></p>
			<div>
				<div id="_idContainer193" class="IMG---Figure">
					<img src="image/B17105_11_014.jpg" alt="Figure 11.14 – EgoNetSplitter community 5" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.14 – EgoNetSplitter community 5</p>
			<p>Again, we<a id="_idIndexMarker805"/> see one node connected to one other node, but not connected to the rest of the nodes in <span class="No-Break">the network.</span></p>
			<p>I don’t want to <a id="_idIndexMarker806"/>say that EgoNetSplitter is inferior to SCD or any other model. I’d say that I personally prefer the outputs of SCD over EgoNetSplitter for community detection. However, it could be argued that it is better to include the few extra nodes as part of the community due to their one connection than it would be to leave them out. It’s important to know the difference between the two approaches, as well as the differences in <span class="No-Break">their results.</span></p>
			<p>However, due to the scalability claims of SCD and due to its clean separation of communities, I lean toward SCD for <span class="No-Break">community detection.</span></p>
			<p>Now that we have explored using unsupervised ML for community detection, let’s move on to using unsupervis<a id="_idTextAnchor455"/>ed ML for creating <span class="No-Break">graph embeddings.</span></p>
			<h1 id="_idParaDest-262"><a id="_idTextAnchor456"/>Graph embeddings in action</h1>
			<p>Now that we are<a id="_idIndexMarker807"/> past the comfort of community detection, we are getting into some weird territory with graph embeddings. The simplest way I think of graph embeddings is just the deconstruction of a complex network into a format more suitable for ML tasks. It’s the translation of a complex data structure into a less complex data structure. That’s a simple way of thinking <span class="No-Break">about it.</span></p>
			<p>Some unsupervised ML models will create more dimensions (more columns/features) of embeddings than others, as you will see in this section. In this section, we are going to create embeddings, inspect nodes that have similar embeddings, and then use the embeddings with supervised ML to predict “revolutionary or not,” like our “Spot the Revolutionary” game from the <span class="No-Break">last chapter.</span></p>
			<p>We’re going to quickly run through the use of several different models – this chapter would be hundreds of pages long if I went into great detail about each model. So, to save time, I’ll provide the link to the documentation and a simple summary, and we’ll just do some simple comparisons. Please know that you should never use ML this blindly. Please read the documentation, read the articles, and know how the models work. I did the legwork, and you should too. Do feel free to just play around with different models to see how they behave. If you are just experimenting and not putting them into production, you aren’t going to accidentally cause a rip in the fabric of spacetime by playing with a <span class="No-Break"><strong class="source-inline">scikit-learn</strong></span><span class="No-Break"> model.</span></p>
			<p>We’re going to need this helper function for visualizations of the <span class="No-Break">upcoming embeddings:</span></p>
			<pre class="source-code">
def draw_clustering(embeddings, nodes, title):
    import plotly.express as px
    from sklearn.decomposition import PCA
    embed_df = pd.DataFrame(embeddings)
    # dim reduction, two features; solely for visualization
    model = PCA(n_components=2)
    X_features = model.fit_transform(embed_df)
    embed_df = pd.DataFrame(X_features)
    embed_df.index = nodes
    embed_df.columns = ['x', 'y']
    fig = px.scatter(embed_df, x='x', y='y', text=embed_df.index)
    fig.update_traces(textposition='top center')
    fig.update_layout(height=800, title_text=title, font_size=11)
    return fig.show()</pre>
			<p>I need to <a id="_idIndexMarker808"/>explain a few things. First, this <strong class="source-inline">draw_clustering</strong> function uses <strong class="source-inline">plotly</strong> to create an interactive scatter plot. You can zoom in and out and inspect nodes interactively. You will need to have <strong class="source-inline">plotly</strong> installed, which can be done with <strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install plotly</strong></span><span class="No-Break">.</span></p>
			<p>Second, I’m<a id="_idIndexMarker809"/> using <strong class="bold">Principal Component Analysis</strong> (<strong class="bold">PCA</strong>) to reduce embeddings into two dimensions, just for the sake of visualization. PCA is also unsupervised learning and useful for dimension reduction. I needed to do this so that I could show you that these embedding models behave differently. Reducing embeddings to two dimensions allows me to visualize them on a scatter plot. I do not recommend doing PCA after creating embeddings. I am onl<a id="_idTextAnchor457"/>y using this process <span class="No-Break">for visualization.</span></p>
			<h2 id="_idParaDest-263"><a id="_idTextAnchor458"/>FEATHER</h2>
			<p>The<a id="_idIndexMarker810"/> first algorithm we will use is called <strong class="bold">FEATHER</strong>, and <a id="_idIndexMarker811"/>you can learn about it <span class="No-Break">at </span><a href="https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.attributed.feathernode.FeatherNode"><span class="No-Break">https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.attributed.feathernode.FeatherNode</span></a><span class="No-Break">.</span></p>
			<p>In Jupyter, if you <em class="italic">Shift</em> + <em class="italic">Tab</em> into the model instantiation code, you can read <span class="No-Break">about it:</span></p>
			<p class="author-quote">An implementation of “FEATHER-N” &lt;<a href="https://arxiv.org/abs/2005.07959">https://arxiv.org/abs/2005.07959</a>&gt; from the CIKM ‘20 paper “Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models”. The procedure uses characteristic functions of node features with random walk weights to describe node neighborhoods.</p>
			<p>FEATHER <a id="_idIndexMarker812"/>claims to create high-quality graph representations, perform transfer learning effectively, and scale well to large networks. It creates <span class="No-Break">node embeddings.</span></p>
			<p>This is actually a <a id="_idIndexMarker813"/>very interesting model, as it is able to take both a graph and additional training data for use in creating embeddings. I would love to explore that idea more, to see how well it does with different kinds of training data such as <strong class="source-inline">tf-idf</strong> <span class="No-Break">or topics:</span></p>
			<ol>
				<li value="1">For now, let’s give it the hand-crafted training data that we <span class="No-Break">used before:</span><pre class="source-code">
from karateclub.node_embedding.attributed.feathernode import FeatherNode</pre><pre class="source-code">
model = FeatherNode()</pre><pre class="source-code">
model.fit(G, clf_df)</pre><pre class="source-code">
embeddings = model.get_embedding()</pre></li>
			</ol>
			<p>First, we import the model, then we instantiate it. On the <strong class="source-inline">model.fit</strong> line, notice that we are passing in both <strong class="source-inline">G</strong> and <strong class="source-inline">clf_df</strong>. The latter is the training data that we created by hand. With every other model, we only pass in G. To me, this is fascinating, as it seems like it’d give the model the ability to learn more about the network based on other <span class="No-Break">contextual data.</span></p>
			<ol>
				<li value="2">Let’s visualize these embeddings to see how the model <span class="No-Break">is working:</span><pre class="source-code">
title = 'Les Miserables Character Similarity (FeatherNode)'</pre><pre class="source-code">
draw_clustering(embeddings, nodes, title)</pre></li>
			</ol>
			<p>We get the <span class="No-Break">following output:</span></p>
			<div>
				<div id="_idContainer194" class="IMG---Figure">
					<img src="image/B17105_03_007.jpg" alt="Figure 11.15 – FEATHER embeddings" width="1570" height="1278"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.15 – FEATHER embeddings</p>
			<p>This is <a id="_idIndexMarker814"/>interesting to look at. We can see that there are <a id="_idIndexMarker815"/>several nodes that appear together. As this is an interactive visualization, we can inspect any of them. If we zoom in on the bottom-left cluster, we can <span class="No-Break">see this:</span></p>
			<div>
				<div id="_idContainer195" class="IMG---Figure">
					<img src="image/B17105_11_016.jpg" alt="Figure 11.16 – FEATHER embeddings zoomed" width="1044" height="1054"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.16 – FEATHER embeddings zoomed</p>
			<p>It’s difficult <a id="_idIndexMarker816"/>to read, due to the overlap, but <strong class="bold">Feuilly</strong> is shown on <a id="_idIndexMarker817"/>the bottom left, close <span class="No-Break">to </span><span class="No-Break"><strong class="bold">Prouvaire</strong></span><span class="No-Break">.</span></p>
			<ol>
				<li value="3">Let’s check both of their ego networks to see what <span class="No-Break">is similar:</span><pre class="source-code">
node = 'Feuilly'</pre><pre class="source-code">
G_ego = nx.ego_graph(G_named, node)</pre><pre class="source-code">
draw_graph(G_ego, show_names=True, node_size=3)</pre></li>
			</ol>
			<p>That produces <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.17</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer196" class="IMG---Figure">
					<img src="image/B17105_11_017.jpg" alt="Figure 11.17 – Feuilly ego network" width="1548" height="1052"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.17 – Feuilly ego network</p>
			<ol>
				<li value="4">Now, let’s <a id="_idIndexMarker818"/>inspect<a id="_idIndexMarker819"/> Prouvaire’s <a id="_idIndexMarker820"/><span class="No-Break">ego network:</span><pre class="source-code">
node = 'Prouvaire'</pre><pre class="source-code">
G_ego = nx.ego_graph(G_named, node)</pre><pre class="source-code">
draw_graph(G_ego, show_names=True, node_size=3)</pre></li>
			</ol>
			<p>This outputs <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.18</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer197" class="IMG---Figure">
					<img src="image/B17105_11_018.jpg" alt="Figure 11.18 – Prouvaire ego network" width="1471" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.18 – Prouvaire ego network</p>
			<p>Nice. The<a id="_idIndexMarker821"/> first <a id="_idIndexMarker822"/>observation is that they are both part of each other’s ego network and also part of each other’s community. Second, their nodes are quite connected. On both ego networks, both nodes show as being quite well connected and also part of a densely <span class="No-Break">connected community.</span></p>
			<ol>
				<li value="5">Let’s take a look at a few <span class="No-Break">other nodes:</span></li>
			</ol>
			<div>
				<div id="_idContainer198" class="IMG---Figure">
					<img src="image/B17105_11_019.jpg" alt="Figure 11.19 – FEATHER embeddings zoomed" width="894" height="804"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.19 – FEATHER embeddings zoomed</p>
			<ol>
				<li value="6">Let’s<a id="_idIndexMarker823"/> inspect <a id="_idIndexMarker824"/>the ego networks for <strong class="bold">MotherInnocent</strong> and <strong class="bold">MmeMagloire</strong>. <span class="No-Break"><strong class="bold">MotherInnocent</strong></span><span class="No-Break"> first:</span><pre class="source-code">
node = 'MotherInnocent'</pre><pre class="source-code">
G_ego = nx.ego_graph(G_named, node)</pre><pre class="source-code">
draw_graph(G_ego, show_names=True, node_size=3)</pre></li>
			</ol>
			<p><span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.20</em> shows <span class="No-Break">the output.</span></p>
			<div>
				<div id="_idContainer199" class="IMG---Figure">
					<img src="image/B17105_11_020.jpg" alt="Figure 11.20 – MotherInnocent ego network" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.20 – MotherInnocent ego network</p>
			<p>And <a id="_idIndexMarker825"/><span class="No-Break">now </span><span class="No-Break"><strong class="bold">MmeMagloire</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
node = 'MmeMagloire'
G_ego = nx.ego_graph(G_named, node)
draw_graph(G_ego, show_names=True, node_size=3)</pre>
			<p><span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.21</em> shows<a id="_idIndexMarker826"/> <span class="No-Break">the results.</span></p>
			<div>
				<div id="_idContainer200" class="IMG---Figure">
					<img src="image/B17105_11_021.jpg" alt="Figure 11.21 – MmeMagloire ego network" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.21 – MmeMagloire ego network</p>
			<p><strong class="bold">MotherInnocent</strong> has two<a id="_idIndexMarker827"/> edges, and <strong class="bold">MmeMagloire</strong> has three. Their ego networks are quite small. These similarities are being picked up by FEATHER and translated <span class="No-Break">into embeddings.</span></p>
			<ol>
				<li value="7">But what <a id="_idIndexMarker828"/>do the actual embeddings <span class="No-Break">look like?</span><pre class="source-code">
eb_df = pd.DataFrame(embeddings, index=nodes)</pre><pre class="source-code">
eb_df['label'] = clf_df['label']</pre><pre class="source-code">
eb_df.head(10)</pre></li>
			</ol>
			<p>This produces the <span class="No-Break">following DataFrame.</span></p>
			<div>
				<div id="_idContainer201" class="IMG---Figure">
					<img src="image/B17105_11_022.jpg" alt="Figure 11.22 – FEATHER embeddings DataFrame" width="1650" height="549"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.22 – FEATHER embeddings DataFrame</p>
			<p>The <a id="_idIndexMarker829"/>graph was translated into 1,750 embedding <a id="_idIndexMarker830"/>dimensions. In this format, you can think of them as columns or features. A simple network was converted into 1,750 columns, which is quite a lot of data for such a small network. Pay attention to the number of dimensions created by these models as we go through the others <span class="No-Break">after FEATHER.</span></p>
			<p>These embeddings are useful for classification, so let’s do just that. I’m going to just throw data at a classification model and hope for the best. This is never a good idea other than for simple experimentation, but that is exactly what we are doing. I encourage you to dig deeper into any of these models that you <span class="No-Break">find interesting.</span></p>
			<ol>
				<li value="8">The preceding code already added the <strong class="source-inline">label</strong> field, but we need to create our <strong class="source-inline">X</strong> and <strong class="source-inline">y</strong> data <span class="No-Break">for classification:</span><pre class="source-code">
from sklearn.model_selection import train_test_split</pre><pre class="source-code">
X_cols = [c for c in eb_df.columns if c != 'label']</pre><pre class="source-code">
X = eb_df[X_cols]</pre><pre class="source-code">
y = eb_df['label']</pre><pre class="source-code">
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1337, test_size=0.3)</pre></li>
			</ol>
			<p><strong class="source-inline">X</strong> is our data, <strong class="source-inline">y</strong> is the correct answer. This is our “Spot the Revolutionary” training data. Nodes that are labeled as revolutionaries have a <strong class="source-inline">y</strong> of <strong class="source-inline">1</strong>. The rest have a <strong class="source-inline">y</strong> <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">0</strong></span><span class="No-Break">.</span></p>
			<ol>
				<li value="9">Let’s train a <a id="_idIndexMarker831"/>Random Forest model, as I want to show you something <span class="No-Break">about interpretability:</span><pre class="source-code">
from sklearn.ensemble import RandomForestClassifier</pre><pre class="source-code">
clf = RandomForestClassifier(random_state=1337)</pre><pre class="source-code">
clf.fit(X_train, y_train)</pre><pre class="source-code">
train_acc = clf.score(X_train, y_train)</pre><pre class="source-code">
test_acc = clf.score(X_test, y_test)</pre><pre class="source-code">
print('train accuracy: {}\ntest accuracy: {}'.format(train_acc, test_acc))</pre></li>
			</ol>
			<p>If we run this code, we get <span class="No-Break">these results:</span></p>
			<pre class="source-code">
<strong class="bold">train accuracy: 0.9811320754716981</strong>
<strong class="bold">test accuracy: 1.0</strong></pre>
			<p>Using the<a id="_idIndexMarker832"/> FEATHER embeddings as training data, the model was able to correctly spot the revolutionary 100% of the time on unseen data. This is a tiny network, though, and never, ever, <em class="italic">ever</em> trust a model that gives 100% accuracy on anything. A model that appears to be hitting 100% accuracy is often hiding a deeper problem, such as data leakage, so it’s a good idea to be skeptical of very high scores or to be skeptical of model results in general until the model has been thoroughly validated. This is a toy model. However, what this shows is that these embeddings can be created using a graph and that a supervised ML model can use these embeddings <span class="No-Break">in prediction.</span></p>
			<p>There’s a nasty downside to using these embeddings with models, though. You lose all interpretability. With our hand-crafted training data, as shown earlier in this chapter, we could see which features the model found to be most useful in making predictions. Let’s inspect the importances with <span class="No-Break">these embeddings:</span></p>
			<pre class="source-code">
importances = pd.DataFrame(clf.feature_importances_, index=X_train.columns)
importances.columns = ['importance']
importances.sort_values('importance', ascending=False, inplace=True)
importances[0:10].plot.barh(figsize=(10,4)).invert_yaxis()</pre>
			<p>We get <a id="_idIndexMarker833"/><span class="No-Break">this output:</span></p>
			<div>
				<div id="_idContainer202" class="IMG---Figure">
					<img src="image/B17105_11_023.jpg" alt="Figure 11.23 – FEATHER embedding feature importance" width="1522" height="934"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.23 – FEATHER embedding feature importance</p>
			<p>Wonderful! Embedding 1531 was <a id="_idIndexMarker834"/>found to be slightly more useful than 1134, but both of these were found to be quite a bit more useful than the other embeddings! Excellent! This is a total loss of interpretability, but the embeddings do work. If you just want to go from graph to ML, this approach will work, but you end up with a black-box model, no matter which model you use <span class="No-Break">for prediction.</span></p>
			<p>OK, for the rest of the models, I’m going to go a lot faster. We’re going to reuse a lot of this code, I’m just going to do less visualization and give less code so<a id="_idTextAnchor459"/> that this chapter doesn’t end up being 100 <span class="No-Break">pages long.</span></p>
			<h2 id="_idParaDest-264"><a id="_idTextAnchor460"/>NodeSketch</h2>
			<p>The <a id="_idIndexMarker835"/>next algorithm we will look at is <strong class="bold">NodeSketch</strong>, and you can learn about it <span class="No-Break">at </span><a href="https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.nodesketch.NodeSketch"><span class="No-Break">https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.nodesketch.NodeSketch</span></a><span class="No-Break">.</span></p>
			<p>In Jupyter, if you <em class="italic">Shift</em> + <em class="italic">Tab</em> into the model instantiation code, you can read <span class="No-Break">about it:</span></p>
			<p class="author-quote">An implementation of “NodeSketch” &lt;https://exascale.info/assets/pdf/yang2019nodesketch.pdf&gt;</p>
			<p class="author-quote">from the KDD ‘19 paper “NodeSketch: Highly-Efficient Graph Embeddings</p>
			<p class="author-quote">via Recursive Sketching”. The procedure starts by sketching the self-loop-augmented adjacency matrix of the graph to output low-order node embeddings, and then recursively generates k-order node embeddings based on the self-loop-augmented adjacency matrix and (k-1)-order node embeddings.</p>
			<p>Like FEATHER, NodeSketch <a id="_idIndexMarker836"/>also creates <span class="No-Break">node embeddings:</span></p>
			<ol>
				<li value="1">Let’s use the model and do the visualization in <span class="No-Break">one shot:</span><pre class="source-code">
from karateclub.node_embedding.neighbourhood.nodesketch import NodeSketch</pre><pre class="source-code">
model = NodeSketch()</pre><pre class="source-code">
model.fit(G)</pre><pre class="source-code">
embeddings = model.get_embedding()</pre><pre class="source-code">
title = 'Les Miserables Character Similarity (NodeSketch)'</pre><pre class="source-code">
draw_clustering(embeddings, nodes, title)</pre></li>
			</ol>
			<p>The following graph is <span class="No-Break">the result:</span></p>
			<div>
				<div id="_idContainer203" class="IMG---Figure">
					<img src="image/B17105_11_024.jpg" alt="Figure 11.24 – NodeSketch embeddings" width="1572" height="1150"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.24 – NodeSketch embeddings</p>
			<ol>
				<li value="2">As before, this<a id="_idIndexMarker837"/> visualization is interactive and you <a id="_idIndexMarker838"/>can zoom in on clusters of nodes for closer inspection. Let’s look at a few nodes that were found to <span class="No-Break">be </span><span class="No-Break"><a id="_idIndexMarker839"/></span><span class="No-Break">similar.</span></li>
			</ol>
			<p><span class="No-Break">First, </span><span class="No-Break"><strong class="bold">Eponine</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
node = 'Eponine'
G_ego = nx.ego_graph(G_named, node)
draw_graph(G_ego, show_names=True, node_size=3)</pre>
			<p>You can see the result in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.25</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer204" class="IMG---Figure">
					<img src="image/B17105_11_025.jpg" alt="Figure 11.25 – Eponine ego network" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.25 – Eponine ego network</p>
			<ol>
				<li value="3"><span class="No-Break">Next, </span><span class="No-Break"><strong class="bold">Brujon</strong></span><span class="No-Break">:</span><pre class="source-code">
node = 'Brujon'</pre><pre class="source-code">
G_ego = nx.ego_graph(G_named, node)</pre><pre class="source-code">
draw_graph(G_ego, show_names=True, node_size=3)</pre></li>
			</ol>
			<p>Shown<a id="_idIndexMarker840"/> in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.26</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer205" class="IMG---Figure">
					<img src="image/B17105_11_026.jpg" alt="Figure 11.26 – Brujon ego network" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.26 – Brujon ego network</p>
			<p>Upon<a id="_idIndexMarker841"/> inspection, the ego networks <a id="_idIndexMarker842"/>look quite different, but the two nodes seem to have about the same number of connections, and they are part of a pretty well-connected community. I’m satisfied that these two nodes are pretty similar in structure and placement. Both nodes are also part of the <span class="No-Break">same community.</span></p>
			<ol>
				<li value="4">What do the embeddings <span class="No-Break">look like?</span><pre class="source-code">
eb_df = pd.DataFrame(embeddings, index=nodes)</pre><pre class="source-code">
eb_df['label'] = clf_df['label']</pre><pre class="source-code">
eb_df.head(10)</pre></li>
			</ol>
			<p>This will show <span class="No-Break">our DataFrame.</span></p>
			<div>
				<div id="_idContainer206" class="IMG---Figure">
					<img src="image/B17105_11_027.jpg" alt="Figure 11.27 – NodeSketch embeddings DataFrame" width="1192" height="652"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.27 – NodeSketch embeddings DataFrame</p>
			<p>Wow, this<a id="_idIndexMarker843"/> is a <a id="_idIndexMarker844"/>much simpler dataset than what FEATHER produced. <strong class="bold">32</strong> features rather than 1,750. Also, note that the values in the embeddings are integers rather than floats. How well is Random Forest able to make predictions with this <span class="No-Break">training data?</span></p>
			<pre class="source-code">
X_cols = [c for c in eb_df.columns if c != 'label']
X = eb_df[X_cols]
y = eb_df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1337, test_size=0.3)
clf = RandomForestClassifier(random_state=1337)
clf.fit(X_train, y_train)
train_acc = clf.score(X_train, y_train)
test_acc = clf.score(X_test, y_test)
print('train accuracy: {}\ntest accuracy: {}'.format(train_acc, test_acc))</pre>
			<p>If we run the code, we get <span class="No-Break">these results:</span></p>
			<pre class="source-code">
<strong class="bold">train accuracy: 0.9811320754716981</strong>
<strong class="bold">test accuracy: 1.0</strong></pre>
			<p>The model <a id="_idIndexMarker845"/>was able to predict with 98% accuracy on the training data and with 100% accuracy on the test data. Again, never ever test a model that gives 100% accuracy. But this still shows that the model is able to use <span class="No-Break">the embeddings.</span></p>
			<ol>
				<li value="5">What<a id="_idIndexMarker846"/> features <a id="_idIndexMarker847"/>did it <span class="No-Break">find important?</span><pre class="source-code">
importances = pd.DataFrame(clf.feature_importances_, index=X_train.columns)</pre><pre class="source-code">
importances.columns = ['importance']</pre><pre class="source-code">
importances.sort_values('importance', ascending=False, inplace=True)</pre><pre class="source-code">
importances[0:10].plot.barh(figsize=(10,4)).invert_yaxis()</pre></li>
			</ol>
			<p>This results in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.28</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer207" class="IMG---Figure">
					<img src="image/B17105_11_028.jpg" alt="Figure 11.28 – NodeSketch embedding feature importance" width="756" height="464"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.28 – NodeSketch embedding feature importance</p>
			<p>Great. As I <a id="_idIndexMarker848"/>showed before, the use of these embeddings has turned Random Forest into a black-box model that we cannot get any <a id="_idIndexMarker849"/>model interpretability for. We know that the model found features <strong class="bold">24</strong> and <strong class="bold">23</strong> to be most useful, but we have no idea why. I won’t be showing feature importances after this. You get <span class="No-Break">the point.</span></p>
			<p>This is a cool model, and it creates simpler embeddings by default than FEATHER. Random Forest did well with both models’ embeddings, and we can’t say which is better without a lot more experimentation, which<a id="_idTextAnchor461"/> is outside of the scope of this chapter. Have <span class="No-Break">fun experimenting!</span></p>
			<h2 id="_idParaDest-265"><a id="_idTextAnchor462"/>RandNE</h2>
			<p>Next<a id="_idIndexMarker850"/> up is <strong class="bold">RandNE</strong>, which claims to be useful for “billion-scale <a id="_idIndexMarker851"/>network embeddings.” This means that this is useful for networks with either billions of nodes or billions of edges. It’s a claim that would make this model useful for large real-world networks. You can read the documentation <span class="No-Break">at </span><a href="https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.randne.RandNE"><span class="No-Break">https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.randne.RandNE</span></a><span class="No-Break">.</span></p>
			<p>In Jupyter, if you <em class="italic">Shift</em> + <em class="italic">Tab</em> into the model instantiation code, you can read <span class="No-Break">about it:</span></p>
			<p class="author-quote">An implementation of “RandNE” &lt;https://zw-zhang.github.io/files/2018_ICDM_RandNE.pdf&gt; from the ICDM ‘18 paper “Billion-scale Network Embedding with Iterative Random Projection”. The procedure uses normalized adjacency matrix based smoothing on an orthogonalized random normally generate base node embedding matrix.</p>
			<ol>
				<li value="1">Once again, let’s <a id="_idIndexMarker852"/>generate the embeddings and do the <a id="_idIndexMarker853"/>visualization in <span class="No-Break">one shot:</span><pre class="source-code">
from karateclub.node_embedding.neighbourhood.randne import RandNE</pre><pre class="source-code">
model = RandNE()</pre><pre class="source-code">
model.fit(G)</pre><pre class="source-code">
embeddings = model.get_embedding()</pre><pre class="source-code">
title = 'Les Miserables Character Similarity (RandNE)'</pre><pre class="source-code">
draw_clustering(embeddings, nodes, title)</pre></li>
			</ol>
			<p>The output is the <span class="No-Break">following graph:</span></p>
			<div>
				<div id="_idContainer208" class="IMG---Figure">
					<img src="image/B17105_11_029.jpg" alt="Figure 11.29 – RandNE embeddings" width="1536" height="1252"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.29 – RandNE embeddings</p>
			<ol>
				<li value="2">Right away, you <a id="_idIndexMarker854"/>can see that this scatterplot <a id="_idIndexMarker855"/>looks very different from both FEATHER and NodeSketch. Let’s take a look at the ego networks for <strong class="source-inline">Marius</strong> and <strong class="source-inline">MotherPlutarch</strong>, two <a id="_idIndexMarker856"/>nodes that have been found to <span class="No-Break">be similar:</span><pre class="source-code">
node = 'Marius'</pre><pre class="source-code">
G_ego = nx.ego_graph(G_named, node)</pre><pre class="source-code">
draw_graph(G_ego, show_names=True, node_size=3)</pre></li>
			</ol>
			<p>We get a <span class="No-Break">network output:</span></p>
			<div>
				<div id="_idContainer209" class="IMG---Figure">
					<img src="image/B17105_11_030.jpg" alt="Figure 11.30 – Marius ego network" width="1510" height="1064"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.30 – Marius ego network</p>
			<ol>
				<li value="3"><span class="No-Break">Next, </span><span class="No-Break"><strong class="bold">MotherPlutarch</strong></span><span class="No-Break">:</span><pre class="source-code">
node = 'MotherPlutarch'</pre><pre class="source-code">
G_ego = nx.ego_graph(G_named, node)</pre><pre class="source-code">
draw_graph(G_ego, show_names=True, node_size=3)</pre></li>
			</ol>
			<p>And<a id="_idIndexMarker857"/> the <a id="_idIndexMarker858"/>network is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer210" class="IMG---Figure">
					<img src="image/B17105_11_031.jpg" alt="Figure 11.31 – MotherPlutarch ego network" width="1582" height="1056"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.31 – MotherPlutarch ego network</p>
			<p>Wow, these ego<a id="_idIndexMarker859"/> networks are so different, and so are the nodes. <strong class="bold">Marius</strong> is a well-connected node, and <strong class="bold">MotherPlutarch</strong> has a single edge with another node. These are two very different nodes, and the embeddings found them to be similar. However, it could be due to the PCA step for the scatter plot visualization, so please<a id="_idIndexMarker860"/> don’t be too quick to judge RandNE from this one example. Check out some of the other similar nodes. I will leave this up to you, for your own practice <span class="No-Break">and learning.</span></p>
			<p>What do the embeddings <span class="No-Break">look like?</span></p>
			<pre class="source-code">
eb_df = pd.DataFrame(embeddings, index=nodes)
eb_df['label'] = clf_df['label']
eb_df.head(10)</pre>
			<p>This will show <span class="No-Break">our embeddings.</span></p>
			<div>
				<div id="_idContainer211" class="IMG---Figure">
					<img src="image/B17105_11_032.jpg" alt="Figure 11.32 – RandNE embeddings DataFrame" width="1650" height="545"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.32 – RandNE embeddings DataFrame</p>
			<p>The <a id="_idIndexMarker861"/>embeddings ended up being 77 features, so <a id="_idIndexMarker862"/>this creates simpler embeddings by default than FEATHER. NodeSketch created 32 features, <span class="No-Break">in comparison.</span></p>
			<ol>
				<li value="4">How well is Random Forest able to use <span class="No-Break">the embeddings?</span><pre class="source-code">
X_cols = [c for c in eb_df.columns if c != 'label']</pre><pre class="source-code">
X = eb_df[X_cols]</pre><pre class="source-code">
y = eb_df['label']</pre><pre class="source-code">
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1337, test_size=0.3)</pre><pre class="source-code">
clf = RandomForestClassifier(random_state=1337)</pre><pre class="source-code">
clf.fit(X_train, y_train)</pre><pre class="source-code">
train_acc = clf.score(X_train, y_train)</pre><pre class="source-code">
test_acc = clf.score(X_test, y_test)</pre><pre class="source-code">
print('train accuracy: {}\ntest accuracy: {}'.format(train_acc, test_acc))</pre></li>
			</ol>
			<p>If we run this code, we get <span class="No-Break">these results:</span></p>
			<pre class="source-code">
<strong class="bold">train accuracy: 0.9811320754716981</strong>
<strong class="bold">test accuracy: 0.9166666666666666</strong></pre>
			<p>The model was able to predict on the test set with 98.1% accuracy, and 91.7% accuracy on the test set. This <a id="_idIndexMarker863"/>is worse than with FEATHER and NodeSketch embeddings, but it could be a fluke. I wouldn’t trust these results with so little training data. The <a id="_idIndexMarker864"/>model was able to successfully use the embeddings as training data. However, as before, if you inspect the feature i<a id="_idTextAnchor463"/>mportances of the embeddings, you will not be able to interpret <span class="No-Break">the results.</span></p>
			<h2 id="_idParaDest-266"><a id="_idTextAnchor464"/>Other models</h2>
			<p>These are not the only three models that Karate Club has available for creating node embeddings. Here are two more. You can experiment with them the same way that we did with FEATHER, NodeSketch, and RandNE. The results with Random Forest for all of the embedding models were about the same. They can all be useful. I recommend that you get curious about Karate Club and start investigating what it <span class="No-Break">has available.</span></p>
			<p>These models do the same thing, but the implementation is different. Their implementations are very interesting. I recommend that you read the papers that were written about the<a id="_idTextAnchor465"/> approaches. You can see these as an evolution for creating <span class="No-Break">node embeddings.</span></p>
			<h3>GraRep</h3>
			<p><strong class="bold">GraRep</strong> is <a id="_idIndexMarker865"/>another model we can use. You can find the <a id="_idIndexMarker866"/>documentation <span class="No-Break">here: </span><a href="https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.grarep.GraRep"><span class="No-Break">https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.grarep.GraRep</span></a><span class="No-Break">:</span></p>
			<pre class="source-code">
from karateclub.node_embedding.neighbourhood.grarep <a id="_idTextAnchor466"/>import GraRep
model = GraRep()
model.fit(G)
embeddings = model.get_embedding()</pre>
			<h3>DeepWalk</h3>
			<p><strong class="bold">DeepWalk</strong> is <a id="_idIndexMarker867"/>another <a id="_idIndexMarker868"/>possible model we can <span class="No-Break">use: </span><a href="https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.deepwalk.DeepWalk"><span class="No-Break">https://karateclub.readthedocs.io/en/latest/modules/root.html#karateclub.node_embedding.neighbourhood.deepwalk.DeepWalk</span></a><span class="No-Break">:</span></p>
			<pre class="source-code">
from karateclub.node_embedding.neighbourhood.deepwalk import DeepWalk
model = DeepWalk()
model.fit(G)
embeddings = model.get_embedding()</pre>
			<p>Now that <a id="_idIndexMarker869"/>we have <a id="_idIndexMarker870"/>several options <a id="_idTextAnchor467"/>for creating graph embeddings, let’s use them in supervised ML <span class="No-Break">for classification.</span></p>
			<h1 id="_idParaDest-267"><a id="_idTextAnchor468"/>Using embeddings in supervised ML</h1>
			<p>Alright! We’ve <a id="_idIndexMarker871"/>made it through some really fun hands-on work involving network construction, community detection, and both unsupervised and supervised ML; done some egocentric network visualization; and inspected the results of the use of different embeddings. This chapter really brought everything together. I hope you enjoyed the hands-on work as much as I did, and I hope you found it useful and informative. Before concluding this chapter, I want to go over the pros and cons of using embeddings the way that <span class="No-Break">we have.</span></p>
			<p>Please also keep in mind that there are many other classification models we could have tested with, not just Random Forest. You can use these embeddings in a neural network if you want, or you could test them with logistic regres<a id="_idTextAnchor469"/>sion. Use what you learned here and go have as much fun as possible <span class="No-Break">while learning.</span></p>
			<h2 id="_idParaDest-268"><a id="_idTextAnchor470"/>Pros and cons</h2>
			<p>Let’s discuss the<a id="_idIndexMarker872"/> pros and cons of using these embeddings. First, let’s start with the cons. I’ve already mentioned this a few times in this chapter, so I’ll just repeat<a id="_idIndexMarker873"/> it one last time: if you use these embeddings, no matter how interpretable a classification model is, you lose all interpretability. No matter what, you now have a black-box model, for better or for worse. If someone asks you why your model is predicting a certain way, you’ll just have to shrug and say it’s magic. You lost the ability to inspect importances when you went with embeddings. It’s gone. The way back is to use hand-crafted network training data like we created at the beginning of this chapter and in the previous chapter, but that requires knowledge of network science, which is probably why some people are happy to just use these embeddings. This leads to the benefit of these embeddings, <span class="No-Break">the pros.</span></p>
			<p>The benefit is <a id="_idIndexMarker874"/>that creating and using these embeddings is much easier and much faster than creating your own training data. You have to know about network science to know what centralities, clustering coefficients, and connected components are. You don’t have to know anything about network science to run <span class="No-Break">this code:</span></p>
			<pre class="source-code">
from karateclub.node_embedding.neighbourhood.grarep import GraRep
model = GraRep()
model.fit(G)
embeddings = model.get_embedding()</pre>
			<p>It’s a problem when <a id="_idIndexMarker875"/>people blindly use stuff in data science, but it happens all the time. I am not excusing it. I am stating that this happens all over the place, and Karate Club’s embeddings give you a shortcut to not really needing to know anything about networks to use graph data in classification. I think that’s a problem, but<a id="_idTextAnchor471"/> it doesn’t just happen with graphs. It happens in NLP and ML in general, all <span class="No-Break">the time.</span></p>
			<h2 id="_idParaDest-269"><a id="_idTextAnchor472"/>Loss of explainability and insights</h2>
			<p>The <a id="_idIndexMarker876"/>worst part about using these embeddings is you lose all model explainability and insights. Personally, building models doesn’t excite me. I get excited about the insights I can pull from predictions and from learned importances. I get excited about understanding the behaviors that the models picked up on. With embeddings, that’s gone. I’ve thrown interpretability in the trash in the hope of quickly creating an <span class="No-Break">effective model.</span></p>
			<p>This is the same problem I have <a id="_idIndexMarker877"/>with <strong class="bold">PCA</strong>. If you use it for dimension reduction, you lose all interpretability. I hope you have done the science first before decidi<a id="_idTextAnchor473"/>ng to use either PCA or graph embeddings. Otherwise, it’s data alchemy, not <span class="No-Break">data science.</span></p>
			<h2 id="_idParaDest-270"><a id="_idTextAnchor474"/>An easier workflow for classification and clustering</h2>
			<p>It’s not <a id="_idIndexMarker878"/>all bad, though. If you find that one of these types of embeddings is reliable and very high-quality, then you do have a shortcut to classification and clustering, so long as you don’t need the interpretability. You can<a id="_idIndexMarker879"/> go from a graph to classification or clustering in minutes rather than hours. That’s a huge speedup compared to hand-crafting training data from graph features. So, if you just want to see whether a graph can be useful for predicting something, this is one definite shortcut to building <span class="No-Break">a prototype.</span></p>
			<p>It’s all pros and cons and use cases. If you need interpretability, you won’t get it here. If you need to move fast, this can help. And it’s very likely that there are insights that can be harvested from embeddings after learning more about them. I have seen that come true as well. Sometimes there are insights that you can find – it just ta<a id="_idTextAnchor475"/>kes an indirect approach to get to them, and hopefully, this book has given you <span class="No-Break">some ideas.</span></p>
			<h1 id="_idParaDest-271"><a id="_idTextAnchor476"/>Summary</h1>
			<p>I can’t believe we’ve made it to this point. At the beginning of this book, this felt like an impossible task, and yet here we are. In order to do the hands-on exercises for this chapter, we’ve used what we learned in the previous chapters. I hope I have shown you how networks can be useful, and how to work <span class="No-Break">with them.</span></p>
			<p>At the beginning of this book, I set out to write a practical hands-on book that would be code-heavy, not math-heavy. There are tons of network analysis books out there that have an emphasis on math but do not show actual implementation very well, or at all. I hope this book has effectively bridged the gap, giving a new skill to coders, and showing social scientists programmatic ways to take their network analysis to new heights. Thank you so much for reading <span class="No-Break">this book!</span></p>
		</div>
	</div>
</div>
</body></html>