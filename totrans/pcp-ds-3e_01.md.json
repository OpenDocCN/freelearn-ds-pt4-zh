["```py\ntweet = \"RT @j_o_n_dnger: $TWTR now top holding for Andor, unseating $AAPL\"\nwords_in_tweet = tweet.split(' ') # list of words in tweet\nfor word in words_in_tweet: # for each word in list\n if \"$\" in word: # if word has a \"cashtag\"\n  print(\"THIS TWEET IS ABOUT\", word) # alert the user\n```", "```py\n    ['RT', '@robdv:', '$TWTR', 'now', 'top', 'holding', 'for', 'Andor,', 'unseating', '$AAPL']\n    ```", "```py\n    if \"$\" in word: # if word has a \"cashtag\"\n    ```", "```py\n    THIS TWEET IS ABOUT $TWTR\n    ```", "```py\n    THIS TWEET IS ABOUT $AAPL\n    ```", "```py\nimport requests\nfrom bs4 import BeautifulSoup\nfrom sklearn.feature_extraction.text import CountVectorizer\n# grab postings from the web\ntexts = []\n# cycle through 100 pages of indeed job resources\nfor i in range(0,1000,10):\n response = requests.get('http://www.indeed.com/jobs?q=data+scientist&sta rt='+str(i)).text\n soup  = BeautifulSoup(response)\n texts += [a.text for a in soup.findAll('span', {'class':'summary'})]\nprint(type(texts))\nprint(texts[0]) # first job description\n```", "```py\ntype(texts) # == list\nvectorizer = CountVectorizer(ngram_range=(1,2), stop_words='english')\n# Get basic counts of one and two word phrases\nmatrix = vectorizer.fit_transform(texts)\n# fit and learn to the vocabulary in the corpus\nprint len(vect.get_feature_names()) # how many features there are\n```"]