- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Types of Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For our first step into the world of data science, let’s take a look at the
    various ways in which data can be formed. In this chapter, we will explore three
    critical categorizations of data:'
  prefs: []
  type: TYPE_NORMAL
- en: Structured versus unstructured data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantitative versus qualitative data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The four levels of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will dive further into each of these topics by showing examples of how data
    scientists look at and work with data. This chapter aims to familiarize us with
    the fundamental types of data so that when we eventually see our first dataset,
    we will know exactly how to dissect, diagnose, and analyze the contents to maximize
    our insight value and machine learning performance.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to note is my use of the word *data*. In the previous chapter,
    I defined data as merely a collection of information. This vague definition exists
    because we may separate data into different categories and need our definition
    to be loose.
  prefs: []
  type: TYPE_NORMAL
- en: The next thing to remember while we go through this chapter is that for the
    most part, when I talk about the type of data, I will refer to either a specific
    characteristic (column/feature) of a dataset or the entire dataset as a whole.
    I will be very clear about which one I refer to at any given time.
  prefs: []
  type: TYPE_NORMAL
- en: At first thought, it might seem worthless to stop and think about what type
    of data we have before getting into the fun stuff, such as statistics and machine
    learning, but this is arguably one of the most important steps you need to take
    to perform data science.
  prefs: []
  type: TYPE_NORMAL
- en: When given a new dataset to analyze, it is tempting to jump right into exploring,
    applying statistical models, and researching the applications of machine learning
    to get results as soon as possible. However, if you don’t understand the type
    of data that you are working with, then you might waste a lot of time applying
    models that are known to be ineffective with that specific type of data.
  prefs: []
  type: TYPE_NORMAL
- en: Structured versus unstructured data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first question we want to ask ourselves about an entire dataset is whether
    we are working with structured or unstructured data. The answer to this question
    can mean the difference between needing three days or three weeks to perform a
    proper analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic breakdown is as follows (this is a rehashed definition of organized
    and unorganized data from [*Chapter 1*](B19488_01.xhtml#_idTextAnchor015)):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Structured (that is, organized) data**: This is data that can be thought
    of as observations and characteristics. It is usually organized using a table
    method (rows and columns) that can be organized in a spreadsheet format or a relational
    database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unstructured (that is, unorganized) data**: This data exists as a free entity
    and does not follow any standard organization hierarchy such as images, text,
    or videos.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are a few examples that could help you differentiate between the two:'
  prefs: []
  type: TYPE_NORMAL
- en: Most data that exists in text form, including server logs and Facebook posts,
    is unstructured
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scientific observations, as recorded by scientists, are kept in a very neat
    and organized (structured) format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A genetic sequence of chemical nucleotides (for example, ACGTATTGCA) is unstructured,
    even if the order of the nucleotides matters, as we cannot form descriptors of
    the sequence using a row/column format without taking a further look
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structured data is generally thought of as being much easier to work with and
    analyze. Most statistical and machine learning models were built with structured
    data in mind and cannot work on the loose interpretation of unstructured data.
    The natural row and column structure is easy to digest for human and machine eyes.
    So, why even talk about unstructured data? Because it is so common! Most estimates
    place unstructured data as 80-90% of the world’s data. This data exists in many
    forms and, for the most part, goes unnoticed by humans as a potential source of
    data. Tweets, emails, literature, and server logs are generally unstructured forms
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: While a data scientist likely prefers structured data, they must be able to
    deal with the world’s massive amounts of unstructured data. If 90% of the world’s
    data is unstructured, that implies that about 90% of the world’s information is
    trapped in a difficult format.
  prefs: []
  type: TYPE_NORMAL
- en: So, with most of our data existing in this free-form format, we must turn to
    pre-analysis techniques, called **pre-processing**, to apply structure to at least
    a part of the data for further analysis. A later chapter will deal with pre-processing
    in great detail; for now, we will consider the part of pre-processing wherein
    we attempt to apply transformations to convert unstructured data into a structured
    counterpart. We will see several examples of this later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: In between the realms of structured and unstructured data lies a hybrid category
    known as **semi-structured data**. While structured data follows a strict schema
    with a defined row and column format, and unstructured data lacks any specific
    format, semi-structured data contains elements of both.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-structured data is a form of data that does not conform entirely to the
    formal structure of data models associated with relational databases or other
    forms of data tables, yet contains tags or other markers to separate semantic
    elements and enforce hierarchies of records and fields within the data. Examples
    of semi-structured data include XML and JSON files, emails, and some types of
    NoSQL databases. This type of data is common in web data and certain types of
    scientific and health research.
  prefs: []
  type: TYPE_NORMAL
- en: Quantitative versus qualitative data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you ask a data scientist, *what type of data is this?* they will usually
    assume that you are asking them whether or not it is mostly quantitative or qualitative.
    It is likely the most common way of describing the specific characteristics of
    a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: For the most part, when talking about quantitative data, you are *usually* (not
    always) talking about a structured dataset with a strict row/column structure
    (because we don’t assume unstructured data even *has* any characteristics). That’s
    all the more reason why the pre-processing step is so important.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two data types can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Quantitative data**: This data can be described using numbers, and basic
    mathematical procedures, including addition, are possible on the set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Qualitative data**: This data cannot be described using numbers and basic
    mathematics. This data is generally thought of as being described using **natural**
    **categories** and language.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a look at an example of qualitative and quantitative data in a small
    business.
  prefs: []
  type: TYPE_NORMAL
- en: Example – coffee shop data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Say that we were processing the customers of a local coffee shop in a major
    city using five descriptors (characteristics) for each customer:'
  prefs: []
  type: TYPE_NORMAL
- en: Name of a coffee shop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revenue (in thousands of dollars)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zip code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Average monthly customers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Country of coffee origin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of these characteristics can be classified as either quantitative or qualitative,
    and that simple distinction can change everything. Let’s take a look at each one:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Name of a coffee* *shop*: Qualitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The name of a coffee shop is not expressed as a number and we cannot perform
    mathematical operations on the name of the shop.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Revenue*: Quantitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much money a coffee shop brings in can be described using a number. Also,
    we can do basic operations, such as adding up the revenue for 12 months to get
    a year’s worth of revenue.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Zip* *code*: Qualitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This one is tricky. A zip code is always represented using numbers, but what
    makes it qualitative is that it does not fit the second part of the definition
    of quantitative – we cannot perform basic mathematical operations on a zip code.
    If we add together two zip codes, it is a nonsensical measurement. We don’t necessarily
    get a new zip code and we don’t get “double the zip code.”
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Average monthly* *customers*: Quantitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Again, describing this factor using numbers and addition makes sense. Add up
    all of your monthly customers and you get your yearly customers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Country of coffee* *origin*: Qualitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will assume this is a very small coffee shop with coffee from a single origin.
    This country is described using a name (Ethiopian, Colombian), not numbers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Even though a zip code is described using numbers, it is not quantitative. This
    is because you can’t talk about the sum of all zip codes or an average zip code.
    These are nonsensical descriptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are having trouble identifying which is which, when you’re trying to
    decide whether or not the data is qualitative or quantitative, ask yourself a
    few basic questions about the data characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: Can you describe the value with numbers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No? It is most likely **qualitative**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Yes? Move on to the next question.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Do the values make numerical sense if you add them together?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No? They are most likely **qualitative**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Yes? You probably have **quantitative** data on your hands.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This method will help you to classify most, if not all, data into one of these
    two categories. If you are wondering how qualitative data can be described with
    numbers, imagine survey results asking people to rank something on a scale from
    1 to 5\. While the contents are being described with numbers, it doesn’t make
    sense to “add” them together. Someone’s score of 1 plus someone else’s score of
    3 doesn’t make a score of 4.
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference between these two categories defines the types of questions
    you may ask about each column. For a quantitative column, you may ask questions
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the average value?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does this quantity increase or decrease over time (if time is a factor)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a threshold where if this number became too high or too low, it would
    signal trouble for the company?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a qualitative column, none of the preceding questions can be answered.
    However, the following questions *only* apply to qualitative values:'
  prefs: []
  type: TYPE_NORMAL
- en: Which value occurs the most and the least?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many unique values are there?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are these unique values?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example – inspecting world alcohol consumption data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **World Health Organization** (**WHO**) released a dataset describing the
    average drinking habits of people in countries across the world. We will use Python
    and the data exploration tool pandas to gain a better look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code block produces this DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – The first five rows from our WHO alcohol consumption data](img/B19488_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – The first five rows from our WHO alcohol consumption data
  prefs: []
  type: TYPE_NORMAL
- en: 'These three lines do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Import pandas, which will be referred to as **pd** in the future
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read in a **comma-separated value** (**CSV**) file as a variable called **drinks**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Call a method, **head**, that reveals the first five rows of the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The table in the preceding figure lists the first five rows of data from the
    `drink.csv` file. We have six different columns that we are working on within
    this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**country**: Qualitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beer_servings**: Quantitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**spirit_servings**: Quantitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wine_servings**: Quantitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**total_litres_of_pure_alcohol**: Quantitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**continent**: Qualitative'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s look at the qualitative column, `continent`. We can use pandas to get
    some basic summary statistics about this non-numerical characteristic. The `describe()`
    method is being used here, which first identifies whether the column is likely
    to be quantitative or qualitative, and then gives basic information about the
    column as a whole. This can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code reveals that WHO has gathered data about five unique continents,
    the most frequent being `AF` (Africa), which occurred `53` times in the `193`
    observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a look at one of the quantitative columns and call the same method,
    we can see the difference in output, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can look at the mean (average) beer serving per person per country (`106.2`
    servings), as well as the lowest beer serving, `0`, and the highest beer serving
    recorded, `376` (that’s more than a beer a day).
  prefs: []
  type: TYPE_NORMAL
- en: Digging deeper
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quantitative data can be broken down into **discrete** and **continuous** quantities.
  prefs: []
  type: TYPE_NORMAL
- en: 'These can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Discrete data**: This describes data that is counted. It can only take on
    certain values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of discrete quantitative data include a dice roll, since it can only
    take on six values, and the number of customers in a coffee shop, because you
    can’t have a real range of people.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Continuous data**: This describes data that is measured. It exists on an
    infinite range of values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good example of continuous data would be a person’s weight because it can
    be 150 pounds or 197.66 pounds (note the decimals). The height of a person or
    building is a continuous number because an infinite scale of decimals is possible.
    Other examples of continuous data would be time and temperature.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Data as a whole can either be structured or unstructured, meaning that the data
    can either take on an organized row/column structure with distinct features that
    describe each row of the dataset or exist in a free-form state that usually must
    be pre-processed into a form that is easily digestible.
  prefs: []
  type: TYPE_NORMAL
- en: If data is structured, we can look at each column (feature) of the dataset as
    being either quantitative or qualitative. Basically, can the column be described
    using mathematics and numbers or not? The next part of this chapter will break
    down data into four very specific and detailed levels. At each order, we will
    apply more complicated rules of mathematics, and, in turn, gain a more intuitive
    and quantifiable understanding of the data.
  prefs: []
  type: TYPE_NORMAL
- en: The four levels of data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is generally understood that a specific characteristic (feature/column)
    of structured data can be broken down into one of four levels of data. These levels
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The nominal level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ordinal level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The interval level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ratio level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we move down the list, we gain more structure and, therefore, more returns
    from our analysis. Each level comes with its own accepted practice in measuring
    the center of the data. We usually think of the mean/average as being an acceptable
    form of center.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is only true for a specific type of data.
  prefs: []
  type: TYPE_NORMAL
- en: The nominal level
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first level of data, the **nominal** level, consists of data that is described
    purely by name or category. Basic examples include gender, nationality, species,
    or yeast strain in a beer. They are not described by numbers and are therefore
    qualitative. The following are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: A type of animal is on the nominal level of data. We may also say that if you
    are a chimpanzee, then you belong to the mammalian class as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A part of speech is also considered at the nominal level of data. The word she
    is a pronoun, and it is also a noun.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, being qualitative, we cannot perform any quantitative mathematical
    operations, such as addition or division. These would not make any sense.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical operations allowed at the nominal level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We cannot perform mathematics at the nominal level of data except the basic
    equality and set membership functions, as shown in the following two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Being a tech entrepreneur is the same as being in the tech industry, but not
    the other way around
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A figure described as a square falls under the description of being a rectangle,
    but not the other way around
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we’ll cover measures of center.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of center
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **measure of center** is a number that describes what the data tends to. It
    is sometimes referred to as the *balance point* of the data. Common examples include
    the mean, median, and mode.
  prefs: []
  type: TYPE_NORMAL
- en: To find the `continent` column.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of center, such as the mean and median, do not make sense at this level
    as we cannot order the observations or even add them together.
  prefs: []
  type: TYPE_NORMAL
- en: What data is like at the nominal level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data at the nominal level is mostly categorical. Because we can generally only
    use words to describe the data, it can be lost in translation between countries,
    or can even be misspelled.
  prefs: []
  type: TYPE_NORMAL
- en: While data at this level can certainly be useful, we must be careful about what
    insights we may draw from them. With only the mode as a basic measure of center,
    we are unable to draw conclusions about an **average** observation. This concept
    does not exist at this level. It is only at the next level that we may begin to
    perform true mathematics on our observations.
  prefs: []
  type: TYPE_NORMAL
- en: The ordinal level
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The nominal level did not provide us with much flexibility in terms of mathematical
    operations due to one seemingly unimportant fact: we could not order the observations
    in any natural way. Data at the **ordinal** level provides us with a rank order
    or the means to place one observation before the other. However, it does not provide
    us with relative differences between observations, meaning that while we may order
    the observations from first to last, we cannot add or subtract them to get any
    real meaning.'
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Likert** is among the most common ordinal-level scales. Whenever you are
    given a survey asking you to rate your satisfaction on a scale from 1 to 10, you
    are providing data at the ordinal level. Your answer, which must fall between
    1 and 10, can be ordered: 8 is better than 7 while 3 is worse than 9.'
  prefs: []
  type: TYPE_NORMAL
- en: However, the differences between the numbers do not make much sense. The difference
    between a 7 and a 6 might be different from the difference between a 2 and a 1.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical operations allowed at the ordinal level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We are allowed much more freedom at this level in terms of mathematical operations.
    We inherit all mathematics from the ordinal level (equality and set membership)
    and we can also add the following to the list of operations allowed at the nominal
    level:'
  prefs: []
  type: TYPE_NORMAL
- en: Ordering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ordering refers to the natural order provided to us by the data. However, this
    can be tricky to figure out sometimes. When speaking about the spectrum of visible
    light, we can refer to the names of colors – **Red**, **Orange**, **Yellow**,
    **Green**, **Blue**, **Indigo**, and **Violet**. Naturally, as we move from left
    to right, the light is gaining energy and other properties. We may refer to this
    as a natural order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – The natural order of color](img/B19488_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – The natural order of color
  prefs: []
  type: TYPE_NORMAL
- en: However, if needed, an artist may impose another order on the data, such as
    sorting the colors based on the cost of the material to make the said color. This
    could change the order of the data, but so long as we are consistent in what defines
    the order, it does not matter what defines it.
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons are another new operation allowed at this level. At the ordinal
    level, it would not make sense to say that one country was naturally better than
    another or that one part of speech is worse than another. At the ordinal level,
    we can make these comparisons. For example, we can talk about how putting a 7
    on a survey is worse than putting a 10.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of center
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the ordinal level, the **median** is usually an appropriate way of defining
    the center of the data. The mean, however, would be impossible because division
    is not allowed at this level. We can also use the mode, similar to how we could
    at the nominal level.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at an example of using the median.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine you have conducted a survey among your employees asking “*How happy
    are you to be working here on a scale from 1-5?*” and your results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s use Python to find the median of this data. It is worth noting that most
    people would argue that the mean of these scores would work just fine. The reason
    that the mean would not be as mathematically viable is that if we subtract/add
    two scores, say a score of 4 minus a score of 2, the difference of 2 does not
    mean anything. If addition/subtraction among the scores doesn’t make sense, the
    mean won’t make sense either:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It turns out that the median is not only more sound but also makes the survey
    results look much better.
  prefs: []
  type: TYPE_NORMAL
- en: The interval level
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we are getting somewhere interesting. At the **interval** level, we are
    beginning to look at data that can be expressed through very quantifiable means,
    and where much more complicated mathematical formulas are allowed. The basic difference
    between the ordinal level and the interval level is, well, just that difference.
  prefs: []
  type: TYPE_NORMAL
- en: Data at the interval level allows meaningful subtraction between data points.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of data at the interval level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Temperature serves as an excellent illustration of interval-level data. When
    comparing a 100-degree Fahrenheit reading in Texas, US, to an 80-degree Fahrenheit
    measurement in Istanbul, Turkey, it becomes evident that Texas is 20 degrees warmer
    than Istanbul. This straightforward comparison highlights the increased potential
    for manipulation and analysis offered by interval-level data in contrast to other
    levels of measurement.
  prefs: []
  type: TYPE_NORMAL
- en: It seems as though the example at the ordinal level (using the 1 to 5 survey)
    fits the bill of the interval level. However, remember that the *difference* between
    the scores (when you subtract them) does not make sense; therefore, this data
    cannot be called at the interval level.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical operations allowed at the interval level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can use all the operations allowed at the lower levels (ordering, comparisons,
    and so on), along with two other notable operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Addition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subtraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The allowance of these two operations allows us to talk about data at this level
    in a whole new way.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of center
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this level, we can use the median and mode to describe this data. However,
    usually, the most accurate description of the center of data would be the **arithmetic
    mean**, more commonly referred to as the **mean**. Recall that the definition
    of the mean requires us to add all the measurements together. At the previous
    levels, addition was meaningless. Therefore, the mean would have lost extreme
    value. It is only at the interval level and above that the arithmetic mean makes
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at an example of using the mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we’re looking at the temperature of a fridge containing a pharmaceutical
    company’s new vaccine. We measure the temperature every hour with the following
    data points (in Fahrenheit):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Using Python again, let’s find the mean and median of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how the mean and median are quite close to each other and both are around
    `31` degrees. The question *How cold is the fridge?* on average has an answer
    of about `31`. However, the vaccine comes with a warning:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“Do not keep this vaccine at a temperature under* *29 degrees.”*'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the temperature dropped below `29` degrees at least twice, but we
    ended up assuming that it isn’t enough for it to be detrimental.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the measure of variation can help us understand how bad the fridge
    situation can be.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of variation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is something new that we have not discussed yet. It is one thing to talk
    about the center of the data but, in data science, it is also very important to
    mention how “spread out” the data is. The measures that describe this phenomenon
    are called **measures of variation**. You have likely heard of *standard deviation*
    from your statistics classes. This idea is extremely important and I would like
    to address it briefly.
  prefs: []
  type: TYPE_NORMAL
- en: A measure of variation (such as the standard deviation) is a number that attempts
    to describe how spread out the data is.
  prefs: []
  type: TYPE_NORMAL
- en: Along with a measure of center, a measure of variation can almost entirely describe
    a dataset with only two numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Standard deviation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Arguably, the standard deviation is the most common measure of the variation
    of data at the interval level and beyond. The standard deviation can be thought
    of as the “average distance a data point is at from the mean.” While this description
    is technically and mathematically incorrect, it is a good way to think about it.
    The formula for standard deviation can be broken down into the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Find the mean of the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each number in the dataset, subtract it from the mean and then square it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the average of each square difference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take the square root of the number obtained in *Step 3* – this is the standard
    deviation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notice how we calculate the arithmetic mean as one of the steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let’s look back at the temperature dataset. Let’s find the standard
    deviation of the dataset using Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: All of this code led us to find out that the standard deviation of the dataset
    is around 2.5, meaning that, *on average,* a data point is 2.5 degrees off from
    the average temperature of around 31 degrees. This means that the temperature
    could likely dip below 29 degrees again in the near future.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The reason we want the “square difference” between each point and the mean and
    not the “actual difference” is because squaring the value emphasizes outliers
    – data points that are abnormally far away.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of variation give us a very clear picture of how spread out or dispersed
    our data is. This is especially important when we are concerned with ranges of
    data and how data can fluctuate (think percentage return on stocks).
  prefs: []
  type: TYPE_NORMAL
- en: The big difference between data at this level and the next level lies in something
    that is not obvious. Data at the interval level does not have a *natural starting
    point or a natural 0.* However, being at 0 degrees Celsius does not mean that
    you have no temperature
  prefs: []
  type: TYPE_NORMAL
- en: The ratio level
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we will take a look at the ratio level. After moving through three
    different levels with differing levels of allowed mathematical operations, the
    ratio level proves to be the strongest of the four.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical operations allowed at the ratio level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Not only can we define order and difference, but the ratio level allows us to
    *multiply and divide* as well. This might seem like not much to make a fuss over
    but it changes almost everything about the way we view data at this level.
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While Fahrenheit and Celsius are stuck at the interval level, the Kelvin scale
    of temperature boasts a natural zero. A measurement of 0 Kelvin means the absence
    of heat. It is a non-arbitrary starting zero. We can scientifically say that 200
    Kelvin is twice as much heat as 100 Kelvin.
  prefs: []
  type: TYPE_NORMAL
- en: Money in the bank is at the ratio level. You can have no money in the bank and
    it makes sense that $200,000 is twice as much as $100,000.
  prefs: []
  type: TYPE_NORMAL
- en: Many people may argue that Celsius and Fahrenheit also have a starting point
    (mainly because we can convert from Kelvin to either of the two). The real difference
    here might seem silly, but because the conversion to Celsius and Fahrenheit makes
    the calculations go into the negative, it does not define a clear and “natural”
    zero.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of center
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The arithmetic mean still holds meaning at this level, as does a new type of
    mean called the **geometric mean**, which is the square root of the product of
    all the values.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in our fridge temperature data, we can calculate the geometric
    mean as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note again how it is close to the arithmetic mean and median, as calculated
    previously. This is not always the case and will be talked about at great length
    in. [*Chapter 8*](B19488_08.xhtml#_idTextAnchor214)*,* *Advanced statistics*.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with the ratio level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Even with all of this added functionality at this level, we must generally also
    make a very large assumption that makes the ratio level a bit restrictive. For
    this reason alone, many data scientists prefer the interval level to the ratio
    level. The reason for this restrictive property is that if we allowed negative
    values, the ratio might not always make sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider that we allowed debt to occur in our money in the bank example. If
    we had a balance of $50,000, the following ratio would not make sense at all:'
  prefs: []
  type: TYPE_NORMAL
- en: 50,000 / -50,000 = -1
  prefs: []
  type: TYPE_NORMAL
- en: Data is in the eye of the beholder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is possible to impose structure on data. For example, while I said that you
    technically cannot use a mean for the 1 to 5 data at the ordinal scale, many statisticians
    would not have a problem using this number as a descriptor of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The level at which you are interpreting data is a *massive* assumption that
    should be made at the beginning of any analysis and done with much care and deliberation.
    If you are looking at data that is generally thought of at the ordinal level and
    applying tools such as the arithmetic mean and standard deviation, this is something
    that data scientists must be aware of. This is mainly because if you continue
    to hold these assumptions as valid in your analysis, you may encounter problems.
    For example, if you also assume divisibility at the ordinal level by mistake,
    you are imposing a structure where the structure may not exist.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve seen a lot of data about, well, data. Let’s wrap up with a summary of
    what we’ve learned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter has provided an overview of the crucial role data types play in
    data science, emphasizing the importance of understanding the nature of the data
    before commencing any analysis. We discussed the significance of asking three
    key questions when encountering a new dataset: whether the data is structured
    or unstructured, whether each column is quantitative or qualitative, and the level
    of data within each column (nominal, ordinal, interval, or ratio).'
  prefs: []
  type: TYPE_NORMAL
- en: By completing this chapter, you should be able to identify the types of data
    they are working with and understand the implications of those data types on their
    analysis. This knowledge will help you select appropriate graphs, interpret results,
    and determine the next steps in the analytical process. You should also be familiar
    with the concept of converting data from one level to another to gain more insights.
  prefs: []
  type: TYPE_NORMAL
- en: With this knowledge, and with the ability to classify data as nominal or ordinal
    through various examples, we can begin to approach data challenges more effectively
    and make informed decisions in data-driven projects.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming chapter, we will delve into how data types are utilized by data
    scientists in the process of data discovery and visualization, further expanding
    on the practical applications of the concepts discussed in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Questions and answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the following statements, classify them as ordinal or nominal:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The origin of the beans in your cup of coffee: *Nominal*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The place someone receives after completing a foot race: *Ordinal*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The metal used to make the medal that they receive after placing in the race:
    *Nominal*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The telephone number of a client: *Nominal*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How many cups of coffee you drink in a day: *Ordinal*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
