- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advanced Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we went over the basics of probability and how we can
    apply simple theorems to complex tasks. To briefly summarize, probability is the
    mathematics of modeling events that may or may not occur. We use formulas in order
    to describe these events and even look at how multiple events can behave together.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore more complicated theorems of probability and
    how we can use them in a predictive capacity. Advanced topics, such as **Bayes’
    theorem** and **random variables**, give rise to common machine learning algorithms,
    such as the **Naïve Bayes algorithm** (also covered in this book).
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will focus on some of the more advanced topics in probability
    theory, including the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exhaustive events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayes’ theorem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic prediction rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In later chapters, we will revisit Bayes’ theorem and use it to create a very
    powerful and fast machine learning algorithm, called the Naïve Bayes algorithm.
    This algorithm captures the power of Bayesian thinking and applies it directly
    to the problem of predictive learning. For now, let’s get started with Bayesian
    thinking!
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian ideas revisited
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we talked very briefly about Bayesian ways of thinking.
    Recall that the Bayesian way of thinking is to let our data shape and update our
    beliefs. We start with a prior probability, or what we naïvely think about a hypothesis,
    and then we have a posterior probability, which is what we think about a hypothesis,
    given some data.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes’ theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Bayes’ theorem is arguably the most well-known part of Bayesian inference.
    Recall that we previously defined the following:'
  prefs: []
  type: TYPE_NORMAL
- en: P(A) = the probability that event A occurs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(A|B) = the probability that A occurs, given that B occurred
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(A, B) = the probability that A and B occur
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(A, B) = P(A) * P(B|A)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That last bullet can be read as “the probability that both A and B occur is
    equal to the probability that A occurs x times the probability that B occurred,
    given that A has already occurred.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting from the last bullet points, we know the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo><mi
    mathvariant="normal">*</mi><mi>P</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>A</mi><mo>)</mo></mrow></mrow></mrow></math>](img/70.png)'
  prefs: []
  type: TYPE_IMG
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>,</mo><mi>A</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo><mi
    mathvariant="normal">*</mi><mi>P</mi><mo>(</mo><mi>A</mi><mo>|</mo><mi>B</mi><mo>)</mo></mrow></mrow></mrow></math>](img/71.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And we also know that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>B</mi><mo>,</mo><mi>A</mi><mo>)</mo></mrow></mrow></mrow></math>](img/72.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, we can combine these together and see that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo><mi
    mathvariant="normal">*</mi><mi>P</mi><mo>(</mo><mi>A</mi><mo>|</mo><mi>B</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo><mi
    mathvariant="normal">*</mi><mi>P</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>A</mi><mo>)</mo></mrow></mrow></mrow></math>](img/73.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Dividing both sides by P(B) gives us Bayes’ theorem, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>|</mo><mi>B</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo><mi
    mathvariant="normal">*</mi><mi>P</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>A</mi><mo>)</mo></mrow><mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/74.png)'
  prefs: []
  type: TYPE_IMG
- en: So, our end result is Bayes’ theorem! This is a way to get from P(A|B) to P(B|A)
    (if you only have one of them) and a way to get P(A|B) if you already know P(A)
    (without knowing B).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try thinking about Bayes using the terms *hypothesis* and *data*.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose H = your hypothesis about the given data and D = the data that you are
    given.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes can be interpreted as trying to figure out P(H|D) (the probability that
    our hypothesis is correct, given the data at hand).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use our terminology from before:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>H</mi><mo>|</mo><mi>D</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mi
    mathvariant="normal">P</mi><mo>(</mo><mi mathvariant="normal">D</mi><mo>|</mo><mi
    mathvariant="normal">H</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>H</mi><mo>)</mo></mrow><mrow><mi>P</mi><mo>(</mo><mi>D</mi><mo>)</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/75.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s take a look at that formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(H)* is the probability of the hypothesis before we observe the data, called
    the **prior probability**, or just **prior**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(H|D)* is what we want to compute, the probability of the hypothesis after
    we observe the data, called the **posterior**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(D|H)* is the probability of the data under the given hypothesis, called
    the **likelihood**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(D)* is the probability of the data under any hypothesis, called the **normalizing
    constant**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concept is not far off from the idea of machine learning and predictive
    analytics. In many cases, when considering predictive analytics, we use the given
    data to predict an outcome. Using the current terminology, H (our hypothesis)
    can be considered our outcome, and P(H|D) (the probability that our hypothesis
    is true, given our data) is another way of saying, what is the chance that my
    hypothesis is correct, given the data in front of me?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at an example of how we can use Bayes’ formula in the workplace.
  prefs: []
  type: TYPE_NORMAL
- en: Consider that you have two people in charge of writing blog posts for your company,
    Lucy and Avinash. From past performance, you like 80% of Lucy’s work and only
    50% of Avinash’s work. A new blog post comes to your desk in the morning, but
    the author isn’t mentioned. You love the article. A+. What is the probability
    that it came from Avinash? Each blogger blogs at a very similar rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we freak out, let’s do what any experienced mathematician (and now you)
    would do. Let’s write out all of our information, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '*H* (hypothesis) = the blog came from Avinash'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*D* (data) = you loved the blog post'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(H|D)* = the chance that it came from Avinash, given that you loved it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(D|H)* = the chance that you loved it, given that it came from Avinash'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(H)* = the chance that an article came from Avinash'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(D)* = the chance that you love an article'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that some of these variables make almost no sense without context. P(D),
    the probability that you would love any given article put on your desk, is a weird
    concept, but trust me – in the context of Bayes’ formula, it will be relevant
    very soon.
  prefs: []
  type: TYPE_NORMAL
- en: Also, note that in the last two items, they assume nothing else. *P(D) does
    not assume the origin of the blog post; think of P(D) as asking, if an article
    was plopped on your desk from some unknown source, what is the chance that you’d
    like it?* (again, I know it sounds weird out of context).
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we want to know *P(H|D)*. Let’s try to use Bayes’ theorem, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>H</mi><mo>|</mo><mi>D</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mi
    mathvariant="normal">P</mi><mo>(</mo><mi mathvariant="normal">D</mi><mo>|</mo><mi
    mathvariant="normal">H</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>H</mi><mo>)</mo></mrow><mrow><mi>P</mi><mo>(</mo><mi>D</mi><mo>)</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/75.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But do we know the numbers on the right-hand side of this equation? I say that
    we do! Let’s see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(H)* is the probability that any given blog post comes from Avinash. As bloggers
    write at a very similar rate, we can assume this is 0.5 because we have a 50/50
    chance that it came from either blogger (note how I did not assume *D*, the data,
    for this).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(D|H)* is the probability that you love a post from Avinash, which we previously
    said was 50% – so, 0.5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(D)* is interesting. This is the chance that you love an article *in general*.
    It means that we must take into account the scenario where the post came from
    either Lucy or Avinash. Now, if the hypothesis forms a suite, we can use our laws
    of probability, as mentioned in the previous chapter. A suite is formed when a
    set of hypotheses is both collectively exhaustive – meaning at least one must
    occur – and mutually exclusive. In layman’s terms, in a suite of events, exactly
    one and only one hypothesis can occur. In our case, the two hypotheses are that
    the article came from Lucy, or that the article came from Avinash. This is definitely
    a suite for the following reasons:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At least one of them wrote it
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: At most one of them wrote it
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, *exactly one* of them wrote it
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we have a suite, we can use our multiplication and addition rules, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – An example of the multiplication and addition rules in action](img/B19488_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – An example of the multiplication and addition rules in action
  prefs: []
  type: TYPE_NORMAL
- en: 'Whew! Way to go! Now, we can finish our equation, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>H</mi><mo>|</mo><mi>D</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>H</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>H</mi><mo>)</mo></mrow><mrow><mi>P</mi><mo>(</mo><mi>D</mi><mo>)</mo></mrow></mfrac><mi>P</mi><mo>(</mo><mi>H</mi><mo>|</mo><mi>D</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mo>.</mo><mn>5</mn><mi
    mathvariant="normal">*</mi><mo>.</mo><mn>5</mn></mrow><mrow><mo>.</mo><mn>65</mn></mrow></mfrac><mo>=</mo><mo>.</mo><mn>38</mn></mrow></mrow></mrow></math>](img/77.png)'
  prefs: []
  type: TYPE_IMG
- en: This means that there is a 38% chance that this article comes from Avinash.
    What is interesting is that P(H) = 0.5 and P(H|D) = 0.38\. This means that without
    any data, the chance that a blog post came from Avinash was a coin flip, or 50/50\.
    Given some data (your thoughts on the article), we updated our beliefs about the
    hypothesis, and it actually lowered the chance. This is what Bayesian thinking
    is all about – updating our posterior beliefs about something from a prior assumption,
    given some new data about the subject.
  prefs: []
  type: TYPE_NORMAL
- en: More applications of Bayes’ theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bayes’ theorem shows up in a lot of applications, usually when we need to make
    fast decisions based on data and probability. Most recommendation engines, such
    as Netflix’s, use some elements of Bayesian updating. And if you consider why
    that might be, it makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s suppose that, in our simplistic world, Netflix only has 10 categories
    to choose from. Now, suppose that, given no data, a user’s chance of liking a
    comedy movie out of 10 categories is 10% (just 1/10).
  prefs: []
  type: TYPE_NORMAL
- en: Okay, now suppose that the user has given a few comedy movies 5/5 stars. Now,
    when Netflix wonders what the chance is that the user would like another comedy,
    the probability that they might like a comedy, P(H|D), is going to be larger than
    a random guess of 10%!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try some more examples of applying Bayes’ theorem using more data. This
    time, let’s get a bit grittier.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Titanic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A very famous dataset involves looking at the survivors of the sinking of the
    Titanic in 1912\. We will use an application of probability in order to figure
    out whether there were any demographic features that showed a relationship to
    passenger survival. Mainly, we are curious to see whether we can isolate any features
    of our dataset that can tell us more about the types of people who were likely
    to survive this disaster.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s read in the data, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 6.1 – Representing the Titanic dataset options Sex and Survived](img/B19488_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 6.1 – Representing the Titanic dataset options Sex and Survived
  prefs: []
  type: TYPE_NORMAL
- en: The Titanic dataset only has two options for **Sex** and two options for **Survived**.
    While Survived is a relatively straightforward feature, this is one of our first
    examples of using a dataset in which data interpretations have “drifted” over
    time. We will revisit the concept of drift in a later chapter, and how datasets
    such as the Titanic dataset can be easy to work with but are outdated in their
    utility.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding table, each row represents a single passenger on the ship,
    and, for now, we will look at two specific features – the sex of the individual
    and whether or not they survived the sinking. For example, the first row represents
    a man who did not survive, while the fourth row (with index 3 – remember how Python
    indexes lists) represents a female who did survive.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with some basics. Let’s start by calculating the probability that
    any given person on the ship survived, regardless of their gender. To do this,
    let’s count the number of yeses in the **Survived** column and divide this figure
    by the total number of rows, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that I only had to calculate `P(Survived)`, and I used the law of conjugate
    probabilities to calculate `P(Died)` because those two events are complementary.
    Now, let’s calculate the probability that any single passenger is male or female:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s ask ourselves a question – did having a certain gender affect the
    survival rate? For this, we can estimate *P(Survived|Female)* or the chance that
    someone survived given that they were female. For this, we need to divide the
    number of women who survived by the total number of women, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>S</mi><mi>u</mi><mi>r</mi><mi>v</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>d</mi><mo>|</mo><mi>F</mi><mi>e</mi><mi>m</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo>(</mo><mi>F</mi><mi>e</mi><mi>m</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>A</mi><mi>N</mi><mi>D</mi><mi>S</mi><mi>u</mi><mi>r</mi><mi>v</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>)</mo></mrow><mrow><mi>P</mi><mo>(</mo><mi>F</mi><mi>e</mi><mi>m</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>)</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/78.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here’s the code for that calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `number_of_women =` `titanic[titanic.Sex==''female''].shape[0] #==` | `314`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `women_who_lived =` `titanic[(titanic.Sex==''female'') &` |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| `(``titanic.Survived==''yes'')].shape[0]` | `#==` | `233` |'
  prefs: []
  type: TYPE_TB
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: That’s a pretty big difference. It seems that gender plays a big part in this
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Example – medical studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A classic use of Bayes’ theorem is the interpretation of medical trials. Routine
    testing for illegal drug use is increasingly common in workplaces and schools.
    The companies that perform these tests maintain that the tests have a high sensitivity,
    which means that they are likely to produce a positive result if there are drugs
    in their system. They claim that these tests are also highly specific, which means
    that they are likely to yield a negative result if there are no drugs.
  prefs: []
  type: TYPE_NORMAL
- en: On average, let’s assume that the sensitivity of common drug tests is about
    60% and the specificity is about 99%. It means that if an employee is using drugs,
    the test has a 60% chance of being positive, while if an employee is not on drugs,
    the test has a 99% chance of being negative. Now, suppose these tests are applied
    to a workforce where the actual rate of drug use is 5%.
  prefs: []
  type: TYPE_NORMAL
- en: The real question here is, of the people who test positive, how many actually
    use drugs?
  prefs: []
  type: TYPE_NORMAL
- en: 'In Bayesian terms, we want to compute the probability of drug use, given a
    positive test:'
  prefs: []
  type: TYPE_NORMAL
- en: Let *D* = the event that drugs are in use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let *E* = the event that the test is positive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let *N* = the event that drugs are *NOT* in use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are looking for P(D|E).
  prefs: []
  type: TYPE_NORMAL
- en: 'By using *Bayes’ theorem*, we can extrapolate as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>E</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo>(</mo><mi>E</mi><mo>|</mo><mi>D</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>D</mi><mo>)</mo></mrow><mrow><mi>P</mi><mo>(</mo><mi>E</mi><mo>)</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/79.png)'
  prefs: []
  type: TYPE_IMG
- en: The prior, P(D), is the probability of drug use before we see the outcome of
    the test, which is 5%. The likelihood, P(E|D), is the probability of a positive
    test assuming drug use, which is the same thing as the sensitivity of the test.
    The normalizing constant, P(E), is a little bit trickier.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to consider two things – P(E and D) as well as P(E and N). Basically,
    we must assume that the test is capable of being incorrect when the user is not
    using drugs. Check out the following equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>E</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>E</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>D</mi><mo>)</mo><mi>o</mi><mi>r</mi><mi>P</mi><mo>(</mo><mi>E</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>N</mi><mo>)</mo></mrow></mrow></mrow></math>](img/80.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>E</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>D</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>E</mi><mo>|</mo><mi>D</mi><mo>)</mo><mo>+</mo><mi>P</mi><mo>(</mo><mi>N</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>E</mi><mo>|</mo><mi>N</mi><mo>)</mo></mrow></mrow></mrow></math>](img/81.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>E</mi><mo>)</mo><mo>=</mo><mo>.</mo><mn>05</mn><mi
    mathvariant="normal">*</mi><mo>.</mo><mn>6</mn><mo>+</mo><mo>.</mo><mn>95</mn><mi
    mathvariant="normal">*</mi><mo>.</mo><mn>01</mn></mrow></mrow></mrow></math>](img/82.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>E</mi><mo>)</mo><mo>=</mo><mn>0.0395</mn></mrow></mrow></mrow></math>](img/83.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, our original equation becomes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>E</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mo>.</mo><mn>6</mn><mi
    mathvariant="normal">*</mi><mo>.</mo><mn>05</mn></mrow><mn>0.0395</mn></mfrac></mrow></mrow></mrow></math>](img/84.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>D</mi><mo>|</mo><mi>E</mi><mo>)</mo><mo>=</mo><mo>.</mo><mn>76</mn></mrow></mrow></mrow></math>](img/85.png)'
  prefs: []
  type: TYPE_IMG
- en: This means that of the people who test positive for drug use, about a quarter
    are innocent!
  prefs: []
  type: TYPE_NORMAL
- en: Random variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A `h` for the hypotenuse, and we must figure out the length of the hypotenuse.
    We also might have the following, in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>x</mi><mo>=</mo><mn>5</mn></mrow></mrow></math>](img/86.png)'
  prefs: []
  type: TYPE_IMG
- en: Both of these variables are equal to one value at a time. In a random variable,
    we are subject to randomness, which means that our variables’ values are, well,
    just that – variable! They might take on multiple values depending on the environment.
  prefs: []
  type: TYPE_NORMAL
- en: A random variable still, as shown previously, holds a value. The main distinction
    between variables as we have seen them and a random variable is the fact that
    a random variable’s value may change, depending on the situation.
  prefs: []
  type: TYPE_NORMAL
- en: However, if a random variable can have many values, how do we keep track of
    them all? Each value that a random variable might take on is associated with a
    percentage, and for each value, there is a single probability that the variable
    will be that value.
  prefs: []
  type: TYPE_NORMAL
- en: With a random variable, we can also obtain the probability distribution of a
    random variable, which gives the variable’s possible values and their probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Written out, we generally use single capital letters (mostly the specific letter
    *X*) to denote random variables. For example, we might have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*X*: The outcome of a dice roll'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y*: The revenue earned by a company this year'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Z*: The score of an applicant on an interview coding quiz (0–100%)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Effectively, a random variable is a function that maps values from the sample
    space of an event (the set of all possible outcomes) to a probability value (between
    0 and 1). Think about the event as being expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>f</mi><mo>(</mo><mi>e</mi><mi>v</mi><mi>e</mi><mi>n</mi><mi>t</mi><mo>)</mo><mo>=</mo><mi>p</mi><mi>r</mi><mi>o</mi><mi>b</mi><mi>a</mi><mi>b</mi><mi>i</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi></mrow></mrow></mrow></math>](img/87.png)'
  prefs: []
  type: TYPE_IMG
- en: The function assigns a probability to each individual option. There are two
    main types of random variables – **discrete** and **continuous**.
  prefs: []
  type: TYPE_NORMAL
- en: Discrete random variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A discrete random variable only takes on a countable number of possible values,
    such as the outcome of a dice roll, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Representing a discrete random variable](img/B19488_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Representing a discrete random variable
  prefs: []
  type: TYPE_NORMAL
- en: Note how I use a capital X to define the random variable. This is a common practice.
    Also, note how the random variable maps a probability to each individual outcome.
    Random variables have many properties, two of which are their *expected value*
    and the *variance*. We will use a **probability mass function** (**PMF**) to describe
    a discrete random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'They take on the following appearance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>P</mi><mi>M</mi><mi>F</mi></mrow></mrow></mrow></math>](img/88.png)'
  prefs: []
  type: TYPE_IMG
- en: So, for a dice roll,
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mn>1</mn><mo>)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mn>6</mn><mi>a</mi><mi>n</mi><mi>d</mi><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mn>5</mn><mo>)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mn>6</mn></mrow></mrow></mrow></math>](img/89.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Consider the following examples of discrete variables:'
  prefs: []
  type: TYPE_NORMAL
- en: The likely result of a survey question (for example, on a scale of 1–10)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether the CEO will resign within the year (either true or false)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected value of a random variable defines the mean value of a long run
    of repeated samples of the random variable. This is sometimes called the *mean*
    of the variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, refer to the following Python code, which defines the random variable
    of a dice roll:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This function will invoke a random variable and come out with a response. Let’s
    roll `100` dice and average the result, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'So, taking `100` dice rolls and averaging them gives us a value of `3.77`!
    Let’s try this with a wide variety of trial numbers, as illustrated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Representing the average of 100 dice rolls](img/B19488_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Representing the average of 100 dice rolls
  prefs: []
  type: TYPE_NORMAL
- en: The preceding graph represents the average dice roll as we look at more and
    more dice rolls. We can see that the average dice roll rapidly approaches `3.5`.
    If we look at the left of the graph, we see that if we only roll a die about 100
    times, then we are not guaranteed to get an average dice roll of `3.5`. However,
    if we roll 10,000 dice one after another, we see that we would very likely expect
    the average dice roll to be about `3.5`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a discrete random variable, we can also use a simple formula, shown as
    follows, to calculate the expected value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>E</mi><mi>x</mi><mi>p</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo>=</mo><mi>E</mi><mo>[</mo><mi>X</mi><mo>]</mo><mo>=</mo><mi>μ</mi><mi>x</mi><mo>=</mo><mo>∑</mo><msub><mi
    mathvariant="normal">x</mi><mi>i</mi></msub><msub><mi mathvariant="normal">p</mi><mi>i</mi></msub></mrow></mrow></mrow></math>](img/90.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *xi* is the *ith* outcome and *pi* is the *ith* probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, for our dice roll, we can find the exact expected value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>(</mo><mn>1</mn><mo>)</mo><mo>+</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>(</mo><mn>2</mn><mo>)</mo><mo>+</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>(</mo><mn>3</mn><mo>)</mo><mo>+</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>(</mo><mn>4</mn><mo>)</mo><mo>+</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>(</mo><mn>5</mn><mo>)</mo><mo>+</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>(</mo><mn>6</mn><mo>)</mo><mo>=</mo><mn>3.5</mn></mrow></mrow></mrow></math>](img/91.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding result shows us that for any given dice roll, we can “expect”
    a dice roll of 3.5\. Now, obviously, that doesn’t make sense because we can’t
    get a 3.5 on a dice roll, but it does make sense when put in the context of many
    dice rolls. If you roll 10,000 dice, your average dice roll should approach 3.5,
    as shown in the graph and code previously.
  prefs: []
  type: TYPE_NORMAL
- en: The average of the expected value of a random variable is generally not enough
    to grasp the full idea behind the variable. For this reason, we will introduce
    a new concept, called variance.
  prefs: []
  type: TYPE_NORMAL
- en: The variance of a random variable represents the spread of the variable. It
    quantifies the variability of the expected value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for the variance of a discrete random variable is expressed as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mi>i</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi><mo>=</mo><mi>V</mi><mo>[</mo><mi>X</mi><mo>]</mo><mo>=</mo><msup><mi>σ</mi><mn>2</mn></msup><mi>x</mi><mo>=</mo><mo>∑</mo><mrow><mo>(</mo></mrow><msub><mi
    mathvariant="script">x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>μ</mi><mi mathvariant="script">x</mi></msub><msup><mo>)</mo><mn>2</mn></msup><msub><mi>p</mi><mi>i</mi></msub></mrow></mrow></mrow></math>](img/92.png)'
  prefs: []
  type: TYPE_IMG
- en: '*xi* and *pi* represent the same values as before, and ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi></mrow></math>](img/93.png)
    represents the expected value of the variable. In this formula, I also mentioned
    the sigma of *X*. Sigma, in this case, is the standard deviation, which is defined
    simply as the square root of the variance. Let’s look at a more complicated example
    of a discrete random variable.'
  prefs: []
  type: TYPE_NORMAL
- en: Variance can be thought of as a *give or take* metric. If I say you can expect
    to win $100 from a poker hand, you might be very happy. If I append that statement
    with the additional detail that you might win $100, give $80, or take $80, you
    now have a wide range of expectations to deal with, which can be frustrating and
    might make a risk-averse player more wary of joining the game. We can usually
    say that we have an expected value, give or take the standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: Consider that your team measures the success of a new product on a **Likert
    scale** – that is, as being in one of five categories, where a value of 0 represents
    a complete failure and 4 represents a great success. They estimate that a new
    project has the following chances of success (shown in *Figure 6**.4*), based
    on user testing and the preliminary results of the performance of the product.
  prefs: []
  type: TYPE_NORMAL
- en: We first have to define our random variable. Let the *X* random variable represent
    the success of our product. *X* is indeed a discrete random variable because the
    *X* variable can only take on one of five options – 0, 1, 2, 3, or 4.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the probability distribution of our random variable, *X*.
    Note how we have a column for each potential outcome of *X*, and following each
    outcome, we have the probability that that particular outcome will be achieved:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – The probability distribution of our random variable](img/B19488_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – The probability distribution of our random variable
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the project has a 2% chance of failing completely and a 26% chance
    of being a great success! We can calculate our expected value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>E</mi><mo>[</mo><mi>X</mi><mo>]</mo><mo>=</mo><mn>0</mn><mo>(</mo><mn>0.02</mn><mo>)</mo><mo>+</mo><mn>1</mn><mo>(</mo><mn>0.07</mn><mo>)</mo><mo>+</mo><mn>2</mn><mo>(</mo><mn>0.25</mn><mo>)</mo><mo>+</mo><mn>3</mn><mo>(</mo><mn>0.4</mn><mo>)</mo><mo>+</mo><mn>4</mn><mo>(</mo><mn>0.26</mn><mo>)</mo><mo>=</mo><mn>2.81</mn></mrow></mrow></mrow></math>](img/94.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This number means that the manager can expect a success of about `2.81` with
    this project. Now, by itself, that number is not very useful. Perhaps, if given
    several products to choose from, an expected value might be a way to compare the
    potential successes of several products. However, in this case, when we have just
    one product to evaluate, we will need more. Now, let’s check the variance, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: Variance = V[X] = X2 = (xi − μX)2pi = (0 − 2.81)2(0.02) + (1 − 2.81)2(0.07)
    + (2 − 2.81)2(0.25) + (3 − 2.81)2(0.4) + (4 − 2.81)2(0.26) = .93
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have both the standard deviation and the expected value of the score
    of the project, let’s try to summarize our results. We could say that our project
    will have an expected score of 2.81, plus or minus 0.96, meaning that we can expect
    something between 1.85 and 3.77.
  prefs: []
  type: TYPE_NORMAL
- en: So, one way we can address this project is that it is probably going to have
    a success rating of 2.81, give or take about a point.
  prefs: []
  type: TYPE_NORMAL
- en: You might be thinking, wow, Sinan – so at best, the project will be a 3.8, and
    at worst it will be a 1.8? Not quite.
  prefs: []
  type: TYPE_NORMAL
- en: 'It might be better than a 4, and it might also be worse than a 1.8\. To take
    this one step further, let’s calculate the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo>></mo><mo>=</mo><mn>3</mn><mo>)</mo></mrow></mrow></mrow></math>](img/95.png)'
  prefs: []
  type: TYPE_IMG
- en: First, take a minute and convince yourself that you can read that formula to
    yourself. What am I asking when I ask for P(X >= 3)? Honestly, take a minute and
    figure it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'P(X >= 3) is the probability that our random variable will take on a value
    at least as big as 3\. In other words, what is the chance that our product will
    have a success rating of 3 or higher? To calculate this, we can calculate the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>></mml:mo><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mn>66</mml:mn><mml:mo>=</mml:mo><mml:mn>66</mml:mn><mml:mi
    mathvariant="normal">%</mml:mi></mml:math>](img/96.png)'
  prefs: []
  type: TYPE_IMG
- en: This means that we have a 66% chance that our product will rate as either a
    3 or a 4.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to calculate this would be the conjugate way, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>></mml:mo><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo><</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:math>](img/97.png)'
  prefs: []
  type: TYPE_IMG
- en: Again, take a moment to convince yourself that this formula holds up. I am claiming
    that to find the probability that the product will be rated at least a 3 is the
    same as 1, minus the probability that the product will receive a rating below
    3\. If this is true, then the two events (X >=3 and X < 3) must complement one
    another.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is obviously true! The product can be either of the following two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Be rated 3 or above
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be rated below a 3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s check our math:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo><</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:math>](img/98.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mo>=</mo><mn>0.02</mn><mo>+</mo><mn>0.07</mn><mo>+</mo><mn>0.25</mn></mrow></mrow></math>](img/99.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mo>=</mo><mo>.</mo><mn>0341</mn><mo>−</mo><mi>P</mi><mo>(</mo><mi>X</mi><mo><</mo><mn>3</mn><mo>)</mo></mrow></mrow></mrow></math>](img/100.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>.</mml:mo><mml:mn>34</mml:mn></mml:math>](img/101.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mn>66</mml:mn></mml:math>](img/102.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mo>=</mo><mi>P</mi><mo>(</mo><mi>x</mi><mo>></mo><mo>=</mo><mn>3</mn><mo>)</mo></mrow></mrow></mrow></math>](img/103.png)'
  prefs: []
  type: TYPE_IMG
- en: It checks out!
  prefs: []
  type: TYPE_NORMAL
- en: Types of discrete random variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can get a better idea of how random variables work in practice by looking
    at specific types of random variables. These specific types of random variables
    model different types of situations and end up revealing much simpler calculations
    for very complex event modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Binomial random variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The first type of discrete random variable we will look at is called a **binomial
    random variable**. With a binomial random variable, we look at a setting in which
    a single event happens over and over, and we try to count the number of times
    the result is positive.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can understand the random variable itself, we must look at the conditions
    in which it is even appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: 'A binomial setting has the following four conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: The possible outcomes are either success or failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The outcomes of trials cannot affect the outcome of another trial
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of trials was set (a fixed sample size)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chance of success of each trial must always be *p*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A binomial random variable is a discrete random variable, *X*, that counts the
    number of successes in a binomial setting. The parameters are *n = the number
    of trials* and *p = the chance of success of* *each trial*.
  prefs: []
  type: TYPE_NORMAL
- en: Example – fundraising meetings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this example, a start-up is taking 20 **Venture Capital** (**VC**) meetings
    to fund and count the number of offers they receive.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **probability mass function** (**PMF**) for a binomial random variable
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mi>k</mi><mo>)</mo><mo>=</mo><mfenced
    open="(" close=")"><mfrac><mi>n</mi><mi>k</mi></mfrac></mfenced><msup><mi>p</mi><mi>k</mi></msup><msup><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfenced><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup></mrow></mrow></mrow></math>](img/104.png)'
  prefs: []
  type: TYPE_IMG
- en: Here,
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfenced
    open="(" close=")"><mfrac><mi>n</mi><mi>k</mi></mfrac></mfenced><mo>=</mo><mi
    mathvariant="normal">t</mi><mi mathvariant="normal">h</mi><mi mathvariant="normal">e</mi><mi
    mathvariant="normal">b</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi
    mathvariant="normal">o</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi
    mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">c</mi><mi
    mathvariant="normal">o</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi><mi
    mathvariant="normal">f</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">c</mi><mi
    mathvariant="normal">i</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi
    mathvariant="normal">t</mi><mo>=</mo><mi mathvariant="normal">n</mi><mo>!</mo><mfrac><mrow><mi
    mathvariant="normal">n</mi><mo>!</mo></mrow><mrow><mo>(</mo><mi mathvariant="normal">n</mi><mo>−</mo><mi
    mathvariant="normal">k</mi><mo>)</mo><mo>!</mo><mi mathvariant="normal">k</mi><mo>!</mo></mrow></mfrac></mrow></mrow></math>](img/105.png)'
  prefs: []
  type: TYPE_IMG
- en: Example – restaurant openings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this example, a new restaurant in a town has a 20% chance of surviving its
    first year. If 14 restaurants open this year, find the probability that exactly
    four restaurants survive their first year of being open to the public.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we should prove that this is a binomial setting:'
  prefs: []
  type: TYPE_NORMAL
- en: The possible outcomes are either success or failure (the restaurants either
    survive or not)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The outcomes of trials cannot affect the outcome of another trial (assume that
    the opening of one restaurant doesn’t affect another restaurant’s opening and
    survival)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of trials was set (14 restaurants opened)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chance of success of each trial must always be *p* (we assume that it is
    always 20%)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here, we have our two parameters of n = 14 and p = 0.2\. So, we can now plug
    these numbers into our binomial formula, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi mathvariant="normal">P</mml:mi><mml:mo>(</mml:mo><mml:mi
    mathvariant="normal">X</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mfrac linethickness="0pt"><mml:mrow><mml:mn>14</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>.</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo><mml:msup><mml:mrow><mml:mn>8</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mn>17</mml:mn></mml:math>](img/106.png)'
  prefs: []
  type: TYPE_IMG
- en: So, we have a 17% chance that exactly four of these restaurants will be open
    after a year.
  prefs: []
  type: TYPE_NORMAL
- en: Example – blood types
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this example, a couple has a 25% chance of having a child with type O blood.
    What is the chance that three of their five kids have type O blood?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let X = the number of children with type O blood with n = 5 and p = 0.25, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi
    mathvariant="normal">P</mi><mo>(</mo><mi mathvariant="normal">X</mi><mo>=</mo><mn>3</mn><mo>)</mo><mo>=</mo><mn>10</mn><mo>(</mo><mn>0.25</mn><msup><mo>)</mo><mn>3</mn></msup><mo>(</mo><mn>0.75</mn><msup><mo>)</mo><mrow><mn>5</mn><mo>−</mo><mn>3</mn></mrow></msup><mo>=</mo><mn>10</mn><mo>(</mo><mo>.</mo><mn>25</mn><msup><mo>)</mo><mn>3</mn></msup><mo>(</mo><mn>0.75</mn><msup><mo>)</mo><mn>2</mn></msup><mo>=</mo><mn>0.087</mn></mrow></mrow></mrow></math>](img/107.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can calculate this probability for the values of 0, 1, 2, 3, 4, and 5 to
    get a sense of the probability distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – The probability for the values of 0, 1, 2, 3, 4, and 5](img/B19488_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – The probability for the values of 0, 1, 2, 3, 4, and 5
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, we can calculate an expected value and the variance of this variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>E</mi><mi>x</mi><mi>p</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>V</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo>=</mo><mi>E</mi><mo>[</mo><mi>X</mi><mo>]</mo><mo>=</mo><msub><mi>μ</mi><mi
    mathvariant="script">x</mi></msub><mo>=</mo><mo>∑</mo><msub><mi mathvariant="script">x</mi><mi>i</mi></msub><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mn>1.25</mn></mrow></mrow></mrow></math>](img/108.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mi>i</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi><mo>=</mo><mi>V</mi><mo>[</mo><mi>X</mi><mo>]</mo><mo>=</mo><msubsup><mi>σ</mi><mi>x</mi><mn>2</mn></msubsup><mo>=</mo><mo>∑</mo><msub><mrow><mo>(</mo><mi
    mathvariant="script">x</mi></mrow><mi>i</mi></msub><mo>−</mo><msub><mi>μ</mi><mi
    mathvariant="script">x</mi></msub><msup><mo>)</mo><mn>2</mn></msup><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mn>0.9375</mn></mrow></mrow></mrow></math>](img/109.png)'
  prefs: []
  type: TYPE_IMG
- en: So, this family can expect to have probably one or two kids with type O blood!
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we want to know the probability that at least three of their kids have
    type O blood? To know the probability that at least three of their kids have type
    O blood, we can use the following formula for discrete random variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>></mo><mo>=</mo><mn>3</mn><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mn>3</mn><mo>)</mo><mo>+</mo><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mn>4</mn><mo>)</mo><mo>+</mo><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mn>3</mn><mo>)</mo><mo>=</mo><mo>.</mo><mn>00098</mn><mo>+</mo><mo>.</mo><mn>01465</mn><mo>+</mo><mo>.</mo><mn>08789</mn><mo>=</mo><mn>0.103</mn></mrow></mrow></mrow></math>](img/110.png)'
  prefs: []
  type: TYPE_IMG
- en: So, there is about a 10% chance that three of their kids have type O blood.
  prefs: []
  type: TYPE_NORMAL
- en: Shortcuts to binomial expected values and variance
  prefs: []
  type: TYPE_NORMAL
- en: 'Binomial random variables have special calculations for the exact values of
    the expected values and variance. If *X* is a binomial random variable, then we
    get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>E</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mi>n</mi><mi>p</mi></mrow></mrow></mrow></math>](img/111.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>V</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mi>n</mi><mi>p</mi><mo>(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo>)</mo></mrow></mrow></mrow></math>](img/112.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For our preceding example, we can use the following formulas to calculate an
    exact expected value and variance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>E</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mo>.</mo><mn>25</mn><mo>(</mo><mn>5</mn><mo>)</mo><mo>=</mo><mn>1.25</mn></mrow></mrow></mrow></math>](img/113.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>V</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mn>1.25</mn><mo>(</mo><mo>.</mo><mn>75</mn><mo>)</mo><mo>=</mo><mn>0.9375</mn></mrow></mrow></mrow></math>](img/114.png)'
  prefs: []
  type: TYPE_IMG
- en: A binomial random variable is a discrete random variable that counts the number
    of successes in a binomial setting. It is used in a wide variety of data-driven
    experiments, such as counting the number of people who will sign up for a website
    given a chance of conversion, or even, at a simple level, predicting stock price
    movements given a chance of decline (don’t worry – we will apply much more sophisticated
    models to predict the stock market later).
  prefs: []
  type: TYPE_NORMAL
- en: Geometric random variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The second discrete random variable we will take a look at is called a **geometric
    random variable**. It is actually quite similar to the binomial random variable
    in the way that we are concerned with a setting, in which a single event occurs
    over and over. However, in the case of a geometric setting, the major difference
    is that we are not fixing the sample size.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are not going into exactly 20 VC meetings as a start-up, nor are we having
    exactly five kids. Instead, in a geometric setting, we are modeling the number
    of trials we will need to see before we obtain even a single success. Specifically,
    a geometric setting has the following four conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: The possible outcomes are either a success or failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The outcomes of trials cannot affect the outcome of another trial
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of trials was not set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chance of success of each trial must always be *p*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that these are the exact same conditions as a binomial variable, except
    for the third condition.
  prefs: []
  type: TYPE_NORMAL
- en: A **geometric random variable** is a discrete random variable, X, that counts
    the number of trials needed to obtain one success. The parameters are *p = the
    chance of success of each trial and (1 − p) = the chance of failure of* *each
    trial*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To transform the previous binomial examples into geometric examples, we might
    do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Count the number of VC meetings that a start-up must take in order to get their
    first *yes*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Count the number of coin flips needed in order to get a head (yes, I know it’s
    boring, but it’s a solid example!)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The formula for the PMF is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>)</mo><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>p</mi><msup><mo>)</mo><mrow><mo>[</mo><mi>x</mi><mo>−</mo><mn>1</mn><mo>]</mo></mrow></msup></mrow></mrow></mrow></math>](img/115.png)'
  prefs: []
  type: TYPE_IMG
- en: Both the binomial and geometric settings involve outcomes that are either successes
    or failures. The big difference is that binomial random variables have a fixed
    number of trials, denoted as *n*. Geometric random variables do not have a fixed
    number of trials. Instead, geometric random variables model the number of samples
    needed in order to obtain the first successful trial, whatever success might mean
    in those experimental conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Example – weather
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this example, there is a 34% chance that it will rain on any day in April.
    Find the probability that the first day of rain in April will occur on April 4.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let X = the number of days until it rains (success) with p = 0.34 and (1 −
    p) = 0.66\. So then, the probability that it will rain by April 4 is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo><</mo><mo>=</mo><mn>4</mn><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mn>1</mn><mo>)</mo><mo>+</mo><mi>P</mi><mo>(</mo><mn>2</mn><mo>)</mo><mo>+</mo><mi>P</mi><mo>(</mo><mn>3</mn><mo>)</mo><mo>+</mo><mi>P</mi><mo>(</mo><mn>4</mn><mo>)</mo><mo>=</mo><mo>.</mo><mn>34</mn><mo>+</mo><mo>.</mo><mn>22</mn><mo>+</mo><mo>.</mo><mn>14</mn><mo>+</mo><mo>></mo><mn>1</mn><mo>=</mo><mo>.</mo><mn>8</mn></mrow></mrow></mrow></math>](img/116.png)'
  prefs: []
  type: TYPE_IMG
- en: So, there is an 80% chance that the first rain of the month will happen within
    the first four days.
  prefs: []
  type: TYPE_NORMAL
- en: Shortcuts to geometric expected values and variance
  prefs: []
  type: TYPE_NORMAL
- en: 'Geometric random variables also have special calculations for the exact values
    of the expected values and variance. If *X* is a geometric random variable, then
    we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>E</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mi>p</mi></mrow></mrow></mrow></math>](img/117.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi
    mathvariant="normal">V</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>p</mi><msup><mrow><mo>)</mo><mo>/</mo><mi
    mathvariant="normal">p</mi></mrow><mn>2</mn></msup></mrow></mrow></mrow></math>](img/118.png)'
  prefs: []
  type: TYPE_IMG
- en: Poisson random variable
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The third and last specific example of a discrete random variable is a Poisson
    random variable.
  prefs: []
  type: TYPE_NORMAL
- en: To understand why we would need this random variable, imagine that an event
    that we wish to model has a small probability of happening and that we wish to
    count the number of times that the event occurs in a certain time frame. If we
    have an idea of the average number of occurrences, µ, over a specific period of
    time, given from past instances, then the Poisson random variable, denoted by
    *X = Poi(µ)*, counts the total number of occurrences of the event during that
    given time period.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the Poisson distribution is a discrete probability distribution
    that counts the number of events that occur in a given interval of time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following examples of Poisson random variables:'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the probability of having a certain number of visitors on your site
    within an hour, knowing the past performance of the site
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating the number of car crashes at an intersection, based on past police
    reports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we let *X = the number of events in a given interval*, and the average number
    of events per interval is the *λ* number, then the probability of observing *X*
    events in a given interval is given by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mrow><mo>−</mo><mi>λ</mi></mrow></msup><msup><mi>λ</mi><mi>x</mi></msup></mrow><mrow><mi>x</mi><mo>!</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/119.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, e = Euler’s constant (2.718....).
  prefs: []
  type: TYPE_NORMAL
- en: Example – a call center
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The number of calls arriving at your call center follows a Poisson distribution
    at the rate of five calls per hour. What is the probability that exactly six calls
    will come in between 10 and 11 p.m.?
  prefs: []
  type: TYPE_NORMAL
- en: To set up this example, let’s write out our given information. Let *X* be the
    number of calls that arrive between 10 and 11 p.m. This is our Poisson random
    variable, with the mean *λ = 5*. The mean is *5* because we are using *5* as the
    expected value of the number of calls to come in at this time. This number could
    have come from the previous work on estimating the number of calls that come in
    every hour, or that specifically come in after 10 p.m. The main point is that
    we do have some idea of how many calls should be coming in, and then we use that
    information to create our *Poisson random variable*, using it to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with our example, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mn>6</mn><mo>)</mo><mo>=</mo><mn>0.146</mn></mrow></mrow></mrow></math>](img/120.png)'
  prefs: []
  type: TYPE_IMG
- en: This means that there is about a 14.6% chance that exactly six calls will come
    in between 10 and 11 p.m.
  prefs: []
  type: TYPE_NORMAL
- en: Shortcuts to Poisson expected values and variance
  prefs: []
  type: TYPE_NORMAL
- en: 'Poisson random variables also have special calculations for the exact values
    of the expected values and variance. If *X* is a Poisson random variable with
    the mean, then we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>E</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mi>λ</mi></mrow></mrow></mrow></math>](img/121.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>V</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mi>λ</mi></mrow></mrow></mrow></math>](img/122.png)'
  prefs: []
  type: TYPE_IMG
- en: This is actually interesting because both the expected value and the variance
    are the same number, and that number is simply the given parameter! Now that we’ve
    seen three examples of discrete random variables, we must take a look at the other
    type of random variable, called the continuous random variable.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous random variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Switching gears entirely, unlike a discrete random variable, a continuous random
    variable can take on an *infinite* number of possible values, not just a few countable
    ones. We call the functions that describe the distribution density curves instead
    of probability mass functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following examples of continuous variables:'
  prefs: []
  type: TYPE_NORMAL
- en: The length of a sales representative’s phone call (not the number of calls)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The actual amount of oil in a drum marked 20 gallons (not the number of oil
    drums)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If *X* is a continuous random variable, then there is a function, *f(x)*, for
    any constants, *a* and *b*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>P</mi><mo>(</mo><mi>a</mi><mo>≤</mo><mi>X</mi><mo>≤</mo><mi>b</mi><mo>)</mo><mo>=</mo><mrow><munderover><mo>∫</mo><mi>a</mi><mi>b</mi></munderover><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mi>d</mi><mi>x</mi></mrow></mrow></mrow></mrow></mrow></math>](img/123.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding f(x) function is known as the **probability density function**
    (**PDF**). The PDF is the continuous random variable version of the PMF for discrete
    random variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most important continuous distribution is the **standard normal distribution**.
    You have, no doubt, either heard of the normal distribution or dealt with it.
    The idea behind it is quite simple. The PDF of this distribution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mi>π</mi><msup><mi>σ</mi><mn>2</mn></msup></mrow></msqrt></mfrac><msup><mi>e</mi><mrow><mo>−</mo><mstyle
    scriptlevel="+1"><mfrac><mrow><mo>(</mo><mi>x</mi><mo>−</mo><mi>μ</mi><msup><mo>)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac></mstyle></mrow></msup></mrow></mrow></mrow></math>](img/124.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, μ is the mean of the variable, and σ is the standard deviation. This
    might look confusing, but let’s graph it in Python, with a mean of 0 and a standard
    deviation of 1, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We get this graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Representing a mean of 0 and a standard deviation of 1](img/B19488_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – Representing a mean of 0 and a standard deviation of 1
  prefs: []
  type: TYPE_NORMAL
- en: 'This reveals the all-too-familiar bell curve. Note that the graph is symmetrical
    around the x = 0 line. Let’s try changing some of the parameters. First, let’s
    try with ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi></mrow></math>](img/93.png)
    = 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Representing the all-too-familiar bell curve](img/B19488_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Representing the all-too-familiar bell curve
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s try with the value ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math>](img/126.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Representing the value ​<?AID d835?><?AID df48?> = 5​](img/B19488_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Representing the value ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math>](img/127.png)
  prefs: []
  type: TYPE_NORMAL
- en: "Lastly, we will try with the values ![<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"\
    \ xmlns:m=\"http://schemas.openxmlformats.org/officeDocument/2006/math\"><mml:mi>μ</mml:mi></mml:math>](img/93.png)\
    \ = 5 ![<math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow><mrow><mo>,</mo><mi\
    \ mathvariant=\"normal\">\uFEFF</mi><mi>σ</mi><mo>=</mo><mn>5</mn></mrow></mrow></math>](img/129.png):"
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 6.9 – A graph representing the values ​<?AID d835?><?AID df41?>​ =\
    \ 5 ​, \uFEFF<?AID d835?><?AID df48?> = 5​](img/B19488_06_10.jpg)"
  prefs: []
  type: TYPE_IMG
- en: "Figure 6.9 – A graph representing the values ![<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"\
    \ xmlns:m=\"http://schemas.openxmlformats.org/officeDocument/2006/math\"><mml:mi\
    \ mathvariant=\"bold-italic\">μ</mml:mi></mml:math>](img/130.png) = 5 ![<math\
    \ xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow><mrow><mo>,</mo><mi mathvariant=\"\
    normal\">\uFEFF</mi><mi mathvariant=\"bold-italic\">σ</mi><mo>=</mo><mn>5</mn></mrow></mrow></math>](img/131.png)"
  prefs: []
  type: TYPE_NORMAL
- en: In all the graphs, we have the standard bell shape that we are all familiar
    with, but as we change our parameters, we can see that the bell might get skinnier,
    thicker, or move from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, which focus on statistics, we will make much more
    use of the normal distribution as it applies to statistical thinking.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probability as a field works to explain our random and chaotic world. Using
    the basic laws of probability, we can model real-life events that involve randomness.
    We can use random variables to represent values that may take on several values,
    and we can use the probability mass or density functions to compare product lines
    or look at the test results.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen some of the more complicated uses of probability in prediction.
    Using random variables and Bayes’ theorem are excellent ways to assign probabilities
    to real-life situations.
  prefs: []
  type: TYPE_NORMAL
- en: The next two chapters focus on statistical thinking. Like probability, these
    chapters will use mathematical formulas to model real-world events. The main difference,
    however, will be the terminology we use to describe the world and the way we model
    different types of events. In these upcoming chapters, we will attempt to model
    entire populations of data points based solely on a sample.
  prefs: []
  type: TYPE_NORMAL
- en: We will revisit many concepts in probability to make sense of statistical theorems,
    as they are closely linked, and both are important mathematical concepts in the
    realm of data science.
  prefs: []
  type: TYPE_NORMAL
