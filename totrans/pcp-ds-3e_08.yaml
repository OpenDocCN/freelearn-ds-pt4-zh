- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advanced Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are concerned with making inferences about entire populations
    based on certain samples of data. We will be using hypothesis tests along with
    different estimation tests in order to gain a better understanding of populations,
    given samples of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key topics that we will cover in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Point estimates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confidence intervals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The central limit theorem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hypothesis testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding point estimates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recall that, in the previous chapter, we mentioned how difficult it is to obtain
    a population parameter; so, we had to use sample data to calculate a statistic
    that was an estimate of a parameter. When we make these estimates, we call them
    **point estimates**.
  prefs: []
  type: TYPE_NORMAL
- en: A point estimate is an estimate of a population parameter based on sample data.
  prefs: []
  type: TYPE_NORMAL
- en: We use point estimates to estimate things such as population means, variances,
    and other statistics. To obtain these estimates, we simply apply the function
    that we wish to measure for our population to a sample of the data. For example,
    suppose there is a company of 9,000 employees and we are interested in ascertaining
    the average length of breaks taken by employees in a single day. As we probably
    cannot ask every single person, we will take a sample of the 9,000 people and
    take a mean of the sample. This sample mean will be our point estimate. We will
    use the probability distribution, known as the Poisson distribution, to randomly
    generate 9,000 answers to the question *For how many minutes in a day do you usually
    take breaks?* This will represent our *population*. Remember, from [*Chapter 6*](B19488_06.xhtml#_idTextAnchor170),
    *Advanced Probability*, that the Poisson random variable is used when we know
    the average value of an event and wish to model a distribution around it.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: I set a random seed in order to encourage reproducibility (this allows us to
    get the same random numbers each time).
  prefs: []
  type: TYPE_NORMAL
- en: We will take a sample of 100 employees (using the Python random sample method)
    and find a point estimate of a mean (called a **sample mean**).
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is just over 1% of our population.
  prefs: []
  type: TYPE_NORMAL
- en: Compare our sample mean (the mean of the sample of 100 employees) to our population
    mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `long_breaks` variable represents 3,000 answers to the question, *How many
    minutes on average do you take breaks for?*, and these answers will be on the
    longer side. Let’s see a visualization of this distribution, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.1 – The histogram of our longer break times with a known average
    of 60 minutes](img/B19488_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – The histogram of our longer break times with a known average of
    60 minutes
  prefs: []
  type: TYPE_NORMAL
- en: We can see that our average of 60 minutes is to the left of the distribution.
    Also, because we only sampled 3,000 people, our bars are at their highest at around
    700–800 people.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s model 6,000 people who take, on average, about 15 minutes’ worth
    of breaks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s again use the Poisson distribution to simulate 6,000 people, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.2 – The histogram of our shorter break times with a known average
    of 15 minutes](img/B19488_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – The histogram of our shorter break times with a known average of
    15 minutes
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, so we have a distribution for the people who take longer breaks and a
    distribution for the people who take shorter breaks. Again, note how our average
    break length of 15 minutes falls to the left-hand side of the distribution, and
    note that the tallest bar is for about 1,600 people:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `breaks` variable is the amalgamation of all the 9,000 employees, both
    long and short break-takers. Let’s see the entire distribution of people in a
    single visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.3 – The histogram of our two types of break-takers](img/B19488_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – The histogram of our two types of break-takers
  prefs: []
  type: TYPE_NORMAL
- en: We can see we have two humps. On the left, we have our larger hump of people
    who take about a 15-minute break, and on the right, we have a smaller hump of
    people who take longer breaks. Later on, we will investigate this graph further.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can find the total average break length by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Our average company break length is about 40 minutes. Remember that our population
    is the entire company’s employee size of 9,000 people, and our parameter is 40
    minutes. In the real world, our goal would be to estimate the population parameter
    because we would not have the resources to ask every single employee in a survey
    their average break length for many reasons. Instead, we will use a point estimate.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to make our point, we want to simulate a world where we ask 100 random
    people about the length of their breaks. To do this, let’s take a random sample
    of 100 employees out of the 9,000 employees we simulated, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s take the mean of the sample and subtract it from the population
    mean and see how far off we were:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This is extremely interesting because, with only about 1% of our population
    (100 out of 9,000), we were able to get within 1 minute of our population parameter
    and get a very accurate estimate of our population mean. Not bad!
  prefs: []
  type: TYPE_NORMAL
- en: We calculated a point estimate for the mean, but we can also do this for proportion
    parameters. By proportion, I am referring to a ratio of two quantitative values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s suppose that in a company of 10,000 people, our employees are 20% white,
    10% black, 10% Hispanic, 30% Asian, and 30% identify as other. We will take a
    sample of 1,000 employees and see whether their race proportions are similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`employee_races` represents our employee population. For example, in our company
    of 10,000 people, 2,000 people are white (20%) and 3,000 people are Asian (30%).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a random sample of 1,000 people, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output obtained would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the race proportion estimates are very close to the underlying
    population’s proportions. For example, we got 10.3% for `hispanic` in our sample
    and the population proportion for `hispanic` was 10%.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [*Chapter 7*](B19488_07.xhtml#_idTextAnchor192), *What Are the Chances?
    An Introduction to Statistics*, we mentioned how much we love it when data follows
    the normal distribution. One of the reasons for this is that many statistical
    tests (including the ones we will use in this chapter) rely on data that follows
    a normal pattern, and for the most part, a lot of real-world data is not normal
    (surprised?). Take our employee break data, for example—you might think I was
    just being fancy creating data using the Poisson distribution, but I had a reason
    for this. I specifically wanted non-normal data, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.4 – The histogram of our break-takers with a larger number of bins,
    showing more granularity](img/B19488_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – The histogram of our break-takers with a larger number of bins,
    showing more granularity
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, our data is definitely not following a normal distribution;
    it appears to be bimodal, which means that there are two peaks of break times,
    at around 25 and 70 minutes. As our data is not normal, many of the most popular
    statistics tests may not apply; however, if we follow the given procedure, we
    can create normal data! Think I’m crazy? Well, see for yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 'First off, we will need to utilize what is known as a sampling distribution,
    which is a distribution of point estimates of several samples of the same size.
    Our procedure for creating a sampling distribution will be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Take 500 different samples of the break times of the size of 100 each.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a histogram of these 500 different point estimates (revealing their distribution).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The number of elements in the sample (100) was arbitrary but large enough to
    be a representative sample of the population. The number of samples I took (500)
    was also arbitrary, but large enough to ensure that our data would converge to
    a normal distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.5 – The distribution of sample means becomes much more normally
    distributed, a blessing of the central limit theorem](img/B19488_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – The distribution of sample means becomes much more normally distributed,
    a blessing of the central limit theorem
  prefs: []
  type: TYPE_NORMAL
- en: Behold! The sampling distribution of the sample mean appears to be normal even
    though we took data from an underlying bimodal population distribution. It is
    important to note that the bars in this histogram represent the average break
    length of 500 samples of employees, where each sample has 100 people in it. In
    other words, a sampling distribution is a distribution of several point estimates.
  prefs: []
  type: TYPE_NORMAL
- en: Our data converged to a normal distribution because of something called the
    central limit theorem, which states that the sampling distribution (the distribution
    of point estimates) will approach a normal distribution as we increase the number
    of samples taken.
  prefs: []
  type: TYPE_NORMAL
- en: 'What’s more, as we take more and more samples, the mean of the sampling distribution
    will approach the true population mean, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This is actually a very exciting result because it means that we can get even
    closer than a single point estimate by taking multiple point estimates and utilizing
    the central limit theorem!
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In general, as we increase the number of samples taken, our estimate will get
    closer to the parameter (actual value).
  prefs: []
  type: TYPE_NORMAL
- en: Confidence intervals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While point estimates are okay, estimates of a population parameter and sampling
    distributions are even better. There are the following two main issues with these
    approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Single point estimates are very prone to error (due to sampling bias among other
    things)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking multiple samples of a certain size for sampling distributions might not
    be feasible, and may sometimes be even more infeasible than actually finding the
    population parameter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For these reasons and more, we may turn to a concept known as the **confidence
    interval** to find statistics.
  prefs: []
  type: TYPE_NORMAL
- en: A confidence interval is a range of values based on a point estimate that contains
    the true population parameter at some confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: Confidence is an important concept in advanced statistics. Its meaning is sometimes
    misconstrued. Informally, a confidence level does not represent a *probability
    of being correct*; instead, it represents the frequency at which the obtained
    answer will be accurate. For example, if you want to have a 95% chance of capturing
    the true population parameter using only a single point estimate, you have to
    set your confidence level to 95%.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Higher confidence levels result in wider (larger) confidence intervals in order
    to be more sure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating a confidence interval involves finding a point estimate and then
    incorporating a margin of error to create a range. The margin of error is a value
    that represents our certainty that our point estimate is accurate and is based
    on our desired confidence level, the variance of the data, and how big our sample
    is. There are many ways to calculate confidence intervals; for the purpose of
    brevity and simplicity, we will look at a single way of taking the confidence
    interval of a population mean. For this confidence interval, we need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A point estimate. For this, we will take our sample mean of break lengths from
    our previous example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An estimate of the population standard deviation, which represents the variance
    in the data. This is calculated by taking the sample standard deviation (the standard
    deviation of the sample data) and dividing that number by the square root of the
    population size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The degrees of freedom (which is the sample size - 1).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Obtaining these numbers might seem arbitrary but, trust me, there is a reason
    for all of them. However, again for simplicity, I will use prebuilt Python modules,
    as shown, to calculate our confidence interval and then demonstrate its value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: To reiterate, this range of values (from `24.28` to `33.14`) represents a confidence
    interval for the average break time with 95% confidence.
  prefs: []
  type: TYPE_NORMAL
- en: We already know that our population parameter is `29.99`, and note that the
    interval includes the population mean of `29.99`.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier that the confidence level is not a percentage of the accuracy
    of our interval but the percent chance that the interval will even contain the
    population parameter at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand the confidence level, let’s take 10,000 confidence intervals
    and see how often our population mean falls in the interval. First, let’s make
    a function, as illustrated, that makes a single confidence interval from our breaks
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a function that will create a single confidence interval,
    let’s create a procedure that will test the probability that a single confidence
    interval will contain the true population parameter, `29.99`:'
  prefs: []
  type: TYPE_NORMAL
- en: Take **10,000** confidence intervals of the sample mean.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Count the number of times that the population parameter falls into our confidence
    intervals.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Output the ratio of the number of times the parameter fell into the interval
    by 10,000:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Success! We see that about 95% of our confidence intervals contained our actual
    population mean. Estimating population parameters through point estimates and
    confidence intervals is a relatively simple and powerful form of statistical inference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s also take a quick look at how the size of confidence intervals changes
    as we change our confidence level. Let’s calculate confidence intervals for multiple
    confidence levels and look at how large the intervals are by looking at the difference
    between the two numbers. Our hypothesis will be that as we make our confidence
    level larger, we will likely see larger confidence intervals to be sure that we
    catch the true population parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We can see that as we wish to be *more confident* in our interval, our interval
    expands in order to compensate.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will take our concept of confidence levels and look at statistical
    hypothesis testing in order to both expand on these topics and create (usually)
    even more powerful statistical inferences.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Hypothesis tests** are one of the most widely used tests in statistics. They
    come in many forms; however, all of them have the same basic purpose.'
  prefs: []
  type: TYPE_NORMAL
- en: A hypothesis test is a statistical test that is used to ascertain whether we
    are allowed to assume that a certain condition is true for the entire population,
    given a data sample. Basically, a hypothesis test is a test for a certain hypothesis
    that we have about an entire population. The result of the test then tells us
    whether we should believe the hypothesis or reject it for an alternative one.
  prefs: []
  type: TYPE_NORMAL
- en: You can think of the hypothesis test’s framework to determine whether the observed
    sample data deviates from what was to be expected from the population itself.
    Now, this sounds like a difficult task but, luckily, Python comes to the rescue
    and includes built-in libraries to conduct these tests easily.
  prefs: []
  type: TYPE_NORMAL
- en: A hypothesis test generally looks at two opposing hypotheses about a population.
    We call them the **null hypothesis** and the **alternative hypothesis**. The null
    hypothesis is the statement being tested and is the default correct answer; it
    is our starting point and our original hypothesis. The alternative hypothesis
    is the statement that opposes the null hypothesis. Our test will tell us which
    hypothesis we should trust and which we should reject.
  prefs: []
  type: TYPE_NORMAL
- en: Based on sample data from a population, a hypothesis test determines whether
    or not to reject the null hypothesis. We usually use a *p* value (which is based
    on our significance level) to make this conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A very common misconception is that statistical hypothesis tests are designed
    to select the more likely of the two hypotheses. This is incorrect. A hypothesis
    test will default to the null hypothesis until there is enough data to support
    the alternative hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some examples of questions you can answer with a hypothesis
    test:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the mean break time of employees differ from 40 minutes?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a difference between people who interacted with website A and people
    who interacted with website B (A/B testing)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does a sample of coffee beans vary significantly in taste from the entire population
    of beans?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting a hypothesis test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are multiple types of hypothesis tests out there, and among them are
    dozens of different procedures and metrics. Nonetheless, there are five basic
    steps that most hypothesis tests follow, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Specify the hypotheses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here, we formulate our two hypotheses: the null and the alternative.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We usually use the notation of ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/140.png)to
    represent the null hypothesis and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math>](img/141.png)
    to represent our alternative hypothesis.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Determine the sample size for the test sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This calculation depends on the chosen test. Usually, we have to determine a
    proper sample size in order to utilize theorems, such as the central limit theorem,
    and assume the normality of data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choose a significance level (usually called alpha or *α*):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A significance level of 0.05 is common.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Collect the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Collect a sample of data to conduct the test.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Decide whether to reject or fail to reject the null hypothesis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This step changes slightly based on the type of test being used. The final result
    will either yield a rejection of the null hypothesis in favor of the alternative
    or fail to reject the null hypothesis.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at the following three types of hypothesis tests:'
  prefs: []
  type: TYPE_NORMAL
- en: One-sample t-tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chi-square goodness of fit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chi-square test for association/independence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many more tests. However, these three are a great combination of distinct,
    simple, and powerful tests. One of the biggest things to consider when choosing
    which test we should implement is the type of data we are working with—specifically,
    whether we are dealing with continuous or categorical data. In order to truly
    see the effects of a hypothesis, I suggest we dive right into an example. First,
    let’s look at the use of *t*-tests to deal with continuous data.
  prefs: []
  type: TYPE_NORMAL
- en: One-sample t-tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The one-sample *t*-test is a statistical test used to determine whether a quantitative
    (numerical) data sample differs significantly from another dataset (the population
    or another sample). Suppose, in our previous employee break time example, we look
    specifically at the engineering department’s break times, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that I took the same approach as making the original break times but with
    the following two differences:'
  prefs: []
  type: TYPE_NORMAL
- en: I took a smaller sample from the Poisson distribution (to simulate that we took
    a sample of 400 people from the engineering department)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of using **mu** of **60** as before, I used **55** to simulate the fact
    that the engineering department’s break behavior isn’t exactly the same as the
    company’s behavior as a whole
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easy to see that there seems to be a difference (of over 5 minutes) between
    the engineering department and the company as a whole. We usually don’t have the
    entire population and the population parameters at our disposal, but I have them
    simulated in order for the example to work. So, even though we (the omniscient
    readers) can see a difference, we will assume that we know nothing of these population
    parameters and, instead, rely on a statistical test in order to ascertain these
    differences.
  prefs: []
  type: TYPE_NORMAL
- en: Example of a one-sample t-test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our objective here is to ascertain whether there is a difference between the
    overall population’s (company employees) break times and the break times of employees
    in the engineering department.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now conduct a *t*-test at a 95% confidence level in order to find a difference
    (or not!). Technically speaking, this test will tell us whether the sample comes
    from the same distribution as the population.
  prefs: []
  type: TYPE_NORMAL
- en: Assumptions of the one-sample t-test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before diving into the five steps, we must first acknowledge that *t*-tests
    must satisfy the following two conditions to work properly:'
  prefs: []
  type: TYPE_NORMAL
- en: The population distribution should be normal, or the sample should be large
    (*n* ≥ 30)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to make the assumption that the sample is independently, randomly sampled,
    it is sufficient to enforce that the population size should be at least 10 times
    larger than the sample size (*10n* < *N*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that our test requires that either the underlying data be normal (which
    we know is not true for us), or that the sample size is at least 30 points large.
    For the *t*-test, this condition is sufficient to assume normality. This test
    also requires independence, which is satisfied by taking a sufficiently small
    sample. Sounds weird, right? The basic idea is that our sample must be large enough
    to assume normality (through conclusions similar to the central limit theorem)
    but small enough to be independent of the population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s follow our five steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Specify the hypotheses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will let ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/142.png)=
    the engineering department take breaks the same as the company as a whole.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If we let this be the company average, we may write the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/142.png):*(engineering
    takes breaks the same length as* *everyone else)*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note how this is our null, or default, hypothesis. It is what we would assume,
    given no data. What we would like to show is the alternative hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we actually have some options for our alternative, we could either
    say that the engineering mean (let’s call it that) is lower than the company average,
    higher than the company average, or just flat-out different (higher or lower)
    from the company average:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we wish to answer the question, *Is the sample mean different from the company
    average?*, then this is called a **two-tailed test** and our alternative hypothesis
    would be as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ha:(engineering takes breaks of different lengths than the rest of* *the company)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to find out whether the sample mean is lower than the company average
    or the sample mean is higher than the company average, then we are dealing with
    a **one-tailed test** and our alternative hypothesis would be one of the following
    hypotheses:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math>](img/144.png):*(engineering
    takes* *longer breaks)*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math>](img/144.png):*(engineering
    takes* *shorter breaks)*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The difference between one and two tails is the difference of dividing a number
    later on by two or not. The process remains completely unchanged for both. For
    this example, let’s choose the two-tailed test. So, we are testing for whether
    or not this sample of the engineering department’s average break times is different
    from the company average.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our test will end in one of two possible conclusions: we will either reject
    the null hypothesis, which means that the engineering department’s break times
    are different from the company average, or we will fail to reject the null hypothesis,
    which means that there wasn’t enough evidence in the sample to support rejecting
    the null.'
  prefs: []
  type: TYPE_NORMAL
- en: Determine the sample size for the test sample.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As mentioned earlier, most tests (including this one) make the assumption that
    either the underlying data is normal or that our sample is in the right range:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The sample is at least 30 points (it is 400)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sample is less than 10% of the population (which would be 900 people)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose a significance level (usually called alpha or *α*). We will choose a
    95% significance level, which means that our alpha would actually be *1 - .95
    = .**05*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Collect the data. This is generated through the two Poisson distributions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Decide whether to reject or fail to reject the null hypothesis. As mentioned
    before, this step varies based on the test used. For a one-sample *t*-test, we
    must calculate two numbers: the test statistic and our *p* value. Luckily, we
    can do this in one line in Python.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A test statistic is a value that is derived from sample data during a type of
    hypothesis test. They are used to determine whether or not to reject the null
    hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: The test statistic is used to compare the observed data with what is expected
    under the null hypothesis. The test statistic is used in conjunction with the
    *p* value.
  prefs: []
  type: TYPE_NORMAL
- en: The *p* value is the probability that the observed data occurred this way by
    chance.
  prefs: []
  type: TYPE_NORMAL
- en: When the data shows very strong evidence against the null hypothesis, the test
    statistic becomes large (either positive or negative) and the *p* value usually
    becomes very small, which means that our test is showing powerful results and
    what is happening is probably not happening by chance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of a *t*-test, a *t* value is our test statistic, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We input the `engineering_breaks` variable (which holds 400 break times) and
    the population mean (`popmean`), and we obtain the following numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The test result shows that the *t* value is `-5.742`. This is a standardized
    metric that reveals the deviation of the sample mean from the null hypothesis.
    The *p* value is what gives us our final answer. Our *p* value tells us how often
    our result would appear by chance. So, for example, if our *p* value was `.06`,
    then that would mean we should expect to observe this data by chance about 6%
    of the time. This means that about 6% of samples would yield results like this.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are interested in how our *p* value compares to our significance level:'
  prefs: []
  type: TYPE_NORMAL
- en: If the *p* value is less than the significance level, then we can reject the
    null hypothesis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the *p* value is greater than the significance level, then we failed to reject
    the null hypothesis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our *p* value is way lower than `.05` (our chosen significance level), which
    means that we may reject our null hypothesis in favor of the alternative. This
    means that the engineering department seems to take different break lengths from
    the company as a whole!
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The use of *p* values is controversial. Many journals have actually banned the
    use of *p* values in tests for significance. This is because of the nature of
    the value. Suppose our *p* value came out to **.04**. This means that 4% of the
    time, our data just randomly happened to appear this way and is not significant
    in any way. 4% is not that small of a percentage! For this reason, many people
    are switching to different statistical tests. However, that does not mean that
    *p* values are useless. It merely means that we must be careful and aware of what
    the number is telling us.
  prefs: []
  type: TYPE_NORMAL
- en: There are many other types of *t*-tests, including one-tailed tests (mentioned
    before) and paired tests as well as two-sample *t*-tests (both not mentioned yet).
    These procedures can be readily found in statistics literature; however, we should
    look at something very important—what happens when we get it wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Type I and Type II errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the realm of statistical hypothesis testing, two kinds of errors can occur:
    Type I and Type II errors. These errors are synonymous with the concepts of false
    positives and false negatives, respectively. Grasping these concepts is crucial
    as they underscore the potential limitations and risks associated with inferential
    statistics, where conclusions about a population are drawn from sample data.'
  prefs: []
  type: TYPE_NORMAL
- en: Type I errors explained
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Type I error is often referred to as a **false positive**. Imagine you have
    an app on your phone designed to identify bird songs from snippets of music it
    hears. If the app indicates it recognizes a bird from the ambient noise when there
    is no bird nearby, it has made a Type I error—it has alerted you to a “hit” when
    there was none. In statistical hypothesis testing, this error occurs when we reject
    a true null hypothesis. The null hypothesis usually represents a default position
    or a statement of no effect—for example, the assumption that a new drug has no
    effect on a disease.
  prefs: []
  type: TYPE_NORMAL
- en: When setting up a hypothesis test, we determine the significance level (denoted
    as *α*), which defines the threshold for how much evidence is required to reject
    the null hypothesis. Commonly, a 5% significance level is used, meaning there
    is a 5% chance of rejecting the null hypothesis when it is actually true. This
    5% is the risk we are willing to take of making a Type I error.
  prefs: []
  type: TYPE_NORMAL
- en: Type II errors explained
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Conversely, a Type II error is when we overlook something significant—a false
    negative. Consider a medical test designed to detect a disease. If the test results
    come back negative when the person has the disease, the test has made a Type II
    error. In the context of hypothesis testing, this error occurs when the null hypothesis
    is not rejected despite being false. For example, we might conclude that the new
    drug has no effect on a disease when, in fact, it does.
  prefs: []
  type: TYPE_NORMAL
- en: The likelihood of a Type II error is represented by *β*, and it is inversely
    related to the significance level *α*. As we lower the risk of committing a Type
    I error by choosing a smaller *α* (for example, setting a higher confidence level
    such as 99%), we inadvertently increase the risk of a Type II error. This is because
    requiring stronger evidence to reject the null hypothesis (i.e., a higher confidence
    level) can make it harder to detect an actual effect.
  prefs: []
  type: TYPE_NORMAL
- en: Balancing these errors is a critical part of designing experiments and interpreting
    statistical results. Researchers must decide on an acceptable balance between
    the risks of Type I and Type II errors, often based on the context of the research
    and the potential consequences of incorrect conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing for categorical variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*T*-tests (among other tests) are hypothesis tests that work to compare and
    contrast quantitative variables and underlying population distributions. In this
    section, we will explore two new tests, both of which serve to explore qualitative
    data. They are both a form of test called **chi-square tests**. These two tests
    will perform the following two tasks for us:'
  prefs: []
  type: TYPE_NORMAL
- en: Determine whether a sample of categorical variables is taken from a specific
    population (similar to the *t*-test)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine whether two variables affect each other and are associated with each
    other
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chi-square goodness of fit test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The one-sample *t*-test was used to check whether a sample mean differed from
    the population mean. The chi-square goodness of fit test is very similar to the
    one-sample *t*-test in that it tests whether the distribution of the sample data
    matches an expected distribution, while the big difference is that it tests for
    categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a chi-square goodness of fit test would be used to see whether
    the race demographics of your company match that of the entire city of the U.S.
    population. It can also be used to see whether users of your website show similar
    characteristics to average internet users.
  prefs: []
  type: TYPE_NORMAL
- en: As we are working with categorical data, we have to be careful because categories
    such as “male,” “female,” or “other” don’t have any mathematical meaning. Therefore,
    we must consider counts of the variables rather than the actual variables themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, we use the chi-square goodness of fit test in the following cases:'
  prefs: []
  type: TYPE_NORMAL
- en: We want to analyze one categorical variable from one population
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to determine whether a variable fits a specified or expected distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a chi-square test, we compare what is observed to what we expect.
  prefs: []
  type: TYPE_NORMAL
- en: Assumptions of the chi-square goodness of fit test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two usual assumptions of this test, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: All the expected counts are at least **5**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Individual observations are independent and the population should be at least
    10 times as large as the sample (*10n* < *N*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second assumption should look familiar to the *t*-test; however, the first
    assumption should look foreign. Expected counts are something we haven’t talked
    about yet but are about to!
  prefs: []
  type: TYPE_NORMAL
- en: 'When formulating our null and alternative hypotheses for this test, we consider
    a default distribution of categorical variables. For example, if we have a die
    and we are testing whether or not the outcomes are coming from a fair die, our
    hypothesis might look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/142.png):
    The specified distribution of the categorical variable is correct.'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>p</mi><mn>1</mn><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>,</mo><mi>p</mi><mn>2</mn><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>,</mo><mi>p</mi><mn>3</mn><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>,</mo><mi>p</mi><mn>4</mn><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>,</mo><mi>p</mi><mn>5</mn><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>,</mo><mi>p</mi><mn>6</mn><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac></mrow></mrow></math>](img/147.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Our alternative hypothesis is quite simple, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math>](img/148.png):
    The specified distribution of the categorical variable is not correct. At least
    one of the pi values is not correct.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *t*-test, we used our test statistic (the *t* value) to find our *p*
    value. In a chi-square test, our test statistic is, well, a chi-square:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Test Statistic: χ2 =* *over k categories*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Degrees of Freedom = k − 1*'
  prefs: []
  type: TYPE_NORMAL
- en: A critical value is when we use ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>](img/149.png)as
    well as our degrees of freedom and our significance level, and then reject the
    null hypothesis if the *p* value is below our significance level (the same as
    before).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at an example to understand this further.
  prefs: []
  type: TYPE_NORMAL
- en: Example of a chi-square test for goodness of fit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The CDC categorizes adult BMIs into four classes: `Under/Normal`, `Over`, `Obesity`,
    and `Extreme Obesity`. A 2009 survey showed the distribution for adults in the
    US to be 31.2%, 33.1%, 29.4%, and 6.3%, respectively. A total of 500 adults were
    randomly sampled and their BMI categories were recorded.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – The raw numbers of people who fall under each BMI category](img/B19488_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – The raw numbers of people who fall under each BMI category
  prefs: []
  type: TYPE_NORMAL
- en: 'Is there evidence to suggest that BMI trends have changed since 2009? Let’s
    test at the `0.05` significance level:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s calculate our expected values. In a sample of 500, we expect 156
    to be **Under/Normal** (that’s 31.2% of 500), and we fill in the remaining boxes
    in the same way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.7 – The same raw numbers as the previous figure with an added row
    representing the “Expected” values in each category given a 2009 survey](img/B19488_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – The same raw numbers as the previous figure with an added row representing
    the “Expected” values in each category given a 2009 survey
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s check that the conditions for our test are satisfied:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All of the expected counts are greater than five
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Each observation is independent and our population is very large (much more
    than 10 times of 500 people)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we will carry out a goodness of fit test. We will set our null and alternative
    hypotheses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/142.png):
    The 2009 BMI distribution is still accurate.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math>](img/151.png):
    The 2009 BMI distribution is no longer accurate (at least one of the proportions
    is different now). We can calculate our test statistic by hand:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Walking through the calculation for our test statistic. Keep
    reading for the Python code to do it for you!](img/B19488_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – Walking through the calculation for our test statistic. Keep reading
    for the Python code to do it for you!
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, we can use our handy-dandy Python skills, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Our *p* value is lower than .05; therefore, we may reject the null hypothesis
    in favor of the fact that the BMI trends today are different from what they were
    in 2009.
  prefs: []
  type: TYPE_NORMAL
- en: Chi-square test for association/independence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Independence as a concept in probability is when knowing the value of one variable
    tells you nothing about the value of another. For example, we might expect that
    the country and the month you were born in are independent. However, knowing which
    type of phone you use might indicate your creativity levels. Those variables might
    not be independent.
  prefs: []
  type: TYPE_NORMAL
- en: The chi-square test for association/independence helps us ascertain whether
    two categorical variables are independent of one another. The test for independence
    is commonly used to determine whether variables such as education levels or tax
    brackets vary based on demographic factors, such as gender, race, and religion.
    Let’s look back at an example posed in the preceding chapter, the A/B split test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that we ran a test and exposed half of our users to a certain landing
    page (**Website A**), exposed the other half to a different landing page (**Website
    B**), and then measured the sign-up rates for both sites. We obtained the following
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Did not** **sign up** | **Signed up** |'
  prefs: []
  type: TYPE_TB
- en: '| **Website A** | 134 | 54 |'
  prefs: []
  type: TYPE_TB
- en: '| **Website B** | 110 | 48 |'
  prefs: []
  type: TYPE_TB
- en: Figure 8.9 – Results of our A/B test
  prefs: []
  type: TYPE_NORMAL
- en: 'We calculated website conversions but what we really want to know is whether
    there is a difference between the two variables: *which website was the user exposed
    to? And did the user sign up?* For this, we will use our chi-square test.'
  prefs: []
  type: TYPE_NORMAL
- en: Assumptions of the chi-square independence test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are the following two assumptions of this test:'
  prefs: []
  type: TYPE_NORMAL
- en: All expected counts are at least **5**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Individual observations are independent and the population should be at least
    10 times as large as the sample (*10n* < *N*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that they are exactly the same as the last chi-square test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s set up our hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/142.png):
    There is no association between two categorical variables in the population of
    interest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/142.png):
    Two categorical variables are independent in the population of interest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math>](img/144.png):
    There is an association between two categorical variables in the population of
    interest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math>](img/144.png):
    Two categorical variables are not independent in the population of interest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You might notice that we are missing something important here. Where are the
    expected counts? Earlier, we had a prior distribution to compare our observed
    results to but now we do not. For this reason, we will have to create some. We
    can use the following formula to calculate the expected values for each value.
    In each cell of the table, we can use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Expected Count = to calculate our chi-square test statistic and our degrees*
    *of freedom*'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Test</mtext><mtext>Statistic:</mtext><msup><mi>χ</mi><mn>2</mn></msup><mo>=</mo><mo>∑</mo><mfrac><msup><mfenced
    open="(" close=")"><mrow><msub><mtext>Observed</mtext><mrow><mi>r</mi><mo>,</mo><mi>c</mi></mrow></msub><mo>−</mo><msub><mtext>Expected</mtext><mrow><mi>r</mi><mo>,</mo><mi>c</mi></mrow></msub></mrow></mfenced><mn>2</mn></msup><msub><mtext>Expected</mtext><mrow><mi>r</mi><mo>,</mo><mi>c</mi></mrow></msub></mfrac></mrow></mrow></math>](img/156.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Degrees</mtext><mtext>of</mtext><mtext>Freedom:</mtext><mfenced
    open="(" close=")"><mrow><mi>r</mi><mo>−</mo><mn>1</mn></mrow></mfenced><mo>⋅</mo><mfenced
    open="(" close=")"><mrow><mi>c</mi><mo>−</mo><mn>1</mn></mrow></mfenced></mrow></mrow></math>](img/157.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *r* is the number of rows and *c* is the number of columns. Of course,
    as before, when we calculate our *p* value, we will reject the null hypothesis
    if that *p* value is less than the significance level. Let’s use some built-in
    Python methods, as shown, in order to quickly get our results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We can see that our *p* value is quite large; therefore, we fail to reject the
    null hypothesis and we cannot say for sure that seeing a particular website has
    any effect on whether or not a user signs up. There is no association between
    these variables.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at different statistical tests, including chi-square
    and *t*-tests, as well as point estimates and confidence intervals, in order to
    ascertain population parameters based on sample data. We were able to find that
    even with small samples of data, we can make powerful assumptions about the underlying
    population as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: Using the concepts reviewed in this chapter, data scientists will be able to
    make inferences about entire datasets based on certain samples of data. In addition,
    they will be able to use hypothesis tests to gain a better understanding of full
    datasets, given samples of data.
  prefs: []
  type: TYPE_NORMAL
- en: Statistics is a very wide and expansive subject that cannot truly be covered
    in a single chapter; however, our understanding of the subject will allow us to
    carry on and talk more about how we can use statistics and probability in order
    to communicate our ideas through data science in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss different ways of communicating results
    from data analysis including various presentation styles as well as visualization
    techniques.
  prefs: []
  type: TYPE_NORMAL
