["```py\n# read the data and set the datetime as the index\n# taken from Kaggle: https://www.kaggle.com/c/bike-sharing-demand/data\nimport pandas as pd\nimport matplotlib.pyplot as plt\nurl ='https://raw.githubusercontent.com/justmarkham/DAT8/master/data/bikeshare.csv'\nbikes = pd.read_csv(url) bikes.head()\n```", "```py\nimport seaborn as sns #using seaborn to get a line of best fit\nsns.lmplot(x='temp', y='count', data=bikes, aspect=1.5, scatter_kws={'alpha':0.2})\n```", "```py\nbikes[['count', 'temp']].corr() # 0.3944\n```", "```py\n# create X and y\nfeature_cols = ['temp'] # a list of the predictors\nX = bikes[feature_cols] # subsetting our data to only the predictors\ny = bikes['count'] # our response variable\n```", "```py\n# import scikit-learn, our machine learning module from sklearn.linear_model import LinearRegression\n```", "```py\nlinreg = LinearRegression() #instantiate a new model linreg.fit(X, y) #fit the model to our data\n# print the coefficients print(linreg.intercept_) print(linreg.coef_) 6.04621295962 # our Beta_0\n[ 9.17054048] # our beta parameters\n```", "```py\nlinreg.predict(20) # a temperatureof 20 degrees would lead our model to predict 189.46 bikes to be in use\n```", "```py\n# create a list of features\nfeature_cols = ['temp', 'season', 'weather', 'humidity'] # create X and y\nX = bikes[feature_cols] y = bikes['count']\n# instantiate and fit linreg = LinearRegression() linreg.fit(X, y)\n# pair the feature names with the coefficients result = zip(feature_cols, linreg.coef_) resultSet = set(result)\nprint(resultSet)\nhis gives us the following output:\n[('temp', 7.8648249924774403),\n('season', 22.538757532466754),\n('weather', 6.6703020359238048),\n('humidity', -3.1188733823964974)]\n```", "```py\n# example true and predicted response values true = [9, 6, 7, 6]\npred = [8, 7, 7, 12]\n# note that each value in the last represents a single prediction for a model\n# So we are comparing four predictions to four actual answers\n# calculate these metrics by hand! from sklearn import metrics\nimport numpy as np\nprint('MAE:', metrics.mean_absolute_error(true, pred)) print('MSE:', metrics.mean_squared_error(true, pred)) print('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))\n```", "```py\nMAE: 2.0\nMSE: 9.5\nRMSE: 3.08220700148\n```", "```py\nfrom sklearn import metrics\n# import metrics from scikit-learn\nfeature_cols = ['temp'] # create X and y\nX = bikes[feature_cols] linreg = LinearRegression() linreg.fit(X, y)\ny_pred = linreg.predict(X) np.sqrt(metrics.mean_squared_error(y, y_pred)) # RMSE # Can be interpreted loosely as an average error #166.45\n```", "```py\nfeature_cols = ['temp', 'humidity'] # create X and y\nX = bikes[feature_cols] linreg = LinearRegression() linreg.fit(X, y)\ny_pred = linreg.predict(X) np.sqrt(metrics.mean_squared_error(y, y_pred)) # RMSE # 157.79\n```", "```py\nfeature_cols = ['temp', 'humidity', 'season', 'holiday', 'workingday', 'windspeed', 'atemp']\n# create X and y\nX = bikes[feature_cols] linreg = LinearRegression() linreg.fit(X, y)\ny_pred = linreg.predict(X) np.sqrt(metrics.mean_squared_error(y, y_pred)) # RMSE # 155.75\n```", "```py\nfrom sklearn.cross_validation import train_test_split\n# function that splits data into training and testing sets\n# setting our overall data X, and y\nfeature_cols = ['temp']\nX = bikes[feature_cols]\ny = bikes['count']\n# Note that in this example, we are attempting to find an association between only the temperature of the day and the number of bike rentals.\nX_train, X_test, y_train, y_test = train_test_split(X, y) # split the data into training and testing sets\n# X_train and y_train will be used to train the model # X_test and y_test will be used to test the model\n# Remember that all four of these variables are just subsets of the overall X and y.\nlinreg = LinearRegression() # instantiate the model\nlinreg.fit(X_train, y_train)\n# fit the model to our training set\ny_pred = linreg.predict(X_test) # predict our testing set\nnp.sqrt(metrics.mean_squared_error(y_test, y_pred)) # RMSE # Calculate our metric:\n# == 166.91\n```", "```py\nfeature_cols = ['temp', 'workingday']\nX = bikes[feature_cols]\ny = bikes['count']\nX_train, X_test, y_train, y_test = train_test_split(X, y) # Pick a new random training and test set\nlinreg = LinearRegression() linreg.fit(X_train, y_train) y_pred = linreg.predict(X_test) # fit and predict\nnp.sqrt(metrics.mean_squared_error(y_test, y_pred)) # 166.95\n```", "```py\n    average_bike_rental = bikes['count'].mean() average_bike_rental\n    ```", "```py\n    # 191.57\n    ```", "```py\n    num_rows = bikes.shape[0] num_rows\n    ```", "```py\n    # 10886\n    ```", "```py\n    null_model_predictions = [average_bike_rental] * num_rows null_model_predictions\n    ```", "```py\n    [191.57413191254824,\n    ```", "```py\n    191.57413191254824,\n    ```", "```py\n    191.57413191254824,\n    ```", "```py\n    191.57413191254824,\n    ```", "```py\n    ...\n    ```", "```py\n    191.57413191254824,\n    ```", "```py\n    191.57413191254824,\n    ```", "```py\n    191.57413191254824,\n    ```", "```py\n    191.57413191254824]\n    ```", "```py\n    np.sqrt(metrics.mean_squared_error(y, null_model_predictions))\n    ```", "```py\n    181.13613\n    ```"]