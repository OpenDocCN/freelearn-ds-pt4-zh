<html><head></head><body>
<div id="_idContainer329" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-236"><a id="_idTextAnchor469" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.1.1">15</span></h1>
<h1 id="_idParaDest-237" class="calibre6"><a id="_idTextAnchor470" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.2.1">Navigating Real-World Data Science Case Studies in Action</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">Kudos to you, diligent reader! </span><span class="kobospan" id="kobo.3.2">Here we are, deep within the intricate tapestry of data science, having traversed its vast expanse together. </span><span class="kobospan" id="kobo.3.3">Your journey to </span><a href="B19488_15.xhtml#_idTextAnchor469" class="pcalibre calibre4 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.4.1">Chapter 15</span></em></span></a><span class="kobospan" id="kobo.5.1"> showcases not just your commitment but also your robust intellectual curiosity in the transformative realm of data. </span><span class="kobospan" id="kobo.5.2">It’s truly a </span><span><span class="kobospan" id="kobo.6.1">noteworthy milestone.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.7.1">In this chapter, we will unravel two meticulously selected case studies that provide a tangible insights into the pragmatic dimensions of data science. </span><span class="kobospan" id="kobo.7.2">These in-depth analyses will act as beacons, illuminating the theoretical principles we’ve previously discussed. </span><span class="kobospan" id="kobo.7.3">However, acknowledging the expansive nature of data science and the myriad scenarios it encompasses, we’ve made a strategic decision. </span><span class="kobospan" id="kobo.7.4">While we will dissect these two scenarios comprehensively here, there exists a treasure trove of additional case studies awaiting your exploration in our book’s </span><span><span class="kobospan" id="kobo.8.1">GitHub repository.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.9.1">Harnessing the academic and formal tone we’ve maintained, let’s recognize that these case studies aren’t merely demonstrations of data methodologies. </span><span class="kobospan" id="kobo.9.2">They represent the intricate dance of challenges, strategies, and triumphs inherent to real-world </span><span><span class="kobospan" id="kobo.10.1">data applications.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.11.1">With the compass (pun intended, as you’ll see soon) of our previous discussions in hand, let’s delve deep into these case studies, </span><span><span class="kobospan" id="kobo.12.1">shall we?</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.13.1">These are the topics we’ll cover in </span><span><span class="kobospan" id="kobo.14.1">this chapter:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><span class="kobospan" id="kobo.15.1">Introduction to the COMPAS dataset </span><span><span class="kobospan" id="kobo.16.1">case study</span></span></li>
<li class="calibre14"><span class="kobospan" id="kobo.17.1">Text embeddings using pre-trained models </span><span><span class="kobospan" id="kobo.18.1">and OpenA</span><a id="_idTextAnchor471" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.19.1">I</span></span></li>
</ul>
<h1 id="_idParaDest-238" class="calibre6"><a id="_idTextAnchor472" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.20.1">Introduction to the COMPAS dataset case study</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.21.1">In the realm </span><a id="_idIndexMarker926" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.22.1">of machine learning, where data drives decision-making, the line between algorithmic precision and ethical fairness often blurs. </span><span class="kobospan" id="kobo.22.2">The COMPAS dataset, a collection of criminal offenders screened in Broward County, Florida, during 2013-2014, serves as a poignant reminder of this intricate dance. </span><span class="kobospan" id="kobo.22.3">While, on the surface, it might appear as a straightforward binary classification task, the implications ripple far beyond simple predictions. </span><span class="kobospan" id="kobo.22.4">Each row and feature isn’t just a digit or a class; it represents years, if not decades, of human experiences, ambitions, and lives. </span><span class="kobospan" id="kobo.22.5">As we dive into this case study, we are reminded that these aren’t mere rows and columns but people with aspirations, dreams, and challenges. </span><span class="kobospan" id="kobo.22.6">With a primary focus on predicting </span><a id="_idIndexMarker927" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.23.1">recidivism (the likelihood of an offender to re-offend), we’re confronted with not just the challenge of achieving model accuracy but also the monumental responsibility of ensuring fairness. </span><span class="kobospan" id="kobo.23.2">Systemic privilege, racial discrepancies, and inherent biases in the data further accentuate the need for an approach that recognizes and mitigates these imbalances. </span><span class="kobospan" id="kobo.23.3">This case study endeavors to navigate these tumultuous waters, offering insights into the biases present, and more importantly, exploring ways to strike a balance between ML accuracy and the paramount importance of human fairness. </span><span class="kobospan" id="kobo.23.4">Let’s embark on this journey, bearing in mind the weight of the decisions we make and the profound impact they hold in </span><span><span class="kobospan" id="kobo.24.1">real-world scenarios.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.25.1">The core of this exploration revolves around the </span><strong class="bold"><span class="kobospan" id="kobo.26.1">Correctional Offender Management Profiling for Alternative Sanctions</span></strong><span class="kobospan" id="kobo.27.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.28.1">COMPAS</span></strong><span class="kobospan" id="kobo.29.1">) dataset. </span><span class="kobospan" id="kobo.29.2">It aggregates data from criminal offenders processed in Broward County, Florida, between 2013–2014. </span><span class="kobospan" id="kobo.29.3">Our focus narrows to a specific subset of this data, dedicated to the </span><em class="italic"><span class="kobospan" id="kobo.30.1">binary classification task of determining the probability of recidivism based on an </span></em><span><em class="italic"><span class="kobospan" id="kobo.31.1">individual’s attributes</span></em></span><span><span class="kobospan" id="kobo.32.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.33.1">For those interested, the dataset is accessible </span><span><span class="kobospan" id="kobo.34.1">here: </span></span><a href="https://www.kaggle.com/danofer/compass" class="pcalibre calibre4 pcalibre1"><span><span class="kobospan" id="kobo.35.1">https://www.kaggle.com/danofer/compass</span></span></a><span><span class="kobospan" id="kobo.36.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.37.1">At first glance, the task seems straightforward. </span><span class="kobospan" id="kobo.37.2">A binary classification with no data gaps, so, why not dive right in? </span><span class="kobospan" id="kobo.37.3">However, the conundrum surfaces when one realizes the profound consequences our ML models can have on real human lives. </span><span class="kobospan" id="kobo.37.4">The mantle of responsibility is upon us, as ML engineers and data practitioners, to not just craft efficient models but also to ensure the outcomes are </span><span><span class="kobospan" id="kobo.38.1">inherently “just.”</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.39.1">Throughout this case study, we’ll endeavor to delineate the multifaceted nature of “fairness.” </span><span class="kobospan" id="kobo.39.2">While multiple definitions are available, the crux lies in discerning which notion of fairness aligns with the specific domain at hand. </span><span class="kobospan" id="kobo.39.3">By unfolding various fairness perspectives, we aim to elucidate their </span><span><span class="kobospan" id="kobo.40.1">intended interpretations.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.41.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.42.1">This case study is illustrative and should not be misconstrued as an exhaustive statistical analysis or a critique of America’s criminal justice framework. </span><span class="kobospan" id="kobo.42.2">Rather, it’s an endeavor to spotlight potential biases in datasets and champion techniques to enhance fairness in our </span><span><span class="kobospan" id="kobo.43.1">ML algorithms.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.44.1">Without </span><a id="_idIndexMarker928" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.45.1">further ado, let’s dive right into </span><span><span class="kobospan" id="kobo.46.1">our dataset:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.47.1">
 import pandas as pd
 import numpy as np
 compas_data = pd.read_csv('../data/compas-scores-two-years.csv')
 compas_data.head()</span></pre>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.48.1">Figure 15</span></em></span><em class="italic"><span class="kobospan" id="kobo.49.1">.1</span></em><span class="kobospan" id="kobo.50.1"> shows the first five rows of </span><span><span class="kobospan" id="kobo.51.1">our dataset:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer322">
<span class="kobospan" id="kobo.52.1"><img alt="Figure 15.1 – An initial view of the COMPAS dataset" src="image/B19488_15_01.jpg" class="calibre5"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.53.1">Figure 15.1 – An initial view of the COMPAS dataset</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.54.1">This unveils certain sensitive data concerning individuals previously incarcerated in Broward County, Florida. </span><span class="kobospan" id="kobo.54.2">The key label here is </span><strong class="source-inline"><span class="kobospan" id="kobo.55.1">two_year_recid</span></strong><span class="kobospan" id="kobo.56.1">, which addresses the binary query: “Did this individual get incarcerated again within 24 months </span><span><span class="kobospan" id="kobo.57.1">of release?”</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.58.1">The 2016 ProPublica investigation, which scrutinized the fairness of the COMPAS algorithm and its foundational data, placed significant emphasis on the decile scores allotted to each subject. </span><span class="kobospan" id="kobo.58.2">A decile score partitions data into 10 equal segments, similar in concept to percentiles. </span><span class="kobospan" id="kobo.58.3">Essentially, an individual is ranked between 1 and 10, where each score denotes a segment of the population based on a specific metric. </span><span class="kobospan" id="kobo.58.4">To illustrate, a decile score of 3 suggests that 70% of the subjects pose a higher risk of re-offending (scoring between 4 and 10) while 20% pose a lower risk (scoring 1 or 2). </span><span class="kobospan" id="kobo.58.5">Conversely, a score of 7 would indicate that 30% have a heightened recidivism rate (scores of 8-10), whereas 60% are considered at a lower risk (scoring between 1 </span><span><span class="kobospan" id="kobo.59.1">and 6).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.60.1">Subsequent </span><a id="_idIndexMarker929" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.61.1">analyses showcased certain disparities in decile score allocation, particularly concerning race. </span><span class="kobospan" id="kobo.61.2">Upon evaluating score distribution, clear racial biases emerge, </span><span><span class="kobospan" id="kobo.62.1">as follows:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.63.1">
compas_data.groupby('race')['decile_score'].value_counts(
     normalize=True
 ).unstack().plot(
     kind='bar', figsize=(20, 7),
     title='Decile Score Histogram by Race', ylabel='% with Decile Score'
 )</span></pre>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.64.1">Figure 15</span></em></span><em class="italic"><span class="kobospan" id="kobo.65.1">.2</span></em><span class="kobospan" id="kobo.66.1"> shows the </span><span><span class="kobospan" id="kobo.67.1">resulting graph:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer323">
<span class="kobospan" id="kobo.68.1"><img alt="Figure 15.2 – The racial variances in decile score distribution are evident" src="image/B19488_15_02.jpg" class="calibre5"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.69.1">Figure 15.2 – The racial variances in decile score distribution are evident</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.70.1">We could delve deeper into how the ProPublica investigation interpreted its findings, but our interest lies in constructing a binary classifier from the data, setting aside the pre-existing </span><span><span class="kobospan" id="kobo.71.1">decile scores</span><a id="_idTextAnchor473" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.72.1">.</span></span></p>
<h2 id="_idParaDest-239" class="calibre7"><a id="_idTextAnchor474" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.73.1">Understanding the task/outlining success</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.74.1">The core </span><a id="_idIndexMarker930" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.75.1">of our investigation is binary classification. </span><span class="kobospan" id="kobo.75.2">Our mission can be encapsulated in the question: “Considering various attributes of an individual, can we predict the likelihood of them re-offending, both efficiently </span><span><span class="kobospan" id="kobo.76.1">and impartially?”</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.77.1">The notion of efficiency is straightforward. </span><span class="kobospan" id="kobo.77.2">We have an arsenal of metrics such as accuracy, precision, and AUC to evaluate model efficacy. </span><span class="kobospan" id="kobo.77.3">But when we discuss “impartiality,” we need to acquaint ourselves with novel concepts and metrics. </span><span class="kobospan" id="kobo.77.4">Before delving into bias and fairness quantification, we should conduct some preliminary </span><span><span class="kobospan" id="kobo.78.1">data exploratio</span><a id="_idTextAnchor475" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.79.1">n.</span></span></p>
<h2 id="_idParaDest-240" class="calibre7"><a id="_idTextAnchor476" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.80.1">Preliminary data exploration</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.81.1">The</span><a id="_idIndexMarker931" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.82.1"> intention is to predict the </span><strong class="source-inline"><span class="kobospan" id="kobo.83.1">two_year_recid</span></strong><span class="kobospan" id="kobo.84.1"> label using the dataset’s features. </span><span class="kobospan" id="kobo.84.2">Specifically, the features that we’re working with are </span><span><span class="kobospan" id="kobo.85.1">as follows:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.86.1">sex</span></strong><span class="kobospan" id="kobo.87.1"> – Binary: “Male” </span><span><span class="kobospan" id="kobo.88.1">or “Female”</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.89.1">age</span></strong><span class="kobospan" id="kobo.90.1"> – Numeric value </span><span><span class="kobospan" id="kobo.91.1">indicating years</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.92.1">race</span></strong><span class="kobospan" id="kobo.93.1"> – </span><span><span class="kobospan" id="kobo.94.1">Categorical</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.95.1">juv_fel_count</span></strong><span class="kobospan" id="kobo.96.1"> – Numeric value denoting prior </span><span><span class="kobospan" id="kobo.97.1">juvenile felonies</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.98.1">juv_misd_count</span></strong><span class="kobospan" id="kobo.99.1"> – Numeric value denoting previous </span><span><span class="kobospan" id="kobo.100.1">juvenile misdemeanors</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.101.1">juv_other_count</span></strong><span class="kobospan" id="kobo.102.1"> – Numeric value representing other </span><span><span class="kobospan" id="kobo.103.1">juvenile convictions</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.104.1">priors_count</span></strong><span class="kobospan" id="kobo.105.1"> – Numeric value indicating earlier </span><span><span class="kobospan" id="kobo.106.1">criminal offenses</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.107.1">c_charge_degree</span></strong><span class="kobospan" id="kobo.108.1"> – Binary: “F” indicating felony and “M” </span><span><span class="kobospan" id="kobo.109.1">indicating misdemeanor</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.110.1">The target variable is </span><span><span class="kobospan" id="kobo.111.1">as follows:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.112.1">two_year_recid</span></strong><span class="kobospan" id="kobo.113.1"> – Binary, indicating whether the individual re-offended within </span><span><span class="kobospan" id="kobo.114.1">two years</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.115.1">It’s worth </span><a id="_idIndexMarker932" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.116.1">noting that we possess three distinct columns detailing juvenile offenses. </span><span class="kobospan" id="kobo.116.2">We might consider merging these columns into one that represents the total count of juvenile offenses. </span><span class="kobospan" id="kobo.116.3">Given our goal of crafting a precise and unbiased model, let’s inspect the recidivism distribution based on race. </span><span class="kobospan" id="kobo.116.4">By categorizing the dataset by race and analyzing recidivism rates, it’s evident that there are varying baseline rates across </span><span><span class="kobospan" id="kobo.117.1">racial groups:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.118.1">
compas_df.groupby('race')['two_year_recid'].describe()</span></pre>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.119.1">Figure 15</span></em></span><em class="italic"><span class="kobospan" id="kobo.120.1">.3</span></em><span class="kobospan" id="kobo.121.1"> shows the resulting matrix of </span><span><span class="kobospan" id="kobo.122.1">descriptive statistics:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer324">
<span class="kobospan" id="kobo.123.1"><img alt="Figure 15.3 – Recidivism descriptive statistics categorized by race; distinctive disparities in recidivism rates across racial groups are visible" src="image/B19488_15_03.jpg" class="calibre5"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.124.1">Figure 15.3 – Recidivism descriptive statistics categorized by race; distinctive disparities in recidivism rates across racial groups are visible</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.125.1">We also observe limited representation of two racial groups: Asian and Native American. </span><span class="kobospan" id="kobo.125.2">This skewed representation may lead to biased inferences. </span><span class="kobospan" id="kobo.125.3">For context, Asians comprise about 4% of the Broward County, Florida, population, but only about 0.44% of this dataset. </span><span class="kobospan" id="kobo.125.4">In this study, we’ll recategorize individuals from Asian or Native American groups as </span><strong class="source-inline"><span class="kobospan" id="kobo.126.1">Other</span></strong><span class="kobospan" id="kobo.127.1"> to address the data imbalances. </span><span class="kobospan" id="kobo.127.2">This allows for a more balanced </span><span><span class="kobospan" id="kobo.128.1">class distribution:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.129.1">
# Modify the race category for educational purposes and to address imbalance in the dataset
compas_df.loc[compas_df['race'].isin(['Native American', 'Asian']), 'race'] = 'Other'  # Adjust "Asian" and "Native American" categories to "Other"
compas_df.groupby('race')['two_year_recid'].value_counts(
    normalize=True
).unstack().plot(
    kind='bar', figsize=(10, 5), title='Recidivism Rates Classified by Race'
)  # Visualize Recidivism Rates across the refined racial groups</span></pre>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.130.1">Figure 15</span></em></span><em class="italic"><span class="kobospan" id="kobo.131.1">.4</span></em><span class="kobospan" id="kobo.132.1"> shows</span><a id="_idIndexMarker933" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.133.1"> the resulting bar plot highlighting the differences in recidivism </span><span><span class="kobospan" id="kobo.134.1">by race:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer325">
<span class="kobospan" id="kobo.135.1"><img alt="Figure 15.4 – A bar graph illustrating recidivism rates per racial category" src="image/B19488_15_04.jpg" class="calibre5"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.136.1">Figure 15.4 – A bar graph illustrating recidivism rates per racial category</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.137.1">Our findings reveal a higher recidivism rate among </span><strong class="bold"><span class="kobospan" id="kobo.138.1">African-American </span></strong><span class="kobospan" id="kobo.139.1">individuals compared to </span><strong class="bold"><span class="kobospan" id="kobo.140.1">Caucasian</span></strong><span class="kobospan" id="kobo.141.1">, </span><strong class="bold"><span class="kobospan" id="kobo.142.1">Hispanic</span></strong><span class="kobospan" id="kobo.143.1">, and </span><strong class="bold"><span class="kobospan" id="kobo.144.1">Other</span></strong><span class="kobospan" id="kobo.145.1"> groups. </span><span class="kobospan" id="kobo.145.2">The underlying reasons are multifaceted and beyond this study’s scope. </span><span class="kobospan" id="kobo.145.3">However, it’s crucial to note the nuanced disparities </span><span><span class="kobospan" id="kobo.146.1">in rates.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.147.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.148.1">We could have analyzed gender biases, as evident differences exist between male and female representations. </span><span class="kobospan" id="kobo.148.2">For this study’s objectives, we’ll emphasize </span><span><span class="kobospan" id="kobo.149.1">racial biases.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.150.1">Advancing </span><a id="_idIndexMarker934" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.151.1">further, let’s analyze other </span><span><span class="kobospan" id="kobo.152.1">dataset attributes:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.153.1">
compas_df['c_charge_degree'].value_counts(normalize=True).plot(
    kind='bar', title='% of Charge Degree', ylabel='%', xlabel='Charge Degree'
)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.154.1">We possess a binary charge degree attribute that, after conversion to a Boolean format, should be readily usable (this plot is shown in </span><span><em class="italic"><span class="kobospan" id="kobo.155.1">Figure 15</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.156.1">.5</span></em></span><span><span class="kobospan" id="kobo.157.1">):</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer326">
<span class="kobospan" id="kobo.158.1"><img alt="Figure 15.5 – A breakdown of our dataset depicting felonies versus misdemeanors" src="image/B19488_15_05.jpg" class="calibre5"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.159.1">Figure 15.5 – A breakdown of our dataset depicting felonies versus misdemeanors</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.160.1">Approximately 65% of charges are felonies, with the remaining </span><span><span class="kobospan" id="kobo.161.1">being misdemeano</span><a id="_idTextAnchor477" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.162.1">rs.</span></span></p>
<h2 id="_idParaDest-241" class="calibre7"><a id="_idTextAnchor478" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.163.1">Preparing the data for modeling</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.164.1">Having </span><a id="_idIndexMarker935" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.165.1">understood the nuances of the bias and fairness definitions, it’s crucial that we give the same attention to our data preparation process. </span><span class="kobospan" id="kobo.165.2">This involves not just the technical transformations but also a thoughtful consideration of the implications of these transformations </span><span><span class="kobospan" id="kobo.166.1">on fairn</span><a id="_idTextAnchor479" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.167.1">ess.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.168.1">Feature engineering</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.169.1">We’ve </span><a id="_idIndexMarker936" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.170.1">already touched on a few points during EDA, such as combining the three juvenile crime columns. </span><span class="kobospan" id="kobo.170.2">However, before jumping into that, it’s crucial to note that any transformations we apply to our data can introduce or exacerbate biases. </span><span class="kobospan" id="kobo.170.3">Let’s take a </span><span><span class="kobospan" id="kobo.171.1">detailed </span><a id="_idTextAnchor480" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.172.1">look.</span></span></p>
<h4 class="calibre116"><span class="kobospan" id="kobo.173.1">Combining juvenile crime data</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.174.1">Combining</span><a id="_idIndexMarker937" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.175.1"> the juvenile offenses into a single feature is logical for model simplicity. </span><span class="kobospan" id="kobo.175.2">However, this can potentially introduce bias if the three types of juvenile crimes have different recidivism implications based on race. </span><span class="kobospan" id="kobo.175.3">By lumping them together, we could be over-simplifying these implications. </span><span class="kobospan" id="kobo.175.4">Always be wary of </span><span><span class="kobospan" id="kobo.176.1">such combinations:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.177.1">
# feature construction, add up our three juv columns and remove the original features
compas_df['juv_count'] = compas_df[["juv_fel_count", "juv_misd_count", "juv_other_count"]].sum(axis=1)
compas_df[['juv_fel_count', 'juv_misd_count', 'juv_other_count', 'juv_count']].describe()</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.178.1">The resulting matrix can be shown in </span><span><em class="italic"><span class="kobospan" id="kobo.179.1">Figure 15</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.180.1">.6</span></em></span><span><span class="kobospan" id="kobo.181.1">:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer327">
<span class="kobospan" id="kobo.182.1"><img alt="Figure 15.6 – A look at our new co﻿lumns" src="image/B19488_15_06.jpg" class="calibre5"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.183.1">Figure 15.6 – A look at our new co</span><a id="_idTextAnchor481" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.184.1">lumns</span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.185.1">One-hot encoding categorical features</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.186.1">We need to convert </span><a id="_idIndexMarker938" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.187.1">our categorical variables such as </span><strong class="source-inline"><span class="kobospan" id="kobo.188.1">sex</span></strong><span class="kobospan" id="kobo.189.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.190.1">race</span></strong><span class="kobospan" id="kobo.191.1">, and </span><strong class="source-inline"><span class="kobospan" id="kobo.192.1">c_charge_degree</span></strong><span class="kobospan" id="kobo.193.1"> into a numerical format. </span><span class="kobospan" id="kobo.193.2">Here, using a method such as one-hot encoding can be appropriate. </span><span class="kobospan" id="kobo.193.3">However, it’s essential to remember that introducing too many binary columns can exacerbate issues in fairness if the model gives undue importance to a </span><span><span class="kobospan" id="kobo.194.1">particular subgroup:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.195.1">
   dummies = pd.get_dummies(compas_df[['sex', 'race', 'c_charge_degree']], drop_first=True)
   compas_df = pd.concat([compas_df, dummies], a</span><a id="_idTextAnchor482" class="pcalibre pcalibre1 calibre162"/><span class="kobospan1" id="kobo.196.1">xis=1)</span></pre>
<h4 class="calibre116"><span class="kobospan" id="kobo.197.1">Standardizing skewed features</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.198.1">We can</span><a id="_idIndexMarker939" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.199.1"> easily see that </span><strong class="source-inline"><span class="kobospan" id="kobo.200.1">age</span></strong><span class="kobospan" id="kobo.201.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.202.1">priors_count</span></strong><span class="kobospan" id="kobo.203.1"> are right-skewed using the following code block and figure. </span><span class="kobospan" id="kobo.203.2">Standardizing these features can help our model train better. </span><span class="kobospan" id="kobo.203.3">Using methods such as log-transform or square root can </span><span><span class="kobospan" id="kobo.204.1">be useful:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.205.1">
# Right skew on Age
 compas_df['age'].plot(
     title='Histogram of Age', kind='hist', xlabel='Age', figsize=(10, 5)
 )
 # Right skew on Priors as well
 compas_df['priors_count'].plot(
     title='Histogram of Priors Count', kind='hist', xlabel='Priors', figsize=(10, 5)
 )</span></pre>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.206.1">Figure 15</span></em></span><em class="italic"><span class="kobospan" id="kobo.207.1">.7</span></em><span class="kobospan" id="kobo.208.1"> shows</span><a id="_idIndexMarker940" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.209.1"> us our two distributions and, more importantly, how much our data </span><span><span class="kobospan" id="kobo.210.1">is skewed:</span></span></p>
<p class="calibre3"> </p>
<div class="calibre2">
<div class="img---figure" id="_idContainer328">
<span class="kobospan" id="kobo.211.1"><img alt="Figure 15.7 – Skewed age and priors data can affect our final predictions" src="image/B19488_15_07.jpg" class="calibre5"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.212.1">Figure 15.7 – Skewed age and priors data can affect our final predictions</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.213.1">If we want to transform our numerical features, we can use a scikit-learn pipeline to run some feature transformations, such as in the following </span><span><span class="kobospan" id="kobo.214.1">code block:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.215.1">
We can use a scikit-learn pipeline to run a standard scaler like so:
numerical_features = ["age", "priors_count"]
numerical_transformer = Pipeline(steps=[
    ('scale', StandardScal</span><a id="_idTextAnchor483" class="pcalibre pcalibre1 calibre162"/><span class="kobospan1" id="kobo.216.1">er())
])</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.217.1">With a transformer in hand, such as the one defined in the preceding code block, we can begin to address</span><a id="_idIndexMarker941" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.218.1"> skewed data in real time in our </span><span><span class="kobospan" id="kobo.219.1">ML pipelines.</span></span></p>
<h2 id="_idParaDest-242" class="calibre7"><a id="_idTextAnchor484" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.220.1">Final thoughts</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.221.1">Remember, while we strive to achieve the best model performance, it’s crucial to constantly revisit the fairness aspect. </span><span class="kobospan" id="kobo.221.2">Addressing fairness isn’t a one-time task but rather an iterative process that involves refining the model, re-evaluating fairness metrics, and ensuring that our model decisions are as impartial as possible. </span><span class="kobospan" id="kobo.221.3">Our ultimate aim is to ensure the equitable treatment of all subgroups while making </span><span><span class="kobospan" id="kobo.222.1">accurate pred</span><a id="_idTextAnchor485" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.223.1">ictions.</span></span></p>
<h1 id="_idParaDest-243" class="calibre6"><a id="_idTextAnchor486" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.224.1">Text embeddings using pretrainedmodels and OpenAI</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.225.1">In the realm of </span><strong class="bold"><span class="kobospan" id="kobo.226.1">natural language processing</span></strong><span class="kobospan" id="kobo.227.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.228.1">NLP</span></strong><span class="kobospan" id="kobo.229.1">), the</span><a id="_idIndexMarker942" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.230.1"> quest for effectively converting textual information into mathematical representations, often referred to as embeddings, has always been paramount. </span><span class="kobospan" id="kobo.230.2">Embeddings</span><a id="_idIndexMarker943" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.231.1"> allow machines to “understand” and process textual content, bridging the gap between human language and computational tasks. </span><span class="kobospan" id="kobo.231.2">In our previous NLP chapters, we dived deep into the creation of text embeddings and witnessed the transformative </span><a id="_idIndexMarker944" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.232.1">power of </span><strong class="bold"><span class="kobospan" id="kobo.233.1">large language models</span></strong><span class="kobospan" id="kobo.234.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.235.1">LLMs</span></strong><span class="kobospan" id="kobo.236.1">) such as BERT in capturing the nuances </span><span><span class="kobospan" id="kobo.237.1">of language.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.238.1">Enter OpenAI, a forefront entity in the field of artificial intelligence research. </span><span class="kobospan" id="kobo.238.2">OpenAI has not only made significant contributions to the LLM landscape but has also provided various tools and engines to foster advancements in embedding technology. </span><span class="kobospan" id="kobo.238.3">In this study, we’re going to embark on a detailed exploration of text embeddings using </span><span><span class="kobospan" id="kobo.239.1">OpenAI’s offerings.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.240.1">By embedding paragraphs from this textbook, we’ll demonstrate the efficacy of OpenAI’s embeddings in answering natural language queries. </span><span class="kobospan" id="kobo.240.2">For instance, a seemingly whimsical question such as “How many horns does a flea have?” </span><span class="kobospan" id="kobo.240.3">can be efficiently addressed by scanning through the embedded paragraphs, showcasing the prowess of </span><span><span class="kobospan" id="kobo.241.1">seman</span><a id="_idTextAnchor487" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.242.1">tic search.</span></span></p>
<h2 id="_idParaDest-244" class="calibre7"><a id="_idTextAnchor488" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.243.1">Setting up and importing necessary libraries</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.244.1">Before we dive into the heart of this case study, it’s essential to set our environment right. </span><span class="kobospan" id="kobo.244.2">We need to ensure we have the appropriate libraries imported for the tasks we’ll perform. </span><span class="kobospan" id="kobo.244.3">This </span><a id="_idIndexMarker945" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.245.1">case study </span><a id="_idIndexMarker946" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.246.1">introduces a couple of </span><span><span class="kobospan" id="kobo.247.1">new packages:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.248.1">
import os
import openai
import numpy as np
from urllib.request import urlopen
from openai.embeddings_utils import get_embedding
from sentence_transformers import util</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.249.1">Let’s break down </span><span><span class="kobospan" id="kobo.250.1">our imports:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.251.1">os</span></strong><span class="kobospan" id="kobo.252.1">: Essential for interacting with the operating system – in our case, to fetch the </span><span><span class="kobospan" id="kobo.253.1">API key.</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.254.1">openai</span></strong><span class="kobospan" id="kobo.255.1">: The official OpenAI library, which will grant us access to various models </span><span><span class="kobospan" id="kobo.256.1">and utilities.</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.257.1">numpy</span></strong><span class="kobospan" id="kobo.258.1">: A fundamental package for scientific computing in Python. </span><span class="kobospan" id="kobo.258.2">Helps in manipulating large data </span><span><span class="kobospan" id="kobo.259.1">and arrays.</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.260.1">urlopen</span></strong><span class="kobospan" id="kobo.261.1">: Enables us to fetch data from URLs, which will be handy when we’re sourcing our </span><span><span class="kobospan" id="kobo.262.1">text data.</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.263.1">get_embedding</span></strong><span class="kobospan" id="kobo.264.1">: A utility from OpenAI to convert text </span><span><span class="kobospan" id="kobo.265.1">to embeddings.</span></span></li>
<li class="calibre14"><strong class="source-inline1"><span class="kobospan" id="kobo.266.1">sentence_transformers.util</span></strong><span class="kobospan" id="kobo.267.1">: Contains helpful utilities for semantic searching, a cornerstone of our </span><span><span class="kobospan" id="kobo.268.1">case study.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.269.1">Once our environment is set up, the next step is to configure our connection to the </span><span><span class="kobospan" id="kobo.270.1">OpenAI service:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.271.1">
openai.api_key = os.environ['OPENAI_API_KEY']
ENGINE = 'text-embedding-ada-002'</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.272.1">Here, we’re </span><a id="_idIndexMarker947" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.273.1">sourcing our API </span><a id="_idIndexMarker948" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.274.1">key from our environment variables. </span><span class="kobospan" id="kobo.274.2">It’s a secure way to access sensitive keys without hardcoding them. </span><span class="kobospan" id="kobo.274.3">The chosen engine for our embeddings </span><span><span class="kobospan" id="kobo.275.1">is </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.276.1">text-emb</span><a id="_idTextAnchor489" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.277.1">edding-ada-002</span></strong></span><span><span class="kobospan" id="kobo.278.1">.</span></span></p>
<div class="calibre9"/><h2 id="_idParaDest-245" class="calibre7"><a id="_idTextAnchor490" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.279.1">Data collection – fetching the textbook data</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.280.1">For this study, we’re</span><a id="_idIndexMarker949" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.281.1"> analyzing a textbook about insects. </span><span class="kobospan" id="kobo.281.2">Let’s fetch and process </span><span><span class="kobospan" id="kobo.282.1">this data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.283.1">
text = urlopen('https://www.gutenberg.org/cache/epub/10834/pg10834.txt').read().decode()
documents = list(filter(lambda x: len(x) &gt; 100, text.split('\r\n\r\n')))
print(f'There are {len(documents)} documents/paragraphs')</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.284.1">Here, we’re downloading the text from its source, splitting it into paragraphs, and ensuring we only keep the more content-rich ones (those longer than </span><strong class="source-inline"><span class="kobospan" id="kobo.285.1">100</span></strong><span class="kobospan" id="kobo.286.1"> characters). </span><span class="kobospan" id="kobo.286.2">We end up with </span><strong class="source-inline"><span class="kobospan" id="kobo.287.1">79</span></strong><span class="kobospan" id="kobo.288.1"> paragraphs </span><a id="_idTextAnchor491" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.289.1">in </span><span><span class="kobospan" id="kobo.290.1">this example.</span></span></p>
<h2 id="_idParaDest-246" class="calibre7"><a id="_idTextAnchor492" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.291.1">Converting text to embeddings</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.292.1">The core </span><a id="_idIndexMarker950" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.293.1">of our analysis lies in converting text data to embeddings. </span><span class="kobospan" id="kobo.293.2">Let’s </span><span><span class="kobospan" id="kobo.294.1">achieve this:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.295.1">
question_embedding = np.array(get_embedding(QUESTION))
embeddings=[get_embedding(document) for document in documents]
embeddings = np.array(embeddings)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.296.1">We loop through each document, convert it into an embedding using our specified engine, and store the embeddings in a </span><strong class="source-inline"><span class="kobospan" id="kobo.297.1">numpy</span></strong><span class="kobospan" id="kobo.298.1"> array for </span><span><span class="kobospan" id="kobo.299.1">effi</span><a id="_idTextAnchor493" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.300.1">cient operations.</span></span></p>
<h2 id="_idParaDest-247" class="calibre7"><a id="_idTextAnchor494" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.301.1">Querying – searching for relevant information</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.302.1">With our data transformed, let’s </span><a id="_idIndexMarker951" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.303.1">pose a natural language query and find the most relevant document using our vector embedding. </span><span class="kobospan" id="kobo.303.2">We are using a kind of nearest-neighbor algorithm, as we </span><span><span class="kobospan" id="kobo.304.1">have seen:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.305.1">
QUESTION = 'How many horns does a flea have?'
</span><span class="kobospan1" id="kobo.305.2">question_embedding = np.array(get_embedding(QUESTION, engine=ENGINE))
hits = util.semantic_search(question_embedding, embeddings, top_k=1)[0]
print(f'Question: {QUESTION}\n')
for i, hit in enumerate(hits):
    print(f'Document {i + 1} Cos_Sim {hit["score"]:.3f}:\n\n{documents[hit["corpus_id"]]}')
    print('\n')</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.306.1">We encode our question into an embedding, and then use semantic search to find the closest matching document from our dataset. </span><span class="kobospan" id="kobo.306.2">The result provides us with insights into our query. </span><span class="kobospan" id="kobo.306.3">With this structure, we’ve transformed our code into a more instructive, step-by-step guide that should be more accessible </span><span><span class="kobospan" id="kobo.307.1">a</span><a id="_idTextAnchor495" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.308.1">nd understandable.</span></span></p>
<h2 id="_idParaDest-248" class="calibre7"><a id="_idTextAnchor496" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.309.1">Concluding thoughts – the power of modern pre-trained models</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.310.1">In the rapidly evolving world of ML and AI, what we’ve witnessed in this case study is just a small taste of the vast potential of modern pre-trained models. </span><span class="kobospan" id="kobo.310.2">Here’s a brief contemplation on their </span><span><span class="kobospan" id="kobo.311.1">profound impact:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.312.1">Unprecedented efficiency</span></strong><span class="kobospan" id="kobo.313.1">: Gone </span><a id="_idIndexMarker952" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.314.1">are the days when we had to train models from scratch for every new task. </span><span class="kobospan" id="kobo.314.2">Pre-trained models, fine-tuned for specific tasks, have removed significant barriers in terms of time, computation, and resources. </span><span class="kobospan" id="kobo.314.3">With a few lines of code, we were able to access and harness the power of models that have trained on vast amounts of data, a task that would’ve been monumental just a </span><span><span class="kobospan" id="kobo.315.1">decade ago.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.316.1">Broadened accessibility</span></strong><span class="kobospan" id="kobo.317.1">: Not </span><a id="_idIndexMarker953" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.318.1">only do pre-trained models save time, but they also democratize access to cutting-edge AI technology. </span><span class="kobospan" id="kobo.318.2">Developers, researchers, and hobbyists without extensive ML backgrounds or access to massive compute resources can now embark on AI projects </span><span><span class="kobospan" id="kobo.319.1">with ease.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.320.1">Rapid prototyping</span></strong><span class="kobospan" id="kobo.321.1">: The </span><a id="_idIndexMarker954" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.322.1">ability to quickly spin up models and test ideas allows for a more iterative and innovative approach to problem-solving. </span><span class="kobospan" id="kobo.322.2">This rapid prototyping is especially important in industries that require quick turnarounds or where the first-mover advantage </span><span><span class="kobospan" id="kobo.323.1">is crucial.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.324.1">Versatility and scalability</span></strong><span class="kobospan" id="kobo.325.1">: The </span><a id="_idIndexMarker955" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.326.1">models we use today, such as OpenAI’s embedding engines, are versatile. </span><span class="kobospan" id="kobo.326.2">Whether you’re building a semantic search engine, a recommendation </span><a id="_idIndexMarker956" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.327.1">system, or any other application that requires understanding context, these models can be your cornerstone. </span><span class="kobospan" id="kobo.327.2">As your project grows, these models can scale with you, ensuring </span><span><span class="kobospan" id="kobo.328.1">consistent performance.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.329.1">In conclusion, the landscape of AI has been revolutionized by the advent of pre-trained models. </span><span class="kobospan" id="kobo.329.2">Their power and efficiency underscore a new era where building advanced AI prototypes and projects is no longer a distant dream but an easily attainable reality. </span><span class="kobospan" id="kobo.329.3">As technology continues to advance, it’s exciting to ponder what further innovations lie on the horizon and how they will shape ou</span><a id="_idTextAnchor497" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.330.1">r </span><span><span class="kobospan" id="kobo.331.1">interconnected world.</span></span></p>
<h1 id="_idParaDest-249" class="calibre6"><a id="_idTextAnchor498" class="pcalibre calibre4 pcalibre1"/><span class="kobospan" id="kobo.332.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.333.1">As we reach the conclusion of this comprehensive case study chapter, it’s important to highlight that the journey doesn’t end here. </span><span class="kobospan" id="kobo.333.2">The power of modern ML and AI is vast and ever-growing, and there is always more to learn, explore, </span><span><span class="kobospan" id="kobo.334.1">and create.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.335.1">Our official GitHub repository serves as a central hub, housing not only the code and detailed explanations from this case study but also an extensive collection of additional resources, examples, and even more intricate </span><span><span class="kobospan" id="kobo.336.1">case studies:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.337.1">More case studies</span></strong><span class="kobospan" id="kobo.338.1">: Dive deeper into the world of ML with an array of case studies spanning various domains and complexities. </span><span class="kobospan" id="kobo.338.2">Each case study is meticulously crafted to provide you with hands-on experience, guiding you through different challenges and solutions in the </span><span><span class="kobospan" id="kobo.339.1">AI landscape.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.340.1">Comprehensive code examples</span></strong><span class="kobospan" id="kobo.341.1">: The repository is rich with code examples that complement the case studies and explanations provided. </span><span class="kobospan" id="kobo.341.2">These examples are designed to be easily understandable and executable, allowing you to grasp the practical aspects of the </span><span><span class="kobospan" id="kobo.342.1">concepts discussed.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.343.1">Interactive learning</span></strong><span class="kobospan" id="kobo.344.1">: Engage with interactive notebooks and applications that provide a hands-on approach to learning, helping solidify your understanding of key concepts </span><span><span class="kobospan" id="kobo.345.1">and techniques.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.346.1">Community and collaboration</span></strong><span class="kobospan" id="kobo.347.1">: Join a community of learners and contributors. </span><span class="kobospan" id="kobo.347.2">The repository is an open space for collaboration, questions, and discussions. </span><span class="kobospan" id="kobo.347.3">Your participation helps create a vibrant learning environment, fostering growth </span><span><span class="kobospan" id="kobo.348.1">and innovation.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.349.1">Continuous updates and additions</span></strong><span class="kobospan" id="kobo.350.1">: The field of ML is dynamic, and our repository reflects that. </span><span class="kobospan" id="kobo.350.2">Stay updated with the latest trends, techniques, and case studies by regularly checking back for new content </span><span><span class="kobospan" id="kobo.351.1">and updates.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.352.1">The road to mastering ML is a journey, not a destination. </span><span class="kobospan" id="kobo.352.2">The repository is designed to be your companion on this journey, providing you with the tools, knowledge, and community support needed to thrive in the </span><span><span class="kobospan" id="kobo.353.1">AI world.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.354.1">Looking forward, we are excited about the future developments in ML and AI. </span><span class="kobospan" id="kobo.354.2">We are committed to updating our resources, adding new case studies, and continually enhancing the learning experience </span><span><span class="kobospan" id="kobo.355.1">for everyone.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.356.1">Thank you for choosing to learn with us, and we hope that the resources provided serve as a springboard for your future endeavors in AI and ML. </span><span class="kobospan" id="kobo.356.2">Here’s to exploring the unknown, solving complex problems, and creating a smarter, more connected </span><span><span class="kobospan" id="kobo.357.1">world together!</span></span></p>
</div>
</body></html>