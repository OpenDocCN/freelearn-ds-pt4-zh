["```py\nmetadata_dict = df.schema[\"<column-name>\"].metadatametadata_dict[\"spark.contentAnnotation.semanticType\"] = \"<semantic-type>\"\ndf = df.withMetadata(\"<column-name>\", metadata_dict)\n```", "```py\n    databricks.automl.classify(  dataset: Union[pyspark.DataFrame, pandas.DataFrame],  *,  target_col: str,  data_dir: Optional[str] = None,  exclude_columns: Optional[List[str]] = None,           # <DBR> 10.3 ML and above  exclude_frameworks: Optional[List[str]] = None,        # <DBR> 10.3 ML and above  experiment_dir: Optional[str] = None,                  # <DBR> 10.4 LTS ML and above  imputers: Optional[Dict[str, Union[str, Dict[str, Any]]]] = None, # <DBR> 10.4 LTS ML and above  max_trials: Optional[int] = None,                     # deprecated in <DBR> 10.3 ML  primary_metric: str = \"f1\",  time_col: Optional[str] = None,  timeout_minutes: Optional[int] = None,) -> AutoMLSummary\n    ```"]