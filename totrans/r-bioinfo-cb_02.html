<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Finding Genetic Variants with HTS Data</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong>High-Throughput Sequencing</strong> <span>(</span><strong>HTS</strong><span>) has made it possible to discover genetic variants and carry out genome-wide genotyping and haplotyping in many samples in a short space of time. The deluge of data that this technology has released has created some unique opportunities for bioinformaticians and computer scientists, and some really innovative new data storage and data analysis pipelines have been created. The fundamental pipeline in variant calling starts with the quality control of HTS reads and the alignment of those reads to a reference genome. These steps invariably take place before analysis in R and typically result in a BAM file of read alignments or a</span> VCF <span>file of variant positions (see the</span> <a href="">Appendix</a> <span>of this book for a brief discussion of these file formats) that we'll want to process in our R code. </span></p>
<p>As variant calling and analysis is such a fundamental technique in <span><span>bioinformatics</span></span>, Bioconductor is well equipped with the tools we need to construct our software and perform our analysis. The key questions researchers will want to ask will range from <em>Where are the genetic variants on my genome?</em> to <em>How many are there?</em> to <em>How can I classify them?</em> We'll look at some recipes to address these questions and also look at other important general techniques that allow us to visualize variants and markers on a genome and assess associations of variants with genotypes. We'll also look at other definitions of the term genetic variant and see how we can assess the copy number of individual loci.</p>
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Finding SNPs and indels in sequence data using VariantTools</li>
<li>Predicting open reading frames in long reference sequences</li>
<li>Plotting features on genetic maps with karyoploteR</li>
<li>Finding alternative transcript isoforms</li>
<li>Selecting and classifying variants with VariantAnnotation</li>
<li>Extracting information in genomic regions of interest</li>
<li>Finding phenotype and genotype associations with GWAS</li>
<li>Estimating the copy number at a locus of interest</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>Here are the R packages you'll need. Some will install with <kbd>install.packages()</kbd>. <span>The packages listed under <kbd>Bioconductor</kbd> need to be installed with the dedicated installer. That's described here. If you need to do anything further, installation will be described in the recipes in which the packages are used:</span></p>
<ul>
<li><kbd>Bioconductor</kbd>: Following are the packages:
<ul>
<li><kbd>Biostrings</kbd> </li>
<li><kbd>GenomicRanges</kbd> </li>
<li><kbd>gmapR</kbd></li>
<li><kbd>karyoploteR</kbd></li>
<li><kbd>rtracklayer</kbd></li>
<li><kbd>systemPipeR</kbd></li>
<li><kbd>SummarizedExperiment</kbd></li>
<li><kbd>VariantAnnotation</kbd></li>
<li><kbd>VariantTools</kbd></li>
</ul>
</li>
<li><kbd>rrBLUP</kbd></li>
</ul>
<p>Bioconductor is huge and has its own installation manager. You can install these packages with the following code (f<span>urther information is available at </span><a href="https://www.bioconductor.org/install/">https://www.bioconductor.org/install/</a>):</p>
<pre>if (!requireNamespace("BiocManager"))
    install.packages("BiocManager")
BiocManager::install()</pre>
<p>Normally, in R, a user will load a library and use the functions directly by name. This is great in interactive sessions but it can cause confusion when many packages are loaded. To clarify which package and function I'm using at a given moment, I will occasionally use the <kbd>packageName::functionName()</kbd> convention. </p>
<p class="mce-root"/>
<p>Sometimes, in the middle of a recipe, I'll interrupt the code so you can see some intermediate output or the structure of an object that's important to understand. Whenever that happens, you'll see a code block where each line begins with <span>double hash (</span><kbd>##</kbd>) symbols, as shown:</p>
<pre>letters[1:5]<br/>## a b c d e</pre>
<p>All of the code and data for the recipes in this chapter are in this book's GitHub repository at <a href="https://github.com/danmaclean/R_Bioinformatics_Cookbook">https://github.com/danmaclean/R_Bioinformatics_Cookbook</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Finding SNPs and indels from sequence data using VariantTools</h1>
                </header>
            
            <article>
                
<p>A key bioinformatics task is to take an alignment of high-throughput sequence reads, typically stored in a BAM file, and compute a list of variant positions. Of course, this is ably handled by many external command-line programs and tools and usually results in a VCF file of variants, but there are some really powerful packages in Bioconductor that can do the whole thing, and in a fast and efficient manner, by taking advantage of BiocParallel's facilities for parallel evaluation—a set of tools designed to speed up work with large datasets in Bioconductor objects. Using Bioconductor tools allows us to keep all of our processing steps within R, and in this section, we'll go through a whole pipeline—from reads to lists of genes carrying variants—using purely R code and a number of Bioconductor packages.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In this section, we'll use a set of synthetic reads on the first 83 KB or so of the human genome chromosome 17. The reads were generated using the <kbd>wgsim</kbd> tool in <kbd>samtools</kbd>—an external command-line program. They have 64 SNPs introduced by <kbd>wgsim</kbd>, which can be seen in the sample data in <kbd>datasets/ch2/snp_positions.txt</kbd><q>.</q> You'll see, as the program progresses, that by default the parameters find many more SNPs than there are—you'll need to spot the places where you can set the parameters properly to finely tune the SNP-finding process.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Finding SNPs and indels from sequence data using <kbd>VariantTools</kbd> can be done using the following steps:</p>
<ol>
<li>Import the required libraries:</li>
</ol>
<pre style="padding-left: 60px">library(GenomicRanges)
library(gmapR)
library(rtracklayer)
library(VariantAnnotation)
library(VariantTools)</pre>
<ol start="2">
<li>Then, load the datasets:</li>
</ol>
<pre style="padding-left: 60px">bam_folder &lt;- file.path(getwd(), "datasets", "ch2")
bam_folder_contents &lt;- list.files(file.path(getwd(), "datasets", "ch2" ) )
bam &lt;- file.path( bam_folder, "hg17_snps.bam")
fasta_file &lt;- file.path(bam_folder,"chr17.83k.fa")</pre>
<ol start="3">
<li>
<p>Set up the genome object and the parameter objects:</p>
</li>
</ol>
<pre style="padding-left: 60px">fa &lt;- rtracklayer::FastaFile(fasta_file)

genome &lt;- gmapR::GmapGenome(fa, create=TRUE)

qual_params &lt;- TallyVariantsParam(
                   genome = genome,
                   minimum_mapq = 20)

var_params &lt;- VariantCallingFilters(read.count = 19,
                                    p.lower = 0.01
                                    )</pre>
<ol start="4">
<li>Call the variants:</li>
</ol>
<pre style="padding-left: 60px">called_variants &lt;- callVariants(bam, qual_params, 
                                calling.filters = var_params
                                )

head(called_variants)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>Now, we move on to annotation and load in the feature position information from a <kbd>.gff</kbd> or <kbd>.bed</kbd> file:</li>
</ol>
<pre style="padding-left: 60px">get_annotated_regions_from_gff &lt;- function(file_name) {
  gff &lt;- rtracklayer::import.gff(file_name) 
  as(gff, "GRanges")
}

get_annotated_regions_from_bed &lt;- function(file_name){
  bed &lt;- rtracklayer::import.bed(file_name)
  as(bed, "GRanges")
}

genes &lt;- get_annotated_regions_from_gff(file.path( bam_folder, "chr17.83k.gff3"))</pre>
<ol start="6">
<li>Now we calculate which variants overlap which genes:</li>
</ol>
<pre style="padding-left: 60px">overlaps &lt;- GenomicRanges::findOverlaps(called_variants, genes) <br/>overlaps</pre>
<ol start="7">
<li>Finally, we subset the genes with the list of overlaps.</li>
</ol>
<pre style="padding-left: 60px">genes[subjectHits(overlaps)]</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This is a long and involved pipeline with a few complicated steps. After loading the libraries, the first four lines set up the files we're going to need from the dataset directory. Note we need a <kbd>.bam</kbd> file and a <kbd>fasta</kbd> file. Next, we create a <kbd>GmapGenome</kbd> object using the <kbd>gmapR::GmapGenome()</kbd> function with the <kbd>fasta</kbd> object—this describes the genome to the later variant-calling function. The next two functions we use, <kbd>TallyVariantParams()</kbd> and <kbd>VariantCallingFilters()</kbd>, are vital for the correct calling and filtering of candidate SNPs. These are the functions in which you can set the parameters that define an SNP or indel. The options here are deliberately very poor. As you can see from the output, there are 6 SNPs called, when we created 64.</p>
<p>Once the parameters are defined, we use the <kbd>callVariants()</kbd> function with all of the information we set up to get a <kbd>vranges</kbd> object of variants.</p>
<p>This results in the following output:</p>
<pre> VRanges object with 6 ranges and 17 metadata columns:
##           seqnames    ranges strand         ref              alt
##              &lt;Rle&gt; &lt;IRanges&gt;  &lt;Rle&gt; &lt;character&gt; &lt;characterOrRle&gt;
##   [1] NC_000017.10        64      *           G                T
##   [2] NC_000017.10        69      *           G                T
##   [3] NC_000017.10        70      *           G                T
##   [4] NC_000017.10        73      *           T                A
##   [5] NC_000017.10        77      *           T                A
##   [6] NC_000017.10        78      *           G                T</pre>
<p>We can then set up the <kbd>GRanges</kbd> object of the <kbd>GFF</kbd> file of annotations (I also provided a function for getting annotations from <kbd>BED</kbd> files).</p>
<p>This results in the following output:</p>
<pre>## Hits object with 12684 hits and 0 metadata columns:
##           queryHits subjectHits
##           &lt;integer&gt;   &lt;integer&gt;
##       [1]     35176           1
##       [2]     35176           2
##       [3]     35176           3
##       [4]     35177           1</pre>
<p>The final step is to use the powerful overlapping and subsetting capability of the <kbd>XRanges</kbd> objects. We use <kbd>GenomicRanges::findOverlaps()</kbd> to find the actual overlap—the returned <kbd>overlaps</kbd> object actually contains the indices in each input object of the overlapped object.</p>
<p><span>This results in the following output:</span></p>
<pre>## GRanges object with 12684 ranges and 20 metadata columns:
##               seqnames      ranges strand |   source       type     score
##                  &lt;Rle&gt;   &lt;IRanges&gt;  &lt;Rle&gt; | &lt;factor&gt;   &lt;factor&gt; &lt;numeric&gt;
##       [1] NC_000017.10 64099-76866      - |   havana ncRNA_gene      &lt;NA&gt;
##       [2] NC_000017.10 64099-76866      - |   havana    lnc_RNA      &lt;NA&gt;
##       [3] NC_000017.10 64099-65736      - |   havana       exon      &lt;NA&gt;</pre>
<p>Hence, we can use <kbd>subjectHits(overlaps)</kbd> to directly subset the genes with SNPs inside and get a very non-redundant list.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>When we're happy with the filters and the set of variants we called, we can save a VCF file of the variants using the following code:</p>
<pre>VariantAnnotation::sampleNames(called_variants) &lt;- "sample_name"
vcf &lt;- VariantAnnotation::asVCF(called_variants)
VariantAnnotation::writeVcf(vcf, "hg17.vcf")</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>Although our recipe makes the steps and code clear, the actual parameters and values we need to change can't be described in such a straightforward manner as the value will be very dataset-dependent. The <kbd>VariantTools</kbd> documentation contains a good discussion of how to work out and set parameters properly: <a href="http://bioconductor.org/packages/release/bioc/vignettes/VariantTools/inst/doc/VariantTools.pdf">http://bioconductor.org/packages/release/bioc/vignettes/VariantTools/inst/doc/VariantTools.pdf</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Predicting open reading frames in long reference sequences</h1>
                </header>
            
            <article>
                
<p>A draft genome assembly of a previously unsequenced genome can be a rich source of biological knowledge, but when genomics resources such as gene annotations aren't available, it can be tricky to proceed. Here, we'll look at a first stage pipeline for finding potential genes and genomic loci of interest absolutely <em>de novo</em> and without information beyond the sequence. We'll use a very simple set of rules to find open reading frames—sequences that begin with a start codon and end with a stop codon. The tools for doing this are encapsulated within a single function in the Bioconductor package, <kbd>systemPipeR</kbd>. We'll end up with yet another <kbd>GRanges</kbd> object that we can integrate into processes downstream that allow us to cross-reference other data, such as RNAseq, as we saw in the <em>Finding unannotated transcribed regions</em> recipe of <a href="ff091bc9-a002-4a63-b0fe-c0b9f9baf7d1.xhtml">Chapter 1</a>, <em>Performing Quantitative RNAseq</em>. As a final step, we'll look at how we can use a genome simulation to assess which of the open reading frames are actually likely to be real and not just occurring by chance.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In this recipe, we need just the short DNA sequence of the <kbd>Arabidopsis</kbd> chloroplast genome as input; it is in <kbd>datasets/ch2/arabidopsis_chloroplast.fa</kbd><q>.</q> We'll also need the <kbd>Bioconductor</kbd> packages <kbd>Biostrings</kbd> and <kbd>systemPipeR</kbd>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Predicting open reading frames in long reference sequences can be done using the following steps:</p>
<ol>
<li>Load the libraries and input genome:</li>
</ol>
<pre style="padding-left: 60px">library(Biostrings)
library(systemPipeR)

dna_object &lt;- readDNAStringSet(file.path(getwd(), "datasets","ch2", "arabidopsis_chloroplast.fa"))</pre>
<ol start="2">
<li>Predict the <strong>ORFs</strong> (<strong><span>open reading frames</span></strong>):</li>
</ol>
<pre style="padding-left: 60px">predicted_orfs &lt;- predORF(dna_object, n = 'all', type = 'gr', mode='ORF', strand = 'both', longest_disjoint = TRUE) <br/>predicted_orfs</pre>
<ol start="3">
<li>Calculate the properties of the reference genome:</li>
</ol>
<pre style="padding-left: 60px">bases &lt;- c("A", "C", "T", "G")
raw_seq_string &lt;- strsplit(as.character(dna_object), "")

seq_length &lt;- width(dna_object[1])
counts &lt;- lapply(bases, function(x) {sum(grepl(x, raw_seq_string))}  )
probs &lt;- unlist(lapply(counts, function(base_count){signif(base_count / seq_length, 2) }))</pre>
<ol start="4">
<li>Create a function that finds the longest ORF in a simulated genome:</li>
</ol>
<pre style="padding-left: 60px">get_longest_orf_in_random_genome &lt;- function(x,
  length = 1000, 
  probs = c(0.25, 0.25, 0.25, 0.25), 
  bases = c("A","C","T","G")){
    
  random_genome &lt;- paste0(sample(bases, size = length, replace = TRUE, prob = probs), collapse = "")
  random_dna_object &lt;- DNAStringSet(random_genome)
  names(random_dna_object) &lt;- c("random_dna_string")
  orfs &lt;- predORF(random_dna_object, n = 1, type = 'gr', mode='ORF', strand = 'both', longest_disjoint = TRUE)
  return(max(width(orfs)))
}</pre>
<ol start="5">
<li>Run the function on 10 simulated genomes:</li>
</ol>
<pre style="padding-left: 60px">random_lengths &lt;- unlist(lapply(1:10, get_longest_orf_in_random_genome, length = seq_length, probs = probs, bases = bases))</pre>
<ol start="6">
<li>Get the length of the longest random ORF:</li>
</ol>
<pre style="padding-left: 60px">longest_random_orf &lt;- max(random_lengths)</pre>
<ol start="7">
<li>Keep only predicted ORFs longer than the longest random ORF:</li>
</ol>
<pre style="padding-left: 60px">keep &lt;- width(predicted_orfs) &gt; longest_random_orf
orfs_to_keep &lt;- predicted_orfs[keep]
orfs_to_keep</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>The first part of this recipe is where we actually predict ORFs. Initially, we load in the DNA sequence as a</span> <kbd>DNAStringSet</kbd><span> object using</span> <kbd>readDNAStringSet()</kbd><span> from</span> <kbd>Biostrings</kbd><span>. The</span> <kbd>predORF()</kbd><span> function from</span> <kbd>systemPipeR</kbd><span> uses this object as input and actually predicts open reading frames according to the options set. Here, we're returning all ORFs on both strands.</span></p>
<p>This will result in the following output:</p>
<pre>## GRanges object with 2501 ranges and 2 metadata columns:
##           seqnames        ranges strand | subject_id inframe2end
##              &lt;Rle&gt;     &lt;IRanges&gt;  &lt;Rle&gt; |  &lt;integer&gt;   &lt;numeric&gt;
##      1 chloroplast   86762-93358      + |          1           2
##   1162 chloroplast     2056-2532      - |          1           3
##      2 chloroplast   72371-73897      + |          2           2
##   1163 chloroplast   77901-78362      - |          2           1
##      3 chloroplast   54937-56397      + |          3           3</pre>
<p class="mce-root"><span>We receive a</span> <kbd>GRanges</kbd><span> object in return, with 2,501 open reading frames described. This is far too many, so we need to filter out those; in particular, we can work out which are ORFs that occurred by chance from the sequence. To do this, we need to do a little simulation and that's what happens in the next section of code.</span></p>
<p class="mce-root"/>
<p>To estimate the length that random ORFs can reach, we're going to create a series of random genomes of a length equal to our input sequence and with the same base proportion and see what the longest ORF that can be predicted is. We do a few iterations of this and we get an idea of what the longest ORF occurring by chance could be. This length serves as a cut-off we can use to reject the predicted ORFs in the real sequence.</p>
<p>Achieving this needs a bit of setup and a custom function. First, we define the bases we will use as a simple character vector. Then, we get a character vector of the original DNA sequence by splitting the <kbd>as.character</kbd> version of <kbd>dna_object</kbd>. We use this information to work out the proportions of each base in the input sequence by first counting the number of each base (resulting in <kbd>counts</kbd> ), then dividing it by the sequence length, resulting in <kbd>probs</kbd>. In both these steps, we use <kbd>lapply()</kbd> to loop over the vector <kbd>bases</kbd> and the list <kbd>counts</kbd> and apply an anonymous function that uses these two variables to give lists of results. <kbd>unlist()</kbd> is used on our final list to reduce it to a simple vector.</p>
<p>Once we have the setup done, we can build our <kbd>get_longest_orf_in_random_genome()</kbd> <span>simulation function. </span>This generates a random genome by sampling length characters from the selection in <kbd>bases</kbd> with probabilities given in <kbd>probs</kbd>. The vector is <kbd>paste0()</kbd> into a single string and then converted into a <kbd>DNAStringSet</kbd> object for the <kbd>predORF()</kbd> function. This time, we ask for only the longest ORF using <em>n</em> = <em>1</em> and return the length of that.</p>
<p>This will result in the following output:</p>
<pre>## GRanges object with 10 ranges and 2 metadata columns:
##         seqnames        ranges strand | subject_id inframe2end
##            &lt;Rle&gt;     &lt;IRanges&gt;  &lt;Rle&gt; |  &lt;integer&gt;   &lt;numeric&gt;
##    1 chloroplast   86762-93358      + |          1           2
##    2 chloroplast   72371-73897      + |          2           2
##    3 chloroplast   54937-56397      + |          3           3
##    4 chloroplast   57147-58541      + |          4           1</pre>
<p>Now, we can run the function, which we do 10 times using <kbd>lapply()</kbd> and the <kbd>length</kbd>, <kbd>probs</kbd>, and <kbd>bases</kbd> information we calculated before. <kbd>unlist()</kbd> turns the result into a simple vector and we extract the longest of the 10 runs with <kbd>max()</kbd>. We can use subsetting on our original <kbd>predicted_orfs GRanges</kbd> object to keep the ORFs longer than the ones generated by chance.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Once you've got a set of ORFs you're happy with, you'll likely want to save them to a file. You can do that by using the <kbd>getSeq()</kbd> function in the <kbd>BSgenome</kbd> package, passing it the original sequence object—<kbd>dna_object</kbd>—and the ranges in <kbd>orfs_to_keep</kbd>, then give the result some names using <kbd>names()</kbd>, and you can use the <kbd>writeXStringSet()</kbd> function to save them to file:</p>
<pre>extracted_orfs &lt;- BSgenome::getSeq(dna_object, orfs_to_keep) 
names(extracted_orfs) &lt;- paste0("orf_", 1:length(orfs_to_keep))
writeXStringSet(extracted_orfs, "saved_orfs.fa")</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Plotting features on genetic maps with karyoploteR</h1>
                </header>
            
            <article>
                
<p>One of the most rewarding and insightful things we can do is visualize data. Very often, we want to see on a chromosome or genetic map where some features of interest lie in relation to others. These are sometimes called chromosome plots, and sometimes ideograms, and in this section, we'll see how to create one of these using the <kbd>karyoploteR</kbd> package. The package takes as input the familiar <kbd>GRanges</kbd> objects and creates detailed plots from configuration. We'll take a quick look at some different plot styles and some configuration options for ironing out the bumps in your plots when labels spill off the page or overlap each other.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>For this recipe, you'll need <kbd>karyoploteR</kbd> installed but all of the data we'll use will be generated within the recipe itself.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Plotting features on genetic maps with <kbd>karyoploteR</kbd> can be done using the following steps:</p>
<ol>
<li>First, we load the libraries:</li>
</ol>
<pre style="padding-left: 60px">library(karyoploteR)<br/>library(GenomicRanges)</pre>
<p class="mce-root"/>
<ol start="2">
<li>Then, set up the genome object that will be the base for our karyotype:</li>
</ol>
<pre style="padding-left: 60px">genome_df &lt;- data.frame( <br/>    chr = paste0("chr", 1:5), <br/>    start = rep(1, 5), <br/>    end = c(34964571, 22037565, 25499034, 20862711, 31270811) <br/>    ) <br/>genome_gr &lt;- makeGRangesFromDataFrame(genome_df)</pre>
<ol start="3">
<li>Set up the SNP positions we will draw on as markers:</li>
</ol>
<pre style="padding-left: 60px">snp_pos &lt;- sample(1:1e7, 25)
snps &lt;- data.frame(
  chr = paste0("chr", sample(1:5,25, replace=TRUE)),
  start = snp_pos,
  end = snp_pos
)
snps_gr &lt;- makeGRangesFromDataFrame(snps)</pre>
<ol start="4">
<li>Create some labels for the markers:</li>
</ol>
<pre style="padding-left: 60px">snp_labels &lt;- paste0("snp_", 1:25)</pre>
<ol start="5">
<li>Set the plot margins:</li>
</ol>
<pre style="padding-left: 60px">plot.params &lt;- getDefaultPlotParams(plot.type=1)
plot.params$data1outmargin &lt;- 600</pre>
<ol start="6">
<li>Create the base plot and add tracks:</li>
</ol>
<pre style="padding-left: 60px">kp &lt;- plotKaryotype(genome=genome_gr, plot.type = 1, plot.params = plot.params)
kpPlotMarkers(kp, snps_gr, labels = snp_labels)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The code first loads the libraries we'll need, then we construct a <kbd>data.frame</kbd> describing the genome we want to draw, with names and lengths set accordingly. The <kbd>data.frame</kbd> is then converted to <kbd>genome_gr</kbd>—a <kbd>GRanges</kbd> object with the <kbd>makeGRangesFromDataFrame()</kbd> <span>conversion function</span>. Next, we create a <kbd>data.frame</kbd> of 25 random SNPs using the <kbd>sample()</kbd> function to choose a position and chromosome. Again, this is converted to <kbd>GRanges</kbd>. Now we can set up our plot. First, we get the default plot parameter object from inside the package using <kbd>getDefaultPlotParams()</kbd>. We can modify this object to make any changes to the default settings in our plot.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Note we have selected <kbd>plot.type = 1</kbd>—this is a simple plot with one data track directly above each chromosome region. We'll need to change the margin height of the data track to stop our marker labels pouring out over the top—this is done with <kbd>plot.params$data1outmargin &lt;- 600</kbd>. Finally, we can draw our plot; we create the base plot object, <kbd>kp</kbd>, by calling <kbd>plotKaryotype()</kbd> and passing in the <kbd>genome_gr</kbd> object, <kbd>plot.type</kbd>, and the parameters in the modified <kbd>plot.params</kbd> object.</p>
<p>This will result in the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-575 image-border" src="Images/125d2fb6-50f7-4424-a449-e31639a10d96.png" style="width:40.92em;height:29.17em;" width="652" height="465"/></p>
<p>Our markers are drawn using the <kbd>kpPlotMarkers()</kbd> function with the new <kbd>kp</kbd> plot object, the <kbd>snps_gr</kbd> data, and the SNP labels.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>We can add numeric data of many different types into data tracks with <kbd>karyoploteR</kbd>. The following example shows how to draw some numeric data onto a plot as a simple line. The first step is to prepare our data. Here, we create a <kbd>data.frame</kbd> that has 100 random numbers that map into 100 windows of chromosome 4 and, as before, we create a <kbd>GRanges</kbd> object. This time, we'll have a data track above and below our chromosome—one for SNP markers and the other for the new data (note that this is <kbd>plot.type = 2</kbd>). We then need to set the parameters for the plo—in particular, the margins, to stop labels and data overlapping; but after that, it's the same plot calls, this time adding a <kbd>kpLines()</kbd> call. The key parameter here is <kbd>y</kbd>, which describes the <kbd>y</kbd> value of the data at each plotting point (note that this comes as a single column from our <kbd>numeric_data</kbd> object). We now have a plot with a numeric data track along chromosome 4. The following are the steps to be performed for this example:</p>
<ol>
<li> Create some numeric data:</li>
</ol>
<pre style="padding-left: 60px">numeric_data &lt;- data.frame(<br/> y = rnorm(100,mean = 1,sd = 0.5 ),<br/> chr = rep("chr4", 100),<br/> start = seq(1,20862711, 20862711/100),<br/> end = seq(1,20862711, 20862711/100)<br/>)<br/>numeric_data_gr &lt;- makeGRangesFromDataFrame(numeric_data)</pre>
<ol start="2">
<li>Set up plot margins:</li>
</ol>
<pre style="padding-left: 60px">plot.params &lt;- getDefaultPlotParams(plot.type=2)<br/>plot.params$data1outmargin &lt;- 800<br/>plot.params$data2outmargin &lt;- 800<br/>plot.params$topmargin &lt;- 800</pre>
<ol start="3">
<li class="mce-root">Create a plot and add tracks:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">kp &lt;- plotKaryotype(genome=genome_gr, plot.type = 2, plot.params = plot.params)<br/>kpPlotMarkers(kp, snps_gr, labels = snp_labels)<br/>kpLines(kp, numeric_data_gr, y = numeric_data$y, data.panel=2)</pre>
<p class="mce-root"/>
<p>This results in the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-576 image-border" src="Images/84f62bee-dec5-4ba7-b03c-c0763a0ec302.png" style="width:39.17em;height:27.67em;" width="652" height="460"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>There are many more types of tracks and plot layouts available that aren't covered here. Try the karyoploteR vignette for a definitive list: <a href="http://bioconductor.org/packages/release/bioc/vignettes/karyoploteR/inst/doc/karyoploteR.html">http://bioconductor.org/packages/release/bioc/vignettes/karyoploteR/inst/doc/karyoploteR.html</a>.</p>
<p>A quirk of <kbd>karyoploteR</kbd> means that it only draws chromosomes horizontally. For vertical maps, there is also the <kbd>chromPlot</kbd> package in Bioconductor.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Selecting and classifying variants with VariantAnnotation</h1>
                </header>
            
            <article>
                
<p>In pipelines where we've called variants, we'll often want to do subsequent analysis steps that need further filtering or classification based on features of the individual variants, such as the depth of coverage in the alternative allele. This is best done from a VCF file, and a common protocol is to save a VCF of all variants from the actual calling step and then experiment with filtering that. In this section, we'll look at taking an input VCF and filtering it to retain variants in which the alternative allele is the major allele in the sample.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>We'll need a <kbd>tabix</kbd> index VCF file; I provide one in the <kbd>datasets/ch2/sample.vcf.gz</kbd> file. We'll also need the Bioconductor package, <kbd>VariantAnnotation</kbd>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it... </h1>
                </header>
            
            <article>
                
<p>Selecting and classifying variants with <kbd>VariantAnnotation</kbd> can be done using the following steps:</p>
<ol>
<li>Create a prefilter function:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">is_not_microsat &lt;- function(x){ !grepl("microsat", x, fixed = TRUE)}</pre>
<ol start="2">
<li>Load up the prefilter function into a <kbd>FilterRules</kbd> object:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">prefilters &lt;- FilterRules(list(microsat = is_not_microsat) )</pre>
<ol start="3">
<li class="mce-root">Create a filter function to keep variants where the reference allele is in less than half the reads:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">major_alt &lt;- function(x){<br/> af &lt;- info(x)$AF <br/> result &lt;- unlist(lapply(af, function(x){x[1] &lt; 0.5}))<br/> return(result)<br/>}</pre>
<ol start="4">
<li class="mce-root">Load the filter function into a <kbd>FilterRules</kbd> object:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">filters &lt;- FilterRules(list(alt_is_major = major_alt))</pre>
<ol start="5">
<li class="mce-root">Load the input VCF file and apply filters:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">vcf_file &lt;- file.path(getwd(), "datasets", "ch2", "sample.vcf.gz")<br/>filterVcf(vcf_file, "hg17", "filtered.vcf", prefilters = prefilters, filters = filters)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>There is a surprisingly large amount of stuff going on in this very short script. The general outline is that we need to define two sets of filtering rules—<kbd>prefilter</kbd> and <kbd>filter</kbd>. This is achieved by defining functions that take the parsed VCF record and return <kbd>TRUE</kbd> if the record passes. Prefilters are generally straightforward text-based filters on an unparsed VCF record line—the raw text of the record. Our first line of code defines a <kbd>is_not_microsat()</kbd> <span>function </span>that, when passed a character string, uses the <kbd>grepl()</kbd> function to work out whether the line contains the word <kbd>microsat</kbd> and returns <kbd>TRUE</kbd> if it doesn't. The prefilter function is bundled into a <kbd>FilterRules</kbd> object we call <kbd>prefilters</kbd>. </p>
<p>The filters are more complex. These take the parsed VCF records (as <strong>VCF</strong> class objects) and operate on those. Our <kbd>major_alt()</kbd> function uses the <kbd>info()</kbd> <strong>VCF</strong><span> accessor function </span>to extract the <kbd>info</kbd> data in the VCF record. It returns a dataframe in which each column is a separate part of the info section. We extract the <kbd>AF</kbd> column, which returns a list with an element for each VCF. To iterate over those elements, we use the <kbd>lapply()</kbd> function to apply an anonymous function that returns <kbd>TRUE</kbd> if the reference allele has a proportion lower than 0.5 (that is, the alternative alleles are the major alleles). We then <kbd>unlist()</kbd> the result to provide a vector. The <kbd>major_alt()</kbd> function is then bundled into a <kbd>FilterRules</kbd> object we call <kbd>filters</kbd>.</p>
<p>Finally, with all of this setup done, we can load the input VCF file and run the filtering with <kbd>filterVCF()</kbd>. This function needs the <kbd>FilterRules</kbd> objects and the output filtered VCF filename. We use <kbd>filtered.vcf</kbd> as the file to write to. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>In filter functions, we can take advantage of other accessor functions to get at different parts of the VCF record. There are the <kbd>geno()</kbd> and <kbd>fixed()</kbd> <span>functions, which</span> will return data structures describing these parts of the VCF record. You can use these to create filters in the same way we used <kbd>info()</kbd>. </p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Extracting information in genomic regions of interest</h1>
                </header>
            
            <article>
                
<p>Very often, you'll want to look in more detail at data that falls in a particular genomic region of interest, whether that be the SNPs and variants in a gene or the genes in a particular locus. This extremely common task is handled very well by the extremely powerful <kbd>GRanges</kbd> and <kbd>SummarizedExperiment</kbd> objects, which are a little fiddly to set up but have very flexible subsetting operations that make the effort well worth it. We'll look at a few ways to set up these objects and a few ways we can manipulate them to get interesting information.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>In this recipe, we need the</span> <kbd>GenomicRanges</kbd><span>,</span> <kbd>SummarizedExperiment</kbd><span>, and</span> <kbd>rtracklayer</kbd> <span>Bioconductor packages.</span><strong> </strong><span>We'll also need two input data files: a GFF file of features of</span> the <kbd>Arabidopsis</kbd><span> chromosome 4 in the</span> <kbd>datasets/ch2/arabidopsis_chr4.gff</kbd> <span>file and a smaller text version of</span> gene-<span>only features of the same chromosome in</span> <kbd>datasets/ch2/arabidopsis_chr4.txt</kbd>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Extracting information in genomic regions of interest can be done using the following steps:</p>
<ol>
<li>Load in packages and define some functions that create <kbd>GRanges</kbd> from common files:</li>
</ol>
<pre style="padding-left: 60px">library(GenomicRanges)
library(rtracklayer)
library(SummarizedExperiment)

get_granges_from_gff &lt;- function(file_name) {
  gff &lt;- rtracklayer::import.gff(file_name)
  as(gff, "GRanges")
}

get_granges_from_bed &lt;- function(file_name){
  bed &lt;- rtracklayer::import.bed(file_name)
  as(bed, "GRanges")
}

get_granges_from_text &lt;- function(file_name){
  df &lt;- readr::read_tsv(file_name, col_names = TRUE ) <br/><span>  GenomicRanges::makeGRangesFromDataFrame(df, keep.extra.columns = TRUE)
}
</span></pre>
<ol start="2">
<li>
<p>Actually create some <kbd>GRanges</kbd> objects using those functions:</p>
</li>
</ol>
<pre style="padding-left: 60px"><span>gr_from_gff &lt;- get_annotated_regions_from_gff(file.path(getwd(), "datasets", "ch2", "arabidopsis_chr4.gff"))
gr_from_txt &lt;- get_granges_from_text(file.path(getwd(), "datasets", "ch2", "arabidopsis_chr4.txt"))</span></pre>
<ol start="3">
<li><span>Extract a region by filtering on attributes; in this case—the</span> <kbd><span>se</span><span>qnames</span></kbd> <span>and <kbd>metadata</kbd> columns:</span></li>
</ol>
<pre style="padding-left: 60px"><span>genes_on_chr4 &lt;- gr_from_gff[ gr_from_gff$type == "gene" &amp; seqnames(gr_from_gff) %in% c("Chr4") ]  </span></pre>
<ol start="4">
<li><span>Manually create a region of </span>interest:</li>
</ol>
<pre style="padding-left: 60px"><span>region_of_interest_gr &lt;- GRanges(
    seqnames = c("Chr4"), 
    IRanges(c(10000), width= c(1000))
)
</span></pre>
<ol start="5">
<li>Use the region of interest to subset the larger object:</li>
</ol>
<pre style="padding-left: 60px"><span>overlap_hits &lt;- findOverlaps(region_of_interest_gr, gr_from_gff)
features_in_region &lt;- gr_from_gff[subjectHits(overlap_hits) ]
features_in_region</span></pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The first step here is to create a <kbd>GRanges</kbd> object that describes the features of the genome you're interested in. The three functions we create all load in information from different file types, namely, <kbd>.gff</kbd>, <kbd>.bed</kbd>, and a tab-delimited <kbd>.txt</kbd> file, and return the necessary <kbd>GRanges</kbd> object. In <em>Step 2</em>, we make use of the GFF and text functions to create two <kbd>GRanges</kbd> objects: <kbd>gr_from_gff</kbd> and <kbd>gr_from_txt</kbd>. These are then used in subsetting. First, in <em>Step 3</em>, we subset on feature attributes. The code finds features of type gene on chromosome 4. Note the difference in syntax between finding genes and features in <kbd>Chr4</kbd>. The base columns in the <kbd>GRanges</kbd> object—namely, <kbd>seqnames</kbd>, <kbd>width</kbd>, and <kbd>start</kbd>—all have accessor functions that return vectors.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Hence, we use that in the second part of the condition. All other columns—called metadata in <kbd>GRanges</kbd> parlance—can be accessed with the standard <kbd>$</kbd> syntax, so we use that in the first part of the condition. </p>
<p>In <em>Step 4</em>, we create a specific region in a custom minimal <kbd>GRanges</kbd> object. This contains only one region but more could be added just by putting more <kbd>seqnames</kbd>, <kbd>start</kbd>, and <kbd>width</kbd> in the manually specified vectors. Finally, in <em>Step 5</em>, we use the <kbd>findOverlaps()</kbd> function to get the indices of features in the <kbd>gr_from_gff</kbd> object that overlap the manually created <kbd>region_of_interest</kbd> and use those indices to subset the larger <kbd>gr_from_gff</kbd> object.</p>
<p>This will result in the following output:</p>
<pre>## GRanges object with 1 range and 10 metadata columns:
##       seqnames     ranges strand |   source     type     score     phase
##          &lt;Rle&gt;  &lt;IRanges&gt;  &lt;Rle&gt; | &lt;factor&gt; &lt;factor&gt; &lt;numeric&gt; &lt;integer&gt;
##   [1]     Chr4 2895-10455      - |   TAIR10     gene      &lt;NA&gt;      &lt;NA&gt;
##                ID        Name                Note          Parent
##       &lt;character&gt; &lt;character&gt;     &lt;CharacterList&gt; &lt;CharacterList&gt;
##   [1]   AT4G00020   AT4G00020 protein_coding_gene            &lt;NA&gt;
##             Index Derives_from
##       &lt;character&gt;  &lt;character&gt;
##   [1]        &lt;NA&gt;         &lt;NA&gt;
##   -------
##   seqinfo: 1 sequence from an unspecified genome; no seqlengths</pre>
<p>Note that we need to extract the subject hits column using the <kbd>subjectHits()</kbd> accessor.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>It's also possible to extract subsets of dataframes or matrices in the same way by taking advantage of <kbd>GRanges</kbd> that are part of other objects. In the following example, we create a matrix of random data and use that to build a <kbd>SummarizedExperiment</kbd> object that uses a <kbd>GRanges</kbd> object to describe its rows:</p>
<pre>set.seed(4321)<br/>experiment_counts &lt;- matrix( runif(4308 * 6, 1, 100), 4308)<br/>sample_names &lt;- c(rep("ctrl",3), rep("test",3) )<br/>se &lt;- SummarizedExperiment::SummarizedExperiment(rowRanges = gr_from_txt, assays = list(experiment_counts), colData = sample_names)</pre>
<p>Then, we can subset in the same way as before and get back a subset of the data as well as a subset of the ranges. The <kbd>assay()</kbd> function returns the actual data matrix:</p>
<pre>overlap_hits &lt;- findOverlaps(region_of_interest_gr, se)<br/>data_in_region &lt;- se[subjectHits(overlap_hits) ]<br/>assay(data_in_region)</pre>
<p>This will give the resultant output:</p>
<pre>##          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]
## [1,] 69.45349 90.44524 88.33501 60.87932 86.24007 45.64919</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Finding phenotype and genotype associations with GWAS</h1>
                </header>
            
            <article>
                
<p>A powerful application of being able to find many thousands of genetic variants in many samples using high-throughput sequencing is <strong>genome-wide association studies</strong> <span>(</span><strong>GWAS</strong>) of genotype and phenotypes. GWAS is a <span>genomic analysis set of genetic variants in different individuals or genetic lines to see whether any particular variant is associated with a trait.</span> There are numerous techniques for doing this, but all rely on gathering data on variants in particular samples and working out each sample's genotype before cross-referencing with the phenotype in some way or other. In this recipe, we'll look at the sophisticated mixed linear model described by Yu <em>et al</em> in 2006 (<em>Nature Genetics</em>, 38:203-208). Describing the workings of the unified mixed linear model is beyond the scope of the recipe, but it is a suitable model for use in data with large sample and broad allelic diversity and is usable on plant and animal data. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In this recipe<span>, we'll look at constructing the data structures we need to run the analysis from input VCF files. We'll use the </span><kbd>GWAS()</kbd><span> function in the </span><kbd>rrBLUP</kbd><span> package. Our sample data file contains three SNPs—for didactic purposes, this will aid our programming task but for a GWAS study, the number is laughably small. Although the code will work, the results will not be biologically meaningful. </span></p>
<p>We'll need <kbd>rrBLUP</kbd>, which is not part of Bioconductor, so install it with <kbd>install.packages()</kbd>, <kbd>VariantAnnotation</kbd>, and the <span><kbd>datasets/ch2/small_sample.vcf</kbd> file.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Finding phenotype and genotype associations with GWAS can be done using the following steps:</p>
<ol>
<li>Load in the libraries and get the VCF file:</li>
</ol>
<pre style="padding-left: 60px">library(VariantAnnotation)
library(rrBLUP)<br/>set.seed(1234)
vcf_file &lt;- file.path(getwd(), "datasets", "ch2", "small_sample.vcf")
vcf &lt;- readVcf(vcf_file, "hg19")</pre>
<ol start="2">
<li>Extract the genotype, sample, and marker position information:</li>
</ol>
<pre style="padding-left: 60px">gts &lt;- geno(vcf)$GT

samples &lt;- samples(header(vcf))
markers &lt;- rownames(gts)
chrom &lt;- as.character(seqnames(rowRanges(vcf)))
pos &lt;- as.numeric(start(rowRanges(vcf)))</pre>
<ol start="3">
<li>Create a custom function to convert VCF genotypes into the convention used by the GWAS function:</li>
</ol>
<pre style="padding-left: 60px">convert &lt;- function(v){
  v &lt;- gsub("0/0", 1, v)
  v &lt;- gsub("0/1", 0, v)
  v &lt;- gsub("1/0", 0, v)
  v &lt;- gsub("1/1",-1, v)
  return(v)
}</pre>
<ol start="4">
<li>Call the function and convert the result into a numeric matrix:</li>
</ol>
<pre style="padding-left: 60px">gt_char&lt;- apply(gts, convert, MARGIN = 2)

genotype_matrix &lt;- matrix(as.numeric(gt_char), nrow(gt_char) )
colnames(genotype_matrix)&lt;- samples</pre>
<ol start="5">
<li>Build a dataframe describing the variant:</li>
</ol>
<pre style="padding-left: 60px">variant_info &lt;- data.frame(marker = markers,
                           chrom = chrom,
                           pos = pos)</pre>
<p class="mce-root"/>
<ol start="6">
<li>Build a combined variant/genotype dataframe:</li>
</ol>
<pre style="padding-left: 60px">genotypes &lt;-  cbind(variant_info, as.data.frame(genotype_matrix))
genotypes</pre>
<ol start="7">
<li>Build a <kbd>phenotype</kbd> dataframe:</li>
</ol>
<pre style="padding-left: 60px">phenotypes &lt;- data.frame(
  line = samples,
  score = rnorm(length(samples))
                         )

phenotypes</pre>
<ol start="8">
<li>Run <kbd>GWAS</kbd>:</li>
</ol>
<pre style="padding-left: 60px">GWAS(phenotypes, genotypes,plot=FALSE)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Most of the code in this recipe is setup code. After loading libraries and fixing the random number generator for reproducibility with <kbd>set.seed()</kbd>, in the first <span><span>step,</span></span> we get the VCF file of useful variants loaded in, and in the second step, we extract some useful information: we get a matrix of genotypes with the <kbd>geno(vcf)$GT</kbd> call, which returns a matrix <span>in which a row is a variant, a column is a sample, and the genotype is recorded at the intersection. We then use some accessor functions to pull sample and marker names and the reference sequence (<kbd>chrom</kbd>) and position (<kbd>pos</kbd>) for each variant. In <em>Step 3</em>, we define a translation function (<kbd>convert()</kbd>) to map VCF-style heterozygous and homozygous annotations to that used in <kbd>GWAS()</kbd>. Briefly, in VCF, <kbd>"0/0"</kbd> means <em>AA</em> (homozygous), which is encoded as 1 in <kbd>GWAS()</kbd>, <kbd>"0/1"</kbd> and <kbd>"1/0"</kbd> is heterozygous <em>Aa</em> or 0 in <kbd>GWAS()</kbd>, and <kbd>"1/1"</kbd> is homozygous <kbd>aa</kbd> or -1 in <kbd>GWAS()</kbd>.</span></p>
<p><span>In <em>Step 4</em>, we apply <kbd>convert()</kbd> into the <kbd>gts</kbd> matrix. Annoyingly, the return value is a character matrix and must be converted to numeric and re-wrapped in a matrix, which is what the last couple of lines in <em>Step 4</em> are for.</span></p>
<p><span>In <em>Step 5</em>, we build a dataframe describing the variant from the sample, marker, and sequence information we created before, and in <em>Step 6</em>, we actually combine the variant information with the genotype encodings. </span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This will give the following output:</p>
<pre>##           marker chrom     pos NA00001 NA00002 NA00003
## 1      rs6054257    20   14370       1       0      -1
## 2   20:17330_T/A    20   17330       1       0       1
## 3 20:1230237_T/G    20 1230237       1       1       0</pre>
<div class="packt_infobox"><span>Note that the order of the columns is important. The <kbd>GWAS()</kbd> function expects us to have this information in the order specified here. </span></div>
<p>In <em>Step 7</em>, we build the phenotype information. The first column must be called <kbd>line</kbd> but contain the sample names in the same order as the columns of the genotype matrix. The rest of the columns can be phenotype scores and have fixed effects.</p>
<p>This will result in something like the following output (your actual numbers may vary if you omit the <kbd>set.seed()</kbd> call at the top of the script because of the randomizing procedures and small sample sizes in the example data):</p>
<pre>##      line     score
## 1 NA00001 -1.2070657
## 2 NA00002 0.2774292
## 3 NA00003 1.0844412</pre>
<p>Finally, in <em>Step 8</em>, we run the <kbd>GWAS()</kbd> function.</p>
<p>This will result in the following output (again, your numbers may vary):</p>
<pre>## [1] "GWAS for trait: score"
## [1] "Variance components estimated. Testing markers."<br/><br/>##           marker chrom     pos      score
## 1      rs6054257    20   14370 0.3010543
## 2   20:17330_T/A    20   17330 0.3010057
## 3 20:1230237_T/G    20 1230237 0.1655498</pre>
<p>By default, the function tries to create a plot. There are too few points for that to work, so we turn it off here with <kbd>plot = FALSE</kbd>.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Estimating the copy number at a locus of interest</h1>
                </header>
            
            <article>
                
<p>It is often of interest to know how often a sequence occurs in a sample of interest—that is, to estimate whether, in your particular sample, a locus has been duplicated or its copy number has increased. The locus could be anything from a gene at Kbp scale or a large section of DNA at Mbp scale. Our approach in this recipe will be to use HTS read coverage after alignment to estimate a background level of coverage and then inspect the coverage of our region of interest. The ratio of the coverage in our region of interest to the background level will give us an estimate of the copy number in the region. The recipe here is the first step. The background model we use is very simple—we calculate only a global mean, but we'll discuss some alternatives later. Also, this recipe does not cover ploidy—the number of copies of the whole genome that are present in a cell. It is possible to estimate ploidy from similar data—especially SNP major/minor allele frequency, but it is a very involved pipeline. Take a look at the <em>See also</em> section for recommendations on packages to use for that long analysis.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>For this recipe, we need the <kbd>csaw</kbd> <span>Bioconductor package </span>and the sample <kbd>hg17</kbd> human genome <kbd>.bam</kbd> file of HTS read alignments in <kbd>datasets/ch2/hg17_snps.bam</kbd><em>.</em></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Estimating the copy number of a locus of interest can be done using the following steps:</p>
<ol>
<li>Load the library and get counts in windows across the genome:</li>
</ol>
<pre style="padding-left: 60px"><span>library(csaw)</span><br/>whole_genome &lt;- csaw::windowCounts( <br/>    file.path(getwd(), "datasets", "ch2", "hg17_snps.bam"), <br/>    bin = TRUE, <br/>    filter = 0, <br/>    width = 100, <br/>    param = csaw::readParam( minq = 20, dedup = TRUE, pe = "both" ) <br/>) <br/>colnames(whole_genome) &lt;- c("h17") </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li>Extract the data from <kbd>SummarizedExperiment</kbd>:</li>
</ol>
<pre style="padding-left: 60px">counts &lt;- assay(whole_genome)[,1] </pre>
<ol start="3">
<li>Work out a low count threshold and set windows with lower counts to <kbd>NA</kbd>:</li>
</ol>
<pre style="padding-left: 60px">min_count &lt;- quantile(counts, 0.1)[[1]]
counts[counts &lt; min_count] &lt;- NA</pre>
<ol start="4">
<li>Double the counts of a set of windows in the middle—these will act as our high copy number region:</li>
</ol>
<pre style="padding-left: 60px">n &lt;- length(counts)
doubled_windows &lt;- 10

left_pad &lt;- floor( (n/2) - doubled_windows )
right_pad &lt;- n - left_pad -doubled_windows
multiplier &lt;- c(rep(1, left_pad ), rep(2,doubled_windows), rep(1, right_pad) )
counts &lt;- counts * multiplier</pre>
<ol start="5">
<li>Calculate the mean coverage and the ratio in each window to that mean coverage, and inspect the ratio vector with a plot:</li>
</ol>
<pre style="padding-left: 60px"> mean_cov &lt;- mean(counts, na.rm=TRUE) 
 ratio &lt;- matrix(log2(counts / mean_cov), ncol = 1)<br/> plot(ratio)</pre>
<ol start="6">
<li>Build <kbd>SummarizedExperiment</kbd> with the new data and the row data of the old one:</li>
</ol>
<pre style="padding-left: 60px">se &lt;- SummarizedExperiment(assays=list(ratio), rowRanges= rowRanges(whole_genome), colData = c("CoverageRatio"))</pre>
<ol start="7">
<li>Create a region of interest and extract coverage data from it:</li>
</ol>
<pre style="padding-left: 60px">region_of_interest &lt;- GRanges(
  seqnames = c("NC_000017.10"),
  IRanges(c(40700), width = c(1500) )
)
 
overlap_hits &lt;- findOverlaps(region_of_interest, se)
data_in_region &lt;- se[subjectHits(overlap_hits)]
assay(data_in_region)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In <em>Step 1</em>, this recipe begins in familiar fashion, using the <kbd>csaw</kbd> package to get read counts in 100 bp windows over our small section of human chromosome 17. The read filtering options are set in the <kbd>param</kbd> argument. In <em>Step 2</em>, we extract the first and only column of data to give us a simple vector of the counts using the <kbd>assay()</kbd> function and subsetting. Next, in <em>Step 3</em>, we use the <kbd>quantile()</kbd> <span>function </span>to get the <kbd>min_count</kbd> value in the lower 10<sup>th</sup> percentile of the <kbd>counts</kbd> vector. The double-bracket subsetting is needed to get a single number from the named vector that the <kbd>quantile()</kbd> function returns. The <kbd>min_count</kbd> value will act as a cut-off. All values in the <kbd>counts</kbd> vector lower than this are set to <kbd>NA</kbd> to remove them from the analysis—this acts as a low coverage threshold and the percentile used can be modified in your own adaptations of the recipe as needed.</p>
<p>In <em>Step 4</em>, we add some regions with doubled coverage—so that we can detect them. We select a number of windows to double the counts in and then create a <kbd>multiplier</kbd> <span>vector </span>of equal length to counts that contains <strong>1</strong> where we don't wish to change counts and <strong>2</strong> where we wish to double them. We then apply the multiplication. <em>Step 4</em> will likely be left out in your own analysis as it is a synthetic data-generation step. </p>
<p>In <em>Step 5</em>, we actually compute the background coverage level. Our function here is a simple global mean, saved in <kbd>mean_cov</kbd>—but you can use many other functions. See the <em>See also</em> section for a discussion on this. We also calculate the <kbd>log2()</kbd> of the ratio of each window count to the global <kbd>mean_cov</kbd> and save it in a one-column matrix object called <kbd>ratio</kbd>—as we'll need the result to be a matrix in our final <kbd>SummarizedExperiment</kbd> object. We quickly use <kbd>plot()</kbd> to inspect <kbd>ratio</kbd> and can clearly see the count doubled windows in the middle of the data.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This will result in the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-577 image-border" src="Images/ab333e87-4cfa-40b0-8f57-e2c7565533c1.png" style="width:39.75em;height:25.08em;" width="657" height="414"/></p>
<p>In <em>Step 6</em>, we build a new <kbd>SummarizedExperiment</kbd> object, <kbd>se</kbd>, to hold the window ranges and the new ratio data. We take the <kbd>GRanges</kbd> and <kbd>colData</kbd> objects from <kbd>window_counts</kbd> and add our new <kbd>ratio</kbd> matrix. We can now start to subset this and see what coverage is in our regions of interest. </p>
<p>In <em>Step 7</em>, we construct a manual <kbd>GRanges</kbd> object for an arbitrary region we're interested in, helpfully called <kbd>region_of_interest</kbd>, and use that to find the overlapping windows in our <kbd>se</kbd> object using <kbd>findOverlaps()</kbd><em>.</em> We then use the resulting <kbd>overlap_hits</kbd> vector to subset the <kbd>se</kbd> object and the <kbd>assay()</kbd> function to view the counts in the region of interest.</p>
<p>This will result in the following output:</p>
<pre>##              [,1]
##  [1,]  0.01725283
##  [2,]  0.03128239
##  [3,] -0.05748994
##  [4,]  0.05893873
##  [5,]  0.94251006
##  [6,]  0.88186246
##  [7,]  0.87927929
##  [8,]  0.63780103
##  [9,]  1.00308550
## [10,]  0.75515798
## [11,]  0.80228189
## [12,]  1.05207419
## [13,]  0.82393626
## [14,]          NA
## [15,]          NA
## [16,] -0.16269298</pre>
<p>In the output, we can see the region has roughly a log2 ratio of 1 (twofold) coverage relative to the background, which we can interpret as a copy number of 2.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>The calculation for the background level in this recipe is really simple—which is great for learning the recipe, but might be quickly underpowered in your own real data. There are numerous options you could take to modify the way you calculate the background level for your own data. Check out the <kbd>rollmeans()</kbd> and <kbd>rollmedians()</kbd> functions in the <kbd>zoo</kbd> package—these give the mean and median in rolling windows of arbitrary step length and can give you a moving window background average that may be more appropriate. </p>
<p>A related analysis to copy number is the estimation of ploidy from SNP allele frequencies. You can check out the <kbd>vcfR</kbd> package's <kbd>freq_peaks()</kbd> function as a starting place to estimate ploidy from variant information in <kbd>BAM</kbd> files.</p>


            </article>

            
        </section>
    </div>



  </body></html>