<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer067">
			<h1 id="_idParaDest-153"><em class="italic"><a id="_idTextAnchor166"/>Chapter 7</em>: Pachyderm Operations</h1>
			<p>In <a href="B17085_06_Final_SB_Epub.xhtml#_idTextAnchor156"><em class="italic">Chapter 6</em></a>, <em class="italic">Creating Your First Pipeline</em>, we created our first pipeline, as well as learning how to create Pachyderm repositories, put data into a repository, create and run a pipeline, and view the results of the pipeline. We now know how to create a standard Pachyderm pipeline specification and include our scripts in it so that they can run against data in our input repository.</p>
			<p>In this chapter, we will review all the different ways to put data inside of Pachyderm and export it to outside systems. We will learn how to update the code that runs inside of your pipeline and what the process of updating the pipeline specification is. We will learn how to build a Docker container and test it locally before uploading it to a registry. </p>
			<p>We will also look into the most common troubleshooting steps that you should perform when a pipeline fails.</p>
			<p>This chapter will cover the following topics:</p>
			<ul>
				<li>Reviewing the standard Pachyderm workflow</li>
				<li>Executing data operations</li>
				<li>Executing pipeline operations</li>
				<li>Running maintenance operations</li>
			</ul>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor167"/>Technical requirements</h1>
			<p>You should have already installed the following components. </p>
			<p>For a local macOS installation, you need the following:</p>
			<ul>
				<li>macOS Mojave, Catalina, Big Sur, or later</li>
				<li>Docker Desktop for Mac 10.14</li>
				<li><strong class="source-inline">minikube</strong> v1.9.0 or later</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.x or later</li>
				<li>Pachyderm 2.0.x or later</li>
			</ul>
			<p>For a local Windows installation, you need the following:</p>
			<ul>
				<li>Windows Pro 64-bit v10 or later</li>
				<li><strong class="bold">Windows Subsystem for Linux</strong> (<strong class="bold">WSL</strong>) 2 or later</li>
				<li>Microsoft PowerShell v6.2.1 or later</li>
				<li>Hyper-V </li>
				<li><strong class="source-inline">minikube</strong> v1.9.0 or later</li>
				<li><strong class="source-inline">kubectl</strong> v1.18 or later</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.x or later</li>
				<li>Pachyderm 2.0.x or later</li>
			</ul>
			<p>For an <strong class="bold">Amazon Elastic Kubernetes Service</strong> (<strong class="bold">Amazon EKS</strong>) installation, you need the following:</p>
			<ul>
				<li><strong class="source-inline">kubectl</strong> v.18 or later</li>
				<li><strong class="source-inline">eksctl</strong></li>
				<li><strong class="source-inline">aws-iam-authenticator</strong></li>
				<li><strong class="source-inline">pachctl</strong> 2.0.x or later</li>
				<li>Pachyderm 2.0.x or later</li>
			</ul>
			<p>For a Microsoft <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>) cloud installation, you need the following:</p>
			<ul>
				<li><strong class="source-inline">kubectl</strong> v.18 or later</li>
				<li>Azure CLI</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.x or later</li>
				<li>Pachyderm 2.0.x or later</li>
				<li><strong class="source-inline">jq</strong> 1.5 or later</li>
			</ul>
			<p>For a <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>) cloud installation, you need the following:</p>
			<ul>
				<li>Google Cloud SDK v124.0.0. or later</li>
				<li><strong class="source-inline">kubectl</strong> v.18 or later</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.x or later</li>
				<li>Pachyderm 2.0.x or later</li>
			</ul>
			<p>In addition to this, you need to have the following:</p>
			<ul>
				<li>A Docker Hub account to be able to upload images</li>
			</ul>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor168"/>Downloading the source files</h2>
			<p>All the source files for this chapter are located in this repository: <a href="https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter07-Pachyderm-Operations">https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter07-Pachyderm-Operations</a>. </p>
			<h1 id="_idParaDest-156"><a id="_idTextAnchor169"/>Reviewing the standard Pachyderm workflow</h1>
			<p>As you <a id="_idIndexMarker620"/>probably noticed when you were creating a pipeline, there is a certain workflow that you will need to follow when working with Pachyderm. Depending on your automation tools, your team processes, and the software that you use, it might differ, but in general, it boils down to the following common steps:</p>
			<ol>
				<li value="1">Add your data to Pachyderm.</li>
				<li>Create a pipeline or pipelines.</li>
				<li>Add more data.</li>
				<li>Modify the parameters.</li>
				<li>Modify your pipeline or pipelines.</li>
				<li>Output the result to an output repository. </li>
				<li>Repeat <em class="italic">Steps 3–6</em> as many times as needed or continuously.</li>
				<li>Serve your model or package your library and make it available for use.</li>
			</ol>
			<p>The following diagram demonstrates this process:</p>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="Images/B17085_07_001.jpg" alt="Figure 7.1 – Pachyderm workflow&#13;&#10;" width="1164" height="990"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – Pachyderm workflow</p>
			<p>Depending on <a id="_idIndexMarker621"/>whether you keep your code in a Docker image, in the pipeline itself, or you use a build pipeline with your Python code, you need to rebuild your Docker image every time you make changes to the code. There is a lightweight workflow for Python pipelines only that uses a base Docker image and a special build pipeline. You can read about this approach in the Pachyderm official documentation at <a href="https://docs.pachyderm.com">https://docs.pachyderm.com</a>. For any other language, you<a id="_idIndexMarker622"/> likely will need to build Docker images regularly.</p>
			<p>Now that we know what the typical workflow is, let's dive into data operations and learn about all the ways you can upload your data to Pachyderm.</p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor170"/>Executing data operations</h1>
			<p>As you <a id="_idIndexMarker623"/>have probably already noticed, to get started working with Pachyderm, you need to put data into it. Then, data is transformed through a number of transformation steps. After that, you can export your data and models to an outside source in a form of libraries, binaries, packages, tables, dashboards, or any other format for further use. In this section, we will review the ways to upload and download data to and from Pachyderm and all the native Pachyderm modifications that can be applied during this process.</p>
			<p>Let's begin with uploading data to Pachyderm.</p>
			<h2 id="_idParaDest-158"><a id="_idTextAnchor171"/>Uploading data to Pachyderm</h2>
			<p>You can<a id="_idIndexMarker624"/> divide data sources that ingest data into<a id="_idIndexMarker625"/> Pachyderm into the following categories:</p>
			<ul>
				<li>From a local filesystem </li>
				<li>From a URL </li>
				<li>A remote object or block storage</li>
				<li>A streaming or messaging platform</li>
			</ul>
			<p>In this section, you will likely mostly use your local filesystem to upload data to Pachyderm repositories. This can be done with a simple Pachyderm command:</p>
			<ol>
				<li value="1">To upload data from a local filesystem, you use the following:<p class="source-code"><strong class="bold">pachctl put file -f &lt;filename&gt; repo@branch</strong></p></li>
			</ol>
			<p>The repository must exist.</p>
			<ol>
				<li value="2">Similarly, to upload the data stored in a remote location, you can use the same command by specifying the correct URL:<p class="source-code"><strong class="bold">pachctl put file -f https://mylink repo@branch</strong></p></li>
				<li>The <a id="_idIndexMarker626"/>same applies to the files stored <a id="_idIndexMarker627"/>in an object store. For example, if you are using an object store on Google Cloud Platform, you use the following:<p class="source-code"><strong class="bold">pachctl put file -f gs://my-bucket repo@branch</strong></p></li>
			</ol>
			<p>The preceding commands put the files in the root of the repo, but you could also put them in any subdirectory by specifying the path to them, like this:</p>
			<p class="source-code"><strong class="bold">pachctl put file -f gs://my-bucket repo@branch:/path</strong></p>
			<ol>
				<li value="4">To upload a whole directory, use the <strong class="source-inline">-r</strong> flag:<p class="source-code"><strong class="bold">pachctl put file -f directory -r repo@branch:/</strong></p></li>
			</ol>
			<p>Run <strong class="source-inline">pachctl put file --help</strong> to view more examples.</p>
			<ol>
				<li value="5">If you want to automatically upload data from a messaging queue to Pachyderm, you need to create a special type of pipeline <a id="_idIndexMarker628"/>called a <strong class="bold">spout</strong>. The main thing a spout does is that it connects a data stream from a messaging platform to Pachyderm and puts it into a specified Pachyderm repository. You could also specify some code to categorize data into folders according to the preferred pattern. Here is an example of a spout pipeline:<p class="source-code">---</p><p class="source-code">pipeline:</p><p class="source-code">  name: my-spout</p><p class="source-code">spout: {}</p><p class="source-code">transform:</p><p class="source-code">  cmd:</p><p class="source-code">  - python</p><p class="source-code">  - myspout.py</p><p class="source-code">  image: registry/image:1.0</p><p class="source-code">  env:</p><p class="source-code">    HOST: my-messaging-queue</p><p class="source-code">    TOPIC: mytopic</p><p class="source-code">    PORT: '5672'</p></li>
			</ol>
			<p>Now that we <a id="_idIndexMarker629"/>know how we can put data into <a id="_idIndexMarker630"/>Pachyderm, let's take a look at data provenance and data lineage in Pachyderm.</p>
			<h2 id="_idParaDest-159"><a id="_idTextAnchor172"/>About data lineage</h2>
			<p>If your <a id="_idIndexMarker631"/>system relies on data, you need to ensure that the data you use in your decision-making process is accurate and credible. Failure to provide a traceable data footprint may result in negative consequences for your organization. As more and more data-based systems are used in all aspects of our lives, wrong decisions based on erroneous data can have devastating impacts on people's lives.</p>
			<p>That's why being able to go back in time and trace the data to its origins is a crucial part of any data management system. The ability to track the changes that happened to the data through the multiple transformation steps back to its origin is called data lineage or data provenance.</p>
			<p>Typically, data lineage is visualized in <a id="_idIndexMarker632"/>the form of a <strong class="bold">Direct Acyclic Graph</strong> (<strong class="bold">DAG</strong>). Here is an example of the DAG representation in the Pachyderm UI:</p>
			<div>
				<div id="_idContainer062" class="IMG---Figure">
					<img src="Images/B17085_07_002.jpg" alt="Figure 7.2 – Pachyderm DAG&#13;&#10;" width="718" height="93"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2 – Pachyderm DAG</p>
			<p>Each container represents either an input or output repository or a pipeline. The preceding example is very simple. In a workflow with more steps, the DAG might look more complex.</p>
			<p>Why is <a id="_idIndexMarker633"/>data lineage so important? Here are a few important points to consider:</p>
			<ul>
				<li>With topics such as privacy and equality being widely discussed on all levels, providing an audit trail for governance is becoming a necessity.</li>
				<li>With data science being widely productized, implementing a system that offers the ability to roll back and correct errors in data and algorithms is crucial.</li>
				<li>Trustworthiness of the data is another aspect that can be verified through data lineage.</li>
			</ul>
			<p>In <a href="B17085_01_Final_SB_Epub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">The Problem of Reproducibility</em>, we discussed many examples where the lack of a proper data management system can have a devastating impact on people's lives, as well as harming your businesses.</p>
			<p>Now that we have discussed the importance of data lineage, let's take a look at how you can explore data lineage in Pachyderm.</p>
			<h2 id="_idParaDest-160"><a id="_idTextAnchor173"/>Exploring data lineage</h2>
			<p><strong class="bold">Data provenance</strong> or <strong class="bold">data lineage</strong> is the <a id="_idIndexMarker634"/>most<a id="_idIndexMarker635"/> important feature of Pachyderm that ensures that your changes are preserved and can be traced to the beginning of the pipeline's existence.</p>
			<p>To demonstrate this functionality, we will use the same pipeline we used in <a href="B17085_06_Final_SB_Epub.xhtml#_idTextAnchor156"><em class="italic">Chapter 6</em></a>, <em class="italic">Creating Your First Pipeline</em>. If you have not downloaded the files yet, go to <a href="https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter06-Creating-Your-First-Pipeline">https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter06-Creating-Your-First-Pipeline</a> and download them from there:</p>
			<ol>
				<li value="1">Create the Pachyderm <strong class="source-inline">photos</strong> repository, put the <strong class="source-inline">brown_vase.png</strong> file in it, and create the contour and histogram pipelines by running the following commands:<p class="source-code"><strong class="bold">pachctl create repo photos</strong></p><p class="source-code"><strong class="bold">pachctl put file -f brown_vase.png photos@master</strong></p><p class="source-code"><strong class="bold">pachctl create pipeline -f contour.yaml</strong></p><p class="source-code"><strong class="bold">pachctl create pipeline -f histogram.yaml</strong></p></li>
			</ol>
			<p>You should see the following output:</p>
			<p class="source-code">brown_vase.png 25.82KB / 25.82 KB [================] 0s 0.00 b/s</p>
			<ol>
				<li value="2">The <a id="_idIndexMarker636"/>following command shows how you can view the lineage of your data and pipelines. First, we need to get a commit number for the desired data change:<p class="source-code"><strong class="bold">pachctl list commit contour@master</strong></p></li>
			</ol>
			<p>The output should look similar to this:</p>
			<p class="source-code">REPO  BRANCH COMMIT  FINISHED SIZE ORIGIN DESCRIPTION</p>
			<p class="source-code">contour master 3d42... 22 seconds ago 23.78KiB AUTO</p>
			<p>In this example, we only have one output commit with the <strong class="source-inline">3d42e6385854478fbd2c9212c3afdab2</strong> hash. </p>
			<ol>
				<li value="3">Then, we can run the <strong class="source-inline">inspect commit</strong> command to get the provenance information:<p class="source-code"><strong class="bold">pachctl inspect commit contour@3d42e6385854478fbd2c9212c3afdab2</strong></p></li>
			</ol>
			<p>The preceding command returns the following output:</p>
			<p class="source-code">{</p>
			<p class="source-code">  "commit": {</p>
			<p class="source-code">    "branch": {</p>
			<p class="source-code">      "repo": {</p>
			<p class="source-code">        "name": "contour",</p>
			<p class="source-code">        "type": "user"</p>
			<p class="source-code">      },</p>
			<p class="source-code">      "name": "master"</p>
			<p class="source-code">    },</p>
			<p class="source-code">    "id": "3d42e6385854478fbd2c9212c3afdab2"</p>
			<p class="source-code">  },</p>
			<p class="source-code"><strong class="bold">  "origin": {</strong></p>
			<p class="source-code"><strong class="bold">    "kind": "AUTO"</strong></p>
			<p class="source-code">  },</p>
			<p class="source-code">  "child_commits": [</p>
			<p class="source-code">    {</p>
			<p class="source-code">      "branch": {</p>
			<p class="source-code">        "repo": {</p>
			<p class="source-code">          "name": "contour",</p>
			<p class="source-code">          "type": "user"</p>
			<p class="source-code">        },</p>
			<p class="source-code">        "name": "master"</p>
			<p class="source-code">      },</p>
			<p class="source-code">      "id": "dfff764bd1dd41b9bf3613af86d6e45c"</p>
			<p class="source-code">    }</p>
			<p class="source-code">  ],</p>
			<p class="source-code">  "started": "2021-08-18T17:03:32.180913500Z",</p>
			<p class="source-code">  "finishing": "2021-08-18T17:03:39.172264700Z",</p>
			<p class="source-code">  "finished": "2021-08-18T17:03:39.225964100Z",</p>
			<p class="source-code">  "direct_provenance": [</p>
			<p class="source-code">    {</p>
			<p class="source-code">      "repo": {</p>
			<p class="source-code">        "name": "contour",</p>
			<p class="source-code">        "type": "spec"</p>
			<p class="source-code">      },</p>
			<p class="source-code">      "name": "master"</p>
			<p class="source-code">    },</p>
			<p class="source-code">    {</p>
			<p class="source-code">      "repo": {</p>
			<p class="source-code">        "name": "photos",</p>
			<p class="source-code">        "type": "user"</p>
			<p class="source-code">      },</p>
			<p class="source-code">      "name": "master"</p>
			<p class="source-code">    }</p>
			<p class="source-code">  ],</p>
			<p class="source-code">  "size_bytes_upper_bound": "24353",</p>
			<p class="source-code">  "details": {</p>
			<p class="source-code">    "size_bytes": "24353"</p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p>This output <a id="_idIndexMarker637"/>shows you that the commit is created in the <strong class="source-inline">photos</strong> repository. It has the <strong class="source-inline">AUTO</strong> type because it was generated when the data was uploaded to the <strong class="source-inline">photos</strong> repository. You can also see that it has created a child commit, <strong class="source-inline">dfff764bd1dd41b9bf3613af86d6e45c</strong>, for which you can run the same command. The child commit will have the <strong class="source-inline">ALIAS</strong> type since it is connected to the original commit in the <strong class="source-inline">photos</strong> repository. Over time, as new data arrives, this list will grow.</p>
			<ol>
				<li value="4">The <a id="_idIndexMarker638"/>preceding command tells us what the predecessors of the commit in the <strong class="source-inline">contour</strong> repository were. We can also use the <strong class="source-inline">wait commit</strong> command with a commit ID to track commits as they land in the output repository. For example, if we want to watch the changes that the <strong class="source-inline">3e16201310374944b48ed73f83be2be7</strong> commit lands in downstream pipelines, we can run the following command:<p class="source-code"><strong class="bold">pachctl wait commitset photos@438428d0c3a145aa905c86c9fb1789ea</strong></p></li>
			</ol>
			<p><strong class="bold">Provenance</strong> is a <a id="_idIndexMarker639"/>powerful feature of Pachyderm. It is especially useful when you need to find an audit trail to find out what made your pipeline biased.</p>
			<p>Now that we have learned how to explore data provenance in Pachyderm, let's look into how to mount your Pachyderm repository to a local filesystem.</p>
			<h2 id="_idParaDest-161"><a id="_idTextAnchor174"/>Mounting a Pachyderm repository to a local filesystem</h2>
			<p>You can <a id="_idIndexMarker640"/>mount your Pachyderm system to your local computer by using the <strong class="bold">Filesystem in Userspace</strong> (<strong class="bold">FUSE</strong>) interface<a id="_idIndexMarker641"/> to access your Pachyderm <a id="_idIndexMarker642"/>repositories as you typically would access local files. FUSE is supported on all major platforms, such as Microsoft Windows, Linux, and macOS. By default, you can mount your Pachyderm repositories with read-only access but write access can also be enabled. You need to understand that modifying the files in these mounts leads to broken provenance and should not generally be used. Use this functionality to do the following:</p>
			<ul>
				<li>View the results of your pipeline runs.</li>
				<li>Give third-party applications access to Pachyderm output repositories for further processing.</li>
			</ul>
			<p>To mount a <a id="_idIndexMarker643"/>Pachyderm repository to your local computer filesystem, complete the following steps:</p>
			<ol>
				<li value="1">Install FUSE on your machine. If you are on macOS, run the following:<p class="source-code"><strong class="bold">brew install osxfuse</strong></p></li>
			</ol>
			<p>If you are on Linux, run the following:</p>
			<p class="source-code"><strong class="bold">sudo apt-get install -y fuse</strong></p>
			<p>On Windows, run the following:</p>
			<p class="source-code"><strong class="bold">choco install winfsp</strong></p>
			<ol>
				<li value="2">Use the <strong class="source-inline">pachctl mount</strong> command to mount a Pachyderm repository. For example, to mount a <strong class="source-inline">contour</strong> repository, run the following:<p class="source-code"><strong class="bold">pachctl mount ~/Documents/contour --repos contour@master </strong></p></li>
			</ol>
			<p>This command will run continuously in your terminal until you interrupt it with <em class="italic">Ctrl</em> + <em class="italic">C</em>.</p>
			<ol>
				<li value="3">To <a id="_idIndexMarker644"/>access your files, go to your file browser. For example, if you are on macOS, use Finder. You should see the <strong class="source-inline">~/Documents/contour</strong> folder mounted like this:</li>
			</ol>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="Images/B17085_07_003.jpg" alt="Figure 7.3 – Mounted Pachyderm repository&#13;&#10;" width="1039" height="266"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3 – Mounted Pachyderm repository</p>
			<p>From here, you can view the files as needed.</p>
			<ol>
				<li value="4">To mount a repository with write access, run the same command with the <strong class="source-inline">--write</strong> flag:<p class="source-code"><strong class="bold">pachctl mount ~/Documents/contour --repos contour@master --write</strong></p></li>
			</ol>
			<p>Use this <a id="_idIndexMarker645"/>functionality with caution as modifying files in output repositories breaks the provenance.</p>
			<ol>
				<li value="5">To <a id="_idIndexMarker646"/>mount multiple repositories, specify the list of the repositories each with a <strong class="source-inline">--repos</strong> flag:<p class="source-code"><strong class="bold">pachctl mount ~/Documents/pachyderm-repos --repos contour@master --repos data@master --repos histogram@master --repos photos@master</strong></p></li>
			</ol>
			<p>The following screenshot shows how the <strong class="source-inline">data</strong>, <strong class="source-inline">contour</strong>, <strong class="source-inline">histogram</strong>, and <strong class="source-inline">photos</strong> repositories are mounted on your machine:</p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="Images/B17085_07_004.jpg" alt="Figure 7.4 – Mounted Pachyderm repositories&#13;&#10;" width="1035" height="293"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.4 – Mounted Pachyderm repositories</p>
			<p>In this section, we learned how to perform the most common Pachyderm data operations, including uploading data to Pachyderm, exploring provenance, and mounting Pachyderm repositories to your local machine, as well as splitting data while uploading it to Pachyderm. Next, we'll look into the most common pipeline operations that you will have to perform while working with Pachyderm.</p>
			<h1 id="_idParaDest-162"><a id="_idTextAnchor175"/>Executing pipeline operations</h1>
			<p>Apart <a id="_idIndexMarker647"/>from creating and deleting pipelines, you likely will need to update your pipelines with new code changes. If changes are made to the pipeline specification itself, such as increasing the number of Pachyderm workers, input repository, glob pattern, or similar, you only need to do it in the YAML or JSON file and update the version of your pipeline spec. However, if the changes are in your code and your code is in your Docker image, you need to rebuild the Docker image. Let's go through each of these use cases.</p>
			<h2 id="_idParaDest-163"><a id="_idTextAnchor176"/>Updating your pipeline specification</h2>
			<p>The <a id="_idIndexMarker648"/>pipeline specification enables you to control various Pachyderm parameters, such as controlling from which repository your pipeline consumes data, how many workers are started, and how many resources are available to your pipeline. You can also specify your code in the pipeline itself through the <strong class="source-inline">stdin</strong> field. Such a pipeline can use a basic Docker image that you won't have to ever update. If this is your case and you need to make changes in your pipeline spec or the code in the <strong class="source-inline">stdin</strong> field, here is what you need to do:</p>
			<ol>
				<li value="1">Make the needed changes in the YAML or JSON file that has your pipeline specification. For example, if you want to change a glob pattern in your <strong class="source-inline">contour.yaml</strong> pipeline from <strong class="source-inline">glob: "/"</strong> to <strong class="source-inline">glob: "/*"</strong>, you just make these changes directly in the YAML file and save it.</li>
				<li>Then, you need to update the version of the already running pipeline by specifying this YAML file:<p class="source-code"><strong class="bold">pachctl update pipeline -f contour.yaml</strong></p></li>
				<li>Verify that the pipeline version is updated:<p class="source-code"><strong class="bold">pachctl list pipeline</strong></p></li>
			</ol>
			<p>If the previous version of your pipeline was <strong class="source-inline">1</strong>, it should change to <strong class="source-inline">2</strong>:</p>
			<p class="source-code">  NAME      VERSION INPUT     CREATED       STATE / LAST JOB  DESCRIPTION</p>
			<p class="source-code"><strong class="bold">contour   2</strong>       photos:/* 6 seconds ago running / success A pipeline that identifies contours on an image.</p>
			<p>The new pipeline will not process the data that has already been processed unless you explicitly specify it by using the <strong class="source-inline">--reprocess</strong> flag.</p>
			<ol>
				<li value="4">To <a id="_idIndexMarker649"/>run the updated pipeline against the already processed data, use the following:<p class="source-code"><strong class="bold">pachctl update pipeline -f contour.yaml --reprocess </strong></p></li>
				<li>In the output, you should see that the version was updated again:<p class="source-code">NAME      VERSION INPUT     CREATED        STATE / LAST JOB  DESCRIPTION</p><p class="source-code"><strong class="bold">contour   3</strong>       photos:/* 15 seconds ago running / success A pipeline that identifies contours on an image.</p></li>
				<li>By default, if you run <strong class="source-inline">pachctl list pipeline</strong>, Pachyderm shows information about the latest pipeline only. If you run this command with the <strong class="source-inline">--history</strong> flag, you can see all previous versions as well:<p class="source-code"><strong class="bold">pachctl list pipeline contour --history 3</strong></p></li>
			</ol>
			<p>Here is what the output should look like:</p>
			<p class="source-code">NAME    VERSION INPUT    CREATED        STATE / LAST JOB  DESCRIPTION</p>
			<p class="source-code">contour 3       photos:/ 25 seconds ago running / success A pipeline that identifies contours on an image.</p>
			<p class="source-code">contour 3       photos:/ 25 seconds ago running / success A pipeline that identifies contours on an image.</p>
			<p class="source-code">contour 3       photos:/ 25 seconds ago running / success A pipeline that identifies contours on an image.</p>
			<p>You can see that the version 3 pipeline ran three times.</p>
			<ol>
				<li value="7">Now, let's <a id="_idIndexMarker650"/>check that the third version of the pipeline output a commit in the <strong class="source-inline">contour</strong> repository:<p class="source-code"><strong class="bold">pachctl list commit contour@master</strong></p></li>
			</ol>
			<p>This command should return similar output:</p>
			<p class="source-code">REPO    BRANCH COMMIT  FINISHED  SIZE  ORIGIN   PROGRESS DESCRIPTION</p>
			<p class="source-code">contour master 38eb403e62844f45939c6307bb0177c7 46 seconds ago 23.78KiB AUTO</p>
			<p>Now that we know how to update a pipeline without changes to the code, let's see the workflow when your code is in a Docker image, and you need to update that code.</p>
			<h2 id="_idParaDest-164"><a id="_idTextAnchor177"/>Updating your code</h2>
			<p>If your <a id="_idIndexMarker651"/>code is specified in a file that is embedded in a Docker image, you need to rebuild this Docker image every time you make changes to it, upload it to the Docker registry with a new version, update the version of the image inside of your pipeline specification, and then run the <strong class="source-inline">pachctl update pipeline</strong> command.</p>
			<p>Let's modify the <strong class="source-inline">contour.py</strong> file in the contour pipeline that we created in <a href="B17085_06_Final_SB_Epub.xhtml#_idTextAnchor156"><em class="italic">Chapter 6</em></a>, <em class="italic">Creating Your First Pipeline</em>. You need to have an account in a Docker registry to complete this section. If you do not have an account, you can create a free account on Docker Hub. All images referenced in this book are stored in Docker Hub and we will use Docker Hub as an example. If you are using any other Docker image registry, follow that registry's documentation to log in and upload images.</p>
			<p>We will also need the Dockerfile for this pipeline to build new images:</p>
			<ol>
				<li value="1">If you have not done so yet, download the Dockerfile from <a href="https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter06-Creating-Your-First-Pipeline">https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter06-Creating-Your-First-Pipeline</a>. </li>
				<li>Configure <a id="_idIndexMarker652"/>your Docker Hub account by signing<a id="_idIndexMarker653"/> up at <a href="https://hub.docker.com/">https://hub.docker.com/</a>.</li>
				<li>When logged in to Docker Hub, click <strong class="bold">Create Repository</strong>.</li>
				<li>Name your repository and write a short description. For this example, we will be using a public registry, but Pachyderm supports private registries as well: </li>
			</ol>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="Images/B17085_07_005.jpg" alt="Figure 7.5 – Creating a Docker Hub registry&#13;&#10;" width="1019" height="890"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.5 – Creating a Docker Hub registry</p>
			<ol>
				<li value="5">Click <strong class="bold">Create</strong>.</li>
				<li>Go to the terminal on your machine and run the following:<p class="source-code"><strong class="bold">docker login</strong></p></li>
				<li>Provide <a id="_idIndexMarker654"/>your Docker Hub credentials to log in to Docker Hub. You should see the following output:<p class="source-code">Login Succeeded</p></li>
				<li>Open the <strong class="source-inline">contour.py</strong> file for editing.</li>
				<li>Let's make a very small change in our code—on <em class="italic">line 18</em>, change <strong class="source-inline">linewidth</strong> to <strong class="source-inline">1</strong>. Here is how it should look:<p class="source-code"><strong class="bold">ax.plot(contour[:, 1], contour[:, 0], linewidth=1)</strong></p></li>
				<li>Save your changes and exit.</li>
				<li>For these changes to take effect in our Pachyderm pipeline, we need to build a new Docker image. You need to have the Dockerfile in the current directory for the next command to work. Run the following command:<p class="source-code"><strong class="bold">docker build . -t &lt;your-registry&gt;/contour-histogram:1.1</strong></p></li>
			</ol>
			<p>Replace <strong class="source-inline">&lt;your-registry&gt;</strong> with the name of your Docker Hub repository that you have created by following the preceding steps. You should see output similar to the following text:</p>
			<p class="source-code">Sending build context to Docker daemon 2.325GB</p>
			<p class="source-code">Step 1/10 : FROM ubuntu:18.04</p>
			<p class="source-code"> ---&gt; 3339fde08fc3</p>
			<p class="source-code">…</p>
			<p class="source-code"><strong class="bold">Step 9/10 : ADD contour.py /contour.py</strong></p>
			<p class="source-code"> ---&gt; 4fb17a5f1f0b</p>
			<p class="source-code">Step 10/10 : ADD histogram.py /histogram.py</p>
			<p class="source-code"> ---&gt; e64f4cb9ecb1</p>
			<p class="source-code">Successfully built e64f4cb9ecb1</p>
			<p>The first time you build a Docker image, it might take some time. Note that in <strong class="source-inline">Step 9</strong> in the preceding output, Docker adds your updated <strong class="source-inline">contour.py</strong> script.</p>
			<ol>
				<li value="12">The <a id="_idIndexMarker655"/>next step is to upload your image to your Docker registry. You could also first mount your Docker image locally and test it before uploading. To mount your Docker image locally, run the following:<p class="source-code"><strong class="bold">docker save &lt;your-registry&gt;/contour-history:1.1 | (\</strong></p><p class="source-code"><strong class="bold">  eval $(minikube docker-env)</strong></p><p class="source-code"><strong class="bold">  docker load</strong></p><p class="source-code"><strong class="bold">)</strong></p></li>
			</ol>
			<p>This command takes some time to run, but it is very handy when you need to test something without constantly pushing new images to Docker Hub. We recommend that you mount your image locally, run your pipeline, and when ready, upload it to Docker Hub.</p>
			<p>Or, if uploading directly to Docker Hub, run the following:</p>
			<p class="source-code"><strong class="bold">docker push &lt;your-registry&gt;/contour-history:1.1</strong></p>
			<ol>
				<li value="13">After you load your image, you need to update your pipeline specification with the new version of your pipeline. Assign a new version number every time you build a new image so that you keep track of your changes. To update the image version in the pipeline specification, open the <strong class="source-inline">contour.yaml</strong> file and change the following online number <strong class="source-inline">9</strong>:<p class="source-code"><strong class="bold">9  image: &lt;your-registry&gt;/contour-histogram:1.1</strong></p></li>
				<li>Now, you can run your updated pipeline with the new code. Let's run the <strong class="source-inline">update</strong> command with the <strong class="source-inline">--reprocess</strong> flag to see how our changes have affected the result:<p class="source-code"><strong class="bold">pachctl update pipeline -f contour.yaml --reprocess</strong></p></li>
			</ol>
			<p>In the<a id="_idIndexMarker656"/> following screenshot, you can see the comparison between the two versions. We have the first version on the left with a visibly thicker contour than the new version on the right:</p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="Images/B17085_07_006.jpg" alt="Figure 7.6 – Comparing the results of the pipeline version&#13;&#10;" width="867" height="487"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.6 – Comparing the results of the pipeline version</p>
			<p>We have learned how to update Pachyderm pipelines. This method works for any language or framework. Pachyderm also provides built-in <strong class="source-inline">Docker build</strong> and <strong class="source-inline">Docker push</strong> commands that you could use. However, we suggest that you follow the process described previously as it seems to be more familiar to the majority of engineers, as well as more transparent.</p>
			<h1 id="_idParaDest-165"><a id="_idTextAnchor178"/>Running maintenance operations</h1>
			<p>Like with <a id="_idIndexMarker657"/>every system or tool, Pachyderm might require periodic maintenance, upgrades, and troubleshooting. In the following sections, we will discuss the most important aspects of pipeline maintenance.</p>
			<h2 id="_idParaDest-166"><a id="_idTextAnchor179"/>Troubleshooting your pipeline</h2>
			<p>In this section, you<a id="_idIndexMarker658"/> will learn how to troubleshoot your pipeline.</p>
			<p>Your <a id="_idIndexMarker659"/>pipelines might fail for the following reasons:</p>
			<ul>
				<li><strong class="bold">Error in your code</strong>: This <a id="_idIndexMarker660"/>type of error occurs when something in your code is incorrect, such as a resource is not available or an incorrect value is specified. Fixing this type of error involves troubleshooting your code. You could try to do it locally before testing it inside Pachyderm.</li>
				<li><strong class="bold">Pipeline specification error</strong>: This<a id="_idIndexMarker661"/> type of error occurs when something is incorrect in the pipeline specification; for example, a pipeline cannot pull the Docker image. This often happens when a wrong image version is specified or there is a network issue.</li>
				<li><strong class="bold">Resource-related error</strong>: This<a id="_idIndexMarker662"/> type of error occurs when your cluster runs out of memory or has a similar resource constraint issue.</li>
			</ul>
			<p>Pachyderm provides built-in functionality for pipeline troubleshooting through the <strong class="source-inline">pachctl logs</strong> command and you could also use Kubernetes-native tools to troubleshoot your pipelines. Since each Pachyderm pipeline is a Kubernetes Pod, you can use Kubernetes logging and debugging tools to troubleshoot them.</p>
			<p>To detect and troubleshoot Pachyderm pipeline errors, complete the following steps:</p>
			<ol>
				<li value="1">When a pipeline fails, you should see it in the pipeline status:<p class="source-code"><strong class="bold">pachctl list pipeline</strong></p></li>
			</ol>
			<p>Here is an example output of a failed pipeline:</p>
			<p class="source-code">NAME    VERSION INPUT    CREATED        STATE / LAST JOB    DESCRIPTION</p>
			<p class="source-code">contour 1       photos:/ 28 seconds ago <strong class="bold">crashing</strong> / starting A pipeline that identifies contours on an image.</p>
			<ol>
				<li value="2">To <a id="_idIndexMarker663"/>troubleshoot this pipeline, we <a id="_idIndexMarker664"/>need to view the logs for the pipeline or the job. To view the logs for the pipeline, run the following:<p class="source-code"><strong class="bold">pachctl logs --pipeline=contour</strong></p></li>
			</ol>
			<p>The following is an example response:</p>
			<p class="source-code">container "user" in pod "pipeline-contour-v1-fmkxj" is waiting to start: image can't be pulled</p>
			<p>In the preceding example, the failure is pretty clear—the pipeline failed to pull the Docker image. This could be due to the wrong image version specified in the pipeline spec or a network issue. Verifying that the pipeline spec is correct will likely solve the problem.</p>
			<ol>
				<li value="3">The following text is an example of another common code error in the pipeline:<p class="source-code">Traceback (most recent call last):</p><p class="source-code">  File "/pos-tag.py", line 13, in &lt;module&gt;</p><p class="source-code">    with open('/pfs/out/pos-tag/pos-table.txt', 'w') as f:</p><p class="source-code">FileNotFoundError: [Errno 2] No such file or directory: '/pfs/out/contour/pos-table.txt'</p></li>
			</ol>
			<p>In the preceding example, the pipeline was not able to find a specified file. This is likely because the path to the file was specified incorrectly in the <strong class="source-inline">pos-tag.py</strong> file.</p>
			<ol>
				<li value="4">In some cases, you won't be able to see the job logs because the pipeline crashed before kicking off a job. However, in most cases, you should be able to view the logs for a job. To view the job logs, first get the hash of the job:<p class="source-code"><strong class="bold">pachctl list job</strong></p></li>
			</ol>
			<p>Here is an example output:</p>
			<p class="source-code">ID                               SUBJOBS PROGRESS CREATED       MODIFIED</p>
			<p class="source-code">5865a26e1795481d96ecf867075c4f35 1       2 minutes ago 2 minutes ago</p>
			<p>When<a id="_idIndexMarker665"/> you have a pipeline error, such <a id="_idIndexMarker666"/>as in the preceding output, the progress bar is yellow instead of green. This indicator gives you a clue that something is wrong in your code.</p>
			<ol>
				<li value="5">Use the job hash to view more information about the failure in the job logs:<p class="source-code"><strong class="bold">pachctl logs --job=contour@5865a26e1795481d96ecf867075c4f35</strong></p></li>
			</ol>
			<p>The output should give you more information about the failure.</p>
			<ol>
				<li value="6">Finally, you can use <strong class="source-inline">kubectl</strong> to analyze possible errors in your pipeline. Get the name of your pipeline Pod by running the following:<p class="source-code"><strong class="bold">kubectl get pod</strong></p></li>
			</ol>
			<p>You should see a similar response to the following:</p>
			<p class="source-code">NAME          READY   STATUS        RESTARTS   AGE</p>
			<p class="source-code">etcd-0         1/1     Running      0           6h10m</p>
			<p class="source-code">pachd-85d69d846-drgrk    1/1  Running 0         6h10m</p>
			<p class="source-code">pg-bouncer-84df8bdc58-7kzzg 1/1 Running 0       6h10m</p>
			<p class="source-code"><strong class="bold">pipeline-contour-v1-7dgwl 1/2  ImagePullBackOff 0    6m54s</strong></p>
			<p class="source-code">postgres-0     1/1     Running      0           6h10m</p>
			<p>You need to get logs for the pipeline Pod.</p>
			<ol>
				<li value="7">Get<a id="_idIndexMarker667"/> the Pod logs by running<a id="_idIndexMarker668"/> the following:<p class="source-code"><strong class="bold">kubectl describe pod pipeline-contour-v1-7dgw</strong></p><p class="callout-heading">Important note</p><p class="callout">The <strong class="bold">Events</strong> part <a id="_idIndexMarker669"/>of the Pod logs typically provides information about any issues. Read <a id="_idIndexMarker670"/>more about Kubernetes debugging and troubleshooting in the Kubernetes documentation at <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/">https://kubernetes.io/docs/tasks/debug-application-cluster/</a>.</p></li>
			</ol>
			<p>This is an example output that you will see:</p>
			<p class="source-code">...</p>
			<p class="source-code">Events:</p>
			<p class="source-code">...</p>
			<p class="source-code">Normal BackOff 3m7s (x20 over 8m6s)  kubelet, minikube <strong class="bold">Back-off pulling image "svekars/contour-histogram:1.2"</strong></p>
			<p>In this section, we have discussed basic troubleshooting operations. The best strategy is to get as many logs as possible, categorize the problem, and then troubleshoot accordingly. If the problem is in the user code, you likely will want to test your code locally before running it in Pachyderm. One limitation that has been recently introduced in Pachyderm is the limit of the number of pipelines that you can run in the free tier. You won't be able to run more than 16 pipelines and 8 workers unless you upgrade to a paid version. </p>
			<p>Next, we'll look into how to upgrade your cluster from one version to another.</p>
			<h2 id="_idParaDest-167"><a id="_idTextAnchor180"/>Upgrading your Pachyderm cluster</h2>
			<p>Pachyderm <a id="_idIndexMarker671"/>releases minor version upgrades on a regular basis. Upgrading between minor versions and patches, such as from version 1.13.0 to 1.13.1 or 1.12.4. to 1.13.0, is pretty straightforward, but moving between major versions, such as 1.13.0 to 2.0, might be a bit more disruptive. Let's review the process for each of these use cases. Upgrades to major versions do <a id="_idIndexMarker672"/>not happen often. Typically, Pachyderm releases a major version once every few years. Those types of upgrades involve breaking changes and likely will have specific instructions. Refer to the Pachyderm documentation for steps to perform a major upgrade.</p>
			<h3>Upgrading between patches and minor versions</h3>
			<p>When you are <a id="_idIndexMarker673"/>upgrading your Pachyderm cluster, you need to make sure you back up your data and pipelines, upgrade the version of <strong class="source-inline">pachctl</strong>, and then redeploy your cluster. If you are upgrading locally in a <strong class="source-inline">minikube</strong> environment, you might not need to use your backup, but create one for safety reasons. If you are redeploying into the same namespace, all your data should still be available. If you are using a cloud environment, then you'll need to redeploy in a new namespace.</p>
			<p>To upgrade from one <a id="_idIndexMarker674"/>patch or a minor version to another, complete the following steps:</p>
			<ol>
				<li value="1">Stop all pipelines that are currently running in your cluster:<p class="source-code"><strong class="bold">pachctl stop pipeline &lt;pipeline&gt;</strong></p></li>
				<li>Let's stop the <strong class="source-inline">contour</strong> pipeline:<p class="source-code"><strong class="bold">pachctl stop pipeline contour</strong></p></li>
				<li>Verify that the pipeline is suspended:<p class="source-code"><strong class="bold">pachctl list pipeline</strong></p></li>
			</ol>
			<p>You should see the following output:</p>
			<p class="source-code">NAME      VERSION INPUT     CREATED      STATE / LAST JOB  DESCRIPTION</p>
			<p class="source-code">contour   1       photos:/* 3 hours ago <strong class="bold">paused</strong> / success  A pipeline that identifies contours on an image.</p>
			<p>If you have any other pipelines running, stop them as well.</p>
			<ol>
				<li value="4">You <a id="_idIndexMarker675"/>need to make sure that all external data loading operations are suspended as well, if you have any automated services uploading data to Pachyderm.</li>
				<li>Just in <a id="_idIndexMarker676"/>case, save your <strong class="source-inline">pachd</strong>, <strong class="source-inline">etcd</strong>, and <strong class="source-inline">console</strong> service manifests to separate YAML files:<p class="source-code"><strong class="bold">kubectl get svc/pachd -o yaml &gt; pachd_backup.yaml</strong></p><p class="source-code"><strong class="bold">kubectl get svc/etcd -o yaml &gt; etcd_backup.yaml</strong></p><p class="source-code"><strong class="bold">kubectl get svc/dash -o yaml &gt; dash_backup.yaml</strong></p></li>
			</ol>
			<p>If your upgrade goes wrong, you should be able to restore from these manifests manually.</p>
			<ol>
				<li value="6">Back up your cluster:<p class="source-code"><strong class="bold">pachctl extract --no-auth --no-enterprise &gt; my-pachyderm-backup</strong></p></li>
			</ol>
			<p>In the preceding example, we have specified the <strong class="source-inline">--no-auth</strong> and <strong class="source-inline">--no-enterprise</strong> flags. If you are using an enterprise version of Pachyderm or have enabled authentication, run this command without these flags.</p>
			<ol>
				<li value="7">Verify that the <strong class="source-inline">values.yaml</strong> file has updated values. Specifically, verify that the following autogenerated values are correct:<p class="source-code">global:</p><p class="source-code">      postgresql.postgresqlPassword</p><p class="source-code">pachd:</p><p class="source-code">      clusterDeploymentID</p><p class="source-code">      rootToken</p><p class="source-code">      enterpriseSecret</p><p class="source-code">      oauthClientSecret</p></li>
				<li>Upgrade your <strong class="source-inline">pachctl</strong> version, as in the following example:<p class="source-code"><strong class="bold">brew upgrade pachyderm/tap/pachctl@2.0</strong></p></li>
			</ol>
			<p>Use the package manager in your system to upgrade.</p>
			<ol>
				<li value="9">Verify<a id="_idIndexMarker677"/> that the Pachyderm version was upgraded:<p class="source-code"><strong class="bold">pachctl version --client-only</strong></p></li>
			</ol>
			<p>You <a id="_idIndexMarker678"/>should see the upgraded version in the output. In this case, it is <strong class="source-inline">2.0.0</strong>:</p>
			<p class="source-code">pachctl             2.0.0</p>
			<ol>
				<li value="10">Use the <strong class="source-inline">helm upgrade</strong> command to redeploy your cluster:<p class="source-code"><strong class="bold">helm upgrade pachd -f &lt;pachyderm_deployment&gt;_my_values.yaml pachyderm/pachyderm</strong></p></li>
				<li>Run <strong class="source-inline">kubectl get pod</strong> until you see the Pachyderm Pods running like this:<p class="source-code">NAME                      READY   STATUS  RESTARTS AGE</p><p class="source-code">console-5db94c4565-pzjft     1/1    Running   0     1m</p><p class="source-code">etcd-0                       1/1    Running   0     1m</p><p class="source-code">pachd-84984bf656-g4w8s       1/1    Running   0     1m</p><p class="source-code">pg-bouncer-7f47f5c567-zwg8d  1/1    Running   0     1m</p><p class="source-code">postgres-0                   1/1    Running   0     1m </p></li>
				<li>Check that <strong class="source-inline">pachd</strong> is running:<p class="source-code"><strong class="bold">pachctl version</strong></p></li>
			</ol>
			<p>This command should return an output similar to this:</p>
			<p class="source-code">COMPONENT           VERSION</p>
			<p class="source-code">pachctl             2.0.0</p>
			<p class="source-code">pachd               2.0.0</p>
			<ol>
				<li value="13">If you are in a cloud environment, use the following command to restore your configuration from the backup that you have created:<p class="source-code"><strong class="bold">pachctl restore &lt; my-pachyderm-backup</strong></p></li>
				<li>Check<a id="_idIndexMarker679"/> that your pipelines <a id="_idIndexMarker680"/>and repositories are in place:<p class="source-code"><strong class="bold">pachctl list pipeline &amp;&amp; pachctl list repo</strong></p></li>
			</ol>
			<p>The system response should look similar to this:</p>
			<p class="source-code">NAME    CREATED        SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code">contour 49 seconds ago 23.78KiB      Output repo for ...</p>
			<p class="source-code">photos  49 seconds ago 25.21KiB</p>
			<p class="source-code">NAME    VERSION INPUT CREATED  STATE / LAST JOB DESCRIPTION</p>
			<p class="source-code">contour 1       photos:/* 6 minutes ago paused / success A pipeline that identifies contours on an image.</p>
			<p>We have successfully restored our repositories and pipelines in our newly deployed cluster.</p>
			<h2 id="_idParaDest-168"><a id="_idTextAnchor181"/>Cleaning up</h2>
			<p>After <a id="_idIndexMarker681"/>you are done experimenting, you might want to clean up your cluster so that you start your next experiment with a fresh install. To clean up the environment, run the following commands:</p>
			<ol>
				<li value="1">Delete all pipelines and repositories:<p class="source-code"><strong class="bold">pachctl delete pipeline –all &amp;&amp; pachctl delete repo --all</strong></p></li>
				<li>Verify that no repositories and pipelines exist in your cluster:<p class="source-code"><strong class="bold">pachctl list repo &amp;&amp; pachctl list pipeline</strong></p></li>
			</ol>
			<p>You should see the following output:</p>
			<p class="source-code">NAME CREATED SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code">NAME VERSION INPUT CREATED STATE / LAST JOB DESCRIPTION</p>
			<p>You have <a id="_idIndexMarker682"/>successfully cleaned up your cluster.</p>
			<h1 id="_idParaDest-169"><a id="_idTextAnchor182"/>Summary</h1>
			<p>In this chapter, we have learned about some of the most important Pachyderm operations that you will need to perform during the lifetime of your Pachyderm cluster. We learned about the various ways to load data into Pachyderm, including how to do it with a messaging system. We learned how to update your pipelines, build Docker images, and mount them locally or upload them to a Docker image registry. Finally, we learned about some basic troubleshooting techniques and upgrading between patches and minor versions.</p>
			<p>In the next chapter, we will implement an end-to-end machine learning workflow and learn more about deploying more complex multi-step Pachyderm pipelines.</p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor183"/>Further reading</h1>
			<ul>
				<li>Docker Hub Quickstart: <a href="https://docs.docker.com/docker-hub/">https://docs.docker.com/docker-hub/</a></li>
				<li>Kubernetes monitoring, logging, and debugging: <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/">https://kubernetes.io/docs/tasks/debug-application-cluster/</a></li>
				<li>Pachyderm build pipelines: <a href="https://docs.pachyderm.com/latest/how-tos/developer-workflow/build-pipelines/">https://docs.pachyderm.com/latest/how-tos/developer-workflow/build-pipelines/</a></li>
				<li>Dua, D. and Graff, C. (2019). <em class="italic">UCI Machine Learning Repository</em> (<a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>). Irvine, CA: University of California, School of Information and Computer Science.</li>
			</ul>
		</div>
	</div></body></html>