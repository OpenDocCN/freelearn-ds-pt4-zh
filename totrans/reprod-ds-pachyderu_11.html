<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer091">
			<h1 id="_idParaDest-188"><em class="italic"><a id="_idTextAnchor202"/>Chapter 9</em>: Distributed Hyperparameter Tuning with Pachyderm</h1>
			<p>In <a href="B17085_08_Final_SB_Epub.xhtml#_idTextAnchor184"><em class="italic">Chapter 8</em></a>, <em class="italic">Creating an End-to-End Machine Learning Workflow</em>, we implemented an <strong class="bold">End-to-End</strong> (<strong class="bold">E2E</strong>) <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) workflow based on a <strong class="bold">Named-Entity Recognition</strong> (<strong class="bold">NER</strong>) pipeline example. This was a multi-step pipeline that included many computational stages, including data cleaning, <strong class="bold">Part-Of-Speech</strong> (<strong class="bold">POS</strong>) tagging, model training, and running the new model against various data. Our goal was to find the main characters in the story, which we successfully achieved.</p>
			<p>In this chapter, we will explore various strategies that can be implemented to select optimal parameters for an ML problem. This technique is called <strong class="bold">hyperparameter tuning</strong> or optimization. In the second part of this chapter, we will implement a hyperparameter tuning pipeline based on a house price prediction example.</p>
			<p>This chapter includes the following topics:</p>
			<ul>
				<li>Reviewing hyperparameter tuning techniques and strategies</li>
				<li>Creating a hyperparameter tuning pipeline in Pachyderm</li>
			</ul>
			<h1 id="_idParaDest-189"><a id="_idTextAnchor203"/>Technical requirements</h1>
			<p>This chapter requires you to have specific components installed and configured.</p>
			<p>For a local macOS installation, you should have the following:</p>
			<ul>
				<li>macOS Mojave, Catalina, Big Sur, or later</li>
				<li>Docker Desktop for Mac 10.14</li>
				<li><strong class="source-inline">minikube</strong> v1.9.0 or later</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.0 or later</li>
				<li>Pachyderm 2.0.0 or later</li>
			</ul>
			<p>For a local Windows installation, you should have the following:</p>
			<ul>
				<li>Windows Pro 64-bit v10 or later</li>
				<li><strong class="bold">Windows Subsystem for Linux</strong> (<strong class="bold">WSL</strong>) 2 or later</li>
				<li>Microsoft PowerShell v6.2.1 or later</li>
				<li>Hyper-V</li>
				<li><strong class="source-inline">minikube</strong> v1.9.0 or later</li>
				<li><strong class="source-inline">kubectl</strong> v1.18 or later</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.0 or later</li>
				<li>Pachyderm 2.0.0 or later</li>
			</ul>
			<p>For an <strong class="bold">Amazon Elastic Kubernetes Service</strong> (<strong class="bold">Amazon EKS</strong>) installation, you should have the following:</p>
			<ul>
				<li><strong class="source-inline">kubectl</strong> v.18 or later</li>
				<li><strong class="source-inline">eksctl</strong></li>
				<li><strong class="source-inline">aws-iam-authenticator</strong></li>
				<li><strong class="source-inline">pachctl</strong> 2.0.0 or later</li>
				<li>Pachyderm 2.0.0 or later</li>
			</ul>
			<p>For a Microsoft Azure cloud installation, you should have the following:</p>
			<ul>
				<li><strong class="source-inline">kubectl</strong> v.18 or later</li>
				<li>The <strong class="bold">Azure Command-Line Interface</strong> (<strong class="bold">Azure CLI</strong>)</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.0 or later</li>
				<li>Pachyderm 2.0.0 or later</li>
				<li><strong class="source-inline">jq</strong> 1.5 or later</li>
			</ul>
			<p>For a <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>) cloud installation, you should have the following:</p>
			<ul>
				<li>Google Cloud <strong class="bold">Software Development Kit</strong> (<strong class="bold">SDK</strong>) v124.0.0. or later</li>
				<li><strong class="source-inline">kubectl</strong> v.18 or later</li>
				<li><strong class="source-inline">pachctl</strong> 2.0.0 or later</li>
				<li>Pachyderm 2.0.0 or later</li>
			</ul>
			<p>To be able to run the pipelines in this chapter, you do not need any special hardware. If you are running your Pachyderm cluster locally, any modern laptop should support all operations in this section. If you are running Pachyderm in a cloud platform, you will need to have a <strong class="bold">Persistent Volume</strong> (<strong class="bold">PV</strong>). See <a href="B17085_05_Final_SB_Epub.xhtml#_idTextAnchor123"><em class="italic">Chapter 5</em></a>, <em class="italic">Installing Pachyderm on a Cloud Platform</em>, for more details.</p>
			<p>All scripts and data described in this chapter are available at <a href="https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter09-Distributed-Hyperparameter-Tuning-with-Pachyderm">https://github.com/PacktPublishing/Reproducible-Data-Science-with-Pachyderm/tree/main/Chapter09-Distributed-Hyperparameter-Tuning-with-Pachyderm</a>.</p>
			<p>Now that we have reviewed the technical requirements for this chapter, let's take a closer look at our pipeline.</p>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor204"/>Reviewing hyperparameter tuning techniques and strategies</h1>
			<p><strong class="bold">Hyperparameter tuning</strong> or <strong class="bold">hyperparameter optimization</strong> is a technique that ML professionals<a id="_idIndexMarker746"/> use to determine the best parameters<a id="_idIndexMarker747"/> to solve a specific ML problem. In different problems, you'd need to tune different types of parameters, such as weights in neural networks, or the number of trees in the Random Forest algorithm, or the learning rate of your model. Ultimately, selecting the best parameters helps you determine which method is best to solve a problem. A data scientist needs to understand the tunable parameters in the algorithm they use to be able to optimize them correctly.</p>
			<p>There are a number of ML algorithms that help solve the hyperparameter optimization problem. Let's review the most common ones.</p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor205"/>Grid search</h2>
			<p><strong class="bold">Grid search</strong> is the simplest algorithm and is sometimes called a <em class="italic">brute-force</em> approach to hyperparameter<a id="_idIndexMarker748"/> optimization. This method calculates the optimum values of hyperparameters.</p>
			<p>In Grid search, you typically<a id="_idIndexMarker749"/> define such hyperparameters as<a id="_idIndexMarker750"/> learning rate, dropout rate, or batch size. Then, you define a range of possible values. After that, the algorithm runs and searches for all possible configurations.</p>
			<p>A disadvantage of Grid search is that it is computationally expensive and is typically used on a smaller set of hyperparameters.</p>
			<p>Still, Grid search is a popular hyperparameter tuning algorithm and is the easiest one to understand. </p>
			<p>The following diagram illustrates Grid search:</p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="Images/B17085_09_001.jpg" alt="Figure 9.1 – Grid search&#13;&#10;" width="681" height="681"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – Grid search</p>
			<p>Now, let's look at another hyperparameter optimization technique called <strong class="bold">Random search</strong>.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor206"/>Random search</h2>
			<p><strong class="bold">Random search</strong> is similar to Grid search, but instead<a id="_idIndexMarker751"/> of checking all possible combinations, it selects them randomly, which often results in better performance and<a id="_idIndexMarker752"/> less computational time and resources. In many cases, Random search has proven to find the best combination faster than the Grid search method.</p>
			<p>This diagram illustrates Random search:</p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="Images/B17085_09_002.jpg" alt="Figure 9.2 – Random search&#13;&#10;" width="705" height="705"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.2 – Random search</p>
			<p>Now that we know what Random search<a id="_idIndexMarker753"/> and Grid search methods are, let's learn about a slightly<a id="_idIndexMarker754"/> more complex hyperparameter tuning method called Bayesian optimization.</p>
			<h2 id="_idParaDest-193"><a id="_idTextAnchor207"/>Bayesian optimization</h2>
			<p>Bayesian optimization is a hyperparameter tuning technique<a id="_idIndexMarker755"/> that finds the minimum of a function. The main difference between Bayesian optimization<a id="_idIndexMarker756"/> and Grid search/Random search is that it keeps track of previous iterations and evaluation results and therefore uses probability (<em class="italic">P</em>) to predict the best combination.</p>
			<p>A model trained with Bayesian optimization provides better results with more available data. Because it takes into account past results, such a model can find the best results with fewer iterations. Based on previous iterations, Bayesian optimization builds a posterior model that is closer to reality.</p>
			<p>This diagram demonstrates the concept of Bayesian optimization:</p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="Images/B17085_09_003.jpg" alt="Figure 9.3 – Bayesian optimization&#13;&#10;" width="1498" height="508"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – Bayesian optimization</p>
			<p>We have learned about the three main hyperparameter optimization techniques. There are more<a id="_idIndexMarker757"/> available, but these three seem to be the most popular and widely used. Now, let's look into model<a id="_idIndexMarker758"/> evaluation metrics that we can use to determine the performance of our models. Because the problem we are going to discuss later in this chapter is a regression problem, we will only consider regression evaluation metrics.</p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor208"/>Regression evaluation metrics</h2>
			<p>Just picking the right algorithm is only half of our success. We need to use an evaluation<a id="_idIndexMarker759"/> metric that determines the performance of our model. Evaluation metrics<a id="_idIndexMarker760"/> can be applied for various parameters to determine the best parameters. They can also be applied to multiple algorithms so that they can be compared and presented for further analysis.</p>
			<p>Because the house price prediction example is a regression problem, we will only consider regression evaluation metrics. The most common evaluation metrics include the following:</p>
			<ul>
				<li><strong class="bold">R-squared</strong> (<strong class="bold">R2</strong>)</li>
				<li><strong class="bold">Mean Square Error</strong> (<strong class="bold">MSE</strong>)</li>
				<li><strong class="bold">Mean Absolute Error</strong> (<strong class="bold">MAE</strong>)</li>
			</ul>
			<p>These metrics<a id="_idIndexMarker761"/> are known statistical methods for evaluating performance.</p>
			<h3>R2</h3>
			<p>R2 is an evaluation<a id="_idIndexMarker762"/> metric that is used in statistics<a id="_idIndexMarker763"/> to determine the variance in a dependent variable or how close the data is to the regression line. The parameter is measured as a percentage. If you get an R2 value of 100%, this means that the data fits the regression model perfectly. However, other values are acceptable, including 75%, 50%, and so on.</p>
			<p>There are many ways to express R2 in a formula, but the simplest one looks like this:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="Images/Formula_B17085_09_001.jpg" alt="" width="1044" height="73"/>
				</div>
			</div>
			<p>If you are not that familiar with math, don't worry about this too much as in our code, we use the <strong class="source-inline">scikit-learn</strong> module to calculate R2.</p>
			<p>Now that you have a general understanding of R2, let's learn about another evaluation metric called MSE.</p>
			<h3>MSE</h3>
			<p>MSE is an evaluation metric that estimates the difference between the predicted values<a id="_idIndexMarker764"/> with the observed value. MSE is highly influenced<a id="_idIndexMarker765"/> by outliers, values that are outside of the standard range. Therefore, you must remove outliers before you evaluate your model.</p>
			<p>The lower the MSE value, the closer the result is to the real value.</p>
			<p>For example, if you have a model that predicts salary based on years of service, your model MSE might be 200, meaning that the predicted value was <strong class="bold">US Dollars</strong> (<strong class="bold">USD</strong>) $200 higher than the actual value. Depending on the sample size, the overall scale, and expected precision, this number might have different significance.</p>
			<p>The following formula is used to calculate MSE:</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="Images/Formula_B17085_09_002.jpg" alt="" width="856" height="73"/>
				</div>
			</div>
			<p>The following values are used in this formula:</p>
			<ul>
				<li><em class="italic">n</em>: A sample size</li>
				<li><em class="italic">observed</em>: The actual value</li>
				<li><em class="italic">predicted</em>: The value that the model has predicted</li>
			</ul>
			<p>As with R2, don't worry about the formula too much as we will use the <strong class="source-inline">scikit-learn</strong> MSE module to calculate MSE.</p>
			<p>Now, let's learn about MAE. </p>
			<h3>MAE</h3>
			<p>MAE is another evaluation metric often used with regression models. It calculates an average<a id="_idIndexMarker766"/> of total errors in your model or an absolute<a id="_idIndexMarker767"/> difference between real and forecasted values. If we were to express MAE in the simplest formula, it would look like this:</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="Images/Formula_B17085_09_003.jpg" alt="" width="856" height="59"/>
				</div>
			</div>
			<p>This metric is provided for your information only. We will not use it in our calculation. However, you can try it if you'd like by using the <strong class="source-inline">scikit-learn</strong> MAE module as well.</p>
			<p>Apart from these metrics, there are a number<a id="_idIndexMarker768"/> of other metrics that can help you evaluate your model, including <strong class="bold">Root MSE</strong> (<strong class="bold">RMSE</strong>) and <strong class="bold">Adjusted R2</strong>. However, the ones that we mentioned previously are the most commonly<a id="_idIndexMarker769"/> used and the easiest to understand.</p>
			<p>Now that we have learned<a id="_idIndexMarker770"/> about the methodology, evaluation metrics, and the algorithms<a id="_idIndexMarker771"/> we will use to configure hyperparameter tunning in Pachyderm, let's review the actual example, the model, the code, and the pipeline specifications. By the end of the next section, we will have a working hyperparameter tuning example in Pachyderm.</p>
			<h1 id="_idParaDest-195"><a id="_idTextAnchor209"/>Creating a hyperparameter tuning pipeline in Pachyderm</h1>
			<p>In this section, we will explore<a id="_idIndexMarker772"/> our hyperparameter tuning pipeline and will create all the required attributes<a id="_idIndexMarker773"/> in Pachyderm to run our example.</p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor210"/>Example overview</h2>
			<p>The house price<a id="_idIndexMarker774"/> prediction challenge is one of the classic ML examples of hyperparameter tunning optimization. It might not sound that complicated and may even be easy to predict based on your empirical experience. Likely, you know the area where you live pretty well and can estimate the price of houses based on square footage, number of rooms, adjacent land plot, and other parameters.</p>
			<p>This information<a id="_idIndexMarker775"/> can be represented in a form of a <strong class="bold">two-dimensional</strong> (<strong class="bold">2D</strong>) array or a table with mentioned parameters. Here<a id="_idIndexMarker776"/> is an example of such a table:</p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="Images/B17085_09_Table_01.jpg" alt="Figure 9.4 – Sample housing data&#13;&#10;" width="1186" height="354"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – Sample housing data</p>
			<p>Based on this information, you can predict the price of a house with similar characteristics without using any ML model and just by looking at these numbers.</p>
			<p>But imagine that all the data you have is a <strong class="bold">Comma-Separated Values</strong> (<strong class="bold">CSV</strong>) file with thousands of rows and 60+ columns. You do<a id="_idIndexMarker777"/> not know anything about the area, and you haven't ever lived there. Imagine that you want to predict house prices continuously based on data that changes all the time. That's where creating a highly performing ML model comes in handy.</p>
			<p>In our example, we will use a dataset that is available for free on <strong class="bold">Kaggle</strong>, a free repository with code<a id="_idIndexMarker778"/> and data. If you ever want a dataset to play with, you can find many examples on Kaggle. Our dataset is available at <a href="https://www.kaggle.com/lespin/house-prices-dataset/">https://www.kaggle.com/lespin/house-prices-dataset/</a>. We will only use the <strong class="source-inline">train.csv</strong> version of this dataset as we will modify it to clean the data.</p>
			<p>The <strong class="source-inline">train.csv</strong> dataset includes <em class="italic">81</em> columns and <em class="italic">1,461</em> rows. You can view the <strong class="source-inline">data_description.txt</strong> file to review the column descriptions. The columns include the various parameters that affect the price of a house. Each row represents an example<a id="_idIndexMarker779"/> of a house sale with a specific sale price.</p>
			<p>Here is an extract from the dataset:</p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="Images/B17085_09_005.jpg" alt="Figure 9.5 – Extract from the housing dataset&#13;&#10;" width="690" height="237"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – Extract from the housing dataset</p>
			<p>We will attempt to create a model that we will train on our training data to predict house prices and will evaluate the performance of the model by using the R2 and MSE evaluation metrics that we discussed in the previous section.</p>
			<p>The following diagram demonstrates our model:</p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="Images/B17085_09_006.jpg" alt="Figure 9.6 – Hyperparameter tuning pipeline" width="1098" height="1420"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.6 – Hyperparameter tuning pipeline</p>
			<p>Now that we<a id="_idIndexMarker780"/> have a basic idea of our pipeline, let's review each step of our pipeline workflow in more detail.</p>
			<h2 id="_idParaDest-197"><a id="_idTextAnchor211"/>Creating an exploratory analysis pipeline</h2>
			<p>Our first pipeline explores<a id="_idIndexMarker781"/> the data and gives us some basic information about the dataset that we are using. Here<a id="_idIndexMarker782"/> is the pipeline specification of the exploratory analysis pipeline:</p>
			<p class="source-code">---</p>
			<p class="source-code"> pipeline:</p>
			<p class="source-code">   name: data-explore</p>
			<p class="source-code"> description: A pipeline that performs exploratory analysis.</p>
			<p class="source-code"> input:</p>
			<p class="source-code">   pfs:</p>
			<p class="source-code">     glob: "/*"</p>
			<p class="source-code">     repo: data</p>
			<p class="source-code"> transform:</p>
			<p class="source-code">   cmd:</p>
			<p class="source-code">   - python3</p>
			<p class="source-code">   - "/data-explore.py"</p>
			<p class="source-code">   image: svekars/hyperparameter-example:1.0</p>
			<p>This pipeline takes all data from the data repository located under <strong class="source-inline">/*</strong> and runs the <strong class="source-inline">data-explore.py</strong> script against it. The pipeline uses the <strong class="source-inline">hyperparameter-example:1.0</strong> Docker image.</p>
			<p>Let's review what's the <strong class="source-inline">data-explore.py</strong> script does. The script imports the following components: </p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import matplotlib.pyplot as plt</p>
			<p class="source-code">import seaborn as sns</p>
			<p>We will use <strong class="source-inline">pandas</strong> to manipulate CSV tables and represent them as <strong class="source-inline">DataFrame</strong> structures. <strong class="source-inline">pandas</strong> is an open source Python library that is widely used by data scientists for data operations, specifically 2D tabular data.</p>
			<p>We will use, familiar<a id="_idIndexMarker783"/> to us from previous sections, <strong class="source-inline">matplotlib</strong> in combination with the <strong class="source-inline">seaborn</strong> library to visualize<a id="_idIndexMarker784"/> the results of our computations. <strong class="source-inline">seaborn</strong> is based on <strong class="source-inline">matplotlib</strong> but provides more sophisticated and visually appealing graphs.</p>
			<p>The first part of the <strong class="source-inline">data-explore.py</strong> script reads the <strong class="source-inline">housing-train.csv</strong> file as a <strong class="source-inline">DataFrame</strong> from the <strong class="source-inline">data</strong> repository and computes a correlation matrix between all columns in our dataset by using the <strong class="source-inline">pandas.DataFrame.corr()</strong> method. The code then creates a heatmap of the created correlation matrix and saves it in the pipeline output repository. The code is illustrated in the following snippet:</p>
			<p class="source-code">plt.subplots(figsize=(20,15))</p>
			<p class="source-code"> data = pd.read_csv("/pfs/data/housing-train.csv", delimiter=',')</p>
			<p class="source-code"> dataset = data.corr().round(2)</p>
			<p class="source-code"> plt.subplots(figsize=(20,15))</p>
			<p class="source-code"> my_plot = sns.heatmap(dataset, annot=True,cmap='YlGnBu', linecolor='white')</p>
			<p class="source-code"> fig = my_plot.get_figure()</p>
			<p class="source-code"> fig.savefig('/pfs/out/heatmap.png', dpi=400)</p>
			<p>The second part of the code saves the types of data objects in a column. Typically, you use a different approach to analyzing and manipulating numerical and categorical data, which is why getting this information might be important. The code saves this information in a <strong class="source-inline">data-types.csv</strong> file and is illustrated here:</p>
			<p class="source-code">data_types = data.dtypes.to_frame('dtypes').reset_index()</p>
			<p class="source-code">data_types.to_csv('/pfs/out/data-types.csv', index=False)</p>
			<p>The third part of the script<a id="_idIndexMarker785"/> checks the columns for missing data, creates a table with percentages of columns<a id="_idIndexMarker786"/> that have missing data, and saves the table to <strong class="source-inline">no-data.csv</strong>, as illustrated in the following code snippet:</p>
			<p class="source-code">cols_no_data = data.isnull().sum() / data.shape[0] * 100.00</p>
			<p class="source-code">no_data = pd.DataFrame({'Column': data.columns, 'Percentage Missing': cols_no_data})</p>
			<p class="source-code">no_data.sort_values(by=['Percentage Missing'], inplace=True, ascending=False)</p>
			<p class="source-code">header = ["Column", "Percentage Missing"]</p>
			<p class="source-code">no_data.to_csv('/pfs/out/no-data.csv', columns = header, index=False)</p>
			<p>Let's create this pipeline, as follows:</p>
			<ol>
				<li>Verify that Pachyderm is up and running by executing the following command:<p class="source-code"><strong class="bold">pachctl version</strong></p></li>
			</ol>
			<p>This command returns the following output (your version of <strong class="source-inline">pachctl</strong> and <strong class="source-inline">pachd</strong> might be different):</p>
			<p class="source-code">COMPONENT           VERSION</p>
			<p class="source-code">pachctl             2.0.0</p>
			<p class="source-code">pachd               2.0.0</p>
			<ol>
				<li value="2">Create a data repository by running the following command:<p class="source-code"><strong class="bold">pachctl create repo data</strong></p></li>
			</ol>
			<p>This command<a id="_idIndexMarker787"/> does not return any output.</p>
			<ol>
				<li value="3">Move the <strong class="source-inline">housing-train.csv</strong> file to the master branch of the <strong class="source-inline">data</strong> repository by running<a id="_idIndexMarker788"/> the following command: <p class="source-code"><strong class="bold">pachctl put file data@master -f housing-train.csv</strong></p></li>
			</ol>
			<p>The system response should look like this:</p>
			<p class="source-code">housing-train.csv 460.68KB / 460.68 KB [=========] 0s 0.00 b/s</p>
			<ol>
				<li value="4">Verify that the file was added to the repository with the <strong class="source-inline">file</strong> type by running the following command:<p class="source-code"><strong class="bold">pachctl list file data@master</strong></p></li>
			</ol>
			<p>The system response should look like this:</p>
			<p class="source-code">NAME               TYPE SIZE</p>
			<p class="source-code">/housing-train.csv file 449.9KiB</p>
			<ol>
				<li value="5">Create a <strong class="source-inline">data-explore</strong> pipeline by using the <strong class="source-inline">data-explore.yaml</strong> file, as follows:<p class="source-code"><strong class="bold">pachctl create pipeline -f data-explore.yaml </strong></p></li>
			</ol>
			<p>This command does not return any response.</p>
			<ol>
				<li value="6">Verify that the pipeline was created by running the following command:<p class="source-code"><strong class="bold">pachctl list pipeline </strong></p></li>
			</ol>
			<p>Here is the system response that you should see:</p>
			<p class="source-code">NAME      VERSION INPUT   CREATED  STATE / LAST JOB   DESC</p>
			<p class="source-code">data-explore 1    data:/* 34 seconds ago running / running A pipeline that performs exploratory data analysis.</p>
			<p>Wait for the pipeline to finish running and display a <strong class="source-inline">success</strong> status for the last job.</p>
			<ol>
				<li value="7">List the repositories, as follows:<p class="source-code"><strong class="bold">pachctl list repo</strong></p></li>
			</ol>
			<p>You should<a id="_idIndexMarker789"/> see that the <strong class="source-inline">data-explore</strong> pipeline uploaded <strong class="source-inline">3.361MiB</strong> of data to the <strong class="source-inline">data-explore</strong> repository, as indicated<a id="_idIndexMarker790"/> in the following output:</p>
			<p class="source-code">NAME         CREATED        SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code">data-explore 46 seconds ago <strong class="bold">3.361MiB</strong>      Output repo for pipeline data-explore.</p>
			<p class="source-code">data         26 minutes ago 449.9KiB </p>
			<ol>
				<li value="8">Let's explore the data in the repository by running the following command:<p class="source-code"><strong class="bold">pachctl list file data-explore@master</strong></p></li>
			</ol>
			<p>You should see the following three files:</p>
			<p class="source-code">NAME            TYPE SIZE</p>
			<p class="source-code">/data-types.csv file 1.37KiB</p>
			<p class="source-code">/heatmap.png    file 3.359MiB</p>
			<p class="source-code">/no-data.csv    file 1.447KiB</p>
			<ol>
				<li value="9">Let's open the <strong class="source-inline">/data-types.csv file</strong>, as follows:<p class="source-code"><strong class="bold">pachctl get file data-explore@master:/data-types.csv </strong></p></li>
			</ol>
			<p>The file includes data types for each column, as we can see in the following code snippet:</p>
			<p class="source-code">index,dtypes</p>
			<p class="source-code">Id,int64</p>
			<p class="source-code">MSSubClass,int64</p>
			<p class="source-code">MSZoning,object</p>
			<p class="source-code">LotFrontage,float64</p>
			<p class="source-code">...</p>
			<ol>
				<li value="10">Let's look at<a id="_idIndexMarker791"/> what's in the <strong class="source-inline">no-data.csv</strong> file by running<a id="_idIndexMarker792"/> the following command:<p class="source-code"><strong class="bold">pachctl get file data-explore@master:/no-data.csv</strong></p></li>
			</ol>
			<p>Alternatively, you could also open the file in an application on your computer. For example, in macOS, you can open it in the <strong class="source-inline">Numbers</strong> application, like this:</p>
			<p class="source-code"><strong class="bold">pachctl get file data-explore@master:/no-data.csv | open -f -a "Numbers"</strong></p>
			<p>This file contains information about columns and the percentage of missing data in these<a id="_idIndexMarker793"/> columns. This is very useful for data cleaning. Some columns have more than 80% of missing data. These columns can be removed so that they don't interfere<a id="_idIndexMarker794"/> with our calculations. We will do that in our next pipeline. Here is a list of columns with the majority of data missing:</p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="Images/B17085_09_007.jpg" alt="Figure 9.7 – Columns with missing data&#13;&#10;" width="477" height="506"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – Columns with missing data</p>
			<ol>
				<li value="11">Now, let's look at the heatmap by running the following command: <p class="source-code"><strong class="bold">pachctl get file data-explore@master:/heatmap.png | open -f -a "Preview.app"</strong></p></li>
			</ol>
			<p>You should see the following heatmap that shows us a correlation between all columns in the dataset:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="Images/B17085_09_008.jpg" alt="Figure 9.8 – Heatmap of all parameters&#13;&#10;" width="1350" height="1170"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – Heatmap of all parameters</p>
			<p>This heatmap<a id="_idIndexMarker795"/> has too many parameters and is difficult to read. But even on this heatmap, we can<a id="_idIndexMarker796"/> see that some parameters affect the sale price more than others. For example, it looks as though the <strong class="source-inline">OverallQuality</strong> parameter affects the price the most, as well as the <strong class="source-inline">GrLivArea</strong> parameter (for <em class="italic">great living area</em>). We will try to narrow down our dataset to these parameters in our next pipeline step.</p>
			<p>We have explored<a id="_idIndexMarker797"/> the dataset and got a basic understanding<a id="_idIndexMarker798"/> of the data. Now, let's review our next pipeline, which will clean up the data based on our findings.</p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor212"/>Creating a data cleaning pipeline</h2>
			<p>Our next step is to<a id="_idIndexMarker799"/> create a pipeline that cleans our data. This pipeline will clean the data according<a id="_idIndexMarker800"/> to our findings in the previous section. Here is the pipeline specification:</p>
			<p class="source-code">---</p>
			<p class="source-code"> pipeline:</p>
			<p class="source-code">   name: data-clean</p>
			<p class="source-code"> description: A pipeline that removes empty cells from the CSV.</p>
			<p class="source-code"> input:</p>
			<p class="source-code">   pfs:</p>
			<p class="source-code">     glob: "/"</p>
			<p class="source-code">     repo: data</p>
			<p class="source-code"> transform:</p>
			<p class="source-code">   cmd:</p>
			<p class="source-code">   - python3</p>
			<p class="source-code">   - "/data-clean.py"</p>
			<p class="source-code">   image: svekars/hyperparameter-example:1.0</p>
			<p>This is a standard Pachyderm pipeline that takes the data from the <strong class="source-inline">data</strong> repository and runs the <strong class="source-inline">data-clean.py</strong> script against that data. The data, in this case, is our <strong class="source-inline">housing-train.csv</strong> dataset.</p>
			<p>Let's look at our <strong class="source-inline">data-clean.py</strong> script. The script imports the following components:</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">import matplotlib.pyplot as plt</p>
			<p class="source-code">import seaborn as sns</p>
			<p class="source-code">from pandas import Series</p>
			<p>These components are similar to the ones in the <strong class="source-inline">data-explore</strong> pipeline. The new component that is being imported is <strong class="source-inline">pandas.Series</strong>, which we need to be able to save our data to a CSV file.</p>
			<p>The first part of our script reads<a id="_idIndexMarker801"/> the data from the <strong class="source-inline">housing-train.csv</strong> dataset as a <strong class="source-inline">DataFrame</strong>. Then, we drop<a id="_idIndexMarker802"/> the columns that have more than 40% of columns with missing data and save the columns that we have dropped in the <strong class="source-inline">col_drop.csv</strong> file, as follows:</p>
			<p class="source-code">data = pd.read_csv("/pfs/data/housing-train.csv", delimiter=',')</p>
			<p class="source-code">col_drop = set(data.count()[data.count()&lt;0.60*max(data.count())].index.tolist())</p>
			<p class="source-code">pd.Series(list(col_drop)).to_csv('/pfs/out/col_drop.csv', index=False)</p>
			<p>Next, we create a new correlation matrix that only includes the parameters that affect the <strong class="source-inline">SalePrice</strong> column with a coefficient of 0.5 or larger. We plot a new heatmap and save it in the <strong class="source-inline">heatmap2.png</strong> file, as follows:</p>
			<p class="source-code">data = data.drop((col_drop), axis=1)</p>
			<p class="source-code">corr = data.corr()</p>
			<p class="source-code">r_var = corr.SalePrice[(corr.SalePrice &gt; 0.5)]</p>
			<p class="source-code">r_col = list(r_var.index.values)</p>
			<p class="source-code">new_corr = data[r_col].corr()</p>
			<p class="source-code">plt.subplots(figsize=(20,15))</p>
			<p class="source-code">my_plot2 = sns.heatmap(new_corr, annot=True,cmap='YlGnBu', linecolor='white')</p>
			<p class="source-code">fig = my_plot2.get_figure()</p>
			<p class="source-code">fig.savefig('/pfs/out/heatmap2.png', dpi=400)</p>
			<p>Finally, we remove the columns that are not part of the new correlation matrix and save them in a new dataset called <strong class="source-inline">cleaned-data.csv</strong> in the pipeline output repository, as follows:</p>
			<p class="source-code">new_data = data.loc[:, data.columns.intersection(r_col)]</p>
			<p class="source-code">new_data.to_csv('/pfs/out/cleaned-data.csv', index=True)</p>
			<p>Now, let's create this data<a id="_idIndexMarker803"/> cleaning pipeline, as<a id="_idIndexMarker804"/> follows:</p>
			<ol>
				<li value="1">Verify that Pachyderm is up and running by executing the following command:<p class="source-code"><strong class="bold">pachctl version</strong></p></li>
			</ol>
			<p>Here is the output:</p>
			<p class="source-code">COMPONENT           VERSION</p>
			<p class="source-code">pachctl             2.0.0</p>
			<p class="source-code">pachd               2.0.0</p>
			<p>Your version of Pachyderm might be different.</p>
			<ol>
				<li value="2">Create a <strong class="source-inline">data-clean</strong> pipeline, as follows:<p class="source-code"><strong class="bold">pachctl create pipeline -f data-clean.yaml </strong></p></li>
			</ol>
			<p>No system response is returned.</p>
			<ol>
				<li value="3">Verify that Pachyderm has successfully created the pipeline by running the following command:<p class="source-code"><strong class="bold">pachctl list pipeline </strong></p></li>
			</ol>
			<p>Here is the system response that you should see:</p>
			<p class="source-code">NAME         VERSION INPUT   CREATED       STATE / LAST JOB  DESCRIPTION</p>
			<p class="source-code"><strong class="bold">data-clean</strong>   1       data:/ 6 seconds ago running / running A pipeline that removes empty cells from the CSV.</p>
			<p class="source-code">data-explore 1       data:/* 4 minutes ago running / success A pipeline that performs exploratory analysis.</p>
			<p>You need to wait for the pipeline to change its status to <strong class="source-inline">success</strong>.</p>
			<ol>
				<li value="4">When the pipeline has successfully finished running, list the repositories by running the following command:<p class="source-code"><strong class="bold">pachctl list repo</strong></p></li>
			</ol>
			<p>You should see<a id="_idIndexMarker805"/> that the <strong class="source-inline">data-clean</strong> pipeline added <strong class="source-inline">780.4KiB</strong> of data, as indicated<a id="_idIndexMarker806"/> in the following output:</p>
			<p class="source-code">NAME         CREATED        SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code"><strong class="bold">data-clean</strong>   42 seconds ago ≤ <strong class="bold">780.4KiB</strong>    Output repo for pipeline data-clean.</p>
			<p class="source-code">data-explore 3 minutes ago  ≤ 3.361MiB    Output repo for pipeline data-explore.</p>
			<p class="source-code">data         12 minutes ago ≤ 449.9KiB </p>
			<ol>
				<li value="5">Let's look at the data in the repository by running the following command:<p class="source-code"><strong class="bold">pachctl list file data-clean@master</strong></p></li>
			</ol>
			<p>The output should look like this:</p>
			<p class="source-code">NAME            TYPE SIZE</p>
			<p class="source-code">/cleaned-data.csv file 67.14KiB</p>
			<p class="source-code">/col_drop.csv     file 45B</p>
			<p class="source-code">/heatmap2.png     file 713.2KiB</p>
			<ol>
				<li value="6">Let's look at the columns that were dropped by running the following command:<p class="source-code"><strong class="bold">pachctl get file data-clean@master:/col_drop.csv</strong></p></li>
			</ol>
			<p>The file includes data types for each column, as we can see here:</p>
			<p class="source-code">0</p>
			<p class="source-code">PoolQC</p>
			<p class="source-code">Alley</p>
			<p class="source-code">FireplaceQu</p>
			<p class="source-code">MiscFeature</p>
			<p class="source-code">Fence</p>
			<p>These were the columns<a id="_idIndexMarker807"/> that had more than 40% columns empty.</p>
			<ol>
				<li value="7">We've also removed<a id="_idIndexMarker808"/> all the columns that we mapped in our new correlation matrix and that have a correlation coefficient of less than 0.5. Run the following command to see what our new correlation matrix looks like:<p class="source-code"><strong class="bold">pachctl get file data-clean@master:/heatmap2.png | open -f -a "Preview.app"</strong></p></li>
			</ol>
			<p>Here is the new heatmap:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="Images/B17085_09_009.jpg" alt="Figure 9.9 – Refined heatmap&#13;&#10;" width="1286" height="1063"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.9 – Refined heatmap</p>
			<p>This heatmap<a id="_idIndexMarker809"/> makes much more sense. We can clearly see the parameters that are the most<a id="_idIndexMarker810"/> prominent in determining the house sale price. Our dataset has been drastically reduced to 11 columns only and was saved to a new <strong class="source-inline">cleaned-data.csv</strong> file. Now, this strategy might not be ideal for every use case—you might decide to keep more parameters in your dataset to ensure and check if the model would perform better with more parameters. But for the purpose of this example, this should be sufficient.</p>
			<p>Now that we have<a id="_idIndexMarker811"/> cleaned the data, we also need to make sure that we remove any outliers or parameters that are outside of the standard range. We will do this in our next section.</p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor213"/>Creating a pipeline that removes outliers</h2>
			<p>Our next pipeline<a id="_idIndexMarker812"/> will evaluate outliers in our dataset and will remove them so that our model performance is not affected by them. We will again use a standard Pachyderm pipeline specification to achieve this goal. Here is the pipeline specification:</p>
			<p class="source-code">---</p>
			<p class="source-code"> pipeline:</p>
			<p class="source-code">   name: remove-outliers</p>
			<p class="source-code"> description: A pipeline that removes outliers from the dataset.</p>
			<p class="source-code"> input:</p>
			<p class="source-code">   pfs:</p>
			<p class="source-code">     glob: "/"</p>
			<p class="source-code">     repo: data-clean</p>
			<p class="source-code"> transform:</p>
			<p class="source-code">   cmd:</p>
			<p class="source-code">   - python3</p>
			<p class="source-code">   - "/outliers.py"</p>
			<p class="source-code">   image: svekars/hyperparameter-example:1.0</p>
			<p>The pipeline specification takes the cleaned data from the <strong class="source-inline">data-clean</strong> repository and applies the <strong class="source-inline">outliers.py</strong> Python script to that data. The pipeline uses the same Docker image as the two previous ones. </p>
			<p>The <strong class="source-inline">outliers.py</strong> script imports the same list of components as the scripts in our previous<a id="_idIndexMarker813"/> pipeline steps, including <strong class="source-inline">seaborn</strong>, <strong class="source-inline">matplotlib</strong>, and <strong class="source-inline">pandas</strong>.</p>
			<p>The script reads the data from the <strong class="source-inline">cleaned-data.csv</strong> file. Then, it creates a histogram that displays outliers in the dataset and saves that histogram to the <strong class="source-inline">histogram.png</strong> file. Then, we only leave 50% of the data that is within the middle range and remove the rest. We create another histogram that shows this new data. We drop the data from the dataset and save it in a new CSV file called <strong class="source-inline">removed-outliers-data.csv</strong>. The code is illustrated in the following snippet:</p>
			<p class="source-code">data = pd.read_csv("/pfs/data-clean/cleaned-data.csv", delimiter=',', encoding='utf-8')</p>
			<p class="source-code">my_plot=sns.boxplot(x=data['SalePrice'])</p>
			<p class="source-code">fig = my_plot.get_figure()</p>
			<p class="source-code">fig.savefig('/pfs/out/histogram.png', dpi=400)</p>
			<p class="source-code">q1 = data['SalePrice'].quantile(0.25)</p>
			<p class="source-code">q3 = data['SalePrice'].quantile(0.75)</p>
			<p class="source-code">iqr = q3-q1</p>
			<p class="source-code">lw = q1 - 1.5*iqr</p>
			<p class="source-code">uw = q3 + 1.5*iqr</p>
			<p class="source-code">dataset = data[(data['SalePrice']&gt;lw)&amp;(data['SalePrice']&lt;uw)]</p>
			<p class="source-code">plt.figure(figsize=(20,10))</p>
			<p class="source-code">my_plot2 = sns.histplot(data=dataset, x="SalePrice", color="orange", element="poly")</p>
			<p class="source-code">fig = my_plot2.get_figure()</p>
			<p class="source-code">fig.savefig('/pfs/out/histogram-outliers.png', dpi=400)</p>
			<p class="source-code">dataset.to_csv('/pfs/out/removed-outliers-data.csv', index=True)</p>
			<p>Now, let's create<a id="_idIndexMarker814"/> this pipeline, as follows:</p>
			<ol>
				<li value="1">Verify that Pachyderm is up and running by executing the following command:<p class="source-code"><strong class="bold">pachctl version</strong></p></li>
			</ol>
			<p>You should get an output similar to this:</p>
			<p class="source-code">COMPONENT           VERSION</p>
			<p class="source-code">pachctl             2.0.0</p>
			<p class="source-code">pachd               2.0.0</p>
			<p>Your version might be different.</p>
			<ol>
				<li value="2">Create a <strong class="source-inline">data-clean</strong> pipeline, as follows:<p class="source-code"><strong class="bold">pachctl create pipeline -f remove-outliers.yaml </strong></p></li>
			</ol>
			<p>This command does not return any output.</p>
			<ol>
				<li value="3">Check that the pipeline was created by running the following command:<p class="source-code"><strong class="bold">pachctl list pipeline </strong></p></li>
			</ol>
			<p>Here is the system response that you should see:</p>
			<p class="source-code">NAME            VERSION INPUT         CREATED       STATE / LAST JOB   DESCRIPTION</p>
			<p class="source-code">remove-outliers 1       data-clean:/ 5 seconds ago running / starting A pipeline that removes outliers from the dataset.</p>
			<p class="source-code">data-clean      1       data:/       4 minutes ago running / success  A pipeline that removes empty cells from the CSV.</p>
			<p class="source-code">data-explore    1       data:/*       8 minutes ago running / success  A pipeline that performs exploratory analysis.</p>
			<p>The <strong class="source-inline">remove-outliers</strong> pipeline is starting. You can run the <strong class="source-inline">pachctl list pipeline</strong> command several times until the pipeline succeeds. </p>
			<ol>
				<li value="4">List the repositories by running the following command:<p class="source-code"><strong class="bold">pachctl list repo</strong></p></li>
			</ol>
			<p>The <strong class="source-inline">remove-outliers</strong> repository should have <strong class="source-inline">413.7KiB</strong> of data uploaded to it, as indicated<a id="_idIndexMarker815"/> in the following output:</p>
			<p class="source-code">NAME            CREATED            SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code">remove-outliers About a minute ago 413.7KiB      Output repo for pipeline remove-outliers.</p>
			<p class="source-code">data-clean      49 minutes ago     780.4KiB      Output repo for pipeline data-clean.</p>
			<p class="source-code">data-explore    53 minutes ago     3.361MiB      Output repo for pipeline data-explore.</p>
			<p class="source-code">data            About an hour ago  449.9KiB</p>
			<ol>
				<li value="5">List the files in the repository by running the following command:<p class="source-code"><strong class="bold">pachctl list file remove-outliers@master</strong></p></li>
			</ol>
			<p>The output should look like this:</p>
			<p class="source-code">NAME                       TYPE SIZE</p>
			<p class="source-code">/histogram-outliers.png    file 290.8KiB</p>
			<p class="source-code">/histogram.png             file 52.8KiB</p>
			<p class="source-code">/removed-outliers-data.csv file 70.04KiB</p>
			<ol>
				<li value="6">Let's first open the <strong class="source-inline">histogram.png</strong> file by running the following command:<p class="source-code"><strong class="bold">pachctl get file remove-outliers@master:/histogram.png | open -f -a "Preview.app"</strong></p></li>
			</ol>
			<p>Here is what you should see:</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="Images/B17085_09_010.jpg" alt="Figure 9.10 – Outliers in the dataset&#13;&#10;" width="1031" height="854"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.10 – Outliers in the dataset</p>
			<p>This boxplot shows us that the majority of houses have a sale price in the range of $50,000 to $350,000, with most of these being in the range of $110,000 to $220,000. A few others are way outside of this range and might be even considered a separate category. Our pipeline removes outliers outside the main box.</p>
			<ol>
				<li value="7">Now, let's look at the histogram after the outliers were removed. We can do this by running the following command:<p class="source-code"><strong class="bold">pachctl get file remove-outliers@master:/histogram-outliers.png | open -f -a "Preview.app"</strong></p></li>
			</ol>
			<p>Here is the new histogram:</p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="Images/B17085_09_011.jpg" alt="Figure 9.11 – Histogram with removed outliers&#13;&#10;" width="1437" height="732"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.11 – Histogram with removed outliers</p>
			<p>We have removed some of the rows from our dataset and we now have 1,400 rows instead of the 1,481 rows that we had before.</p>
			<p>Now that we have finished cleaning our data, we can next train our model.</p>
			<h2 id="_idParaDest-200"><a id="_idTextAnchor214"/>Creating a training pipeline</h2>
			<p>Our next pipeline will train our model on a training part of our dataset. Here is the pipeline specification:</p>
			<p class="source-code">---</p>
			<p class="source-code"> pipeline:</p>
			<p class="source-code">   name: train</p>
			<p class="source-code"> description: A pipeline that trains the model with a selected estimator.</p>
			<p class="source-code"> input:</p>
			<p class="source-code">   pfs:</p>
			<p class="source-code">     glob: "/"</p>
			<p class="source-code">     repo: remove-outliers</p>
			<p class="source-code"> transform:</p>
			<p class="source-code">   cmd:</p>
			<p class="source-code">   - python3</p>
			<p class="source-code">   - "/train.py"</p>
			<p class="source-code">   image: svekars/hyperparameter-example:1.0</p>
			<p>As you can see, this is another standard Pachyderm pipeline. It takes the data from the <strong class="source-inline">remove-outliers</strong> repository and applies the <strong class="source-inline">train.py</strong> script to it. It uses the same Docker image as other pipelines in this section.</p>
			<p>Here is a list of components that the <strong class="source-inline">train.py</strong> script imports:</p>
			<p class="source-code">from sklearn.model_selection import train_test_split</p>
			<p class="source-code">from sklearn import metrics</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">from sklearn.metrics import r2_score, mean_squared_error, make_scorer</p>
			<p class="source-code">from sklearn.linear_model import Ridge</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import matplotlib.pyplot as plt</p>
			<p class="source-code">import seaborn as sns</p>
			<p class="source-code">from contextlib import redirect_stdout</p>
			<p>We import <strong class="source-inline">train_test_split</strong>, <strong class="source-inline">metrics</strong>, <strong class="source-inline">r2_score</strong>, <strong class="source-inline">mean_squared_error</strong>, and <strong class="source-inline">make_scorer</strong> modules from the <strong class="source-inline">sklearn</strong> library to split the data into train and test data and calculate the R2 and MSE metrics for our model. We import the <strong class="source-inline">Ridge</strong> regression model from <strong class="source-inline">sklearn.linear_model</strong> to train our model using Ridge regression. Ridge regression is a variation of linear regression, one of the algorithms that you can use for this type of regression problem. We import <strong class="source-inline">seaborn</strong> and <strong class="source-inline">matplotlib</strong> to visualize our results, and <strong class="source-inline">pandas</strong> and <strong class="source-inline">numpy</strong> to manipulate the data. <strong class="source-inline">redirect_stdout</strong> is used to redirect output to a file.</p>
			<p>The first part of our script reads the <strong class="source-inline">removed-outliers-data.csv</strong> file from the <strong class="source-inline">remove-outliers</strong> repository as a <strong class="source-inline">DataFrame</strong>. Then, we use <strong class="source-inline">train_test_split</strong> to split our dataset into training and testing parts. The training part is used to train the data, and the testing part is used to test the performance of our model in the cross-validation stage. The code is illustrated here:</p>
			<p class="source-code">data = pd.read_csv("/pfs/remove-outliers/removed-outliers-data.csv", delimiter=',')</p>
			<p class="source-code">X=data.drop('SalePrice', axis=1)</p>
			<p class="source-code">y=data['SalePrice']</p>
			<p class="source-code">train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.4, random_state=0)</p>
			<p>Next, we define our estimator, which is the Ridge regression. <strong class="source-inline">alpha</strong> is the parameter that we will be tuning to achieve better performance. We initially set <strong class="source-inline">alpha</strong> to <strong class="source-inline">1</strong>, make a prediction, and save our R2 and MSE scores in the <strong class="source-inline">r_squared_mse.txt</strong> file, as illustrated in the following code snippet:</p>
			<p class="source-code">estimator = Ridge(alpha=1).fit(train_X, train_y)</p>
			<p class="source-code">prediction = estimator.predict(test_X)</p>
			<p class="source-code">with open('/pfs/out/r_squared_mse.txt', 'w', encoding='utf-8') as f:</p>
			<p class="source-code">     with redirect_stdout(f):</p>
			<p class="source-code">         print('R-squared:', metrics.r2_score(test_y, prediction))</p>
			<p class="source-code">         print('MSE:', np.sqrt(metrics.mean_squared_error(test_y, prediction)))</p>
			<p>Lastly, we'll plot our data and save it in the <strong class="source-inline">prediction.png</strong> file, as follows:</p>
			<p class="source-code">plt.figure(figsize=(20,10))</p>
			<p class="source-code">myplot1 = sns.distplot(test_y, hist=True, kde=False)</p>
			<p class="source-code">myplot2 = sns.distplot(prediction, hist=True, kde=False)</p>
			<p class="source-code">plt.legend(labels=['Real Price', 'Predicted Price'])</p>
			<p class="source-code">plt.xlim(0,)</p>
			<p class="source-code">fig1 = myplot1.get_figure()</p>
			<p class="source-code">fig1.savefig('/pfs/out/prediction.png', dpi=400)</p>
			<p>Let's create this pipeline, as follows:</p>
			<ol>
				<li value="1">Check that your Pachyderm cluster is running by executing the following command:<p class="source-code"><strong class="bold">pachctl version</strong></p></li>
			</ol>
			<p>Here is the output:</p>
			<p class="source-code">COMPONENT           VERSION</p>
			<p class="source-code">pachctl             2.0.0</p>
			<p class="source-code">pachd               2.0.0</p>
			<ol>
				<li value="2">Create a <strong class="source-inline">train</strong> pipeline by running the following command:<p class="source-code"><strong class="bold">pachctl create pipeline -f train.yaml </strong></p></li>
			</ol>
			<p>No output is returned.</p>
			<ol>
				<li value="3">List all pipelines by running the following command:<p class="source-code"><strong class="bold">pachctl list pipeline </strong></p></li>
			</ol>
			<p>You should see the following output:</p>
			<p class="source-code">NAME            VERSION INPUT         CREATED       STATE / LAST JOB   DESCRIPTION</p>
			<p class="source-code"><strong class="bold">train           1</strong>       remove-outliers:/ 34 seconds ago running / success A pipeline that trains the model with a selected estimator.</p>
			<p class="source-code">remove-outliers 1       data-clean:/ 5 seconds ago running / starting A pipeline that removes outliers from the dataset.</p>
			<p class="source-code">data-clean      1       data:/       4 minutes ago running / success  A pipeline that removes empty cells from the CSV.</p>
			<p class="source-code">data-explore    1       data:/*       8 minutes ago running / success  A pipeline that performs exploratory analysis.</p>
			<p>The output should list the <strong class="source-inline">train</strong> pipeline. Wait for the pipeline to finish running.</p>
			<ol>
				<li value="4">Let's look at the repositories. We can do this by running the following command:<p class="source-code"><strong class="bold">pachctl list repo</strong></p></li>
			</ol>
			<p>You should see a new repository called <strong class="source-inline">train</strong> added with <strong class="source-inline">186.3KiB</strong> of data, as indicated in the following output:</p>
			<p class="source-code">NAME            CREATED            SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code"><strong class="bold">train</strong>           2 minutes ago <strong class="bold">186.3KiB</strong>      Output repo for pipeline train.</p>
			<p class="source-code">remove-outliers About a minute ago 413.7KiB      Output repo for pipeline remove-outliers.</p>
			<p class="source-code">data-clean      49 minutes ago     780.4KiB      Output repo for pipeline data-clean.</p>
			<p class="source-code">data-explore    53 minutes ago     3.361MiB      Output repo for pipeline data-explore.</p>
			<p class="source-code">data            About an hour ago  449.9KiB</p>
			<ol>
				<li value="5">Now, let's look at the files that were uploaded to the repository. We can do this by running the following command:<p class="source-code"><strong class="bold">pachctl list file train@master</strong></p></li>
			</ol>
			<p>The output should look like this:</p>
			<p class="source-code">NAME               TYPE SIZE</p>
			<p class="source-code">/prediction.png    file 186.2KiB</p>
			<p class="source-code">/r_squared_mse.txt file 54B</p>
			<p>There should be two files.</p>
			<ol>
				<li value="6">Open the <strong class="source-inline">r_squared_mse.txt</strong> file to check the MSE and R2 scores. You can do this by running the following command:<p class="source-code"><strong class="bold">pachctl get file train@master:/r_squared_mse.txt</strong></p></li>
			</ol>
			<p>The output should look like this:</p>
			<p class="source-code">R-squared: 0.7803812645495943</p>
			<p class="source-code">MSE: 29521.138357806965</p>
			<p>Our R2 value is pretty high, meaning that the calculation should be quite precise.</p>
			<ol>
				<li value="7">Now, let's open the <strong class="source-inline">prediction.png</strong> file by running the following command:<p class="source-code"><strong class="bold">pachctl get file train@master:/prediction.png | open -f -a "Preview.app"</strong></p></li>
			</ol>
			<p>This is what you should see:</p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="Images/B17085_09_012.jpg" alt="Figure 9.12 – Predicted versus real price&#13;&#10;" width="1361" height="705"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.12 – Predicted versus real price</p>
			<p>As you can see, the predicted price looks pretty close to the real one, with a few minor exceptions.</p>
			<p>In our last pipeline step, we will try to find the best value of <strong class="source-inline">alpha</strong> and will perform cross-validation of our parameters with Grid search.</p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor215"/>Creating an evaluation pipeline</h2>
			<p>Our evaluation pipeline<a id="_idIndexMarker816"/> specification looks<a id="_idIndexMarker817"/> like this:</p>
			<p class="source-code">---</p>
			<p class="source-code"> pipeline:</p>
			<p class="source-code">   name: evaluate</p>
			<p class="source-code"> description: A pipeline that evaluates the performance of the model.</p>
			<p class="source-code"> input:</p>
			<p class="source-code">   pfs:</p>
			<p class="source-code">     glob: "/"</p>
			<p class="source-code">     repo: remove-outliers</p>
			<p class="source-code"> transform:</p>
			<p class="source-code">   cmd:</p>
			<p class="source-code">   - python3</p>
			<p class="source-code">   - "/grid-search.py"</p>
			<p class="source-code">   image: svekars/hyperparameter-example:1.0</p>
			<p>Since you've seen quite a few of those, you can probably guess that it's a standard Pachyderm pipeline that takes data from the <strong class="source-inline">remove-outliers</strong> repository and applies the <strong class="source-inline">grid-search.py</strong> file to that data. The pipeline uses the same Docker image as all other pipelines.</p>
			<p>The <strong class="source-inline">grid-search.py</strong> file imports the components already familiar to us from previous sections. In addition, it imports <strong class="source-inline">GridSearchCV</strong> from the <strong class="source-inline">sklearn.model_selection</strong> library and <strong class="source-inline">joblib</strong>, which saves the model to a <strong class="source-inline">pickle</strong> file.</p>
			<p>The first part of the script<a id="_idIndexMarker818"/> performs the same data manipulation as in <strong class="source-inline">train.py</strong>—it opens the data file and splits<a id="_idIndexMarker819"/> it into two sets.</p>
			<p>Next, we set the <strong class="source-inline">estimator</strong> property to have <strong class="source-inline">Ridge</strong> regression and specify <strong class="source-inline">scoring</strong> values and <strong class="source-inline">alpha</strong> parameters, like this:</p>
			<p class="source-code">estimator = Ridge(alpha=10)</p>
			<p class="source-code">scoring={'R_squared':'r2','MSE':'neg_mean_squared_error'}</p>
			<p class="source-code">params = {'alpha':[1,0.1,0.01,0.001,0.0001,0,10,100,1000]}</p>
			<p>The next part of our script uses <strong class="source-inline">GridSearchCV</strong> to train and determine the best <strong class="source-inline">alpha</strong> parameter and saves the best score and the best <strong class="source-inline">alpha</strong> parameter in the <strong class="source-inline">best_score.txt</strong> file. The model is also saved in the <strong class="source-inline">my_model.pkl</strong> file. The code is illustrated in the following snippet:</p>
			<p class="source-code">with open('/pfs/out/best_score.txt', 'w', encoding='utf-8') as f:</p>
			<p class="source-code">      with redirect_stdout(f):</p>
			<p class="source-code">          for i, v in scoring.items():</p>
			<p class="source-code">             grid = GridSearchCV(estimator, params, cv=10, scoring= "r2")</p>
			<p class="source-code">             grid.fit(train_X, train_y)</p>
			<p class="source-code">             print(i)</p>
			<p class="source-code">             print('Best params:', grid.best_params_)</p>
			<p class="source-code">             if grid.best_score_ &gt; 0:</p>
			<p class="source-code">                 print('Best score:', grid.best_score_)</p>
			<p class="source-code">             else:</p>
			<p class="source-code">                 print('Best score:', np.sqrt(abs(grid.best_score_)))</p>
			<p class="source-code">             print()</p>
			<p class="source-code"> joblib.dump(estimator, '/pfs/out/my_model.pkl', compress =1)</p>
			<p>Lastly, we plot<a id="_idIndexMarker820"/> our performance graph<a id="_idIndexMarker821"/> and save it to <strong class="source-inline">performance-plot.png</strong>.</p>
			<p>Follow the next steps to create this pipeline:</p>
			<ol>
				<li value="1">Verify that Pachyderm is running by executing the following command:<p class="source-code"><strong class="bold">pachctl version</strong></p></li>
			</ol>
			<p>You should see the following output. Note that your version of <strong class="source-inline">pachctl</strong> and <strong class="source-inline">pachd</strong> might vary:</p>
			<p class="source-code">COMPONENT           VERSION</p>
			<p class="source-code">pachctl             2.0.0</p>
			<p class="source-code">pachd               2.0.0</p>
			<ol>
				<li value="2">Create an <strong class="source-inline">evaluate</strong> pipeline by running the following command:<p class="source-code"><strong class="bold">pachctl create pipeline -f evaluate.yaml </strong></p></li>
			</ol>
			<p>This command does not return any output.</p>
			<ol>
				<li value="3">View the active pipelines<a id="_idIndexMarker822"/> by running the following command:<p class="source-code"><strong class="bold">pachctl list pipeline </strong></p></li>
			</ol>
			<p>You should<a id="_idIndexMarker823"/> see the following output:</p>
			<p class="source-code">NAME            VERSION INPUT         CREATED       STATE / LAST JOB   DESCRIPTION</p>
			<p class="source-code"><strong class="bold">evaluate    </strong>    1       remove-outliers:/ 5 seconds ago  running / running A pipeline that evaluates the performance of the model.</p>
			<p class="source-code">train           1       remove-outliers:/ 34 seconds ago running / success A pipeline that trains the model with a selected estimator.</p>
			<p class="source-code">remove-outliers 1       data-clean:/* 5 seconds ago running / starting A pipeline that removes outliers from the dataset.</p>
			<p class="source-code">data-clean      1       data:/*       4 minutes ago running / success  A pipeline that removes empty cells from the CSV.</p>
			<p class="source-code">data-explore    1       data:/*       8 minutes ago running / success  A pipeline that performs exploratory analysis.</p>
			<p>You should see the <strong class="source-inline">evaluate</strong> pipeline running or finished with a <strong class="source-inline">success</strong> status.</p>
			<ol>
				<li value="4">Look at the repository<a id="_idIndexMarker824"/> that the <strong class="source-inline">evaluate</strong> pipeline has created by running the following<a id="_idIndexMarker825"/> command:<p class="source-code"><strong class="bold">pachctl list repo</strong></p></li>
			</ol>
			<p>You should see a new repository called <strong class="source-inline">train</strong> with <strong class="source-inline">121KiB</strong> of data in it, as indicated in the following output:</p>
			<p class="source-code">NAME            CREATED            SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code"><strong class="bold">evaluate</strong>        2 minutes ago  <strong class="bold">121KiB</strong>        Output repo for pipeline evaluate.</p>
			<p class="source-code">train           2 minutes ago 186.3KiB      Output repo for pipeline train.</p>
			<p class="source-code">remove-outliers About a minute ago 413.7KiB      Output repo for pipeline remove-outliers.</p>
			<p class="source-code">data-clean      49 minutes ago     780.4KiB      Output repo for pipeline data-clean.</p>
			<p class="source-code">data-explore    53 minutes ago     3.361MiB      Output repo for pipeline data-explore.</p>
			<p class="source-code">data            About an hour ago  449.9KiB</p>
			<ol>
				<li value="5">List the files in the <strong class="source-inline">evaluate</strong> repository by running the following command:<p class="source-code"><strong class="bold">pachctl list file evaluate@master</strong></p></li>
			</ol>
			<p>The output should look like this:</p>
			<p class="source-code">NAME               TYPE SIZE</p>
			<p class="source-code">/best_score.txt       file 132B</p>
			<p class="source-code">/my_model.pkl         file 187B</p>
			<p class="source-code">/performance-plot.png file 120.7KiB</p>
			<p>These files are our model, best MSE and R2 scores, and best <strong class="source-inline">alpha</strong> parameter, and a graph<a id="_idIndexMarker826"/> that shows how the training data compares to testing data.</p>
			<ol>
				<li value="6">Let's look at<a id="_idIndexMarker827"/> our best scores by running the following command:<p class="source-code"><strong class="bold">pachctl get file evaluate@master:/best_score.txt</strong></p></li>
			</ol>
			<p>The output should look like this:</p>
			<p class="source-code">R_squared</p>
			<p class="source-code">Best params: {'alpha': 10}</p>
			<p class="source-code">Best score: 0.7040913319322766</p>
			<p class="source-code">MSE</p>
			<p class="source-code">Best params: {'alpha': 10}</p>
			<p class="source-code">Best score: 0.7040913319322766</p>
			<p>Alpha 10 is our best <strong class="source-inline">alpha</strong> parameter. It should be used for predicting house prices.</p>
			<ol>
				<li value="7">The <strong class="source-inline">performance-plot.png</strong> file should<a id="_idIndexMarker828"/> show us how our training data evaluates against the testing<a id="_idIndexMarker829"/> data. We can view this by running the following command:<p class="source-code"><strong class="bold">pachctl get file evaluate@master:/performance-plot.png | open -f -a "Preview.app"</strong></p></li>
			</ol>
			<p>Here is the graph it outputs:</p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="Images/B17085_09_013.jpg" alt="Figure 9.13 – Performance plot&#13;&#10;" width="1286" height="962"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.13 – Performance plot</p>
			<p>As you can see, <strong class="source-inline">alpha=10</strong> is likely the best parameter in the range that we have provided. This<a id="_idIndexMarker830"/> pipeline concludes our example. The resulting model can be used to predict house<a id="_idIndexMarker831"/> prices with the trained <strong class="source-inline">alpha</strong> hyperparameter.</p>
			<p>This concludes our example. Now, let's clean up our cluster. </p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor216"/>Cleaning up</h2>
			<p>After you are done experimenting, you might want to clean up your cluster so that you start your next<a id="_idIndexMarker832"/> experiment with a fresh install. To clean up the environment, proceed as follows:</p>
			<ol>
				<li value="1">Delete all pipelines and repositories by running the following command:<p class="source-code"><strong class="bold">pachctl delete pipeline –all &amp;&amp; pachctl delete repo --all</strong></p></li>
				<li>Verify that no repositories and pipelines exist in your cluster by running the following command:<p class="source-code"><strong class="bold">pachctl list repo &amp;&amp; pachctl list pipeline</strong></p></li>
			</ol>
			<p>You should see the following output:</p>
			<p class="source-code">NAME CREATED SIZE (MASTER) DESCRIPTION</p>
			<p class="source-code">NAME VERSION INPUT CREATED STATE / LAST JOB DESCRIPTION</p>
			<p>You have successfully cleaned up your cluster.</p>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor217"/>Summary</h1>
			<p>In this chapter, we have learned how to implement an ML pipeline that performs hyperparameter tuning on a house price prediction example. We've created five steps of this pipeline, each outputting relevant files and information into Pachyderm output repositories. In our first pipeline, we performed an exploratory analysis to gather a general understanding of the dataset and built a heatmap that helped us outline the correlation between various parameters in our dataset. In our second pipeline, we cleaned the data of columns with missing information, as well as removed parameters that have little influence on the sale price of a house. In our third pipeline, we removed outliers—values that were outside of the standard range. Our fourth pipeline split our dataset into two parts—one for testing and the other for training. And finally, our fifth pipeline performed hyperparameter tuning for the <strong class="source-inline">alpha</strong> parameter and found the best alpha for our use case. The last pipeline output our model in a <strong class="source-inline">.pkl</strong> file and created a graph where we could see the performance of our model against the training and testing dataset.</p>
			<p>In the next chapter, we will learn about Pachyderm language clients. While you can do pure Python, R, or Scala in Pachyderm, you could also leverage one of our language clients or even build your own to take Pachyderm even further.</p>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor218"/>Further reading</h1>
			<ul>
				<li>Kaggle House Prices dataset: <a href="https://www.kaggle.com/lespin/house-prices-dataset">https://www.kaggle.com/lespin/house-prices-dataset</a></li>
				<li><strong class="source-inline">seaborn</strong>: <a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a></li>
			</ul>
		</div>
	</div></body></html>