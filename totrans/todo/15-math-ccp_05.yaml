- en: <st c="0">4</st>
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="0">4</st>
- en: <st c="2">Loss Functions and Optimization</st>
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="2">损失函数与优化</st>
- en: <st c="33">In</st> [*<st c="37">Chapter 2</st>*](B19496_02.xhtml#_idTextAnchor061)
    <st c="46">and</st> [*<st c="51">Chapter 3</st>*](B19496_03.xhtml#_idTextAnchor141)<st
    c="60">, we focused on the two most important and core math concepts that are
    at the heart of virtually all of data science.</st> <st c="178">In this chapter,
    we are going to move on to math concepts behind specific, but still very important,
    data science activities.</st> <st c="304">Specifically, we are going to lay some
    of the groundwork for building</st> <st c="374">predictive models.</st>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33">在</st> [*<st c="37">第二章</st>*](B19496_02.xhtml#_idTextAnchor061)
    <st c="46">和</st> [*<st c="51">第三章</st>*](B19496_03.xhtml#_idTextAnchor141)<st
    c="60">中，我们重点介绍了数据科学几乎所有核心活动中最重要的两个数学概念。</st> <st c="178">在本章中，我们将继续探讨数据科学中一些特定但仍然非常重要的数学概念。</st>
    <st c="304">具体来说，我们将为构建</st> <st c="374">预测模型</st> 打下基础。
- en: '<st c="392">At the end of the last chapter, we hinted that one of the key concepts
    when building models is knowing or measuring how good a model is.</st> <st c="530">When
    we train or fit a</st> **<st c="553">machine learning</st>** <st c="569">(</st>**<st
    c="571">ML</st>**<st c="573">) model, we adjust the parameter values of the model
    so that it gives a “better” fit or explanation of the data.</st> <st c="687">But
    this raises the question: What do we mean by “better”?</st> <st c="746">Without
    an exact quantitative definition of what we mean when we say that one set of parameter
    values gives a better fit to the data than another, we cannot construct an objective
    and quantitative training process.</st> <st c="961">This is where loss functions
    come in.</st> <st c="999">They measure how well a model fits the training data.</st>
    <st c="1053">This chapter goes into the details behind loss functions and their
    use in the training of models.</st> <st c="1151">We do this by covering the</st>
    <st c="1178">following topics:</st>'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="392">在上一章的结尾，我们提到，在构建模型时，了解或衡量模型好坏是关键概念之一。</st> <st c="530">当我们训练或拟合一个</st>
    **<st c="553">机器学习</st>** <st c="569">(</st>**<st c="571">ML</st>**<st c="573">)
    模型时，我们调整模型的参数值，以便它能“更好”地拟合或解释数据。</st> <st c="687">但这就引出了一个问题：我们所说的“更好”是什么意思？</st>
    <st c="746">如果没有明确的定量定义来说明何为“更好”，即一组参数值如何比另一组参数值更好地拟合数据，我们就无法构建一个客观且定量的训练过程。</st>
    <st c="961">这就是损失函数的作用。</st> <st c="999">它们衡量模型对训练数据的拟合程度。</st> <st c="1053">本章将深入讲解损失函数及其在模型训练中的应用。</st>
    <st c="1151">我们将通过以下主题来进行讲解：</st>
- en: '*<st c="1195">Loss functions – what are they?</st>*<st c="1227">: In this section,
    we learn the basics of loss functions and</st> <st c="1289">risk functions</st>'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="1195">损失函数——它是什么？</st>*<st c="1227">：在本节中，我们将学习损失函数和</st> <st c="1289">风险函数</st>
    的基础知识。'
- en: '*<st c="1303">Least squares</st>* <st c="1317">(</st>*<st c="1319">LS</st>*<st
    c="1321">): In this section, we learn at a high level about least squares minimization
    as a general technique for estimating</st> <st c="1438">model parameters</st>'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="1303">最小二乘法</st>* <st c="1317">(</st>*<st c="1319">LS</st>*<st c="1321">)：在本节中，我们将高层次地了解最小二乘法最小化作为一种估计</st>
    <st c="1438">模型参数</st> 的通用技术。'
- en: '*<st c="1454">Linear models</st>*<st c="1468">: In this section, we learn how
    to use least squares minimization for fitting linear models via</st> **<st c="1565">ordinary
    least squares</st>** <st c="1587">(</st>**<st c="1589">OLS</st>**<st c="1592">)
    regression</st>'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="1454">线性模型</st>*<st c="1468">：在本节中，我们将学习如何通过最小二乘法最小化来拟合线性模型，使用</st>
    **<st c="1565">普通最小二乘法</st>** <st c="1587">(</st>**<st c="1589">OLS</st>**<st
    c="1592">) 回归</st>'
- en: '*<st c="1605">Gradient descent</st>*<st c="1622">: In this section, we learn
    a powerful and general technique for minimizing risk functions and</st> <st c="1718">objective
    functions</st>'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*<st c="1605">梯度下降法</st>*<st c="1622">：在本节中，我们将学习一种强大且通用的技术，用于最小化风险函数和</st>
    <st c="1718">目标函数</st>'
- en: <st c="1737">Technical requirements</st>
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="1737">技术要求</st>
- en: <st c="1760">All code examples given in this chapter (and additional examples)
    can be found at the GitHub repository,</st> [<st c="1866">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter04</st>](https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter04)<st
    c="1970">. To run the Jupyter notebooks, you will need a full Python installation
    including the</st> <st c="2057">following packages:</st>
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="1760">本章中给出的所有代码示例（以及其他示例）可以在 GitHub 仓库中找到，</st> [<st c="1866">https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter04</st>](https://github.com/PacktPublishing/15-Math-Concepts-Every-Data-Scientist-Should-Know/tree/main/Chapter04)<st
    c="1970">。要运行 Jupyter 笔记本，您需要完整的 Python 安装，包括以下包：</st>
- en: '`<st c="2076">pandas</st>` <st c="2083">(>=2.0.3)</st>'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2076">pandas</st>` <st c="2083">(>=2.0.3)</st>'
- en: '`<st c="2093">numpy</st>` <st c="2099">(>=1.24.3)</st>'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2093">numpy</st>` <st c="2099">(>=1.24.3)</st>'
- en: '`<st c="2110">scipy</st>` <st c="2116">(>=1.11.1)</st>'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2110">scipy</st>` <st c="2116">(>=1.11.1)</st>'
- en: '`<st c="2127">scikit-learn</st>` <st c="2140">(>=1.3.0)</st>'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2127">scikit-learn</st>` <st c="2140">(>=1.3.0)</st>'
- en: '`<st c="2150">matplotlib</st>` <st c="2161">(>=3.7.2)</st>'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2150">matplotlib</st>` <st c="2161">(>=3.7.2)</st>'
- en: '`<st c="2171">statsmodels</st>` <st c="2183">(>=0.14.0)</st>'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="2171">statsmodels</st>` <st c="2183">(>=0.14.0)</st>'
- en: <st c="2194">Loss functions – what are they?</st>
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="2194">损失函数 – 它是什么？</st>
- en: <st c="2226">A</st> **<st c="2229">loss function</st>** <st c="2242">takes two
    inputs; for example, a model prediction and the corresponding ground-truth value.</st>
    <st c="2335">It then compares the two inputs and summarizes this comparison into
    a</st> <st c="2405">single number.</st>
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2226">一个</st> **<st c="2229">损失函数</st>** <st c="2242">接收两个输入；例如，一个模型预测值和相应的真实值。</st>
    <st c="2335">然后它比较这两个输入，并将比较结果总结为一个</st> <st c="2405">数字。</st>
- en: <st c="2419">Let’s take that example further.</st> <st c="2453">We’ll denote</st>
    <st c="2465">the ground-truth value by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="2492"><st c="2515">and the model prediction by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1302.png)<st
    c="2543"><st c="2544">. A loss function in this example would then be a function
    of both</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="2611"><st c="2634">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1302.png)<st
    c="2638"><st c="2639">, which returns a single real number.</st> <st c="2677">Let’s
    call that loss function</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1305.png)<st
    c="2707"><st c="2708">. We’ll meet a concrete example of a loss function in the
    next section.</st> <st c="2780">But for now, it suffices to say that a loss function</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1306.png)
    <st c="2833"><st c="2834">attempts to measure how similar</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="2867"><st c="2868">is to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="2875"><st c="2898">, with a loss function value of zero indicating that</st>
    <st c="2951">ˆ</st><st c="2952">y</st> <st c="2953">is identical</st> <st c="2967">to</st>
    <st c="2970">y</st><st c="2971">.</st></st></st></st></st></st></st></st></st>
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2419">让我们进一步探讨这个例子。</st> <st c="2453">我们用</st> <st c="2465">真实值表示为</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="2492"><st c="2515">并用模型预测表示为</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1302.png)<st
    c="2543"><st c="2544">。在这个例子中，损失函数将是</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="2611"><st c="2634">和</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1302.png)<st
    c="2638"><st c="2639">的函数，它返回一个实数。</st> <st c="2677">我们将这个损失函数称为</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1305.png)<st
    c="2707"><st c="2708">。我们将在下一节中遇到一个具体的损失函数例子。</st> <st c="2780">但现在，暂时可以说损失函数</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1306.png)
    <st c="2833"><st c="2834">试图衡量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="2867"><st c="2868">与</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="2875"><st c="2898">的相似度，损失函数的值为零表示</st> <st c="2951">ˆ</st><st c="2952">y</st>
    <st c="2953">与</st> <st c="2967">y</st><st c="2970">相同。</st></st></st></st></st></st></st></st></st>
- en: <st c="2972">In general, a lower value of the function</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1306.png)
    <st c="3015"><st c="3016">means that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="3028"><st c="3029">is closer or more similar to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)<st
    c="3059"><st c="3069">, while a higher value of the loss function means that</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="3124"><st c="3125">is further from or less similar</st> <st c="3158">to</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="3161"><st c="3184">.</st></st></st></st></st></st>
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，函数的较低值表示 <st c="2972">函数的</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1306.png)
    <st c="3015"><st c="3016">意味着</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="3028"><st c="3029">与</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)<st
    c="3059"><st c="3069">更接近或更相似</st> , 而较高的损失函数值则意味着</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="3124"><st c="3125">更远或更不相似</st> <st c="3158">于</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="3161"><st c="3184">.</st></st></st></st></st></st>
- en: <st c="3185">When training a model, our training data will consist of lots of
    ground-truth values, so we will also have lots of predictions.</st> <st c="3314">If
    our training set consists of</st> <st c="3346">N</st> <st c="3347">datapoints,
    then we will have</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)
    <st c="3378"><st c="3379">ground-truth values,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/1315.png)<st
    c="3401"><st c="3411">. We can represent these by the vector</st> <st c="3450">y</st><st
    c="3451">_</st> <st c="3452">=</st> <st c="3453">(</st><st c="3454">y</st><st
    c="3455">1</st><st c="3456">,</st> <st c="3457">y</st><st c="3458">2</st><st c="3459">,</st>
    <st c="3460">…</st> <st c="3461">,</st> <st c="3462">y</st><st c="3463">N</st><st
    c="3464">)</st><st c="3465">. Similarly, we can represent the corresponding set
    of predictions by the vector</st> <st c="3546">ˆ</st><st c="3547">y</st><st c="3548">_</st>
    <st c="3549">=</st> <st c="3550">(</st><st c="3551">ˆ</st><st c="3552">y</st><st
    c="3553">1</st><st c="3554">,</st> <st c="3555">ˆ</st><st c="3556">y</st><st c="3557">2</st><st
    c="3558">,</st> <st c="3559">…</st> <st c="3560">,</st> <st c="3561">ˆ</st><st
    c="3562">y</st><st c="3563">N</st><st c="3564">)</st><st c="3565">. Once we have
    chosen a particular form for the loss function</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1305.png)
    <st c="3627"><st c="3628">we can use it to measure</st> <st c="3653">how close
    the whole set of predictions</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1317.png)
    <st c="3693"><st c="3694">are to their corresponding ground-truth values</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1318.png)
    <st c="3742"><st c="3743">by simply calculating the average loss over the entire
    set.</st> <st c="3804">In other words, we calculate the</st> <st c="3837">following
    quantity:</st></st></st></st></st></st>
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3185">在训练模型时，我们的训练数据将包含大量的真实值，因此我们也会有大量的预测值。</st> <st c="3314">如果我们的训练集包含</st>
    <st c="3346">N</st> <st c="3347">个数据点，那么我们将拥有</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>N</mml:mi></mml:math>](img/443.png)
    <st c="3378"><st c="3379">个真实值，</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>](img/1315.png)<st
    c="3401"><st c="3411">。我们可以用向量</st> <st c="3450">y</st><st c="3451">_</st> <st
    c="3452">=</st> <st c="3453">(</st><st c="3454">y</st><st c="3455">1</st><st c="3456">,</st>
    <st c="3457">y</st><st c="3458">2</st><st c="3459">,</st> <st c="3460">…</st>
    <st c="3461">,</st> <st c="3462">y</st><st c="3463">N</st><st c="3464">)</st><st
    c="3465">来表示这些值。同样地，我们可以用向量</st> <st c="3546">ˆ</st><st c="3547">y</st><st c="3548">_</st>
    <st c="3549">=</st> <st c="3550">(</st><st c="3551">ˆ</st><st c="3552">y</st><st
    c="3553">1</st><st c="3554">,</st> <st c="3555">ˆ</st><st c="3556">y</st><st c="3557">2</st><st
    c="3558">,</st> <st c="3559">…</st> <st c="3560">,</st> <st c="3561">ˆ</st><st
    c="3562">y</st><st c="3563">N</st><st c="3564">)</st><st c="3565">来表示对应的预测集。</st>
    <st c="3627"><st c="3628">一旦我们为损失函数选择了一个特定的形式，</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1305.png)
    <st c="3627"><st c="3628">我们可以用它来衡量</st> <st c="3653">整个预测集</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1317.png)
    <st c="3693"><st c="3694">与其对应的真实值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1318.png)
    <st c="3742"><st c="3743">之间的接近程度，只需通过计算整个数据集的平均损失。</st> <st c="3804">换句话说，我们计算以下量：</st>
    <st c="3837">的计算。</st></st></st></st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mtext>L</mtext><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub></mrow></mfenced></mrow></mrow></mrow></mrow></math>](img/1319.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mtext>L</mtext><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></sub></mrow></mfenced></mrow></mrow></mrow></mrow></math>](img/1319.png)'
- en: <st c="3858">Eq.</st> <st c="3862">1</st>
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 公式 <st c="3858">1</st>
- en: <st c="3863">The value of the quantity in</st> *<st c="3892">Eq.</st> <st c="3896">1</st>*
    <st c="3897">tells us how close our fitted model values are to the</st> <st c="3952">ground-truth
    values.</st>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 公式中的值 *<st c="3892">Eq.</st> <st c="3896">1</st>* 告诉我们拟合模型的值与实际值之间的接近程度。
- en: <st c="3972">When training our model, we adjust the model parameters so that
    the quantity in</st> *<st c="4053">Eq.</st> <st c="4057">1</st>* <st c="4058">is
    minimized.</st> <st c="4073">However, no model is perfect.</st> <st c="4103">Even
    a suitably trained model that has not been overfitted to the training data will
    not have</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1320.png)
    <st c="4197"><st c="4198">identical to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1321.png)<st
    c="4212"><st c="4213">. Using</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1320.png)
    <st c="4221"><st c="4222">to represent</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1321.png)
    <st c="4236"><st c="4237">is an approximation.</st> <st c="4259">It will be an
    imperfect approximation in the sense that there will be some loss of the information
    that was present in</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1324.png)<st
    c="4378"><st c="4379">, hence the name “loss function.” A loss function enables
    us to measure how much loss we suffer when representing</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1325.png)
    <st c="4493"><st c="4494">by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1326.png)<st
    c="4498"><st c="4499">. Or rather, it attempts to quantify how much loss we suffer
    when we represent the true process that generates the real data</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1327.png)
    <st c="4624"><st c="4625">by our model, which produces the predictions</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1328.png)<st
    c="4671"><st c="4672">. In this way, the loss function measures how well our model
    represents the true data generation process – it is a measure of how good our</st>
    <st c="4811">model is.</st></st></st></st></st></st></st></st></st></st>
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练我们的模型时，我们调整模型参数，使得<st c="4053">公式</st> *<st c="4053">Eq.</st> <st c="4057">1</st>*
    <st c="4058">的数量最小化。</st> <st c="4073">然而，没有模型是完美的。</st> <st c="4103">即使是一个经过适当训练、没有过拟合训练数据的模型，也不能完全与</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1320.png)
    <st c="4197"><st c="4198">完全相同。</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1321.png)<st
    c="4212"><st c="4213">使用</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1320.png)
    <st c="4221"><st c="4222">来表示</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1321.png)
    <st c="4236"><st c="4237">是一种近似。</st> <st c="4259">它将是一个不完美的近似，因为会丢失</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1324.png)<st
    c="4378"><st c="4379">中存在的信息， 因此得名“损失函数”。损失函数使我们能够衡量当我们用</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1325.png)
    <st c="4493"><st c="4494">来表示</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1326.png)<st
    c="4498"><st c="4499">时我们所遭受的损失。</st> 或者更确切地说，它试图量化当我们用我们的模型来表示生成实际数据的真实过程时所遭受的损失</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1327.png)
    <st c="4624"><st c="4625">，其生成的预测值为</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1328.png)<st
    c="4671"><st c="4672">。通过这种方式，损失函数衡量我们模型在表示真实数据生成过程方面的表现——它是衡量我们模型好坏的一个标准。</st>
- en: <st c="4820">Risk functions</st>
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="4820">风险函数</st>
- en: <st c="4835">The quantity in</st> *<st c="4852">Eq.</st> <st c="4856">1</st>*
    <st c="4857">is an example of a</st> **<st c="4877">risk function</st>**<st c="4890">.
    A risk function is the expectation value of a loss</st> <st c="4942">function;
    that is, its</st> <st c="4966">average value.</st>
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4835">此处的数量</st> *<st c="4852">方程式</st> <st c="4856">1</st>* <st c="4857">是一个</st>
    **<st c="4877">风险函数</st>**<st c="4890">的例子。风险函数是损失</st> <st c="4942">函数的期望值；也就是说，它的</st>
    <st c="4966">平均值。</st>
- en: <st c="4980">Why would we want to calculate the expectation of a loss function?</st>
    <st c="5048">Let’s take a closer look at what a loss function is.</st> <st c="5101">For
    our example, our loss function</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1329.png)
    <st c="5136"><st c="5137">is a function of data.</st> <st c="5161">The model prediction
    value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="5188"><st c="5189">is a function of the feature vector</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="5226"><st c="5227">that we input into the model, so</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="5261"><st c="5262">is a function of data.</st> <st c="5286">Similarly,
    the ground-truth value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/209.png)
    <st c="5320"><st c="5325">is also data.</st> <st c="5339">This makes the loss
    function value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/1334.png)
    <st c="5374"><st c="5375">a random variable – recall from</st> [*<st c="5408">Chapter
    2</st>*](B19496_02.xhtml#_idTextAnchor061) <st c="5417">that all data contains
    a random component, and anything derived from data contains a</st> <st c="5503">random
    component.</st></st></st></st></st></st></st>
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4980">为什么我们要计算损失函数的期望值呢？</st> <st c="5048">让我们仔细看看什么是损失函数。</st> <st c="5101">在我们的例子中，损失函数</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1329.png)
    <st c="5136"><st c="5137">是数据的一个函数。</st> <st c="5161">模型预测值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="5188"><st c="5189">是特征向量的一个函数</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="5226"><st c="5227">我们输入到模型中的数据，因此</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="5261"><st c="5262">是数据的一个函数。</st> <st c="5286">同样，真实值</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/209.png)
    <st c="5320"><st c="5325">也是数据。</st> <st c="5339">这使得损失函数值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/1334.png)
    <st c="5374"><st c="5375">是一个随机变量——回想一下</st> [*<st c="5408">第二章</st>*](B19496_02.xhtml#_idTextAnchor061)
    <st c="5417">所有数据都包含一个随机成分，任何从数据中派生的东西都包含一个</st> <st c="5503">随机成分。</st></st></st></st></st></st></st>
- en: <st c="5520">As we learned in</st> [*<st c="5538">Chapter 2</st>*](B19496_02.xhtml#_idTextAnchor061)<st
    c="5547">, a random variable can take a range of values, and by taking the expectation
    value, we get a single, deterministic, quantity.</st> <st c="5674">When constructing
    a measure of how good a model is or constructing a measure to minimize as part
    of a training process, a scalar deterministic quantity is always easier to work
    with than a random quantity.</st> <st c="5880">The risk</st> <st c="5888">function
    associated with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/1335.png)
    <st c="5914"><st c="5915">is defined as the expectation of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/1336.png)
    <st c="5949"><st c="5950">over the values of the feature vector</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="5989"><st c="5990">and the ground-truth value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="6018"><st c="6041">. So, the risk is calculated using the</st> <st c="6080">following
    formula:</st></st></st></st></st>
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="5520">正如我们在</st> [*<st c="5538">第2章</st>*](B19496_02.xhtml#_idTextAnchor061)<st
    c="5547">中学到的，随机变量可以取一系列值，通过求期望值，我们得到一个单一的、确定性的量。</st> <st c="5674">在构建模型的优度度量或作为训练过程一部分来构建最小化度量时，标量确定性量总是比随机量更容易处理。</st>
    <st c="5880">风险</st> <st c="5888">函数与</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/1335.png)
    <st c="5914"><st c="5915">定义为</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/1336.png)
    <st c="5949"><st c="5950">关于特征向量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="5989"><st c="5990">和真实值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="6018"><st c="6041">之间的期望值。所以，风险是使用以下公式计算的：</st> <st c="6080">如下公式：</st></st></st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Risk</mtext><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><msub><mi mathvariant="double-struck">E</mi><mrow><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mo>,</mo><mi>y</mi></mrow></msub><mfenced open="("
    close=")"><mrow><mtext>L</mtext><mfenced open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mfenced open="(" close=")"><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder></mfenced></mrow></mfenced></mrow></mfenced><mo>=</mo><mspace
    width="0.25em" /><mo>∫</mo><mtext>L</mtext><mfenced open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mspace
    width="0.25em" /><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover><mfenced open="("
    close=")"><munder><mi>x</mi><mo stretchy="true">_</mo></munder></mfenced></mrow></mfenced><mspace
    width="0.25em" /><mi>p</mi><mfenced open="(" close=")"><mrow><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mo>,</mo><mspace width="0.25em" /><mi>y</mi></mrow></mfenced><mi>d</mi><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>d</mi><mi>y</mi></mrow></mrow></math>](img/1339.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>风险</mtext><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><msub><mi mathvariant="double-struck">E</mi><mrow><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mo>,</mo><mi>y</mi></mrow></msub><mfenced open="("
    close=")"><mrow><mtext>L</mtext><mfenced open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mfenced open="(" close=")"><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder></mfenced></mrow></mfenced></mrow></mfenced><mo>=</mo><mspace
    width="0.25em" /><mo>∫</mo><mtext>L</mtext><mfenced open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mspace
    width="0.25em" /><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover><mfenced open="("
    close=")"><munder><mi>x</mi><mo stretchy="true">_</mo></munder></mfenced></mrow></mfenced><mspace
    width="0.25em" /><mi>p</mi><mfenced open="(" close=")"><mrow><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mo>,</mo><mspace width="0.25em" /><mi>y</mi></mrow></mfenced><mi>d</mi><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>d</mi><mi>y</mi></mrow></mrow></math>](img/1339.png)'
- en: <st c="6143">Eq.</st> <st c="6147">2</st>
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6143">公式</st> <st c="6147">2</st>
- en: <st c="6148">Since we have integrated over all possible values of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="6201"><st c="6202">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="6207"><st c="6230">, the risk function defined by</st> *<st c="6261">Eq.</st>
    <st c="6265">2</st>* <st c="6266">is now a function of the model parameters only.</st>
    <st c="6315">It is now a function we can use to work out optimal model parameter
    values because it is deterministic – whenever we minimize the risk function in</st>
    *<st c="6462">Eq.</st> <st c="6466">2</st>* <st c="6467">with respect to the model
    parameters we will always get the</st> <st c="6528">same answer.</st></st></st>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6148">由于我们已经对所有可能的</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="6201"><st c="6202">和</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)<st
    c="6207"><st c="6230">，由</st> *<st c="6261">公式</st> <st c="6265">2</st>* <st c="6266">定义的风险函数现在仅仅是模型参数的函数。</st>
    <st c="6315">它现在是一个我们可以用来计算最优模型参数值的函数，因为它是确定性的——每当我们最小化</st> *<st c="6462">公式</st>
    <st c="6466">2</st>* <st c="6467">中的风险函数并根据模型参数进行调整时，我们总是能得到</st> <st c="6528">相同的结果。</st></st></st>
- en: <st c="6540">In practice, calculating the risk function in</st> *<st c="6587">Eq.</st>
    <st c="6591">2</st>* <st c="6592">can be tricky, so instead, if we have a training
    dataset, we can approximate the expectation value in</st> *<st c="6695">Eq.</st>
    <st c="6699">2</st>* <st c="6700">by the sample average of the loss function.</st>
    <st c="6745">That is, we approximate</st> <st c="6769">the following:</st>
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6540">在实际操作中，计算</st> *<st c="6587">公式</st> <st c="6591">2</st>* <st c="6592">中的风险函数可能很棘手，因此，如果我们有一个训练数据集，我们可以通过样本平均的损失函数来近似</st>
    *<st c="6695">公式</st> <st c="6699">2</st>* <st c="6700">中的期望值。</st> <st c="6745">也就是说，我们近似如下：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Risk</mtext><mspace
    width="0.25em" /><mo>≃</mo><mspace width="0.25em" /><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mtext>L</mtext></mrow><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub></mrow></mfenced></mrow></mrow></math>](img/1342.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>风险</mtext><mspace
    width="0.25em" /><mo>≃</mo><mspace width="0.25em" /><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mtext>L</mtext></mrow><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub></mrow></mfenced></mrow></mrow></math>](img/1342.png)'
- en: <st c="6785">Eq.</st> <st c="6789">3</st>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6785">公式</st> <st c="6789">3</st>
- en: <st c="6790">You’ll recognize the quantity in</st> *<st c="6823">Eq.</st> <st
    c="6827">3</st>* <st c="6828">as being the same as that in</st> *<st c="6858">Eq.</st>
    <st c="6862">1</st>*<st c="6863">, which is why we said the quantity in</st> *<st
    c="6902">Eq.</st> <st c="6906">1</st>* <st c="6907">was a risk function.</st>
    <st c="6929">As we learned in</st> [*<st c="6946">Chapter 2</st>*](B19496_02.xhtml#_idTextAnchor061)<st
    c="6955">, we can think of a sample average as an expectation value calculated
    using the empirical density function.</st> <st c="7063">In this case, the empirical
    density function is calculated as</st> <st c="7125">the following:</st>
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6790">你会发现</st> *<st c="6823">公式</st> <st c="6827">3</st>* <st c="6828">中的量和</st>
    *<st c="6858">公式</st> <st c="6862">1</st>*<st c="6863">中的量是相同的，这就是我们之前说过</st>
    *<st c="6902">公式</st> <st c="6906">1</st>* <st c="6907">中的量是风险函数的原因。</st> <st
    c="6929">正如我们在</st> [*<st c="6946">第二章</st>*](B19496_02.xhtml#_idTextAnchor061)<st
    c="6955">中所学，我们可以将样本平均值视为使用经验密度函数计算的期望值。</st> <st c="7063">在这种情况下，经验密度函数的计算方式为</st>
    <st c="7125">如下：</st>
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>Empirical density function</mml:mtext><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">δ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi> </mml:mi><mml:munder underaccent="false"><mml:mrow><mml:mi
    mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder><mml:mi> </mml:mi><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi></mml:mrow></mml:mfenced><mml:mi
    mathvariant="normal">δ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi> </mml:mi><mml:mi
    mathvariant="normal">y</mml:mi><mml:mi> </mml:mi><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/1343.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>经验密度函数</mml:mtext><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">δ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi> </mml:mi><mml:munder underaccent="false"><mml:mrow><mml:mi
    mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder><mml:mi> </mml:mi><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:munder
    underaccent="false"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi></mml:mrow></mml:mfenced><mml:mi
    mathvariant="normal">δ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi> </mml:mi><mml:mi
    mathvariant="normal">y</mml:mi><mml:mi> </mml:mi><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/1343.png)'
- en: <st c="7191">Eq.</st> <st c="7195">4</st>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7191">公式</st> <st c="7195">4</st>
- en: <st c="7196">We can use the empirical density function in</st> *<st c="7241">Eq.</st>
    <st c="7245">4</st>* <st c="7246">to approximate the density function</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1344.png)
    <st c="7283"><st c="7292">in</st> *<st c="7295">Eq.</st> <st c="7299">2</st>*<st
    c="7300">. Plugging it into</st> *<st c="7319">Eq.</st> <st c="7323">2</st>*<st
    c="7324">, we then get</st> *<st c="7338">Eq.</st> <st c="7342">3</st>*<st c="7343">.
    Because of this, we call the risk function defined by</st> *<st c="7399">Eq.</st>
    <st c="7403">3</st>* <st c="7404">(and</st> *<st c="7410">Eq.</st> <st c="7414">1</st>*<st
    c="7415">) the</st> **<st c="7421">empirical risk function</st>**<st c="7444">.
    Training a model by minimizing</st> <st c="7477">the quantity in</st> *<st c="7493">Eq.</st>
    <st c="7497">3</st>* <st c="7498">with</st> <st c="7504">respect to the model
    parameters is called</st> **<st c="7546">empirical</st>** **<st c="7556">risk
    minimization</st>**<st c="7573">.</st></st>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7196">我们可以在</st> *<st c="7241">方程</st> <st c="7245">4</st>* <st c="7246">中使用经验密度函数来近似密度函数</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1344.png)
    <st c="7283"><st c="7292">中</st> *<st c="7295">方程</st> <st c="7299">2</st>*<st
    c="7300">。将其代入</st> *<st c="7319">方程</st> <st c="7323">2</st>*<st c="7324">，我们得到</st>
    *<st c="7338">方程</st> <st c="7342">3</st>*<st c="7343">。因此，我们称通过</st> *<st c="7399">方程</st>
    <st c="7403">3</st>* <st c="7404">(以及</st> *<st c="7410">方程</st> <st c="7414">1</st>*<st
    c="7415">)定义的</st> **<st c="7421">经验风险函数</st>**<st c="7444">。通过最小化</st> <st c="7477">在</st>
    *<st c="7493">方程</st> <st c="7497">3</st>* <st c="7498">中量</st> <st c="7504">相对于模型参数的量，训练模型称为</st>
    **<st c="7546">经验</st>** **<st c="7556">风险最小化</st>**<st c="7573">。</st>
- en: <st c="7574">Note that the empirical risk function still has a dependence on
    data, because we have approximated the population</st> <st c="7688">distribution</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1344.png)
    <st c="7702"><st c="7711">using a finite sample of data.</st> <st c="7742">The
    empirical risk function is a function of the entire training dataset, and so its
    value will be a random variable.</st> <st c="7860">If the dataset is large, then
    the variance of the empirical risk function may be small enough that we can confidently
    ignore this variation, but clearly, in general, the model parameter values that
    result from minimizing the empirical risk function will be sensitive to (depend
    on) the precise details of the training</st> <st c="8178">set used.</st></st>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7574">请注意，经验风险函数仍然依赖于数据，因为我们已经使用有限样本数据对总体</st> <st c="7688">分布</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1344.png)
    <st c="7702"><st c="7711">进行了近似。</st> <st c="7742">经验风险函数是整个训练数据集的函数，因此其值是一个随机变量。</st>
    <st c="7860">如果数据集很大，那么经验风险函数的方差可能足够小，我们可以放心忽略这种变化，但显然，通常情况下，通过最小化经验风险函数得到的模型参数值将对（依赖于）训练</st>
    <st c="8178">集的具体细节非常敏感。</st>
- en: <st c="8187">Finally, we should point out that because an empirical risk function
    is just a sum of loss function values, the terminology “risk function” and “loss
    function” are often used interchangeably in a loose fashion.</st> <st c="8399">So,
    sometimes, you may hear someone speak of a loss function when they are referring
    to a risk function or vice versa.</st> <st c="8518">However, the intent is usually
    clear – they are referring to a function that is to be minimized in order to find
    good values for the</st> <st c="8651">model parameters.</st>
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="8187">最后，我们应该指出，由于经验风险函数仅仅是损失函数值的总和，因此“风险函数”和“损失函数”这两个术语在日常使用中往往可以互换使用。</st>
    <st c="8399">所以，有时你可能听到有人在提到风险函数时称其为损失函数，反之亦然。</st> <st c="8518">然而，通常其意图是明确的——他们指的是一个需要最小化的函数，以便找到模型参数的最佳值。</st>
    <st c="8651">模型参数。</st>
- en: <st c="8668">There are many loss functions</st>
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="8668">有很多损失函数</st>
- en: <st c="8698">So far, we have been vague about the details of our loss function.</st>
    <st c="8766">We have referred to it</st> <st c="8789">simply as</st> <st c="8798">L</st><st
    c="8800">(</st><st c="8801">y</st><st c="8802">,</st> <st c="8803">ˆ</st><st c="8804">y</st><st
    c="8805">)</st><st c="8806">, but we haven’t given an</st> <st c="8832">actual
    formula for our loss function.</st> <st c="8870">This is deliberate because there
    are many potential choices of loss function formula, and so we wanted to keep
    the explanation of how loss functions are used very general to encompass all these
    potentially different loss</st> <st c="9091">function formulas.</st>
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="8698">到目前为止，我们一直没有明确说明我们的损失函数的细节。</st> <st c="8766">我们只是将其称为</st> <st
    c="8789">L</st><st c="8800">(</st><st c="8801">y</st><st c="8802">,</st> <st c="8803">ˆ</st><st
    c="8804">y</st><st c="8805">)</st><st c="8806">，但我们还没有给出一个</st> <st c="8832">实际的损失函数公式。</st>
    <st c="8870">这是故意的，因为有很多潜在的损失函数公式选择，因此我们希望保持损失函数使用的解释非常通用，以涵盖所有这些可能不同的损失</st>
    <st c="9091">函数公式。</st>
- en: <st c="9109">One of the simplest loss function formula for</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1346.png)
    <st c="9156"><st c="9157">is to take the difference between</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)
    <st c="9192"><st c="9202">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1348.png)
    <st c="9206"><st c="9207">and square it, to ensure a positive quantity.</st> <st
    c="9254">That is, we use the</st> <st c="9274">following formula:</st></st></st></st>
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9109">其中一个最简单的损失函数公式是</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1346.png)
    <st c="9156"><st c="9157">是取</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)
    <st c="9192"><st c="9202">和</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1348.png)
    <st c="9206"><st c="9207">之间的差值并对其进行平方，以确保得到一个正数。</st> <st c="9254">也就是说，我们使用如下公式：</st></st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>L</mtext><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover></mrow></mfenced><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><msup><mfenced open="(" close=")"><mrow><mi>y</mi><mo>−</mo><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover></mrow></mfenced><mn>2</mn></msup></mrow></mrow></math>](img/1349.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>L</mtext><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover></mrow></mfenced><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><msup><mfenced open="(" close=")"><mrow><mi>y</mi><mo>−</mo><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover></mrow></mfenced><mn>2</mn></msup></mrow></mrow></math>](img/1349.png)'
- en: <st c="9294">Eq.</st> <st c="9298">5</st>
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9294">公式</st> <st c="9298">5</st>
- en: <st c="9299">The loss function</st> <st c="9316">formula in</st> *<st c="9328">Eq.</st>
    <st c="9332">5</st>* <st c="9333">is called the</st> **<st c="9348">squared loss</st>**<st
    c="9360">. It is a very simple formula.</st> <st c="9391">Because of that, it
    is an extremely widely used loss function, with some convenient properties.</st>
    <st c="9487">Consequently, in the next section, we go into more detail about this</st>
    <st c="9556">loss function.</st>
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9299">损失函数</st> <st c="9316">公式在</st> *<st c="9328">公式</st> <st c="9332">5</st>*
    <st c="9333">中被称为</st> **<st c="9348">平方损失</st>**<st c="9360">。这是一个非常简单的公式。</st>
    <st c="9391">因此，它是一个被广泛使用的损失函数，具有一些方便的性质。</st> <st c="9487">因此，在下一部分，我们将更详细地讨论这个</st>
    <st c="9556">损失函数。</st>
- en: <st c="9570">Different loss functions = different end results</st>
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="9570">不同的损失函数 = 不同的结果</st>
- en: <st c="9619">The squared loss is just one way of combining</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="9666"><st c="9689">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="9693"><st c="9694">into a positive number.</st> <st c="9719">We could just
    as well have chosen to use the formula</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1352.png)<st
    c="9772"><st c="9773">, which is called the</st> **<st c="9795">absolute loss</st>**<st
    c="9808">. Different</st> <st c="9820">choices of loss function will lead to different
    results.</st> <st c="9877">If we used an absolute-loss loss function in the empirical
    risk function in</st> *<st c="9953">Eq.</st> <st c="9957">3</st>* <st c="9958">when
    doing our model training, we would end up with different model parameter estimates
    compared to if we had used a squared-loss function.</st> <st c="10099">How the
    parameter estimates would differ depends on the different properties of the two
    loss functions.</st> <st c="10203">This highlights</st> <st c="10219">the following:</st></st></st></st>
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9619">平方损失只是将</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="9666"><st c="9689">和</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="9693"><st c="9694">结合成一个正数的方式。</st> <st c="9719">我们也可以选择使用公式</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1352.png)<st
    c="9772"><st c="9773">，这被称为</st> **<st c="9795">绝对损失</st>**<st c="9808">。不同的</st>
    <st c="9820">损失函数选择将导致不同的结果。</st> <st c="9877">如果我们在经验风险函数中使用了绝对损失损失函数，如</st>
    *<st c="9953">公式</st>* <st c="9957">3</st>* <st c="9958">进行模型训练，我们将得到与使用平方损失函数时不同的模型参数估计。</st>
    <st c="10099">参数估计的差异取决于两种损失函数的不同性质。</st> <st c="10203">这突出了以下几点：</st> <st c="10219">
- en: <st c="10233">The properties of the parameter estimates depend upon the properties
    of the loss function.</st> <st c="10325">Some of these properties are advantageous,
    and so often, we will choose a particular loss function precisely because we want
    the parameter estimates to have</st> <st c="10482">certain properties.</st>
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="10233">参数估计的性质取决于损失函数的性质。</st> <st c="10325">这些性质中的一些是有利的，因此我们通常会选择特定的损失函数，正因为我们希望参数估计具有</st>
    <st c="10482">某些特性。</st>
- en: <st c="10501">The end results of training a model depend not only on the choice
    of model and choice of training data but also the whole training process, so also
    on such things as the choice of loss function; that is, how we choose to measure
    how good a model is.</st> <st c="10752">The end results can also depend on the
    algorithm we choose to minimize the empirical risk once we make our choice of</st>
    <st c="10869">loss function.</st>
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="10501">训练模型的最终结果不仅取决于模型的选择和训练数据的选择，还取决于整个训练过程，因此也包括像损失函数的选择；也就是说，我们如何选择衡量模型好坏的标准。</st>
    <st c="10752">最终结果也可能取决于我们选择的算法，用于在选择了损失函数后最小化经验风险。</st> <st c="10869">损失函数。</st>
- en: <st c="10883">Loss functions for anything</st>
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="10883">任何事物的损失函数</st>
- en: <st c="10911">Up till now, we have been talking about loss functions</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1353.png)
    <st c="10967"><st c="10968">that measure the difference between a ground-truth
    value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="11026"><st c="11049">and the</st> <st c="11057">corresponding model prediction</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)<st
    c="11088"><st c="11089">. But at the very start of this section, we just said
    that a loss function took in two inputs and compared them.</st> <st c="11202">From
    this, you’re probably beginning to realize that we can use loss functions to compare
    more than just predictions and ground-truth values.</st> <st c="11344">For example,
    we might want to measure the difference between our estimates of some model parameters
    and what should be the true model parameter values.</st> <st c="11496">If we denote
    a true model parameter value by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1356.png)
    <st c="11541"><st c="11542">and our estimate of it by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)<st
    c="11569"><st c="11572">, then we could measure how close</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)
    <st c="11606"><st c="11609">is to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1356.png)
    <st c="11615"><st c="11616">using the squared loss,</st> <st c="11641">as follows:</st></st></st></st></st></st></st></st>
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="10911">到目前为止，我们一直在讨论损失函数</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1353.png)
    <st c="10967"><st c="10968">用来衡量地面真实值之间的差异</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="11026"><st c="11049">和</st> <st c="11057">相应的模型预测</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)<st
    c="11088"><st c="11089">。但在本节的开头，我们只是说损失函数接受两个输入并进行比较。</st> <st c="11202">从中，你可能开始意识到我们可以使用损失函数来比较不仅仅是预测和地面真实值。</st>
    <st c="11344">例如，我们可能希望衡量某些模型参数的估计与真实模型参数值之间的差异。</st> <st c="11496">如果我们用</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1356.png)
    <st c="11541"><st c="11542">表示真实模型参数值，用</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)<st
    c="11569"><st c="11572">表示我们的估计，那么我们可以用平方损失来衡量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)
    <st c="11606"><st c="11609">与</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1356.png)
    <st c="11615"><st c="11616">的接近程度</st> <st c="11641">如下：</st></st></st></st></st></st></st></st>
- en: <st c="11652">Similarity between</st> <st c="11672">β</st> <st c="11673">and</st>
    <st c="11677">ˆ</st><st c="11678">β</st> <st c="11679">=</st> <st c="11680">(</st><st
    c="11681">β</st><st c="11682">−</st> <st c="11683">ˆ</st><st c="11684">β</st><st
    c="11685">)</st><st c="11686">2</st>
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="11652">β</st> <st c="11672">和</st> <st c="11673">ˆ</st><st c="11678">β</st>
    <st c="11679">的相似度</st> = <st c="11680">(</st><st c="11681">β</st><st c="11682">−</st>
    <st c="11683">ˆ</st><st c="11684">β</st><st c="11685">)</st><st c="11686">²</st>
- en: <st c="11687">Eq.</st> <st c="11691">6</st>
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="11687">公式</st> <st c="11691">6</st>
- en: <st c="11692">In the preceding example, we have effectively defined a loss function</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1360.png)
    <st c="11762"><st c="11770">that takes model parameter values as input.</st> <st
    c="11814">But it is still just comparing two real numbers.</st> <st c="11863">Again,
    we highlight the fact that at the start of this section, we said that a loss function
    just takes two inputs.</st> <st c="11979">There is no reason why those inputs
    must always be two real numbers.</st> <st c="12048">There are, in fact, many situations
    where we want to compare other mathematical objects.</st> <st c="12137">For</st>
    <st c="12141">example, we may want to compare two continuous probability distributions,
    particularly if the model we are building is not a model of the ground-truth values</st>
    <st c="12299">y</st><st c="12300">, but is a model of a</st> <st c="12322">probability
    distribution.</st></st>
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们已经有效地定义了一个损失函数![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>L</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:math>](img/1360.png)，<st
    c="11762"><st c="11770">它以模型参数值作为输入。</st> <st c="11814">但它仍然仅仅是在比较两个实数。</st> <st
    c="11863">再次强调，在本节开始时，我们提到过损失函数仅接受两个输入。</st> <st c="11979">没有理由要求这两个输入必须始终是两个实数。</st>
    <st c="12048">事实上，在许多情况下，我们希望比较其他数学对象。</st> <st c="12137">例如，我们可能希望比较两个连续的概率分布，特别是当我们构建的模型不是对真实值的模型</st>
    <st c="12299">y</st><st c="12300">，而是对概率分布的模型。</st>
- en: <st c="12347">One of the most common functions for comparing two probability
    distributions is the</st> **<st c="12432">Kullback-Leibler</st>** <st c="12448">(</st>**<st
    c="12450">KL</st>**<st c="12452">) divergence.</st> <st c="12467">If the two</st>
    <st c="12477">continuous probability distributions we wish to compare have probability
    density functions</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1361.png)
    <st c="12569"><st c="12574">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>q</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1362.png)<st
    c="12578"><st c="12583">, and they are distributions of a thing denoted by</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)<st
    c="12634"><st c="12635">, then the KL divergence is defined</st> <st c="12671">as
    follows:</st></st></st></st>
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="12347">比较两个概率分布最常用的函数之一是</st> **<st c="12432">Kullback-Leibler</st>**
    <st c="12448">(</st>**<st c="12450">KL</st>**<st c="12452">) 散度。</st> <st c="12467">如果我们希望比较的两个</st>
    <st c="12477">连续概率分布具有概率密度函数</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1361.png)
    <st c="12569"><st c="12574">和</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>q</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1362.png)<st
    c="12578"><st c="12583">，它们是一个由</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)<st
    c="12634"><st c="12635">表示的事物的分布，</st> <st c="12671">则 KL 散度定义如下：</st></st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>KL</mtext><mfenced
    open="(" close=")"><mrow><mi>p</mi><mo>∥</mo><mi>q</mi></mrow></mfenced><mo>=</mo><mspace
    width="0.25em" /><mo>∫</mo><mi>p</mi><mfenced open="(" close=")"><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder></mfenced><mi mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi
    mathvariant="normal">g</mi><mfenced open="(" close=")"><mfrac><mrow><mi>p</mi><mfenced
    open="(" close=")"><munder><mi>x</mi><mo stretchy="true">_</mo></munder></mfenced></mrow><mrow><mi>q</mi><mfenced
    open="(" close=")"><munder><mi>x</mi><mo stretchy="true">_</mo></munder></mfenced></mrow></mfrac></mfenced><mi>d</mi><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1364.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>KL</mtext><mfenced
    open="(" close=")"><mrow><mi>p</mi><mo>∥</mo><mi>q</mi></mrow></mfenced><mo>=</mo><mspace
    width="0.25em" /><mo>∫</mo><mi>p</mi><mfenced open="(" close=")"><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder></mfenced><mi mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi
    mathvariant="normal">g</mi><mfenced open="(" close=")"><mfrac><mrow><mi>p</mi><mfenced
    open="(" close=")"><munder><mi>x</mi><mo stretchy="true">_</mo></munder></mflenced></mrow><mrow><mi>q</mi><mfenced
    open="(" close=")"><munder><mi>x</mi><mo stretchy="true">_</mo></munder></mflenced></mrow></mfrac></mfenced><mi>d</mi><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1364.png)'
- en: <st c="12712">Eq.</st> <st c="12716">7</st>
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="12712">方程</st> <st c="12716">7</st>
- en: <st c="12717">As the KL divergence is the average of the logarithmic difference
    between</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1365.png)
    <st c="12791"><st c="12796">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>q</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1366.png)<st
    c="12800"><st c="12805">, we can think of the KL divergence as a</st> <st c="12846">risk
    function.</st></st></st>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="12717">由于KL散度是</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1365.png)
    <st c="12791"><st c="12796">与</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>q</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1366.png)<st
    c="12800"><st c="12805">之间的对数差的平均值，我们可以将KL散度视为一个</st> <st c="12846">风险函数。</st></st></st>
- en: <st c="12860">We haven’t been specific about what the thing</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="12907"><st c="12908">represents, so you’ll realize that the KL divergence
    can be used for measuring the similarity of distributions of many exotic mathematical
    objects – vectors, networks, matrices, and so on.</st> <st c="13098">We won’t
    go into any more details.</st> <st c="13133">We’ll meet the KL divergence again
    in</st> [*<st c="13171">Chapter 13</st>*](B19496_13.xhtml#_idTextAnchor646)<st
    c="13181">, but for now, we’ll leave it by just saying that the KL divergence
    can be used to measure the expected loss that occurs when we use</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>q</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1362.png)
    <st c="13314"><st c="13319">to</st> <st c="13322">approximate</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1361.png)<st
    c="13334"><st c="13339">.</st></st></st></st>
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="12860">我们并没有明确说明这个东西</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="12907"><st c="12908">代表的是什么，因此你会意识到KL散度可以用于衡量许多奇异数学对象的分布相似性——如向量、网络、矩阵等等。</st>
    <st c="13098">我们将不再深入探讨。</st> <st c="13133">我们将在</st> [*<st c="13171">第13章</st>*](B19496_13.xhtml#_idTextAnchor646)<st
    c="13181">再次遇到KL散度，但目前我们暂时只说，KL散度可以用来衡量当我们使用</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>q</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1362.png)
    <st c="13314"><st c="13319">来</st> <st c="13322">近似</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>p</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1361.png)<st
    c="13334"><st c="13339">时发生的期望损失。</st></st></st></st>
- en: <st c="13340">Hopefully, by now, you’ll have realized that the concept of a
    loss function is a very general one.</st> <st c="13440">A loss function measures
    the similarity between two mathematical objects.</st> <st c="13514">We can do
    this for many different types of mathematical objects.</st> <st c="13579">Even
    for a given type of mathematical object, there are many different potential choices
    of formula for the loss function we use, with each different formula leading to
    subtle differences and nuances in the final results when we use the loss function
    for, say,</st> <st c="13840">model training.</st>
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13340">希望到现在为止，你已经意识到损失函数的概念是非常广泛的。</st> <st c="13440">损失函数衡量两个数学对象之间的相似性。</st>
    <st c="13514">我们可以对许多不同类型的数学对象进行此类操作。</st> <st c="13579">即使对于给定类型的数学对象，我们在使用损失函数时，也有许多不同的公式选择，每种不同的公式都会导致细微的差异和变化，最终影响我们在例如</st>
    <st c="13840">模型训练</st>中的结果。
- en: <st c="13855">A loss function by any other name</st>
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="13855">损失函数的另一种名称</st>
- en: <st c="13889">Since the concept of a loss function is a very general one and
    they just compare two mathematical objects, it is not surprising that such functions
    occur in many different branches of science and mathematics and consequently have
    different names for the same or related concepts.</st> <st c="14170">Therefore,
    you</st> <st c="14185">may also see the following concepts and</st> <st c="14225">terminology
    used:</st>
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13889">由于损失函数的概念非常广泛，它们只是比较两个数学对象，因此，这种函数出现在许多不同的科学和数学领域，并且因此对相同或相关概念有不同的命名，这并不令人惊讶。</st>
    <st c="14170">因此，你</st> <st c="14185">也可能会看到以下概念和</st> <st c="14225">术语的使用：</st>
- en: '**<st c="14242">Cost function</st>**<st c="14256">: Since our model predictions</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1370.png)
    <st c="14287"><st c="14288">are an imperfect representation of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1371.png)<st
    c="14324"><st c="14325">, there may be some consequences or</st> <st c="14360">costs
    to that imprecision.</st> <st c="14388">For example, in a business setting, using</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1372.png)
    <st c="14430"><st c="14431">as an imperfect prediction of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1327.png)
    <st c="14462"><st c="14463">could result in lost revenue or overstocking of inventory,
    and so has a real cost to the business.</st> <st c="14563">Consequently, a loss
    function is also sometimes called a</st> *<st c="14620">cost function</st>*<st
    c="14633">. Clearly, we would want to choose the model parameter values to minimize
    this cost as much as possible, so we also talk of minimizing a</st> <st c="14770">cost
    function.</st></st></st></st></st>'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="14242">代价函数</st>**<st c="14256">：由于我们的模型预测</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1370.png)
    <st c="14287"><st c="14288">是</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1371.png)<st
    c="14324"><st c="14325">的不完美表示，可能会因此产生一些后果或</st> <st c="14360">代价。</st> <st c="14388">例如，在商业环境中，使用</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1372.png)
    <st c="14430"><st c="14431">作为对</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1327.png)
    <st c="14462"><st c="14463">的不完美预测可能会导致收入损失或库存过剩，因此对业务有实际的代价。</st> <st c="14563">因此，损失函数有时也被称为</st>
    *<st c="14620">代价函数</st>*<st c="14633">。显然，我们希望选择模型参数值，以尽可能地最小化这种代价，因此我们也会讨论最小化</st>
    <st c="14770">代价函数。</st></st></st></st></st>'
- en: '**<st c="14784">Objective function</st>**<st c="14803">: When minimizing a</st>
    <st c="14824">risk function with respect to our model’s parameters, minimizing
    the risk function is the aim or</st> *<st c="14921">objective</st>* <st c="14930">of
    the whole exercise.</st> <st c="14954">Consequently, the risk function is also
    referred to as the</st> *<st c="15013">objective function</st>*<st c="15031">.
    This terminology is particularly common in the field of mathematical optimization,
    which studies methods and general algorithms for</st> <st c="15165">optimizing
    functions.</st>'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="14784">目标函数</st>**<st c="14803">：在对我们的模型参数进行风险函数最小化时，最小化风险函数是整个过程的目标或</st>
    *<st c="14921">目标</st>* <st c="14930">。因此，风险函数也被称为</st> *<st c="15013">目标函数</st>*<st
    c="15031">。这种术语在数学优化领域中尤其常见，数学优化研究方法和优化函数的通用算法。</st>'
- en: <st c="15186">That note on the widespread use of loss functions across different
    mathematical fields is a good place to stop for now and recap what we have learned
    in</st> <st c="15340">this section.</st>
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15186">关于损失函数在不同数学领域广泛应用的说明是一个很好的停顿点，可以回顾我们在这一节中学到的内容。</st>
- en: <st c="15353">What we learned</st>
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="15353">我们所学的内容</st>
- en: <st c="15369">In this section, we have learned</st> <st c="15403">the following:</st>
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15369">在这一节中，我们学到了以下内容：</st> <st c="15403">以下：</st>
- en: <st c="15417">How a loss function measures the loss incurred when we approximate
    one mathematical object</st> <st c="15509">by another</st>
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="15417">损失函数如何衡量我们在用一个数学对象</st> <st c="15509">近似另一个数学对象时所产生的损失</st>
- en: <st c="15519">How a risk function is constructed as the expectation value of
    a</st> <st c="15585">loss function</st>
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="15519">风险函数如何构建为损失函数的期望值</st>
- en: <st c="15598">How to calculate the empirical risk function from a loss function
    and</st> <st c="15669">a dataset</st>
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="15598">如何根据损失函数和</st> <st c="15669">数据集计算经验风险函数</st>
- en: <st c="15678">How the optimal parameter values of a model can be estimated by
    minimizing the empirical</st> <st c="15768">risk function</st>
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="15678">如何通过最小化经验风险函数来估计模型的最优参数值</st>
- en: <st c="15781">How the choice of loss function changes the properties of the
    model parameter estimates obtained through the empirical risk</st> <st c="15906">minimization
    process</st>
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="15781">损失函数的选择如何改变通过经验风险</st> <st c="15906">最小化过程得到的模型参数估计的性质</st>
- en: <st c="15926">Having learned about loss functions in general, in the next section,
    we are going to focus on one loss function in particular – the squared-loss function.</st>
    <st c="16082">This is because the squared-loss function is so ubiquitous.</st>
    <st c="16142">As we will see in further sections, it is one of the common data
    science methods for estimating</st> <st c="16238">model parameters.</st>
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15926">在一般学习了损失函数之后，接下来的章节我们将专注于一种特定的损失函数——平方损失函数。</st> <st c="16082">这是因为平方损失函数无处不在。</st>
    <st c="16142">正如我们在后续章节中将看到的，它是估计</st> <st c="16238">模型参数的常见数据科学方法之一。</st>
- en: <st c="16255">Least Squares</st>
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="16255">最小二乘法</st>
- en: <st c="16269">Least squares or least squares regression is probably a term you’ve
    heard before.</st> <st c="16352">Why is that so?</st> <st c="16368">It is because
    it is an extremely versatile but simple technique.</st> <st c="16433">These</st>
    <st c="16438">characteristics of least squares stem from the properties of the
    squared-loss function.</st> <st c="16527">So to start we’ll delve into the squared-loss
    function in a bit</st> <st c="16591">more detail.</st>
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16269">最小二乘法或最小二乘回归可能是你以前听说过的术语。</st> <st c="16352">为什么会这样呢？</st> <st
    c="16368">因为它是一种非常通用但又简单的技术。</st> <st c="16433">这些</st> <st c="16438">最小二乘法的特点源自于平方损失函数的性质。</st>
    <st c="16527">所以我们首先将更详细地探讨平方损失函数。</st> <st c="16591">。</st>
- en: <st c="16603">The squared-loss function</st>
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="16603">平方损失函数</st>
- en: <st c="16629">The squared-loss function in</st> *<st c="16659">Eq.</st> <st
    c="16663">5</st>* <st c="16664">is a function</st> <st c="16679">of the difference</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1374.png)<st
    c="16697"><st c="16698">, and so we</st> <st c="16710">can write the squared loss
    in a slightly</st> <st c="16751">simpler fo</st><st c="16761">rm:</st></st>
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16629">平方损失函数在</st> *<st c="16659">公式</st> <st c="16663">5</st>* <st
    c="16664">中是一个函数</st> <st c="16679">，表示差值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1374.png)<st
    c="16697"><st c="16698">，因此我们</st> <st c="16710">可以将平方损失表示为一种稍微</st> <st c="16751">简化的形式：</st><st
    c="16761">。</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mtext>L</mtext><mrow><mi>s</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mo>−</mo><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow></msub><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover></mrow></mfenced><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><msub><mi>f</mi><mrow><mi>s</mi><mi>q</mi></mrow></msub><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>−</mo><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover></mrow></mfenced><mspace
    width="0.25em" /><mspace width="0.25em" /><mspace width="0.25em" /><mspace width="0.25em"
    /><mtext>with</mtext><mspace width="0.25em" /><mspace width="0.25em" /><mspace
    width="0.25em" /><mspace width="0.25em" /><msub><mi>f</mi><mrow><mi>s</mi><mi>q</mi></mrow></msub><mfenced
    open="(" close=")"><mi>x</mi></mfenced><mo>=</mo><msup><mi>x</mi><mn>2</mn></msup></mrow></mrow></math>](img/1375.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mtext>L</mtext><mrow><mi>s</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>d</mi><mo>−</mo><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow></msub><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover></mrow></mfenced><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><msub><mi>f</mi><mrow><mi>s</mi><mi>q</mi></mrow></msub><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>−</mo><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover><mi>y</mi></mrow></mfenced><mspace
    width="0.25em" /><mspace width="0.25em" /><mspace width="0.25em" /><mspace width="0.25em"
    /><mtext>与</mtext><mspace width="0.25em" /><mspace width="0.25em" /><mspace width="0.25em"
    /><mspace width="0.25em" /><msub><mi>f</mi><mrow><mi>s</mi><mi>q</mi></mrow></msub><mfenced
    open="(" close=")"><mi>x</mi></mfenced><mo>=</mo><msup><mi>x</mi><mn>2</mn></msup></mrow></mrow></math>](img/1375.png)'
- en: <st c="16801">Eq.</st> <st c="16805">8</st>
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16801">方程</st> <st c="16805">8</st>
- en: <st c="16806">The form of the function</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1376.png)
    <st c="16831"><st c="16832">is show</st><st c="16840">n in</st> *<st c="16846">Figure
    4</st>**<st c="16854">.1</st>*<st c="16856">:</st></st>
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16806">函数的形式</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1376.png)
    <st c="16831"><st c="16832">如图</st><st c="16840">所示，</st> *<st c="16846">图 4</st>**<st
    c="16854">.1</st>*<st c="16856">：</st></st>
- en: '![Figure 4.1: The shape of the squared-loss function](img/B19496_04_01.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1: 平方损失函数的形状](img/B19496_04_01.jpg)'
- en: '<st c="16880">Figure 4.1: The shape of the squared-loss function</st>'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1: 平方损失函数的形状](img/B19496_04_01.jpg)'
- en: <st c="16930">For the squared loss, the empirical risk function can be written</st>
    <st c="16996">as follows:</st>
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16930">对于平方损失，经验风险函数可以写成</st> <st c="16996">如下形式：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>f</mi><mrow><mi>s</mi><mi>q</mi></mrow></msub><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub></mrow></mfenced></mrow></mrow><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub></mrow></mfenced><mn>2</mn></msup></mrow></mrow></mrow></math>](img/1377.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>f</mi><mrow><mi>s</mi><mi>q</mi></mrow></msub><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub></mrow></mfenced></mrow></mrow><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub></mrow></mfenced><mn>2</mn></msup></mrow></mrow></mrow></math>](img/1377.png)'
- en: <st c="17009">Eq.</st> <st c="17013">9</st>
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="17009">方程</st> <st c="17013">9</st>
- en: <st c="17014">The model prediction,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1378.png)<st
    c="17036"><st c="17037">, obviously depends upon the model parameters, which we’ll
    denote by the vector</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="17117"><st c="17118">, and the</st> <st c="17128">vector of feature values,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1380.png)<st
    c="17154"><st c="17158">, for which we are making the prediction.</st> <st c="17200">So,
    we denote our model as</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1381.png)<st
    c="17227"><st c="17233">. The vertical bar in that mathematical expression means
    “given,” so we can read this mathematical</st> <st c="17331">expression as the
    value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="17359"><st c="17360">evaluated at</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1331.png)
    <st c="17374"><st c="17375">and given the model parameter values</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="17413"><st c="17414">. The specific model prediction</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1378.png)
    <st c="17446"><st c="17447">is obtained by plugging the feature vector</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1380.png)
    <st c="17491"><st c="17495">into this expression for our model, so</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1387.png)<st
    c="17534"><st c="17535">. If we determine</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1388.png)
    <st c="17553"><st c="17554">by minimizing the empirical risk function with respect
    to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="17613"><st c="17614">, this is equivalent to minimizing</st> <st c="17649">the
    followi</st><st c="17660">ng:</st></st></st></st></st></st></st></st></st></st></st></st></st>
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="17014">模型预测</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1378.png)<st
    c="17036"><st c="17037">显然依赖于模型参数，我们用向量表示该参数</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="17117"><st c="17118">，以及用于预测的</st> <st c="17128">特征值向量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1380.png)<st
    c="17154"><st c="17158">，基于此进行预测。</st> <st c="17200">因此，我们将模型表示为</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1381.png)<st
    c="17227"><st c="17233">。该数学表达式中的竖线表示“已知”，因此我们可以将这个数学表达式读作</st> <st c="17331">在给定</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1307.png)
    <st c="17359"><st c="17360">的值，并且给定模型参数值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="17413"><st c="17414">。具体的模型预测</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1378.png)
    <st c="17446"><st c="17447">是通过将特征向量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1380.png)
    <st c="17491"><st c="17495">代入模型的表达式中得到的，因此</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1387.png)<st
    c="17534"><st c="17535">。如果我们通过最小化经验风险函数相对于</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1388.png)
    <st c="17553"><st c="17554">来确定</st> ![<mml:math xmlns:mml
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mspace width="0.25em" /><mo>|</mo><mspace
    width="0.25em" /><munder><mi>β</mi><mo stretchy="true">_</mo></munder></mrow></mfenced></mrow></mfenced><mn>2</mn></msup></mrow></mrow></math>](img/1390.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mspace width="0.25em" /><mo>|</mo><mspace
    width="0.25em" /><munder><mi>β</mi><mo stretchy="true">_</mo></munder></mrow></mfenced></mrow></mfenced><mn>2</mn></msup></mrow></mrow></math>](img/1390.png)'
- en: <st c="17666">Eq.</st> <st c="17670">10</st>
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="17666">方程</st> <st c="17670">10</st>
- en: <st c="17672">We have dropped the pre-factor of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math>](img/1391.png)
    <st c="17707"><st c="17708">in</st> *<st c="17712">Eq.</st> <st c="17716">10</st>*
    <st c="17718">because it is a constant and therefore makes no difference to the
    value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1392.png)
    <st c="17794"><st c="17795">thatminimizes</st> *<st c="17810">Eq.</st> <st c="17814">10</st>*<st
    c="17816">. The difference</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1393.png)
    <st c="17833"><st c="17834">is the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math>](img/1394.png)
    <st c="17842">**<st c="17846">residual</st>** <st c="17854">of the model, and
    so the</st> <st c="17879">quantity in</st> *<st c="17892">Eq.</st> <st c="17896">10</st>*
    <st c="17898">is the</st> **<st c="17906">sum-of-squared-residuals</st>**<st c="17930">,
    which is often shortened to</st> **<st c="17960">sum-of-squares</st>**<st c="17974">.
    When we determine the model parameters</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1395.png)
    <st c="18015"><st c="18016">by minimizing the sum-of-squares in</st> *<st c="18053">Eq.</st>
    <st c="18057">10</st>*<st c="18059">, we are adjusting</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1388.png)
    <st c="18078"><st c="18079">until the sum-of-squares reaches its least possible
    value.</st> <st c="18139">Hence this technique for determining a model’s</st>
    <st c="18185">parameters is known as</st> **<st c="18209">least squares</st>**
    <st c="18222">or</st> **<st c="18226">least</st>** **<st c="18232">squares minimization</st>**<st
    c="18252">.</st></st></st></st></st></st></st>
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经去掉了前因子！[<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math>](img/1391.png)，<st
    c="17707"><st c="17708">在</st> *<st c="17712">方程</st> <st c="17716">10</st>* <st
    c="17718">中，因为它是一个常数，因此对</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1392.png)
    <st c="17794"><st c="17795">的值没有影响</st> *<st c="17810">方程</st> <st c="17814">10</st>*<st
    c="17816">。差异</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1393.png)
    <st c="17833"><st c="17834">是</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math>](img/1394.png)
    <st c="17842">**<st c="17846">模型的残差</st>** <st c="17854">，因此</st> <st c="17879">在</st>
    *<st c="17892">方程</st> <st c="17896">10</st>* <st c="17898">中的量是</st> **<st c="17906">残差的平方和</st>**<st
    c="17930">，通常简称为</st> **<st c="17960">平方和</st>**<st c="17974">。当我们通过最小化</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1395.png)
    <st c="18015"><st c="18016">的平方和时</st> *<st c="18053">方程</st> <st c="18057">10</st>*<st
    c="18059">，我们正在调整</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1388.png)
    <st c="18078"><st c="18079">，直到平方和达到其最小值。</st> <st c="18139">因此，这种确定模型参数的技术被称为</st>
    <st c="18185">**<st c="18209">最小二乘法</st>** 或</st> **<st c="18226">最小二乘最优化</st>**<st
    c="18252">。</st></st></st></st></st></st></st>
- en: <st c="18253">We have said very little about</st> <st c="18284">the mathematical
    form of our model</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1397.png)<st
    c="18320"><st c="18321">. This is because we haven’t needed to.</st> <st c="18361">This
    makes least squares a very general technique for estimating the parameters of
    a model.</st> <st c="18453">We</st> <st c="18456">can apply the idea to very many
    different types of models and very many different situations.</st> <st c="18550">We
    already encountered least squares minimization in disguise when we minimized the
    dissimilarity between</st> <st c="18655">two matrices in</st> [*<st c="18672">Chapter
    3</st>*](B19496_03.xhtml#_idTextAnchor141) <st c="18681">when we introduced</st>
    **<st c="18701">Non-negative Matrix</st>** **<st c="18721">Factorization</st>**
    <st c="18734">(</st>**<st c="18736">NMF</st>**<st c="18739">).</st></st>
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18253">我们很少提到</st> <st c="18284">我们模型的数学形式</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/1397.png)<st
    c="18320"><st c="18321">。这是因为我们没有必要。</st> <st c="18361">这使得最小二乘法成为一种非常通用的技术，用于估计模型的参数。</st>
    <st c="18453">我们</st> <st c="18456">可以将这个思想应用于许多不同类型的模型和许多不同的情境。</st> <st c="18550">当我们最小化</st>
    <st c="18655">两个矩阵之间的不相似性时，</st> [*<st c="18672">第3章</st>*](B19496_03.xhtml#_idTextAnchor141)
    <st c="18681">我们已经遇到过最小二乘法的变形。</st> <st c="18701">非负矩阵</st> **<st c="18721">分解</st>**
    <st c="18734">(</st>**<st c="18736">NMF</st>**<st c="18739">).</st></st>
- en: <st c="18742">The idea of least squares minimization is a very intuitive one
    – simply construct a mathematical expression for your model predictions, which
    depends on the model parameters, use it to calculate the residuals</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1398.png)
    <st c="18952"><st c="18953">, then minimize the sum of the squared residuals.</st>
    <st c="19003">However, least squares minimization is a heuristic idea, meaning
    that, at the moment, we have not provided a formal or rigorous justification of
    why we should minimize the sum-of-squared residuals to determine the model parameters.</st>
    <st c="19235">Why, for example, do we square the residuals and not raise them
    to the fourth power instead?</st> <st c="19328">We have given no proof that squaring
    the residuals is the best choice we can make to turn the residual into a positive
    quantity.</st> <st c="19457">We will provide a formal justification of least squares
    minimization when we introduce probabilistic models in</st> *<st c="19568">Chapter
    5</st>*<st c="19577">, but for now, we will stick with the heuristic viewpoint
    – it is a very general, powerful, and extremely useful technique.</st> <st c="19701">So,
    let’s dive into least squares minimization in a bit</st> <st c="19757">more detail.</st></st>
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18742">最小二乘法的思想非常直观——简单地构建一个依赖于模型参数的数学表达式，用于预测模型的结果，并用它来计算残差</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1398.png)
    <st c="18952"><st c="18953">，然后最小化残差的平方和。</st> <st c="19003">然而，最小二乘法的最小化是一个启发式的思路，这意味着目前我们还没有提供一个正式或严格的理由来说明为什么我们应该最小化残差平方和来确定模型参数。</st>
    <st c="19235">例如，为什么我们要对残差进行平方，而不是将其提升到四次方呢？</st> <st c="19328">我们并没有证明对残差进行平方是将残差转化为正数的最佳选择。</st>
    <st c="19457">当我们引入概率模型时，在</st> *<st c="19568">第五章</st>*<st c="19577">中会提供最小二乘法最小化的正式证明，但现在，我们将坚持启发式的观点——它是一种非常通用、强大且极其有用的技术。</st>
    <st c="19701">所以，让我们稍微深入了解一下最小二乘法最小化。</st> <st c="19757">更多细节。</st></st>
- en: <st c="19769">OLS regression</st>
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="19769">最小二乘回归（OLS 回归）</st>
- en: <st c="19784">The scatter plot in</st> <st c="19804">the left-hand plot of</st>
    *<st c="19827">Figure 4</st>**<st c="19835">.2</st>* <st c="19837">shows some
    example data that we would like to build a model of.</st> <st c="19902">The</st>
    <st c="19906">scatter plot suggests a linear relationship, so we’ll use a linear
    model to capture the relationship between the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="20019"><st c="20020">and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)
    <st c="20025"><st c="20035">values.</st> <st c="20043">For this 1D data (we have
    only one feature,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="20087"><st c="20088">), a linear model is of the</st> <st c="20116">following
    form:</st></st></st></st>
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="19784">左侧图中的散点图</st> <st c="19804">展示了我们希望构建模型的一些示例数据。</st> *<st c="19827">图
    4</st>**<st c="19835">.2</st>* <st c="19837">显示了这些数据。</st> <st c="19902">散点图表明存在线性关系，因此我们将使用线性模型来捕捉</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)
    <st c="20019"><st c="20020">和</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/769.png)
    <st c="20025"><st c="20035">之间的关系。</st> <st c="20043">对于这组一维数据（我们只有一个特征，</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="20087"><st c="20088">），线性模型的形式如下：</st></st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><mspace
    width="0.25em" /><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi></mrow></mrow></math>](img/1402.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><mspace
    width="0.25em" /><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi></mrow></mrow></math>](img/1402.png)'
- en: <st c="20141">Eq.</st> <st c="20145">11</st>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="20141">方程</st> <st c="20145">11</st>
- en: <st c="20147">The intercept</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/1403.png)
    <st c="20162"><st c="20163">and gradient</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/1404.png)
    <st c="20177"><st c="20178">are the parameters of our model, so our parameter
    vector</st> <st c="20236">β</st><st c="20237">_</st> <st c="20238">=</st> <st
    c="20239">(</st><st c="20240">β</st><st c="20241">0</st><st c="20242">,</st> <st
    c="20243">β</st><st c="20244">1</st><st c="20245">)</st><st c="20246">. An</st>
    <st c="20250">example model is shown on the left-hand side of</st> *<st c="20299">Figure
    4</st>**<st c="20307">.2</st>* <st c="20309">by the solid red line.</st> <st c="20333">In
    fact, this line is the optimal or least squares ch</st><st c="20386">oice</st>
    <st c="20392">for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="20396"><st c="20397">:</st></st></st></st>
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="20147">截距</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/1403.png)
    <st c="20162"><st c="20163">和梯度</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/1404.png)
    <st c="20177"><st c="20178">是我们模型的参数，因此我们的参数向量</st> <st c="20236">β</st><st c="20237">_</st>
    <st c="20238">=</st> <st c="20239">(</st><st c="20240">β</st><st c="20241">0</st><st
    c="20242">,</st> <st c="20243">β</st><st c="20244">1</st><st c="20245">)</st><st
    c="20246">。一个</st> <st c="20250">示例模型如*图 4*<st c="20299">.2</st>*<st c="20307">所示，红色实线表示。</st>
    <st c="20333">事实上，这条线是最优解或最小二乘法的选择</st> <st c="20386">ch</st><st c="20392">oice</st>
    <st c="20396">:</st>
- en: '![Figure 4.2: least squares model optimization for a simple linear model](img/B19496_04_02.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2：简单线性模型的最小二乘法优化](img/B19496_04_02.jpg)'
- en: '<st c="20454">Figure 4.2: least squares model optimization for a simple linear
    model</st>'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="20454">图 4.2：简单线性模型的最小二乘法优化</st>
- en: <st c="20524">On the right-hand side of</st> *<st c="20551">Figure 4</st>**<st
    c="20559">.2</st>*<st c="20561">, we have reproduced the scatter plot and least
    squares optimal model line, but we have also highlighted, with vertical blue line
    segments, the residuals of each of the datapoints.</st> <st c="20742">A residual
    line segment above the red line indicates a positive residual, while a residual
    line segment below the red line indicates a negative residual.</st> <st c="20896">We
    can see that there is a mix of positive and negative residuals.</st> <st c="20963">At
    any given value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/1406.png)
    <st c="20985"><st c="20986">the red line is passing approximately through the
    middle of the</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/769.png)
    <st c="21051"><st c="21061">values that are located at that value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/169.png)<st
    c="21102"><st c="21103">. In other words, the red line, or the least squares model,
    is attempting the estimate the mean value of</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/24.png)
    <st c="21208"><st c="21231">given the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="21250"><st c="21251">. Because we are estimating parameter values</st> <st
    c="21296">β</st>![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>β</mi></mrow></math>](img/1411.png)
    <st c="21297"><st c="21298">that make our linear model predict the mean of</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/24.png)
    <st c="21345"><st c="21368">given</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="21374"><st c="21375">, the overall estimation process is called regression.</st>
    <st c="21430">And because we are using least squares to estimate the optimal values
    of</st> <st c="21503">β</st>![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>β</mi></mrow></math>](img/1411.png)<st
    c="21504"><st c="21505">, we call the overall process</st> **<st c="21535">least
    squares regression</st>**<st c="21559">. Furthermore, because we are</st> <st
    c="21588">using the vertical residuals we call this</st> **<st c="21631">ordinary
    least squares</st>** <st c="21654">(</st>**<st c="21655">OLS</st>**<st c="21658">)</st>
    **<st c="21660">regression</st>**<st c="21671">.</st></st></st></st></st></st></st></st></st></st>
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="20524">在</st> *<st c="20551">图 4</st>**<st c="20559">.2</st>*<st c="20561">的右侧，我们复制了散点图和最小二乘最优模型线，但我们还用垂直蓝色线段突出显示了每个数据点的残差。</st>
    <st c="20742">红线上方的残差线段表示正残差，而红线下方的残差线段表示负残差。</st> <st c="20896">我们可以看到正负残差混合存在。</st>
    <st c="20963">在任意给定的</st> [![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/1406.png)
    的值处，<st c="20985">红线大致穿过</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/769.png)
    <st c="21051">位于该值处的值，即红线或最小二乘模型试图估计给定</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/169.png)<st
    c="21102">的平均值。换句话说，红线或最小二乘模型试图估计</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/24.png)
    <st c="21208">在给定</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="21250">的值下。因为我们正在估计参数值</st> <st c="21296">β</st>![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>β</mi></mrow></math>](img/1411.png)
    <st c="21297">使得我们的线性模型预测</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/24.png)
    <st c="21345">的平均值，即给定</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi></mml:math>](img/10.png)<st
    c="21374">的整体估计过程称为回归。</st> <st c="21430">而因为我们使用最小二乘法来估计</st> <st c="21503">β</st>![<math
    xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>β</mi></mrow></math>](img/1411.png)<st
    c="21504">的最优值，我们将整个过程称为</st> **<st c="21535">最小二乘回归</st>**<st c="21559">。此外，因为我们使用垂直残差，我们称之为</st>
    **<st c="21631">普通最小二乘</st>** <st c="21654">（</st>**<st c="21655">OLS</st>**<st
    c="21658">）</st> **<st c="21660">回归</st>**<st c="21671">。</st></st></st></st></st></st></st></st></st></st>
- en: <st c="21672">You may be wondering what is</st> <st c="21701">ordinary about
    OLS regression.</st> <st c="21733">This refers to the fact that we are using least
    squares regression in its most common setting – fitting a linear model and using
    the vertical residuals.</st> <st c="21886">There are other types of least squares
    regression that you may encounter.</st> <st c="21960">For example, if we have
    a non-linear model but still use the vertical residuals, this is unsurprisingly</st>
    <st c="22064">called</st> **<st c="22071">non-linear least squares regression</st>**
    <st c="22106">(</st>**<st c="22108">NLS</st>**<st c="22111">).</st> <st c="22115">Alternatively,
    if we still want to model a linear relationship but want the relationship to capture
    how the</st> <st c="22223">x</st> <st c="22224">and</st> <st c="22229">y</st>
    <st c="22230">values</st> <st c="22237">vary together, then the squares of the
    orthogonal distances from the model line to the datapoints, rather than the vertical
    distances, are a better way to measure the loss.</st> <st c="22411">This is</st>
    <st c="22419">called</st> **<st c="22426">total least squares</st>** <st c="22445">(</st>**<st
    c="22447">TLS</st>**<st c="22450">) regression.</st> <st c="22465">We already
    encountered TLS regression in disguise when we learned about</st> **<st c="22537">principal
    component analysis</st>** <st c="22565">(</st>**<st c="22567">PCA</st>**<st c="22570">)
    in</st> [*<st c="22576">Chapter 3</st>*](B19496_03.xhtml#_idTextAnchor141)<st
    c="22585">, when we</st> <st c="22594">chose our principal components to minimize
    the variance lost by approximating a full dataset through</st> <st c="22696">dimensionality
    reduction.</st>
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21672">你可能会想，OLS 回归有什么</st> <st c="21701">特别之处。</st> <st c="21733">这指的是我们在最常见的设置下使用最小二乘回归——拟合一个线性模型并使用垂直残差。</st>
    <st c="21886">还有其他类型的最小二乘回归，你可能会遇到。</st> <st c="21960">例如，如果我们有一个非线性模型，但仍然使用垂直残差，这通常被称为</st>
    **<st c="22071">非线性最小二乘回归</st>** <st c="22106">(</st>**<st c="22108">NLS</st>**<st
    c="22111">)。</st> <st c="22115">另外，如果我们仍然想建模线性关系，但希望该关系能捕捉到</st> <st c="22223">x</st>
    <st c="22224">和</st> <st c="22229">y</st> <st c="22230">值的变化关系，那么，从模型线到数据点的正交距离的平方，而非垂直距离，将是衡量损失的更好方式。</st>
    <st c="22411">这被称为</st> **<st c="22426">总最小二乘回归</st>** <st c="22445">(</st>**<st
    c="22447">TLS</st>**<st c="22450">)回归。</st> <st c="22465">我们在学习</st> **<st c="22537">主成分分析</st>**
    <st c="22565">(</st>**<st c="22567">PCA</st>**<st c="22570">)时已经以某种形式遇到了TLS回归</st>
    [*<st c="22576">第3章</st>*](B19496_03.xhtml#_idTextAnchor141)<st c="22585">，当时我们选择主成分来最小化通过</st>
    <st c="22696">降维方法近似完整数据集时的方差损失。</st>
- en: <st c="22721">For now, we’re going to focus only on OLS regression.</st> <st
    c="22776">It sounds like a great data science technique to have in our toolkit,
    right?</st> <st c="22853">It is, but that doesn’t mean it doesn’t have its weaknesses.</st>
    <st c="22914">We’ll explore one of its main</st> <st c="22944">weaknesses next.</st>
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="22721">现在，我们将只关注OLS回归。</st> <st c="22776">它听起来是我们工具包中一个很棒的数据科学技术，对吧？</st>
    <st c="22853">确实如此，但这并不意味着它没有弱点。</st> <st c="22914">接下来我们将探讨它的主要</st> <st c="22944">弱点之一。</st>
- en: <st c="22960">OLS, outliers, and robust regression</st>
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="22960">OLS，异常值和稳健回归</st>
- en: <st c="22997">The scatter plot in</st> *<st c="23018">Figure 4</st>**<st c="23026">.3</st>*
    <st c="23028">shows the influence of outliers on OLS regression.</st> <st c="23080">The
    dataset clearly has two outlier values (with high</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/24.png)
    <st c="23134"><st c="23157">values) toward the right-hand end of the scatter plot.</st>
    <st c="23212">The solid red line shows the OLS model</st> <st c="23251">when we
    use all 31 datapoints, while the red</st> <st c="23296">dashed line shows the
    OLS model when we exclude the two</st> <st c="23352">outlier points.</st></st>
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="22997">下图中的散点图</st> *<st c="23018">图 4</st>**<st c="23026">.3</st>* <st
    c="23028">展示了异常值对OLS回归的影响。</st> <st c="23080">数据集中明显存在两个异常值（其</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>](img/24.png)
    <st c="23134"><st c="23157">值较高）位于散点图的右端。</st> <st c="23212">实线红色线条表示我们使用所有31个数据点时的OLS模型，而红色</st>
    <st c="23296">虚线表示我们排除这两个异常值后的OLS模型。</st></st>
- en: <st c="23367">Including the outlier points in the OLS regression has clearly
    pulled the regression line upward despite the number of outliers being small.</st>
    <st c="23509">One look at the shape of the loss function in</st> *<st c="23555">Figure
    4</st>**<st c="23563">.1</st>* <st c="23565">explains why this is so.</st> <st
    c="23591">The quadratic shape of the loss function means that outliers – that
    is, points with large residuals – contribute significantly more to the sum-of-squared
    residuals value.</st> <st c="23762">A residual,</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi></mrow></math>](img/1416.png)<st
    c="23774"><st c="23775">, of size 1.0 contributes a value of 1.0 when we plug
    it into the squared-loss function</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1417.png)<st
    c="23863"><st c="23864">. However, a residual of size</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:math>](img/1418.png)
    <st c="23894"><st c="23895">contributes a value of 4.0 when we plug it into</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1419.png)<st
    c="23944"><st c="23945">. Since OLS regression works by minimizing the sum-of-squared
    residuals, the OLS algorithm is going to pay disproportionately more attention
    to the outlier contributions when adjusting the m</st><st c="24135">odel</st>
    <st c="24141">parameters</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="24151"><st c="24153">.</st></st></st></st></st></st>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="23367">将离群值包含在 OLS 回归中，尽管离群值的数量很少，但显然将回归线拉高了。</st> <st c="23509">从</st>
    *<st c="23555">图 4</st>**<st c="23563">.1</st>* <st c="23565">的损失函数形状可以解释为什么会这样。</st>
    <st c="23591">损失函数的二次曲线形状意味着离群值——也就是说，具有大残差的点——会对残差平方和值做出显著更大的贡献。</st> <st c="23762">一个大小为
    1.0 的残差，</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi></mrow></math>](img/1416.png)<st
    c="23774"><st c="23775">，当我们将其代入平方损失函数时，贡献值为 1.0</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1417.png)<st
    c="23863"><st c="23864">。然而，一个大小为</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:math>](img/1418.png)
    <st c="23894"><st c="23895">的残差代入时，贡献值为 4.0</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/1419.png)<st
    c="23944"><st c="23945">。由于 OLS 回归通过最小化残差平方和来工作，因此 OLS 算法在调整模型</st><st c="24135">参数</st>
    <st c="24141">时，会对离群值的贡献给予不成比例的更多关注</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1379.png)<st
    c="24151"><st c="24153">。</st></st></st></st></st></st>
- en: '![Figure 4.3: The effect of outliers on OLS regression](img/B19496_04_03.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3：离群值对 OLS 回归的影响](img/B19496_04_03.jpg)'
- en: '<st c="24186">Figure 4.3: The effect of outliers on OLS regression</st>'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24186">图 4.3：离群值对 OLS 回归的影响</st>
- en: <st c="24238">This tells us that OLS is sensitive to the</st> <st c="24281">effect
    of outliers.</st> <st c="24302">Including the outliers in the OLS regression in</st>
    *<st c="24350">Figure 4</st>**<st c="24358">.3</st>* <st c="24360">has led to
    a</st> <st c="24374">model that is a poor fit for most of the data in the scatterplot,
    and importantly, it has led to a model that will predict poorly for new datapoints.</st>
    <st c="24524">Can we rectify this?</st> <st c="24545">Yes, we can.</st> <st c="24558">One
    way to do so would be to modify the shape of our loss function so that it wasn’t
    quadratic at large residual values.</st> <st c="24679">Such a loss function is
    shown by the solid black line in</st> *<st c="24736">Figure 4</st>**<st c="24744">.4</st>*<st
    c="24746">. For comparison, we have also plotted in</st> *<st c="24788">Figure
    4</st>**<st c="24796">.4</st>* <st c="24798">the squared-loss function</st> <st
    c="24825">of</st> *<st c="24828">Eq.</st> <st c="24832">8</st>*<st c="24833">,
    as the dashed</st> <st c="24849">red line:</st>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24238">这告诉我们 OLS 对离群点的</st> <st c="24281">影响非常敏感。</st> <st c="24302">将离群点纳入
    OLS 回归分析</st> *<st c="24350">图 4</st>**<st c="24358">.3</st>* <st c="24360">导致了一个对散点图中大多数数据拟合不佳的模型，更重要的是，它导致了一个对新数据点预测效果不佳的模型。</st>
    <st c="24524">我们能纠正这个问题吗？</st> <st c="24545">是的，我们可以。</st> <st c="24558">一种方法是修改损失函数的形状，使其在较大的残差值下不再是二次的。</st>
    <st c="24679">这种损失函数由</st> *<st c="24736">图 4</st>**<st c="24744">.4</st>*<st
    c="24746">中的实线黑色曲线表示。为了对比，我们还在</st> *<st c="24788">图 4</st>**<st c="24796">.4</st>*
    <st c="24798">中绘制了</st> *<st c="24828">公式</st> <st c="24832">8</st>*<st c="24833">的平方损失函数，作为虚线红色曲线：</st>
- en: '![Figure 4.4: The shape of the pseudo-Huber robust loss function](img/B19496_04_04.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4: 伪-Huber 鲁棒损失函数的形状](img/B19496_04_04.jpg)'
- en: '<st c="24949">Figure 4.4: The shape of the pseudo-Huber robust loss function</st>'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '<st c="24949">图 4.4: 伪-Huber 鲁棒损失函数的形状</st>'
- en: <st c="25011">This particular loss</st> <st c="25033">function is known as a
    pseudo-Huber loss function, and its mathematical for</st><st c="25108">m is</st>
    <st c="25114">the following:</st>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25011">这个特殊的损失</st> <st c="25033">函数被称为伪-Huber 损失函数，它的数学形式是</st> <st
    c="25108">如下：</st> <st c="25114">以下：</st>
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo> </mml:mo><mml:mo>-</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:math>](img/1421.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo> </mml:mo><mml:mo>-</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:math>](img/1421.png)'
- en: <st c="25144">Eq.</st> <st c="25148">12</st>
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25144">公式</st> <st c="25148">12</st>
- en: <st c="25150">At large values of</st> <st c="25170">x</st><st c="25171">, this
    loss function is</st> <st c="25195">approximately linear.</st> <st c="25217">The
    contrast to the squared-loss function at large values of</st> <st c="25278">x</st>
    <st c="25279">is marked.</st> <st c="25291">Using the pseudo-Huber loss function
    in</st> *<st c="25331">Figure 4</st>**<st c="25339">.4</st>* <st c="25341">would
    mean</st> <st c="25352">that outlier values would still contribute to the empirical
    risk function, but not disproportionately so.</st> <st c="25459">The regression
    algorithm would then be robust to the presence of outliers in the dataset, and
    importantly, we would produce a model that is more accurate in its predictions
    on new values</st> <st c="25646">of</st> <st c="25649">x</st><st c="25650">.</st>
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25150">在较大的</st> <st c="25170">x</st><st c="25171">值时，这个损失函数大致是线性的。</st>
    <st c="25195">与平方损失函数在较大</st> <st c="25278">x</st> <st c="25279">值下的对比很明显。</st>
    <st c="25291">在</st> *<st c="25331">图 4</st>**<st c="25339">.4</st>* <st c="25341">中使用伪-Huber
    损失函数意味着离群点的值仍然会对经验风险函数产生影响，但不会过度影响。</st> <st c="25459">回归算法因此能对数据集中的离群点保持鲁棒性，更重要的是，我们将得到一个对新值的预测更准确的模型。</st>
    <st c="25646">对于</st> <st c="25649">x</st><st c="25650">的值。</st>
- en: <st c="25651">Not surprisingly, loss functions of the shape shown in</st> *<st
    c="25707">Figure 4</st>**<st c="25715">.4</st>* <st c="25717">are studied as a
    part of statistics known as</st> **<st c="25763">robust statistics</st>**<st c="25780">.
    A detailed explanation of robust statistics techniques is beyond the scope of
    this book.</st> <st c="25871">However, the</st> <st c="25883">very fact that robust
    regression techniques</st> <st c="25927">are available to us may make you ask
    why we still use and study OLS regression.</st> <st c="26008">The answer lies
    in something we haven’t yet spoken about – for OLS, how do we actually do the
    minimization of the empirical risk function?</st> <st c="26147">What are the details
    of the algorithm we use?</st> <st c="26193">For OLS regression, the combination
    of a linear model with a squared-loss function leads to an extremely efficient
    solution to the empirical risk minimization problem.</st> <st c="26361">It is
    this solution we will cover in the next section, but for now, let’s summarize
    what we have learned about the squared-loss function and</st> <st c="26502">least
    squares.</st>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25651">不出所料，形如</st> *<st c="25707">图 4</st>**<st c="25715">.4</st>* <st
    c="25717">的损失函数被作为一种统计方法，属于</st> **<st c="25763">稳健统计学</st>**<st c="25780">的研究范畴。稳健统计学技术的详细解释超出了本书的范围。</st>
    <st c="25871">然而，</st> <st c="25883">正因为稳健回归技术的存在</st> <st c="25927">，你可能会问：为什么我们仍然使用和研究普通最小二乘（OLS）回归呢？</st>
    <st c="26008">答案就在于我们尚未讨论的一个问题——对于 OLS，我们到底是如何进行经验风险函数的最小化的？</st> <st c="26147">我们使用的算法的具体细节是什么？</st>
    <st c="26193">对于 OLS 回归，线性模型与平方损失函数的结合提供了一个极为高效的经验风险最小化解法。</st> <st c="26361">这一解法将在下一节中详细讲解，但现在，让我们总结一下关于平方损失函数和</st>
    <st c="26502">最小二乘法的知识。</st>
- en: <st c="26516">What we learned</st>
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="26516">我们所学到的内容</st>
- en: <st c="26532">In this section, we have learned about</st> <st c="26572">the
    following:</st>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26532">在本节中，我们学习了以下内容：</st>
- en: <st c="26586">The squared-loss function and its</st> <st c="26621">mathematical
    shape</st>
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="26586">平方损失函数及其</st> <st c="26621">数学形态</st>
- en: <st c="26639">Least squares minimization as a general heuristic technique for
    estimating optimal model</st> <st c="26729">parameter values</st>
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="26639">最小二乘法最小化作为一种通用启发式技术，用于估计最佳模型</st> <st c="26729">参数值</st>
- en: <st c="26745">OLS regression as a technique for estimating the parameters of</st>
    <st c="26809">linear models</st>
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="26745">OLS 回归作为一种估计</st> <st c="26809">线性模型参数的技术</st>
- en: <st c="26822">The sensitivity of OLS regression</st> <st c="26857">to outliers</st>
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="26822">OLS 回归的</st> <st c="26857">对离群值的敏感性</st>
- en: <st c="26868">Robust loss functions and how they can mitigate the sensitivity
    of OLS regression</st> <st c="26951">to outliers</st>
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="26868">稳健损失函数及其如何减少 OLS 回归</st> <st c="26951">对离群值的敏感性</st>
- en: <st c="26962">Having learned about the general ideas and principles of OLS regression,
    we will delve into the mathematical detail behind OLS in the next section.</st>
    <st c="27111">This will be useful because i) OLS is one of the workhorse algorithms
    of data science, ii) it will help to highlight some ideas about the optimization
    of objective functions in general that we will want to make use of</st> <st c="27329">later
    on.</st>
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26962">了解了 OLS 回归的一般思路和原则后，我们将在下一节深入探讨 OLS 背后的数学细节。</st> <st c="27111">这将非常有用，因为
    i) OLS 是数据科学中的主要算法之一，ii) 它将有助于揭示一些关于优化目标函数的思路，这些思路我们将在后续使用。</st> <st c="27329">以后会用到这些思路。</st>
- en: <st c="27338">Linear models</st>
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="27338">线性模型</st>
- en: <st c="27352">We’ve already introduced, at a high level, the idea of OLS regression
    for a linear model.</st> <st c="27443">But this particular combination of squared
    loss for measuring the risk and a linear model for</st> <st c="27537">ˆ</st><st
    c="27538">y</st> <st c="27539">has some very convenient</st> <st c="27564">and
    simple-to-use properties.</st> <st c="27595">This simplicity means that OLS regression
    is one of the most widely used and studied data science modeling techniques.</st>
    <st c="27714">That is why we are going to look in detail at fitting linear models
    to data using</st> <st c="27796">OLS regression.</st>
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27352">我们已经在较高层次上介绍了 OLS 回归在线性模型中的应用。</st> <st c="27443">但这种将平方损失用于衡量风险的特殊组合以及线性模型的使用</st>
    <st c="27537">ˆ</st><st c="27538">y</st> <st c="27539">具有一些非常方便</st> <st c="27564">且易于使用的特性。</st>
    <st c="27595">这种简洁性意味着 OLS 回归是最广泛使用和研究的数据科学建模技术之一。</st> <st c="27714">这就是为什么我们要详细探讨如何使用
    OLS 回归来拟合线性模型。</st>
- en: <st c="27811">To start with, we’ll revisit the squared-loss empirical risk function
    in</st> *<st c="27885">Eq.</st> <st c="27889">10</st>* <st c="27891">and look
    at what happens to it when we have a linear model</st> <st c="27951">ˆ</st><st
    c="27952">y</st><st c="27953">. To recap, the squared-loss empirical risk is</st>
    <st c="27999">given by</st> <st c="28009">the following:</st>
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27811">首先，我们将重新审视在</st> *<st c="27885">方程</st>* <st c="27889">10</st>*
    <st c="27891">中的平方损失经验风险函数，并观察当我们有一个线性模型时，它的变化。</st> <st c="27951">ˆ</st><st c="27952">y</st><st
    c="27953">。回顾一下，平方损失经验风险是</st> <st c="27999">由以下公式给出：</st> <st c="28009">如下：</st>
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>Risk</mml:mtext><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>](img/1422.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>风险</mml:mtext><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>](img/1422.png)'
- en: <st c="28025">Eq.</st> <st c="28029">13</st>
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28025">方程。</st> <st c="28029">13</st>
- en: <st c="28031">Now, for a linear model with</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>d</mml:mi></mml:math>](img/596.png)
    <st c="28061"><st c="28062">features,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math>](img/1424.png)<st
    c="28073"><st c="28086">, we can wri</st><st c="28098">te the model</st> <st c="28112">as
    follows:</st></st></st>
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28031">现在，对于一个线性模型，具有</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>d</mml:mi></mml:math>](img/596.png)
    <st c="28061"><st c="28062">特征，</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math>](img/1424.png)<st
    c="28073"><st c="28086">，我们可以将模型表示为：</st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><mspace
    width="0.25em" /><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mspace
    width="0.25em" /><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mspace
    width="0.25em" /><mo>⋯</mo><mo>+</mo><mspace width="0.25em" /><msub><mi>β</mi><mi>d</mi></msub><msub><mi>x</mi><mi>d</mi></msub></mrow></mrow></math>](img/1425.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><mspace
    width="0.25em" /><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mspace
    width="0.25em" /><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mspace
    width="0.25em" /><mo>⋯</mo><mo>+</mo><mspace width="0.25em" /><msub><mi>β</mi><mi>d</mi></msub><msub><mi>x</mi><mi>d</mi></msub></mrow></mrow></math>](img/1425.png)'
- en: <st c="28142">Eq.</st> <st c="28146">14</st>
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28142">方程。</st> <st c="28146">14</st>
- en: <st c="28148">The vector of model parameters is</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1426.png)<st
    c="28183"><st c="28196">. We can write the features in vector form as well.</st>
    <st c="28248">We’ll write</st> <st c="28259">it as a row-vector,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1427.png)<st
    c="28280"><st c="28299">. Doing so allows us to write</st> *<st c="28329">Eq.</st>
    <st c="28333">14</st>* <st c="28335">in the</st> <st c="28343">following form:</st></st></st>
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28148">模型参数的向量是</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1426.png)<st
    c="28183"><st c="28196">。我们也可以用向量形式来表示特征。</st> <st c="28248">我们将其表示为</st> <st
    c="28259">行向量，</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1427.png)<st
    c="28280"><st c="28299">。这样我们可以将</st> *<st c="28329">方程</st> <st c="28333">14</st>*
    <st c="28335">写成如下形式：</st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1428.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1428.png)'
- en: <st c="28360">Eq.</st> <st c="28364">15</st>
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28360">方程</st> <st c="28364">15</st>
- en: <st c="28366">We can think of the extra 1 in the feature vector</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1429.png)
    <st c="28417"><st c="28436">as being a feature value</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/1430.png)
    <st c="28461"><st c="28462">that multiplies the intercept</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/1431.png)
    <st c="28493"><st c="28494">in the linear model in Eq.</st> <st c="28522">14\.</st>
    <st c="28526">For the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math>](img/1394.png)
    <st c="28534"><st c="28538">datapoint the feature values can be written in vector
    form,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1433.png)<st
    c="28598"><st c="28599">, with obviously</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/1434.png)
    <st c="28616"><st c="28617">for all</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi></mml:math>](img/102.png)<st
    c="28626"><st c="28627">. We can combine all the feature vectors</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1380.png)
    <st c="28668"><st c="28672">from all the datapoints into a</st> <st c="28703">data
    matrix:</st></st></st></st></st></st></st></st></st>
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将特征向量中的额外1看作是![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1429.png)
    <st c="28417"><st c="28436">作为特征值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/1430.png)
    <st c="28461"><st c="28462">，它与截距相乘</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>](img/1431.png)
    <st c="28493"><st c="28494">在方程14中的线性模型中</st> <st c="28522">。对于第</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math>](img/1394.png)
    <st c="28534"><st c="28538">个数据点，特征值可以表示为向量形式，</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1433.png)<st
    c="28598"><st c="28599">，显然</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/1434.png)
    <st c="28616"><st c="28617">对于所有的</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>i</mml:mi></mml:math>](img/102.png)<st
    c="28626"><st c="28627">。我们可以将所有的特征向量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1380.png)
    <st c="28668"><st c="28672">从所有数据点组合成一个</st> <st c="28703">数据矩阵：</st></st></st></st></st></st></st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mspace width="0.25em"
    /><mo>=</mo><mspace width="0.25em" /><mfenced open="(" close=")"><mtable columnspacing="0.8000em
    0.8000em 0.8000em 0.8000em" columnwidth="auto auto auto auto auto" columnalign="center
    center center center center" rowspacing="1.0000ex 1.0000ex 1.0000ex" rowalign="baseline
    baseline baseline baseline"><mtr><mtd><msub><mi>x</mi><mn>10</mn></msub></mtd><mtd><msub><mi>x</mi><mn>11</mn></msub></mtd><mtd><msub><mi>x</mi><mn>12</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>1</mn><mi>d</mi></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>x</mi><mn>20</mn></msub></mtd><mtd><msub><mi>x</mi><mn>21</mn></msub></mtd><mtd><msub><mi>x</mi><mn>22</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>2</mn><mi>d</mi></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋱</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>0</mn></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>1</mn></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>2</mn></mrow></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mi>d</mi></mrow></msub></mtd></mtr></mtable></mfenced><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mfenced open="(" close=")"><mtable
    columnspacing="0.8000em 0.8000em 0.8000em 0.8000em" columnwidth="auto auto auto
    auto auto" columnalign="center center center center center" rowspacing="1.0000ex
    1.0000ex 1.0000ex" rowalign="baseline baseline baseline baseline"><mtr><mtd><mn>1</mn></mtd><mtd><msub><mi>x</mi><mn>11</mn></msub></mtd><mtd><msub><mi>x</mi><mn>12</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>1</mn><mi>d</mi></mrow></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><msub><mi>x</mi><mn>21</mn></msub></mtd><mtd><msub><mi>x</mi><mn>22</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>2</mn><mi>d</mi></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋱</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>1</mn></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>2</mn></mrow></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mi>d</mi></mrow></msub></mtd></mtr></mtable></mfenced></mrow></mrow></math>](img/1437.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mspace width="0.25em"
    /><mo>=</mo><mspace width="0.25em" /><mfenced open="(" close=")"><mtable columnspacing="0.8000em
    0.8000em 0.8000em 0.8000em" columnwidth="auto auto auto auto auto" columnalign="center
    center center center center" rowspacing="1.0000ex 1.0000ex 1.0000ex" rowalign="baseline
    baseline baseline baseline"><mtr><mtd><msub><mi>x</mi><mn>10</mn></msub></mtd><mtd><msub><mi>x</mi><mn>11</mn></msub></mtd><mtd><msub><mi>x</mi><mn>12</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>1</mn><mi>d</mi></mrow></msub></mtd></tr><mtr><mtd><msub><mi>x</mi><mn>20</mn></msub></mtd><mtd><msub><mi>x</mi><mn>21</mn></msub></mtd><mtd><msub><mi>x</mi><mn>22</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>2</mn><mi>d</mi></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋱</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>0</mn></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>1</mn></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>2</mn></mrow></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mi>d</mi></mrow></msub></mtd></mtr></mtable></mfenced><mspace
    width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mfenced open="(" close=")"><mtable
    columnspacing="0.8000em 0.8000em 0.8000em 0.8000em" columnwidth="auto auto auto
    auto auto" columnalign="center center center center center" rowspacing="1.0000ex
    1.0000ex 1.0000ex" rowalign="baseline baseline baseline baseline"><mtr><mtd><mn>1</mn></mtd><mtd><msub><mi>x</mi><mn>11</mn></msub></mtd><mtd><msub><mi>x</mi><mn>12</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>1</mn><mi>d</mi></mrow></msub></mtd></tr><mtr><mtd><mn>1</mn></mtd><mtd><msub><mi>x</mi><mn>21</mn></msub></mtd><mtd><msub><mi>x</mi><mn>22</mn></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mn>2</mn><mi>d</mi></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋱</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>1</mn></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mn>2</mn></mrow></msub></mtd><mtd><mo>…</mo></mtd><mtd><msub><mi>x</mi><mrow><mi>N</mi><mi>d</mi></mrow></msub></mtd></mtr></mtable></mfenced></mrow></mrow></math>](img/1437.png)'
- en: <st c="28724">Eq.</st> <st c="28728">16</st>
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28724">等式</st> <st c="28728">16</st>
- en: <st c="28730">If we also put all the observed values,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1438.png)<st
    c="28771"><st c="28772">, into a vector</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1439.png)<st
    c="28788"><st c="28807">, then we can write the risk function in</st> *<st c="28848">Eq.</st>
    <st c="28852">13</st>* <st c="28854">in a very</st> <st c="28865">succinct form</st>
    <st c="28879">as follows:</st></st></st>
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们还将所有观察到的值，![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1438.png)<st
    c="28771"><st c="28772">，放入一个向量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1439.png)<st
    c="28788"><st c="28807">，那么我们可以将风险函数写成</st> *<st c="28848">公式</st> <st c="28852">13</st>*
    <st c="28854">的简洁形式</st> <st c="28865">如下：</st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>Risk</mtext><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><mspace
    width="0.25em" /><msup><mfenced open="(" close=")"><mrow><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder><mo>−</mo><mspace width="0.25em" /><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mspace width="0.25em"
    /><munder><mi>β</mi><mo stretchy="true">_</mo></munder></mrow></mfenced><mi mathvariant="normal">⊤</mi></msup><mfenced
    open="(" close=")"><mrow><munder><mi>y</mi><mo stretchy="true">_</mo></munder><mo>−</mo><mspace
    width="0.25em" /><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfenced></mrow></mrow></math>](img/1440.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>风险</mtext><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><mspace
    width="0.25em" /><msup><mfenced open="(" close=")"><mrow><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder><mo>−</mo><mspace width="0.25em" /><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mspace width="0.25em"
    /><munder><mi>β</mi><mo stretchy="true">_</mo></munder></mrow></mfenced><mi mathvariant="normal">⊤</mi></msup><mfenced
    open="(" close=")"><mrow><munder><mi>y</mi><mo stretchy="true">_</mo></munder><mo>−</mo><mspace
    width="0.25em" /><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfenced></mrow></mrow></math>](img/1440.png)'
- en: <st c="28892">Eq.</st> <st c="28896">17</st>
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 公式<st c="28892">17</st>
- en: <st c="28898">The data matrix</st> <st c="28915">X</st><st c="28916">_</st><st
    c="28917">_</st> <st c="28918">is also called the</st> **<st c="28938">design
    matrix</st>**<st c="28951">. This terminology originates from statistics, where
    often the datapoints</st> <st c="29024">and, hence, feature values were part of
    a scientific experiment to quantify the various influences on the response variable</st>
    <st c="29149">y</st><st c="29150">. Being part of a scientific experiment, the
    feature values</st> <st c="29210">x</st><st c="29211">ij</st> <st c="29213">were
    planned in advance; that</st> <st c="29244">is,</st> *<st c="29248">designed</st>*<st
    c="29256">.</st>
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 数据矩阵<st c="28915">X</st><st c="28916">_</st><st c="28917">_</st> 也称为 **设计矩阵**。这个术语源自统计学，其中数据点<st
    c="29024">以及特征值通常是科学实验的一部分，用于量化对响应变量</st> <st c="29149">y</st><st c="29150">的各种影响</st>。作为科学实验的一部分，特征值<st
    c="29210">x</st><st c="29211">ij</st> 是预先规划的；也就是说，*被设计过*。
- en: <st c="29257">The optimal values of the model</st> <st c="29290">parameters</st>
    <st c="29301">β</st><st c="29302">_</st> <st c="29303">are obtained by minimizing
    the right-hand side of</st> *<st c="29354">Eq.</st> <st c="29358">17</st>* <st
    c="29360">with respect to</st> <st c="29377">β</st><st c="29378">_</st><st c="29379">.
    We’ll denote the optimal values of</st> <st c="29416">β</st><st c="29417">_</st>
    <st c="29418">by the symbol</st> <st c="29433">ˆ</st><st c="29434">β</st><st c="29435">_</st><st
    c="29436">. We can use the differential calculus we recapped in</st> [*<st c="29490">Chapter
    1</st>*](B19496_01.xhtml#_idTextAnchor014) <st c="29499">to do the minimization.</st>
    <st c="29524">Differentiating the right-hand side of</st> *<st c="29563">Eq.</st>
    <st c="29567">17</st>* <st c="29569">with respect to</st> <st c="29586">β</st><st
    c="29587">_</st> <st c="29588">and setting the derivatives to z</st><st c="29621">ero
    gives us</st> <st c="29635">the following:</st>
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29257">模型的最优值</st> <st c="29290">参数</st> <st c="29301">β</st><st c="29302">_</st>
    <st c="29303">是通过最小化</st> *<st c="29354">方程</st> <st c="29358">17</st>* <st c="29360">右边的部分得到的</st>
    <st c="29377">β</st><st c="29378">_</st><st c="29379">。我们将模型的最优值</st> <st c="29416">β</st><st
    c="29417">_</st> <st c="29418">表示为</st> <st c="29433">ˆ</st><st c="29434">β</st><st
    c="29435">_</st><st c="29436">。我们可以使用我们在</st> [*<st c="29490">第1章</st>*](B19496_01.xhtml#_idTextAnchor014)
    <st c="29499">回顾过的微积分方法来进行最小化。</st> <st c="29524">对</st> *<st c="29563">方程</st>
    <st c="29567">17</st>* <st c="29569">右边部分对</st> <st c="29586">β</st><st c="29587">_</st>
    <st c="29588">求导并将导数设为零，得到如下结果：</st> <st c="29621">零</st><st c="29635">如下：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mfenced
    open="" close="|"><mrow><mspace width="0.25em" /><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mrow></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></munder></mrow></msub><mo>=</mo><mfrac><mn>2</mn><mi>N</mi></mfrac><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><mfenced
    open="(" close=")"><mrow><munder><mi>y</mi><mo stretchy="true">_</mo></munder><mo>−</mo><mspace
    width="0.25em" /><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced><mo>=</mo><mspace
    width="0.25em" /><munder><mn>0</mn><mo stretchy="true">_</mo></munder></mrow></mrow></math>](img/1441.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mfenced
    open="" close="|"><mrow><mspace width="0.25em" /><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mrow></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></munder></mrow></msub><mo>=</mo><mfrac><mn>2</mn><mi>N</mi></mfrac><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><mfenced
    open="(" close=")"><mrow><munder><mi>y</mi><mo stretchy="true">_</mo></munder><mo>−</mo><mspace
    width="0.25em" /><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced><mo>=</mo><mspace
    width="0.25em" /><munder><mn>0</mn><mo stretchy="true">_</mo></munder></mrow></mrow></math>](img/1441.png)'
- en: <st c="29651">Eq.</st> <st c="29655">18</st>
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29651">方程</st> <st c="29655">18</st>
- en: <st c="29657">Re-arranging</st> *<st c="29671">Eq</st><st c="29673">. 18</st>*<st
    c="29677">, we get</st> <st c="29686">the following:</st>
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29657">对</st> *<st c="29671">方程</st><st c="29673">18</st>*<st c="29677">重新排列后，得到如下结果：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mspace width="0.25em"
    /><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>=</mo><mspace
    width="0.25em" /><msup><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1442.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mspace width="0.25em"
    /><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>=</mo><mspace
    width="0.25em" /><msup><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1442.png)'
- en: <st c="29713">Eq.</st> <st c="29717">19</st>
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29713">方程</st> <st c="29717">19</st>
- en: <st c="29719">We can solve</st> *<st c="29733">Eq.</st> <st c="29737">19</st>*
    <st c="29739">by applying</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math>](img/1443.png)<st
    c="29752"><st c="29753">to both the left- and right-hand sides of</st> *<st c="29795">E</st><st
    c="29796">q.</st> <st c="29799">19</st>* <st c="29801">to get</st> <st c="29809">the
    following:</st></st>
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29719">我们可以通过应用</st> *<st c="29733">方程</st> <st c="29737">19</st>* <st
    c="29739">来解</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math>](img/1443.png)<st
    c="29752"><st c="29753">应用于方程</st> *<st c="29795">E</st><st c="29796">q.</st>
    <st c="29799">19</st>* <st c="29801">的左右两边，得到：</st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>=</mo><mspace
    width="0.25em" /><msup><mfenced open="(" close=")"><mrow><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder></mrow></mfenced><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1444.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>=</mo><mspace
    width="0.25em" /><msup><mfenced open="(" close=")"><mrow><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></mml:munder><mo stretchy="true">_</mo></mml:mrow></mfenced><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><munder><munder><mi>X</mi><mo
    stretchy="true">_</mo></munder><mo stretchy="true">_</mo></munder><mi mathvariant="normal">⊤</mi></msup><munder><mi>y</mi><mo
    stretchy="true">_</mo></munder></mrow></mrow></math>](img/1444.png)'
- en: <st c="29825">Eq.</st> <st c="29829">20</st>
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29825">方程</st> <st c="29829">20</st>
- en: <st c="29831">This solution is very efficient.</st> <st c="29865">It is in a
    closed-form, meaning we have an equation with the thing we want,</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)<st
    c="29941"><st c="29942">, on its own on the left-hand side, and a mathematical
    expression that doesn’t involve</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)
    <st c="30029"><st c="30030">on the right-hand side.</st> <st c="30055">There is
    no iterative algorithm required.</st> <st c="30097">We just perform a couple of
    matrix calculations, and we have our optimal parameter estimates</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1447.png)<st
    c="30190"><st c="30195">. That we can obtain a closed-form expression for the
    parameter estimates is one of the most attractive aspects of OLS regression and
    part of the reason it is so widely used.</st> <st c="30370">We’ll walk through
    some code examples in a moment to illustrate how easy it is to perform</st> <st
    c="30460">OLS regression.</st></st></st></st>
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29831">这个解法非常高效。</st> <st c="29865">它是封闭形式的，这意味着我们得到了一个包含我们想要的内容的方程，</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)<st
    c="29941"><st c="29942">，它单独位于左边，而右边的数学表达式不包含</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)
    <st c="30029"><st c="30030">。无需迭代算法。</st> <st c="30055">我们只需要进行几次矩阵计算，就可以得到我们的最优参数估计</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1447.png)<st
    c="30190"><st c="30195">。能够为参数估计得到封闭形式的表达式是OLS回归最吸引人的方面之一，也是它被广泛使用的部分原因。</st>
    <st c="30370">稍后我们将通过一些代码示例，演示如何轻松地进行</st> <st c="30460">OLS回归。</st></st></st></st>
- en: <st c="30475">Practical issues</st>
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="30475">实际问题</st>
- en: <st c="30492">This doesn’t mean the closed-form expression in</st> *<st c="30541">Eq.</st>
    <st c="30545">20</st>* <st c="30547">doesn’t cause problems.</st> <st c="30572">Firstly,
    you’ll recall from</st> [*<st c="30600">Chapter 3</st>*](B19496_03.xhtml#_idTextAnchor141)
    <st c="30609">on linear</st> <st c="30620">algebra that we can have square matrices
    that do not have an inverse.</st> <st c="30690">It is very possible that the matrix</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math>](img/1448.png)<st
    c="30726"><st c="30727">does not exist.</st> <st c="30743">This happens when there
    are linear dependencies between the columns of the design matrix</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1449.png)<st
    c="30832"><st c="30833">; for example, if one feature is simply a scaled version
    of another feature, or where combining several features together gives the same
    numerical value as another feature.</st> <st c="31006">In these circumstances,
    one or more of the features are redundant since they add no</st> <st c="31090">new
    information.</st></st></st>
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30492">这并不意味着</st> *<st c="30541">公式</st> <st c="30545">20</st>* <st
    c="30547">中的闭式表达式不会引起问题。</st> <st c="30572">首先，您会从</st> [*<st c="30600">第3章</st>*](B19496_03.xhtml#_idTextAnchor141)
    <st c="30609">线性代数部分回想起，我们可以有一些没有逆矩阵的方阵。</st> <st c="30690">矩阵</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math>](img/1448.png)<st
    c="30726"><st c="30727">是不存在的。</st> <st c="30743">这种情况发生在设计矩阵的列之间存在线性依赖时</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1449.png)<st
    c="30832"><st c="30833">；例如，如果某个特征只是另一个特征的缩放版本，或者将多个特征组合在一起得到的数值与另一个特征相同。</st>
    <st c="31006">在这些情况下，一个或多个特征是冗余的，因为它们没有提供任何</st> <st c="31090">新信息。</st></st></st>
- en: <st c="31106">Secondly, in a modern-day data science setting where we might
    have many thousands of features in a model, the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>d</mml:mi><mml:mo> </mml:mo><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:math>](img/1450.png)
    <st c="31217"><st c="31218">matrix</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1451.png)
    <st c="31226"><st c="31230">can be unwieldy to work with if</st> <st c="31262">d</st>
    <st c="31263">is of the order of</st> <st c="31283">several thousand.</st></st></st>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31106">其次，在现代数据科学中，如果模型中包含成千上万的特征，</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>d</mml:mi><mml:mo> </mml:mo><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:math>](img/1450.png)
    <st c="31217"><st c="31218">矩阵</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1451.png)
    <st c="31226"><st c="31230">在处理时可能会变得笨重，尤其是当</st> <st c="31262">d</st> <st c="31263">的数量级达到</st>
    <st c="31283">几千时。</st></st></st>
- en: <st c="31300">How to deal with these computational issues is beyond the scope
    of the book, but they are something you should be aware of in case they crop up
    in a problem you are trying</st> <st c="31473">to solve.</st>
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31300">如何处理这些计算问题超出了本书的范围，但如果你在解决问题时遇到这些问题，应该对此有所了解。</st>
- en: <st c="31482">The model residuals</st>
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="31482">模型残差</st>
- en: <st c="31502">Once we have obtained an estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)
    <st c="31537"><st c="31538">for the</st> <st c="31547">model parameters, using</st>
    *<st c="31571">Eq.</st> <st c="31575">20</st>*<st c="31577">, we can calculate
    the residuals.</st> <st c="31611">If we denote the</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math>](img/1394.png)
    <st c="31628"><st c="31632">residual by</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1454.png)<st
    c="31644"><st c="31645">, then obviously we have</st> <st c="31670">the following:</st></st></st></st>
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31502">一旦我们获得了一个估计值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)
    <st c="31537"><st c="31538">对于</st> <st c="31547">模型参数，使用</st> *<st c="31571">公式</st>
    <st c="31575">20</st>*<st c="31577">，我们可以计算残差。</st> <st c="31611">如果我们将</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math>](img/1394.png)
    <st c="31628"><st c="31632">残差记作</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1454.png)<st
    c="31644"><st c="31645">，那么显然我们得到以下公式：</st> <st c="31670">以下：</st></st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><mspace
    width="0.25em" /><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><msub><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mo>=</mo><mspace
    width="0.25em" /><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>i</mi></msub><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>=</mo><mspace
    width="0.25em" /><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><msub><mfenced open="(" close=")"><mrow><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced><mi>i</mi></msub></mrow></mrow></math>](img/1455.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><mspace
    width="0.25em" /><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><msub><mover><mi>y</mi><mo stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mo>=</mo><mspace
    width="0.25em" /><msub><mi>y</mi><mi>i</mi></sub><mo>−</mo><mspace width="0.25em"
    /><msub><munder><mi>x</mi><mo stretchy="true">_</mo></munder><mi>i</mi></msub><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>=</mo><mspace
    width="0.25em" /><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><msub><mfenced open="(" close=")"><mrow><munder><munder><mi>X</mi><mo stretchy="true">_</mo></munder><mo
    stretchy="true">_</mo></munder><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced><mi>i</mi></sub></mrow></mrow></math>](img/1455.png)'
- en: <st c="31695">Eq.</st> <st c="31699">21</st>
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31695">公式</st> <st c="31699">21</st>
- en: <st c="31701">What happens if we sum up all the residuals?</st> <st c="31747">To
    answer this question, we make use of</st> *<st c="31787">Eq.</st> <st c="31791">19</st>*
    <st c="31793">and recall that the first row of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:math>](img/1456.png)<st
    c="31827"><st c="31830">is all ones if our model has an intercept.</st> <st c="31873">So,</st>
    *<st c="31877">Eq.</st> <st c="31881">19</st>* <st c="31883">tells us</st> <st
    c="31893">the following:</st></st>
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31701">如果我们将所有的残差加起来，会发生什么呢？</st> <st c="31747">为了解答这个问题，我们使用</st> *<st
    c="31787">公式</st> <st c="31791">19</st>* <st c="31793">并回顾一下，如果我们的模型有截距，则第一行的</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:math>](img/1456.png)<st
    c="31827"><st c="31830">是全为1的。</st> <st c="31873">所以，</st> *<st c="31877">公式</st>
    <st c="31881">19</st>* <st c="31883">告诉我们</st> <st c="31893">以下内容：</st></st>
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mfenced open="" close="" separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo>⇒</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced
    open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:math>](img/1457.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mfenced open="" close="" separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo>⇒</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced
    open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:math>](img/1457.png)'
- en: <st c="31909">Eq.</st> <st c="31913">22</st>
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31909">方程式</st> <st c="31913">22</st>
- en: <st c="31915">So, the sum of all the residuals is zero if our model has</st>
    <st c="31974">an intercept.</st>
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31915">所以，如果我们的模型有</st> <st c="31974">截距项，那么所有残差的和为零。</st>
- en: <st c="31987">Let’s see these ideas in</st> <st c="32012">action with a</st>
    <st c="32027">code example.</st>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31987">让我们通过</st> <st c="32012">一个</st> <st c="32027">代码示例来看这些思想如何应用。</st>
- en: <st c="32040">OLS regression code example</st>
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="32040">OLS 回归代码示例</st>
- en: <st c="32068">The data in the</st> `<st c="32085">Data/power_plant_output.csv</st>`
    <st c="32112">file in the GitHub repository contains measurements of the power
    output from electricity generation plants.</st> <st c="32221">The power (</st>`<st
    c="32232">PE</st>`<st c="32235">) is generated from a combination of gas turbines,
    steam turbines, and heat recovery steam generators, and</st> <st c="32343">so
    is affected by environmental factors in which the turbines operate, such as the
    ambient temperature (</st>`<st c="32447">AT</st>`<st c="32450">) and the steam
    turbine exhaust vacuum level (</st>`<st c="32497">V</st>`<st c="32499">).</st>
    <st c="32502">The dataset consists of 9,568 observations of the</st> `<st c="32552">PE</st>`<st
    c="32554">,</st> `<st c="32556">AT</st>`<st c="32558">, and</st> `<st c="32564">V</st>`
    <st c="32565">values.</st> <st c="32574">The data is a subset of the publicly
    available dataset held in the</st> *<st c="32641">UCI Machine Learning Repository</st>*
    <st c="32673">(</st>[<st c="32674">https://archive.ics.uci.edu/datasets</st>](https://archive.ics.uci.edu/datasets)<st
    c="32710">).</st> <st c="32714">The original data can be found</st> <st c="32745">at</st>
    [<st c="32748">https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant</st>](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant)<st
    c="32814">.</st>
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32068">GitHub 仓库中的</st> `<st c="32085">Data/power_plant_output.csv</st>`
    <st c="32112">文件包含了来自电力发电厂的功率输出测量数据。</st> <st c="32221">功率（</st>`<st c="32232">PE</st>`<st
    c="32235">）是由燃气轮机、蒸汽轮机和热回收蒸汽发生器的组合产生的，因此受环境因素的影响，如轮机操作时的环境温度（</st>`<st c="32447">AT</st>`<st
    c="32450">）和蒸汽轮机排气真空度（</st>`<st c="32497">V</st>`<st c="32499">）。</st> <st c="32502">数据集包含了9,568个关于</st>
    `<st c="32552">PE</st>`<st c="32554">、</st> `<st c="32556">AT</st>`<st c="32558">和</st>
    `<st c="32564">V</st>` <st c="32565">值的观察数据。</st> <st c="32574">该数据是公开可用数据集的一个子集，数据集存放在</st>
    *<st c="32641">UCI机器学习库</st>* <st c="32673">(</st>[<st c="32674">https://archive.ics.uci.edu/datasets</st>](https://archive.ics.uci.edu/datasets)<st
    c="32710">)。</st> <st c="32714">原始数据可以在</st> <st c="32745">以下链接找到：</st> [<st c="32748">https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant</st>](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant)<st
    c="32814">。</st>
- en: <st c="32815">We’ll use the data to build a linear model of the power output</st>
    `<st c="32879">PE</st>` <st c="32881">as a function of the</st> `<st c="32903">AT</st>`
    <st c="32905">and</st> `<st c="32910">V</st>` <st c="32911">values.</st> <st c="32920">We
    will build the linear model in two ways – i) using the Python</st> `<st c="32985">statsmodels</st>`
    <st c="32996">package, ii) using</st> *<st c="33016">Eq.</st> <st c="33020">20</st>*
    <st c="33022">via an explicit calculation.</st> <st c="33052">The following code
    example can be found in the</st> `<st c="33099">Code_Examples_Chap4.ipynb</st>`
    <st c="33124">notebook in the GitHub repository.</st> <st c="33160">To begin,
    we need to read in</st> <st c="33189">the data:</st>
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32815">我们将使用这些数据来构建一个线性模型，表示功率输出</st> `<st c="32879">PE</st>` <st c="32881">作为环境温度</st>
    `<st c="32903">AT</st>` <st c="32905">和</st> `<st c="32910">蒸汽压</st>` <st c="32911">的函数。</st>
    <st c="32920">我们将通过两种方式来构建这个线性模型 – i) 使用 Python</st> `<st c="32985">statsmodels</st>`
    <st c="32996">库，ii) 使用</st> *<st c="33016">方程 20</st>* <st c="33020">通过显式计算。</st>
    <st c="33052">以下代码示例可以在 GitHub 仓库中的</st> `<st c="33099">Code_Examples_Chap4.ipynb</st>`
    <st c="33124">笔记本中找到。</st> <st c="33160">首先，我们需要读取数据：</st>
- en: '[PRE0]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: <st c="33381">We’ll do a quick inspection of the data.</st> <st c="33423">First,
    we’ll compute some summary statistics of</st> <st c="33471">the data:</st>
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33381">我们将对数据进行快速检查。</st> <st c="33423">首先，我们将计算一些数据的摘要统计：</st>
- en: '[PRE1]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|  | <st c="33556">AT</st> | <st c="33559">V</st> | <st c="33561">PE</st> |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  | <st c="33556">环境温度</st> | <st c="33559">蒸汽压</st> | <st c="33561">发电量</st>
    |'
- en: '| --- | --- | --- | --- |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| <st c="33563">Count</st> | <st c="33569">9568.000000</st> | <st c="33581">9568.000000</st>
    | <st c="33593">9568.000000</st> |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33563">计数</st> | <st c="33569">9568.000000</st> | <st c="33581">9568.000000</st>
    | <st c="33593">9568.000000</st> |'
- en: '| <st c="33605">Mean</st> | <st c="33610">19.651231</st> | <st c="33620">54.305804</st>
    | <st c="33630">454.365009</st> |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33605">均值</st> | <st c="33610">19.651231</st> | <st c="33620">54.305804</st>
    | <st c="33630">454.365009</st> |'
- en: '| <st c="33641">Std</st> | <st c="33645">7.452473</st> | <st c="33654">12.707893</st>
    | <st c="33664">17.066995</st> |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33641">标准差</st> | <st c="33645">7.452473</st> | <st c="33654">12.707893</st>
    | <st c="33664">17.066995</st> |'
- en: '| <st c="33674">Min</st> | <st c="33678">1.810000</st> | <st c="33687">25.360000</st>
    | <st c="33697">420.260000</st> |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33674">最小值</st> | <st c="33678">1.810000</st> | <st c="33687">25.360000</st>
    | <st c="33697">420.260000</st> |'
- en: '| <st c="33708">25%</st> | <st c="33712">13.510000</st> | <st c="33722">41.740000</st>
    | <st c="33732">439.750000</st> |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33708">25%</st> | <st c="33712">13.510000</st> | <st c="33722">41.740000</st>
    | <st c="33732">439.750000</st> |'
- en: '| <st c="33743">50%</st> | <st c="33747">20.345000</st> | <st c="33757">52.080000</st>
    | <st c="33767">451.550000</st> |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33743">50%</st> | <st c="33747">20.345000</st> | <st c="33757">52.080000</st>
    | <st c="33767">451.550000</st> |'
- en: '| <st c="33778">75%</st> | <st c="33782">25.720000</st> | <st c="33792">66.540000</st>
    | <st c="33802">468.430000</st> |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33778">75%</st> | <st c="33782">25.720000</st> | <st c="33792">66.540000</st>
    | <st c="33802">468.430000</st> |'
- en: '| <st c="33813">Max</st> | <st c="33817">37.110000</st> | <st c="33827">81.560000</st>
    | <st c="33837">495.760000</st> |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| <st c="33813">最大值</st> | <st c="33817">37.110000</st> | <st c="33827">81.560000</st>
    | <st c="33837">495.760000</st> |'
- en: '<st c="33848">Table 4.1: Summary statistics for the power-plant dataset</st>'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33848">表 4.1：电厂数据集的汇总统计</st>
- en: <st c="33906">Next, we’ll visualize the relationship</st> <st c="33945">between
    the response variable (the target variable) and the features.</st> <st c="34016">We’ll
    start with the relationship between power output (</st>`<st c="34072">PE</st>`<st
    c="34075">) and ambient</st> <st c="34090">temperature (</st>`<st c="34103">AT</st>`<st
    c="34106">):</st>
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33906">接下来，我们将可视化响应变量（目标变量）与特征之间的关系。</st> <st c="33945">我们将从功率输出（</st>`<st
    c="34072">PE</st>`<st c="34075">）与环境</st> <st c="34090">温度（</st>`<st c="34103">AT</st>`<st
    c="34106">）之间的关系开始：</st>
- en: '[PRE2]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Figure 4.5: Plot of power output (PE) versus ambient temperature (AT)](img/B19496_04_05.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5：功率输出（PE）与环境温度（AT）关系图](img/B19496_04_05.jpg)'
- en: '<st c="34423">Figure 4.5: Plot of power output (PE) versus ambient temperature
    (AT)</st>'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34423">图 4.5：功率输出（PE）与环境温度（AT）关系图</st>
- en: <st c="34492">Now, let’s look at the relationship</st> <st c="34528">between
    power and</st> <st c="34547">vacuum (</st>`<st c="34555">V</st>`<st c="34557">):</st>
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34492">现在，让我们来看一下</st> <st c="34528">功率与</st> <st c="34547">真空（</st>`<st
    c="34555">V</st>`<st c="34557">）之间的关系：</st>
- en: '[PRE3]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Figure 4.6: Plot of power output (PE) versus vacuum level (V)](img/B19496_04_06.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6：功率输出（PE）与真空水平（V）关系图](img/B19496_04_06.jpg)'
- en: '<st c="34942">Figure 4.6: Plot of power output (PE) versus vacuum level (V)</st>'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34942">图 4.6：功率输出（PE）与真空水平（V）关系图</st>
- en: <st c="35003">Now, we’ll fit a linear model using the</st> `<st c="35044">statsmodels</st>`
    <st c="35055">package.</st> <st c="35065">The linear model formula is specified
    in statistical notation as</st> <st c="35130">PE</st> <st c="35132">∼</st> <st
    c="35134">AT + V</st><st c="35140">. You can think of it as the statistical formula
    equivalent</st> <st c="35199">of the mathematical formula</st> <st c="35228">PE
    =</st> <st c="35233">β</st><st c="35234">0</st> <st c="35235">+</st> <st c="35236">β</st><st
    c="35237">AT</st> <st c="35239">x</st><st c="35241">AT</st> <st c="35243">+</st>
    <st c="35245">β</st><st c="35246">V</st> <st c="35247">x</st><st c="35248">V</st><st
    c="35249">. We do this fitting using the</st> <st c="35280">following code:</st>
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35003">现在，我们将使用</st> `<st c="35044">statsmodels</st>` <st c="35055">包来拟合一个线性模型。</st>
    <st c="35065">线性模型公式用统计符号表示为</st> <st c="35130">PE</st> <st c="35132">∼</st> <st
    c="35134">AT + V</st><st c="35140">。你可以将其视为数学公式的统计等式</st> <st c="35199">PE =</st>
    <st c="35233">β</st><st c="35234">0</st> <st c="35235">+</st> <st c="35236">β</st><st
    c="35237">AT</st> <st c="35239">x</st><st c="35241">AT</st> <st c="35243">+</st>
    <st c="35245">β</st><st c="35246">V</st> <st c="35247">x</st><st c="35248">V</st><st
    c="35249">。我们通过以下代码进行拟合：</st>
- en: '[PRE4]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <st c="35632">This gives the following parameter estimates for our</st> <st
    c="35686">linear model:</st>
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35632">这给出了我们线性模型的以下参数估计：</st> <st c="35686">线性模型：</st>
- en: '| <st c="35699">OLS</st> <st c="35704">Regression Results</st> |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| <st c="35699">OLS</st> <st c="35704">回归结果</st> |'
- en: '|  | <st c="35722">coef</st> | <st c="35727">std err</st> | <st c="35735">T</st>
    | <st c="35737">P>&#124;t&#124;</st> | <st c="35742">[</st><st c="35744">0.025</st>
    | <st c="35749">0.975]</st> |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  | <st c="35722">系数</st> | <st c="35727">标准误差</st> | <st c="35735">T</st>
    | <st c="35737">P>&#124;t&#124;</st> | <st c="35742">[</st><st c="35744">0.025</st>
    | <st c="35749">0.975]</st> |'
- en: '| <st c="35756">Intercept</st> | <st c="35766">505.4774</st> | <st c="35775">0.240</st>
    | <st c="35781">2101.855</st> | <st c="35790">0.000</st> | <st c="35796">505.006</st>
    | <st c="35804">505.949</st> |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| <st c="35756">截距</st> | <st c="35766">505.4774</st> | <st c="35775">0.240</st>
    | <st c="35781">2101.855</st> | <st c="35790">0.000</st> | <st c="35796">505.006</st>
    | <st c="35804">505.949</st> |'
- en: '| <st c="35812">AT</st> | <st c="35815">-</st><st c="35817">1.7043</st> | <st
    c="35823">0.013</st> | <st c="35829">-</st><st c="35831">134.429</st> | <st c="35838">0.000</st>
    | <st c="35844">-</st><st c="35846">1.729</st> | <st c="35851">-</st><st c="35853">1.679</st>
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| <st c="35812">AT</st> | <st c="35815">-</st><st c="35817">1.7043</st> | <st
    c="35823">0.013</st> | <st c="35829">-</st><st c="35831">134.429</st> | <st c="35838">0.000</st>
    | <st c="35844">-</st><st c="35846">1.729</st> | <st c="35851">-</st><st c="35853">1.679</st>
    |'
- en: '| <st c="35858">V</st> | <st c="35860">-</st><st c="35861">0.3245</st> | <st
    c="35867">0.007</st> | <st c="35873">-</st><st c="35875">43.644</st> | <st c="35881">0.000</st>
    | <st c="35887">-</st><st c="35889">0.339</st> | <st c="35894">-</st><st c="35896">0.310</st>
    |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| <st c="35858">V</st> | <st c="35860">-</st><st c="35861">0.3245</st> | <st
    c="35867">0.007</st> | <st c="35873">-</st><st c="35875">43.644</st> | <st c="35881">0.000</st>
    | <st c="35887">-</st><st c="35889">0.339</st> | <st c="35894">-</st><st c="35896">0.310</st>
    |'
- en: '<st c="35901">Table 4.2: OLS regression parameter estimates for our power-plant
    linear model</st>'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35901">表 4.2：我们电厂线性模型的OLS回归参数估计</st>
- en: <st c="35980">We can see from</st> *<st c="35997">Table 4.2</st>* <st c="36006">that,
    as</st> <st c="36015">expected, we get negative estimates for the parameters corresponding
    to the</st> `<st c="36092">AT</st>` <st c="36094">and</st> `<st c="36099">V</st>`
    <st c="36100">features.</st> <st c="36111">Now, we’ll repeat the calculation explicitly
    using the formula in</st> *<st c="36177">Eq.</st> <st c="36181">20</st>*<st c="36183">.
    We’ll use the linear algebra functions available to us in</st> `<st c="36243">numpy</st>`<st
    c="36248">. First, we need to extract the data from the</st> `<st c="36294">pandas</st>`
    <st c="36300">DataFrame to appropriate</st> `<st c="36326">numpy</st>` <st c="36331">arrays:</st>
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35980">从</st> *<st c="35997">表 4.2</st>* <st c="36006">可以看出，正如</st> <st
    c="36015">预期的那样，我们得到的与</st> `<st c="36092">AT</st>` <st c="36094">和</st> `<st
    c="36099">V</st>` <st c="36100">特征对应的参数估计为负。</st> <st c="36111">现在，我们将使用</st>
    *<st c="36177">公式</st> <st c="36181">20</st>*<st c="36183">显式地重复计算。我们将使用</st>
    `<st c="36243">numpy</st>`<st c="36248">提供的线性代数函数。</st> <st c="36294">首先，我们需要从</st>
    `<st c="36294">pandas</st>` <st c="36300">DataFrame中提取数据并转换为适当的</st> `<st c="36326">numpy</st>`
    <st c="36331">数组：</st>
- en: '[PRE5]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: <st c="36920">Now, we can calculate the OLS parameter estimates using the</st>
    <st c="36981">formula</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1444.png)<st
    c="36989"><st c="36990">::</st></st>
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="36920">现在，我们可以使用</st> <st c="36981">公式</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1444.png)<st
    c="36989"><st c="36990">::</st></st>
- en: '[PRE6]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: <st c="37312">We can compare the OLS parameter</st> <st c="37346">estimates
    obtained from</st> `<st c="37370">statsmodels</st>` <st c="37381">with those obtained
    from the</st> <st c="37411">explicit calculation:</st>
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37312">我们可以比较通过</st> <st c="37346">`statsmodels`获得的OLS参数</st> <st c="37381">估计值和通过</st>
    <st c="37411">显式计算得到的估计值：</st>
- en: '[PRE7]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '|  | <st c="37649">statsmodels</st> | <st c="37661">explicit_ols</st> |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  | <st c="37649">statsmodels</st> | <st c="37661">explicit_ols</st> |'
- en: '| --- | --- | --- |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| <st c="37674">Intercept</st> | <st c="37684">505.477434</st> | <st c="37695">505.477434</st>
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| <st c="37674">截距</st> | <st c="37684">505.477434</st> | <st c="37695">505.477434</st>
    |'
- en: '| <st c="37706">AT</st> | <st c="37709">-</st><st c="37711">1.704266</st> |
    <st c="37719">-</st><st c="37721">1.704266</st> |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| <st c="37706">AT</st> | <st c="37709">-</st><st c="37711">1.704266</st> |
    <st c="37719">-</st><st c="37721">1.704266</st> |'
- en: '| <st c="37729">V</st> | <st c="37731">-</st><st c="37732">0.324487</st> |
    <st c="37740">-</st><st c="37742">0.324487</st> |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| <st c="37729">V</st> | <st c="37731">-</st><st c="37732">0.324487</st> |
    <st c="37740">-</st><st c="37742">0.324487</st> |'
- en: '<st c="37750">Table 4.3: A comparison of the parameter estimates from the statsmodels
    packages and explicit calculation using the OLS formula</st>'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37750">表4.3：从statsmodels包和显式计算使用OLS公式的参数估计的比较</st>
- en: <st c="37878">The parameter estimates from the two different OLS regression
    codes are identical to more than 6</st> <st c="37976">decimal places.</st>
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37878">来自两种不同OLS回归代码的参数估计至少相同到小数点后6位。</st>
- en: <st c="37991">This walkthrough of a real example highlights the power of the
    closed-form OLS regression formula in</st> *<st c="38093">Eq.</st> <st c="38097">20</st>*<st
    c="38099">. This closed-form arises from the linear (in</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1392.png)<st
    c="38145"><st c="38146">) nature of the optimality criterion in</st> *<st c="38186">Eq.</st>
    <st c="38190">18</st>*<st c="38192">, which itself arises from the quadratic nature
    of the risk function in</st> *<st c="38264">Eq.</st> <st c="38268">17</st>*<st
    c="38270">, which ultimately is a consequence of the quadratic form of the squared-loss
    function in</st> *<st c="38360">Eq.</st> <st c="38364">8</st>*<st c="38365">.</st></st>
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37991">这个真实示例的演示突显了在</st> *<st c="38093">Eq.</st> <st c="38097">20</st>*<st
    c="38099">中，封闭式OLS回归公式的力量。这个封闭式公式源自（在</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1392.png)<st
    c="38145"><st c="38146">优化标准的线性特性源自</st> *<st c="38186">Eq.</st> <st c="38190">18</st>*<st
    c="38192">，这本身源自于</st> *<st c="38264">Eq.</st> <st c="38268">17</st>*<st c="38270">中风险函数的二次特性，最终是由</st>
    *<st c="38360">Eq.</st> <st c="38364">8</st>*<st c="38365">的平方损失函数的二次形式所导致的。</st></st>
- en: <st c="38366">But what if we don’t want to use</st> <st c="38399">a linear model
    or a squared-loss function?</st> <st c="38443">Firstly, we can’t use OLS regression!</st>
    <st c="38481">Secondly, a different choice of loss function, such as the absolute
    loss or the pseudo-Huber robust loss function in</st> *<st c="38598">Eq.</st>
    <st c="38602">12</st>*<st c="38604">, will not lead to a closed-form solution
    for</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1460.png)
    <st c="38650"><st c="38654">if we minimize the empirical risk in</st> *<st c="38691">Eq.</st>
    <st c="38695">3</st>*<st c="38696">. So, how do we minimize the empirical risk
    to obtain optimal model parameter estimates in these situations?</st> <st c="38805">We’ll
    learn how to address this question in the next section, but for now, let’s review
    what we have learned in</st> <st c="38917">this section.</st></st>
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38366">但如果我们不想使用</st> <st c="38399">线性模型或平方损失函数呢？</st> <st c="38443">首先，我们不能使用OLS回归！</st>
    <st c="38481">其次，选择不同的损失函数，如绝对损失或伪Huber鲁棒损失函数在</st> *<st c="38598">Eq.</st> <st
    c="38602">12</st>*<st c="38604">中，不会导致</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1460.png)
    <st c="38650"><st c="38654">的闭合形式解。</st> *<st c="38691">Eq.</st> <st c="38695">3</st>*<st
    c="38696">中，我们如何最小化经验风险以获得这些情况下的最佳模型参数估计？</st> <st c="38805">我们将在下一节中学习如何解决这个问题，但现在让我们回顾一下我们在</st>
    <st c="38917">本节中学到的内容。</st></st>
- en: <st c="38930">What we learned</st>
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="38930">我们学到了什么</st>
- en: <st c="38946">In this section, we have learned</st> <st c="38980">the following:</st>
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38946">在本节中，我们学到了</st> <st c="38980">以下内容:</st>
- en: <st c="38994">How to write the empirical risk for OLS regression in</st> <st
    c="39049">matrix notation</st>
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="38994">如何在OLS回归中以</st> <st c="39049">矩阵符号</st>
- en: <st c="39064">How to derive a closed-form expression for OLS model</st> <st
    c="39118">parameter estimates</st>
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="39064">如何推导 OLS 模型的封闭形式表达式</st> <st c="39118">参数估计</st>
- en: <st c="39137">Some of the properties and practical limitations of</st> <st c="39190">OLS
    regression</st>
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="39137">一些 OLS 回归的属性和实际限制</st> <st c="39190">OLS 回归</st>
- en: <st c="39204">How to perform OLS regression using available Python packages
    such</st> <st c="39272">as</st> `<st c="39275">statsmodels</st>`
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="39204">如何使用现有的 Python 包来执行 OLS 回归，如</st> <st c="39272">例如</st> `<st c="39275">statsmodels</st>`
- en: <st c="39286">How to perform OLS regression by explicitly calculating the closed-form
    formula for OLS model</st> <st c="39381">parameter estimates</st>
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="39286">如何通过显式计算 OLS 模型的封闭形式公式来执行 OLS 回归</st> <st c="39381">参数估计</st>
- en: <st c="39400">Having learned how to perform OLS regression, we’ll now learn
    how to perform least squares regression in more general settings by using gradient
    descent techniques to minimize the</st> <st c="39581">empirical risk.</st>
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="39400">在学会如何执行 OLS 回归之后，我们将学习如何在更一般的设置下通过使用梯度下降技术来最小化</st> <st c="39581">经验风险。</st>
- en: <st c="39596">Gradient descent</st>
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="39596">梯度下降法</st>
- en: <st c="39613">As we just hinted at the end of the last section, we aren’t always
    in a position where we can use the closed-form OLS solution of</st> *<st c="39744">Eq.</st>
    <st c="39748">20</st>*<st c="39750">. What are</st> <st c="39761">our options?</st>
    <st c="39774">To construct a more general approach to empirical risk minimization,
    we’ll have to revisit the shape of the empirical risk function so that we can
    understand how to locate</st> <st c="39946">its minima.</st>
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="39613">正如我们在上一节的结尾所暗示的那样，我们并不总是在可以使用封闭形式 OLS 解的情况下，</st> *<st c="39744">公式</st>
    <st c="39748">20</st>*<st c="39750">。我们有哪些选择呢？</st> <st c="39761">我们的选择是什么？</st>
    <st c="39774">为了构建一个更通用的经验风险最小化方法，我们必须重新审视经验风险函数的形状，以便理解如何找到</st> <st c="39946">其最小值。</st>
- en: <st c="39957">Locating the minimum of a simple risk function</st>
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="39957">定位简单风险函数的最小值</st>
- en: <st c="40004">To understand the shape of the empirical risk function, let’s
    take a simple example with a model that has a single parameter.</st> <st c="40131">We’ll
    use the risk</st> <st c="40149">function for a linear model and a squared-loss
    function.</st> <st c="40207">We’ll use a linear model with a single feature, and
    so it is of the</st> <st c="40275">following form:</st>
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40004">为了理解经验风险函数的形状，我们以一个具有单个参数的模型为例。</st> <st c="40131">我们将使用线性模型的风险</st>
    <st c="40149">函数和平方损失函数。</st> <st c="40207">我们将使用一个具有单个特征的线性模型，因此它的形式为：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><mi>β</mi><mi>x</mi></mrow></mrow></math>](img/1461.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mo>=</mo><mspace width="0.25em" /><mi>β</mi><mi>x</mi></mrow></mrow></math>](img/1461.png)'
- en: <st c="40292">Eq.</st> <st c="40296">23</st>
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40292">公式</st> <st c="40296">23</st>
- en: <st c="40298">The model has a single parameter,</st> <st c="40333">β</st><st
    c="40334">, which multiplies the single feature</st> <st c="40372">x</st><st c="40373">.
    In</st> *<st c="40378">Figure 4</st>**<st c="40386">.7</st>* <st c="40388">we
    have plotted the shape of the empirical risk function against the value of</st>
    <st c="40467">β</st><st c="40468">, and where we have calculated the empirical
    risk on a dataset of 100 datapoints.</st> <st c="40550">The dataset has been generated
    via simulation and using a model of the mathematical form in</st> *<st c="40642">Eq.</st>
    <st c="40646">23</st>*<st c="40648">. The model we are going to fit to this data
    by minimizing the empirical risk is of the correct mathematical form (by construction);
    it is just that we don’t know the true value of</st> <st c="40829">β</st> <st
    c="40830">– well, I do, but I’m not going to tell you just yet.</st> <st c="40885">To
    estimate the true value of</st> <st c="40915">β</st> <st c="40916">that underlies
    the data, we’ll have to use the model form in</st> *<st c="40978">Eq.</st> <st
    c="40982">23</st>* <st c="40984">and minimize the</st> <st c="41002">empirical
    risk:</st>
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40298">该模型有一个单一的参数</st> <st c="40333">β</st><st c="40334">，它与单一特征</st>
    <st c="40372">x</st><st c="40373">相乘。在</st> *<st c="40378">图 4</st>**<st c="40386">.7</st>*
    <st c="40388">中，我们已经绘制了经验风险函数随</st> <st c="40467">β</st><st c="40468">值变化的形状，并且我们在100个数据点的
    dataset 上计算了经验风险。</st> <st c="40550">该数据集是通过模拟生成的，并且使用了</st> *<st c="40642">公式</st>
    <st c="40646">23</st>*<st c="40648">中的数学模型。我们将通过最小化经验风险来拟合此数据的模型符合正确的数学形式（通过构造）；只是我们不知道</st>
    <st c="40829">β</st> <st c="40830">的真实值——好吧，我知道，但我现在还不打算告诉你。</st> <st c="40885">为了估计潜在数据背后的真实</st>
    <st c="40915">β</st> <st c="40916">值，我们将不得不使用</st> *<st c="40978">公式</st> <st
    c="40982">23</st>* <st c="40984">中的模型形式，并最小化</st> <st c="41002">经验风险：</st>
- en: '![Figure 4.7: Empirical risk function and starting parameter estimate for our
    simulated dataset](img/B19496_04_07.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7：我们模拟数据集的经验风险函数和初始参数估计](img/B19496_04_07.jpg)'
- en: '<st c="41081">Figure 4.7: Empirical risk function and starting parameter estimate
    for our simulated dataset</st>'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41081">图 4.7：我们模拟数据集的经验风险函数和初始参数估计</st>
- en: <st c="41174">From the shape of the risk function in</st> *<st c="41214">Figure
    4</st>**<st c="41222">.7</st>*<st c="41224">, you can see that there is a single
    minimum close to</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:math>](img/1462.png)<st
    c="41278"><st c="41279">. As you may have guessed,</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:math>](img/1463.png)
    <st c="41306"><st c="41307">is the value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1356.png)
    <st c="41324"><st c="41325">that I used to generate the simulated data.</st> <st
    c="41370">Let’s</st> <st c="41375">say we start with a guess for the true value
    of</st> <st c="41424">β</st> <st c="41425">that is 1\.</st> <st c="41437">That
    is, we’re going to initially set our estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:math>](img/1465.png)<st
    c="41488"><st c="41490">. How good is that initial estimate?</st> <st c="41527">We
    have also plotted the position of this estimate as a red dot in</st> *<st c="41594">Figure
    4</st>**<st c="41602">.7</st>* <st c="41604">so that you can see how good an estimate
    it is by seeing how close it is to the minimum.</st> <st c="41694">If it were
    the optimal (best) estimate, we would be at the minimum of the empirical risk;
    that is, we would have</st> <st c="41807">the following:</st></st></st></st></st>
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41174">从</st> *<st c="41214">图 4</st>**<st c="41222">.7</st>*<st c="41224">中的风险函数形状可以看出，接近</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:math>](img/1462.png)<st
    c="41278"><st c="41279">处有一个单一的最小值。</st> 正如你可能已经猜到的，</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:math>](img/1463.png)
    <st c="41306"><st c="41307">是我用来生成模拟数据的</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1356.png)
    <st c="41324"><st c="41325">值。</st> <st c="41370">假设</st> <st c="41375">我们从对真实值</st>
    <st c="41424">β</st> <st c="41425">的猜测开始，它为 1\。</st> <st c="41437">也就是说，我们将最初设定我们的估计值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:math>](img/1465.png)<st
    c="41488"><st c="41490">。这个初始估计值有多准确呢？</st> <st c="41527">我们还在</st> *<st c="41594">图
    4</st>**<st c="41602">.7</st>* <st c="41604">中用红点标出了这个估计值的位置，您可以通过查看它与最小值的接近程度来判断这个估计值的准确性。</st>
    <st c="41694">如果它是最优（最佳）估计，我们将位于经验风险的最小值处；也就是说，我们将拥有</st> <st c="41807">如下：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mfenced
    open="" close="|"><mrow><mspace width="0.25em" /><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac></mrow></mfenced><mrow><mi>β</mi><mo>=</mo><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover></mrow></msub><mo>=</mo><mn>0</mn></mrow></mrow></math>](img/1466.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mfenced
    open="" close="|"><mrow><mspace width="0.25em" /><mfrac><mrow><mo>∂</mo><mtext>风险</mtext></mrow><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac></mrow></mfenced><mrow><mi>β</mi><mo>=</mo><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover></mrow></msub><mo>=</mo><mn>0</mn></mrow></mrow></math>](img/1466.png)'
- en: <st c="41828">Eq.</st> <st c="41832">24</st>
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41828">公式</st> <st c="41832">24</st>
- en: <st c="41834">We can easily derive a formula for the derivative on the left-hand
    side of</st> *<st c="41910">Eq.</st> <st c="41914">24</st>*<st c="41916">. It
    is</st> <st c="41924">the following:</st>
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41834">我们可以轻松推导出左侧导数的公式</st> *<st c="41910">公式</st> <st c="41914">24</st>*<st
    c="41916">。它是</st> <st c="41924">如下：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac><mo>=</mo><mspace
    width="0.25em" /><mfrac><mn>1</mn><mn>100</mn></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>100</mn></munderover><mrow><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac><mspace
    width="0.25em" /><msup><mfenced open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace
    width="0.25em" /><mi>β</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfenced><mn>2</mn></msup><mo>=</mo><mo>−</mo><mfrac><mn>2</mn><mn>100</mn></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>100</mn></munderover><mrow><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><mi>β</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfenced><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow></mrow></mrow></mrow></mrow></math>](img/1467.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mrow><mo>∂</mo><mtext>风险</mtext></mrow><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac><mo>=</mo><mspace
    width="0.25em" /><mfrac><mn>1</mn><mn>100</mn></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>100</mn></munderover><mrow><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac><mspace
    width="0.25em" /><msup><mfenced open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace
    width="0.25em" /><mi>β</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfenced><mn>2</mn></msup><mo>=</mo><mo>−</mo><mfrac><mn>2</mn><mn>100</mn></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>100</mn></munderover><mrow><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mspace width="0.25em"
    /><mi>β</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfenced><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow></mrow></mrow></mrow></mrow></math>](img/1467.png)'
- en: <st c="41984">Eq.</st> <st c="41988">25</st>
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41984">方程</st> <st c="41988">25</st>
- en: <st c="41990">So, we can just plug our current estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/1468.png)
    <st c="42033"><st c="42034">into</st> *<st c="42040">Eq.</st> <st c="42044">25</st>*
    <st c="42046">to see how close we are to the optimality criterion in</st> *<st
    c="42102">Eq.</st> <st c="42106">24</st>*<st c="42108">. If we are within a specified
    tolerance of the criterion in</st> *<st c="42169">Eq.</st> <st c="42173">24</st>*<st
    c="42175">, our estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)
    <st c="42190"><st c="42194">is good.</st></st></st>
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41990">因此，我们可以将当前的估计值代入</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/1468.png)
    <st c="42033"><st c="42034">代入</st> *<st c="42040">方程</st> <st c="42044">25</st>*
    <st c="42046">中，看看我们与</st> *<st c="42102">方程</st> <st c="42106">24</st>*<st c="42108">中的最优标准有多接近。如果我们在</st>
    *<st c="42169">方程</st> <st c="42173">24</st>*<st c="42175">中设定的容差范围内，估计值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)
    <st c="42190"><st c="42194">就是好的。</st></st></st>
- en: <st c="42202">What happens if we are not within the specified tolerance?</st>
    <st c="42262">How should we adjust our estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)<st
    c="42296"><st c="42299">? Clearly, we want to adjust our estimate</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)
    <st c="42341"><st c="42344">by moving it downhill toward the minimum.</st> <st
    c="42386">How do we work out which direction is downward – that is, which direction
    reduces the empirical risk?</st> <st c="42488">Well, this is what the derivative
    in</st> *<st c="42525">Eq.</st> <st c="42529">25</st>* <st c="42531">tells us.</st>
    <st c="42542">Recall from</st> [*<st c="42554">Chapter 1</st>*](B19496_01.xhtml#_idTextAnchor014)
    <st c="42563">that the derivative of a function tells us the gradient or slope
    of a function.</st> <st c="42644">So, the numerical</st> <st c="42661">value of
    the calculation in</st> *<st c="42690">Eq.</st> <st c="42694">25</st>* <st c="42696">evaluated
    at</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)
    <st c="42710"><st c="42714">tells us in which direction we should adjust</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1473.png)<st
    c="42759"><st c="42763">. If the derivative is positive then increasing</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1473.png)
    <st c="42811"><st c="42815">will increase the empirical risk, so we want to decrease</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)<st
    c="42872"><st c="42875">. Conversely, if the derivative is negative then increasing</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="42935"><st c="42939">will decrease the empirical risk</st> <st c="42972">as
    desired.</st></st></st></st></st></st></st></st>
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42202">如果我们不在指定的容差范围内会发生什么？</st> <st c="42262">我们应该如何调整我们的估计值？</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)<st
    c="42296"><st c="42299">？显然，我们希望通过将其向下移动到最小值来调整我们的估计值。</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)
    <st c="42341"><st c="42344">我们如何计算出哪个方向是向下的——也就是说，哪个方向可以减少经验风险？</st> <st c="42386">嗯，这正是</st>
    *<st c="42525">公式</st>* <st c="42529">25</st>* <st c="42531">所告诉我们的。</st> <st
    c="42542">回想一下，来自</st> [*<st c="42554">第一章</st>*](B19496_01.xhtml#_idTextAnchor014)
    <st c="42563">的内容，函数的导数告诉我们函数的梯度或斜率。</st> <st c="42644">因此，</st> <st c="42661">在</st>
    *<st c="42690">公式</st>* <st c="42694">25</st>* <st c="42696">中计算出的数值，在</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)
    <st c="42710"><st c="42714">会告诉我们应该调整的方向</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1473.png)<st
    c="42759"><st c="42763">。如果导数为正，则增加</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1473.png)
    <st c="42811"><st c="42815">将增加经验风险，因此我们希望减少</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)<st
    c="42872"><st c="42875">。相反，如果导数为负，则增加</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="42935"><st c="42939">将减少经验风险</st> <st c="42972">，如我们所愿。</st></st></st></st></st></st></st></st>
- en: <st c="42983">The size of the derivative also gives us a guide by how much we
    should adjust</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43062"><st c="43066">. If the absolute value of the derivative is large, it
    tells us we are high on the steep slopes of the risk function, as depicted by
    the red dot starting point in</st> *<st c="43229">Figure 4</st>**<st c="43237">.7</st>*<st
    c="43239">, and so we are a long way from the minimum.</st> <st c="43284">Overall,
    the bigger the absolute value of the derivative, the more we should</st> <st c="43361">adjust</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43368"><st c="43372">.</st></st></st>
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42983">导数的大小还为我们提供了一个指导，告诉我们应该调整多少</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43062"><st c="43066">。如果导数的绝对值很大，这意味着我们处于风险函数的陡坡上，正如在</st> *<st c="43229">图
    4</st>**<st c="43237">.7</st>*<st c="43239">中所示的红点起始位置所示，说明我们离最小值还很远。</st> <st
    c="43284">总体来说，导数的绝对值越大，我们应该</st> <st c="43361">调整</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43368"><st c="43372">。</st></st></st>
- en: <st c="43373">Putting together the arguments from the previous two paragraphs,
    we should adjust our estimate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)
    <st c="43472"><st c="43476">by descending according to the direction and size
    of the gradient of our objective function.</st> <st c="43569">This approach is</st>
    <st c="43585">called</st> **<st c="43593">gradient descent</st>** <st c="43609">and
    tells us we should adjust our estimate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="43656"><st c="43660">according to an</st> <st c="43676">update rule:</st></st></st>
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43373">结合前两段的论述，我们应该根据目标函数的梯度方向和大小来调整对</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)
    <st c="43472"><st c="43476">的估计。</st> <st c="43569">这种方法被称为</st> <st c="43585">**梯度下降法**</st>
    <st c="43609">，它告诉我们应该根据以下更新规则来调整对</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="43656"><st c="43660">的估计：</st></st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mfenced
    open="" close=""><mrow><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mspace
    width="0.25em" /><mo>←</mo><mspace width="0.25em" /><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo>−</mo><mspace
    width="0.25em" /><mi>η</mi><msub><mfenced open="" close="|"><mrow><mspace width="0.25em"
    /><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac></mrow></mfenced><mrow><mi>β</mi><mo>=</mo><mspace
    width="0.25em" /><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover></mrow></msub><mspace
    width="0.25em" /></mrow></mfenced></mrow></math>](img/1481.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mfenced
    open="" close=""><mrow><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mspace
    width="0.25em" /><mo>←</mo><mspace width="0.25em" /><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo>−</mo><mspace
    width="0.25em" /><mi>η</mi><msub><mfenced open="" close="|"><mrow><mspace width="0.25em"
    /><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><mi>β</mi></mrow></mfrac></mrow></mfenced><mrow><mi>β</mi><mo>=</mo><mspace
    width="0.25em" /><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover></mrow></msub><mspace
    width="0.25em" /></mrow></mfenced></mrow></math>](img/1481.png)'
- en: <st c="43690">Eq.</st> <st c="43694">26</st>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43690">公式</st> <st c="43694">26</st>
- en: <st c="43696">The quantity</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi></mml:math>](img/1482.png)
    <st c="43710"><st c="43711">controls how quickly we adjust</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43743"><st c="43747">, and so is called the learning rate, since it controls
    how quickly we move toward or learn the true optimal value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43865"><st c="43869">. A very small value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi></mml:math>](img/1482.png)
    <st c="43893"><st c="43894">will mean we make relatively small adjustments to</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1486.png)
    <st c="43945"><st c="43949">even when the derivative</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mtext>Risk</mml:mtext></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:math>](img/1487.png)
    <st c="43974"><st c="43980">is relatively large.</st> <st c="44001">Conversely,
    a larger value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi></mml:math>](img/1482.png)
    <st c="44031"><st c="44032">will mean we take larger steps toward the minimum
    of the</st> <st c="44090">empirical risk.</st></st></st></st></st></st></st></st>
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43696">量</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi></mml:math>](img/1482.png)
    <st c="43710"><st c="43711">控制我们调整</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43743"><st c="43747">的速度，因此被称为学习率，因为它控制我们向最优值的移动速度，或者说学习真实的最优值</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="43865"><st c="43869">。一个非常小的</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi></mml:math>](img/1482.png)
    <st c="43893"><st c="43894">值意味着我们对</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1486.png)
    <st c="43945"><st c="43949">的调整相对较小，即使在导数</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mtext>风险</mml:mtext></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:math>](img/1487.png)
    <st c="43974"><st c="43980">相对较大时。</st> <st c="44001">反之，较大的</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi></mml:math>](img/1482.png)
    <st c="44031"><st c="44032">值意味着我们朝着最小的</st> <st c="44090">经验风险</st>迈出更大的步伐。</st>
- en: <st c="44105">Let’s see what happens when we use the update rule in</st> *<st
    c="44160">Eq.</st> <st c="44164">26</st>* <st c="44166">for a few iterations.</st>
    <st c="44189">The results are shown in</st> *<st c="44214">Figure 4</st>**<st
    c="44222">.</st><st c="44223">8</st>*<st c="44225">:</st>
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我们在*<st c="44160">方程</st> <st c="44164">26</st>* <st c="44166">中使用更新规则进行几次迭代时会发生什么。</st>
    <st c="44189">结果如</st> *<st c="44214">图 4</st>**<st c="44222">.</st><st c="44223">8</st>*<st
    c="44225">所示：</st>
- en: '![Figure 4.8: Evolution of the model parameter estimate as we iterate the gradient
    descent update rule](img/B19496_04_08.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8：当我们迭代梯度下降更新规则时，模型参数估计的演化](img/B19496_04_08.jpg)'
- en: '<st c="44411">Figure 4.8: Evolution of the model parameter estimate as we iterate
    the gradient descent update rule</st>'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44411">图 4.8：当我们迭代梯度下降更新规则时，模型参数估计的演化</st>
- en: <st c="44511">In the left-hand panel of</st> *<st c="44538">Figure 4</st>**<st
    c="44546">.8</st>*<st c="44548">, we see our starting estimate of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="44582"><st c="44586">=1, shown by the position of the red dot.</st> <st c="44628">After
    one iteration, we have updated our estimate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)
    <st c="44681"><st c="44684">according to the update rule in</st> *<st c="44716">Eq.</st>
    <st c="44720">26</st>* <st c="44722">(and using a learning rate of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/1491.png)<st
    c="44753"><st c="44763">).</st> <st c="44766">This gives us a new value of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>2.062</mml:mn></mml:math>](img/1492.png)
    <st c="44795"><st c="44805">for</st> <st c="44808">our estimate</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)<st
    c="44822"><st c="44826">. This is shown in the middle panel of</st> *<st c="44865">Figure
    4</st>**<st c="44873">.8</st>*<st c="44875">, with again the red dot showing the
    position of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1486.png)
    <st c="44924"><st c="44928">and its corresponding empirical risk value.</st> <st
    c="44972">In the right-hand panel, the red dot shows the updated value of</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="45036"><st c="45040">at</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>2.664</mml:mn></mml:math>](img/1496.png)
    <st c="45043"><st c="45053">(and corresponding empirical risk) after iteration
    2\.</st> <st c="45107">For each of the iterations in</st> *<st c="45137">Figure
    4</st>**<st c="45145">.8</st>*<st c="45147">, the direction and size of the update
    to the current estimate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="45213"><st c="45217">is shown schematically by the arrow.</st> <st c="45254">We
    can see that the updates all move the estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1498.png)
    <st c="45304"><st c="45308">closer to the minimum, but the magnitude of the updates
    decrease as we get closer to the minimum.</st> <st c="45406">What happens if we
    carry on iterating?</st> <st c="45445">Let’s look at how we would do that in a</st>
    <st c="45485">code example.</st></st></st></st></st></st></st></st></st></st></st>
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在*<st c="44538">图 4</st>**<st c="44546">.8</st>*<st c="44548">的左侧面板中，我们看到我们初始的估计值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)<st
    c="44582"><st c="44586">=1，由红点的位置表示。</st> <st c="44628">经过一次迭代后，我们更新了</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1357.png)
    <st c="44681"><st c="44684">的估计值，依据的是</st> *<st c="44716">公式</st> <st c="44720">26</st>*
    <st c="44722">（并且使用了学习率</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/1491.png)<st
    c="44753"><st c="44763">）。</st> <st c="44766">这给出了新的估计值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>2.062</mml:mn></mml:math>](img/1492.png)
    <st c="44795"><st c="44805">，这是我们估计值</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1469.png)<st
    c="44822"><st c="44826">所对应的。</st> 这在*<st c="44865">图 4</st>**<st c="44873">.8</st>*<st
    c="44875">的中间面板中显示，红点表示</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1486.png)
    <st c="44924"><st c="44928">及其对应的经验风险值。</st> <st c="44972">在右侧面板中，红点显示了迭代 1 后更新的</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="45036"><st c="45040">的值为</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>2.664</mml:mn></mml:math>](img/1496.png)
    <st c="45043"><st c="45053">(以及对应的经验风险)，这是在迭代 2 后得到的。</st> <st c="45107">对于</st>
    *<st c="45137">图 4</st>**<st c="45145">.8</st>*<st c="45147">中的每次迭代，更新当前估计值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="45213"><st c="45217">的方向和大小由箭头示意表示。</st> <st c="45254">我们可以看到，这些更新都使得估计值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1498.png)
    <st c="45304"><st c="45308">逐步接近最小值，但随着接近最小值，更新的幅度减小。</st> <st c="45406">如果我们继续迭代，会发生什么呢？</st>
    <st c="45445">让我们看看如何在</st> <st c="45485">代码示例中实现这一点。</st>
- en: <st c="45498">Gradient descent code example</st>
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="45498">梯度下降代码示例</st>
- en: <st c="45528">The simulated data is in the</st> `<st c="45558">Data/gradient_descent_example.csv</st>`
    <st c="45591">file in the GitHub repository.</st> <st c="45623">You’ll also find
    the following code example (and more) in the</st> `<st c="45685">Code_Examples_Chap4.ipynb</st>`
    <st c="45710">Jupyter</st> <st c="45718">notebook in</st> <st c="45731">the repository.</st>
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="45528">模拟数据位于</st> `<st c="45558">Data/gradient_descent_example.csv</st>`
    <st c="45591">文件中，该文件在 GitHub 仓库内。</st> <st c="45623">你还可以在</st> `<st c="45685">Code_Examples_Chap4.ipynb</st>`
    <st c="45710">Jupyter</st> <st c="45718">笔记本中找到以下代码示例（以及更多）</st> <st c="45731">，该笔记本也在仓库中。</st>
- en: <st c="45746">To begin, we’ll read in</st> <st c="45771">the data:</st>
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="45746">首先，我们将读取</st> <st c="45771">数据：</st>
- en: '[PRE8]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: <st c="46016">Then, we’ll define some functions to</st> <st c="46054">calculate
    the empirical risk and</st> <st c="46087">its derivative:</st>
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="46016">然后，我们将定义一些函数来</st> <st c="46054">计算经验风险并</st> <st c="46087">计算其导数：</st>
- en: '[PRE9]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: <st c="46967">Now, we’ll perform 20 iterations</st> <st c="47000">of the gradient
    descent</st> <st c="47025">update rule:</st>
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="46967">接下来，我们将执行 20 次迭代</st> <st c="47000">的梯度下降</st> <st c="47025">更新规则：</st>
- en: '[PRE10]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: <st c="47594">Finally, we can plot the trajectory of the</st> <st c="47638">parameter
    estimates:</st>
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="47594">最后，我们可以绘制</st> <st c="47638">参数估计的轨迹：</st>
- en: '[PRE11]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Figure 4.9: Plot of gradient descent trajectory of the model parameter estimate](img/B19496_04_09.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9：模型参数估计的梯度下降轨迹图](img/B19496_04_09.jpg)'
- en: '<st c="48018">Figure 4.9: Plot of gradient descent trajectory of the model
    parameter estimate</st>'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48018">图 4.9：模型参数估计的梯度下降轨迹图</st>
- en: <st c="48097">We can see from</st> *<st c="48114">Figure 4</st>**<st c="48122">.9</st>*
    <st c="48124">that as we perform more gradient descent iterations, the parameter
    estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="48201"><st c="48205">appears to converge to a value close to 3.5\.</st>
    <st c="48250">What is the value that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="48273"><st c="48277">converges to?</st> <st c="48291">If you run the</st>
    <st c="48305">code in the notebook, you’ll find that</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1501.png)
    <st c="48345"><st c="48349">converges to 3.453\.</st> <st c="48369">This is not
    the true value of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:math>](img/1502.png)
    <st c="48399"><st c="48400">that was used to generate the data.</st> <st c="48437">Why
    is this so?</st> <st c="48453">What has happened?</st> <st c="48472">The answer
    is that the empirical risk is a function of the dataset, and the data contains
    a random component.</st> <st c="48582">Because of this, the value of</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1503.png)
    <st c="48612"><st c="48613">that minimizes the empirical risk will be close to
    but not precisely the same as the true value that was used to generate</st> <st
    c="48736">the data.</st></st></st></st></st></st>
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 从*<st c="48114">图4</st>**<st c="48122">.9</st>* <st c="48124">我们可以看到，当我们执行更多的梯度下降迭代时，参数估计值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="48201"><st c="48205">似乎趋向于接近3.5的值。</st> <st c="48250">那么，</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1476.png)
    <st c="48273"><st c="48277">最终收敛的值是多少呢？</st> <st c="48291">如果你运行笔记本中的</st> <st
    c="48305">代码，你会发现</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/1501.png)
    <st c="48345"><st c="48349">最终收敛值是3.453。</st> <st c="48369">这并不是用来生成数据的真实值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:math>](img/1502.png)
    <st c="48399"><st c="48400">，该值用于生成数据。</st> <st c="48437">为什么会这样呢？</st> <st c="48453">发生了什么呢？</st>
    <st c="48472">答案是，经验风险是数据集的一个函数，而数据中包含了随机成分。</st> <st c="48582">正因为如此，</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>β</mml:mi></mml:math>](img/1503.png)
    <st c="48612"><st c="48613">能够最小化经验风险的值将接近但不完全相同于用来生成数据的真实值。</st> <st c="48736">数据。</st></st></st></st></st></st>
- en: <st c="48745">Gradient descent is a general technique</st>
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="48745">梯度下降是一种通用技术</st>
- en: <st c="48785">The example we just walked</st> <st c="48812">through, including
    the code, is very simplistic.</st> <st c="48862">What it does highlight, though,
    is how general the update rule in</st> *<st c="48928">Eq.</st> <st c="48932">26</st>*
    <st c="48934">is.</st> <st c="48939">We can extend the update rule to when we
    have multiple model parameters, which we’ll denote by the vector</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1504.png)<st
    c="49045"><st c="49046">. The new update rule is</st> <st c="49071">the following:</st></st>
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48785">我们刚刚讲解的例子，包括代码，非常简单。</st> <st c="48812">然而，它确实突出了</st> *<st c="48928">公式</st>
    <st c="48932">26</st>* <st c="48934">中更新规则的通用性。</st> <st c="48939">我们可以将更新规则扩展到有多个模型参数的情况，我们用向量</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1504.png)<st
    c="49045"><st c="49046">表示。</st> <st c="49071">新的更新规则如下：</st></st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mfenced
    open="" close=""><mrow><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></munder><mo>←</mo><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>−</mo><mspace
    width="0.25em" /><mi>η</mi><mspace width="0.25em" /><msub><mfenced open="" close="|"><mrow><mspace
    width="0.25em" /><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mrow></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></msub></mrow></mfenced></mrow></math>](img/1505.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mfenced
    open="" close=""><mrow><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></munder><mo>←</mo><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo>−</mo><mspace
    width="0.25em" /><mi>η</mi><mspace width="0.25em" /><msub><mfenced open="" close="|"><mrow><mspace
    width="0.25em" /><mfrac><mrow><mo>∂</mo><mtext>风险</mtext></mrow><mrow><mo>∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mrow></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><mspace width="0.25em" /><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></mml:munder></mrow></msub></mrow></mfenced></mrow></math>](img/1505.png)'
- en: <st c="49087">Eq.</st> <st c="49091">27</st>
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49087">公式</st> <st c="49091">27</st>
- en: <st c="49093">The gradient descent update rule in</st> *<st c="49130">Eq.</st>
    <st c="49134">27</st>* <st c="49136">can be applied to any empirical risk function,
    meaning we have a method of constructing optimal parameter estimates</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)
    <st c="49253"><st c="49254">for any model and any choice of</st> <st c="49287">loss
    function.</st></st>
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49093">梯度下降更新规则在</st> *<st c="49130">公式</st> <st c="49134">27</st>* <st
    c="49136">中可以应用于任何经验风险函数，这意味着我们有了一种构造最佳参数估计的方法</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>_</mml:mo></mml:mrow></mml:munder></mml:math>](img/1445.png)
    <st c="49253"><st c="49254">适用于任何模型和任何损失函数的选择。</st></st>
- en: <st c="49301">To illustrate this, imagine</st> <st c="49330">we wanted to use
    the pseudo-Huber loss function of</st> *<st c="49381">Eq.</st> <st c="49385">12</st>*<st
    c="49387">. Our empirical risk function is given by</st> <st c="49429">the following:</st>
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49301">为了说明这一点，假设</st> <st c="49330">我们想使用</st> *<st c="49381">公式</st>
    <st c="49385">12</st>*<st c="49387">的伪-Huber 损失函数。</st> <st c="49429">我们的经验风险函数为：</st>
- en: <st c="49443">Empirical Risk =</st> <st c="49461">1</st><st c="49462">_</st><st
    c="49463">N</st> <st c="49464">∑</st><st c="49465">i</st><st c="49466">=</st><st
    c="49467">1</st><st c="49468">N</st><st c="49469">[</st><st c="49470">√</st><st
    c="49471">_______________</st><st c="49486">1</st><st c="49488">+</st> <st c="49489">(</st><st
    c="49490">y</st><st c="49491">i</st><st c="49492">−</st> <st c="49493">ˆ</st><st
    c="49494">y</st><st c="49495">i</st><st c="49496">(</st><st c="49497">x</st><st
    c="49498">_</st><st c="49499">i</st><st c="49500">|</st> <st c="49501">β</st><st
    c="49502">_</st><st c="49503">)</st><st c="49504">)</st><st c="49505">2</st> <st
    c="49506">−</st> <st c="49507">1</st><st c="49508">]</st>
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49443">经验风险 =</st> <st c="49461">1</st><st c="49462">_</st><st c="49463">N</st>
    <st c="49464">∑</st><st c="49465">i</st><st c="49466">=</st><st c="49467">1</st><st
    c="49468">N</st><st c="49469">[</st><st c="49470">√</st><st c="49471">_______________</st><st
    c="49486">1</st><st c="49488">+</st> <st c="49489">(</st><st c="49490">y</st><st
    c="49491">i</st><st c="49492">−</st> <st c="49493">ˆ</st><st c="49494">y</st><st
    c="49495">i</st><st c="49496">(</st><st c="49497">x</st><st c="49498">_</st><st
    c="49499">i</st><st c="49500">|</st> <st c="49501">β</st><st c="49502">_</st><st
    c="49503">)</st><st c="49504">)</st><st c="49505">2</st> <st c="49506">−</st>
    <st c="49507">1</st><st c="49508">]</st>
- en: <st c="49509">Eq.</st> <st c="49513">28</st>
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49509">等式</st> <st c="49513">28</st>
- en: <st c="49515">So, we have a gradient descent update rule of the</st> <st c="49566">following
    form:</st>
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49515">因此，我们有一个梯度下降更新规则如下：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo mathvariant="italic">←</mo><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo mathvariant="italic">+</mo><mn
    mathvariant="italic">2</mn><mfrac><mi>η</mi><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfenced
    open="[" close="]"><mrow><mfrac><mfenced open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>|</mo><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced></mrow></mfenced><msqrt><mrow><mn>1</mn><mo>+</mo><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>|</mo><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced></mrow></mfenced><mn>2</mn></msup></mrow></msqrt></mfrac><msub><mfenced
    open="" close="|"><mfrac><mrow><mo mathvariant="italic">∂</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>|</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfenced></mrow><mrow><mo mathvariant="italic">∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></munder></mrow></msub></mrow></mfenced></mrow></mrow></mrow></math>](img/1507.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo mathvariant="italic">←</mo><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder><mo mathvariant="italic">+</mo><mn
    mathvariant="italic">2</mn><mfrac><mi>η</mi><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfenced
    open="[" close="]"><mrow><mfrac><mfenced open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>|</mo><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced></mrow></mfenced><msqrt><mrow><mn>1</mn><mo>+</mo><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>|</mo><munder><mover><mi>β</mi><mo
    stretchy="true">ˆ</mo></mover><mo stretchy="true">_</mo></munder></mrow></mfenced></mrow></mfenced><mn>2</mn></msup></mrow></msqrt></mfrac><msub><mfenced
    open="" close="|"><mfrac><mrow><mo mathvariant="italic">∂</mo><msub><mover><mi>y</mi><mo
    stretchy="true">ˆ</mo></mover><mi>i</mi></msub><mfenced open="(" close=")"><mrow><msub><munder><mi>x</mi><mo
    stretchy="true">_</mo></munder><mi>i</mi></msub><mo>|</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfenced></mrow><mrow><mo mathvariant="italic">∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></munder></mrow></msub></mrow></mfenced></mrow></mrow></mrow></math>](img/1507.png)'
- en: <st c="49607">Eq.</st> <st c="49611">29</st>
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49607">公式</st> <st c="49611">29</st>
- en: <st c="49613">Beyond simple gradient descent</st>
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="49613">超越简单的梯度下降</st>
- en: <st c="49644">Although being an iterative technique rather than a closed-form
    solution, gradient descent is a very general technique.</st> <st c="49765">This
    makes it a very powerful technique.</st> <st c="49806">Consequently, it has been
    widely studied, modified, and adapted in different ways.</st> <st c="49889">One
    of the main drivers of this is the fact that</st> <st c="49938">variants of gradient
    descent are used in the training of</st> **<st c="49995">neural networks</st>**
    <st c="50010">(</st>**<st c="50012">NNs</st>**<st c="50015">), including</st>
    **<st c="50029">deep learning</st>** <st c="50042">(</st>**<st c="50044">DL</st>**<st
    c="50046">) NNs.</st> <st c="50054">We don’t have</st> <st c="50067">space here
    to go into the full mathematical detail of the various adaptations of gradient
    descent.</st> <st c="50167">Instead, we will briefly describe some of the most
    important modifications</st> <st c="50242">and concepts:</st>
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49644">尽管梯度下降是一种迭代技术，而非封闭形式的解法，但它是一种非常通用的技术。</st> <st c="49765">这使得它成为一种非常强大的技术。</st>
    <st c="49806">因此，它被广泛研究、修改并以不同的方式应用。</st> <st c="49889">其中一个主要原因是</st> <st c="49938">梯度下降的变体被用于训练</st>
    **<st c="49995">神经网络</st>** <st c="50010">(</st>**<st c="50012">NNs</st>**<st
    c="50015">)，包括</st> **<st c="50029">深度学习</st>** <st c="50042">(</st>**<st c="50044">DL</st>**<st
    c="50046">) 神经网络。</st> <st c="50054">我们这里没有空间深入探讨梯度下降各种适配方法的数学细节。</st> <st c="50067">相反，我们将简要描述一些最重要的修改</st>
    <st c="50242">和概念：</st>
- en: '**<st c="50255">Local minima</st>**<st c="50268">: The risk function shown
    in</st> *<st c="50298">Figure 4</st>**<st c="50306">.7</st>* <st c="50308">has
    a single minimum.</st> <st c="50331">For real-world datasets, it is typical for</st>
    <st c="50373">a risk function to have multiple minima.</st> <st c="50415">Since
    the process of gradient descent is akin to the red dot shown in</st> *<st c="50485">Figure
    4</st>**<st c="50493">.7</st>* <st c="50495">rolling down the slope of the risk
    function, it means gradient descent will roll downhill to the minimum closest
    to its starting point.</st> <st c="50632">Consequently, the result of a simple
    gradient descent can vary according to where we start.</st> <st c="50724">One
    pragmatic solution to this is to run the gradient descent multiple times and keep
    the results from the run with the lowest final value of the</st> <st c="50870">risk
    function.</st>'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="50255">局部最小值</st>**<st c="50268">：在</st> *<st c="50298">图 4</st>**<st
    c="50306">.7</st>* <st c="50308">中展示的风险函数有一个最小值。</st> <st c="50331">对于现实世界的数据集，风险函数通常有多个最小值。</st>
    <st c="50373">由于梯度下降过程类似于</st> *<st c="50485">图 4</st>**<st c="50493">.7</st>*
    <st c="50495">中红点沿着风险函数的斜坡滚下，它意味着梯度下降将朝着距离起始点最近的最小值滚动。</st> <st c="50632">因此，简单的梯度下降结果会根据我们开始的位置有所不同。</st>
    <st c="50724">一种务实的解决方案是多次运行梯度下降，并保留最终风险函数值最低的一次结果。</st>'
- en: '**<st c="50884">Stochastic gradient descent (SGD)</st>**<st c="50918">: If
    we have a large training dataset, calculating even just a single iteration of
    the update rule given by</st> *<st c="51027">Eq.</st> <st c="51031">27</st>* <st
    c="51033">may be computationally costly.</st> <st c="51065">An alternative</st>
    <st c="51080">approach is to evaluate the empirical risk (and hence the update
    rule) for just a random subset of the training data.</st> <st c="51198">At one
    extreme, we can just select a single training datapoint to update our model parameter
    estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1508.png)<st
    c="51300"><st c="51301">. This leads to quicker updating of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1508.png)
    <st c="51337"><st c="51338">but we must perform multiple updates (that is, random
    selections of single training datapoints) to obtain a reliable overall estimate</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1510.png)<st
    c="51473"><st c="51474">. We may cycle through the entire training data but in
    a random order.</st> <st c="51545">Because of this random order in which we use
    the training data to calculate parameter updates, this</st> <st c="51645">approach
    is called SGD.</st> <st c="51669">An alternative version of SGD is to use bigger
    random subsets of the training data to calculate the empirical risk in the update
    rule in</st> *<st c="51806">Eq.</st> <st c="51810">27</st>*<st c="51812">. This
    approach is known as</st> **<st c="51840">mini-batch</st>** <st c="51850">SGD
    since we are using the training data in small batches, rather than just its entirety
    as we did in the simple</st> <st c="51963">version of gradient descent.</st> <st
    c="51993">In fact, the simple version of gradient descent is also known as batch
    gradient descent</st> <st c="52081">because we are using the entire batch of training
    data in</st> <st c="52139">one go.</st></st></st></st>'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="50884">随机梯度下降法 (SGD)</st>**<st c="50918">：如果我们有一个大规模的训练数据集，计算单次更新规则</st>
    *<st c="51027">公式</st> <st c="51031">27</st>* <st c="51033">可能会非常耗时。</st> <st
    c="51065">一种替代方法是仅对训练数据的随机子集评估经验风险（从而更新规则）。</st> <st c="51198">在一个极端情况下，我们可以选择一个训练数据点来更新我们的模型参数估计</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1508.png)<st
    c="51300"><st c="51301">。这样可以更快地更新</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1508.png)，<st
    c="51337"><st c="51338">但是我们必须进行多次更新（也就是随机选择单个训练数据点），才能得到一个可靠的整体估计</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1510.png)<st
    c="51473"><st c="51474">。我们可能会以随机的顺序遍历整个训练数据。</st> <st c="51545">由于我们使用训练数据计算参数更新的顺序是随机的，这种方法被称为SGD。</st>
    <st c="51645">SGD的另一种版本是使用更大的随机子集来计算更新规则中的经验风险</st> *<st c="51806">公式</st> <st
    c="51810">27</st>*<st c="51812">。这种方法被称为</st> **<st c="51840">小批量</st>** <st c="51850">SGD，因为我们是以小批量的方式使用训练数据，而不是像简单的梯度下降法那样使用整个数据集。</st>
    <st c="51963">事实上，简单版本的梯度下降法也被称为批量梯度下降法</st> <st c="51993">因为我们在一次迭代中使用了整个训练数据批次。</st>'
- en: '**<st c="52146">Adaptive gradient descent algorithms</st>**<st c="52183">:
    The simple version of gradient descent we demonstrated had a fixed learning rate.</st>
    <st c="52268">We explained that this learning rate had to be chosen well, but</st>
    <st c="52332">we didn’t explain how to do this.</st> <st c="52366">Tuning the
    learning rate can be an art.</st> <st c="52406">However, adaptive gradient descent
    algorithms attempt to automatically tune parameters such as the learning rate,
    so we have an adaptive learning rate whose value depends on where we are on the
    empirical risk function surface.</st> <st c="52633">There are a number of these
    adaptive gradient descent algorithms.</st> <st c="52699">Some of the more well-known
    (and well-used) ones include the AdaGrad optimizer and the Adam optimizer.</st>
    <st c="52802">The Adam optimizer also</st> <st c="52825">makes use of the concept
    of</st> **<st c="52854">momentum</st>**<st c="52862">, whereby the updates to
    the parameter estimate</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1511.png)
    <st c="52910"><st c="52911">are based not just on the current risk gradient</st>
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mfenced open=""
    close="|"><mstyle scriptlevel="+1"><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mstyle></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></munder></mrow></msub></mrow></math>](img/1512.png) <st
    c="52960"><st c="52961">but also on the gradient at the</st> <st c="52994">preceding
    iterations.</st></st></st>'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**<st c="52146">自适应梯度下降算法</st>**<st c="52183">：我们演示的简单版本的梯度下降有一个固定的学习率。</st>
    <st c="52268">我们解释了这个学习率必须选得很好，但</st> <st c="52332">我们没有解释如何做到这一点。</st> <st c="52366">调整学习率可以是一门艺术。</st>
    <st c="52406">然而，自适应梯度下降算法试图自动调整参数，如学习率，因此我们拥有一个自适应的学习率，其值取决于我们在经验风险函数表面的位置。</st>
    <st c="52633">这些自适应梯度下降算法有很多种。</st> <st c="52699">其中一些更为著名（并且广泛使用）的是AdaGrad优化器和Adam优化器。</st>
    <st c="52802">Adam优化器还</st> <st c="52825">利用了</st> **<st c="52854">动量</st>**<st
    c="52862">的概念，其中参数估计的更新</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:munder
    underaccent="false"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:math>](img/1511.png)
    <st c="52910"><st c="52911">不仅基于当前的风险梯度</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mfenced
    open="" close="|"><mstyle scriptlevel="+1"><mfrac><mrow><mo>∂</mo><mtext>Risk</mtext></mrow><mrow><mo>∂</mo><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder></mrow></mfrac></mstyle></mfenced><mrow><munder><mi>β</mi><mo
    stretchy="true">_</mo></munder><mo>=</mo><munder><mover><mi>β</mi><mo stretchy="true">ˆ</mo></mover><mo
    stretchy="true">_</mo></mml:munder></mrow></math>](img/1512.png) <st c="52960"><st
    c="52961">还基于前几次迭代的梯度。</st></st></st>'
- en: <st c="53015">That brief summary of some of the improvements on simple gradient
    descent is a good place to stop and recap what we have learned in this section
    and summarize the</st> <st c="53179">chapter overall.</st>
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53015">关于简单梯度下降的一些改进的简要总结，是一个很好的停顿点，可以回顾我们在本节中学到的内容，并总结本</st> <st c="53179">章的内容。</st>
- en: <st c="53195">What we learned</st>
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="53195">我们学到的内容</st>
- en: <st c="53211">In this section, we have learned</st> <st c="53245">the following:</st>
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53211">在本节中，我们已经学习了</st> <st c="53245">以下内容：</st>
- en: <st c="53259">How to use the derivative of the empirical risk to estimate model
    parameters with any choice of</st> <st c="53356">loss function</st>
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="53259">如何使用经验风险的导数来估计模型参数，适用于任何损失函数的选择</st> <st c="53356">损失函数</st>
- en: <st c="53369">How the simple idea of gradient descent has been extended to create
    sophisticated gradient-based general</st> <st c="53475">optimization algorithms</st>
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="53369">如何将简单的梯度下降思想扩展，创造出复杂的基于梯度的通用</st> <st c="53475">优化算法</st>
- en: <st c="53498">Summary</st>
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="53498">总结</st>
- en: <st c="53506">This chapter has focused on a single, but important, concept –
    loss functions.</st> <st c="53586">Loss functions are important because they help
    us measure how good our predictive models are and, more generally, how well one
    mathematical object approximates another.</st> <st c="53755">They are also important
    because we can minimize them with respect to our model parameters, and so we can
    use loss functions, or more specifically risk functions, to fit our models to
    training data.</st> <st c="53953">In this chapter, we have learned about the different
    aspects of risk functions and how to minimize them.</st> <st c="54058">Specifically,
    we have learned about</st> <st c="54094">the following:</st>
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53506">本章重点介绍了一个重要的概念——损失函数。</st> <st c="53586">损失函数很重要，因为它们帮助我们衡量预测模型的好坏，或者更广泛地说，衡量一个数学对象对另一个对象的近似程度。</st>
    <st c="53755">它们同样重要，因为我们可以针对模型参数进行最小化，因此我们可以使用损失函数，或者更具体地说，风险函数，来将模型拟合到训练数据上。</st>
    <st c="53953">在本章中，我们学习了风险函数的不同方面以及如何最小化它们。</st> <st c="54058">具体来说，我们学习了</st>
    <st c="54094">以下内容：</st>
- en: <st c="54108">What a loss function is and what</st> <st c="54142">it measures</st>
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54108">损失函数是什么，以及</st> <st c="54142">它衡量什么</st>
- en: <st c="54153">That a risk function is the expectation value of a</st> <st c="54205">loss
    function</st>
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54153">风险函数是损失函数的期望值</st>
- en: <st c="54218">What the empirical risk function is and how it is calculated from</st>
    <st c="54285">training data</st>
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54218">经验风险函数是什么，以及它如何从</st> <st c="54285">训练数据中计算得出</st>
- en: <st c="54298">How least squares minimization is a form of empirical risk minimization
    and can be used to estimate optimal parameter values for</st> <st c="54428">a
    model</st>
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54298">最小二乘法最小化是一种经验风险最小化形式，可以用来估计</st> <st c="54428">模型的最优参数值</st>
- en: <st c="54435">How OLS regression performs least squares minimization for</st>
    <st c="54495">linear models</st>
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54435">OLS回归如何进行最小二乘法最小化以拟合</st> <st c="54495">线性模型</st>
- en: <st c="54508">How to derive the closed-form formula for the OLS parameter estimates
    of a</st> <st c="54584">linear model</st>
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54508">如何推导出线性模型的OLS参数估计的封闭形式公式</st>
- en: <st c="54596">How to perform OLS regression using specialized regression packages
    such as</st> `<st c="54673">statsmodels</st>` <st c="54684">and via explicit calculation
    using the</st> <st c="54724">closed-form formula</st>
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54596">如何使用专门的回归包如</st> `<st c="54673">statsmodels</st>` <st c="54684">进行OLS回归，或通过使用</st>
    <st c="54724">封闭形式公式</st> <st c="54724">进行显式计算</st>
- en: <st c="54743">How empirical risk minimization can also be performed very generally
    via</st> <st c="54817">gradient descent</st>
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54743">如何通过</st> <st c="54817">梯度下降法</st> <st c="54743">一般地进行经验风险最小化</st>
- en: <st c="54833">Variants of simple gradient descent, such as SGD, and also adaptive
    gradient descent algorithms such as the</st> <st c="54942">Adam optimizer</st>
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="54833">简单梯度下降的变体，如SGD，以及自适应梯度下降算法，如</st> <st c="54942">Adam优化器</st>
- en: <st c="54956">Now we have learned how to measure how good a model is, we’ll
    move on to the task of learning the math behind the building of those models.</st>
    <st c="55097">Since those models will be built on data and data always contains
    a random component, it is natural for the building of models to use the probability
    concepts we introduced in</st> [*<st c="55273">Chapter 2</st>*](B19496_02.xhtml#_idTextAnchor061)<st
    c="55282">. That is why, in the next chapter, we’ll learn about</st> <st c="55336">probabilistic
    models.</st>
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="54956">现在我们已经学会了如何衡量一个模型的好坏，接下来我们将学习构建这些模型背后的数学原理。</st> <st c="55097">由于这些模型将建立在数据上，而数据总是包含随机成分，因此使用我们在</st>
    [*<st c="55273">第2章</st>*](B19496_02.xhtml#_idTextAnchor061)<st c="55282">中介绍的概率概念来构建模型是很自然的。</st>
    <st c="55336">这就是为什么在下一章中，我们将学习</st> <st c="55336">概率模型。</st>
- en: <st c="55357">Exercises</st>
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="55357">练习</st>
- en: <st c="55367">Next is a series of exercises.</st> <st c="55399">Answers to all
    the exercises are given in the</st> `<st c="55445">Answers_to_Exercises_Chap4.ipynb</st>`
    <st c="55477">Jupyter notebook in the</st> <st c="55502">GitHub repository:</st>
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="55367">接下来是一系列练习。</st> <st c="55399">所有练习的答案都在</st> `<st c="55445">Answers_to_Exercises_Chap4.ipynb</st>`
    <st c="55477">Jupyter笔记本中，位于</st> <st c="55502">GitHub仓库：</st>
- en: <st c="55520">Look at the documentation for the</st> `<st c="55555">scikit-learn</st>`
    <st c="55567">class named</st> `<st c="55580">sklearn.linear_model.LinearRegression</st>`<st
    c="55617">, which can fit a linear model using OLS regression.</st> <st c="55670">See
    if you can use it to fit a linear model to the power-plant output data that we
    analyzed in the code example in the</st> *<st c="55789">Linear models</st>* <st
    c="55802">section of this chapter.</st> <st c="55828">Do you get the same parameter
    estimates as when we used the</st> `<st c="55888">statsmodels</st>` <st c="55899">package?</st>
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="55520">查看名为</st> `<st c="55555">scikit-learn</st>` <st c="55567">的类的文档，该类名为</st>
    `<st c="55580">sklearn.linear_model.LinearRegression</st>`<st c="55617">，可以使用
    OLS 回归拟合线性模型。</st> <st c="55670">看看你是否可以用它拟合我们在本章</st> *<st c="55789">线性模型</st>*
    <st c="55802">部分代码示例中分析的电厂输出数据。</st> <st c="55828">你得到的参数估计是否与我们使用</st> `<st c="55888">statsmodels</st>`
    <st c="55899">包时相同？</st>
- en: <st c="55908">The data plotted in</st> *<st c="55929">Figure 4</st>**<st c="55937">.3</st>*
    <st c="55939">is stored in the</st> `<st c="55957">Data/outliers_example.csv</st>`
    <st c="55982">file of the GitHub repository.</st> <st c="56014">Using the pseudo-Huber
    loss function in</st> *<st c="56054">Eq.</st> <st c="56058">12</st>* <st c="56060">and
    a learning rate of</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/1513.png)<st
    c="56084"><st c="56094">, see if you can use the simple gradient descent algorithm
    to construct robust estimates for both the intercept and the slope for a linear
    model of</st> <st c="56242">the data.</st></st>
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="55908">在</st> *<st c="55929">图 4</st>**<st c="55937">.3</st>* <st c="55939">中绘制的数据存储在</st>
    `<st c="55957">Data/outliers_example.csv</st>` <st c="55982">文件中。</st> <st c="56014">使用</st>
    *<st c="56054">公式</st> <st c="56058">12</st>* <st c="56060">中的伪Huber损失函数，学习率为</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math>](img/1513.png)<st
    c="56084"><st c="56094">，看看能否使用简单的梯度下降算法来为线性模型构建稳健的截距和斜率估计，这个模型是用于分析</st> <st
    c="56242">这些数据的。</st></st>
- en: <st c="56251">The data in the</st> `<st c="56268">Data/nls_example.csv</st>`
    <st c="56288">file of the GitHub repository contains data that has been generated
    according to the</st> <st c="56374">following relationship:</st>
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="56251">GitHub 仓库中的</st> `<st c="56268">Data/nls_example.csv</st>` <st
    c="56288">文件包含根据以下关系生成的数据：</st>
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>y</mi><mo
    mathvariant="italic">=</mo><mi>A</mi><mo mathvariant="italic">+</mo><mi>B</mi><msup><mi>e</mi><mrow><mo
    mathvariant="italic">−</mo><mi>C</mi><mi>x</mi></mrow></msup></mrow></mrow></math>](img/1514.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>y</mi><mo
    mathvariant="italic">=</mo><mi>A</mi><mo mathvariant="italic">+</mo><mi>B</mi><msup><mi>e</mi><mrow><mo
    mathvariant="italic">−</mo><mi>C</mi><mi>x</mi></mrow></msup></mrow></mrow></math>](img/1514.png)'
- en: <st c="56406">Eq.</st> <st c="56410">30</st>
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="56406">公式</st> <st c="56410">30</st>
- en: <st c="56412">The</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="56417"><st c="56440">values in the dataset have been corrupted by noise;
    that is, they also contain an additive random component.</st> <st c="56549">Use
    least squares minimization to estimate suitable values for the parameters</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:math>](img/1516.png)<st
    c="56627"><st c="56628">, and</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>C</mml:mi></mml:math>](img/461.png)<st
    c="56634"><st c="56635">. That is, minimize the empirical risk using a squared-loss
    function and a model of the form in the preceding equation.</st> <st c="56755">You
    can assume that the parameter</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>C</mml:mi></mml:math>](img/461.png)
    <st c="56789"><st c="56790">is strictly positive; that</st> <st c="56818">is,</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>C</mml:mi><mml:mo>></mml:mo><mml:mn>0</mml:mn></mml:math>](img/1519.png)<st
    c="56822"><st c="56823">.</st></st></st></st></st></st>
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="56412">这些</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>y</mml:mi></mml:math>](img/24.png)
    <st c="56417"><st c="56440">数据集中的值已被噪声干扰；也就是说，它们还包含了一个加性的随机成分。</st> <st c="56549">使用最小二乘法来估计合适的参数值</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:math>](img/1516.png)<st
    c="56627"><st c="56628">，以及</st> ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>C</mml:mi></mml:math>](img/461.png)<st
    c="56634"><st c="56635">。也就是说，使用平方损失函数和前述方程中的模型来最小化经验风险。</st> <st c="56755">你可以假设参数</st>
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>C</mml:mi></mml:math>](img/461.png)
    <st c="56789"><st c="56790">是严格正数；也就是说，</st> <st c="56818">即</st> ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>C</mml:mi><mml:mo>></mml:mo><mml:mn>0</mml:mn></mml:math>](img/1519.png)<st
    c="56822"><st c="56823">。</st></st></st></st></st></st>
