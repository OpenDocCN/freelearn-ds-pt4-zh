["```py\npip install matplotlib numpy statsmodels scikit-learn scipy\n```", "```py\nconda install matplotlib numpy statsmodels scikit-learn scipy\n```", "```py\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport numpy as np\n```", "```py\ndef read_dataset(folder, file, date_col=None, format=None, index=False):\n    '''\n    folder: is a Path object\n    file: the CSV filename in that Path object.\n    date_col: specify a column which has datetime\n    index_col: True if date_col should be the index\n\n    returns: a pandas DataFrame with a DatetimeIndex\n    '''\n    index_col = date_col if index is True else None\n\n    df = pd.read_csv(folder / file,\n                     index_col=index_col,\n                     parse_dates=[date_col],\n                     date_format=format)\n    return df\n```", "```py\ndef plot_dfs(df1, df2, col, title=None, xlabel=None, ylabel=None):\n    '''   \n    df1: original dataframe without missing data\n    df2: dataframe with missing data\n    col: column name that contains missing data\n    '''   \n    df_missing = df2.rename(columns={col: 'missing'})\n\n    columns = df_missing.loc[:, 'missing':].columns.tolist()\n    subplots_size = len(columns)   \n    fig, ax = plt.subplots(subplots_size+1, 1, sharex=True)\n    plt.subplots_adjust(hspace=0.25)\n    fig.suptitle = title\n\n    df1[col].plot(ax=ax[0], figsize=(10, 12))\n    ax[0].set_title('Original Dataset')\n    ax[0].set_xlabel(xlabel)\n    ax[0].set_ylabel(ylabel)   \n\n    for i, colname in enumerate(columns):\n        df_missing[colname].plot(ax=ax[i+1])\n        ax[i+1].set_title(colname.upper())\n    plt.show()\n```", "```py\ndef rmse_score(df1, df2, col=None):\n    '''\n    df1: original dataframe without missing data\n    df2: dataframe with missing data\n    col: column name that contains missing data\n    returns: a list of scores\n    '''\n    df_missing = df2.rename(columns={col: 'missing'})\n    columns = df_missing.loc[:, 'missing':].columns.tolist()\n    scores = []\n    for comp_col in columns[1:]:\n        rmse = np.sqrt(np.mean((df1[col] - df_missing[comp_col])**2))\n        scores.append(rmse)\n        print(f'RMSE for {comp_col}: {rmse}')\n    return scores\n```", "```py\nfolder = Path('../../datasets/Ch7/')\nco2_file = Path('co2_missing.csv')\necom_file = Path('clicks_missing_multiple.csv')\nco2_df = read_dataset(folder,\n                      co2_file,\n                      index=True,\n                      date_col='year')\necom_df = read_dataset(folder,\n                       ecom_file,\n                       index=True,\n                       date_col='date')\necom_df.head()\n```", "```py\nisinstance(True, int)\n>> True\nint(True)\n>> 1\n```", "```py\nco2_df.isnull().sum()\n>>\nco2     25\ndtype: int64\necom_df.isnull().sum()\n>>\nprice        1\nlocation     1\nclicks      14\ndtype: int64\n```", "```py\nco2_df.reset_index(inplace=True)\necom_df.reset_index(inplace=True)\n```", "```py\nco2_df.isnull().sum()\n>>\nyear     0\nco2     25\ndtype: int64\necom_df.isnull().sum()\n>>\ndate         4\nprice        1\nlocation     1\nclicks      14\ndtype: int64\n```", "```py\necom_df.isnull().sum().sum()\n>> 20\n```", "```py\nco2_df.isnull().sum().sum()\n>> 25\n```", "```py\nco2_df[190:195]\n```", "```py\necom_df.isnull().values.any()\n>> True\nco2_df.isnull().values.any()\n>> True\n```", "```py\necom_df.info()\n>>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 135 entries, 0 to 134\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype        \n---  ------    --------------  -----        \n 0   date      132 non-null    datetime64[ns]\n 1   price     134 non-null    float64      \n 2   location  134 non-null    float64      \n 3   clicks    121 non-null    object       \ndtypes: datetime64[ns](1), float64(2), object(1)\nmemory usage: 4.3+ KB\nco2_df.info()\n>>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 226 entries, 0 to 225\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   year     226 non-null    datetime64[ns]\n 1   co2      201 non-null    float64\ndtypes: float64(1), int64(1)\nmemory usage: 3.7 KB\n```", "```py\nco2_df.describe(include='all')\n```", "```py\necom_df.describe(include='all')\n```", "```py\nco2_df.replace(0, np.NaN, inplace=True)\necom_df.replace('?', np.NaN, inplace=True)\necom_df['clicks'] = ecom_df['clicks'].astype('float')\n```", "```py\nco2_df.isnull().sum()\n>>\nyear        0\nmissing    35\ndtype: int64\necom_df.isnull().sum()\n>>\ndate         4\nprice        1\nlocation     1\nclicks      16\ndtype: int64\n```", "```py\nco2_df = pd.read_csv(folder/co2_file,\n                     keep_default_na=False)\nco2_df.isna().sum()\n>>\nyear    0\nco2     0\ndtype: int64\nco2_df.shape\n>> (226, 2)\n```", "```py\nco2_df.info()\n>>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 226 entries, 0 to 225\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype        \n---  ------  --------------  -----        \n 0   year    226 non-null    datetime64[ns]\n 1   co2     226 non-null    object       \ndtypes: datetime64[ns](1), object(1)\nmemory usage: 3.7+ KB\n```", "```py\nco2_df[190:195]\n```", "```py\nco2_df.iloc[132:139]\n```", "```py\nco2_df.isnull().sum()\nco2_df.isnull().sum().sum()\n```", "```py\necom_df = pd.read_csv(folder/ecom_file,\n                      parse_dates=['date'],\n                      na_values={'?'})\n```", "```py\nco2_original = read_dataset(folder, 'co2_original.csv', 'year', index=True)\nco2_missing = read_dataset(folder, 'co2_missing_only.csv', 'year', index=True)\nclicks_original = read_dataset(folder, 'clicks_original.csv', 'date', index=True)\nclicks_missing = read_dataset(folder, 'clicks_missing.csv', 'date', index=True)\n```", "```py\nplot_dfs(co2_original,\n         co2_missing,\n         'co2',\n         title=\"Annual CO2 Emission per Capita\",\n         xlabel=\"Years\",\n         ylabel=\"x100 million tons\")\n```", "```py\nplot_dfs(clicks_original,\n         clicks_missing,\n         'clicks',\n         title=\"Page Clicks per Day\",\n         xlabel=\"date\",\n         ylabel=\"# of clicks\")\n```", "```py\nclicks_missing[clicks_missing['clicks'].isna()]\n```", "```py\nco2_missing['ffill'] = co2_missing['co2'].ffill()\nco2_missing['bfill'] = co2_missing['co2'].bfill()\nco2_missing['mean'] = co2_missing['co2'].fillna(co2_missing['co2'].mean())\n```", "```py\n_ = rmse_score(co2_original,\n                    co2_missing,\n                    'co2')\n>>\nRMSE for ffil: 0.05873012599267133\nRMSE for bfill: 0.05550012995280968\nRMSE for mean: 0.7156383637041684\n```", "```py\nplot_dfs(co2_original, co2_missing, 'co2')\n```", "```py\nclicks_missing['ffil'] = clicks_missing['clicks'].ffill()\nclicks_missing['bfill'] = clicks_missing['clicks'].bfill()\nclicks_missing['mean'] = clicks_missing['clicks'].fillna(clicks_missing['clicks'].mean())\n```", "```py\n_ = rmse_score(clicks_original,\n                    clicks_missing,\n                    'clicks')\n>>\nRMSE for ffil: 1034.1210689204554\nRMSE for bfill: 2116.6840489225033\nRMSE for mean: 997.7600138929953\n```", "```py\nplot_dfs(clicks_original, clicks_missing, 'clicks')\n```", "```py\nclicks_missing = read_dataset(folder, 'clicks_missing_more.csv', 'date', index=True)\nclicks_missing.isna().sum()\n```", "```py\nprice        5\nlocation     6\nclicks      16\ndtype: int64\n```", "```py\nvalues = {'clicks': clicks_missing['clicks'].median(),\n         'price': clicks_missing['clicks'].mean(),\n         'location': clicks_missing['location'].mode()}\nclicks_missing.fillna(value=values, inplace=True)\nclicks_missing.isna().sum()\n```", "```py\nprice       0\nlocation    0\nclicks      0\ndtype: int64\n```", "```py\nclicks_missing = read_dataset(folder, 'clicks_missing_more.csv', 'date', index=True)\nclicks_original = read_dataset(folder, 'clicks_original.csv', 'date', index=True)\n```", "```py\nclicks_missing.fillna(value=clicks_original, inplace=True)\nclicks_missing.isna().sum()\n```", "```py\nprice       0\nlocation    0\nclicks      0\ndtype: int64\n```", "```py\nfrom sklearn.impute import SimpleImputer\nfolder = Path('../../datasets/Ch7/')\nco2_original = read_dataset(folder,\n                            'co2_original.csv', 'year', index=True)\nco2_missing = read_dataset(folder,\n                           'co2_missing_only.csv', 'year', index=True)\nclicks_original = read_dataset(folder,\n                               'clicks_original.csv', 'date', index=True)\nclicks_missing = read_dataset(folder,\n                              'clicks_missing.csv', 'date', index=True)\n```", "```py\nstrategy = [\n    ('Mean Strategy', 'mean'),\n    ('Median Strategy', 'median'),\n    ('Most Frequent Strategy', 'most_frequent')]\n```", "```py\nco2_vals = co2_missing['co2'].values.reshape(-1,1)\nclicks_vals = clicks_missing['clicks'].values.reshape(-1,1)\nfor s_name, s in strategy:\n    co2_missing[s_name] = (\n        SimpleImputer(strategy=s).fit_transform(co2_vals))\n    clicks_missing[s_name] = (\n        SimpleImputer(strategy=s).fit_transform(clicks_vals))\n```", "```py\n_ = rmse_score(co2_original, co2_missing, 'co2')\n>>\nRMSE for Mean Strategy: 0.7156383637041684\nRMSE for Median Strategy: 0.8029421606859859\nRMSE for Most Frequent Strategy: 1.1245663822743381\n```", "```py\n_ = rmse_score(clicks_original, clicks_missing, 'clicks')\n>>\nRMSE for Mean Strategy: 997.7600138929953\nRMSE for Median Strategy: 959.3580492530756\nRMSE for Most Frequent Strategy: 1097.6425985146868\n```", "```py\nplot_dfs(co2_original, co2_missing, 'co2')\n```", "```py\nplot_dfs(clicks_original, clicks_missing, 'clicks')\n```", "```py\ntest = pd.Series([np.nan, np.nan, np.nan])\ntest\n>>\n0   NaN\n1   NaN\n2   NaN\ndtype: float64\n```", "```py\navg = co2_missing['co2'].mean()\nco2_missing['pands_fillna'] = co2_missing['co2'].fillna(avg)\ncols = ['co2', 'Mean Strategy', 'pands_fillna']\n_ = rmse_score(co2_original, co2_missing[cols], 'co2')\n>>\nRMSE for Mean Strategy: 0.7156383637041684\nRMSE for pands_fillna: 0.7156383637041684\n```", "```py\nco2_missing = read_dataset(folder,\n                           'co2_missing_only.csv', 'year', index=True)\nco2_vals = co2_missing['co2'].values.reshape(-1,1)\nimputer = SimpleImputer(strategy='mean', add_indicator=True)\nimputer.fit(co2_vals)\nimputer.get_params()\n>>\n{'add_indicator': True,\n 'copy': True,\n 'fill_value': None,\n 'keep_empty_features': False,\n 'missing_values': nan,\n 'strategy': 'mean'}\n```", "```py\nco2_missing[['imputed', 'indicator']] = (imputer.transform(co2_vals))\nco2_missing.head(5)\n```", "```py\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.ensemble import ExtraTreesRegressor, BaggingRegressor\nfrom sklearn.linear_model import ElasticNet, LinearRegression\nfrom sklearn.neighbors import KneighborsRegressor\n```", "```py\nfolder = Path('../../datasets/Ch7/')\nclicks_original = read_dataset(folder,\n                            'clicks_original.csv', 'date')\nclicks_missing = read_dataset(folder,\n                            'clicks_missing.csv', 'date')\n```", "```py\nestimators = [\n    ('bayesianRidge', BayesianRidge()),\n    ('extra_trees', ExtraTreesRegressor(n_estimators=50)),\n    ('bagging', BaggingRegressor(n_estimators=50)),\n    ('elastic_net', ElasticNet()),\n    ('linear_regression', LinearRegression()),\n    ('knn', KNeighborsRegressor(n_neighbors=3))\n]\n```", "```py\nclicks_vals = clicks_missing.iloc[:,0:3].values\nfor e_name, e in estimators:\n    est = IterativeImputer(\n                random_state=15,\n                estimator=e).fit(clicks_vals)\n    clicks_missing[e_name] = est.transform(clicks_vals)[: , 2]\n```", "```py\n_ = rmse_score(clicks_original, clicks_missing, 'clicks')\n```", "```py\nRMSE for bayesianRidge: 949.4393973455851\nRMSE for extra_trees: 1577.3003394830464\nRMSE for bagging: 1237.4433923801062\nRMSE for elastic_net: 945.40752093431\nRMSE for linear_regression: 938.9419831427184\nRMSE for knn: 1336.8798392251822\n```", "```py\nplot_dfs(clicks_original, clicks_missing, 'clicks')\n```", "```py\nfrom statsmodels.imputation.mice import MICE, MICEData, MICEResults\nimport statsmodels.api as sm\n```", "```py\n# create a MICEData object\nfltr = ['price', 'location','clicks']\nmice_data = MICEData(clicks_missing[fltr],\n                     perturbation_method='gaussian')\n# 20 iterations\nmice_data.update_all(n_iter=20)\nmice_data.set_imputer('clicks', formula='~ price + location', model_class=sm.OLS)\n```", "```py\nclicks_missing['MICE']  = mice_data.data['clicks'].values.tolist()\n_ = rmse_score(clicks_original, clicks_missing, 'clicks')\n>>\nRMSE for bayesianRidge: 949.4393973455851\nRMSE for extra_trees: 1577.3003394830464\nRMSE for bagging: 1237.4433923801062\nRMSE for elastic_net: 945.40752093431\nRMSE for linear_regression: 938.9419831427184\nRMSE for knn: 1336.8798392251822\nRMSE for MICE: 1367.190103013395\n```", "```py\ncols = ['clicks','bayesianRidge', 'bagging', 'knn', 'MICE']\nplot_dfs(clicks_original, clicks_missing[cols], 'clicks')\n```", "```py\nfolder = Path('../../datasets/Ch7/')\nco2_original = read_dataset(folder,\n                            'co2_original.csv', 'year', index=True)\nco2_missing = read_dataset(folder,\n                           'co2_missing_only.csv', 'year', index=True)\nclicks_original = read_dataset(folder,\n                               'clicks_original.csv', 'date', index=True)\nclicks_missing = read_dataset(folder,\n                              'clicks_missing.csv', 'date', index=True)\n```", "```py\ninterpolations = [\n    'linear',\n    'quadratic',\n    'nearest',\n    'cubic'\n]\n```", "```py\nfor intp in interpolations:\n    co2_missing[intp] = co2_missing['co2'].interpolate(method=intp)\n    clicks_missing[intp] = clicks_missing['clicks'].interpolate(method=intp)\n```", "```py\nco2_missing['spline'] = \\\n        co2_missing['co2'].interpolate(method='spline', order=2)\nclicks_missing['spline'] = \\\n        clicks_missing['clicks'].interpolate(method='spline',order=2)\nco2_missing['polynomial'] = \\\n        co2_missing['co2'].interpolate(method='polynomial',order=5)\nclicks_missing['polynomial'] = \\\n        clicks_missing['clicks'].interpolate(method='polynomial',order=5)\n```", "```py\n_ = rmse_score(co2_original, co2_missing, 'co2')\n>>\nRMSE for linear: 0.05507291327761665\nRMSE for quadratic: 0.08367561505614347\nRMSE for nearest: 0.05385422309469095\nRMSE for cubic: 0.08373627305833133\nRMSE for spline: 0.1878602347541416\nRMSE for polynomial: 0.06728323553134927\n```", "```py\n_ = rmse_score(clicks_original, clicks_missing, 'clicks')\n>>\nRMSE for linear: 1329.1448378562811\nRMSE for quadratic: 5224.641260626975\nRMSE for nearest: 1706.1853705030173\nRMSE for cubic: 6199.304875782831\nRMSE for spline: 5222.922993448641\nRMSE for polynomial: 56757.29323647127\n```", "```py\ncols = ['co2', 'linear', 'nearest', 'polynomial']\nplot_dfs(co2_original, co2_missing[cols], 'co2')\n```", "```py\ncols = ['clicks', 'linear', 'nearest', 'polynomial', 'spline']\nplot_dfs(clicks_original, clicks_missing[cols], 'clicks')\n```", "```py\nclicks_missing['clicks'].isna().sum()\n>> 16\nexample = clicks_missing['clicks'].interpolate(limit = 5)\nexample.isna().sum()\n>> 11\n```"]