<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xml:lang="en"
lang="en"
xmlns="http://www.w3.org/1999/xhtml"
xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<title>Time Series Analysis with Python Cookbook, 2E - Second Edition</title>
<link rel="stylesheet" type="text/css" href="../override_v1.css"/>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/><link rel="stylesheet" type="text/css" href="../styles/stylesheet2.css"/>
</head>
<body>
<div id="book-content">
<div id="sbo-rt-content"><section id="building-univariate-time-series-models-using-statistical-methods" class="level1 pkt" data-number="11">
<h1 data-number="11">10 Building Univariate Time Series Models Using Statistical Methods</h1>
<section id="join-our-book-community-on-discord-9" class="level2" data-number="11.1">
<h2 data-number="11.1">Join our book community on Discord</h2>
<p>
<img style="width:15rem" src="../media/file0.png" width="200" height="200"/>
</p>
<p><a href="https://packt.link/zmkOY">https://packt.link/zmkOY</a></p>
<p>In <em>Chapter 9</em>, <em>Exploratory Data Analysis and Diagnosis</em>, you were introduced to several concepts to help you understand the time series process. Such recipes included <em>Decomposing time series data</em>, <em>Detecting time series stationarity</em>, <em>Applying power transformations,</em> and <em>Testing for autocorrelation in time series data</em>. These techniques will come in handy in the statistical modeling approach that will be discussed in this chapter.</p>
<p>When working with time series data, different methods and models can be used, depending on whether the time series you are working with is <strong>univariate</strong> or <strong>multivariate</strong>, <strong>seasonal</strong> or <strong>non-seasonal</strong>, <strong>stationary</strong> or <strong>non-stationary</strong>, and <strong>linear</strong> or <strong>nonlinear</strong>. If you list the assumptions you need to consider and examine – for example, stationarity and autocorrelation – it will become apparent why time series data is deemed to be complex and challenging. Thus, to model such a complex system, your goal is to get a good enough approximation that captures the critical factors of interest. These factors will vary by industry domain and the study's objective, such as forecasting, analyzing a process, or detecting abnormalities.</p>
<p>Some popular statistical modeling methods include <strong>Exponential Smoothing</strong>, <strong>Autoregressive Integrated Moving Average</strong> (<strong>ARIMA</strong>), <strong>Seasonal ARIMA</strong> (<strong>SARIMA</strong>), <strong>Vector Autoregressive</strong> (<strong>VAR</strong>), and other variants of these models such as ARIMAX, SARIMAX, VARX, and VARMA. Many practitioners, such as economists and data scientists, still use such statistical “classical” models. Additionally, these models can be found in popular software packages such as EViews, MATLAB, Orange, KNIME, and Alteryx, as well as libraries in Python and R.</p>
<p>In this chapter, you will learn how to build these statistical models in Python. In other words, I will only provide a brief introduction to the theory and math since the focus is on the implementation. I will provide references where it makes sense if you are interested in diving deeper into the math and theory of such models.</p>
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Plotting ACF and PACF</li>
<li>Forecasting univariate time series data with exponential smoothing</li>
<li>Forecasting univariate time series data with non-seasonal ARIMA</li>
<li>Forecasting univariate time series data with seasonal ARIMA</li>
<li>Forecasting univariate time series data with Auto_Arima</li>
</ul>
<p>Before diving into these recipes, pay special attention to the upcoming <em>Technical requirements</em> section, in which you will perform upfront preparation. This will remove any distractions and repetitive coding so that you can focus on the recipe's core goals and the concepts behind each implementation.</p>
</section>
<section id="technical-requirements-9" class="level2" data-number="11.2">
<h2 data-number="11.2">Technical requirements</h2>
<p>You can download the Jupyter Notebooks and necessary datasets from this book's GitHub repository:</p>
<ul>
<li>Jupyter Notebook: <a href="https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./blob/main/code/Ch10/Chapter%2010.ipynb">https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./blob/main/code/Ch10/Chapter%2010.ipynb</a></li>
<li>Datasets: <a href="https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./tree/main/datasets/Ch10">https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./tree/main/datasets/Ch10</a></li>
</ul>
<p>Before you start working through the recipes in this chapter, please run the following code to load the datasets and functions that will be referenced throughout:</p>
<ol>
<li>Start by importing the basic libraries that will be shared across all the recipes in this chapter:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
from statsmodels.tsa.api import (kpss, adfuller,
                              seasonal_decompose, STL)
from statsmodels.tools.eval_measures import rmspe, rmse
from sklearn.metrics import mean_absolute_percentage_error as mape
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from itertools import product
from pathlib import Path
warnings.filterwarnings('ignore')
plt.rcParams["figure.figsize"] = [12, 5]
plt.style.use('grayscale')
warnings.filterwarnings('ignore')</code></pre>
</div>
<ol>
<li>You will be working with two datasets throughout this chapter: <code>Life Expectancy from Birth</code> and <code>Monthly Milk Production</code>. Import these datasets, which are stored in CSV format (<code>life_expectancy_birth.csv</code>, and <code>milk_production.csv</code>), into pandas DataFrames. Each dataset comes from a different time series process, so they will contain a different trend or seasonality. Once you've imported the datasets, you will have two DataFrames called <code>life</code> and <code>milk</code>:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>life_file = Path('../../datasets/Ch10/life_expectancy_birth.csv')
milk_file = Path('../../datasets/Ch10/milk_production.csv')
life = pd.read_csv(life_file,
                   index_col='year',
                   parse_dates=True,
                  skipfooter=1)
milk = pd.read_csv(milk_file,
                   index_col='month',
                   parse_dates=True)</code></pre>
</div>
<p>Inspect the data visually and observe if the time series contains any trend or seasonality. You can always come back to the plots shown in this section for reference:</p>
<div class="C1-SHCodePACKT">
<pre><code>fig, ax = plt.subplots(2, 1, figsize=(16, 12))
life.plot(title='Annual Life Expectancy',
                        legend=False, ax=ax[0])
milk.plot(title='Monthly Milk Production',
                        legend=False, ax=ax[1]);­</code></pre>
</div>
<p>This should display two time series plots:</p>
<figure>
<img src="../media/file152.png" alt="Figure 10.1: Time series plots for Annual Life Expectancy and Monthly Milk Production" width="1093" height="850"/><figcaption aria-hidden="true">Figure 10.1: Time series plots for Annual Life Expectancy and Monthly Milk Production</figcaption>
</figure>
<p>The preceding figure shows a time series plot for the <code>life expectancy</code> DataFrame showing a positive (upward) trend and no seasonality. The life expectancy data contains <em>annual</em> life expectancy records at birth from 1960 to 2018 (59 years). The original dataset contained records for each country, but you will be working with <em>world</em> records in this chapter.</p>
<p>The time series plot for the <code>monthly milk production</code> DataFrame shows a positive (upward) trend and a repeating seasonality (every summer). The milk production data is recorded monthly from January 1962 to December 1975 (168 months). The seasonal magnitudes and variations over time seem to be steady, indicating an additive nature. Having a seasonal decomposition that specifies the level, trend, and season of an additive model will reflect this as well.</p>
<p>For more insight on seasonal decomposition, please review the <em>Decomposing time series data</em> recipe in <em>Chapter 9</em>, <em>Exploratory Data Analysis and Diagnosis</em>.</p>
<ol>
<li>You will need to split the data into <code>test</code> and <code>train</code> datasets. You will train the models (fitting) on the training dataset and use the test dataset to evaluate the model and compare your predictions. A forecast that's created on the data that is used in training is called an <strong>in-sample</strong> forecast, while forecasting for unseen data such as a test set is called an <strong>out-of-sample</strong> forecast. When you're evaluating the different models, you will be using the out-of-sample or test sets.</li>
</ol>
<p>Create a generalized function, <code>split_data</code>, which splits the data based on a test split factor. This way, you can experiment on different splits as well. We will be referencing this function throughout this chapter:</p>
<div class="C1-CodePACKT">
<pre><code> def split_data(data, test_split):
    l = len(data)
    t_idx = round(l*(1-test_split))
    train, test = data[ : t_idx], data[t_idx : ]
    print(f'train: {len(train)} , test: {len(test)}')
    return train, test</code></pre>
</div>
<ol>
<li>Call the <code>split_data</code> function to split the two DataFrames into <code>test</code> and <code>train</code> datasets (start with 15% test and 85% train). You can always experiment with different split factors:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>test_split = 0.15
milk_train, milk_test = split_data(milk, test_split)
life_train, life_test = split_data(life, test_split)
&gt;&gt;
train: 143 , test: 25
train: 50 , test: 9</code></pre>
</div>
<ol>
<li>You will be checking for stationarity often since it is an essential assumption for many of the models you will build. For example, in <em>Chapter 9</em>, <em>Exploratory Data Analysis and Diagnosis</em>, in the <em>Detecting time series stationarity</em> recipe, we discussed the importance of testing for stationarity and using the <strong>Augmented Dickey-Fuller</strong> test. Create a function that you can refer to throughout this chapter to perform the test and interpret the results:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>def check_stationarity(df):
    results = adfuller(df)[1:3]
    s = 'Non-Stationary'
    if results[0] &lt; 0.05:
        s = 'Stationary'
    print(f"'{s}\t p-value:{results[0]} \t lags:{results[1]}")
    return (s, results[0])</code></pre>
</div>
<ol>
<li>There will be recipes in which you will run multiple variations of a model as you search for the optimal configuration, a practice commonly called <strong>hyperparameter tuning</strong>. For example, you may train an ARIMA model with different parameter values and thus produce multiple variations of the ARIMA model (multiple models).</li>
</ol>
<p>The <code>get_top_models_df</code> function will compare the different models – for example, multiple ARIMA models – to select the best model and the set of parameters associated with that model. The <code>get_top_models_df</code> function will take a dictionary that contains the produced models, the associated parameters, and the scores for each model. It returns a DataFrame detailing the top performing models, for easier comparison. The function allows you to specify the number of top models to return and the <code>criterion</code> for their selection, such as Root Mean Squared Percentage Error (<strong>RMSPE</strong>), Root Mean Square Error (<strong>RMSE</strong>), Mean Absolute Percentage Error (<strong>MAPE</strong>), Akaike's Information Criteria (<strong>AIC</strong>), Corrected Akaike's Information Criteria (<strong>AICc</strong>), or Bayesian Information Criteria (<strong>BIC</strong>). These metrics can be crucial in determining the most suitable model for your data analysis needs.</p>
<p>For example, you may opt to evaluate the models based on their AIC scores by default, but you can easily switch to another metric like RMSPE or RMSE if these are more relevant to your specific situation. This flexibility ensures that you can tailor the model selection process to best fit the analytical demands and complexity of your data.</p>
<div class="C1-CodePACKT">
<pre><code>def get_top_models_df(scores, criterion='AIC', top_n=5):
    sorted_scores = sorted(scores.items(),
                           key=lambda item: item[1][criterion])
   
    top_models = sorted_scores[:top_n]
    data = [v for k, v in top_models]
    df = pd.DataFrame(data)
   
    df['model_id'] = [k for k, v in top_models]
    df.set_index('model_id', inplace=True)
    return df</code></pre>
</div>
<ol>
<li>Create the <code>plot_forecast</code> function, which takes a model object that you have trained, a starting position, and both the train and test datasets to create a plot that compares the forecast (predicted values) against actuals. This will become clearer as you dive into this chapter's recipes:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>def plot_forecast(model, start, train, test):
    forecast = pd.DataFrame(model.forecast(test.shape[0]),
                            index=test.index)
    ax = train.loc[start:].plot(style='--')
    test.plot(ax=ax)
    forecast.plot(ax=ax, style = '-.')
    ax.legend(['orig_train', 'orig_test', 'forecast'])
    plt.show()</code></pre>
</div>
<ol>
<li>Lastly, create a <code>combinator</code> utility function that takes a list of parameter values and returns a <strong>cartesian product</strong> of these choices. You will use this when performing a grid search for hyperparameter tuning. In grid search, you specify a combination of parameter values to train multiple models on each set and then evaluate the winning model using the <code>get_top_models_df </code>function. For example, suppose your list contains three possible values for three different parameters. In such a case, the <code>combinator</code> function will return a list containing 3x3 or nine possible combinations. This will become clearer as you dive into this chapter's recipes:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>def combinator(items):
    combo = [i for i in product(*items)]
    return combo</code></pre>
</div>
<p>We can represent the overall flow as in <em>Figure 10.2</em> which shows how you will be utilizing the functions you just created.</p>
<figure>
<img src="../media/file153.jpg" alt="Figure 10.2: The overall process in this Chapter utilizing the prepared helper functions created" width="883" height="274"/><figcaption aria-hidden="true">Figure 10.2: The overall process in this Chapter utilizing the prepared helper functions created</figcaption>
</figure>
<p>Now, let's dive into the recipes.</p>
<p>In the first recipe, you will be introduced to the <strong>ACF</strong> and <strong>PACF</strong> plots, which are used to evaluate model fit, check stationarity, and determine the <strong>orders</strong> (<strong>parameters</strong>) for some of the models that will be used in this chapter, such as the ARIMA model.</p>
</section>
<section id="plotting-acf-and-pacf" class="level2" data-number="11.3">
<h2 data-number="11.3">Plotting ACF and PACF</h2>
<p>Before building any statistical forecasting models such as <strong>AR</strong> (AutoRegressive), <strong>MA</strong> (Moving Average), <strong>ARMA</strong> (AutoRegressive Moving Average), <strong>ARIMA</strong> (AutoRegressive Integrated Moving Average), or <strong>SARIMA</strong> (Seasonal AutoRegressive Integrated Moving Average), you will need to determine the most suitable type of time series model for your data. Additionally, you will need to identify the values for some required parameters, known as orders. More specifically, these include the lag orders for the autoregressive (AR) or moving average (MA) components. This process will be explored further in the <em>'Forecasting Univariate Time Series Data with ARIMA'</em> section of this chapter. For example, an Autoregressive Moving Average (ARMA) model is denoted as <code>ARMA(p, q)</code>, where <code>'p'</code> represents the autoregressive order, or AR(p) component, and <code>'q'</code> represents the moving average order, or MA(q) component. Hence, an ARMA model combines an AR(p) and an MA(q) model.</p>
The core idea behind these models is built on the assumption that the current value of a particular variable,
<figure>
<img style="width:2rem" src="../media/file154.png" width="35" height="34"/>
</figure>
, can be estimated from past values of itself. For example, in an autoregressive model of order <code>p</code> or <code>AR(p)</code>, we assume that the current value,
<figure>
<img style="width:2rem" src="../media/file155.png" width="43" height="49"/>
</figure>
, at time
<figure>
<img style="width:2rem" src="../media/file156.png" width="26" height="43"/>
</figure>
can be estimated from its past values (
<figure>
<img style="width:10rem" src="../media/file157.png" width="338" height="53"/>
</figure>
) up to <code>p</code>, where <code>p</code> determines how many lags (steps back) we need to go. If
<figure>
<img style="width:4rem" src="../media/file158.png" width="116" height="50"/>
</figure>
, this means we must use two previous periods
<figure>
<img style="width:10rem" src="../media/file159.png" width="202" height="53"/>
</figure>
) to predict
<figure>
<img style="width:2rem" src="../media/file160.png" width="45" height="50"/>
</figure>
. Depending on the granularity of your time series data, <code>p=2</code> can be 2 hours, 2 days, 2 months, 2 quarters, or 2 years.
<p>To build an ARMA(p,q) model, you will need to provide values for the <code>p</code> and <code>q</code> orders (known as lags). These are considered <strong>hyperparameters</strong> since they are supplied by you to influence the model.</p>
<p>The terms parameters and hyperparameters are sometimes used interchangeably. However, they have different interpretations and you need to understand the distinction.</p>
<blockquote>
<p>PARAMETERS VERSUS HYPERPARAMETERS</p>
<blockquote>
<p>When training an ARMA or an ARIMA model, the outcome will produce a set of parameters called coefficients – for example, a coefficient value for AR Lag 1 or sigma – that are estimated by the algorithm during the model training process and are used for making predictions. They are referred to as the model's parameters.</p>
</blockquote>
<blockquote>
<p>On the other hand, the (p, d, q) parameters are the ARIMA(p, q, d) orders for AR, differencing, and MA, respectively. These are called hyperparameters. They are provided during training and influence the model’s parameters that are produced (for example, the coefficients). These hyperparameters, can be tuned using grid search, for example, to find the best set of values that produce the best model.</p>
</blockquote>
</blockquote>
<p>Now, you might be asking yourself, how do I find the significant lag values for AR and MA models?</p>
<p>This is where the <strong>Autocorrelation Function</strong> (<strong>ACF</strong>) and the <strong>Partial Autocorrelation Function</strong> (<strong>PACF</strong>) and their plots come into play. The ACF and PACF can be plotted to help you identify if the time series process is an AR, MA, or an ARMA process (if both are present) and the <em>significant</em> lag values (for <code>p</code> and <code>q</code>). Both PACF and ACF plots are referred to as <strong>correlograms</strong> since the plots represent the <strong>correlation</strong> statistics.</p>
<p>The difference between an ARMA and ARIMA, written as <code>ARIMA(p, d, q)</code>, is in the stationarity assumption. The <code>d</code> parameter in ARIMA is for the differencing order. An ARMA model assumes a <strong>stationary</strong> process, while an ARIMA model does not since it handles differencing. An ARIMA model is a more generalized model since it can satisfy an ARMA model by making the differencing factor <code>d=0</code>. Hence, an <code>ARIMA(1,0,1)</code> is <code>ARMA(1,1)</code>.</p>
<blockquote>
<p><strong>AR</strong> ORDER VERSUS <strong>MA</strong> ORDER</p>
<blockquote>
<p>You will use the PACF plot to estimate the AR order and the ACF plot to estimate the MA order. Both the ACF and PACF plots show values that range from <code>-1</code> to <code>1</code> on the vertical axis (y-axis), while the horizontal axis (x-axis) indicates the size of the lag. A <em>significant</em> lag is any lag that goes outside the shaded confidence interval, as you shall see from the plots.</p>
</blockquote>
</blockquote>
<p>The <strong>statsmodels</strong> library provides two functions: <code>acf_plot</code> and <code>pacf_plot</code>. The correlation (for both ACF and PACF) at lag zero is always <em>one</em> (since it represents autocorrelation of the first observation on itself). Hence, both functions provide the <code>zero</code> parameter, which takes a Boolean. Therefore, to exclude the zero lag in the visualization, you can pass <code>zero=False</code> instead.</p>
<p>In <em>Chapter 9</em>, <em>Exploratory Data Analysis and Diagnosis</em>, in the <em>Testing autocorrelation in time series data</em> recipe, you used the <strong>Ljung-Box</strong> test to evaluate autocorrelation on the residuals. In this recipe, you will also learn how to use the ACF plot to examine <strong>residual autocorrelation</strong> visually as well.</p>
<section id="how-to-do-it-39" class="level3" data-number="11.3.1">
<h3 data-number="11.3.1">How to do it…</h3>
<p>In this recipe, you will explore <code>acf_plot</code> and <code>pacf_plot</code> from the <code>statsmodels</code> library. Let's get started:</p>
<ol>
<li>You will use the life expectancy data in this recipe. As shown in <em>Figure 10.1</em>, the data is not stationary due to the presence of a long-term trend. In such a case, you will need to difference (detrend) the time series to make it stationary <strong>before</strong> applying the ACF and PACF plots.</li>
</ol>
<p>Start by differencing and then create the plots without the zero lag:</p>
<div class="C1-CodePACKT">
<pre><code>life_diff = life.diff().dropna()
fig, ax = plt.subplots(2,1, figsize=(12,8))
plot_acf(life_diff, zero=False, ax=ax[0])
plot_pacf(life_diff, zero=False, ax=ax[1]);</code></pre>
</div>
<p>This should produce the following two plots:</p>
<figure>
<img src="../media/file161.png" alt="Figure 10.3: The ACF and PACF plots for the life expectancy data after differencing" width="1004" height="685"/><figcaption aria-hidden="true">Figure 10.3: The ACF and PACF plots for the life expectancy data after differencing</figcaption>
</figure>
<p>If you want to see the calculated PACF and ACF for more lags you can update the <code>lags</code> parameter as shown:</p>
<div class="C1-CodePACKT">
<pre><code>fig, ax = plt.subplots(2,1, figsize=(12,8))
plot_acf(life_diff, lags=25, zero=False, ax=ax[0])
plot_pacf(life_diff, lags=25,  zero=False, ax=ax[1]);</code></pre>
</div>
<p>This should produce the following two plots:</p>
<figure>
<img src="../media/file162.png" alt="Figure 10.4: The ACF and PACF for the first 25 lags" width="1002" height="684"/><figcaption aria-hidden="true">Figure 10.4: The ACF and PACF for the first 25 lags</figcaption>
</figure>
<p>The ACF plot shows a significant spike at lag (order) 1. Significance is represented when a lag (vertical line) goes above or below the shaded area. The shaded area represents the confidence interval, which is set to <code>95%</code> by default. In the ACF plot, only the first lag is significant, which is below the lower confidence interval, and then <em>cuts off</em> right after. All the remaining lags are not significant. This indicates a moving average of order one or MA(1).</p>
<p>The PACF plot shows a <em>gradual</em> decay with oscillation. Generally, if PACF shows a gradual decay, it indicates a moving average model. For example, if you are using an ARMA or ARIMA model, it would be represented as <code>ARMA(0, 1)</code> once the data has been differenced to make it stationary, or <code>ARIMA(0, 1, 1)</code>, indicating a first-order differencing with <code>d=1</code>. In both ARMA and ARIMA, the AR order is <code>p=0</code>, and the MA order is <code>q=1</code>.</p>
<ol>
<li>Now, let's see how PACF and ACF can be used with a more complex dataset containing strong trends and seasonality. In <em>Figure 10.1</em>, the <code>Monthly Milk Production</code> plot shows an annual seasonal effect and a positive upward trend indicating a non-stationary time series. It is more suitable with a SARIMA model. In a SARIMA model, you have two components: a non-seasonal and a seasonal component. For example, in addition to the AR and MA processes for the non-seasonal components represented by lower case <code>p</code> and <code>q</code>, which you saw earlier, you will have AR and MA orders for the seasonal component, which are represented by upper case <code>P</code> and <code>Q</code>, respectively. This can be written as <code>SARIMA(p,d,q)(P,D,Q,S)</code>. You will learn more about the SARIMA model in the <em>Forecasting univariate time series data with seasonal ARIMA</em> recipe.</li>
</ol>
<p>To make such time series stationary, you will need to start with seasonal differencing to remove the seasonal effect. Since the observations are taken monthly, the seasonal effects are observed annually (every 12 months or period):</p>
<div class="C1-CodePACKT">
<pre><code>milk_diff_12 = milk.diff(12).dropna()</code></pre>
</div>
<ol>
<li>Use the <code>check_stationarity</code> function that you created earlier in this chapter to perform an Augmented Dickey-Fuller test to check for stationarity:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>check_stationarity(milk_diff_12)
&gt;&gt; 'Non-Stationary     p-value:0.16079880527711382      lags:12</code></pre>
</div>
<ol>
<li>The differenced time series is still not stationary, so you still need to perform a second differencing. This time, you must perform first-order differencing (detrend). When the time series data contains seasonality and trend, you may need to difference it twice to make it stationary. Store the resulting DataFrame in the <code>milk_diff_12_1</code> variable and run <code>check_stationarity</code> again:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>milk_diff_12_1 = milk.diff(12).diff(1).dropna()
check_stationarity(milk_diff_12_1)
&gt;&gt; 'Stationary     p-value:1.865423431878876e-05     
lags:11</code></pre>
</div>
<p>Great – now, you have a stationary process.</p>
<ol>
<li>Plot ACF and PACF for the stationary time series in <code>milk_diff_12_1</code>:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>fig, ax = plt.subplots(1,2)
plot_acf(milk_diff_12_1, zero=False, ax=ax[0], lags=36)
plot_pacf(milk_diff_12_1, zero=False, ax=ax[1], lags=36);</code></pre>
</div>
<p>This should produce the following ACF and PACF plots:</p>
<figure>
<img src="../media/file163.png" alt="Figure 10.5: PACF and ACF for Monthly Milk Production after differencing" width="2002" height="1362"/><figcaption aria-hidden="true">Figure 10.5: PACF and ACF for Monthly Milk Production after differencing</figcaption>
</figure>
<p>For the seasonal orders, <code>P</code> and <code>Q</code>, you should diagnose spikes or behaviors at lags <code>s</code>, <code>2s</code>, <code>3s</code>, and so on, where <code>s </code>is the number of periods in a season. For example, in the milk production data, <code>s=12</code> (since there are 12 monthly periods in a season). Then, we observe for significance at 12 (s), 24 (2s), 36 (3s), and so on.</p>
<p>Starting with the ACF plot, there is a significant spike at lag 1, which represents the <em>non-seasonal</em> order for the MA process as <code>q=1</code>. The spike at lag 12 represents the <em>seasonal</em> order for the MA process as <code>Q=1</code>. Notice that there is a cut-off right after lag 1, then a spike at lag 12, followed by a cut-off (no other significant lags afterward). These indicate a moving average model: an MA(1) for the non-seasonal component and an MA(1) for the seasonal component. The PACF plot confirms this as well; an exponential decay at lags 12, 24, and 36 indicates an MA model. So, the SARIMA model would be <code>ARIMA (0, 1,1)(0, 1, 1, 12)</code>.</p>
<blockquote>
<p>Though using ACF and PACF plots can be useful for identifying the ARIMA orders p and q, it should not be used alone. There are different techniques that you will explore in this chapter to help you determine the orders such as model selection techniques using AIC and BIC.</p>
</blockquote>
</section>
<section id="how-it-works-38" class="level3" data-number="11.3.2">
<h3 data-number="11.3.2">How it works…</h3>
<p>The ACF and PACF plots can help you understand the strength of the linear relationship between past observations and their significance at different lags.</p>
<p>The ACF and PACF plots show significant autocorrelation or partial autocorrelation above the <strong>confidence interval</strong>. The shaded portion represents the confidence interval, which is controlled by the <code>alpha</code> parameter in both <code>pacf_plot</code> and <code>acf_plot</code> functions. The default value for <code>alpha</code> in <code>statsmodels</code> is <code>0.05</code> (at a 95% confidence interval). Being significant could be in either direction; strongly positive the closer to <code>1</code> (above) or strongly negative the closer to <code>-1</code> (below).</p>
<p>The following table shows an example guide for identifying the stationary AR and MA orders from PACF and ACF plots:</p>
<figure>
<img src="../media/file164.jpg" width="1378" height="423"/>
</figure>
<p>Table 10.1: Identifying the AR, MA, and ARMA models using ACF and PACF plots</p>
</section>
<section id="theres-more...-9" class="level3" data-number="11.3.3">
<h3 data-number="11.3.3">There's more...</h3>
<p>In this recipe, you used ACF and PACF plots to try and estimate what order values (lags) to use for the seasonal and non-seasonal ARIMA models.</p>
<p>Let's see how ACF plots can be used to diagnose the model's <strong>residuals</strong>. Inspecting a model’s residuals is an integral part of evaluating a model. The assumption here is quite simple: if the model captured all the necessary information correctly, then the residuals should not include any correlated data points at any lags (no autocorrelation). Hence, you would expect an ACF plot of the residuals to show autocorrelations closer to zero.</p>
<p>Let's build the Seasonal ARIMA model we identified earlier in this recipe as <code>SARIMA(0,1,1)(0,1,1,12)</code>, then use the ACF to diagnose the residuals. If the model captured all the information that's been embedded within the time series, you would expect the residuals to have <em>no autocorrelation</em>:</p>
<div class="C0-SHCodePACKT">
<pre><code>from statsmodels.tsa.statespace.sarimax import SARIMAX
model = SARIMAX(milk, order=(0,1,1),
                seasonal_order=(0,1,1, 12)).fit(disp=False)
plot_acf(model.resid, zero=False, lags=36);</code></pre>
</div>
<p>This should produce the following autocorrelation plot:</p>
<figure>
<img src="../media/file165.png" alt="Figure 10.6: Autocorrelation plot of the SARIMA residuals" width="997" height="450"/><figcaption aria-hidden="true">Figure 10.6: Autocorrelation plot of the SARIMA residuals</figcaption>
</figure>
<p>Overall, the <code>SARIMA(0,1,1)(0,1,1,12)</code> did a good job at capturing the necessary information, and yet there might be some opportunity for improvement. There is one significant lag (at lag=12 above the confidence threshold) indicating the existence of some autocorrelation in the residuals.</p>
<p>You can further tune the model and experiment with other values for the seasonal and non-seasonal orders. In this chapter and later recipes, you will explore a grid search method for selecting the best hyperparameters to find the best model.</p>
<p>If you want to further diagnose your model’s residuals you can do so using the <code>plot_diagnostics</code> method:</p>
<div class="C0-SHCodePACKT">
<pre><code>model.plot_diagnostics(figsize=(12,7), lags=36);</code></pre>
</div>
<p>This should produce the following plots:</p>
<figure>
<img src="../media/file166.png" alt="Figure 10.7: Residual analysis using plot_diagnostics method" width="999" height="626"/><figcaption aria-hidden="true">Figure 10.7: Residual analysis using plot_diagnostics method</figcaption>
</figure>
<p>Note that the diagnostic plots produced are based on the standardized residuals, a common technique that makes comparing residuals between models easier because they are normalized and expressed in terms of standard deviations.</p>
<p>You can replicate the same diagrams by accessing the <code>model.standardized_forecasts_error</code> as shown below:</p>
<div class="C0-SHCodePACKT">
<pre><code>plot_acf(model.standardized_forecasts_error.ravel(), lags=36,
         title='Standardized Residuals ACF Plot');</code></pre>
</div>
<p>and</p>
<div class="C0-SHCodePACKT">
<pre><code>pd.DataFrame(model.standardized_forecasts_error.ravel(),
             index=milk.index).plot(title='Standardized Residuals Plot',
                                    legend=False);</code></pre>
</div>
<p>The two plots produced should resemble the following figures, illustrating the autocorrelation and time series pattern of the standardized residuals:</p>
<figure>
<img src="../media/file167.png" alt="Figure 10.8: ACF plot of the standardized residuals of the SARIMA model" width="1000" height="449"/><figcaption aria-hidden="true">Figure 10.8: ACF plot of the standardized residuals of the SARIMA model</figcaption>
</figure>
<figure>
<img src="../media/file168.png" alt="Figure 10.9: Standardized residuals plot of the SARIMA model" width="980" height="472"/><figcaption aria-hidden="true">Figure 10.9: Standardized residuals plot of the SARIMA model</figcaption>
</figure>
<p>The difference between <em>Figure 10.6</em> and <em>Figure 10.8</em> is due to scale normalization. Standardization can reduce the impact of outliers, as the residuals are scaled down. This is why the autocorrelation at Lag 12, though still visible in both figures, is at the border of the confidence interval in Figure 10.8, as opposed to <em>Figure 10.6</em>. At the same time, standardization can amplify smaller autocorrelations that may not be initially visible in the original ACF plot. Throughout the recipes, you will rely on the <code>plot_diagnostics method for residual diagnosis.</code></p>
</section>
<section id="see-also-44" class="level3" data-number="11.3.4">
<h3 data-number="11.3.4">See also</h3>
<ul>
<li>To learn more about ACF plots, visit the official documentation at <a href="https://www.statsmodels.org/dev/generated/statsmodels.graphics.tsaplots.plot_acf.html.">https://www.statsmodels.org/dev/generated/statsmodels.graphics.tsaplots.plot_acf.html.</a></li>
<li>To learn more about PACF plots, visit the official documentation at <a href="https://www.statsmodels.org/dev/generated/statsmodels.graphics.tsaplots.plot_pacf.html">https://www.statsmodels.org/dev/generated/statsmodels.graphics.tsaplots.plot_pacf.html</a>.</li>
</ul>
<p>With that, you know how to use ACF and PACF plots when building an ARIMA model and its variants – for example, an ARMA or SARIMA model. In the next recipe, you will be introduced to this chapter's first time series forecasting technique.</p>
</section>
</section>
<section id="forecasting-univariate-time-series-data-with-exponential-smoothing" class="level2" data-number="11.4">
<h2 data-number="11.4">Forecasting univariate time series data with exponential smoothing</h2>
<p>In this recipe, you will explore the <strong>exponential smoothing</strong> technique using the <code>statsmodels</code> library, which offers functionality similar to popular implementations from the R <code>forecast</code> package, such as <code>ets()</code> and <code>HoltWinters()</code>. In statsmodels, there are three different implementations (<em>classes</em>) of exponential smoothing, depending on the nature of the data you are working with:</p>
<ul>
<li><strong>SimpleExpSmoothing</strong>: Simple exponential smoothing is used when the time series process lacks seasonality and trend. This is also referred to as single exponential smoothing.</li>
<li><strong>Holt</strong>: Holt's exponential smoothing is an enhancement of the simple exponential smoothing and is used when the time series process contains only trend (but no seasonality). It is referred to as double exponential smoothing.</li>
<li><strong>ExponentialSmoothing</strong>: Holt-Winters' exponential smoothing is an enhancement of Holt's exponential smoothing and is used when the time series process has both seasonality and trend. It is referred to as triple exponential smoothing.</li>
</ul>
<p><strong>You can import the classes as shown:</strong></p>
<div class="C0-SHCodePACKT">
<pre><code>from statsmodels.tsa.api import (ExponentialSmoothing,
                                SimpleExpSmoothing,
                                Holt)</code></pre>
</div>
<p>The <code>statsmodels</code> implementation adheres to the definitions found in <em>Forecasting: principles and practice, by Hyndman, Rob J., and George Athanasopoulos</em>, which you can reference here: <a href="https://otexts.com/fpp3/expsmooth.html">https://otexts.com/fpp3/expsmooth.html</a>.</p>
<section id="how-to-do-it-40" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1">How to do it…</h3>
<p>In this recipe, you will perform exponential smoothing on the two datasets introduced earlier in the chapter (<em>Technical Requirements</em>). Since the <code>Holt</code> class and the <code>SimpleExpSmoothing</code> class are restricted versions of the <code>ExponentialSmoothing</code> class, you will be using the latter for simplicity. Instead of using all three, you can use the <code>ExponentialSmoothing</code> class to run the three different types since <code>ExponentialSmoothing</code> is a more generic implementation. This approach allows you to manage different types of time series—whether they exhibit trend, seasonality, or both—using a single, more versatile implementation. Let's get started:</p>
<ol>
<li>Import the <code>ExponentialSmoothing</code> class:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>from statsmodels.tsa.api import ExponentialSmoothing</code></pre>
</div>
<ol>
<li>You will start with the life expectancy dataset and use the <code>ExponentialSmoothing</code> class.</li>
</ol>
<p>The <code>ExponentialSmoothing</code> takes several parameters (referred to as hyperparameters) and can be broken into two types: those specified when constructing the model and those specified while fitting the model.</p>
<ol>
<li><strong>Model Construction:</strong>
<ul>
<li><code>trend</code>: Choose from ‘<code>multiplicative’ </code>(alias ‘<code>mul</code>’), '<code>additive</code>' (alias '<code>add</code>'), or <code>None</code>.</li>
<li><code>seasonal</code>: Choose from ‘<code>multiplicative’ </code>(alias ‘<code>mul</code>’), '<code>additive</code>' (alias '<code>add</code>'), or <code>None</code>.</li>
<li><code>seasonal_periods</code>: An integer representing the seasonality period; for example, use 12 for monthly data or 4 for quarterly data.</li>
<li><code>damped_trend</code>: A Boolean value (<code>True</code> or <code>False</code>) to specify if the trend should be damped.</li>
<li><code>use_boxcox</code>: A Boolean value (<code>True</code> or <code>False</code>) to determine if a Box-Cox transform should be applied.</li>
</ul></li>
<li><strong>Model Fitting:</strong>
<ul>
<li><p><code>smoothing_level</code>: A float specifying the smoothing factor for the level known as <strong>alpha</strong> (</p>
<figure>
<img style="width:2rem" src="../media/file169.png" width="32" height="44"/>
</figure>
<p>), with valid values between 0 and 1 (</p>
<figure>
<img style="width:10rem" src="../media/file170.png" width="195" height="46"/>
</figure>
<p>).</p></li>
<li><p><code>smoothing_trend</code>: A float specifying the smoothing factor for the trend known as <strong>beta</strong> (</p>
<figure>
<img style="width:2rem" src="../media/file171.png" width="37" height="51"/>
</figure>
<p>), with valid values between 0 and 1 (</p>
<figure>
<img style="width:10rem" src="../media/file172.png" width="199" height="49"/>
</figure>
<p>).</p></li>
<li><p><code>smoothing_seasonal</code>: A float specifying the smoothing factor for the seasonal trend known as <em>gamma</em> (</p>
<figure>
<img style="width:2rem" src="../media/file173.png" width="33" height="49"/>
</figure>
<p>), with valid values between 0 and 1 (</p>
<figure>
<img style="width:10rem" src="../media/file174.png" width="196" height="49"/>
</figure>
<p>).</p></li>
</ul></li>
</ol>
<p>Later, in the <em>How it works…</em> section, you will explore the <strong>Holt-Winters'</strong> formulas for level, trend, and seasonality and how these parameters are applied.</p>
<ol>
<li>Create a list that contains different combinations of values for the <strong>hyperparameters</strong>. This way, in the next step you get to evaluate different combination of hyperparameter values in each run. Essentially, you will train a different model and capture its scores during each iteration. Once every combination has been evaluated, you will use the <code>get_top_models_df </code>function (from the <em>Technical requirements</em> section) to determine the best-performing model and its optimal hyperparameter values through this exhaustive grid search. This process can be a time-consuming process, but fortunately, there is an alternative hybrid technique to shorten the search.</li>
</ol>
You can use the <code>ExponentialSmoothing</code> class to find the optimal values for <code>alpha</code>, <code>beta</code>, and <code>gamma</code> (
<figure>
<img style="width:10rem" src="../media/file175.png" width="125" height="54"/>
</figure>
). This approach eliminates the need to specify these values in your grid (although you still do so if you prefer to control the process). This simplification means that you only need to provide values for the remaining hyperparameters like <code>trend</code> and <code>seasonal</code>. You can initially attempt to identify whether the components are multiplicative or additive by plotting their decomposition using the <code>seasonal_decompose()</code> function. If you're still uncertain, the exhaustive grid search remains a viable alternative.
<p>For the <code>life</code> DataFrame, you only have <em>trend</em>, so you only need to explore different values for the <em>two</em> parameters; that is, <code>trend</code> and <code>damped</code>:</p>
<div class="C1-CodePACKT">
<pre><code>trend = ['add', 'mul']
damped = [True, False]
life_ex_comb = combinator([trend, damped])
life_ex_comb
[('add', True), ('add', False), ('mul', True), ('mul', False)]</code></pre>
</div>
<p>Here, we have two parameters that take two different values, each providing us with a 2x2 or four total combinations to evaluate for.</p>
<ol>
<li>Loop through the combination list and train (fit) a different model at each iteration. Capture the evaluation metrics in a dictionary to compare the results later. Example scores you will capture include RMSE, RMSPE, MAPE, AIC, and BIC, to name a few. Keep in mind that most automated tools and software will use the AIC and BIC scores behind the scenes to determine the best model:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>train = life_train.values.ravel()
y = life_test.values.ravel()
score = {}
for i, (t, dp) in enumerate(life_ex_comb):
    exp = ExponentialSmoothing(train,
                     trend=t,
                     damped_trend=dp,
                     seasonal=None)
    model = exp.fit(use_brute=True, optimized=True)   
    y_hat = model.forecast(len(y))
    score[i] = {'trend':t,
                'damped':dp,
                'AIC':model.aic,
                'BIC':model.bic,
                'AICc':model.aicc,
                'RMSPE': rmspe(y, y_hat),
                'RMSE' : rmse(y, y_hat),
                'MAPE' : mape(y, y_hat),
                'model': model}</code></pre>
</div>
<p>In the previous function, you used <code>life_train</code> for training the different models, and <code>life_test</code> for evaluating the error metrics such as RMSPE, RMSE, and MAPE.</p>
<p>To retrieve the top models using the <code>get_top_models_df</code> function, just pass the scores dictionary. For now, keep the default criteria set to <code>c=AIC</code> to be consistent:</p>
<div class="C1-CodePACKT">
<pre><code>model_eval = get_top_models_df(score, 'AIC', top_n=5)</code></pre>
</div>
<ol>
<li>The <code>get_top_models_df </code>function will return a DataFrame displaying the top models (up to 5 by default), ranked based on the criterion selected, such as the AIC score in this case. The DataFrame not only includes all additional scores but also stores the model instances themselves in a column labeled 'model'.</li>
</ol>
<p>To view the ranking and the various scores, you can execute the following line:</p>
<div class="C1-CodePACKT">
<pre><code>model_eval.iloc[:, 0:-1]</code></pre>
</div>
<p>The preceding code excludes the last column which contains the model instances, thus displaying a DataFrame that includes columns for each of the evaluation metrics such as AIC, BIC, RMSE, etc</p>
<figure>
<img src="../media/file176.png" alt="Figure 10.10: Exponential Smoothing models for the Life Expectancy data ranked based on AIC scores" width="1384" height="352"/><figcaption aria-hidden="true">Figure 10.10: Exponential Smoothing models for the Life Expectancy data ranked based on AIC scores</figcaption>
</figure>
<p>Generally, for model selection based on information criteria such as AIC, BIC, and AICc, lower values are better, indicating a more optimal balance between model fit and complexity. In our case we opted to use AIC. If you inspect the DataFrame in figure 10.10 there are a few observations you can make:</p>
<ul>
<li>If prioritizing information criteria (AIC, BIC, AICc), <strong>Model 1</strong> (trend: additive, damped: False) would be considered the best model as it scores the lowest across all three information criteria. This model likely offers the best trade-off between model complexity and fit.</li>
<li>If prioritizing error metrics (RMSPE, RMSE, MAPE), which measure prediction accuracy, <strong>Model 0</strong> (trend: additive, damped: True) would be considered superior due to its lower prediction errors.</li>
</ul>
<blockquote>
<p>Selecting the "winning" model will depend on your specific goals and the context in which the model will be used. If you need a balance between both approaches, you might consider other factors or further validation to decide between Models 1 and 0.</p>
</blockquote>
<p>We will continue with the AIC as our selection criteria.</p>
<ol>
<li>The models stored in the DataFrame are an instance of the <code>HoltWintersResultsWrapper</code> class. You can access the top model directly from the DataFrame, which allows you to utilize additional methods and attributes associated with the model, such as <code>summary</code>, <code>predict</code>, and <code>forecast</code>. To extract and interact with the winning model in the first row, use the following code:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>top_model = model_eval.iloc[0,-1]</code></pre>
</div>
<p>You can access the <code>summary()</code> method as shown:</p>
<div class="C1-CodePACKT">
<pre><code>top_model.summary()</code></pre>
</div>
<p>The preceding code will produce a summary output that provides a tabular layout detailing the model—for example, the parameter values that were used and the coefficients calculated:</p>
<figure>
<img src="../media/file177.png" alt="Figure 10.11: Exponential Smoothing summary for the life expectancy data" width="1060" height="828"/><figcaption aria-hidden="true">Figure 10.11: Exponential Smoothing summary for the life expectancy data</figcaption>
</figure>
<p>The summary will show key information such as the optimal values for <strong>alpha</strong> (<em>smoothing_level</em>) and <strong>beta</strong> (<em>smoothing_trend</em>) that have been automatically deduced by the fitting process.</p>
<ol>
<li>You can forecast future values using the <code>forecast</code> method and then evaluate the results against the test set (unseen data by the model). The <code>plot_forecast()</code> function, which we introduced earlier in this chapter in the <em>Technical requirements</em> section, will be used to generate and plot the forecast results alongside the test data. To perform this visualization, pass the model object stored in <code>top_model</code> along with both the <code>training</code> and <code>test</code> datasets to <code>plot_forecast()</code>:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>plot_forecast(life_best_model, '2000', life_train, life_test)</code></pre>
</div>
<p>The <code>start</code> argument in the <code>plot_forecast</code> function slices the data from that point forward to make it easier to compare the results. Think of it as zooming in on a specific segment of the timeline. For example, instead of displaying data spanning from 1960 to 2018 (59 months), you request only the segment starting from the year 2000.</p>
<p>This should produce a plot with the x-axis starting from the year 2000. There should be three lines: One line representing the training data, another line for the test data, and a third line depicting the forecast (predicted values):</p>
<figure>
<img src="../media/file178.jpg" alt="Figure 10.12: Plotting the exponential smoothing forecast versus the actual data for the life expectancy dataset" width="1380" height="617"/><figcaption aria-hidden="true">Figure 10.12: Plotting the exponential smoothing forecast versus the actual data for the life expectancy dataset</figcaption>
</figure>
<p>The forecast from the simple exponential smoothing produced a straight line extending the upward trend from the trained data.</p>
<ol>
<li>Replicate the same process as earlier but with the <code>milk</code> DataFrame. Keep in mind that the most significant difference here is the addition of the seasonal parameters. This means you will be adding two additional hyperparameters to evaluate for – that is, <code>seasonal</code> and <code>seasonal_periods</code>.</li>
</ol>
<p>Build a cartesian product for the different options. For <code>seasonal_periods</code>, you can explore three periods – 4, 6, and 12 months. This should give you a total of 24 models that you will need to evaluate for:</p>
<div class="C1-CodePACKT">
<pre><code>trend , damped= ['add', 'mul'], [True, False]
seasonal, periods = ['add' , 'mul'], [4, 6, 12]
milk_exp_comb = combinator([trend, damped, seasonal, periods])</code></pre>
</div>
<p>Loop through the list of combinations to train multiple models and capture their scores:</p>
<div class="C1-CodePACKT">
<pre><code>train = milk_train.values.ravel()
y = milk_test.values.ravel()
milk_model_scores = {}
for i, (t, dp, s, sp) in enumerate(milk_exp_comb):
    exp = ExponentialSmoothing(train,
                        trend=t,
                        damped_trend=dp,
                        seasonal=s,
                        seasonal_periods=sp)
    model = exp.fit(use_brute=True, optimized=True)   
    y_hat = model.forecast(len(y))
    score[i] = {'trend':t,
                'damped':dp,
                'AIC':model.aic,
                'BIC':model.bic,
                'AICc': model.aicc,
                'RMSPE': rmspe(y, y_hat),
                'RMSE' : rmse(y, y_hat),
                'MAPE' : mape(y, y_hat),
                'model': model}</code></pre>
</div>
<ol>
<li>Upon training completion, run the <code>get_top_models_df </code>function to identify the top models based on the AIC score:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>model_eval = get_top_models_df(score, 'AIC', top_n=5)
model_eval.iloc[:, 0:-1]</code></pre>
</div>
<p>This should display the following DataFrame:</p>
<figure>
<img src="../media/file179.png" alt="Figure 10.13: Top 5 Exponential Smoothing models for the Milk Production data ranked based on AIC scores" width="1352" height="418"/><figcaption aria-hidden="true">Figure 10.13: Top 5 Exponential Smoothing models for the Milk Production data ranked based on AIC scores</figcaption>
</figure>
<p>To determine the winning model from the results, you typically look at various metrics like AIC, BIC, AICc (which are information criteria), and error metrics such as RMSPE, RMSE, and MAPE. Lower values in AIC, BIC, and AICc indicate a model with a better balance between goodness of fit and complexity. Lower values in RMSPE, RMSE, and MAPE indicate better predictive accuracy.</p>
<p>If you inspect the DataFrame in Figure 10.13 there are a few observations you can make:</p>
<p>If prioritizing information criteria (AIC, BIC, AICc), <strong>Model 8</strong> (trend: additive, damped: False) appears to be the best model as it has the lowest values across all information criteria. This suggests that it provides a favorable balance between fitting the data well and maintaining simplicity.</p>
<p>If prioritizing error metrics (RMSPE, RMSE, MAPE), <strong>Model 2</strong> (trend: additive, damped: True) is superior in terms of prediction accuracy. This model has the lowest error rates, indicating it predicts future values most accurately among the models listed.</p>
<blockquote>
<p>Selecting the "winning" model will depend on your specific goals and the context in which the model will be used. If you need a balance between both approaches, you might consider other factors or further validation to decide between Models 8 and 2.</p>
</blockquote>
<p>We will continue with the AIC as our selection criteria.</p>
<p>You can display the best model's summary with the following:</p>
<div class="C1-CodePACKT">
<pre><code>top_model = model_eval.iloc[0,-1]
top_model.summary()</code></pre>
</div>
<p>This should produce a tabular layout summarizing the best model – for example, the parameter values that were used to build the model and the calculated coefficients:</p>
<figure>
<img src="../media/file180.png" alt="Figure 10.14: Exponential Smoothing summary for the Monthly Milk Production data" width="1062" height="762"/><figcaption aria-hidden="true">Figure 10.14: Exponential Smoothing summary for the Monthly Milk Production data</figcaption>
</figure>
<p>Notice the optimal combination of hyperparameter values for <code>Trend</code>, <code>Seasonal</code>, and <em></em> <code>Seasonal Periods</code>. The optimal <code>Seasonal Periods</code> was at 12 months or lags. The summary results table will show the coefficients for all those lags, and it will be a long list. The preceding screenshot only shows the top section.</p>
<p>Additionally, the summary will show key information such as the optimal values for alpha (<em>smoothing_level</em>), beta (<em>smoothing_trend</em>), and gamma (<em>smoothing_seasonal</em>).</p>
<p>Recall that the best model is selected based on the AIC score. Therefore, you should explore different metrics that have been captured, for example, using <code>get_top_models_df(score, 'MAPE', top_n=5)</code>.</p>
<ol>
<li>Compare your forecast using the best model against the test data:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>plot_forecast(top_model, '1969', milk_train, milk_test);</code></pre>
</div>
<p>This should result in a plot starting from the year 1969, featuring three lines representing the training data, test data, and the forecast (predicted values):</p>
<figure>
<img src="../media/file181.png" alt="Figure 10.15: Plotting the exponential smoothing forecast versus the actual Monthly Milk Production data" width="1968" height="904"/><figcaption aria-hidden="true">Figure 10.15: Plotting the exponential smoothing forecast versus the actual Monthly Milk Production data</figcaption>
</figure>
<p>Overall, the model effectively captured both the trend and seasonality, closely aligning with the actual values from the test set.</p>
</section>
<section id="how-it-works-39" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2">How it works…</h3>
<p>There are various techniques for smoothing time series data, including the simple moving average, simple exponential smoothing, Holt's exponential smoothing, and Holt-Winter's exponential smoothing.</p>
<p>The moving average model treats past values equally, while exponential smoothing models place greater emphasis (weight) on more recent observations. In exponential smoothing, the influence of older observations decreases (weight decay) exponentially, hence the term "exponential". This approach is based on the logical assumption that more recent events are likely to be more significant than older ones. For instance, in a daily time series, occurrences from yesterday or the day before are generally more relevant than those from two months ago.</p>
<p>The formula for simple exponential smoothing (single), ideal for time series processes without trend or seasonality, is as follows:</p>
<figure>
<img style="width:10rem" src="../media/file182.jpg" width="181" height="53"/>
</figure>
Here, the <code>ExponentialSmoothing</code> class aims to find the optimal value for the smoothing parameter <strong>alpha</strong> (
<figure>
<img style="width:2rem" src="../media/file183.png" width="33" height="41"/>
</figure>
). In this formula,
<figure>
<img style="width:2rem" src="../media/file184.png" width="40" height="50"/>
</figure>
represents the expected (smoothed) level at the current time
<figure>
<img style="width:2rem" src="../media/file185.png" width="24" height="40"/>
</figure>
,
<figure>
<img style="width:5rem" src="../media/file186.png" width="81" height="50"/>
</figure>
is the previous smoothed level value at time
<figure>
<img style="width:5rem" src="../media/file187.png" width="93" height="46"/>
</figure>
, and
<figure>
<img style="width:2rem" src="../media/file188.png" width="47" height="48"/>
</figure>
is the observed value at the current time
<figure>
<img style="width:2rem" src="../media/file189.png" width="22" height="42"/>
</figure>
.
The alpha (
<figure>
<img style="width:2rem" src="../media/file190.png" width="33" height="46"/>
</figure>
) parameter is critical, serving as the level smoothing parameter and plays a role in determining whether the model should trust the past (
<figure>
<img style="width:5rem" src="../media/file191.png" width="82" height="50"/>
</figure>
) versus the present (
<figure>
<img style="width:2rem" src="../media/file192.png" width="45" height="43"/>
</figure>
). Hence, as
<figure>
<img style="width:2rem" src="../media/file193.png" width="36" height="40"/>
</figure>
gets closer to zero, the first term,
<figure>
<img style="width:4rem" src="../media/file194.png" width="71" height="46"/>
</figure>
, gets closer to zero, and more weight is put on the past. And as
<figure>
<img style="width:2rem" src="../media/file195.png" width="35" height="37"/>
</figure>
gets closer to one, then the
<figure>
<img style="width:10rem" src="../media/file196.png" width="219" height="54"/>
</figure>
term gets closer to zero and more emphasis or weight is put on the present.
Several factors influence the choice of
<figure>
<img style="width:2rem" src="../media/file197.png" width="34" height="45"/>
</figure>
, including the degree of randomness in the system. The output value for the coefficient
<figure>
<img style="width:2rem" src="../media/file197.png" width="34" height="45"/>
</figure>
determines how the model weighs current and past observations to forecast future events
<figure>
<img style="width:5rem" src="../media/file198.png" width="86" height="50"/>
</figure>
.
<p>This explanation aligns with the theme present throughout similar formulae; while we won't delve into every detail, the overarching concept remains consistent.</p>
The formula for Holt's exponential smoothing (double) incorporates the addition of the trend (
<figure>
<img style="width:2rem" src="../media/file199.png" width="37" height="45"/>
</figure>
) and its smoothing parameter, beta (
<figure>
<img style="width:2rem" src="../media/file200.png" width="29" height="53"/>
</figure>
). Hence, once a trend is included, the model will output the values for both coefficients – that is, <strong>alpha</strong> and <strong>beta</strong> (
<figure>
<img style="width:4rem" src="../media/file201.png" width="73" height="51"/>
</figure>
):
<figure>
<img style="width:20rem" src="../media/img_chapter10_image53.jpg" width="607" height="53"/>
</figure>
The Holt-Winters exponential smoothing (triple) formula incorporates both trend (
<figure>
<img style="width:2rem" src="../media/img_chapter10_image56.png" width="33" height="42"/>
</figure>
) and seasonality (
<figure>
<img style="width:2rem" src="../media/file202.png" width="35" height="44"/>
</figure>
). The following equation shows <strong>multiplicative</strong> seasonality as an example:
<figure>
<img style="width:15rem" src="../media/img_chapter10_image58.jpg" width="633" height="104"/>
</figure>
When using <code>ExponentialSmoothing</code> to find the best
<figure>
<img style="width:5rem" src="../media/file203.png" width="111" height="50"/>
</figure>
parameter values, it does so by minimizing the error rate (the <strong>Sum of Squared Error</strong> or <strong>SSE</strong>). So, every time in the loop you were passing new parameters values (for example, damped as either <code>True</code> or <code>False</code>), the model was solving for the optimal set of values for the
<figure>
<img style="width:5rem" src="../media/file203.png" width="111" height="50"/>
</figure>
coefficients by minimizing for SSE. This can be written as follows:
<figure>
<img style="width:10rem" src="../media/img_chapter10_image64.jpg" width="246" height="53"/>
</figure>
<p>In some textbooks, you will see different letters used for level, trend, and seasonality, but the overall structure of the formulas holds.</p>
<p>Generally, exponential smoothing is a fast and effective technique for smoothing a time series for improved analysis, dealing with outliers, data imputation, and forecasting (prediction).</p>
</section>
<section id="theres-more-35" class="level3" data-number="11.4.3">
<h3 data-number="11.4.3">There's more…</h3>
<p>An exciting library known as <strong>Darts</strong> offers a <code>ExponentialSmoothing</code> class that is a wrapper on top of statsmodels's <code>ExponentialSmoothing</code> class.</p>
<p>To install Darts using <code>pip</code>, run the following command:</p>
<div class="C0-SHConPACKT">
<pre><code>pip install darts</code></pre>
</div>
<p>To install using <code>conda</code>, run the following command:</p>
<div class="C0-SHConPACKT">
<pre><code>conda install -c conda-forge -c pytorch u8darts-all</code></pre>
</div>
<p>Load the <code>ExponentialSmoothing</code> and <code>TimeSeries</code> classes:</p>
<div class="C0-SHCodePACKT">
<pre><code>from darts.models import ExponentialSmoothing
from darts import TimeSeries</code></pre>
</div>
<p><strong>Darts</strong> expects the data to be an instance of the <code>TimeSeries</code> class, so you need to convert your pandas DataFrame before using it to train the model. The <code>TimeSeries</code> class provides the <code>from_dataframe</code> method, which you will be using:</p>
<div class="C0-SHCodePACKT">
<pre><code>model = ExponentialSmoothing(seasonal_periods=12)
ts = TimeSeries.from_dataframe(milk.reset_index(),
                                    time_col='month', value_cols='production', freq='MS')</code></pre>
</div>
<p>When creating the <code>TimeSeries</code> object, you must specify which column name is the date and which column contains the observations (values). You can train the model using the <code>.fit()</code> method. Once trained, you can forecast using the <code>.predict()</code> method. To plot the results, you can use the <code>.plot()</code> method:</p>
<div class="C0-SHCodePACKT">
<pre><code>train, test = split_data(ts, 0.15)
model.fit(train)
forecast = model.predict(len(test), num_samples=100)
train.plot()
forecast.plot(label='forecast', low_quantile=0.05, high_quantile=0.95)</code></pre>
</div>
<figure>
<img src="../media/file204.png" alt="Figure 10.16: ExponentialSmoothing forecast for the Monthly Milk Production data using Darts" width="2256" height="1048"/><figcaption aria-hidden="true">Figure 10.16: ExponentialSmoothing forecast for the Monthly Milk Production data using Darts</figcaption>
</figure>
<p>The <code>darts</code> library automated the evaluation process to find the optimal configuration (hyperparameters). Darts' <code>ExponentialSmoothing</code> class is a wrapper to statsmodels's <code>ExponentialSmoothing</code> class, which means you have access to familiar methods and attributes, such as the <code>summary()</code> method:</p>
<div class="C0-SHCodePACKT">
<pre><code>model.model.summary()</code></pre>
</div>
<p>This should produce the familiar statsmodels tabular summary of the model and the optimized parameter values. As a challenge, compare the summary using Dart with the results shown in <em>Figure 10.14</em>. Though you will notice you achieved similar results, it was with less effort using Darts. It automatically picked the best hyperparameters as those established in Figure 10.14.</p>
<p>The Darts library features another useful class called <strong>StatsForecastAutoETS</strong>, which draws its functionality from the AutoETS implementation in the StatsForecast library. Compared to the traditional <strong>ExponentialSmoothing</strong> class, AutoETS is often lauded for its faster performance.</p>
<p>To explore the capabilities of <strong>StatsForecastAutoETS</strong>, consider the following code snippet:</p>
<div class="C0-SHCodePACKT">
<pre><code>from darts.models import StatsForecastAutoETS
modelets = StatsForecastAutoETS(season_length=12)
modelets.fit(train)
etsforecast = modelets.predict(len(test))
train.plot()
etsforecast.plot(label='AutoETS');</code></pre>
</div>
<figure>
<img src="../media/file204.png" alt="Figure 10.17: AutoETS forecast for the Monthly Milk Production data using Darts" width="2256" height="1048"/><figcaption aria-hidden="true">Figure 10.17: AutoETS forecast for the Monthly Milk Production data using Darts</figcaption>
</figure>
<p>You can compare the two forecasts, ExponentialSmoothing and StatsForecastAutoETS, using the following code:</p>
<div class="C0-SHCodePACKT">
<pre><code>forecast.plot(label='ExponentialSmoothing')
etsforecast.plot(label='StatsForecastAutoETS');</code></pre>
</div>
<figure>
<img src="../media/file206.png" alt="Figure 10.18: Comparing AutoETS and ExponentialSmothing" width="2590" height="732"/><figcaption aria-hidden="true">Figure 10.18: Comparing AutoETS and ExponentialSmothing</figcaption>
</figure>
<p>The top line represents the <code>ExponentialSmoothing</code> forecast, while the bottom line represents the <code>StatsForecastAutoETS</code> forecast.</p>
<blockquote>
<p><strong>Exponential Smoothing versus ETS</strong></p>
<blockquote>
<p>ETS and Exponential Smoothing are very closely related, as they both use smoothing of past data points for forecasting time series data. However, they differ in their approach. Exponential Smoothing estimates the parameters by minimizing the Sum of Squared Errors, while ETS maximizes the likelihood. Additionally, Exponential Smoothing provides point forecasts (predictions). ETS also provides the same point forecasts but with added prediction intervals</p>
</blockquote>
</blockquote>
</section>
<section id="see-also-45" class="level3" data-number="11.4.4">
<h3 data-number="11.4.4">See also</h3>
<p>To learn more about the <code>ExponentialSmoothing</code> class, you can visit statsmodels's official documentation at <a href="https://www.statsmodels.org/dev/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html">https://www.statsmodels.org/dev/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html</a>.</p>
<blockquote>
<p>Did you notice that you did not have to test for stationarity with exponential smoothing? Exponential smoothing is only appropriate for non-stationary time series (for example, a time series with trend or seasonality).</p>
</blockquote>
<p>In the next section, while building an ARIMA model, you will be testing for stationarity to determine the differencing factor and leverage the ACF and PACF plots that were discussed earlier in this chapter.</p>
</section>
</section>
<section id="forecasting-univariate-time-series-data-with-arima" class="level2" data-number="11.5">
<h2 data-number="11.5">Forecasting univariate time series data with ARIMA</h2>
<p>In this recipe, you will explore ARIMA, using the <strong>statsmodels</strong> package for implementation. ARIMA stands for Autoregressive Integrated Moving Average, which combines three principal components: the <strong>autoregressive</strong> or <code>AR(p)</code> model, the <strong>moving average</strong> or <code>MA(q)</code> model, and an <strong>integrated</strong> process or <code>I(d) </code>which applies differencing to the data.</p>
<p>An ARIMA model is characterized by the <code>p</code>, <code>d</code>, and <code>q</code> parameters, an ARIMA model for a non-seasonal time series is described by the notation <code>ARIMA(p, d, q)</code>. The <code>p</code> and <code>q</code> parameters denote the <strong>orders or lags</strong>; for example, an AR of order <code>p</code> and MA of order <code>q</code>. They are called lags as they represent the number of “past” periods we need to consider. You may also come across another reference for <code>p</code> and <code>q</code>, namely <strong>polynomial degrees</strong>.</p>
<p>ARIMA models can handle non-stationary time series data through differencing, a time series transformation technique, to make a non-stationary time series stationary. The integration or order of differencing, <code>d</code>, is one of the parameters that you will need to pick a value for when building the model. For a refresher on stationarity, please refer to the <em>Detecting time series stationarity recipe in Chapter 9, Exploratory Data Analysis and Diagnosis</em>.</p>
<p>While ARIMA models are designed to handle trends by utilizing the integrated factor '<em>d</em>', they traditionally assume the absence of seasonality within the dataset. However, should seasonality be a factor, the Seasonal ARIMA, or SARIMA, model is the appropriate alternative, as it extends ARIMA to include seasonal differencing.</p>
<section id="getting-ready-33" class="level3" data-number="11.5.1">
<h3 data-number="11.5.1">Getting ready</h3>
<p>Start by loading this recipe's necessary classes and functions from the <code>statsmodels</code> library:</p>
<div class="C0-SHCodePACKT">
<pre><code>from statsmodels.tsa.arima.model import ARIMA
from statsmodels.stats.diagnostic import acorr_ljungbox</code></pre>
</div>
</section>
<section id="how-to-do-it-41" class="level3" data-number="11.5.2">
<h3 data-number="11.5.2">How to do it…</h3>
<p>Different time series models are suited to various kinds of data. Therefore, it is crucial to choose a model that aligns with the characteristics of your dataset and the specific problem you're addressing. In this recipe, you will use the <code>life</code> DataFrame, which exhibits a trend but no seasonality.</p>
<p>You will combine visual inspection (using the ACF and PACF plots) and statistical tests to make an informed decision for the AR and MA components of the model - known as the <code>p</code> and <code>q</code> orders. These methods were covered in <em>Chapter 9</em>, <em>Exploratory Data Analysis and Diagnosis</em>, in the <em>Testing data for autocorrelation</em>, <em>Decomposing time series data</em>, and <em>Detecting time series stationarity</em> recipes. Let's get started:</p>
<ol>
<li>Begin by <strong>decomposing</strong> the dataset to separate it into its three principal components: trend, seasonality, and residual (often considered as noise). You can achieve this using the <code>seasonal_decompose</code> function</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>decomposed = seasonal_decompose(life)
decomposed.plot();</code></pre>
</div>
<p>You can see the plot as follows:</p>
<figure>
<img src="../media/file205.png" alt="Figure 10.19: Decomposition of life expectancy data" width="2266" height="1050"/><figcaption aria-hidden="true">Figure 10.19: Decomposition of life expectancy data</figcaption>
</figure>
<p>Observe that the decomposition shows a positive (upward) trend within the dataset. This indicates a consistent increase over time. However, there is no observable seasonality effect, which aligns with our expectations for the <strong>life</strong> dataset.</p>
<ol>
<li>You will need to detrend the data first. Perform a first-order differencing and then test for stationarity by using the <code>check_stationarity</code> function you created earlier in this chapter:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>check_stationarity(life)
&gt;&gt;
Non-Stationary   p-value:0.6420882853800064      lags:2
life_df1 = life.diff().dropna()
check_stationarity(life_df1)
&gt;&gt;
Stationary     p-value:1.5562189676003248e-14      lags:1</code></pre>
</div>
<p>Now, the data is <em>stationary</em>. The p-value is significant, and you can reject the null hypothesis. Note that the default <code>periods</code> value for <code>diff()</code> is <code>1</code>. Generally, <code>diff(periods=n)</code> is the difference between the current observation at period <code>t </code>and its lagged version at period <code>t-n</code>. In the case of <code>diff(1)</code> or <code>diff()</code>, the lagged version is <code>t-1</code> (for example, the prior month's observation).</p>
<p>You can plot the differenced time series data using the <code>plot</code> method:</p>
<div class="C1-CodePACKT">
<pre><code>life_df1.plot();</code></pre>
</div>
<p>This should produce the following plot:</p>
<figure>
<img src="../media/file207.png" alt="Figure 10.20: First-order differencing for life expectancy data (detrending)" width="2270" height="1040"/><figcaption aria-hidden="true">Figure 10.20: First-order differencing for life expectancy data (detrending)</figcaption>
</figure>
<p>Next, you will need to determine the <code>p</code> and <code>q </code>orders for the ARIMA (p, d, q) model.</p>
<ol>
<li>The ACF and PACF plots will help you estimate the appropriate <code>p</code> and <code>q</code> values for the AR and MA models, respectively. Use <code>plot_acf</code> and <code>plot_pacf</code> on the stationary <code>life_df1</code> data:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>fig, ax = plt.subplots(1,2)
plot_acf(life_df1, ax=ax[0])
plot_pacf(life_df1, ax=ax[1]);</code></pre>
</div>
<p>It produces the following plots:</p>
<figure>
<img src="../media/file208.png" width="2274" height="1038"/><figcaption aria-hidden="true">Figure 10.21: ACF and PACF plot for life expectancy data after differencing</figcaption>
</figure>
<p>In the preceding example, the zero lag is included in the plot to help you visually compare it against past lags. The ACF and PACF at lag(0) are always one; they are sometimes omitted from plots because they does not provide any meaningful information. Therefore, it’s more important to focus on lag(1) and subsequent lags to determine their significance.</p>
<p>The ACF plot helps identify significant lags for the MA(q) component. The ACF plot shows a cut-off after lag 1, indicating an MA(1) model. Conversely, the PACF plot helps determine the significant lags for the AR(p) component. You can observe a gradual decay with oscillation after lag 1, indicating an MA model at lag 1 or MA(1). This indicates a lack of an AR process, so the <code>p</code> order is zero or AR(0). Please refer to <em>Table 10.1</em> for more details.</p>
<p>An MA(1) process is also called a first-order moving average process, and implies that the current value (at time <code>t</code>) is influenced by the value immediately preceding it (at time <code>t-1</code>).</p>
<p>Now, you can construct an ARIMA(p, d, q) model using p=0, q=1, and d=1 specifications , resulting in an <code>ARIMA(0,1,1)</code>. Often, the optimal lag values (orders) for p and q are not immediately apparent, so you will need to experiment by evaluating multiple ARIMA models using different p, d, and q parameters. This can be archived through approaches like grid-search, similar to the method described and used in the <em>Forecasting univariate time series data with Exponential Smoothing</em> recipe.</p>
<ol>
<li>Train the ARIMA model on the training set, <code>life_train</code>, and inspect the model's summary. It is important not to use the previously differenced <code>life_df1</code> for this, since ARIMA internally applies differencing based on the value of the <code>d</code> parameter. In this example, since first-order differencing (d=1) was satisfactory to detrend and make the data stationary, and you will set <code>d=1 </code>in the model initialization:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>model = ARIMA(life_train, order=(0,1,1))
results = model.fit()
results.summary()</code></pre>
</div>
<p>You will see the summary as follows:</p>
<figure>
<img src="../media/img_chapter10_image71.jpg" alt="Figure 10.22: Summary of ARIMA(0,1,1) for the life expectancy data" width="818" height="842"/><figcaption aria-hidden="true">Figure 10.22: Summary of ARIMA(0,1,1) for the life expectancy data</figcaption>
</figure>
<p>Notice that the AIC and BIC scores are provided in the model summary. While these scores are useful, they are most meaningful when used to compare multiple models, as they help in assessing model fit while penalizing excessive complexity.</p>
<p>In this example, the ARIMA model is primarily an MA process with an integration (differencing) factor of <code>d=1</code>, the summary results provide the coefficient values for the MA(1) component only. More on that in the <em>How it works…</em> section.</p>
<ol>
<li>You will need to validate the model's residuals to determine if the ARIMA(0, 1, 1) model adequately captured the information in the time series. You would assume the residuals from the model's prediction are random (noise) and do not follow a pattern. More specifically, you would expect no autocorrelation in the residuals. You can start with the <code>acorr_ljungbox</code> test followed by the autocorrelation (ACF) plot on the residuals. Ideally, if the model was good you would expect no autocorrelation:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>(acorr_ljungbox(results.resid,
                lags=25,
                return_df=True) &lt; 0.05)['lb_pvalue'].sum()
&gt;&gt; 0</code></pre>
</div>
<p>The result shows <code>0</code>, which is an aggregate of the results for the first 25 lags, indicating no autocorrelation.</p>
<p>Try the ACF plot as well:</p>
<div class="C1-CodePACKT">
<pre><code>plot_acf(results.resid, zero=False);</code></pre>
</div>
<p>This should produce an ACF plot. Here you would expect the plot to show no significant lags. In other words, all the vertical lines should be closer to zero or at zero for all lags:</p>
<figure>
<img src="../media/file209.png" alt="Figure 10.23: ACF plot showing no autocorrelation for the residuals" width="2298" height="1086"/><figcaption aria-hidden="true">Figure 10.23: ACF plot showing no autocorrelation for the residuals</figcaption>
</figure>
<p>This plot confirms no signs of autocorrelation (visually).</p>
<ol>
<li>You can also inspect the distribution of the residuals. For example, you would expect normally distributed residuals with a mean of zero. You can use the QQPlot and <strong>Kernel Density Estimation</strong> (<strong>KDE</strong>) plot to observe the distribution and assess normality. You can accomplish this with the <code>plot_diagnostics</code> method:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>results.plot_diagnostics();plt.show()</code></pre>
</div>
<p>The preceding code will produce following plots:</p>
<figure>
<img src="../media/file210.png" alt="Figure 10.24: Visual diagnostics for the ARIMA(0,1,1) model" width="2250" height="1042"/><figcaption aria-hidden="true">Figure 10.24: Visual diagnostics for the ARIMA(0,1,1) model</figcaption>
</figure>
<p>The plots show a slight deviation from a normal distribution. For example, a perfect normally distributed dataset will have a perfect bell-curved KDE plot and all the points will be perfectly aligned on the line in the QQPlot.</p>
<p>So far, the results and diagnostics indicate a decent model, though there might be room for improvements. Remember, building an ARIMA model is often an iterative process involving multiple rounds of testing and adjustments to achieve the best results.</p>
<ol>
<li>The final step in the ARIMA modeling process is to forecast future values and compare these predictions with your test dataset, which represents unseen or out-of-sample data. Use the <code>plot_forecast()</code> function, which you created earlier in this chapter in the <em>Technical requirements</em> section:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>plot_forecast(results, '1998', life_train, life_test)</code></pre>
</div>
<p>Executing this function will generate a plot where the x-axis starts from the year 1998. The plot will display three lines: the actual data is split into two lines, one for the training data (<code>orig_train</code>) and another for the test data (<code>orig_test</code>), and a third line for the <code>forecast</code> (predicted values).</p>
<p>This visual representation helps in assessing how well the ARIMA model has captured the underlying patterns of the dataset and how accurately it forecasts future values.</p>
<figure>
<img src="../media/Picture9.jpg" alt="Figure 10.25: ARIMA(0,1,1) forecast versus the actual life expectancy data" width="903" height="418"/><figcaption aria-hidden="true">Figure 10.25: ARIMA(0,1,1) forecast versus the actual life expectancy data</figcaption>
</figure>
<p>The dashed line (forecast) doesn't seem to align with the expected trend, unlike the results from the exponential smoothing model shown in Figure 10.6, which demonstrated better performance. To address this, you can run multiple ARIMA models with varying (p, d, q) values and compare their RMSE, MAPE, AIC, or BIC scores to pick the best-fitted model. You will explore this option in the <em>There's more...</em> section.</p>
</section>
<section id="how-it-works-40" class="level3" data-number="11.5.3">
<h3 data-number="11.5.3">How it works…</h3>
<p>An autoregressive model or AR(p) is a linear model that uses observations from previous time steps as inputs into a regression equation to determine the predicted value of the next step. Hence, the <em>auto</em> part in autoregression indicates <em>self</em> and can be described as the regression of a variable on a past version of itself. A typical linear regression model will have this equation:</p>
<figure>
<img style="width:30rem" src="../media/Picture1.jpg" width="1560" height="112"/>
</figure>
Here,
<figure>
<img style="width:2rem" src="../media/Picture2.png" width="32" height="45"/>
</figure>
is the predicted variable,
<figure>
<img style="width:2rem" src="../media/file211.png" width="43" height="47"/>
</figure>
is the intercept,
<figure>
<img style="width:10rem" src="../media/file212.png" width="263" height="54"/>
</figure>
are the features or independent variables, and
<figure>
<img style="width:10rem" src="../media/file213.png" width="257" height="51"/>
</figure>
are the <strong>coefficients</strong> for each of the independent variables. In regression, your goal is to solve for these coefficients, including the intercept (think of them as weights), since they are later used to make predictions. The error term,
<figure>
<img style="width:2rem" src="../media/file214.png" width="29" height="43"/>
</figure>
, denotes the residual or noise (the unexplained portion of the model).
<p>Compare that with the autoregressive equation and you will see the similarities:</p>
<figure>
<img style="width:3-rem" src="../media/Picture3.jpg" width="1651" height="103"/>
</figure>
This is an AR model of order <code>p</code> written as <code>AR(p)</code>. The main difference between an autoregressive and regression model is that the predicted variable is
<figure>
<img style="width:2rem" src="../media/Picture4.jpg" width="49" height="51"/>
</figure>
, which is
<figure>
<img style="width:2rem" src="../media/file215.png" width="34" height="49"/>
</figure>
at the current time,
<figure>
<img style="width:2rem" src="../media/file216.png" width="28" height="45"/>
</figure>
, and that the
<figure>
<img style="width:10rem" src="../media/file217.png" width="363" height="52"/>
</figure>
variables are lagged (previous) versions of
<figure>
<img style="width:2rem" src="../media/file215.png" width="34" height="49"/>
</figure>
. In this recipe, you used an ARIMA(0,1,1), which translates into an AR(0), indicating no autoregressive model being used.
<p>Unlike an autoregressive model that uses past values, the moving average or MA(q) uses past errors (from past estimates) to make a prediction:</p>
<figure>
<img style="width:30rem" src="../media/Picture5.jpg" width="1763" height="103"/>
</figure>
<p>Combining the AR(p) and MA(q) models would produce an ARMA(p,q) model (autoregressive moving average). Both the AR and ARMA processes assume a stationary time series. However, suppose the time series is not stationary due to the presence of a trend. In that case, you cannot use the AR or ARMA models on non-stationary data, unless you perform some transformations, such as <strong>differencing</strong>. This was the case with the <code>life</code> data.</p>
Differencing is just subtracting a current value from its previous (lagged) version. For example, a differencing order of one (lag=1) can be written as
<figure>
<img style="width:6rem" src="../media/Picture6.png" width="170" height="41"/>
</figure>
. In pandas, you used the <code>diff</code> method, which is set to <code>periods=1</code> by default.
<p>The ARIMA model improves on the ARMA model by adding an integrated (differencing) factor to make the time series stationary.</p>
<p>You leveraged both ACF plots and PACF plots to estimate the order values for the AR and MA models. The autocorrelation function measures the correlation between a current observation and its lagged version. The purpose of the ACF plot is to determine how reliable past observations are in making predictions.</p>
<p>On the other hand, a <strong>partial autocorrelation function</strong> (<strong>PACF</strong>) is like autocorrelation but with the relationships of intervening observations removed.</p>
<blockquote>
<p>ACF VERSUS PACF THROUGH AN EXAMPLE</p>
<blockquote>
<p>If there is a strong correlation between past observations at lags 1, 2, 3, and 4, this means that the correlation measure at lag 1 is influenced by the correlation with lag 2, lag 2 is influenced by the correlation with lag 3, and so on.</p>
</blockquote>
<blockquote>
<p>The ACF measure at lag 1 will include these influences of prior lags if they are correlated. In contrast, a PACF at lag 1 will remove these influences to measure the pure relationship at lag 1 with the current observation.</p>
</blockquote>
</blockquote>
<p>One of the reasons ARIMA is popular is because it generalizes to other simpler models, as follows:</p>
<ul>
<li>ARIMA(1, 0, 0) is a first-order autoregressive or AR(1) model</li>
<li>ARIMA(1, 1, 0) is a <em>differenced</em> first-order autoregressive model</li>
<li>ARIMA(0, 0, 1) is a first-order moving average or MA(1) model</li>
<li>ARIMA(1, 0, 1) is an ARMA (1,1) model</li>
<li>ARIMA(0, 1, 1) is a simple exponential smoothing model</li>
</ul>
</section>
<section id="theres-more-36" class="level3" data-number="11.5.4">
<h3 data-number="11.5.4">There's more…</h3>
<p>Sometimes, it isn't easy to identify if the time series is an MA or AR process or determine the optimal order (lag) values for <code>p</code> or <code>q</code>. You can look at the following example of a naive grid search approach by trying different combinations for <code>p</code>, <code>d</code>, and <code>q</code> to train other ARIMA models before picking a winning model.</p>
<p>Here, you will leverage the <code>combinator()</code> function that you created in the <em>Technical requirements</em> section. You will train multiple ARIMA models and then use <code>get_top_models_df() </code>to find the best model. As a starter, try a combination of (0,1,2) for each of the three hyperparameters (p, d, and q). You will be testing 3x3x3 or 27 ARIMA models:</p>
<div class="C0-SHCodePACKT">
<pre><code>pv, dv, qv = [list(range(3))]*3
vals = combinator([pv, dv, qv ])
score = {}
for i, (p, d, q) in enumerate(vals):
    m = ARIMA(life_train, order=(p,d,q))
    res = m.fit()
    y = life_train.values.ravel()
    y_hat = res.forecast(steps=len(y))
    score[i] = {'order': (p,d,q),
                'AIC':res.aic,
                'RMSPE': rmspe(y, y_hat),
                'BIC': res.bic,
                'AICc':res.aicc,
                'RMSE' : rmse(y, y_hat),
                'MAPE' : mape(y, y_hat),
                'model': res}
get_top_models_df(score, 'AIC')</code></pre>
</div>
<p>This should produce a DataFrame sorted by AIC. The following table shows the first five models:</p>
<figure>
<img src="../media/Picture7.jpg" alt="Figure 10.26: Results from the 27 ARIMA models sorted by AIC score" width="1205" height="376"/><figcaption aria-hidden="true">Figure 10.26: Results from the 27 ARIMA models sorted by AIC score</figcaption>
</figure>
<p>You can select the top model using the following:</p>
<div class="C0-SHCodePACKT">
<pre><code>best_m = get_top_models_df(score, 'AIC').iloc[0,-1]</code></pre>
</div>
<p>If you run <code>best_m.summary()</code> to view the model's summary, you will notice that it is an <code>ARIMA(0,2, 2)</code>. This further confirms our earlier observation that this is a moving average (MA) process, but we missed the orders.</p>
<p>The <strong>Akaike Information Criterion</strong> (<strong>AIC</strong>) is a metric that aims to find a balance between a model's maximum likelihood and a model's simplicity. Overly complex models can sometimes overfit, meaning they can look like they learned but once they are presented with unseen data, they perform poorly. The AIC score penalizes as the number of parameters increases since they increase complexity:</p>
<figure>
<img style="width:15rem" src="../media/file219.jpg" width="369" height="52"/>
</figure>
<p>Here, <em>2k</em> is considered the penalty term.</p>
<p>The <strong>Bayesian Information Criteria</strong> (<strong>BIC</strong>) is very similar to AIC but has a higher penalty term on the model's complexity. In general, the BIC penalty term is more significant, so it can encourage models with fewer parameters than AIC does. Therefore, if you change the sorting or evaluation criteria from AIC to BIC, you may see different results. Simpler models are preferred more with BIC:</p>
<figure>
<img style="width:15rem" src="../media/file220.jpg" width="450" height="52"/>
</figure>
Here,
<figure>
<img style="width:2rem" src="../media/Picture8.png" width="48" height="48"/>
</figure>
is the maximum likelihood, <em>k</em> is the number of estimated parameters, and <em>n</em> is the number of data points.
<p>To plot a forecast using the best model, you can run the following command:</p>
<div class="C0-SHCodePACKT">
<pre><code>plot_forecast(best_m, '1998', life_train, life_test);</code></pre>
</div>
<p>This should produce the following plot:</p>
<figure>
<img src="../media/file222.png" alt="Figure 10.26: ARIMA(0,2,2) forecast versus the actual life expectancy data" width="2262" height="1034"/><figcaption aria-hidden="true">Figure 10.26: ARIMA(0,2,2) forecast versus the actual life expectancy data</figcaption>
</figure>
<p>Compare the output in <em>Figure 10.25</em> for ARIMA(0, 1, 1) model with <em>Figure 10.26</em> for the ARIMA(0,2,2). How do they compare with the Figure 10.12 using Exponential Smoothing?</p>
<p>Before we proceed to the next recipe, let's apply an ARIMA model to the Milk Production data, which, unlike the life expectancy data, exhibits both trend and seasonality:</p>
<div class="C0-SHCodePACKT">
<pre><code>pv, dv, qv = [list(range(3))]*3
vals = combinator([pv, dv, qv])
score = {}
for i, (p, d, q) in enumerate(vals):
    m = ARIMA(milk_train, order=(p,d,q))
    res = m.fit()
    y = milk_test.values.ravel()
    y_hat = res.forecast(steps=len(y))
    score[i] = {'order': (p,d,q),
                'AIC':res.aic,
                'BIC': res.bic,
                'AICc':res.aicc,
                'RMSPE': rmspe(y, y_hat),
                'RMSE' : rmse(y, y_hat),
                'MAPE' : mape(y, y_hat),
                'model': res}
model = get_top_models_df(score, 'AIC').iloc[0,-1]
plot_forecast(model, '1971', milk_train, milk_test);</code></pre>
</div>
<p>After running the code and inspecting the top model with <strong>model.summary()</strong>, you will find that it identifies an ARIMA(2,2,2). The resulting forecast plot will likely show poor predictions overall, as depicted in Figure 10.27 – forecasting against actual Milk Production data</p>
<figure>
<img src="../media/file223.png" alt="Figure 10.27: ARIMA(2,2,2) forecast versus the actual Milk Production data" width="2270" height="726"/><figcaption aria-hidden="true">Figure 10.27: ARIMA(2,2,2) forecast versus the actual Milk Production data</figcaption>
</figure>
<p>This outcome is expected since standard ARIMA models are not designed to handle seasonality. The next recipe will introduce SARIMA (Seasonal ARIMA), which is better equipped to model time series data with both seasonal patterns and trends.</p>
</section>
<section id="see-also-46" class="level3" data-number="11.5.5">
<h3 data-number="11.5.5">See also</h3>
<p>To learn more about the ARIMA class, you can visit statsmodels's official documentation at <a href="https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html">https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html</a>.</p>
<p>How about the <code>milk</code> data, which has trend and seasonality? The next recipe will explore working with a SARIMA model to handle such data.</p>
<blockquote>
<p>FORECAST VERSUS PREDICT METHODS</p>
<blockquote>
<p>In the <code>plot_forecast</code> function, we used the forecast method. In statsmodels, the SARIMA family of models, such as ARMA and ARIMA, have two methods for making predictions: <code>predict</code> and <code>forecast</code>.</p>
</blockquote>
<blockquote>
<p>The <code>predict</code> method allows you to include both <strong>in-sample</strong> (historical) and <strong>out-of-sample</strong> (future) predictions, hence why the method takes the <code>start</code> and <code>end</code> parameters. On the other hand, the <code>forecast</code> method only takes <strong>steps</strong>, which is the number of <strong>out-of-sample</strong> forecasts, starting from the end of the sample or the training set.</p>
</blockquote>
</blockquote>
</section>
</section>
<section id="forecasting-univariate-time-series-data-with-seasonal-arima" class="level2" data-number="11.6">
<h2 data-number="11.6">Forecasting univariate time series data with Seasonal ARIMA</h2>
<p>In this recipe, you will be introduced to an enhancement to the ARIMA model for handling seasonality, known as the <strong>Seasonal Autoregressive Integrated Moving Average</strong> or <strong>SARIMA</strong>. Like an ARIMA(p, d, q), a SARIMA model also requires (p, d, q) to represent non-seasonal orders. Additionally, a SARIMA model requires the orders for the seasonal component, which is denoted as (P, D, Q, s). Combining both components, the model can be written as a SARIMA(p, d, q)(P, D, Q, s). The letters still mean the same, and the letter case indicates which component. For example, the lowercase letters represent the non-seasonal orders, while the uppercase letters represent the seasonal orders. The new parameter, <code>s</code>, is the number of steps per cycle – for example, <code>s=12</code> for monthly data or <code>s=4</code> for quarterly data.</p>
<p>In statsmodels, you will use the <code>SARIMAX</code> class to build a SARIMA model.</p>
<p>In this recipe, you will be working with the <code>milk</code> data, which contains both trend and seasonality. This was prepared in the <em>Technical requirements</em> section.</p>
<section id="how-to-do-it-42" class="level3" data-number="11.6.1">
<h3 data-number="11.6.1">How to do it…</h3>
<p>Follow these steps:</p>
<ol>
<li>Start by importing the necessary libraries:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>from statsmodels.tsa.statespace.sarimax import SARIMAX</code></pre>
</div>
<ol>
<li>From <em>Figure 10.1</em>, we determined that both seasonality and trend exist. We could also see that the seasonal effect is additive. The periodicity or number of periods in a season is 12 since the data is monthly. This can be confirmed with an ACF plot:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>plot_acf(milk, lags=40, zero=False);</code></pre>
</div>
<p>This should produce an ACF plot for the <code>milk</code> data with a noticeable cyclical pattern of spikes at specific lags:</p>
<figure>
<img src="../media/file224.png" alt="Figure 10.28: ACF plot showing significant spikes at lags 1, 12, and 24" width="2274" height="738"/><figcaption aria-hidden="true">Figure 10.28: ACF plot showing significant spikes at lags 1, 12, and 24</figcaption>
</figure>
<p>Notice that there is a repeating pattern every 12 months (lags). If the pattern is not easy to spot, you can try the ACF plot after you difference the data – for example, detrend (first-order differencing) the data first, then plot the ACF plot:</p>
<div class="C1-CodePACKT">
<pre><code>plot_acf(milk.diff(1).dropna(), lags=40, zero=False);</code></pre>
</div>
<p>This should produce an ACF plot on the differenced data that makes the seasonal spikes more apparent:</p>
<figure>
<img src="../media/file225.png" alt="Figure 10.29 – ACF plot after differencing shows significant spikes at lags 1, 12, 24, and 36" width="2270" height="736"/><figcaption aria-hidden="true">Figure 10.29 – ACF plot after differencing shows significant spikes at lags 1, 12, 24, and 36</figcaption>
</figure>
<p>You can also extract the seasonal component and use that for the ACF plot, as shown in the following code:</p>
<div class="C1-CodePACKT">
<pre><code>decomposed = seasonal_decompose(milk, period=12, model='multiplicative')
milk_s = decomposed.seasonal
plot_acf(milk_s, zero=False, lags=40);</code></pre>
</div>
<p>The ACF plot will show the autocorrelation using the seasonal component after decomposition and will tell a similar story to what's shown in <em>Figure 10.28</em> and <em>Figure 10.29</em>.</p>
<figure>
<img src="../media/file226.png" alt="Figure 10.30: ACF on the seasonal component after decomposition shows significant spikes at lags 1, 12, 24, and 36" width="2596" height="1622"/><figcaption aria-hidden="true">Figure 10.30: ACF on the seasonal component after decomposition shows significant spikes at lags 1, 12, 24, and 36</figcaption>
</figure>
<p>Generally, you can assume a 12-month cycle when working with monthly data. For example, for the non-seasonal ARIMA portion, start with <code>d=1</code> for detrending, and for the seasonal ARIMA portion, start with <code>D=1</code> as well, given <code>s=12</code>.</p>
<ol>
<li>Suppose you are not sure about the values for <code>d</code> (non-seasonal differencing) and <code>D</code> (seasonal differencing). In that case, you can use the <code>check_stationarity</code> function after differencing to determine if seasonal differencing was enough or not. In most cases, if the time series has both trend and seasonality, you may need to difference twice. First, you perform seasonal differencing, followed by a first-order differencing for detrending.</li>
</ol>
<p>Start with seasonal differencing by using <code>diff(12)</code> (<em>deseasonalize</em>) and test if that is enough to make the time series stationarity. If not, then you will need to follow it with a first-order differencing, <code>diff()</code>:</p>
<div class="C1-CodePACKT">
<pre><code>milk_dif_12 = milk.diff(12).dropna()
milk_dif_12_1 = milk.diff(12).diff(1).dropna()
sets = [milk, milk_dif_12, milk_dif_12_1]
desc = ['Original', 'Deseasonalize (Difference Once)', 'Differencing Twice']
fig, ax = plt.subplots(2,2, figsize=(20,10))
index, l = milk.index, milk.shape[0]
for i, (d_set, d_desc) in enumerate(zip(sets, desc)):
    v, r = i // 2, i % 2
    outcome, pval = check_stationarity(d_set)
    d_set.plot(ax= ax[v,r], title=f'{d_desc}: {outcome}', legend=False)
    pd.Series(d_set.mean().values.tolist()*l, index=index).plot(ax=ax[v,r])
    ax[v,r].title.set_size(20)
ax[1,1].set_visible(False)
plt.show()</code></pre>
</div>
<p>This should produce 2x2 subplots (two plots per row), where the extra subplot is hidden:</p>
<figure>
<img src="../media/file227.png" alt="Figure 10.31: Stationarity comparison for original, seasonally differenced, and differenced twice time series" width="2274" height="730"/><figcaption aria-hidden="true">Figure 10.31: Stationarity comparison for original, seasonally differenced, and differenced twice time series</figcaption>
</figure>
<ol>
<li>Now, you will need to estimate the AR and MA orders for the non-seasonal (p, q) and seasonal components (P, Q). To do this, you must use the ACF and PACF plots on the stationary data, which can be found in the <code>milk_dif_12_1</code> DataFrame:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>fig, ax = plt.subplots(1,2)
plot_acf(milk_dif_12_1, zero=False, lags=36, ax=ax[0], title=f'ACF - {d_desc}')
plot_pacf(milk_dif_12_1, zero=False, lags=36, ax=ax[1], title=f'PACF - {d_desc}')
plt.show()</code></pre>
</div>
<p>This should produce ACF and PACF plots on the same row:</p>
<figure>
<img src="../media/file228.png" alt="Figure 10.32: ACF and PACF plots for the milk data after becoming stationary" width="2444" height="1682"/><figcaption aria-hidden="true">Figure 10.32: ACF and PACF plots for the milk data after becoming stationary</figcaption>
</figure>
<p>Starting with the ACF plot, there is a significant spike at lag 1, which represents the non-seasonal order for the MA process. The spike at lag 12 represents the seasonal order for the MA process. Notice that there is a cut-off right after lag 1, then a spike at lag 12, followed by another cut-off (no other significant lags afterward). These are indications of a moving average model – more specifically, an order of <code>q=1</code> and <code>Q=1</code>.</p>
<p>The PACF plot confirms this as well; an exponential decay at lags 12, 24, and 36 indicates an MA model. Here, the seasonal ARIMA would be ARIMA(0, 1,1)(0, 1, 1, 12).</p>
<ol>
<li>Build the SARIMA model based on the initial information that was extracted for the AR and MA orders. The following code will fit a SARIMA(0, 1, 1)(0, 1, 1, 12) model on the training dataset. Note that the results may differ from those shown in the <em>Plotting ACF and PACF</em> recipe since the data was not split in that recipe, but it has been split here:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>sarima_model = SARIMAX(milk_train,
                       order=(0,1,1),
                       seasonal_order=(0,1,1,12))
model = sarima_model.fit(disp=0)</code></pre>
</div>
<ol>
<li>Now, use the <code>plot_diagnostics</code> method, which becomes available after fitting the model:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>model.plot_diagnostics(figsize=(15,7));</code></pre>
</div>
<p>This will provide four plots – a standardized residual plot, a QQPlot, an ACF residual plot, and a histogram with kernel density plot:</p>
<figure>
<img src="../media/file229.png" alt="Figure 10.33: SARIMA(0,1,1)(0,1,1,12) diagnostic plots" width="1139" height="360"/><figcaption aria-hidden="true">Figure 10.33: SARIMA(0,1,1)(0,1,1,12) diagnostic plots</figcaption>
</figure>
<p>The residual's ACF plot (correlogram) does not show autocorrelation (ignoring the spike at lag 0 since it is always 1). However, the histogram and QQPlot show that the residuals do not fit a perfectly normal distribution. These are not critical assumptions compared to random residuals (no autocorrelation). Overall, the results look very promising.</p>
<p>You can obtain the summary using the <code>summary</code> method:</p>
<div class="C1-CodePACKT">
<pre><code>model.summary()</code></pre>
</div>
<p>This should print out additional information regarding the model in a tabular format including the coefficients for the seasonal and non-seasonal components. Recall, the diagnostic plots are based on the standardized residuals. You can plot ACF for the residuals without standardization:</p>
<div class="C1-CodePACKT">
<pre><code>plot_acf(model.resid[1:])</code></pre>
</div>
<p>This should produce the following ACF plot which shows a couple of lags beyond the threshold indicating some autocorrelation and potential for more improvements.</p>
<figure>
<img src="../media/file230.png" alt="Figure 10.34: The residual ACF Plot for SARIMA(0,1,1)(0,1,1,12)" width="2256" height="722"/><figcaption aria-hidden="true">Figure 10.34: The residual ACF Plot for SARIMA(0,1,1)(0,1,1,12)</figcaption>
</figure>
<ol>
<li>Use the <code>plot_forecast</code> function to plot the forecast from the SARIMA model and compare it with the test set:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>plot_forecast(model, '1971', milk_train, milk_test);</code></pre>
</div>
<p>This should produce a plot with the x-axis starting from the year 1971:</p>
<figure>
<img src="../media/file231.png" alt="Figure 10.35: Milk production forecast versus actual production using SARIMA(0,1,1)(0,1,1,12)" width="1622" height="406"/><figcaption aria-hidden="true">Figure 10.35: Milk production forecast versus actual production using SARIMA(0,1,1)(0,1,1,12)</figcaption>
</figure>
<p>Overall, the SARIMA model did a decent job of capturing the seasonal and trend effects. You can always iterate and test different values for (p, q) and (P, Q) by evaluating the results using other metrics such as RMSE, MAPE, or AIC, to name a few. More on that in the <em>There’s more…</em> section.</p>
</section>
<section id="how-it-works-41" class="level3" data-number="11.6.2">
<h3 data-number="11.6.2">How it works…</h3>
<p>The SARIMA model extends the ARIMA model by incorporating seasonality, requiring an additional set of seasonal parameters. For instance, a SARIMA model with non-seasonal order (1, 1, 1) and no seasonal components would be specified as SARIMA(1,1,1)(0,0,0,0), which essentially reduces to an ARIMA(1, 1, 1) model. To handle seasonality, you would set the seasonal order to non-zero values</p>
<p>In statsmodels, the <code>SARIMAX</code> class generalizes AR, MA, ARMA, ARIMA, and SARIMA models, allowing you to fit a model tailored to your time series data, whether it has seasonal components or not. Similarly, as discussed in the <em>Forecasting univariate time series data with Exponential Smoothing</em> recipe, the <code>ExponentialSmoothing</code> class serves as a generalized implementation for both <code>SimpleExpSmoothing</code> and <code>Holt</code>’s models.</p>
</section>
<section id="theres-more-37" class="level3" data-number="11.6.3">
<h3 data-number="11.6.3">There's more…</h3>
<p>Similar to the approach in the <em>Forecasting univariate time series data with ARIMA</em> recipe, you can execute a naive grid search to evaluate different combinations of the non-seasonal (p, d, q) and seasonal (P, D, Q, s) parameters to identify the best SARIMA model.</p>
<p>This can be done by leveraging the <code>combinator()</code> function to loop through all possible parameter combinations, fitting a SARIMA model at each iteration. To determine the top N models, you can use the <code>get_top_models_df</code> function.</p>
<p>For instance, let’s consider testing all combinations where the non-seasonal (p, d, q) parameters each takes the values (0,1,2), and the seasonal (P, D, Q) parameters each takes the values (0,1), while keeping <code>s</code>, the seasonal period, at 12. This setup would test a total of (3x3x3x2x2x2) = 216 SARIMA models. Although this brute force (naïve) approach can be computationally intensive, it is still a valid method. Automated time series libraries such as <code>Auto_ARIMA</code> often employ similar exhaustive grid searches to optimize model parameters:</p>
<div class="C0-SHCodePACKT">
<pre><code>P_ns, D_ns, Q_ns = [list(range(3))]*3
P_s, D_s, Q_s = [list(range(2))]*3
vals = combinator([P_ns, D_ns, Q_ns, P_s, D_s, Q_s])
score = {}
for i, (p, d, q, P, D, Q) in enumerate(vals):
    if i%15 == 0:
        print(f'Running model #{i} using SARIMA({p},{d},{q})({P},{D},{Q},12)')
    m = SARIMAX(milk_train,
                order=(p,d,q),
                seasonal_order=(P, D, Q, 12),
                enforce_stationarity=False)
    res = m.fit(disp=0)
    y = milk_test.values.ravel()
    y_hat = res.forecast(steps=len(y))
    score[i] = {'non-seasonal order': (p,d,q),
                'seasonal order': (P, D, Q),
                'AIC':res.aic,
                'AICc': res.aicc,
                'BIC': res.bic,
                'RMSPE': rmspe(y, y_hat),
                'RMSE' : rmse(y, y_hat),
                'MAPE' : mape(y, y_hat),
                'model': res}</code></pre>
</div>
<p>After executing the previous code, it should print a status output every 15 iterations as shown:</p>
<div class="C0-SHCodePACKT">
<pre><code>Running model #0 using SARIMA(0,0,0)(0,0,0,12)
Running model #15 using SARIMA(0,0,1)(1,1,1,12)
Running model #30 using SARIMA(0,1,0)(1,1,0,12)
Running model #45 using SARIMA(0,1,2)(1,0,1,12)
Running model #60 using SARIMA(0,2,1)(1,0,0,12)
Running model #75 using SARIMA(1,0,0)(0,1,1,12)
Running model #90 using SARIMA(1,0,2)(0,1,0,12)
Running model #105 using SARIMA(1,1,1)(0,0,1,12)
Running model #120 using SARIMA(1,2,0)(0,0,0,12)
Running model #135 using SARIMA(1,2,1)(1,1,1,12)
Running model #150 using SARIMA(2,0,0)(1,1,0,12)
Running model #165 using SARIMA(2,0,2)(1,0,1,12)
Running model #180 using SARIMA(2,1,1)(1,0,0,12)
Running model #195 using SARIMA(2,2,0)(0,1,1,12)
Running model #210 using SARIMA(2,2,2)(0,1,0,12)</code></pre>
</div>
<p>Notice the <code>enforce_stationarity=False</code> parameter to avoid a <code>LinAlgError</code> that may occur when running a naive grid search.</p>
<p>To identify the top 5 models sorted by AIC, you can run the <code>get_top_models_df</code> function:</p>
<div class="C0-SHCodePACKT">
<pre><code>get_top_models_df(score, 'AIC')</code></pre>
</div>
<figure>
<img src="../media/file232.png" alt="Figure 10.36: Top 5 SARIMA models ranked by AIC for the Milk Production data" width="1614" height="394"/><figcaption aria-hidden="true">Figure 10.36: Top 5 SARIMA models ranked by AIC for the Milk Production data</figcaption>
</figure>
<p>Notice that the first two models have similar AIC scores. Generally, when two models have similar AIC scores, the simpler model is preferred. For example, a SARIMA(0,2,2)(0,1,1) model is simpler than a SARIMA(2,2,2)(0,1,1) model. There are also other metrics such as AICc and BIC, which in this case, would favor the second model (model_id=67) over the first model (model_id=211). Similarly, if you consider RMSPE or MAPE, you may end up selecting different models.</p>
<blockquote>
<p><strong>Occam's Razor</strong></p>
<blockquote>
<p>Occam's Razor is a principal suggesting that when multiple models produce similar quality, in other words similarly produce good fit to the data, then the simpler model should be preferred. This principal is especially useful when evaluating several models, such as evaluating multiple SARIMA models. If a few models emerge as strong candidates, generally, the simplest model is favored, assuming all are equally likely candidates to begin with.</p>
</blockquote>
</blockquote>
<p>To sort the models based on BIC score, rerun the function:</p>
<div class="C0-SHCodePACKT">
<pre><code>get_top_models_df(score, 'BIC')</code></pre>
</div>
<p>Examine the results displayed in Figure 10.36 below, which shows the top 5 SARIMA models ranked by BIC for the Milk Production data.</p>
<figure>
<img src="../media/file233.png" alt="Figure 10.37: Top 5 SARIMA models ranked by BIC for the Milk Production data" width="1129" height="366"/><figcaption aria-hidden="true">Figure 10.37: Top 5 SARIMA models ranked by BIC for the Milk Production data</figcaption>
</figure>
<p>Comparing the results in Figure 10.36 and Figure 10.35, you will notice the third model in Figure 10.36 (model_id = 35), the SARIMA(0,1,1)(0,1,1) model, which was derived earlier.</p>
<p>Now, let’s select the best model based on the BIC score:</p>
<div class="C0-SHCodePACKT">
<pre><code>best_model = get_top_models_df(score, BIC).iloc[0,-1]</code></pre>
</div>
<p>Finally, you can visualize the model’s forecast alongside the actual data using the <code>plot_forecast</code> function:</p>
<div class="C0-SHCodePACKT">
<pre><code>plot_forecast(best_model, '1962', milk_train, milk_test);</code></pre>
</div>
<p>This should produce a plot with the x-axis starting from the year 1962, as shown in Figure 10.37:</p>
<figure>
<img src="../media/file234.png" alt="Figure 10.38: Milk production forecast versus actual production using SARIMA(0,2,2)(0,1,1,12)" width="1032" height="974"/><figcaption aria-hidden="true">Figure 10.38: Milk production forecast versus actual production using SARIMA(0,2,2)(0,1,1,12)</figcaption>
</figure>
</section>
<section id="see-also-47" class="level3" data-number="11.6.4">
<h3 data-number="11.6.4">See also</h3>
<p>To learn more about the SARIMAX class, you can visit statsmodels's official documentation at <a href="https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html">https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html</a>.</p>
</section>
</section>
<section id="forecasting-univariate-time-series-with-auto_arima" class="level2" data-number="11.7">
<h2 data-number="11.7">Forecasting univariate time series with auto_arima</h2>
<p>For this recipe, you will need to install <strong>pmdarima</strong>, a Python library that includes <code>auto_arima</code> – a tool designed to automate the optimization and fitting of ARIMA models. The <code>auto_arima</code> implementation in Python is inspired by the popular <code>auto.arima</code> from the <code>forecast</code> package in R.</p>
<p>As you've seen in earlier recipes, determining the correct orders for the AR and MA components can be challenging. While techniques like examining ACF and PACF plots are helpful, finding the optimal model often involves training multiple models – a process known as <strong>hypeparameter tuning</strong>, which can be quite labor-intensive. This is where <code>auto_arima</code> shines as it simplifies the effort.</p>
<p>Instead of the naïve, brute force, approach of manually conducting a grid search to try every parameter combination, auto_arima uses a more efficient approach to finding the optimal parameters. The <code>auto_arima</code> function uses a <strong>stepwise</strong> <strong>algorithm</strong> that is faster and more efficient than a full <strong>grid search</strong> or <strong>random search</strong>:</p>
<ul>
<li>By default, with <code>stepwise=True</code>, <code>auto_arima</code> conducts a stepwise search which iteratively refines the model parameters.</li>
<li>If you set <code>stepwise=False</code>, it performs an exhaustive “brute-force” grid search across all parameter combinations.</li>
<li>With <code>random=True</code>, it performs a random search.</li>
</ul>
<p>The <strong>stepwise</strong> <strong>algorithm</strong> was proposed in 2008 by Rob Hyndman and Yeasmin Khandakar in the paper <em>Automatic Time Series Forecasting: The forecast Package for R</em>, which was published in the Journal of Statistical Software 27, no. 3 (2008) (<a href="https://doi.org/10.18637/jss.v027.i03">https://doi.org/10.18637/jss.v027.i03</a>). In a nutshell, <strong>stepwise</strong> is an optimization technique that utilizes grid search more efficiently. This is accomplished using <strong>unit root tests</strong> and minimizing information criteria (for example, <strong>Akaike Information Criterion</strong> (<strong>AIC</strong>) and <strong>Maximum Likelihood Estimation</strong> (<strong>MLE</strong>).</p>
<p>Further, <code>auto_arima</code> can handle both seasonal and non-seasonal ARIMA models. For seasonal models, set <code>seasonal=True</code> to enable optimization of the seasonal parameters (P, D, Q).</p>
<section id="getting-ready-34" class="level3" data-number="11.7.1">
<h3 data-number="11.7.1">Getting ready</h3>
<p>You will need to install <code>pmdarima</code> before you can proceed with this recipe.</p>
<p>To install it using <code>pip</code>, use the following command:</p>
<div class="C0-SHConPACKT">
<pre><code>pip install pmdarima</code></pre>
</div>
<p>To install it using <code>conda</code>, use the following command:</p>
<div class="C0-SHConPACKT">
<pre><code>conda install -c conda-forge pmdarima</code></pre>
</div>
<p>You will use the Milk Production dataset which you prepared in the Technical Requirements section You will be using <code>milk_train</code> for training and <code>milk_test</code> for evaluation<code>.</code> Recall that the data contains both trend and seasonality, so you will be training a <strong>SARIMA</strong> model.</p>
</section>
<section id="how-to-do-it-43" class="level3" data-number="11.7.2">
<h3 data-number="11.7.2">How to do it…</h3>
<p>The <strong>pmdarima</strong> library wraps over the <strong>statsmodels</strong> library, so you will encounter familiar methods and attributes. You will follow a similar process by loading the data, splitting the data into train and test sets, first training the model, and then evaluating the results. These steps were already completed in the <em>Technical Requirements</em> section.</p>
<ol>
<li>Begin by importing the <code>pmdarima</code> library</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>import pmdarima as pm</code></pre>
</div>
<ol>
<li>Utilize the <code>auto_arima</code> function from <code>pmdarima</code> to find the optimal configuration for your SARIMA model. Prior knowledge about the Milk Production dataset is key to obtaining the best results from <code>auto_arima</code>. You know the data exhibits seasonal patterns, so you will need to provide values for the <em>two parameters</em>: <code>seasonal=True</code> and <code>m=12</code>, which represents the number of periods in the season. Failing to set these parameters (<code>seasonal</code> and <code>m</code>) would limit the search to non-seasonal orders (p, d, q) only.</li>
</ol>
<p>The <code>test</code> parameter specifies the type of <strong>unit root test</strong> to use to detect stationarity to determine the differencing order (<code>d</code>). The default test is <code>kpss</code>. You will change the parameter to use <code>adf</code> instead (to be consistent with what you did in earlier recipes). Similarly, <code>seasonal_test</code> is used to determine the order (<code>D</code>) for seasonal differencing. The default <code>seasonal_test</code> is <code>OCSB</code>, which you will keep as-is:</p>
<div class="C1-CodePACKT">
<pre><code>auto_model = pm.auto_arima(milk_train,
                           seasonal=True,
                           m=12,
                           test='adf',
                           stepwise=True)
auto_model.summary()</code></pre>
</div>
<p>The summary provides a detailed configuration of the chosen SARIMA model, including information criteria scores like AIC and BIC:</p>
<figure>
<img src="../media/file235.png" alt="Figure 10.39: Summary of the best SARIMA model selected using auto_arima" width="1138" height="660"/><figcaption aria-hidden="true">Figure 10.39: Summary of the best SARIMA model selected using auto_arima</figcaption>
</figure>
<p>Interestingly, the selected model, SARIMA(0,1,1)(0,1,1,12), algins with the one you derived in the <em>Forecasting univariate time series data with seasonal ARIMA</em> recipe, where you estimated the non-seasonal order (p, q) and seasonal orders (P, Q) using the ACF and PACF plots.</p>
<ol>
<li>To monitor the performance of each model configuration evaluated during the stepwise search, enable the <code>trace=True</code> parameter in the <code>auto.arima</code> function:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>auto_model = pm.auto_arima(milk_train,
                           seasonal=True,
                           m=12,
                           test='adf',
                           stepwise=True,
                           trace=True)</code></pre>
</div>
<p>This setting will print the AIC results for each SARIMA model tested by the step-wise algorithm, as shown in Figure 10.39:</p>
<figure>
<img src="../media/file236.png" alt="Figure 10.40: auto_arima evaluating different SARIMA models based on AIC" width="1162" height="650"/><figcaption aria-hidden="true">Figure 10.40: auto_arima evaluating different SARIMA models based on AIC</figcaption>
</figure>
<p>The best model was selected based on AIC, which is determined by the <code>information_criterion</code> parameter. By default, this is set to <code>aic</code>, but it can be changed to one of the other supported criteria: <code>bic</code>, <code>hqic</code>, or <code>oob</code>.</p>
<p>In <em>Figure 10.39,</em> the two highlighted models have similar AIC scores but drastically different non-seasonal (p, q) orders. The preferred model (marked with number 1) lacks a non-seasonal autoregressive AR(p) component and instead relies on a moving average MA(q) process. Conversely, the second highlighted model (marked with number 2) features only an AR(p) process for the non-seasonal component. This demonstrates, while <code>auto_arima</code> significantly aids in the model selection, careful judgement and analysis are still required to interpret and evaluate results effectively.</p>
<p>To explore how the choice of information criterion affects model selection, change the<code> information_criterion</code> to <code>bic</code> and rerun the code:</p>
<div class="C1-CodePACKT">
<pre><code>auto_model = pm.auto_arima(milk_train,
                           seasonal=True,
                           m=12,
                           test='adf',
                           information_criterion='bic',
                           stepwise=True,
                           trace=True)</code></pre>
</div>
<figure>
<img src="../media/file237.png" alt="Figure 10.41: auto_arima evaluating different SARIMA models based on BIC" width="1047" height="723"/><figcaption aria-hidden="true">Figure 10.41: auto_arima evaluating different SARIMA models based on BIC</figcaption>
</figure>
<p>As illustrated in Figure 10.40, this will produce output from each iteration based on BIC. Notably, the winning remains the same as the one selected based on AIC from Figure 10.39. However, observe how the second model (marked with number 2), which was a close contender in Figure 10.39, is no longer as competitive under the BIC criterion.</p>
<ol>
<li>Evaluate the overall performance of the model using the <code>plot_diagnostics</code> method. This is the same method you used previously from statsmodels.</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>auto_model.plot_diagnostics(figsize=(15,7));</code></pre>
</div>
<p>This should produce the diagnostic plots for residual analysis of the selected SARIMA model as shown in Figure 10.41:</p>
<figure>
<img src="../media/file238.png" alt="Figure 10.42: Diagnostic plots for residual analysis based on the selected SARIMA model" width="1054" height="980"/><figcaption aria-hidden="true">Figure 10.42: Diagnostic plots for residual analysis based on the selected SARIMA model</figcaption>
</figure>
<p>To access the model summary, use the <code>summary</code> method. This will produce Figure 10.42, showing the SARIMA model summary as selected by <code>auto_arima</code>:</p>
<figure>
<img src="../media/file239.png" alt="Figure 10.43: SARIMA model summary based on auto_arima selected model" width="977" height="379"/><figcaption aria-hidden="true">Figure 10.43: SARIMA model summary based on auto_arima selected model</figcaption>
</figure>
<ol>
<li>To forecast future periods, utilize the <code>predict</code> method. You will need to specify the number of periods to forecast forward into the future:</li>
</ol>
<div class="C1-CodePACKT">
<pre><code>n = milk_test.shape[0]
index = milk_test.index
ax = milk_test.plot(style='--', alpha=0.6, figsize=(12,4))
pd.Series(auto_model.predict(n_periods=n),
          index=index).plot(style='-', ax=ax)
plt.legend(['test', 'forecast']);</code></pre>
</div>
<p>The produced plot, shown in Figure 10.43, compares the forecast with the test data:</p>
<figure>
<img src="../media/file240.png" alt="Figure 10.44: Plotting the forecast from auto_arima against actual test data" width="983" height="378"/><figcaption aria-hidden="true">Figure 10.44: Plotting the forecast from auto_arima against actual test data</figcaption>
</figure>
<p>You can obtain the confidence intervals with the prediction by updating the <code>return_conf_int</code> parameter from <code>False</code> to <code>True</code>. This will allow you to plot the lower and upper confidence intervals using matplotlib's <code>fill_between</code> function. The default confidence interval is set to 95% (<code>alpha=0.05).</code></p>
<p>The following code uses the <code>predict</code> method, returns the confidence intervals, and plots the predicted values against the test set:</p>
<div class="C1-CodePACKT">
<pre><code>n = milk_test.shape[0]
forecast, conf_interval = auto_model.predict(n_periods=n,
                                             return_conf_int=True,
                                            alpha=0.05)
lower_ci, upper_ci  = zip(*conf_interval)
index = milk_test.index
ax = milk_test.plot(style='--', alpha=0.6, figsize=(12,4))
pd.Series(forecast, index=index).plot(style='-', ax=ax)
plt.fill_between(index, lower_ci, upper_ci, alpha=0.2)
plt.legend(['test', 'forecast']);</code></pre>
</div>
<p>This should produce a plot with a shaded area representing the likelihood that the real values would lie within this range. Ideally, you would prefer a narrower confidence interval range.</p>
<p>The shaded area is based on the lower and upper bounds of the confidence intervals as shown in Figure 10.44:</p>
<figure>
<img src="../media/file241.png" alt="Figure 10.45: Plotting the forecast from auto_arima against actual test data with the confidence intervals" width="2272" height="732"/><figcaption aria-hidden="true">Figure 10.45: Plotting the forecast from auto_arima against actual test data with the confidence intervals</figcaption>
</figure>
<p>Notice that the forecast line lies in the middle of the shaded area. This represents the mean of the upper and lower bounds.</p>
<p>The following code checks if the forecast values align with the mean of the confidence intervals:</p>
<div class="C1-CodePACKT">
<pre><code>sum(forecast) == sum(conf_interval.mean(axis=1))
&gt;&gt; True</code></pre>
</div>
</section>
<section id="how-it-works-42" class="level3" data-number="11.7.3">
<h3 data-number="11.7.3">How it works…</h3>
<p>The <code>auto_arima</code> function from the <strong>pmdarima</strong> library serves as a wrapper for the <strong>statsmodels</strong> SARIMAX class and aims to automate the process of identifying the best model and parameters. This function provides three primary methods to control the optimization of the training process, dictated by the <code>stepwise</code> and <code>random</code> parameters:</p>
<ul>
<li><strong>Naive brute-force grid search</strong>: Conducts a comprehensive grid search over all parameter combinations by setting <code>stepwise=False</code> and <code>random=False</code>. This method exhaustively evaluates each combination, which can be time-consuming but thorough.</li>
<li><strong>Random grid search</strong>: Activates a random search across the parameter space by setting <code>stepwise=False</code> and <code>random=True</code>. This approach randomly selects combinations to test, which can be faster and still effective, especially in large parameter spaces.</li>
<li><strong>Stepwise search algorithm</strong>: Enabled by default with <code>stepwise=True</code>, this method uses a heuristic to explore the parameter space step by step, adding or subtracting from each parameter based on the AIC or BIC scores from previous steps. It is generally faster and more efficient than the full grid search, as it intelligently narrows down the range of models to those most likely to provide the best fit.</li>
</ul>
</section>
<section id="theres-more-38" class="level3" data-number="11.7.4">
<h3 data-number="11.7.4">There's more…</h3>
<p>The <code>pmdarima</code> library offers a plethora of useful functions to help you make informed decisions so that you can understand the data you are working with.</p>
<p>For example, the <code>ndiffs</code> function performs stationarity tests to determine the differencing order, <code>d</code>, to make the time series stationary. The tests include the <strong>Augmented Dickey-Fuller</strong> (<code>adf</code>) test, the <strong>Kwiatkowski–Phillips–Schmidt–Shin</strong> (<code>kpss</code>) test, and the <strong>Phillips-Perron</strong> (<code>pp</code>) test.</p>
<p>Similarly, the <code>nsdiffs</code> function helps estimate the number of seasonal differencing orders (<code>D</code> ) that are needed. The implementation covers two tests – the <strong>Osborn-Chui-Smith-Birchenhall</strong> (<code>ocsb</code>) and <strong>Canova-Hansen</strong> (<code>ch</code>) tests:</p>
<div class="C0-SHCodePACKT">
<pre><code>from pmdarima.arima.utils import ndiffs, nsdiffs
n_adf = ndiffs(milk, test='adf')
# KPSS test (the default in auto_arima):
n_kpss = ndiffs(milk, test='kpss')
n_pp = ndiffs(milk, test='pp') 
n_ch = nsdiffs(milk, test='ocsb', m=10, max_D=12,)
n_ocsb = nsdiffs(milk, test='ch' , m=10, max_D=12,)</code></pre>
</div>
<p>The <code>auto_arima</code> function allows for detailed control over the model evaluation process by setting the minimum and maximum constraints on various parameters. For example, you can specify limits for the non-seasonal autoregressive order, <code>p</code>, or the seasonal moving average, <code>Q</code>. The following code example demonstrates how to set some of these parameters and constraints:</p>
<div class="C0-SHCodePACKT">
<pre><code>model = pm.auto_arima(milk_train,
                      seasonal=True,
                      with_intercept=True,
                      d=1,
                      max_d=2,
                      start_p=0, max_p=2,
                      start_q=0, max_q=2,
                      m=12,
                      D=1,
                      max_D=2,
                      start_P=0, max_P=2,
                      start_Q=0, max_Q=2,
                      information_criterion='aic',
                      stepwise=False,
                      out_of_sample_siz=25,
                      test = 'kpss',
                      score='mape',
                      trace=True)                     </code></pre>
</div>
<p>If you run the preceding code, <code>auto_arima</code> will create different models for every combination of the parameter values based on the constraints you provided. Because <em>stepwise</em> is set to <em>False</em>, it becomes a brute-force <strong>grid search</strong> in which every permutation for the different variable combinations is tested one by one. Hence, this is generally a much slower process, but by providing these constraints, you can improve the search performance.</p>
<p>By enabling <code>trace=True</code>, the AIC scores for each model configuration tested are displayed. Once completed, it should print out the best model.</p>
<p>The approach that was taken here, with <code>stepwise=False</code>, should resemble the approach you took in the <em>Forecasting univariate time series data with seasonal ARIMA</em> recipe, in the <em>There's more...</em> section.</p>
<section id="using-darts-autoarima" class="level4" data-number="11.7.4.1">
<h4 data-number="11.7.4.1">Using Darts AutoArima</h4>
<p>In <em>the Forecasting univariate time series data with exponential smoothing</em> recipe, you were introduced to the <strong>Darts</strong> library in the <em>There’s more…</em> section</p>
<p>The Darts library offers the <code>AutoArima </code>class, a thin wrapper around <strong>pmdarima</strong>’s <strong>auto_arima</strong>. The following code demonstrates how you can leverage Darts to perform the same functionality:</p>
<div class="C0-SHCodePACKT">
<pre><code>model = AutoARIMA(seasonal=True,
                           m=12,
                 stepwise=True)
ts = TimeSeries.from_dataframe(milk_train.reset_index(),
                                    time_col='month', value_cols='production', freq='MS')
darts_arima = model.fit(ts)
darts_forecast = model.predict(len(milk_test))
ts.plot(label='Training')
darts_forecast.plot(label='Forecast', linestyle='--');</code></pre>
</div>
<p>This code produces a plot showing the forecast, as displayed in Figure 10.45:</p>
<figure>
<img src="../media/file242.png" alt="Figure 10.46: Plotting the forecast using AutoARIMA from the Darts library" width="2268" height="742"/><figcaption aria-hidden="true">Figure 10.46: Plotting the forecast using AutoARIMA from the Darts library</figcaption>
</figure>
</section>
<section id="using-darts-statsforecastautoarima" class="level4" data-number="11.7.4.2">
<h4 data-number="11.7.4.2">Using Darts StatsForecastAutoARIMA</h4>
<p>Darts also provides a wrapper over <strong>Statsforecasts</strong>’ Auto_ARIMA which offers a potentially faster implementation than AutoArima. The following code demonstrates how you can use the <code>StatsForecastAutoARIMA</code> to perform the same functionality:</p>
<div class="C0-SHCodePACKT">
<pre><code>from darts.models import StatsForecastAutoARIMA
model = StatsForecastAutoARIMA(season_length=12)
model.fit(ts)
pred = model.predict(len(milk_test))
ts.plot(label='Training')
darts_forecast.plot(label='AutoArima', linestyle='--');
pred.plot(label='StatsforecstsAutoArima');</code></pre>
</div>
<p>This code produces a plot comparing forecasts from AutoARIMA and StatsForecastAutoARIMA, as shown in Figure 10.47:</p>
<figure>
<img src="../media/Picture10.jpg" alt="Figure 10.47: Plotting the forecast using StatsForecastAutoARIMA from the Darts library" width="903" height="295"/><figcaption aria-hidden="true">Figure 10.47: Plotting the forecast using StatsForecastAutoARIMA from the Darts library</figcaption>
</figure>
</section>
</section>
<section id="see-also-48" class="level3" data-number="11.7.5">
<h3 data-number="11.7.5">See also</h3>
<p>To learn more about the <code>auto_arima</code> implementation, please visit the official documentation at <a href="https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html">https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html</a>.</p>
<p>In the next recipe, you will learn about a new algorithm that provides a simpler API for model tuning and optimization. In other words, there are far fewer parameters that you need to worry about.</p>
</section>
</section>
</section>
</div>
</div>
</body>
</html>