["```py\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rc(\"figure\", figsize=(16, 5))\n```", "```py\nconda create -n prophet python=3.11 -y\n```", "```py\npython -m ipykernel install --user --name prophet --display-name \"Prophet\"\nconda activate prophet\n```", "```py\npip install prophet\n```", "```py\nconda install -c conda-forge prophet\n```", "```py\nfrom prophet import Prophet\nmilk_file = Path('../../datasets/Ch11/milk_production.csv')\nmilk = pd.read_csv(milk_file, parse_dates=['month'])\nmilk.columns = ['ds', 'y']\nmilk.info()\n>>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 168 entries, 0 to 167\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype        \n---  ------  --------------  -----        \n 0   ds      168 non-null    datetime64[ns]\n 1   y       168 non-null    int64        \ndtypes: datetime64[ns](1), int64(1)\nmemory usage: 2.8 KB\n```", "```py\nidx = round(len(milk) * 0.90)\ntrain = milk[:idx]\ntest = milk[idx:]\nprint(f'Train: {train.shape}')\nprint(f'Test: {test.shape}')\n>>\nTrain: (151, 2)\nTest: (17, 2)\n```", "```py\nfrom prophet import Prophet\nmodel = Prophet().fit(train)\n```", "```py\nfuture = m_milk.make_future_dataframe(len(test), freq='MS')\n```", "```py\nlen(milk) == len(future)\n>> True\nprint(future.tail())\n>>\n            ds\n163 1975-08-01\n164 1975-09-01\n165 1975-10-01\n166 1975-11-01\n167 1975-12-01\n```", "```py\nforecast = model.predict(future)\nforecast.columns.tolist()\n>>\n['ds',\n 'trend',\n 'yhat_lower',\n 'yhat_upper',\n 'trend_lower',\n 'trend_upper',\n 'additive_terms',\n 'additive_terms_lower',\n 'additive_terms_upper',\n 'yearly',\n 'yearly_lower',\n 'yearly_upper',\n 'multiplicative_terms',\n 'multiplicative_terms_lower',\n 'multiplicative_terms_upper',\n 'yhat']\n```", "```py\nmodel.plot(forecast,\n           ylabel='Milk Production in Pounds',\n           include_legend=True);\n```", "```py\npredicted = model.predict(test)\nmodel.plot(predicted,\n           ylabel='Milk Production in Pounds',\n          include_legend=True);\n```", "```py\nmodel.plot_components(forecast);\n```", "```py\nax = test.plot(x='ds', y='y',\n                    label='Actual',\n                    style='-.',\n                    figsize=(12,4))\npredicted.plot(x='ds', y='yhat',\n               label='Predicted',\n               ax=ax,\n               title='Milk Production Actual vs Forecast');\n```", "```py\nmodel.seasonalities\n>>\nOrderedDict([('yearly',\n              {'period': 365.25,\n               'fourier_order': 10,\n               'prior_scale': 10.0,\n               'mode': 'additive',\n               'condition_name': None})])\n```", "```py\nmodel = Prophet(uncertainty_samples=False).fit(train)\nforecast = model.predict(future)\nforecast.columns.tolist()\n>>\n['ds', 'trend', 'additive_terms', 'yearly', 'multiplicative_terms', 'yhat']\n```", "```py\nmodel.changepoints.shape\n>>\n(25,)\nmodel.changepoints.head()\n>>\n5    1962-06-01\n10   1962-11-01\n14   1963-03-01\n19   1963-08-01\n24   1964-01-01\nName: ds, dtype: datetime64[ns]\n```", "```py\nax = milk.set_index('ds').plot(figsize=(12,5))\nmilk.set_index('ds').loc[model.changepoints].plot(style='X', ax=ax)\nplt.legend(['original data', 'changepoints']);\n```", "```py\nfrom prophet.plot import add_changepoints_to_plot\nfig = model.plot(forecast, ylabel='Milk Production in Pounds')\nadd_changepoints_to_plot(fig.gca(), model, forecast);\n```", "```py\nfrom prophet.diagnostics import cross_validation, performance_metrics\ndf_cv = cross_validation(model, initial='730 days', period='180 days', horizon='365 days')\ndf_cv.head()\n>>\n         ds        yhat  yhat_lower  yhat_upper    y     cutoff\n0 1964-03-01  689.889300  685.612439  694.504671  688 1964-02-19\n1 1964-04-01  701.435214  697.157285  706.019257  705 1964-02-19\n2 1964-05-01  776.047139  771.707065  780.994528  770 1964-02-19\n3 1964-06-01  735.045494  730.374821  739.547374  736 1964-02-19\n4 1964-07-01  671.333097  666.625404  675.994830  678 1964-02-19\n```", "```py\ndf_p = performance_metrics(df_cv)\nprint(df_p.iloc[: , 0:-1].head())\n>>\nhorizon         mse       rmse        mae      mape     mdape     smape\n0 41 days  226.788248  15.059490  12.300991  0.016356  0.016894  0.016345\n1 42 days  220.336066  14.843721  11.849186  0.015699  0.015678  0.015694\n2 45 days  214.385008  14.641892  11.647620  0.015503  0.015678  0.015503\n3 46 days  207.646253  14.409936  11.380352  0.015170  0.014446  0.015164\n4 47 days  242.132208  15.560598  12.179413  0.015953  0.014446  0.015986\n```", "```py\nfrom prophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(df_cv, metric='rmse');\n```", "```py\nconda install -c anaconda pandas-datareader\n```", "```py\npip install pandas-datareader\n```", "```py\nimport pandas_datareader.data as web\nimport pandas as pd\nfrom statsmodels.tsa.api import VAR,adfuller, kpss\nfrom statsmodels.tsa.stattools import grangercausalitytests\n```", "```py\nimport pandas_datareader.data as web\nstart = \"01-01-1990\"\nend = \"01-09-2024\"\neconomic_df = web.FredReader(\n        symbols=[\"FEDFUNDS\", \"unrate\"],\n        start=start,\n        end=end).read()\nfile = '../../datasets/Ch11/economic_df.pickle'\neconomic_df.to_pickle(file)\n```", "```py\neconomic_df.isna().sum()\n>>\nFEDFUNDS    0\nunrate      0\ndtype: int64\n```", "```py\neconomic_df.index.freq = 'MS'\n```", "```py\neconomic_df.plot(subplots=True); plt.show()\n```", "```py\ncorrelation_matrix = economic_df.corr()\ncorrelation_matrix\n>>\n          FEDFUNDS    unrate\nFEDFUNDS  1.000000 -0.435171\nunrate   -0.435171  1.000000\n```", "```py\nfrom statsmodels.graphics.tsaplots import plot_ccf\nimport numpy as np\nlags = np.arange(-12, 13)\nplot_ccf(economic_df['FEDFUNDS'], economic_df['unrate'], lags=lags)\nplt.grid(True)\n```", "```py\nfrom statsmodels.tsa.stattools import adfuller\ndef check_stationarity(df):\n    adf_pv = adfuller(df)[1]\n    result = 'Stationary' if adf_pv < 0.05 else \"Non-Stationary\"\n    return result\n```", "```py\nfor i in economic_df:\n    adf = check_stationarity(economic_df[i])\n    print(f'{i} adf: {adf}')\n>>\nFEDFUNDS adf: Stationary\nunrate adf: Stationary\n```", "```py\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfor col in economic_df.columns:\n    fig, ax = plt.subplots(1,2, figsize=(18,4))\n    plot_acf(economic_df[col], zero=False,\n             lags=30, ax=ax[0], title=f'ACF - {col}')\n    plot_pacf(economic_df[col], zero=False,\n              lags=30, ax=ax[1], title=f'PACF - {col}');\n```", "```py\ntrain = economic_df.loc[:'2022']\ntest = economic_df.loc['2023':]\nprint(f'Train: {len(train)}, Test: {len(test)}')\n>>\nTrain: 396, Test: 21\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nscale.fit(train)\ntrain_sc = pd.DataFrame(scale.transform(train),\n                        index=train.index,\n                        columns=train.columns)\ntest_sc = pd.DataFrame(scale.transform(test),\n                       index=test.index,\n                       columns=test.columns)\n```", "```py\nmodel = VAR(endog=train_sc)\nres = model.select_order(maxlags=10)\nres.summary()\n```", "```py\nVAR Order Selection (* highlights the minimums) \n==================================================\n       AIC         BIC         FPE         HQIC  \n--------------------------------------------------\n0      -0.2862     -0.2657      0.7511     -0.2780\n1       -7.345      -7.283   0.0006461      -7.320\n2       -7.874      -7.772   0.0003805      -7.833\n3       -7.960     -7.817*   0.0003491     -7.903*\n4       -7.960      -7.775   0.0003492      -7.887\n5       -7.951      -7.726   0.0003523      -7.862\n6       -7.967      -7.701   0.0003467      -7.861\n7      -7.974*      -7.667  0.0003443*      -7.852\n8       -7.957      -7.609   0.0003502      -7.819\n9       -7.947      -7.557   0.0003539      -7.792\n10      -7.931      -7.501   0.0003593      -7.761\n--------------------------------------------------\n```", "```py\nprint(res.selected_orders)\n>>\n{'aic': 7, 'bic': 3, 'hqic': 3, 'fpe': 7}\n```", "```py\nresults = model.fit(ic='bic')\n```", "```py\n Summary of Regression Results  \n==================================\nModel:                         VAR\nMethod:                        OLS\nDate:           Mon, 07, Oct, 2024\nTime:                     14:49:51\n--------------------------------------------------------------------\nNo. of Equations:         2.00000    BIC:                   -7.83732\nNobs:                     393.000    HQIC:                  -7.92278\nLog likelihood:           466.565    FPE:                0.000342624\nAIC:                     -7.97888    Det(Omega_mle):     0.000330737\n--------------------------------------------------------------------\n```", "```py\nCorrelation matrix of residuals\n            FEDFUNDS    unrate\nFEDFUNDS    1.000000 -0.115904\nunrate     -0.115904  1.000000\n```", "```py\nlag_order = results.k_ar\nlag_order\n>> 3\n```", "```py\npast_y = train_sc[-lag_order:].values\nn = test_sc.shape[0]\nforecast, lower, upper = results.forecast_interval(past_y, steps=n)\n```", "```py\nforecast_df = pd.DataFrame(scale.inverse_transform(forecast),\n                           index=test_sc.index,\n                           columns=test_sc.columns)\nlower_df = pd.DataFrame(scale.inverse_transform(lower),\n                        index=test_sc.index,\n                        columns=test_sc.columns)\nupper_df = pd.DataFrame(scale.inverse_transform(upper),\n                        index=test_sc.index,\n                        columns=test_sc.columns)\n```", "```py\nidx = test.index\nplt.figure(figsize=(10, 6))\nplt.plot(idx, test['unrate'], label='Actual unrate')\nplt.plot(idx, forecast_df['unrate'], label='Forecasted unrate', linestyle='dashed')\nplt.fill_between(idx, lower_df['unrate'], upper_df['unrate'], alpha=0.2, label='Confidence Interval')\nplt.title('Actual vs Forecasted unrate with Confidence Intervals')\nplt.legend()\nplt.show()\n```", "```py\nidx = test.index\nplt.figure(figsize=(10, 6))\nplt.plot(idx, test['FEDFUNDS'], label='Actual FEDFUNDS')\nplt.plot(idx, forecast_df['FEDFUNDS'], label='Forecasted FEDFUNDS', linestyle='dashed')\nplt.fill_between(idx, lower_df['FEDFUNDS'], upper_df['FEDFUNDS'], alpha=0.2, label='Confidence Interval')\nplt.title('Actual vs Forecasted FEDFUNDS with Confidence Intervals')\nplt.legend()\nplt.show()\n```", "```py\nfrom statsmodels.tsa.arima.model import ARIMA\nmodel = ARIMA(train['unrate'],\n              order=(lag_order,0,0)).fit()\n```", "```py\nfig = model.plot_diagnostics(figsize=(12,6));\nfig.tight_layout()\nplt.show()\n```", "```py\n# Forecast from AR(3) model\nar_forecast = pd.Series(model.forecast(n), index=test.index)\n# Plot the forecast for AR(3) against the actual data\nidx = test.index\nplt.figure(figsize=(10, 4))\nplt.plot(idx, test['unrate'], label='Actual unrate')\nplt.plot(idx, ar_forecast, label='Forecasted unrate', linestyle='dashed')\nplt.title('AR(3) model - Actual vs Forecasted unrate')\nplt.legend()\nplt.show()\n```", "```py\n# plotting VAR(3) same code as before but without confidence intervals\nidx = test.index\nplt.figure(figsize=(10, 4))\nplt.plot(idx, test['unrate'], label='Actual unrate')\nplt.plot(idx, forecast_df['unrate'], label='Forecasted unrate', linestyle='dashed')\nplt.title('VAR(3) model - Actual vs Forecasted unrate')\nplt.legend()\nplt.show()\n```", "```py\nfrom statsmodels.tools.eval_measures import rmse\nrmse_var = rmse(test['FEDFUNDS'], forecast_df['unrate'])\nprint('VAR(3) RMSE = ', rmse_var)\nrmse_ar = rmse(test['FEDFUNDS'], ar_forecast)\nprint('AR(3) RMSE = ', rmse_ar)\n>>\nVAR(3) RMSE =  0.9729655920788434\nAR(3) RMSE =  0.7693416723850359\n```", "```py\ngranger = grangercausalitytests(\n            x=economic_df[['unrate', 'FEDFUNDS']],\n            maxlag=3)\n```", "```py\nGranger Causality\nnumber of lags (no zero) 1\nssr based F test:         F=0.5680  , p=0.4515  , df_denom=413, df_num=1\nssr based chi2 test:   chi2=0.5721  , p=0.4494  , df=1\nlikelihood ratio test: chi2=0.5717  , p=0.4496  , df=1\nparameter F test:         F=0.5680  , p=0.4515  , df_denom=413, df_num=1\nGranger Causality\nnumber of lags (no zero) 2\nssr based F test:         F=21.9344 , p=0.0000  , df_denom=410, df_num=2\nssr based chi2 test:   chi2=44.4039 , p=0.0000  , df=2\nlikelihood ratio test: chi2=42.1852 , p=0.0000  , df=2\nparameter F test:         F=21.9344 , p=0.0000  , df_denom=410, df_num=2\nGranger Causality\nnumber of lags (no zero) 3\nssr based F test:         F=21.6694 , p=0.0000  , df_denom=407, df_num=3\nssr based chi2 test:   chi2=66.1262 , p=0.0000  , df=3\nlikelihood ratio test: chi2=61.3477 , p=0.0000  , df=3\nparameter F test:         F=21.6694 , p=0.0000  , df_denom=407, df_num=3\n```", "```py\nresults.plot_acorr(resid=True)\nplt.show();\n```", "```py\nfor col in results.resid.columns:\n    fig, ax = plt.subplots(1,1, figsize=(10,2))\n    plot_acf(results.resid[col], zero=False,\n             lags=10, ax=ax, title=f'ACF - {col}')\n```", "```py\nirf_output = results.irf()\nirf_output.plot()\nplt.show()\n```", "```py\nfig = irf_output.plot(impulse='FEDFUNDS', response='unrate', figsize=(5, 7))\nfig.tight_layout()\nplt.show()\n```", "```py\nirf.plot_cum_effects()\nplt.show()\n```", "```py\nfv = results.fevd()\n```", "```py\nfv.plot()\nplt.show()\n```", "```py\nn = len(test)\nresults.plot_forecast(steps=n, plot_stderr=True);\n```", "```py\npip install arch\n```", "```py\nconda install -c conda-forge arch-py\n```", "```py\nfrom arch import arch_model\nimport pandas as pd\n```", "```py\nmsft = pd.read_csv('../../datasets/Ch11/MSFT.csv',\n                   index_col='date',\n                    usecols=['date', 'close'],\n                   parse_dates=True)\n```", "```py\nmsft['returns'] = 100 * msft.pct_change()\nmsft.dropna(inplace=True, how='any')\n```", "```py\ntitle = 'Microsoft Daily Closing Price and Daily Returns'\nmsft.plot(subplots=True,\n          title=title);\n```", "```py\ntrain = msft.returns[:-5] \ntest = msft.returns[-5:]  \nprint(f'Train: {train.shape}')\nprint(f'Test: {test.shape}')\nprint(f'Train: {train.shape}')\nprint(f'Test: {test.shape}')\n>>\nTrain: (1253,)\nTest: (5,)\n```", "```py\nmodel = arch_model(train,\n                   p=1, q=1,\n                   mean='Constant',\n                   vol='GARCH',\n                   dist='normal')\nresults = model.fit(update_freq=5)\n>>\nIteration:      3,   Func. Count:     22,   Neg. LLF: 2419.4197011866704\nIteration:      6,   Func. Count:     41,   Neg. LLF: 2409.599553434422\nIteration:      9,   Func. Count:     55,   Neg. LLF: 2409.592672855605\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 2409.59267285418\n            Iterations: 9\n            Function evaluations: 55\n            Gradient evaluations: 9\n```", "```py\nPrint(results.summary())\n```", "```py\nprint(results.params)\n>>\nmu          0.144878\nomega       0.055152\nalpha[1]    0.095416\nbeta[1]     0.891086\nName: params, dtype: float64\n```", "```py\nresults.plot();\n```", "```py\nresults.std_resid.hist(bins=20)\nplt.title('Standardized Residuals')\n```", "```py\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\nacorr_ljungbox(results.std_resid,\n               lags=10,\n               return_df=True)['lb_pvalue']\n>>\n1     0.050203\n2     0.038038\n3     0.077375\n4     0.136003\n5     0.195838\n6     0.157237\n7     0.201474\n8     0.248204\n9     0.153473\n10    0.210838\nName: lb_pvalue, dtype: float64\n```", "```py\nmsft_forecast = results.forecast(horizon=test.shape[0])\n```", "```py\nforecast = msft_forecast.variance\nprint(forecast)\n>>\n                 h.1       h.2       h.3       h.4       h.5\ndate                                                       \n2024-08-27  1.623692  1.656928  1.689714  1.722059  1.753967\n```", "```py\nprint(msft_forecast.mean)\n>>\n                 h.1       h.2       h.3       h.4       h.5\ndate                                                       \n2024-08-27  0.144878  0.144878  0.144878  0.144878  0.144878\n```", "```py\nmodel = arch_model(train,\n                   p=1, q=1,\n                   mean='Zero',\n                   vol='GARCH',\n                   dist='normal')\nresults = model.fit(disp=False)\n```"]