- en: 11 Additional Statistical Modeling Techniques for Time Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Join our book community on Discord
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/file0.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/zmkOY](https://packt.link/zmkOY)'
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 10*, *Building Univariate Time Series Models Using Statistical Methods*,
    you were introduced to popular forecasting techniques such as *exponential smoothing,
    non-seasonal ARIMA*, *and seasonal ARIMA*. These methods, often referred to as
    classical statistical forecasting approaches, are fast, simple to implement, and
    easy to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will dive head-first and learn about additional statistical
    methods that build on the foundation you gained from the previous chapter. This
    chapter will introduce a few libraries that can automate time series forecasting
    and model optimization - Facebook's (meta) `Prophet` library. Additionally, you
    will explore `statsmodels'` **vector autoregressive (VAR)** class for working
    with multivariate time series and the `arch` library, which supports **GARCH**
    for modeling volatility in financial data.
  prefs: []
  type: TYPE_NORMAL
- en: The main goal of this chapter is to familiarize you with **automated forecasting
    tools** (like Prophet) and introduce the concept of **multivariate time series
    modeling** with VAR models. You will also gain an understanding of how to model
    and forecast **volatility** in financial time series, which is essential for risk
    management and financial decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting time series data using Facebook Prophet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecasting multivariate time series data using VAR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating vector autoregressive (VAR) models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecasting volatility in financial time series data with GARCH
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can download the Jupyter Notebooks to follow along and the necessary datasets
    for this chapter from this book''s GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jupyter Notebooks: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./blob/main/code/Ch11/Chapter%2011.ipynb](https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./blob/main/code/Ch11/Chapter%2011.ipynb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Datasets: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./tree/main/datasets/Ch11](https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook./tree/main/datasets/Ch11)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are common libraries that you will be using throughout the recipes in
    this chapter. You can import them in advance by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Forecasting time series data using Facebook Prophet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Prophet** library is a popular open-source project that was initially
    developed at Facebook (now Meta), based on a 2017 paper that proposed an algorithm
    for time series forecasting titled *Forecasting at Scale*. The project gained
    popularity due to its simplicity, ability to create performant forecasting models,
    and ability to handle complex seasonality, holiday effects, missing data, and
    outliers. Prophet automates many aspects of designing a forecasting model while
    providing rich built-in visualizations. Additional capabilities include building
    growth models (like **saturated forecasts**), working with uncertainty in trend
    and seasonality, and **detecting changepoints**.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will use the `Milk Production` dataset for benchmarking
    performance. This is the same dataset introduced in *Chapter 10*, *Building Univariate
    Time Series Models Using Statistical Methods*. Using the same dataset helps in
    understanding and comparing different methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prophet is an **additive regression model** that can handle **non-linear trends**,
    especially when there are strong seasonal effects. The model decomposes time series
    data into three main components: *trend*, *seasonality*, and *holidays*, represented
    in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file244.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: is the trend function,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: represents the periodic seasonality function,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: accounts for the effects of holidays,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: is the residual error term.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prophet uses **Bayesian inference** to automate tuning and optimization of the
    model components. Behind the scenes, it relies on **Stan**, a state-of-the-art
    platform for Bayesian modeling, with **cmdstand** and **cmdstanpy** as the current
    Python interface (replacing the earlier **PyStan**). Recent updates have improved
    compatibility with Apple M1/M2 chips and enhanced model customization options,
    such as adjusting the handling of holidays and scaling output.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can find the Jupyter Notebooks and necessary datasets from this book's GitHub
    repository. Please refer to the *Technical requirements* section of this chapter
    for more information. We use Prophet 1.0 version for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a new Python environment when installing new libraries like Prophet
    is always a good idea. If you need a quick refresher on creating a virtual Python
    environment, check out the *Development environment setup recipe* from *Chapter
    1*, *Getting Started with Time Series Analysis*. The chapter covers two methods:
    using `conda` and `venv`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, you can create the environment using conda as in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This preceding code will create a new virtual environment named `prophet`.
    To make the new `prophet` environment visible in Jupyter, you can run the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the new environment is activated, you can install the Prophet library.
    To install using **pip,** you can run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To install using **conda,** use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Prophet requires the input data to be in a pandas DataFrame with two specific
    columns: a **datetime** column named `ds` and a target variable column named `y`
    – this is the variable you wish to forecast. Prophet does not work with a `Datetimeindex`
    directly. Hence, it’s crucial to have these columns explicitly named. If your
    data contains more than two columns, Prophet will only recognize `ds` and `y`,
    and ignore the rest by default. However, if you want to include additional predictors
    (regressors), use the `add_regressor` method. If these columns are missing or
    incorrectly named, Prophet will throw an error.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure your data is formatted properly, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by reading the `milk_productions.csv` file and rename the columns `ds`
    and `y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Split the data into **test** and **train** sets. Let''s go with a `90/10` split
    by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can create an instance of the Prophet class and fit it on the training
    set in one line with the `fit` method. The milk production time series is *monthly*,
    with both a trend and a steady seasonal fluctuation (additive). The default `seasonality_mode`
    in Prophet is `additive`, so leave it as-is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Some setup needs to be done before you can use the model to make predictions.
    Use the `make_future_dataframe` method to extend the `train` DataFrame forward
    for a specific number of periods and at a specified frequency:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This extends the training data by 17 months (the number of periods in the `test`
    set). In total, you should have the exact number of periods that are in the milk
    DataFrame (train and test). The frequency is set to **month start** with `freq=''MS''`.
    The `future` object only contains one column, `ds`, of type `datetime64[ns]` ,
    which is used to populate the predicted values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `predict` method to take the `future` DataFrame and make the predictions.
    The result will be a DataFrame that''s the same length as `forecast` but now with
    additional columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Notice that Prophet returned a lot of details to help you understand how the
    model performs. Of interest are `ds` and the predicted value, `yhat`. Both `yhat_lower`
    and `yhat_upper` represent the uncertainty intervals for the prediction (`yhat`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `model` object provides two plotting methods: `plot` and `plot_components`.
    Start by using `plot` to visualize the forecast from Prophet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce a plot of the Prophet forecast: the dots in the plot represent
    the training data point, the line over the dots represents the estimated forecast
    for the historical data, the line is extended beyond the training points reflect
    the future prediction'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Plotting the forecast (historical and future) using Prophet](img/file245.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 – Plotting the forecast (historical and future) using Prophet
  prefs: []
  type: TYPE_NORMAL
- en: 'If you only want to show the forecast just for the periods beyond the training
    set you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here you are only forecasting for the length of the test dataset. The predict
    method will only capture the `ds` column (datetime). This should produce a plot
    that's similar to the one shown in *Figure 11.4*, but it will only show the forecast
    line for future data points (beyond the training points)– that is, the future
    forecast.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Plotting the forecast (historical and future) using Prophet](img/file246.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – Plotting the forecast (historical and future) using Prophet
  prefs: []
  type: TYPE_NORMAL
- en: The shaded area in *Figure 11.4* represents the uncertainty intervals. This
    is represented by the `yhat_lower` and `yhat_upper` columns in the `forecast`
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next important plot deals with the forecast components. Use the `plot_components`
    method to plot the components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The number of subplots will depend on the number of components that have been
    identified in the forecast. For example, if holiday was included, then it will
    show the `holiday` component. In our example, there will be two subplots: `trend`
    and `yearly`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – Plotting the components showing trend and seasonality (annual)](img/file247.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 – Plotting the components showing trend and seasonality (annual)
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11.6* breaks down the trend and seasonality of the training data. If
    you look at *Figure 11.6*, you will see a positive upward trend that has become
    steady (slowing down) since 1972\. Additionally, the seasonal pattern shows an
    increase in production around summertime.'
  prefs: []
  type: TYPE_NORMAL
- en: The shaded area in the trend plot represents the uncertainty interval for estimating
    the trend. The data is stored in the `trend_lower` and `trend_upper` columns of
    the `forecast` DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, compare with out-of-sample data (the test data) to see how well the
    model performs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Compare the following plot with *Figure 10.43 from Chapter 10* to see how **Prophet**
    compares to the **SARIMA** model that you obtained using `auto_arima`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Comparing Prophet''s forecast against test data](img/file248.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 – Comparing Prophet's forecast against test data
  prefs: []
  type: TYPE_NORMAL
- en: Notice that for the highly seasonal milk production data, the model did a great
    job. Generally, Prophet shines when it's working with strong seasonal time series
    data.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prophet streamlines many aspects of building and optimizing time series models,
    but a few key instructions are required at the start to allow Prophet to properly
    tune the model. For example, initializing the model, you need to decide whether
    the seasonal effect should be additive or multiplicative. You also specify parameters
    like the frequency of the data (e.g., `freq='MS'` for monthly data) when extending
    the forecast horizon using the `make_future_dataframe` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you instantiated a model with `model = Prophet()`, Prophet used the default
    values for parameters like `yearly_seasonality=''auto''`, `weekly_seasonality=''auto''`,
    and `daily_seasonality=''auto''`. This lets Prophet **automatically** determine
    which seasonal components to include based on the data. In the case of the Milk
    Production dataset, only yearly seasonality is detected, as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Prophet also provides **uncertainty intervals** for predictions, which are
    influenced by three factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Observation noise**: refers to the random variations in the observed data
    that cannot be explained by the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parameter uncertainty**: refers to the uncertainty in estimating the model
    parameters. For example, adjusting the `mcmc_samples` parameter (**Markov Chain
    Monte Carlo** or **MCMC** sampling) to get the uncertainty in seasonal components.
    The defaults value is set to zero (`0`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Future trend uncertainty**: refers to uncertainty about future changes in
    trends based on historical data. For example, increasing the `changepoint_prior_scale`
    parameter can increase the forecast uncertainty. The default value is set to `0.05`.
    Additionally the width of the uncertainty intervals can also be adjusted with
    the `interval_width` parameter (defaults to 0.80 or 80%).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, the `uncertainty_samples` parameter is set to `1000`, which means
    Prophet will run 1000 simulations using **Hamiltonian Monte Carlo (HMC)** algorithm
    to estimate uncertainty. You can adjust this to control the number of simulation
    or even turn off uncertainty estimates entirely by setting `uncertainty_samples=0`
    or `uncertainty_samples=False`. If uncertainty samples are disabled, Prophet will
    omit uncertainty intervals like `yhat_lower` and `yhat_upper` from the forecast
    results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Prophet’s strength lies in its ability to **automatically detect changepoints**,
    which are points in time where the **trend shifts** significantly. By default,
    Prophet will identify 25 potential changepoints within the first 80% of the training
    data. You can modify this behavior by adjusting the `n_changepoints` parameter
    or control how much historical data to use for changepoint detection via `changepoint_range`,
    which defaults to `0.8` (or 80%).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can inspect the detected changepoints using the model’s `changepoints`
    attribute. For example, the following code displays the first five changepoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'These changepoints can also be visualized on a plot. The following code overlays
    the changepoints on the original time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This should generate a plot with the original time series and the 25 potential
    changepoints, showing moments where Prophet identified shifts in the trend.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – The 25 potential changepoints, as identified by Prophet](img/file249.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 – The 25 potential changepoints, as identified by Prophet
  prefs: []
  type: TYPE_NORMAL
- en: These potential changepoints were estimated from the first 80% of the training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will explore changepoint detection in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To plot the **significant** changepoints that capture the impactful changes
    in trend, you can use the `add_changepoints_to_plot` function, as shown in the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce a plot similar to *Figure 11.8*, but with the additional
    changepoint lines and the trend line. There are ten (10) significant changepoints
    (the vertical lines in Figure 11.9) out of the 25\. The linear trend line should
    be the same as the trend component shown in *Figure 11.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Showing the ten significant change points and the trend line](img/file250.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – Showing the ten significant change points and the trend line
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the trend line changes at the identified changepoints. This is how
    Prophet can detect changes in the trend. The line is not an exact straight line
    since **piecewise regression** was applied to build the trend model. When thinking
    about *piecewise linear models*, you can think of multiple linear regression lines
    between the significant changepoints (segments) that are then connected. This
    gives the model the flexibility to capture **non-linear** changes in trends and
    make future predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Prophet also includes **cross-validation** capabilities to better evaluate how
    well the model performs in forecasting future data. Cross-validation is used to
    ensure that the model generalizes well to unseen data and is not overfitting or
    underfitting. Additionally, cross-validation can help you determine how far into
    the future the forecasts remain reliable.
  prefs: []
  type: TYPE_NORMAL
- en: Prophet provides the `cross_validation` and `performance_metrics` functions,
    which allow you to split the data into training and testing sets across multiple
    horizons. This method helps evaluate the model's accuracy by making predictions
    at different points in time and comparing them to the actual value.
  prefs: []
  type: TYPE_NORMAL
- en: Here is how to implement cross-validation in Prophet.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we specified the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`initial`: The size of the initial training period. In our code, we specified
    730 days, which is roughly 2 years, or 24-months for our Monthly Milk Production
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: '`period`: The spacing between cutoff points for making forecasts. In this example,
    we specified 180 days (roughly 6 months). This means after the initial training,
    Prophet will step forward in increments of 6 months.'
  prefs: []
  type: TYPE_NORMAL
- en: '`horizon`: The forecast horizon (how far into the future you are predicting).
    In this example, we specified 365 days or 1-year. This means Prophet will forecast
    for the next 12 months (1 year) ahead of each cutoff point.'
  prefs: []
  type: TYPE_NORMAL
- en: After running the cross-validation, you can evaluate the model's performance
    using `performance_metrics` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The function computes several metrics such as **Mean Absolute Error** (MAE),
    **Root Mean Squared Error** (RMSE), among many others.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can visualize the performance of the cross-validated forecasts using the
    `plot_cross_validation_metric` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This should plot the RMSE over the different forecast horizons.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – plot showing the model’s RMSE over different forecast horizon](img/file251.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – plot showing the model’s RMSE over different forecast horizon
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the plot indicates that the models is better at short forecast
    horizons as RMSE is relatively low. As the forecast horizons increase, the RMSE
    seems to generally increase. Generally, we expect these models to perform better,
    with lower errors, at short-term forecasts (1-3 months).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Prophet supports both Python and R. For more information on the Python API,
    please visit the following documentation: [https://facebook.github.io/prophet/docs/quick_start.html#python-api](https://facebook.github.io/prophet/docs/quick_start.html#python-api).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are interested in reading the original paper behind the Prophet algorithm,
    which is publicly available, go to [https://peerj.com/preprints/3190/](https://peerj.com/preprints/3190/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-validation can also be used for fine-tuning hyperparameters of the model.
    You can learn more about this here [https://facebook.github.io/prophet/docs/diagnostics.html#hyperparameter-tuning](https://facebook.github.io/prophet/docs/diagnostics.html#hyperparameter-tuning)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, you have been working with univariate time series. The following recipe
    will teach you how to work with multivariate time series.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting multivariate time series data using VAR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, you will explore the **Vector Autoregressive** (**VAR**) model
    for working with multivariate time series. In *Chapter 10*, *Building Univariate
    Time Series Models Using Statistical Methods,* we discussed AR, MA, ARIMA, and
    SARIMA as examples of univariate one-directional models. VAR, on the other hand,
    is **bi-directional** and **multivariate**.
  prefs: []
  type: TYPE_NORMAL
- en: VAR VERSUS AR MODELS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can think of a VAR of order p, or **VAR(p)**, as a generalization of the
    univariate AR(p) made for working with multiple time series. Multiple time series
    are represented as a vector, hence the name vector autoregression. A VAR of lag
    one (1) can be written as VAR(1) across two or more variables.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are other forms of multivariate time series models, including **Vector
    Moving Average** (**VMA**), **Vector Autoregressive Moving Average** (**VARMA**),
    and **Vector Autoregressive Integrated Moving Average** (**VARIMA**), that generalize
    other univariate models. In practice, you will find that VAR is used the most
    due to its simplicity. VAR models are very popular in economics, but you will
    find them used in other areas, such as social sciences, natural sciences, and
    engineering.
  prefs: []
  type: TYPE_NORMAL
- en: The premise behind multivariate time series is that you can add more power to
    your forecast when leveraging multiple time series (or input variables) instead
    of a single time series (single variable). Simply put, VAR is used when you have
    two or more time series that have (or are assumed to have) an influence on each
    other's behavior. These are normally referred to as **endogenous** variables and
    the relationship is bi-directional. If the variables or time series are not directly
    related, or we do not know if there is a direct influence within the same system,
    we refer to them as **exogenous** variables.
  prefs: []
  type: TYPE_NORMAL
- en: EXOGENOUS VERSUS ENDOGENOUS VARIABLES
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When you start researching more about VAR models, you will come across references
    to **endogenous** and **exogenous** variables. At a high level, the two are the
    opposite of each other and in `statsmodels`, you will see them referenced as `endog`
    and `exog`, respectively.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Endogenous** variables are influenced by other variables within the system.
    In other words, we expect that a change in one''s state affects the other. Sometimes,
    these can be referred to as dependent variables in machine learning literature.
    You can use the **Granger causality tests** to determine if there is such a relationship
    between multiple endogenous variables. For example, in `statsmodels`, you can
    use `grangercausalitytests`.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: On the other hand, **exogenous** variables are outside the system and do not
    have a direct influence on the variables. They are external influencers. Sometimes,
    these can be referred to as independent variables in machine learning literature.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: A VAR model, like an AR model, assumes the **stationarity** of the time series
    variables. This means that each endogenous variable (time series) needs to be
    stationary.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate how VAR works and the mathematical equation behind it, let's start
    with a simple VAR(1) with **two** (2) endogenous variables, referred to as (![](img/file252.png)).
    Recall from *Chapter 10*, *Building Univariate Time Series Models Using Statistical
    Methods*, that an AR(1) model would take the following form:![](img/file253.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, an AR(p) model is a linear model of past values of itself and the
    (p) parameter tells us how far back we should go. Now, assume you have **two**
    AR(1) models for two different time series data. This will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file254.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'However, these are two separate models that do not show any relationship or
    that influence each other. If we create a **linear combination** of the two models
    (the past values of itself and the past values of the other time series), we would
    get the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Formula for a VAR model with lag one or VAR(1)](img/file255.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – Formula for a VAR model with lag one or VAR(1)
  prefs: []
  type: TYPE_NORMAL
- en: The preceding equation may seem complex, but in the end, like an AR model, it
    is still simply a linear function of past lags. In other words, in a VAR(1) model,
    you will have a linear function of lag (1) for each variable. When fitting a VAR
    model, as you shall see in this recipe, the **Ordinary Least Squares** (**OLS**)
    method is used for each equation to estimate the VAR model.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this recipe, you will be using you will use the `pandas_datareader` library
    to download data from FRED (Federal Reserve Economic Data). The files are also
    available for you to download from the GitHub repo of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install using **conda**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To install using **pip**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this recipe, you will use the `FredReader()` function from the `pandas_datareader`
    library to pull two different time series datasets. As mentioned on FRED's website,
    the first symbol, `FEDFUNDS`, is the **Federal Funds Effective Rate**, which *"is
    the interest rate at which depository institutions trade federal funds (balances
    held at Federal Reserve Banks) with each other overnight*." Simply put, the federal
    funds effective rate influences the cost of borrowing. It is *the target interest
    rate set by the Federal Open Market Committee (FOMC) for what banks can charge
    other institutions for lending excess cash from their reserve balances.* The second
    symbol is `unrate` for the **Unemployment Rate**, which is the percentage of the
    total labor force that is unemployed but actively seeking employment or willing
    to work.
  prefs: []
  type: TYPE_NORMAL
- en: CITATIONS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Board of Governors of the Federal Reserve System (US)*, *Federal Funds Effective
    Rate [FEDFUNDS]*, retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/FEDFUNDS,
    October 6, 2024.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*U.S. Bureau of Labor Statistics*, *Unemployment Rate [UNRATE]*, retrieved
    from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UNRATE,
    October 6, 2024.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by loading the necessary libraries and pulling the data. Note that both
    `FEDFUNDS` and `unrate` are reported monthly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Pull the data using `FredReader`, which wraps over the FRED API and returns
    a pandas DataFrame. For the `FEDFUNDS` and `unrate` symbols, you will pull close
    to 34 years'' worth of data (417 months):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Store the DataFrame as a `pickle` object, as shown in the last line of the preceding
    code. This way, you do not have make an API call to rerun the example. You can
    read the `economic_df.pickle` file using `economic_df = pd.read_pickle(file)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspect the data and make sure there are no null values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the DataFrame''s frequency to month start (`MS`) to reflect how the
    data is being stored:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the datasets for visual inspection and understanding:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Since `subplots` is set to `True`, this will produce two subplots for each
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Plotting both Federal Funds Effective Rate and Unemployment
    Rate](img/file256.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – Plotting both Federal Funds Effective Rate and Unemployment Rate
  prefs: []
  type: TYPE_NORMAL
- en: 'There is some sort of inverse relationship between `FEDFUND` and `unrate` –
    as `FEDFUNDS` increases, `unrate` decreases. There is interesting anomalous behavior
    starting in 2020 due to the COVID-19 pandemic. We can further check the correlation
    between the variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The correlation between `FEDFUNDS` and `unrate` is -0.435 indicating a moderate
    negative relationship (inverse correlation). This suggest that as federal funds
    rate increases, the unemployment rate tends to decrease, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: Further you can perform a **Cross-Correlation Function** (CCF) between `FEDFUNDS`
    and `unrate` to see the correlation at different lags. The CFF helps identity
    lagged relationships or temporal dependencies between the two time series. The
    outcome mainly tells us whether one series leads or lags the other. It does not
    a formal test of causality, which you will investigate later.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 11.13 – Cross-Correlation Function plot for 12 months ahead and 12
    months behind for better interpretability](img/file257.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 – Cross-Correlation Function plot for 12 months ahead and 12 months
    behind for better interpretability
  prefs: []
  type: TYPE_NORMAL
- en: The plot shows spikes that extend beyond the shaded confidence interval which
    indicates significant negative correlation. This suggests that changes in `FEDFUNDS`
    might be associate with opposite changes in `unrate` within the same frame
  prefs: []
  type: TYPE_NORMAL
- en: 'An important assumption in VAR is **stationarity**. Both variables (the two
    endogenous time series) need to be stationary. Create a `check_stationarity()`
    function, which returns the stationarity results from the **Augmented Dickey-Fuller**
    (`adfuller`) test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `check_stationarity` function to evaluate each endogenous variable
    (column):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Overall, both time series are shown to be stationary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot both **ACF** and **PACF** plots to gain an intuition over each variable
    and which process they belong to – for example, an AR or MA process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce an ACF and PACF for `FEDFUNDS` and `unrate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – ACF and PACF plots for FEDFUNDS and unrate](img/file258.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – ACF and PACF plots for FEDFUNDS and unrate
  prefs: []
  type: TYPE_NORMAL
- en: The ACF and PACF plots for `FEDFUNDS` and `unrate` indicate we are dealing with
    an **autoregressive** (**AR**) process. The ACF plots show a slow gradual decay,
    while the PACF plots show a sharp cutoff after lag 1\. The PACF for `FEDFUNDS`
    shows slightly significant (above or below the shaded area) lags at 2 and 3, while
    the PACF for `unrate` shows some significance at lag 24\. We can ignore those
    for now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Split the data into train and test sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: You can scale the data (**standardization**), even though it is not necessary
    for VAR, and the two time series are not far off in terms of scale. In this step,
    you will perform scaling for *illustrative purposes* to show how it can be done
    and how you inversely transform the results for interpretation later on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is often a debate on whether the variables need to be scaled (standardized)
    when implementing VAR. However, the VAR algorithm does not inherently require
    the variables to be scaled, as it is **scale-invariant**. In practice, it is common
    to leave variables in their original units to **preserver the interpretability**
    of the coefficients and residuals in meaningful terms (e.g., percentage points).
    However, if the variables differ significantly in scale, then standardization
    can be applied to make the **coefficients easier to compare** and detect **outliers**
    more effectively.
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you choose to standardize (for example, using `StandardScalar` from **Scikit-Learn**),
    it is important to note that the results will be in terms of **standard deviations.**
    You can use the `inverse_transform` method to revert the data back to its original
    units when interpreting the results. This is useful when you need to explain the
    findings in the context of the original variable scale.
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Scale the data using `StandardScalar` by fitting the train set using the `fit`
    method. Then, apply the scaling transformation to both the **train** and **test**
    sets using the `transform` method. The transformation will return a NumPy `ndarray`,
    which you will then return as pandas DataFrames. This will make it easier for
    you to plot and examine the DataFrames further:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'But how can you determine the optimal **lag order** **p** for your VAR model?
    Luckily, the VAR implementation in `statsmodels` will pick the best VAR order.
    You only need to define the maximum number of lags (threshold); the model will
    determine the best `p` values that minimize each of the four information criteria
    scores: **AIC**, **BIC**, **FPE**, and **HQIC**. The `select_order` method will
    compute the scores at each lag order, while the `summary` method will display
    the scores for each lag. The results will help when you train (`fit`) the model
    to specify which information criteria the algorithm should use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show the results for all `10` lags. The lowest scores are marked
    with an `*`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The `res` object is an instance of the `LagOrderResults` class. You can print
    the selected lag number for each information criterion using the `selected_orders`
    attribute, which return a dictionary of the **optimal lag orders** for **AIC**,
    **BIC**, **FPE**, and **HQIC**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: At lag 7, both *AIC* and *FPE* scores were the lowest. On the other hand, both
    *BIC* and *HQ* scores were the lowest at lag 3, suggesting a more parsimonious
    model with fewer lags.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, *BIC* and *HQIC* tend to favor more **parsimonious** models (i.e.,
    models with fewer lags) because they impose higher penalty on model complexity.
    In contrats, *AIC* and *FPE* tend to be more lenient and may suggest higher lag
    orders since they are less strict in penalizing for complexity.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, **lag 3** seems like a safer choice, helping to aim for simplicity
    and avoiding overfitting. However, choosing **lag 7** would result in a more complex
    model that might capture more dynamics in the data, but it comes with a higher
    risk of overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: To train the model, you must use the *BIC* score (or another criterion of your
    choice). You experiment with a different information criterion by updating the
    `ic` parameter. The `maxlags` parameter is optional –if you leave it blank, the
    model will automatically determine the optimal lag order based on the selected
    information criterion, which in this case is `'bic'`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This will automatically select the lag order that minimizes the BIC score (i.e.
    lag 3). You can experiment with other criteria, such as AIC, by setting `ic='aic'`.
    If you prefer to manually specify the maximum number of lags, you can use the
    `maxlags` parameter. Keep in mind if both `maxlags` and `ic` are used then `ic`
    will take precedence.
  prefs: []
  type: TYPE_NORMAL
- en: Running `results.summary()` will print a detailed summary, including the regression
    results for each autoregressive process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The summary includes information on the **number of equations** (corresponding
    to the number of variables), the **information criteria** (AIC, BIC, HQIC, and
    FPE), and other details like **log likelihood**. These metrics help assess the
    overall fit and complexity of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: At the end of the summary, there is **correlation matrix** of residuals. The
    matrix show the correlations between the residuals (Errors) from each equation
    in the VAR model. Ideally, you want these off-diagonal values to be as close to
    **zero** as possible. A low correlation suggests that the model has captured most
    of the relationship between the variables, and there is little leftover correlation
    in the residuals.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The correlation between the residuals for `FEDFUNDS` and `unrate` is `-0.1159`,
    which is relatively small, indicating that the model has done a good job capturing
    the relationship between the two variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Store the VAR lag order using the `k_ar` attribute so that we can use it later
    when we use the forecast method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This shows that the optimal lag order selected was 3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you can forecast using either the `forecast` or `forecast_interval`
    method. The latter will return the forecast, as well as the **upper** and **lower
    confidence intervals**. Both methods will require past values and the number of
    steps ahead to forecast. The prior values (`past_y`) will be used as the initial
    values for the forecast:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Since you applied `StandardScalar` on the dataset, the forecast values are
    scaled. You will need to apply `inverse_transform` to convert them back to the
    original scale of the data. You can also convert the forecasts and confidence
    interval into pandas DataFrames for convenience:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the actual versus forecasted `unrate` with the confidence intervals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This should plot the actual test data, the forecast (middle dashed line) for
    `unrate`, along with the upper and lower confidence intervals:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Plotting the forecast with confidence intervals for unrate](img/file259.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – Plotting the forecast with confidence intervals for unrate
  prefs: []
  type: TYPE_NORMAL
- en: 'In a VAR model, all variables are forecasted simultaneously because the model
    assumes that past values of all variables in the system contribute to the future
    values of each variable. So, even though you may only be interested in predicting
    `unrate` from `FEDFUNDS`, the model forecasts the future values of `FEDFUNDS`
    based on `unrate`. You can visualize the forecast for `FEDFUNDS` in a similar
    way as you did for `unrate` as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 11.13 – Plotting the forecast with confidence intervals for FEDFUNDS](img/file260.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 – Plotting the forecast with confidence intervals for FEDFUNDS
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the training data was set up until the end of 2022, which includes
    the significant economic disruption caused by COVID-19 in 2020\. Thus, the model’s
    predictions may not perform as well as expected due to the large and sudden shifts
    in the data.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You may need to adjust the train-test split to accommodate this fact and perform
    different experiments with the model. When dealing with major anomalies like COVID-19,
    it is essential to assess whether the event is a **one-time anomaly** whose effects
    will fade or whether it represents a lasting change that requires special handling
    in your model.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is where **domain knowledge** becomes crucial: understanding the economic
    context will help you decide whether to model such events or treat them as outliers
    that shouldn’t influence future predictions.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Vector autoregressive models (VAR) are very useful, especially in **econometrics**.
    When evaluating the performance of a VAR model, it is common to report to report
    results from several important analysis, such as **Granger causality tests**,
    residual (or error) analysis, and **impulse response analysis**. These are critical
    for understanding the interactions between variables. You will explore these in
    the next recipe, *Evaluating vector autoregressive (VAR) models*.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 11.11*, a VAR(1) model for two variables results in two equations.
    Each equation models the current value of one variables as a function of its own
    lagged values and the lagged values of the other variable. The matrix notation
    shows **four coefficients** and **two constants**. Each equation has two **coefficients**
    for the lagged values of both variables (e.g. and for and and for ). The **constants**
    and represent the intercepts for each equation.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, the model selected was a VAR(3) model for two variables. The
    key difference between a VAR(1) and a VAR(3) is the increased complexity due to
    additional lagged terms. In VAR(3) model, you will have **twelve coefficients**
    (three lags per variable) and **two constants** to solve for. Each equation is
    estimated using **OLS**, as shown in the `results.summary()` output.
  prefs: []
  type: TYPE_NORMAL
- en: The two functions represented in *Figure 11.11* for VAR(1) show how each variables
    is influence not only by its own past values but also the past values of the second
    (endogenous) variable. This is a key difference between a VAR model and an AR
    model (which only considers a variable’s own lags). A VAR model captures the dynamic
    interaction between multiple variables over time.
  prefs: []
  type: TYPE_NORMAL
- en: In the next recipe, now that the model is fitted, you will spend time plotting
    VAR-specific outputs – for example, the **impulse responses (IRs)** and the **forecast
    error variance decomposition (FEVD)** – to better understand these interactions
    and how the variables influence each other.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe we focused on using the model for **forecasting**; next, we will
    focus on understanding the **causal relationships**, using tools like Granger
    causality tests, and evaluating the overall performance of the model through additional
    diagnostics.
  prefs: []
  type: TYPE_NORMAL
- en: VARIMA (Vector ARIMA) models extend VAR to handle non-stationary data by incorporating
    **differencing**. We didn't use it here because both time series were stationary,
    so differencing wasn’t needed. Consider VARIMA when dealing with multiple non-stationary
    variables that require differencing to achieve stationarity.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we are focusing on comparing forecasting results, it would be interesting
    to see if our VAR(3) model, with two endogenous variables, performs better than
    a univariate AR(3) model. Comparing multivariate VAR(3) model to a simpler AR(3)
    (or ARIMA(3,0,0)) model will help assess whether the inclusion of the second variables
    (`FEDFUNDS`) improves the forecast for `unrate`.
  prefs: []
  type: TYPE_NORMAL
- en: You can try fitting an AR(3) or ARIMA(3,0,0) model to the **unrate** time series,
    using the same lag values for consistency. Since that the `unrate` series is stationary,
    there is no need for differencing. Recall, from the previous activity that `lag_order`
    is equal to 3.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'You can review the ARIMA model''s summary using `model.summary()`. After fitting
    the model, you can evaluate the residuals by plotting diagnostic charts to check
    for any issues with the model’s fit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce four diagnostic subplots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.14 –Output of AR(3) or ARIMA(3, 0, 0) model diagnostic plots](img/file261.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.14 –Output of AR(3) or ARIMA(3, 0, 0) model diagnostic plots
  prefs: []
  type: TYPE_NORMAL
- en: The Standardized residual plot shows a significant spike around 2020, likely
    due to the economic impact of COVID-19\. There are also some deviations from normality
    based on the Q-Q plots suggesting the model may not full capture the tail behavior
    of the data. Overall, the AR model captured the necessary information based on
    the autocorrelation plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, forecast future streps using the AR(3) model and compare it to the VAR(3)
    model, which we already fitted and applied `inverse_transform` to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.15 – AR(3) forecast versus actual comparison against test](img/file262.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.15 – AR(3) forecast versus actual comparison against test
  prefs: []
  type: TYPE_NORMAL
- en: 'The same plot can be done for the VAR(3) model, which includes the impact of
    `FEDFUNDS` on `unrate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.16 – VAR(3) forecast versus actual comparison against test](img/file263.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.16 – VAR(3) forecast versus actual comparison against test
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s calculate the **root-mean-square error** (**RMSE**) scores for
    both models (VAR and AR) to see which one performs better on the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The AR(3) model has a lower RMSE compared to the VAR(3) model, indicating that
    the simpler AR(3) model, which only considers the past values of `unrate`, actually
    performs better in this case. The VAR(3) model, which incorporates both `unrate`
    and `FEDFUNDS`, doesn’t significantly improve the forecast for `unrate`.
  prefs: []
  type: TYPE_NORMAL
- en: Given the results, an AR(3) model might be preferred due to its lower complexity
    and better forecasting accuracy. However, when there are stronger interactions
    between the variables, a VAR model can provide **additional insights** and more
    accurate forecasts.
  prefs: []
  type: TYPE_NORMAL
- en: See also...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To learn more about the VAR class in statsmodels, please visit the official
    documentation at [https://www.statsmodels.org/dev/generated/statsmodels.tsa.vector_ar.var_model.VAR.html](https://www.statsmodels.org/dev/generated/statsmodels.tsa.vector_ar.var_model.VAR.html).
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating vector autoregressive (VAR) models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After fitting a VAR model, the next step is to evaluate how well the model captures
    the interactions and dynamic relationships between the different endogenous variables
    (multiple time series). Understanding these relationships can help you asses causality,
    how one variable influences another, and how shocks to one variable propagate
    through the system.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will continue where you left off from the previous recipe,
    *Forecasting multivariate time series data* using *VAR*, and explore various diagnostic
    tools to deepen your understanding of the VAR model. Specifically, test for granger
    causality, analyze **Residual Autocorrelation Function** (**ACF**) plots, use
    the **Impulse Response Function** (**IRF**), and perform **Forecast Error Variance
    Decomposition** (**FEVD**).
  prefs: []
  type: TYPE_NORMAL
- en: These evaluation steps will help you understand both the **causal relationships**
    and the **interdependencies** between the variables in your system, ensuring that
    your model captures the underlying dynamics correctly.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following steps continue from the previous recipe. If you have not performed
    those steps, you can run the code from the accompanying **Jupyter Notebook** to
    follow along. You will focus on diagnosing the VAR(3) model that was created in
    the earlier recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: First, perform a Granger causality test to determine if one time series can
    be used to predict another. In this case, you want to find out if `FEDFUNDS` can
    be used to predict `unrate`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on the previous recipe, you have already selected **3 lags** using the
    **BIC** criterion. However, you can adjust the lag order and test for higher lags
    if needed, depending on the nature of your data or specific research question.
  prefs: []
  type: TYPE_NORMAL
- en: '**Granger causality tests** are implemented in `statsmodels` with the `grangercausalitytests()`
    function, which performs **four tests** across each past lag. You can control
    this using the `maxlag` parameter. Granger causality tests are used to determine
    if past values from one variable influence the other variable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The **null hypothesis** in the Granger causality test is that the second variable
    (in this case `FEDFUNDS`) does not granger cause the first variable (in this case,
    `unrate`). In other words, it assumes there is no **statistical significance**
    *in terms of influence or effect*. To test if `FEDFUNDS` influences `unrate`,
    you will need to switch the order of the columns before applying the test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The test is set for a maximum of 3 lags, based on the BIC criterion selected
    earlier. The output will show the *test statistics*, *p-values*, *and degrees
    of freedom* for each lag. Focus on the **p-value** to decide whether to reject
    or accept the null hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Since the p-values for lags 2 and 3 are less than 0.05, this suggests that `FEDFUNDS`
    does **Granger-cause** `unrate`. In other words, past values of `FEDFUNDS` provide
    significant predictive power for `unrate` when considering a lag of 2 or 3 months.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you will explore the residual plots. The `results` object from the previous
    recipe `results = model.fit(ic=''bic'')`, is of the `VARResultsWrapper` type,
    which is the same as the `VARResults` class and has access to the same methods
    and attributes. Start with the **ACF** plot of the residuals using the `plot_acorr`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce four plots (2x2 plots – two for each variable) for **autocorrelation**
    and **cross-correlation** between the residuals. Recall from *Figure 11.11* that
    for two variables, you will have two functions, and this translates into 2x2 residual
    subplots. If you had three variables, you would have a 3x3 subplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.17 – Residual autocorrelation and cross-correlation plots](img/file264.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.17 – Residual autocorrelation and cross-correlation plots
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the plots in *Figure 11.17* do not have proper labels. The first
    row of plots corresponds to the first variable in the DataFrame (`FEDFUNDS`),
    and the second row corresponds to the second variable in the DataFrame (`unrate`).
  prefs: []
  type: TYPE_NORMAL
- en: You are looking for no significant autocorrelation in the residuals which is
    the case in *Figure 11.17*. This would confirm that the VAR(3) model has effectively
    captured the dynamic relationships between the variables (`FEDFUNDS` and `unrate`),
    with no leftover patterns in the residual that the model failed to capture and
    account for.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want a mode tailed look at the residuals for each variable separately,
    you can do so by extracting the residuals using the `resid` attribute. This would
    return a DataFrame of the residuals for each variable. You can use the standard
    `plot_acf` function to create your ACF plots:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: This should produce two ACF plots – one for `FEDFUNDS` and another for `unrate`.
    This will confirm the same finding – that there is no significant autocorrelation
    in the residuals.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will move to the **Impulse Response Function (IRF)** analysis. The
    IRF helps you visualize and understand how shocks to one variable affect another
    variable (or itself) over time, which is crucial for assessing the dynamic interactions
    between the variables in a VAR model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will analyze the impulse response to shocks in the system using the `irf`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The `irf_output` object is of the `IRAnalysis` type and has access to a `plot()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.18 – Impulse response showing the effect of one unit change in
    one variable against another](img/file265.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.18 – Impulse response showing the effect of one unit change in one
    variable against another
  prefs: []
  type: TYPE_NORMAL
- en: The **Impulse Response Function (IRF)** analysis computes the dynamic impulse
    responses and the approximated standard errors, and displays the effect of a shock
    (or impulse) in one variable and the response in the other variables over time
    (lags). In a **VAR model**, all the variables influence each other, and the IRF
    traces the effect of a change in one variable and its influence on the other variables
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the plot **FEDFUNDS → unrate** (bottom left in *Figure 11.18*)
    shows
  prefs: []
  type: TYPE_NORMAL
- en: how `unrate` responds to a one-unit increase in `FEDFUNDS` across the 10 lags.
    Immediately, there is noticeable **sharp negative response** in `unrate`, indicating
    that an increase in federal funds rate lowers the unemployment rate. The effect
    persists but gradually diminishes over time, which is consistent with how monetary
    policy impacts employment in the economy. We see this effect from *lag 2* to *lag
    3*, where these is a period of **stabilization**. The response levels off a bit,
    this is where the **delayed effect** becomes visible; as the initial drop occurs
    quickly, the total adjustment takes longer as `unrate` remains below the starting
    point. After *lag 3*, we see a slight upward movement in `unrate` and this gradual
    adjustment suggests that the `unrate` starts to recover slowly but does not yet
    fully return to its pre-shock level for several periods.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the **unrate → FEDFUNDS** (top right in *Figure 11.18*) shows
    a relatively small and slightly positive response. This suggests that an increase
    in unemployment (`unrate`) leads to a slight rise in `FEDFUNDS`, but the effect
    diminishes over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you only want to see the response of one variable to another (instead of
    all subplots), you can specify the `impulse` and a `response` variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the cumulative response effect:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 11.19 – Plot of the Cumulative Impulse Responses Function](img/file266.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.19 – Plot of the Cumulative Impulse Responses Function
  prefs: []
  type: TYPE_NORMAL
- en: The cumulative response plot shows how the effect of a shock builds up over
    time. For example, **FEDFUNDS → unrate** plot (bottom left in *Figure 11.19*),
    you can see that the commutative effect of a one-unit increase in FEDFUNDS leads
    to a sustained decrease in `unrate` overtime. The cumulative response helps you
    assess the long-term impact of these shocks.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will move to **Forecast Error Variance Decomposition (FEVD**) to quantity
    how much of the **forecast error variance** of each variable in the system is
    attributed to shocks in itself and shocks in the other variables. In other words,
    you want to understand the contribution of shocks from each variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can compute the FEVD using the using the `fevd()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'You can explore the FEVD results using either `fv.summay()` and `fv.plot()`
    methods. Both of which provide similar information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: This will produce two FEVD plot (Figure 11.20) one for each variable.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.20 – FEVD plot for the FEDFUNDS and unrate variables](img/file267.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.20 – FEVD plot for the FEDFUNDS and unrate variables
  prefs: []
  type: TYPE_NORMAL
- en: The x-axis represents the number of periods (lags) from 0 to 9, and the y-axis
    represents the percentage (0 to 100%) that each shock contributed to the forecast
    error variance Visually, the contribution of each shock is represented as a portion
    of the total bar for every period.
  prefs: []
  type: TYPE_NORMAL
- en: The **FEDFUNDS plot** (top) shows that the entire forecast error variance in
    `FEDFUNDS` is explained by its own shocks. This means that shocks to `unrate`
    have no impact on the forecast error variance of `FEDFUNDS`.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the **unrate plot** (bottom) starts off by showing that the
    forecast error variance of `unrate` is mostly explained by its own shocks. However,
    starting from *lag 4*, the contribution from `FEDFUNDS` begins to grow. By *lag
    9*, roughly around 30% of the variance in `unrate` can be said to be driven by
    shocks from `FEDFUNDS`. This suggest that, over longer time horizons, `FEDFUNDS`
    becomes a more significant driver to `unrate’s` forecast error variance.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The VAR implementation from statsmodels offers several tools to help you understand
    the dynamic relationships between the different time series (or endogenous variables).
    This includes methods like Granger causality tests, Impulse Response Functions
    (IRFs), and Forecast Error Variance Decomposition (FEVD). Each of these tools
    gives you a different perspective on how variables in the system interact over
    time, whether through causal links or how shocks to one variable influence others.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to understanding relationships, diagnostic tools (such as residual
    analysis and autocorrelation plots) are provided to help you assess model fit
    and determine whether any adjustments (like model order, differencing, or additional
    variables) are necessary.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Earlier, in the *Forecasting multivariate time series data using VAR* recipe,
    you manually created a forecast plot. However, the `results` object (an instance
    of the `VARResults` class) offers a convenient way for you to plot your forecasts
    quickly using the `plot_forecast` method. This function automatically generates
    a forecast along with confidence intervals.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `n` is the number of future steps. This should produce two subplots,
    with one forecast for each variable, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.21 – Forecast plots for FEDFUNDS and unrate](img/file268.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.21 – Forecast plots for FEDFUNDS and unrate
  prefs: []
  type: TYPE_NORMAL
- en: See also…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To learn more about the `VARResults` class and all the available methods and
    attributes, visit the official documentation at [https://www.statsmodels.org/dev/generated/statsmodels.tsa.vector_ar.var_model.VARResults.html](https://www.statsmodels.org/dev/generated/statsmodels.tsa.vector_ar.var_model.VARResults.html).
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting volatility in financial time series data with GARCH
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When working with financial time series data, a common task is measuring **volatility**,
    which represents uncertainty in future returns. Generally, volatility measures
    the spread of the probability distribution of returns over a specific period,
    often calculated as the **variance** or **standard deviation** (which is the square
    root of variance). It is used as a proxy for quantifying **risk** or **uncertainty**.
    In other words, it measures the dispersion of financial asset returns around an
    expected value. Higher volatility indicates higher risks. This helps investors
    understand the level of return they can expect and how often their returns will
    differ from the expected value.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the models we discussed previously (e.g., ARIMA, SARIMA, and Prophet)
    focused on forecasting an observed variable based on its past values. However,
    these models assume a constant variance (**homoskedasticity**) and do not account
    for changes in variance over time (**heteroskedasticity**).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, you will work with a different kind of forecasting: forecasting
    and modeling changes in variance over time. This is known as volatility. In general,
    volatility is an important measure of risk when there is uncertainty and it is
    an important concept when working with financial data.'
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, you will be introduced to a new family of algorithms related
    to **Autoregressive Conditional Heteroskedasticity (ARCH)**. The ARCH model captures
    change in variance over time, modeled as a function of squared error terms (*innovations*)
    from past time points. An extension of ARCH is the **GARCH** model, which stands
    for **Generalized Autoregressive Conditional Heteroskedasticity**. It extends
    ARCH by adding a moving average component to account for past variances, providing
    a more flexible and persistent volatility structure.
  prefs: []
  type: TYPE_NORMAL
- en: GARCH is popular in econometrics and is widely used by financial institutes
    for assessing investments and market risks. Predicting turbulence and volatility
    is just as important as forecasting future prices, and many trading strategies
    -such as **mean reversion**- utilize volatility as a key factor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving forward, let''s break down the components of a general ARCH model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Autoregressive**- a concept we explored in *Chapter 10*, *Building Univariate
    Time Series Models Using Statistical Methods*, means that the current value of
    a variable is influenced by its past values. In ARCH models this means that current
    volatility (*variance*) is influence by past values of the squared error terms
    (*innovations*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heteroskedasticity-** means that the model may have different magnitudes
    or variability at different time points (variance changes over time).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conditional**- since the variance (volatility) is not fixed, it depends on
    past information. In other words, the variance at a given time point is conditionally
    dependent on past values from the series, meaning that volatility is updated as
    new information becomes available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this recipe, you will create a **GARCH model** of order (**p, q**), where
    **p** represents the number of lagged **variances** (the **GARCH term**), and
    **q** represents the number of lagged **squared residuals** (the **ARCH term**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `arch` Python library, you will implement this with the `arch_model`
    function. The parameters in this function can be broken down into three main components
    based on the GARCH model''s assumptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dist` : Controls the distribution assumption for the innovations (residuals)
    and defaults to `''normal''`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mean` : Controls the model for the conditional mean and defaults to `''Constant''`,
    whichassumes a constant mean'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vol` : Controls the volatility model (conditional variance) and defaults to
    `''GARCH''`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In most literature, **q** typically represents the **ARCH order** (the number
    of lagged squared residuals or innovations), while **p** represents the **GARCH
    order** (the number of lagged variances). However, in the `arch` Python library,
    the roles of **p** and **q** are **reversed**.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the `arch` package, **p** refers to the lag order of the **squared residuals**
    (the **ARCH** component), and **q** refers to the lag order of the **lagged variances**
    (the **GARCH** component).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This distinction is important to keep in mind when specifying and interpreting
    GARCH models using the `arch` library, as it differs from the conventional notation
    used in the academic literature.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For example, specifying `p=2` and `q=1` in `arch_model` would actually fit a
    **GARCH(1, 2)** model according to the conventional notation (with 1 lagged variance
    and 2 lagged residuals)
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this recipe, you will be using the `arch` library, which contains several
    volatility models, as well as financial econometrics tools. The library produces
    similar output to those from the statsmodels library. At the time of writing,
    the latest version is `7.1.0`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install `arch` using **pip**, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'To install `arch` using **conda**, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When using the `arch_model` function from the `arch` library to build the **GARCH**
    model, there are a few key parameters: the default **distribution** is *normal*
    (`dist=''normal''`), the **mean** model is constant (`mean=''Constant''`), and
    the **volatility model** is GARCH (`vol=''GARCH''` by default). Other mean models,
    such as autoregressive models (`''AR''`) can also be specified depending on the
    context. Similarly, other volatility models can be selected such `''GARCH''`,
    `''ARCH''`, `''EGARCH''`, `''FIGARCH''`, and `''APARCH''`. You can also select
    different distributions such as ''`gaussian''`, `''t''`, `''studentst''`, `''skewstudent''.`'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be using the **Microsoft** daily closing price dataset for this recipe.
    Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by loading the necessary libraries for this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the `MSFT.csv` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: You will need to convert the daily stock price into a **daily stock return.**
    This can be calculated as where is the price at time and is the price from the
    previous day. This can be done easily in pandas using the `DataFrame.pct_change()`
    function, followed by multiplying by 100to express returns as **percentages**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `pct_change()` function takes a `periods` parameter that defaults to `1`.
    If you want to calculate a 30-day return, then you will need change that value
    to `pct_change(periods=30)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: The `dropna` step is necessary because calculating `returns` will produce `NaN`
    for the first row.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can plot both the daily stock price and daily return:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.22 – Microsoft daily closing price and daily returns](img/file269.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.22 – Microsoft daily closing price and daily returns
  prefs: []
  type: TYPE_NORMAL
- en: Split the data into train and test. For short-term volatility forecasting you
    will examin how well the model predicts the next few day’s volatility. When splitting
    the data, you will leave the last 5 days for testing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Fit a **GARCH(p, q)** model. Start with the simple GARCH(1,1) model with all
    the default options – that is, `mean='Constant'`, distribution as `dist='normal'`,
    volatility as `vol='GARCH'`, `p=1`, and `q=1`. A GARCH(1,1) is the most commonly
    used model, and a good starting point, for volatility forecasting due to its simplicity
    and effectiveness in capturing volatility clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The fitting process was completed in nine (9) iterations. Using `update_freq=3`
    affects the frequency of printing the progress during the fitting process. The
    default is one (1) which means it will print out an output on each iteration.
    By setting it to three (3) we get an output every three iterations. To print the
    summary, use the `summary()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.22 – Summary of the GARCH(1,1) model](img/file270.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.22 – Summary of the GARCH(1,1) model
  prefs: []
  type: TYPE_NORMAL
- en: The *omega*, *alpha*, and *beta* parameters (the symbols) of the GARCH(1,1)
    model are estimated using the **Maximum Likelihood** method. The `p-value` for
    the coefficients indicates they are *statistically* *significant*.
  prefs: []
  type: TYPE_NORMAL
- en: You can access several of the components that you see in the summary table by
    calling the appropriate attribute from the `results` object – for example, `results.pvalues`,
    `results.tvalues`, `results.std_err`, or `results.params`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you need to evaluate the model''s performance. Start by plotting the
    standardized residuals and conditional volatility using the `plot` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.23 – Model diagnostics for the GARCH(1,1) model](img/file271.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.23 – Model diagnostics for the GARCH(1,1) model
  prefs: []
  type: TYPE_NORMAL
- en: If the model is well-fitted, then the **Standardized Residuals** plot should
    look like white noise, indicating no patterns remain in the residuals. The plot
    seems to show randomness without obvious patterns indicating a good fit. The **Conditional
    Volatility** plot shows the time-varying volatility that the model has estimated,
    reflecting how volatility changes over time. You can see periods of high and low
    volatility reflecting market conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot a histogram for the standardized residuals. You can obtain this using
    the `std_resid` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 11.24 – Histogram plot for the standardized residuals of the GARCH
    model](img/file272.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.24 – Histogram plot for the standardized residuals of the GARCH model
  prefs: []
  type: TYPE_NORMAL
- en: The histogram suggests that the standardized residuals are roughly normal, though
    you can use additional statistical tests, like the **Jarque-Bera** test, for a
    more formal assessment of normality
  prefs: []
  type: TYPE_NORMAL
- en: You can further evaluate the model by testing for **autocorrelation** using
    the **Ljung-Box test**, which tests the null hypothesis of no autocorrelation.
    For the first 10 lags, use `acorr_ljungbox`. A p-value greater than 0.05 indicates
    that the null hypothesis cannot be rejected, suggesting no significant autocorrelation
    at that lag.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: The p-values from the Ljung-Box test suggest that there is no significant autocorrelation
    in the standardized residuals at most lags. Since most p-values are above 0.05,
    we fail to reject the null hypothesis of no autocorrelation, indicating a good
    model fit.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make a prediction, use the `forecast()` method. The default is to produce
    a one (1) step ahead forecast. To get `n` number of steps ahead, you will need
    to update the `horizon` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'To access the predicted future variance (or volatility), use the `variance`
    property from the `msft_forecast` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also evaluate the predicted mean. Recall that when you fit the model,
    you specified that the mean as `Constant`. This is further validated if you examine
    the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: This will print out a constant value of `0.144878` across all horizons.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`GARCH(p,q)` can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file273.jpg)Omega, alpha, and beta (![](img/file274.png)) are parameters
    here. The `p` order is commonly referred to as the GARCH order, while `q` is referred
    to as the ARCH order.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The parameters for the GARCH model represent the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Omega** : the constant or baseline variance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alpha**: The coefficient for the lagged squared residuals (*ARCH term*),
    which measures the impact of recent shocks on volatility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Beta**: The coefficient for the lagged variances (*GARCH term*), representing
    the persistence of volatility over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the `arch` Python package, the roles of **p** and **q** are swapped, with
    **p** representing the ARCH component (lagged squared residuals) and **q** representing
    the GARCH component (lagged variances).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The GARCH(1,1) that you implemented can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file275.png)'
  prefs: []
  type: TYPE_IMG
- en: INNOVATIONS VERSUS ERRORS IN TIME SERIES
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In time series literature, you will come across the term **innovations**, which
    refers to unexpected and unpredictable new information, shocks, or errors that
    cannot be forecasted using past information. Put simply, you can think of **innovations**
    as forecast errors or surprises at each time step. While in machine learning,
    we often refer to these as prediction errors, in time series models like ARCH/GARCH,
    we use the term **innovations** to describe the new, unanticipated information
    affecting the model.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Previously, when implementing the GARCH model, you set the mean to `'Constant'`.
    Now, let's explore the impact of changing the mean to `'Zero'`, which effectively
    removes the mean model from the equation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by setting `mean='Zero':`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce the GARCH summary in a tabular format:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.25 – GARCH(1, 1) with a zero mean](img/file276.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.25 – GARCH(1, 1) with a zero mean
  prefs: []
  type: TYPE_NORMAL
- en: Notice that in Figure 11.25, there is no mean model like the one shown in Figure
    11.21\. Using a **Zero Mean** is common when you want to separate the modeling
    of **volatility** from the **mean**. This approach can be helpful in situations
    where you are primarily interested in modeling volatility and don’t need a mean
    model for the underlying returns.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To learn more about the `arch` library, please visit the official documentation
    at [https://arch.readthedocs.io/en/latest/univariate/introduction.html](https://arch.readthedocs.io/en/latest/univariate/introduction.html).
  prefs: []
  type: TYPE_NORMAL
